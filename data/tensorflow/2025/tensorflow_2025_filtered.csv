yi,copybara-service[bot],Update `googletest` used by XLA and Tensorflow from the 2022/6/30 version to the 2025/3/21 version. This:,"Update `googletest` used by XLA and Tensorflow from the 2022/6/30 version to the 2025/3/21 version. This:  makes the internal build and the OSS build of OpenXLA use the same googletest version and thus be consistent.  unlocks a bunch of planned improvements (enforcing that a test program has at least one test case, simplifying copybara setup, etc).",2025-03-26T23:24:30Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/90082
rag,copybara-service[bot],[HLO Test Coverage] Add XLA Builder lit tests for uncovered APIs used by tf2xla,[HLO Test Coverage] Add XLA Builder lit tests for uncovered APIs used by tf2xla Other minor additions:  HLO Translate for Cosine / Sine / ResultAccuracyMode Tolerance  Dynamic conv custom call tests  IsConstant visitor test,2025-03-26T18:14:52Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/90072
yi,copybara-service[bot],Update OpenXLA's `googletest` from the 2022/6/30 version to the 2025/3/21 version. This:,"Update OpenXLA's `googletest` from the 2022/6/30 version to the 2025/3/21 version. This:  makes the internal build and the OSS build of OpenXLA use the same googletest version and thus be consistent.  unlocks a bunch of planned improvements (enforcing that a test program has at least one test case, simplifying copybara setup, etc).",2025-03-26T17:29:33Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/90069
gemma,copybara-service[bot],[XLA] Reorder GEMMA2 benchmark from nightly build script due to temp failure,[XLA] Reorder GEMMA2 benchmark from nightly build script due to temp failure This has been causing build errors for a while.,2025-03-26T16:49:05Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/90067
rag,copybara-service[bot],[XLA:GPU] Clean up `DebugOptions` and turn off autotuning in `dot_algorithms_test`.,[XLA:GPU] Clean up `DebugOptions` and turn off autotuning in `dot_algorithms_test`. This makes the test run >10x faster without loss of useful coverage.,2025-03-26T15:57:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/90062
yi,Rolexo,Tensorflow_installation_issue," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.19.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? i expected the dataset to be loaded  ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[7], line 1 > 1 import tensorflow as tf       2 print(tf.__version__) File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\User\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.  Standalone code to reproduce the issue ```shell  ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[7], line 1 > 1 import tensorflow as tf       2 print(tf.__version__) File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\User\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. ```  Relevant log output ```shell  ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[7], line 1 > 1 import tensorflow as tf       2 print(tf.__version__) File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\User\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. ```",2025-03-26T04:08:13Z,stat:awaiting response type:build/install TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/90025,"Hi  , could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios: You need to install the MSVC 2019 redistributable Your CPU does not support AVX2 instructions Your CPU/Python is on 32 bits There is a library that is in a different location/not installed on your system that cannot be loaded. Also kindly provide the environment details and the steps followed to install the tensorflow. https://github.com/tensorflow/tensorflow/issues/61887 Also this is a duplicate of https://github.com/tensorflow/tensorflow/issues/19584 Thank you!",Did you reinstall packages? Check if you are in the right env?
transformer,copybara-service[bot],Add a proto matcher library for XLA.,"Add a proto matcher library for XLA. This library defines `EqualsProto(expected)` for matching a proto by equality. It also defines two matcher transformers `Partially()` and `IgnoringRepeatedFieldOrdering()` for making the matcher ignore fields not set in the expected proto and ignore order of elements in repeated fields, respectively. Also use the library in tensorflow/compiler/xla/client/executable_build_options_test..",2025-03-25T23:55:49Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/90006
gemma,copybara-service[bot],Run gemma3_1b_flax_call.hlo and gemma3_1b_flax_sample_loop.hlo in CPU/GPU nightly workflows,Run gemma3_1b_flax_call.hlo and gemma3_1b_flax_sample_loop.hlo in CPU/GPU nightly workflows,2025-03-25T17:38:01Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89967
yi,copybara-service[bot],[xla:copy_insertion] Generalize the handling of pipelined Send/Recv to handle,[xla:copy_insertion] Generalize the handling of pipelined Send/Recv to handle asynchronous operations that produce noncopyable results. FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/89799 from mistersmee:master fe2a4036944d0a3d9f9a16a85581a79ddba11775,2025-03-25T15:48:30Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89960
yi,raghureddy-sripathi,from deepface import DeepFace," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.19  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: unable import DeepFace from deepface how to get rid of this error?  Standalone code to reproduce the issue ```shell  ImportError                               Traceback (most recent call last) File c:\Users\ADMIN\AppData\Local\Programs\Python\Python311\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[2], line 2       1 import cv2 > 2 from deepface import DeepFace File c:\Users\ADMIN\AppData\Local\Programs\Python\Python311\Lib\sitepackages\deepface\DeepFace.py:15      13 import numpy as np      14 import pandas as pd > 15 import tensorflow as tf      17  package dependencies      18 from deepface.commons import package_utils, folder_utils File c:\Users\ADMIN\AppData\Local\Programs\Python\Python311\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File c:\Users\ADMIN\AppData\Local\Programs\Python\Python311\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.')      97  pylint: enable=wildcardimport,gimportnotattop,unusedimport,linetoolong ImportError: Traceback (most recent call last):   File ""c:\Users\ADMIN\AppData\Local\Programs\Python\Python311\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. ```  Relevant log output ```shell ```",2025-03-24T20:40:57Z,type:bug TF 2.18,closed,0,9,https://github.com/tensorflow/tensorflow/issues/89906,"Hi sripathi , could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios: You need to install the MSVC 2019 redistributable Your CPU does not support AVX2 instructions Your CPU/Python is on 32 bits There is a library that is in a different location/not installed on your system that cannot be loaded. Also kindly provide the environment details and the steps followed to install the tensorflow. https://github.com/tensorflow/tensorflow/issues/61887 Also this is a duplicate of https://github.com/tensorflow/tensorflow/issues/19584 Thank you!",Are you satisfied with the resolution of your issue? Yes No,"> Hi sripathi , could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios: >  > You need to install the MSVC 2019 redistributable Your CPU does not support AVX2 instructions Your CPU/Python is on 32 bits There is a library that is in a different location/not installed on your system that cannot be loaded. Also kindly provide the environment details and the steps followed to install the tensorflow.  CC(Tensorflow failed build due to ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.) Also this is a duplicate of  CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) Thank you! HI   Thank you for response. Actually the thing is that i'm using python 3.11.5 and want to use deepface library but it doesn't work with latest version of python so i'm getting this error every time i'm trying to run. so i tried to download 3.9 version of python it works right now. maybe latest version doesn't have all modules.","If 3.9 works but 3.11 doesn't, then that's a different issue than CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.), sorry for that. Can you please post some samples to show how a simple Python script (could be as simple as `import tensorflow as tf`) fails to execute with 3.11 but fails with 3.9? For both versions, also please post output of `pip list`. And, just to confirm, are you building from source (given ""source"" answer in the form) or installing TF via `pip install`? Can you also list how you are installing TF/packages you use, if it's not `pip install`?","> Deepface is not TF, likely the issue should be opened there. >  > But, for the TF bits, this is a duplicate. Always search for duplicates. Hi  yeah I know but i tried to run this it doesn't work with latest version of python. I thought if i update tensorflow version it might change but I already have latest version. So, instead of  using python 3.11.5 i tried to solve in python 3.9. now the issue is sorted.","Yeah, if the issue is between python 3.9 and python 3.11 we need to sort this soon, since this is the last version of TF that would support 3.9, I think",Are you satisfied with the resolution of your issue? Yes No,"> Yeah, if the issue is between python 3.9 and python 3.11 we need to sort this soon, since this is the last version of TF that would support 3.9, I think I have no idea that latest version of python does'nt support full extent of  tensorflow. is that true?",We cannot support all versions of Python with all versions of TF. So each release of TF one version of Python might be dropped and another added in.
yi,kossyrev-bg,Keras Hub Model Conversion Fails," 1. System information  Ubuntu 18.04, python 3.12.3  tf installed via `uv pip`   `tensorflow==2.18.1, keras==3.9.0`  2. Code ```  %% import os os.environ['KERAS_BACKEND'] = 'tensorflow'   Set the models from keras_hub to use tensorflow  %% import tensorflow as tf import tensorflow.keras as keras import keras_hub from PIL import Image from IPython.display import display import numpy as np  %%  %%  Input variables here  See https://keras.io/keras_hub/presets/ MODEL_NAME = ""efficientnet_b0_ra4_e3600_r224_imagenet""  Path to training data TRAINING_DATA_PATH = ...  How many classes we want to classify NUM_CLASSES = 2  Trainingrelated tuning  How many GPUs to use, assumes they are named GPU:0, GPU:1, etc. NUM_GPUS = 4 BATCH_SIZE = 32   Per GPU NUM_EPOCHS = 10 NUM_AUGS = 2   Number of random augmentations to apply to each image AUG_STRENGTH = 0.5   How strong the augmentations should be  Whether to quantize pertensor or perchannel PER_TENSOR_TFLITE = False  IMAGE_SIZE = 224   GLOBAL_BATCH = NUM_GPUS * BATCH_SIZE  %%  Create a MirroredStrategy. gpus = [f""GPU:{i}"" for i in range(NUM_GPUS)] strategy = tf.distribute.MirroredStrategy(gpus) print(""Number of devices: {}"".format(strategy.num_replicas_in_sync))  Open a strategy scope. with strategy.scope():      Everything that creates variables should be under the strategy scope.      In general this is only model construction & `compile()`.     image_classifier = keras_hub.models.ImageClassifier.from_preset(         MODEL_NAME,         activation=None,   outputs logits         num_classes=NUM_CLASSES     )     image_classifier.compile(         optimizer=keras.optimizers.Adam(             learning_rate=1e4,              clipnorm=1.0         ),         loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),   Consumes logits         metrics=[keras.metrics.SparseCategoricalAccuracy()]     )  %%  Create dataset train_dataset, val_dataset = keras.preprocessing.image_dataset_from_directory(     TRAINING_DATA_PATH,     labels=""inferred"",     label_mode=""int"",     batch_size=None,     image_size=(IMAGE_SIZE, IMAGE_SIZE),     shuffle=True,     validation_split=0.2,     subset=""both"",     interpolation=""bilinear"",     verbose=True,     seed=42 )  Define simple augmenter aug_layer = keras.layers.RandAugment(value_range=(0, 255), num_ops=NUM_AUGS, factor=AUG_STRENGTH) map_fn = lambda x, y: (aug_layer(x, training=True), y)  Prefetch the data, adding augmentation to the training dataset train_dataset = train_dataset.batch(GLOBAL_BATCH, drop_remainder=True).map(map_fn, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE) val_dataset = val_dataset.batch(GLOBAL_BATCH, drop_remainder=True).prefetch(tf.data.AUTOTUNE)  %%  %%  Freeze the base model to only retrain the head (optional)  image_classifier.backbone.trainable = False  Train the model on all available devices. image_classifier.fit(train_dataset, epochs=NUM_EPOCHS, validation_data=val_dataset)  Test the model on all available devices.  TODO: Need a test dataset  image_classifier.evaluate(test_dataset) image_classifier.save(f""{MODEL_NAME}.keras"")  %%  Test the trained model on 10 validation images  This works fine, getting at least 8 correct for imgs, label in val_dataset.take(1):     for i in range(10):         img = imgs[i:i+1]         preds = image_classifier.predict(img)         print(f""Raw preds: {preds}, Predicted: {preds.argmax()}, Actual: {label[i]}"")  %%  Remove preprocessor model_preprocessor = image_classifier.preprocessor image_classifier.preprocessor = None  %%  Create endtoend model that takes in UINT8 image of size 224   Modify preprocessor, because GPU doesn't like bicubic? idk cfg = model_preprocessor.get_config() cfg[""image_converter""][""config""][""interpolation""] = ""bilinear"" new_preproc = keras_hub.models.ImageClassifierPreprocessor.from_config(cfg)  Input layer is (1, 224, 224, 3) uint8 input_layer = keras.layers.Input(shape=(224, 224, 3), dtype=tf.uint8, batch_size=1)  Convert to float 32 like the preprocessor expects (I'd like to skip this if possible,  because it might be part of why the tflite conversion is failing,  but I don't know how without dismantling the preprocessor) float_input = keras.layers.Lambda(lambda x: tf.cast(x, tf.float32))(input_layer)  Preprocess the image preprocessed_input = new_preproc(float_input, training=False)  Run through the model  no doublepreprocessing since we removed it logits = image_classifier(preprocessed_input, training=False)  Combine into one model full_model = keras.models.Model(inputs=float_input, outputs=logits)  Compile the model (unclear if necessary) full_model.compile(     optimizer=keras.optimizers.Adam(1e4),     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),   Consumes logits     metrics=[keras.metrics.SparseCategoricalAccuracy()] ) full_model.trainable = False  %%  Test the new model on 10 validation images. This works too, roughly same  accuracy as above num_correct = 0 num_wrong = 0 for imgs, label in val_dataset.take(1):     for i in range(GLOBAL_BATCH):         img = imgs[i:i+1]          preds = full_model.predict(tf.cast(img, tf.uint8))         preds = full_model.predict(img)         print(f""Raw preds: {preds}, Predicted: {preds.argmax()}, Actual: {label[i]}"")         if preds.argmax() == label[i]:             num_correct += 1         else:             num_wrong += 1 print(f""Correct: {num_correct}, Wrong: {num_wrong}"")  %%  Use data from the validation dataset to calibrate the quantized model def representative_data_gen():     batch_count = (300 // GLOBAL_BATCH) + 1     run = 0     for x, _ in val_dataset.take(batch_count):   Use a few samples         run += 1         print(f""Running batch {run}/{batch_count}"")          Pull one image at a time         for i in range(GLOBAL_BATCH):             img = x[i:i+1]             yield [tf.cast(img, tf.uint8)]             yield [img]  Convert to tflite, using pertensor quantization for ARTPEC8 converter = tf.lite.TFLiteConverter.from_keras_model(full_model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_data_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.inference_input_type = tf.uint8 converter.inference_output_type = tf.float32 if PER_TENSOR_TFLITE:     converter._experimental_disable_per_channel = True tflite_quant_model = converter.convert() with open(f""{MODEL_NAME}.tflite"", ""wb"") as f:     f.write(tflite_quant_model)  %%  Run the TFLite model on some test data interpreter = tf.lite.Interpreter(model_content=tflite_quant_model) input_details = interpreter.get_input_details() output_details = interpreter.get_output_details() input_index = input_details[0][""index""] output_index = output_details[0][""index""] interpreter.allocate_tensors()  %% num_correct = 0 num_wrong = 0 for x, label in val_dataset.take(3):     for i in range(GLOBAL_BATCH):         img = x[i:i+1]          Need to cast to uint8 because tflite model expects it         interpreter.set_tensor(input_index, tf.cast(img, tf.uint8))         interpreter.invoke()         output_data = interpreter.get_tensor(output_index)         print(f""Raw preds: {output_data}, Predicted: {output_data.argmax()}, Actual: {label[i]}"")         if output_data.argmax() == label[i]:             num_correct += 1         else:             num_wrong += 1 print(f""{num_correct=}, {num_wrong=}"") ```  3. Failure after conversion Model accuracy drastically drops after conversion: ``` Raw preds: [[0.08086799  0.20216998]], Predicted: 1, Actual: 0 Raw preds: [[ 0.       0.040434]], Predicted: 0, Actual: 1 Raw preds: [[1.0512838   0.48520795]], Predicted: 1, Actual: 0 Raw preds: [[1.0108498   0.36390597]], Predicted: 1, Actual: 1 Raw preds: [[0.9704159   0.12130199]], Predicted: 1, Actual: 0 Raw preds: [[0.72781193  0.24260397]], Predicted: 1, Actual: 1 Raw preds: [[0.08086799 0.24260397]], Predicted: 0, Actual: 0 Raw preds: [[ 0.16173598 0.040434  ]], Predicted: 0, Actual: 0 Raw preds: [[1.1321518  0.040434 ]], Predicted: 1, Actual: 0 ... Raw preds: [[0.24260397  0.12130199]], Predicted: 1, Actual: 1 Raw preds: [[0.76824594 0.08086799]], Predicted: 1, Actual: 0 Raw preds: [[0.36390597  0.24260397]], Predicted: 1, Actual: 1 num_correct=196, num_wrong=188 ```",2025-03-24T20:37:10Z,stat:awaiting response comp:lite TFLiteConverter TF 2.18,open,0,10,https://github.com/tensorflow/tensorflow/issues/89904,This belongs in keras repos.,"I found the problem with the model setup. However, after the tflite conversion, the model accuracy is still drastically lower than it was before. I can update the code snippet to show the new setup, but it's basically just combining preprocessing with the model into one allinone model. I would still like help with why tflite conversion is reducing accuracy by so much. ","Oh, I misunderstood (from the title), this is not about Keras but model conversion to TFLite. Can you minimize this to a model as small as possible?","This is an efficientnet model from the keras hub: https://www.kaggle.com/models/keras/efficientnet/keras/efficientnet_b0_ra4_e3600_r224_imagenet/ It's about 5MB after quantization to tflite. Is that too big? Do you need the keras model and the tflite model, and do you need the data?",The smaller the model the easier is to debug,"Hi, bg  I apologize for the delay in response, I am able to replicate the same behavior from my end with sample flowers dataset with your provided code snippet here is gistfile for reference so we will have to dig more into this issue and will update you, thank you for bringing this issue to our attention. Thank you for your cooperation. ``` Original model predictions: 1/1 ━━━━━━━━━━━━━━━━━━━━ 3s 3s/step Raw preds: [[2.7760098  3.1728508]], Predicted: 1, Actual: 1 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 326ms/step Raw preds: [[0.55148685  0.8257771 ]], Predicted: 1, Actual: 1 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 280ms/step Raw preds: [[ 3.8654664 4.097068 ]], Predicted: 0, Actual: 0 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 299ms/step Raw preds: [[ 15.905437 15.347878]], Predicted: 0, Actual: 0 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 313ms/step Raw preds: [[0.43868783  1.6053506 ]], Predicted: 1, Actual: 1 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 247ms/step Raw preds: [[ 13.696747 12.681302]], Predicted: 0, Actual: 0 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 199ms/step Raw preds: [[1.2708153   0.60328835]], Predicted: 1, Actual: 1 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 188ms/step Raw preds: [[0.7198984  0.65562236]], Predicted: 0, Actual: 1 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 207ms/step Raw preds: [[1.3494838  2.3646579]], Predicted: 1, Actual: 1 1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 192ms/step Raw preds: [[1.334792   1.3840239]], Predicted: 1, Actual: 1 ``` ``` TFLite model predictions: TFLite output: [[2.4290873e+13  2.2772695e+13]], Predicted class: 1 TFLite output: [[6.0727183e+12  3.0363592e+12]], Predicted class: 1 TFLite output: [[0. 0.]], Predicted class: 0 TFLite output: [[2.1254514e+13  1.9736335e+13]], Predicted class: 1 TFLite output: [[4.2509028e+13  2.1254514e+13]], Predicted class: 1 TFLite output: [[2.2772695e+13  2.1254514e+13]], Predicted class: 1 TFLite output: [[7.5908980e+12  1.2145437e+13]], Predicted class: 1 TFLite output: [[3.1881771e+13  2.1254514e+13]], Predicted class: 1 TFLite output: [[2.4290873e+13  2.1254514e+13]], Predicted class: 1 TFLite output: [[0. 0.]], Predicted class: 0 TFLite output: [[2.4290873e+13 3.4918130e+13]], Predicted class: 1 TFLite output: [[1.3663616e+13  1.5181796e+12]], Predicted class: 1 TFLite output: [[1.5181796e+13  2.2772695e+13]], Predicted class: 1 TFLite output: [[0. 0.]], Predicted class: 0 TFLite output: [[3.4918130e+13  2.7327233e+13]], Predicted class: 1 TFLite output: [[1.0627257e+13  2.1254514e+13]], Predicted class: 1 ```","Ah I'm sorry, let me update the code in the example. I'm no longer running into quite the same scaling error issue. But the outputs are still wrong. I'll post again once it's updated","Okay  the code has been updated, with new example logits, thank you for your help!","I'll go ahead and update the gist file as well, if I can","Hi bg To facilitate further investigation and debugging of the current issue, we would greatly appreciate it if you could consider updating the existing gist file or creating a new Google Colab notebook including a sample flowers dataset within this resource would be particularly helpful for us to reproduce the reported behavior and analyze the underlying cause effectively. Thank you for your cooperation."
yi,copybara-service[bot],[xla] Verify buffer related HLO.,"[xla] Verify buffer related HLO. We have introduced buffer_id field in Shape for representing HLO buffer types. We now extend the verifier to recognize customcall targets pin and unpin along with the existing target allocateBuffer for buffer related operations. When buffers aren't allowed in a program, no Shape can have a valid buffer_id and customcall targets pin and unpin can't be used. This is what all the existing HLO passes would expect. When buffers are allowed, we verify that pin and unpin are used properly. We allow other customcall targets to use buffers. We also allow instructions, such as kTuple, kWhile, kParameter and kGetTupleElement to pass through buffers. All other instructions aren't allowed to use buffers. We will introduce a new HLO pass to convert buffer information to XLA attributes that copyinsertion would understand and clear the buffer_id field in Shapes so that all existing HLO passes won't need to handle buffer_ids.",2025-03-24T14:22:26Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89875
yi,copybara-service[bot],[XLA:GPU] Add number of local participants to GpuCliqueKey.,"[XLA:GPU] Add number of local participants to GpuCliqueKey. The number of local participants doesn't add new information to the key, because we should never get two identical cliques that only different in the number of local participants. However, putting the number inside the key makes so many places in the codebase simpler and avoids annoying recalculations. We can easily count the number of local devices when we create the key, but later it requires getting runtime param and devices ids again.",2025-03-24T14:07:55Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89874
rag,copybara-service[bot],[XLA:GPU] Use the GetReplicaGroupCountAndSize helper in RaggedAllToAllDecomposer pass.,[XLA:GPU] Use the GetReplicaGroupCountAndSize helper in RaggedAllToAllDecomposer pass.,2025-03-24T12:25:26Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89869
gemma,copybara-service[bot],[xla:cpu:benchmarks] Move Gemma 2 PyTorch benchmark to the correct folder.,[xla:cpu:benchmarks] Move Gemma 2 PyTorch benchmark to the correct folder. It was added to the old path by mistake.,2025-03-24T08:59:19Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89858
chat,anushikhov,Move duplicate CUDA/XLA registration logs from INFO to VLOG,"This PR downgrades harmless duplicate cuDNN, cuBLAS, and cuFFT factory registration logs from INFO to VLOG(1), fully silencing them during normal usage. Upstream already reduced these from ERROR to INFO, but they still create unnecessary log noise when XLA and GPU backends initialize. Since the duplicate registration is safe and expected this change preserves visibility only for debugging sessions. Coinspired by ChatGPT during a deep dive into TensorFlow's logging system. Fixes: CC(cuDNN, cuFFT, and cuBLAS Errors)",2025-03-23T04:27:34Z,ready to pull comp:xla size:XS,open,0,1,https://github.com/tensorflow/tensorflow/issues/89808,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request."
yi,mistersmee,"Replace deprecated ""pipes.quote"" with ""shlex.quote"" for ROCm","This is basically f6d09e2, but for ROCm. Quite a minor change, but one I ran across when trying to build the ROCm bits, because the build failed as it tried to import pipes.",2025-03-22T14:48:26Z,ready to pull comp:gpu size:XS,closed,0,1,https://github.com/tensorflow/tensorflow/issues/89799,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request."
yi,copybara-service[bot],ifrt-proxy nit: remove TODO for `array_is_deleted_hack` flag.,"ifrtproxy nit: remove TODO for `array_is_deleted_hack` flag. While a recent commit allowed `IsDeleted()` to be determined at the IFRTproxy client without contacting the server, this may not be always possible; when some IFRT backends are running behind the IFRTproxy server, some `IsDeleted()`calls may need to be proxied through from the client to the server.",2025-03-21T20:17:12Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89762
yi,copybara-service[bot],[xla] Add buffer_id to ShapeProto and the C++ Shape class.,"[xla] Add buffer_id to ShapeProto and the C++ Shape class. This field can be used in an HLO program input to the compiler to group a chain of HLO values sharing the same memory buffer. We intend to have a new HLO pass to convert HLO values with valid buffer_ids to XLA attributes that can be used by copy_insertion, so that all other existing HLO passes won't be affected by this new field. Extend hlo_parser to pass buffer_id.",2025-03-21T17:35:10Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89753
yi,copybara-service[bot],[XLA:GPU] Add a pattern to fold vector.insert(vector.extract).,"[XLA:GPU] Add a pattern to fold vector.insert(vector.extract). When there is nothing fused in the transpose, we read the input and then write it to shmem. We can fold away the packing/unpacking of the vectors. ``` %0 = vector.transfer_read scf.for %arg2 = %c0 to %c2 step %c1 iter_args(%arg3 = %cst) > (vector) {          405:  %3 = vector.extract %0[%arg2] : f32 from vector          406:  %4 = vector.insert %3, %arg3 [%arg2] : f32 into vector          407:  scf.yield %4 : vector          408:  }  ``` vector.transfer_write",2025-03-21T15:07:35Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89741
rag,copybara-service[bot],"If the `dynamic_dimensions` parameter is empty in the `Shape` ctor, assume all dimensions are static.","If the `dynamic_dimensions` parameter is empty in the `Shape` ctor, assume all dimensions are static. Some callers call the `Shape(element_type, dimensions, dynamic_dimensions)` ctor with a nonempty `dimensions` and an empty `dynamic_dimensions`. This breaks the shape object's invariant that the two should have the same size. We have two options for fixing this: 1. Force the caller to always provide a `dynamic_dimensions` whose size matches that of `dimensions`. 2. Provide a sensible default behavior when `dynamic_dimensions` is empty. I chose CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"") as: 1. CC(Add support for Python 3.x) is more risky as it may cause the compiler to crash in production (e.g. if we don't have adequate test coverage). 2. It's very common for an array to have only static dimensions. Therefore it's good to optimize the user experience for this common case.",2025-03-20T22:51:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89684
rag,copybara-service[bot],Support expanding ragged all-to-all dims similar to all-to-alls is not needed.,Support expanding ragged alltoall dims similar to alltoalls is not needed.,2025-03-20T21:45:09Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89680
yi,distlibs,TensorFlow Lite 2.19 ARM compilation failed: TfLiteQuantizationType : int expected identifier or ...," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.19  OS platform and distribution Raspberry Pi OS Bookworm  GCC/compiler version gcc (Debian 12.2.014) 12.2.0  Current behavior? Getting error when trying to compile simple program using TensorFlow Lite 2.19 library on Raspberry Pi. main.c: ``` include  include  include  int main() {     return 0; } ``` Compilation error: ``` In file included from build/usr/local/include/tensorflow/lite/c/common.h:31,                  from main.c:2: build/usr/local/include/tensorflow/lite/core/c/common.h:325:37: error: expected identifier or ‘(’ before ‘:’ token   325    ^~~~~~~~~~~~~~~~~~~~~~ ``` Compilation command: ``` gcc main.c Ibuild/usr/local/include Lbuild/usr/local/lib o test ltensorflowlite_c ``` No problems using TensorFlow Lite 2.18. This commit https://github.com/tensorflow/tensorflow/commit/977257e45ea83169c2dd6ff24a403cdd05b138bd caused issue.",2025-03-20T17:57:36Z,type:build/install comp:lite subtype: raspberry pi TF 2.18,open,0,0,https://github.com/tensorflow/tensorflow/issues/89666
gemma,copybara-service[bot],PR #89210: Qualcomm AI Engine Direct - Provide op optimization,PR CC(Qualcomm AI Engine Direct  Provide op optimization): Qualcomm AI Engine Direct  Provide op optimization Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/89210 Summary:  Support FC>CONV2D optimization  Add CONV2D op builder with CPU transpose Test:  [x] a8w8 Gemma3 compile and execution successfully  [x] qnn_compiler_plugin_test all pass Copybara import of the project:  8ff43628b495ce8ae730a5ed42fa6bea1ef15844 by jiunkaiy : Qualcomm AI Engine Direct  Op optimization Summary:  Support FC>CONV2D optimization  Add CONV2D op builder with CPU transpose Merging this change closes CC(Qualcomm AI Engine Direct  Provide op optimization) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/89210 from jiunkaiy:dev/jiunkaiy/gemma2_fc 8ff43628b495ce8ae730a5ed42fa6bea1ef15844,2025-03-20T17:36:30Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89662
yi,copybara-service[bot],`ArrayImpl` is now a proper subclass of `jax.Array`,"`ArrayImpl` is now a proper subclass of `jax.Array` This allows to make `jax.Array` a ""strict"" ABC which doesn't support virtual subclasses and is thus can do faster isinstance/issubclass checks. Note that I had to move `StrictABC` from `util` into a separate submodule to avoid an import cycle with `basearray` and `xla_client`.",2025-03-20T14:16:14Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89651
yi,eewindfly,Add support for SeparableConv2DTranspose (Depthwise Conv2DTranspose)," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.16.1  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Feature Request TensorFlow currently lacks a SeparableConv2DTranspose operation, which is essential for efficient depthwise transposed convolutions. PyTorch already supports this easily via the groups parameter in ConvTranspose2d. However, TensorFlow’s Conv2DTranspose does not have a groups argument, making it impossible to achieve the same functionality. Workarounds Currently, the only way to approximate this functionality in TensorFlow is: 	•	Manually splitting input channels and applying Conv2DTranspose separately (inefficient and slow). Proposed Solution 	•	Either add a groups parameter to Conv2DTranspose, similar to PyTorch, 	•	Or implement a native SeparableConv2DTranspose API to complement SeparableConv2D. Use Case Separable transposed convolutions are useful for: 	•	Efficient upsampling in lightweight CNN architectures. 	•	Mobile and edge computing models requiring optimized computations. Would be great to have this officially supported in TensorFlow! Thanks. CC(Feature Request: Add separable_conv2d_transpose operation)  Previous discussion has been closed which is not able to reopen, so I create a new one for it.  Standalone code to reproduce the issue ```shell None ```  Relevant log output ```shell ```",2025-03-20T09:27:50Z,type:feature,open,0,0,https://github.com/tensorflow/tensorflow/issues/89628
yi,zhouxiaoyaozzz,NotImplementedError: StreamingModel.call() not implemented," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf2.18.0  Custom code Yes  OS platform and distribution windows 11  Mobile device _No response_  Python version 3.12.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When I try to compile and run my custom Keras model (StreamingModel), I encounter the following error: `NotImplementedError: Exception encountered when calling StreamingModel.call(). Could not automatically infer the output shape / dtype of 'streaming_model' (of type StreamingModel). Either the `StreamingModel.call()` method is incorrect, or you need to implement the `StreamingModel.compute_output_spec() / compute_output_shape()` method. Error encountered: Model StreamingModel does not have a `call()` method implemented.` Expected Behavior I expect the StreamingModel to correctly implement the call() method and infer the output shape/dtype automatically, or allow me to manually specify it using compute_output_spec() or compute_output_shape().  Standalone code to reproduce the issue ```shell import tensorflow as tf  Define CircularBufferLayer class CircularBufferLayer(tf.keras.layers.Layer):     def __init__(self, num_features, buffer_size, stride, **kwargs):         super().__init__(**kwargs)         self.num_features = num_features         self.buffer_size = buffer_size         self.stride = stride         self.gradient_scale = 0.1         self.buffer = self.add_weight(name='buffer', shape=(1, buffer_size, num_features),                                       initializer='zeros', trainable=False, dtype=tf.float32)         self.call_count = self.add_weight(name='call_count', shape=(), initializer='zeros',                                           dtype=tf.int32, trainable=False)         self.total_call_count = self.add_weight(name='total_call_count', shape=(), initializer='zeros',                                                 dtype=tf.int32, trainable=False)     def call(self, inputs):         scaled_input = tf.multiply(inputs, self.gradient_scale)         new_buffer = tf.concat([scaled_input, self.buffer[:, :1]], axis=1)         self.buffer.assign(new_buffer)         return self.buffer  Define StreamingModel class StreamingModel(tf.keras.Model):     def call(self, inputs):         x, _ = super().call(inputs)   Assume another branch is truncated         return x  Instantiate the model buffer_layer = CircularBufferLayer(num_features=64, buffer_size=10, stride=1) model = StreamingModel()  Define input shape input_shape = (None, 10, 64)   (batch_size, sequence_length, num_features) inputs = tf.keras.Input(shape=input_shape[1:])   Ignore batch_size outputs = model(inputs)  Build the model model = tf.keras.Model(inputs=inputs, outputs=outputs)  Compile the model model.compile(     optimizer='adam',   Use Adam optimizer     loss='mse',        Use mean squared error as the loss function     metrics=['mae']    Use mean absolute error as the evaluation metric ) ```  Relevant log output ```shell 20250319 16:09:45.545622: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250319 16:09:46.283611: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250319 16:09:48.149403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. WARNING:tensorflow:From D:\project\DLComplier\.venv\Lib\sitepackages\keras\src\backend\tensorflow\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead. Traceback (most recent call last):   File ""D:\project\DLComplier\.venv\statiblity.py"", line 37, in      outputs = model(inputs)               ^^^^^^^^^^^^^   File ""D:\project\DLComplier\.venv\Lib\sitepackages\keras\src\utils\traceback_utils.py"", line 122, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""D:\project\DLComplier\.venv\statiblity.py"", line 27, in call     x, _ = super().call(inputs)   Assume another branch is truncated            ^^^^^^^^^^^^^^^^^^^^ NotImplementedError: Exception encountered when calling StreamingModel.call(). Could not automatically infer the output shape / dtype of 'streaming_model' (of type StreamingModel). Either the `StreamingModel.call()` method is incorrect, or you need to implement the `StreamingModel.compute_output_spec() / compute_output_shape()` method. Error encountered: Model StreamingModel does not have a `call()` method implemented. Arguments received by StreamingModel.call():   • args=('',)   • kwargs= ```",2025-03-20T02:55:01Z,type:bug TF 2.18,open,0,0,https://github.com/tensorflow/tensorflow/issues/89600
rag,copybara-service[bot],Adjust sharding rules for ragged_dot operations.,Adjust sharding rules for ragged_dot operations.  Mode 3 (the ragged dimension is a batch dimension) Do not propagate shardings to/from the group_sizes (the 3rd operand) since it is redundant. We will discard this tensor and convert ragged_dot into a standard dot in the partitioner.  Mode 1 (the ragged dimension is a lhs noncontracting dimension) The ragged dimension and the group_size dimension needs full replication in the partitioner.  Mode 2 (the ragged dimension is a contracting dimension) The ragged dimension and the group_size dimension needs full replication in the partitioner. We do not mark the ragged dimension as replicated although it is a contracting dimension.,2025-03-20T00:11:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89592
yi,copybara-service[bot],IFRT: Introduce `LoadedExecutable::GetDonatableInputIndices()`.,"IFRT: Introduce `LoadedExecutable::GetDonatableInputIndices()`. The function returns indices of parameters that will be donated whenever `Execute` gets called, provided they are not present in `execute_options.non_donatable_input_indices`. This change will be used in an upcoming IFRTproxy commit that will allow make incurring RPC roundtrips for `Array::IsDeleted()` unnecessary.",2025-03-19T17:59:40Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89569
yi,copybara-service[bot],internal BUILD rule visibility,internal BUILD rule visibility,2025-03-19T17:52:26Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89568
yi,copybara-service[bot],[XLA:GPU] new fusion kind for nested dot fusions,[XLA:GPU] new fusion kind for nested dot fusions To prevent priority fusion from modifying the construct produced by nest_gemm_fusion pass.  For example priority fusion may insert back bitcasts that we have carefully extracted before.,2025-03-19T16:48:47Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89562
yi,zhouxiaoyaozzz,Compilation error（The call method of the StreamingModel class is not implemented correctly）," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf2.18.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Is this a new compilation error？The call method of the StreamingModel class is not implemented correctly, causing TensorFlow/Karas to be unable to infer the output shape and data type of the model.  Standalone code to reproduce the issue ```shell import tensorflow as tf  定义 CircularBufferLayer class CircularBufferLayer(tf.keras.layers.Layer):     def __init__(self, num_features, buffer_size, stride, **kwargs):         super().__init__(**kwargs)         self.num_features = num_features         self.buffer_size = buffer_size         self.stride = stride         self.gradient_scale = 0.1         self.buffer = self.add_weight(name='buffer', shape=(1, buffer_size, num_features),                                       initializer='zeros', trainable=False, dtype=tf.float32)         self.call_count = self.add_weight(name='call_count', shape=(), initializer='zeros',                                           dtype=tf.int32, trainable=False)         self.total_call_count = self.add_weight(name='total_call_count', shape=(), initializer='zeros',                                                 dtype=tf.int32, trainable=False)     def call(self, inputs):         scaled_input = tf.multiply(inputs, self.gradient_scale)         new_buffer = tf.concat([scaled_input, self.buffer[:, :1]], axis=1)         self.buffer.assign(new_buffer)         return self.buffer  定义 StreamingModel class StreamingModel(tf.keras.Model):     def call(self, inputs):         x, _ = super().call(inputs)   假设另一个分支被截断         return x  实例化模型 buffer_layer = CircularBufferLayer(num_features=64, buffer_size=10, stride=1) model = StreamingModel()  定义输入形状 input_shape = (None, 10, 64)   (batch_size, sequence_length, num_features) inputs = tf.keras.Input(shape=input_shape[1:])   忽略 batch_size outputs = model(inputs)  构建模型 model = tf.keras.Model(inputs=inputs, outputs=outputs)  编译模型 model.compile(     optimizer='adam',   使用 Adam 优化器     loss='mse',        使用均方误差作为损失函数     metrics=['mae']    使用平均绝对误差作为评估指标 )  准备训练数据 x_train = tf.random.normal((100, 10, 64))   100 个样本，每个样本的形状为 (10, 64) y_train = tf.random.normal((100, 10, 64))   100 个样本，每个样本的形状为 (10, 64)  训练模型 history = model.fit(     x_train, y_train,     batch_size=32,   批量大小     epochs=10,       训练轮数     validation_split=0.2   使用 20% 的数据作为验证集 )  保存模型 model.save('streaming_model.h5') ```  Relevant log output ```shell D:\project\DLComplier\.venv\Scripts\python.exe D:\project\DLComplier\.venv\statiblity.py  20250319 16:09:45.545622: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250319 16:09:46.283611: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250319 16:09:48.149403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. WARNING:tensorflow:From D:\project\DLComplier\.venv\Lib\sitepackages\keras\src\backend\tensorflow\core.py:216: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead. Traceback (most recent call last):   File ""D:\project\DLComplier\.venv\statiblity.py"", line 37, in      outputs = model(inputs)               ^^^^^^^^^^^^^   File ""D:\project\DLComplier\.venv\Lib\sitepackages\keras\src\utils\traceback_utils.py"", line 122, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""D:\project\DLComplier\.venv\statiblity.py"", line 27, in call     x, _ = super().call(inputs)   假设另一个分支被截断            ^^^^^^^^^^^^^^^^^^^^ NotImplementedError: Exception encountered when calling StreamingModel.call(). Could not automatically infer the output shape / dtype of 'streaming_model' (of type StreamingModel). Either the `StreamingModel.call()` method is incorrect, or you need to implement the `StreamingModel.compute_output_spec() / compute_output_shape()` method. Error encountered: Model StreamingModel does not have a `call()` method implemented. Arguments received by StreamingModel.call():   • args=('',)   • kwargs= ```",2025-03-19T08:11:56Z,type:bug TF 2.18,open,0,0,https://github.com/tensorflow/tensorflow/issues/89540
yi,copybara-service[bot],[XLA] Adds a helper function for copying original value,[XLA] Adds a helper function for copying original value,2025-03-18T21:01:59Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89489
rag,copybara-service[bot],PR #23320: [NVIDIA GPU] Add utility functions for multi-host fast-interconnect domain,"PR CC([Feature Request] Addition of new operation to Tensorflow Lite for ""ENet""): [NVIDIA GPU] Add utility functions for multihost fastinterconnect domain Imported from GitHub PR https://github.com/openxla/xla/pull/23320 On Blackwell and onwards, multiple hosts may be connected by NVLink thus creating a fastinterconnect domain beyond a single node. This PR leverages NVML APIs to detect the actual fastinterconnect domain. Followup PRs will update the logic in PjRt client on top of these utility functions. Copybara import of the project:  ee084714876336243fa3ba52a857d2d41124b730 by Terry Sun : pipe nvml to detect nvl  36e1f71dfabb75dbd0853355a7be8c0d6d103903 by Terry Sun : convert clusterUUID  917eb219a1bdebfc7a12f5849545615c83092c73 by Terry Sun : bake boot id into key  cbd909ab66ccf47f6e140632645fbb4d6c61c7c3 by Terry Sun : use global id and add getter  e487c4718eefe72e77708ffaf2c8cbbf6c979e8e by Terry Sun : use device ordinal and add doc string  2c761da2c04ea39d6cc79314f0dc14efef6d0380 by Terry Sun : merge fabric info into device proto  ed34dfbba07fbc5ffaaa914478381184a90f9cbb by Terry Sun : error handling and cleanup  c62f08691b7e3a59effc0f721948b30baea5b8a8 by Terry Sun : polish doc string  ab9d41e3142a0792859b9d37b99fe3ddfd9bbba8 by Terry Sun : conditional compile  29d857815a55d7df7911625cfeb35047bfbb07cb by Terry Sun : more conditional compile  524b569f1937db51babdaac04b50e9499da81a95 by Terry Sun : fix field designator order  7a0fb0f10be555c32403af4d226e687c650603d2 by Terry Sun : str buffer size  91e28b675b2f25e2b5d6c73732c8dae193b0dff3 by Terry Sun : compute capability condition  48fafb9dc4f44c451ca64bdb8ca15a1678cae398 by Terry Sun : protobuf backward compatibility  90f07569cf64d4d7d957cf4efe16fd2c9142eb4c by Terry Sun : guard cluster uuid size Merging this change closes CC([Feature Request] Addition of new operation to Tensorflow Lite for ""ENet"") FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23320 from terryysun:terryysun/detect_mnnvl 4820e4b53c9a72fe6ee8c08ab29ee640f1697c8d",2025-03-18T20:59:16Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89488
yi,AYUHSPATIL,Fix doc bug in tf.keras.losses.SparseCategoricalCrossentropy,"Fixes CC(tf.keras.losses.SparseCategoricalCrossentropy has logical/Doc bug) This PR enhances the error handling for invalid values of the reduction parameter. Previously, if reduction was None or an incorrect value (including variations like ""None"", ""Auto"", ""Sum"", etc.), the error message was not specific enough, making it difficult for users to understand what went wrong. If the value does not match exactly (casesensitive), a clear error message is raised, specifying the invalid value and listing the expected options. This improves usability by guiding the user toward the correct values. Impact: 1. Improves error clarity for developers using the reduction parameter. 2. Ensures better debugging by explicitly pointing out incorrect values. 3. Reduces confusion caused by incorrect casing or unexpected inputs.  For more details, open the Copilot Workspace session.",2025-03-18T18:47:30Z,size:XL invalid python,closed,0,3,https://github.com/tensorflow/tensorflow/issues/89480,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.","Hi , can you please sign the CLA? Many thanks!",This seems like AI generated content which goes against contributors guidelines and could be considered spam.
yi,copybara-service[bot],Unify implicit dependencies of OSS and internal xla_test macro,Unify implicit dependencies of OSS and internal xla_test macro Both macro implementations used to add different implicit runtime dependency targets. This change is unifying that.,2025-03-18T08:08:56Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89436
rag,copybara-service[bot],Move `value_inference_test.py` next to file to improve code coverage and remove unnecessary dependencies.,Move `value_inference_test.py` next to file to improve code coverage and remove unnecessary dependencies.,2025-03-17T22:29:18Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89403
rag,copybara-service[bot],Support ragged_dot in Shardy.,"Support ragged_dot in Shardy. 1. Allow_xla_features (mhlo.ragged_dot) in MhloToStablehlo translation. 2. Add mhlo_extensions for ShardyXLA, and define the sharding rule for ragged_dot operations.",2025-03-17T18:43:51Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89388
yi,copybara-service[bot],[XLA] Adjust the `CallInliner` pass to allow uniquifying channel ids after inlining.,"[XLA] Adjust the `CallInliner` pass to allow uniquifying channel ids after inlining. This is an option that can be enabled specifically on the pass, and will now enabled in the XLA:GPU compilation pipeline if `xla_ignore_channel_id` is `true`. This works around an issue whereby the `CallInliner` might inline several computations involving collectives with the same `channel_id` into the same computation. This is actually not wellbehaved and can result in the creation of cyclic HLO graphs. This change ensures that inlining does not create cyclic graphs. Note that the transformation is actually not semanticspreserving, in that a computation involving several `call` instructions wrapping collectives that use the same `channel_id` is already illformed. Nevertheless, `channel_id`s are only used as a ""hack"" for pipeline parallelism in XLA:GPU currently, and are mostly vestigial at this point. The flagdriven enablement can be deleted once this feature is deprecated (WIP). The proper solution would be to completely get rid of them, but they are currently enforced by the HLO verifier and removing them will take time.",2025-03-17T18:14:04Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89382
yi,copybara-service[bot],Align accelerator application during compiled model creation to the expected behaviour.,"Align accelerator application during compiled model creation to the expected behaviour. This adds a new function field in the accelerator implementation structure and associated functions to set/call that function. The function queries the accelerator to know if the underlying TFLite delegate does JIT compilation. When that's the case, even if the accelerator is registered, it won't be used to create and apply a delegate unless explicitly requested through the compilation options.",2025-03-17T12:31:20Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89364
yi,copybara-service[bot],Use `UniquifyName(HloModule*)` and `UniquifyId(HloModule*)` whenever possible.,Use `UniquifyName(HloModule*)` and `UniquifyId(HloModule*)` whenever possible.,2025-03-17T10:53:57Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89360
yi,woegerbauerJ,Conv1D Layer with kernel size 1 does not match with iteratively processing," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.1  Custom code Yes  OS platform and distribution Linux Ubuntu  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I was trying to set up a realtime/causal Conv2D layers, by multiple Conv1D layers. I noticed an error in the order of 1e7, so i started to narrow down the issue. This is why i ended up with the following code. I essentially create 2 identical conv1D layers where i then load the weights from one into the other. When iterating over the time dimension (axis 1; as one would to in an realtime/causal implementation) this error occurs. Note:  this issue only happens for ""large"" filters (> 10)  this issue only happens for ""large"" features (> 30)  when setting the weights to integer this issue is not reproducible  Standalone code to reproduce the issue ```shell import numpy as np import tensorflow as tf class Conv1D_wrapper(tf.keras.layers.Layer):     def __init__(self, filters):         super(Conv1D_wrapper, self).__init__()         self.conv1d = tf.keras.layers.Conv1D(             filters = filters,             kernel_size = 1,             padding='valid',             activation='relu',             strides = 1,             use_bias = False         )     def load(self, other_layer):         kernel = other_layer.get_weights()         self.conv1d.set_weights([kernel[0]])     def call(self, input):         x = self.conv1d(input)         return x if __name__ == ""__main__"":     dummy data     x1 = np.ones([1,3,1,10])      init the layers     conv1 = Conv1D_wrapper(30)     conv2 = Conv1D_wrapper(30)     conv1(x1.copy())     conv2(x1.copy())      load conv1 into conv2     conv2.load(conv1)      output1 (calculated over all time steps)     output1 = conv1(x1.copy())     output2 = np.zeros_like(output1)     for i in range(output1.shape[1]): calculated iteratively over time steps         output2[:,i,:] = conv2(x1[:,i,:][:,None,:])     print(""not iterated matching"", np.allclose(conv1(x1.copy()), conv2(x1.copy())))     print(""matching kernels?"",np.allclose(conv2.get_weights()[0],conv1.get_weights()[0]))     print(""bias?"",conv2.conv1d.use_bias, conv1.conv1d.use_bias)     print(""max error"", np.max(abs(output1output2))) ```  Relevant log output ```shell not iterated matching True matching kernels? True bias? False False max error 1.1920929e07 ```",2025-03-17T10:20:20Z,stat:awaiting response type:bug comp:ops TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/89353,"addon: this issue also happens for `    x1 = np.ones([1,11,10,10])      init the layers     conv1 = tf.keras.layers.Conv1D(filters = 30,kernel_size=1, use_bias =False)     output1 = conv1(x1.copy())     output2 = np.zeros_like(output1)     for i in range(output1.shape[1]): calculated iteratively over time steps         output2[:,i,:] = conv1(x1[:,i,:])     print(""max error"", np.max(abs(output1output2)))` and also leads to the same error!","Hi  , Apologies for the delay, and thanks for raising your concern here. I tried running your code on Colab using TensorFlow versions 2.18.0, 2.19.0, and the nightly build. However, I encountered a different issue. After making some modifications, the code worked for me. Additionally, I noticed that you are using an older version of TensorFlow. I recommend upgrading to the latest version for better results. I have attached a gist for your reference. Thank you!","Hi, thanks for your response! Due to our hardware we somewhat bounded to tf 2.14 (we are working with an NPU).  Thanks for finding out the issue with the dimension. I still assume this is somewhat of an issue, since mathematically it should be identical right? Even for 4 dimensions. However i am happy with the solution. Thank you very much!",Are you satisfied with the resolution of your issue? Yes No
yi,devnas-2004,Failed to load the native TensorFlow runtime.," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tensorflow2.19.0   Custom code Yes  OS platform and distribution windows  Mobile device _No response_  Python version 3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[2], line 5       3 stemmer = LancasterStemmer()       4 import numpy as np > 5 import tflearn       6 import tensorflow as tf       7 import random File ~\anaconda3\Lib\sitepackages\tflearn\__init__.py:4       1 from __future__ import absolute_import       3  Disable TF eager mode > 4 import tensorflow.compat.v1 as tf       5 tf.disable_v2_behavior()       7  Config File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\saxen\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime.  Standalone code to reproduce the issue ```shell import nltk from nltk.stem.lancaster import LancasterStemmer stemmer = LancasterStemmer() import numpy as np import tflearn import tensorflow as tf import random ```  Relevant log output ```shell ```",2025-03-15T10:58:30Z,stat:awaiting response type:build/install subtype:windows TF 2.18,closed,0,3,https://github.com/tensorflow/tensorflow/issues/89296,"Hi 2004 , Apologies for the delay, could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios:  You need to install the MSVC 2019 redistributable  Your CPU does not support AVX2 instructions  Your CPU/Python is on 32 bits  There is a library that is in a different location/not installed on your system that cannot be loaded. Also kindly provide the environment details and the steps followed to install the tensorflow. https://github.com/tensorflow/tensorflow/issues/61887 Also this is a duplicate of https://github.com/tensorflow/tensorflow/issues/19584 Thank you!",Please search for duplicates before opening a new issue.,Are you satisfied with the resolution of your issue? Yes No
yi,maludwig,TensorFlow on RTX 5090," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.20.0.dev20250314  Custom code No  OS platform and distribution Windows 11  WSL2  Ubuntu 22.04.5 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version 7.4.1  GCC/compiler version gcc (Ubuntu 11.4.01ubuntu1~22.04) 11.4.0  CUDA/cuDNN version CUDA Version: 12.8  GPU model and memory RTX 5090 32GB  Current behavior? I had hoped that tensorflow would work on the RTX 5090 at all. It does not, sadly. I tried building from source but that didn't work either. I tried running the environment script but that didn't work either. At least bash is my primary programming language, so I was able to tidy that one up here: https://github.com/tensorflow/tensorflow/pull/89271 But I wasn't able to get tensorflow running. I had a similar issue with PyTorch, which needed to use CUDA 12.8.* to work on the Blackwell cards, but no dice with the nightly build of tensorflow. Below is my test and the output, and under that is the `tf_env.txt` from my patched script. It may be helpful to know that nvidia themselves seem to have it running here: https://docs.nvidia.com/deeplearning/frameworks/tensorflowreleasenotes/rel2502.html But I get the same errors that this other guy does when I try it out: https://www.reddit.com/r/tensorflow/comments/1iutjoj/tensorflow_2501_cuda_128_rtx_5090_on_wsl2_cuda/ This conversation was another one I found that may be helpful, according to these guys, you need to support CUDA 12.8.1 to support Blackwell (aka the RTX 50 series cards): https://discuss.ai.google.dev/t/buildingtensorflowfromsourceforrtx5000gpuseries/65171/15 ``` (tfnightie) mitch:~/stable_diff $ cat tfnightie/test_2.py import tensorflow as tf import time  Check if TensorFlow sees the GPU print(""TensorFlow version:"", tf.__version__) print(""Available GPUs:"", tf.config.experimental.list_physical_devices('GPU'))  Matrix multiplication test shape = (5000, 5000) a = tf.random.normal(shape) b = tf.random.normal(shape)  Time execution on GPU with tf.device('/GPU:0'):     print(""Running on GPU..."")     start_time = time.time()     c = tf.matmul(a, b)     tf.print(""Matrix multiplication (GPU) done."")     print(""Execution time (GPU):"", time.time()  start_time, ""seconds"")  Time execution on CPU for comparison with tf.device('/CPU:0'):     print(""Running on CPU..."")     start_time = time.time()     c = tf.matmul(a, b)     tf.print(""Matrix multiplication (CPU) done."")     print(""Execution time (CPU):"", time.time()  start_time, ""seconds"") (tfnightie) mitch:~/stable_diff $ python tfnightie/test_2.py 20250314 21:35:33.400099: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. TensorFlow version: 2.20.0dev20250314 WARNING: All log messages before absl::InitializeLog() is called are written to STDERR W0000 00:00:1742009735.413544  326199 gpu_device.cc:2429] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jitcompiled from PTX, which could take 30 minutes or longer. Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] W0000 00:00:1742009735.417720  326199 gpu_device.cc:2429] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jitcompiled from PTX, which could take 30 minutes or longer. I0000 00:00:1742009735.572153  326199 gpu_device.cc:2018] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29043 MB memory:  > device: 0, name: NVIDIA GeForce RTX 5090, pci bus id: 0000:09:00.0, compute capability: 12.0 20250314 21:35:36.969440: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_INVALID_PTX' 20250314 21:35:36.969480: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE' 20250314 21:35:36.969505: W tensorflow/core/framework/op_kernel.cc:1843] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' 20250314 21:35:36.969533: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' Traceback (most recent call last):   File ""/home/mitch/stable_diff/tfnightie/test_2.py"", line 10, in      a = tf.random.normal(shape)   File ""/home/mitch/.virtualenvs/tfnightie/lib/python3.10/sitepackages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""/home/mitch/.virtualenvs/tfnightie/lib/python3.10/sitepackages/tensorflow/python/framework/ops.py"", line 6027, in raise_from_not_ok_status     raise core._status_to_exception(e) from None   pylint: disable=protectedaccess tensorflow.python.framework.errors_impl.InternalError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Mul] name: ``` Also, while nvidia's site says that the Compute Capability of the RTX5090 is ""10.0"", the card itself seems to report ""12.0"". I am not so sure that info will be helpful, but it spun me for a loop: ``` $ cat  card_details.cu > include  include  int main() {     cudaDeviceProp prop;     int device;     cudaGetDevice(&device); // Get the current device ID     cudaGetDeviceProperties(&prop, device); // Get device properties     size_t free_mem, total_mem;     cudaMemGetInfo(&free_mem, &total_mem); // Get VRAM usage     std::cout _75' will be removed in a future release (Use Wnodeprecatedgputargets to suppress warning). GPU Name: NVIDIA GeForce RTX 5090 Compute Capability: 12.0 VRAM Usage: 1763 MB / 32606 MB ```  tf_env.txt ``` == check python ==================================================== python version: 3.10.12 python branch: python build version: ('main', 'Feb  4 2025 14:57:36') python compiler version: GCC 11.4.0 python implementation: CPython == check os platform =============================================== os: Linux os kernel version: CC(Add support for Python 3.x) SMP Tue Nov 5 00:21:55 UTC 2024 os release version: 5.15.167.4microsoftstandardWSL2 os platform: Linux5.15.167.4microsoftstandardWSL2x86_64withglibc2.35 freedesktop os release: {'NAME': 'Ubuntu', 'ID': 'ubuntu', 'PRETTY_NAME': 'Ubuntu 22.04.5 LTS', 'VERSION_ID': '22.04', 'VERSION': '22.04.5 LTS (Jammy Jellyfish)', 'VERSION_CODENAME': 'jammy', 'ID_LIKE': 'debian', 'HOME_URL': 'https://www.ubuntu.com/', 'SUPPORT_URL': 'https://help.ubuntu.com/', 'BUG_REPORT_URL': 'https://bugs.launchpad.net/ubuntu/', 'PRIVACY_POLICY_URL': 'https://www.ubuntu.com/legal/termsandpolicies/privacypolicy', 'UBUNTU_CODENAME': 'jammy'} mac version: ('', ('', '', ''), '') uname: uname_result(system='Linux', node='win11ml', release='5.15.167.4microsoftstandardWSL2', version=' CC(Add support for Python 3.x) SMP Tue Nov 5 00:21:55 UTC 2024', machine='x86_64') architecture: ('64bit', 'ELF') machine: x86_64 == are we in docker ================================================ No == c++ compiler ==================================================== /usr/bin/c++ c++ (Ubuntu 11.4.01ubuntu1~22.04) 11.4.0 Copyright (C) 2021 Free Software Foundation, Inc. This is free software; see the source for copying conditions.  There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. == check pips ====================================================== numpy                   2.1.3 protobuf                5.29.3 tf_nightly              2.20.0.dev20250314 == check for virtualenv ============================================ Running inside a virtual environment. == tensorflow import =============================================== 20250314 21:02:48.002965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. WARNING: All log messages before absl::InitializeLog() is called are written to STDERR W0000 00:00:1742007769.198398  317963 gpu_device.cc:2429] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jitcompiled from PTX, which could take 30 minutes or longer. W0000 00:00:1742007769.202246  317963 gpu_device.cc:2429] TensorFlow was not built with CUDA kernel binaries compatible with compute capability 12.0. CUDA kernels will be jitcompiled from PTX, which could take 30 minutes or longer. I0000 00:00:1742007769.355021  317963 gpu_device.cc:2018] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29043 MB memory:  > device: 0, name: NVIDIA GeForce RTX 5090, pci bus id: 0000:09:00.0, compute capability: 12.0 tf.version.VERSION = 2.20.0dev20250314 tf.version.GIT_VERSION = v1.12.1123444g07ff428d432 tf.version.COMPILER_VERSION = Ubuntu Clang 18.1.8 (++20240731024944+3b5b5c1ec4a31~exp1~20240731145000.144) Sanity check:  libcudnn not found == env ============================================================= LD_LIBRARY_PATH /usr/local/cuda12.8/lib64: DYLD_LIBRARY_PATH is unset == nvidiasmi ====================================================== Fri Mar 14 21:02:52 2025 ++  ++ == cuda libs ======================================================= /usr/local/cuda11.8/targets/x86_64linux/lib/libcudart_static.a /usr/local/cuda11.8/targets/x86_64linux/lib/libcudart.so.11.8.89 /usr/local/cuda12.8/targets/x86_64linux/lib/libcudart_static.a /usr/local/cuda12.8/targets/x86_64linux/lib/libcudart.so.12.8.90 == tensorflow installation ========================================= tensorflow not found == tf_nightly installation ========================================= Name: tf_nightly Version: 2.20.0.dev20250314 Summary: TensorFlow is an open source machine learning framework for everyone. Homepage: https://www.tensorflow.org/ Authoremail: packages.org License: Apache 2.0 Location: /home/mitch/.virtualenvs/tfnightie/lib/python3.10/sitepackages Requiredby: == python version ================================================== (major, minor, micro, releaselevel, serial) (3, 10, 12, 'final', 0) == bazel version =================================================== Bazelisk version: v1.25.0 Build label: 7.4.1 Build time: Mon Nov 11 21:24:53 2024 (1731360293) Build timestamp: 1731360293 Build timestamp as int: 1731360293 ```  Standalone code to reproduce the issue ```shell Try running anything with an RTX 5090. My test script is above. ```  Relevant log output ```shell ```",2025-03-15T03:40:16Z,stat:awaiting tensorflower type:bug wsl2 TF 2.18,open,0,29,https://github.com/tensorflow/tensorflow/issues/89272,same problem,"I should mention that I'm a Senior AI Developer by trade and I'm more than happy to invest my personal time in helping to fix this, I'm just not sure where to start.","I should also mention that the latest clang release here supports building for compute_100/sm_100+ https://github.com/llvm/llvmproject/releases/tag/llvmorg20.1.0 It's not supported in LLVM 18. But it compiles this on my GPU just fine (extra logs attached just in case they help someone else). ``` mitch:~/stable_diff/build_tf/hello/hello_nvcc $ clang++ version clang version 20.1.0 (https://github.com/llvm/llvmproject 24a30daaa559829ad079f2ff7f73eb4e18095f88) Target: x86_64unknownlinuxgnu Thread model: posix InstalledDir: /home/mitch/stable_diff/fix_tf/llvm/LLVM20.1.0LinuxX64/bin mitch:~/stable_diff/build_tf/hello/hello_nvcc $ cat card_details.cu include  include  int main() {     cudaDeviceProp prop;     int device;     cudaGetDevice(&device); // Get the current device ID     cudaGetDeviceProperties(&prop, device); // Get device properties     size_t free_mem, total_mem;     cudaMemGetInfo(&free_mem, &total_mem); // Get VRAM usage     std::cout << ""GPU Name: "" << prop.name << std::endl;     std::cout << ""Compute Capability: "" << prop.major << ""."" << prop.minor << std::endl;     std::cout << ""VRAM Usage: "" << (total_mem  free_mem) / (1024 * 1024) << "" MB / "" << total_mem / (1024 * 1024) << "" MB"" << std::endl;     return 0; } mitch:~/stable_diff/build_tf/hello/hello_nvcc $ clang++ std=c++17 cudagpuarch=sm_120 x cuda cudapath=""$CUDA_HOME"" I""$CUDA_HOME/include"" L""$CUDA_HOME/lib64""  lcudart card_details.cu o card_details clang++: warning: CUDA version 12.8 is only partially supported [Wunknowncudaversion] mitch:~/stable_diff/build_tf/hello/hello_nvcc $ ./card_details GPU Name: NVIDIA GeForce RTX 5090 Compute Capability: 12.0 VRAM Usage: 1763 MB / 32606 MB mitch:~/stable_diff/build_tf/hello/hello_nvcc $ echo ""$CUDA_HOME"" /usr/local/cuda12.8 mitch:~/stable_diff/build_tf/hello/hello_nvcc $ ls ""$CUDA_HOME"" DOCS  EULA.txt  README  bin  computesanitizer  doc  extras  gds  include  lib64  libnvvp  nsightee_plugins  nvml  nvvm  share  src  targets  tools  version.json mitch:~/stable_diff/build_tf/hello/hello_nvcc $ cat /usr/local/cuda12.8/version.json | head n5 {    ""cuda"" : {       ""name"" : ""CUDA SDK"",       ""version"" : ""12.8.1""    }, ```","I'm going to keep writing my attempts to get things working here. I've cut a branch on my fork, still no luck, but here's some halfdiscoveries. More and more of the project is building as I continue, zero idea how far away I am from victory. He's the branch I'm on, compared with the base: https://github.com/maludwig/tensorflow/compare/ml/fixing_tf_env...maludwig:tensorflow:ml/attempting_build_rtx5090?expand=1 A few findings:  CUDA 12.8.1 adds support for the RTX 5090 (and other Blackwells), so we need that  There's a bug in cutlass, which was forked for tensorflow for a reason I don't know, the bug was fixed here: https://github.com/NVIDIA/cutlass/pull/1784/files  The old fork, done by  was certainly done for a reason, no idea what I'm breaking by going back to the NVIDIA main branch here. Not sure how to message people on GitHub, but maybe they'll get notified on this?  I updated NCCL to the latest 2.26.2 wheel  Build is still failing, but it's taking WAY longer to fail now. This is possibly a good sign.","Yep, I'm stopping for the night, it's currently stuck on what seems to be duplicate logging macros, looks like maybe two different logging libraries are somehow being included at the same time. Two very very similar logging libraries. But instead of taking 30 seconds before it fails, now it takes 17 minutes to fail, which I define as progress! ``` external/com_google_absl/absl/log/check.h:122:9: warning: 'CHECK_LT' macro redefined [Wmacroredefined]   122          ^ In file included from tensorflow/core/kernels/fill_empty_rows_functor_gpu.cu.cc:21: In file included from ./tensorflow/core/common_runtime/gpu/gpu_event_mgr.h:21: In file included from ./tensorflow/core/common_runtime/device/device_event_mgr.h:30: In file included from ./tensorflow/core/platform/stream_executor.h:21: In file included from external/local_xla/xla/stream_executor/dnn.h:47: In file included from external/local_xla/xla/stream_executor/scratch_allocator.h:26: In file included from external/local_xla/xla/stream_executor/device_memory_allocator.h:22: ```"," VICTORY Ok I didn't stop for the night. Instead, I just ignored all manner of warnings that shouldn't be ignored: ``` bazel build //tensorflow/tools/pip_package:wheel repo_env=WHEEL_NAME=tensorflow config=cuda config=cuda_wheel  copt=Wnognuoffsetofextensions copt=Wnoerror copt=Wnoc23extensions verbose_failures copt=Wnomacroredefined ``` And bam! ``` INFO: Found 1 target... Target //tensorflow/tools/pip_package:wheel uptodate:   bazelbin/tensorflow/tools/pip_package/wheel_house/tensorflow2.20.0.dev0+selfbuiltcp310cp310linux_x86_64.whl INFO: Elapsed time: 87.690s, Critical Path: 86.67s INFO: 2 processes: 1 internal, 1 local. INFO: Build completed successfully, 2 total actions ``` No idea if it'll work, but it **did build**! I've pushed the latest code changes to my branch. https://github.com/maludwig/tensorflow/compare/ml/fixing_tf_env...maludwig:tensorflow:ml/attempting_build_rtx5090?expand=1","It passed one test! ``` (tfnightie) mitch:~/stable_diff/fix_tf/tensorflow $ bazel test repo_env=WHEEL_NAME=tensorflow config=cuda config=cuda_wheel  copt=Wnognuoffsetofextensions copt=Wnoerror copt=Wnoc23extensions verbose_failures copt=Wnomacroredefined tensorflow/python/kernel_tests/nn_ops:softmax_op_test WARNING: The following configs were expanded more than once: [cuda_clang, cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior. INFO: Reading 'startup' options from /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: windows_enable_symlinks INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=243 INFO: Reading rc options for 'test' from /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc:   Inherited 'common' options: announce_rc experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility noenable_bzlmod noincompatible_enable_cc_toolchain_resolution noincompatible_enable_android_toolchain_resolution experimental_repo_remote_exec java_runtime_version=remotejdk_21 INFO: Reading rc options for 'test' from /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc:   Inherited 'build' options: repo_env=ML_WHEEL_TYPE=snapshot repo_env=ML_WHEEL_BUILD_DATE= repo_env=ML_WHEEL_VERSION_SUFFIX= define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive features=force_no_whole_archive host_features=force_no_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 INFO: Reading rc options for 'test' from /home/mitch/stable_diff/fix_tf/tensorflow/.tf_configure.bazelrc:   Inherited 'build' options: action_env PYTHON_BIN_PATH=/home/mitch/.virtualenvs/tfnightie/bin/python action_env PYTHON_LIB_PATH=/home/mitch/.virtualenvs/tfnightie/lib/python3.10/sitepackages python_path=/home/mitch/.virtualenvs/tfnightie/bin/python action_env LD_LIBRARY_PATH=/usr/local/cuda12.8/lib64:/home/mitch/stable_diff/fix_tf/libs/cudnnlinuxx86_649.8.0.87_cuda12archive/lib: config=cuda_clang action_env CLANG_CUDA_COMPILER_PATH=/home/mitch/stable_diff/fix_tf/llvm/LLVM20.1.0LinuxX64/bin/clang20 config=cuda_clang INFO: Reading rc options for 'test' from /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc:   'test' options: test_env=GTEST_INSTALL_FAILURE_SIGNAL_HANDLER=1 INFO: Reading rc options for 'test' from /home/mitch/stable_diff/fix_tf/tensorflow/.tf_configure.bazelrc:   'test' options: test_size_filters=small,medium test_env=LD_LIBRARY_PATH INFO: Found applicable config definition build:short_logs in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition test:v2 in file /home/mitch/stable_diff/fix_tf/tensorflow/.tf_configure.bazelrc: test_tag_filters=benchmarktest,no_oss,oss_excluded,no_gpu,oss_serial,v1only build_tag_filters=benchmarktest,no_oss,oss_excluded,no_gpu,v1only INFO: Found applicable config definition build:cuda_clang in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: config=cuda //:cuda_compiler=clang copt=Qunusedarguments repo_env=HERMETIC_CUDA_COMPUTE_CAPABILITIES=sm_60,sm_70,sm_80,sm_89,compute_90 copt=Wnounknowncudaversion host_linkopt=fuseld=lld host_linkopt=lm linkopt=fuseld=lld linkopt=lm INFO: Found applicable config definition build:cuda in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true INFO: Found applicable config definition build:cuda in file /home/mitch/stable_diff/fix_tf/tensorflow/.tf_configure.bazelrc: repo_env HERMETIC_CUDA_VERSION=12.8.1 repo_env HERMETIC_CUDNN_VERSION=9.8.0 repo_env HERMETIC_CUDA_COMPUTE_CAPABILITIES=compute_120 INFO: Found applicable config definition build:cuda_clang in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: config=cuda //:cuda_compiler=clang copt=Qunusedarguments repo_env=HERMETIC_CUDA_COMPUTE_CAPABILITIES=sm_60,sm_70,sm_80,sm_89,compute_90 copt=Wnounknowncudaversion host_linkopt=fuseld=lld host_linkopt=lm linkopt=fuseld=lld linkopt=lm INFO: Found applicable config definition build:cuda in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true INFO: Found applicable config definition build:cuda in file /home/mitch/stable_diff/fix_tf/tensorflow/.tf_configure.bazelrc: repo_env HERMETIC_CUDA_VERSION=12.8.1 repo_env HERMETIC_CUDNN_VERSION=9.8.0 repo_env HERMETIC_CUDA_COMPUTE_CAPABILITIES=compute_120 INFO: Found applicable config definition build:cuda in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true INFO: Found applicable config definition build:cuda in file /home/mitch/stable_diff/fix_tf/tensorflow/.tf_configure.bazelrc: repo_env HERMETIC_CUDA_VERSION=12.8.1 repo_env HERMETIC_CUDNN_VERSION=9.8.0 repo_env HERMETIC_CUDA_COMPUTE_CAPABILITIES=compute_120 INFO: Found applicable config definition build:cuda_wheel in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: //cuda:include_cuda_libs=false INFO: Found applicable config definition build:linux in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels experimental_guard_against_concurrent_changes INFO: Found applicable config definition build:dynamic_kernels in file /home/mitch/stable_diff/fix_tf/tensorflow/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS DEBUG: /home/mitch/.cache/bazel/_bazel_mitch/98f54844abcf3e1cdc99e9d96b271d9e/external/local_xla/third_party/py/python_repo.bzl:154:14: HERMETIC_PYTHON_VERSION variable was not set correctly, using default version. Python 3.10 will be used. To select Python version, either set HERMETIC_PYTHON_VERSION env variable in your shell:   export HERMETIC_PYTHON_VERSION=3.12 OR pass it as an argument to bazel command directly or inside your .bazelrc file:   repo_env=HERMETIC_PYTHON_VERSION=3.12 DEBUG: /home/mitch/.cache/bazel/_bazel_mitch/98f54844abcf3e1cdc99e9d96b271d9e/external/local_xla/third_party/py/python_repo.bzl:87:10: ============================= Hermetic Python configuration: Version: ""3.10"" Kind: """" Interpreter: ""default"" (provided by rules_python) Requirements_lock label: ""//:requirements_lock_3_10.txt"" ===================================== WARNING: The following configs were expanded more than once: [cuda_clang, cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior. WARNING: Build options @//cuda:include_cuda_libs, copt, cxxopt, and 2 more have changed, discarding analysis cache (this can be expensive, see https://bazel.build/advanced/performance/iterationspeed). INFO: Analyzed 2 targets (749 packages loaded, 56015 targets configured). INFO: Found 2 test targets... INFO: Elapsed time: 270.116s, Critical Path: 245.71s INFO: 2560 processes: 378 internal, 2182 local. INFO: Build completed successfully, 2560 total actions //tensorflow/python/kernel_tests/nn_ops:softmax_op_test_cpu              PASSED in 217.4s //tensorflow/python/kernel_tests/nn_ops:softmax_op_test_gpu              PASSED in 218.4s Executed 2 out of 2 tests: 2 tests pass. ``` I also installed the wheel generated in the last step to a new python venv, and it worked! ``` (test5090build) mitch:~/stable_diff/fix_tf/test5090build $ python c ""import tensorflow as tf; print(tf.__version__)"" 20250317 04:37:51.455319: I external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1742207871.466384  646442 cuda_dnn.cc:8670] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered I0000 00:00:1742207871.469996  646442 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered W0000 00:00:1742207871.479137  646442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207871.479166  646442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207871.479169  646442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207871.479172  646442 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. 20250317 04:37:51.481701: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 2.20.0dev0+selfbuilt (test5090build) mitch:~/stable_diff/fix_tf/test5090build $ python c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"" 20250317 04:38:02.348770: I external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1742207882.360431  646471 cuda_dnn.cc:8670] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered I0000 00:00:1742207882.364089  646471 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered W0000 00:00:1742207882.373383  646471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207882.373422  646471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207882.373426  646471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207882.373437  646471 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. 20250317 04:38:02.376028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] (test5090build) mitch:~/stable_diff/fix_tf/test5090build $ cat test_gpu.py import tensorflow as tf  Check if GPU is available gpus = tf.config.list_physical_devices('GPU') if not gpus:     print(""🚫 No GPU found!"") else:     print(f""✅ Found GPU(s): {[gpu.name for gpu in gpus]}"")  Place operations on GPU with tf.device('/GPU:0'):      Create two tensors     a = tf.constant([[1.0, 2.0], [3.0, 4.0]])     b = tf.constant([[5.0, 6.0], [7.0, 8.0]])      Add tensors     add_result = tf.add(a, b)     print(""\nAddition result:"")     print(add_result)      Matrix multiplication     matmul_result = tf.matmul(a, b)     print(""\nMatrix multiplication result:"")     print(matmul_result)  Print device placement info (optional, debug) print(""\nDevice placement log:"") tf.debugging.set_log_device_placement(True) (test5090build) mitch:~/stable_diff/fix_tf/test5090build $ python test_gpu.py 20250317 04:38:25.409242: I external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1742207905.420314  646517 cuda_dnn.cc:8670] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered I0000 00:00:1742207905.423851  646517 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered W0000 00:00:1742207905.432651  646517 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207905.432680  646517 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207905.432684  646517 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742207905.432686  646517 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. 20250317 04:38:25.435305: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. ✅ Found GPU(s): ['/physical_device:GPU:0'] I0000 00:00:1742207906.790435  646517 gpu_device.cc:2018] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29043 MB memory:  > device: 0, name: NVIDIA GeForce RTX 5090, pci bus id: 0000:09:00.0, compute capability: 12.0 Addition result: tf.Tensor( [[ 6.  8.]  [10. 12.]], shape=(2, 2), dtype=float32) Matrix multiplication result: tf.Tensor( [[19. 22.]  [43. 50.]], shape=(2, 2), dtype=float32) Device placement log: ``` I...am...going...to...run all the tests overnight? My build process is complete trash and I have no idea what I'm doing, but I COULD also PR this code, but like, that's slightly terrifying. I've ignoring probably thousands of warnings that a competent C++ developer could probably actually solve, rather than just ignore...","Tests didn't pass, but it did build! And it could do basic matrix addition and multiplication in Python! NOW I'm definitely going to bed though.","It also is able to do the classic ""hello world"" ML task of learning digits on MNIST, but the warnings are PLENTIFUL and cryptic. I don't know what they mean, but the final model happens to work great! ``` (test5090build) mitch:~/stable_diff/fix_tf/test5090build $ cat mnist_test.py !/usr/bin/env python import tensorflow as tf from tensorflow.keras import layers, models import numpy as np  Load MNIST dataset (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()  Normalize pixel values to [0,1] x_train = x_train / 255.0 x_test = x_test / 255.0  Build the model model = models.Sequential([     layers.Flatten(input_shape=(28, 28)),       Flatten 28x28 to 784     layers.Dense(128, activation='relu'),       Hidden layer     layers.Dense(10, activation='softmax')      Output layer ])  Compile the model model.compile(optimizer='adam',               loss='sparse_categorical_crossentropy',               metrics=['accuracy'])  Train the model model.fit(x_train, y_train, epochs=5, validation_split=0.1)  Evaluate the model test_loss, test_acc = model.evaluate(x_test, y_test) print(f""Test accuracy: {test_acc:.4f}"")  Make predictions predictions = model.predict(x_test)  Example: Print prediction for the first image print(f""First test sample  Predicted: {np.argmax(predictions[0])}, Actual: {y_test[0]}"") (test5090build) mitch:~/stable_diff/fix_tf/test5090build $ ./mnist_test.py 20250317 11:23:11.786039: I external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1742232191.796888  662647 cuda_dnn.cc:8670] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered I0000 00:00:1742232191.800405  662647 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered W0000 00:00:1742232191.809207  662647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742232191.809234  662647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742232191.809238  662647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. W0000 00:00:1742232191.809259  662647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once. 20250317 11:23:11.811904: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. /home/mitch/.virtualenvs/test5090build/lib/python3.10/sitepackages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.   super().__init__(**kwargs) I0000 00:00:1742232193.910442  662647 gpu_device.cc:2018] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 29043 MB memory:  > device: 0, name: NVIDIA GeForce RTX 5090, pci bus id: 0000:09:00.0, compute capability: 12.0 Epoch 1/5 20250317 11:23:15.366974: I external/local_xla/xla/service/service.cc:152] XLA service 0x7f5928008d30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: 20250317 11:23:15.367006: I external/local_xla/xla/service/service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 5090, Compute Capability 12.0 20250317 11:23:15.376904: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable. I0000 00:00:1742232195.434380  662725 cuda_dnn.cc:529] Loaded cuDNN version 90800 20250317 11:23:16.211437: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 80 bytes spill stores, 80 bytes spill loads 20250317 11:23:16.220559: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95_0', 164 bytes spill stores, 164 bytes spill loads 20250317 11:23:16.340804: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 392 bytes spill stores, 392 bytes spill loads 20250317 11:23:16.364181: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 76 bytes spill stores, 76 bytes spill loads 20250317 11:23:16.374280: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_232', 176 bytes spill stores, 176 bytes spill loads 20250317 11:23:16.385374: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 76 bytes spill stores, 76 bytes spill loads 20250317 11:23:16.393417: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 292 bytes spill stores, 292 bytes spill loads 20250317 11:23:16.451825: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 532 bytes spill stores, 532 bytes spill loads 20250317 11:23:16.522600: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_232', 168 bytes spill stores, 168 bytes spill loads 20250317 11:23:16.556430: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 1040 bytes spill stores, 1040 bytes spill loads 20250317 11:23:16.607519: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_232', 112 bytes spill stores, 112 bytes spill loads 20250317 11:23:16.806055: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 4920 bytes spill stores, 4992 bytes spill loads 20250317 11:23:16.867917: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 5084 bytes spill stores, 5028 bytes spill loads WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1742232197.511568  662725 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process. 1684/1688 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step  accuracy: 0.8767  loss: 0.446420250317 11:23:20.774706: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_232', 32 bytes spill stores, 32 bytes spill loads 20250317 11:23:20.804309: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 288 bytes spill stores, 288 bytes spill loads 20250317 11:23:20.807183: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 76 bytes spill stores, 76 bytes spill loads 20250317 11:23:20.828074: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 76 bytes spill stores, 76 bytes spill loads 20250317 11:23:20.895561: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 752 bytes spill stores, 752 bytes spill loads 20250317 11:23:21.076717: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_232', 80 bytes spill stores, 80 bytes spill loads 20250317 11:23:21.096547: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_232', 72 bytes spill stores, 72 bytes spill loads 20250317 11:23:21.177785: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 4920 bytes spill stores, 4992 bytes spill loads 20250317 11:23:21.227351: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_95', 5084 bytes spill stores, 5028 bytes spill loads 1688/1688 ━━━━━━━━━━━━━━━━━━━━ 8s 3ms/step  accuracy: 0.8768  loss: 0.4459  val_accuracy: 0.9668  val_loss: 0.1275 Epoch 2/5 1688/1688 ━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step  accuracy: 0.9598  loss: 0.1359  val_accuracy: 0.9710  val_loss: 0.0985 Epoch 3/5 1688/1688 ━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step  accuracy: 0.9748  loss: 0.0853  val_accuracy: 0.9728  val_loss: 0.0920 Epoch 4/5 1688/1688 ━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step  accuracy: 0.9810  loss: 0.0640  val_accuracy: 0.9775  val_loss: 0.0809 Epoch 5/5 1688/1688 ━━━━━━━━━━━━━━━━━━━━ 3s 2ms/step  accuracy: 0.9855  loss: 0.0473  val_accuracy: 0.9782  val_loss: 0.0797 313/313 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step  accuracy: 0.9720  loss: 0.0911 Test accuracy: 0.9753 313/313 ━━━━━━━━━━━━━━━━━━━━ 1s 2ms/step First test sample  Predicted: 7, Actual: 7 ```", you should upgrade commit hash256 XLA on bazel file and it should work,"Sorry that's a bit cryptic for me. I'm normally a Python dev, apologies. Did you mean in my commits on my branch above? https://github.com/maludwig/tensorflow/compare/ml/fixing_tf_env...maludwig:tensorflow:ml/attempting_build_rtx5090?expand=1",+1," Steps to get it running on your RTX 5000 series card  Guide for all platforms  Install llvm 20.1.0 LLVM 20.1.0 is required to compile code for compute capability 10.0 and 12.0 (RTX 5000 series). All platforms here: https://github.com/llvm/llvmproject/releases/tag/llvmorg20.1.0  Install CUDA 12.8.1 CUDA 12.8.1 is required to compile code for compute capability 10.0 and 12.0 (RTX 5000 series). Also install cuDNN 9.8.0 and NCCL 2, for CUDA 12.  Install Python 3.10.12 This just happens to be the version I'm using and may be completely unnecessary. I personally love pyenv because it installs it to your local user, so you don't need to fret about admin/root permissions.  Make a Python venv for tensorflow This will prevent your system from being polluted by tensorflow dependencies, and will make it much much much easier to clean up if you want to start over.  Install Bazelisk Bazelisk is a wrapper for Bazel that downloads the correct version of Bazel for the project.  Clone tensorflow ```bash echo ""Clone tensorflow"" git clone git.com:tensorflow/tensorflow.git cd tensorflow echo ""Add my remote to the repo"" git remote add maludwig 'git.com:maludwig/tensorflow.git' echo ""Fetch my remote"" git fetch all echo ""Checkout my branch"" git checkout ml/attempting_build_rtx5090 echo ""Pull my branch"" git pull maludwig ml/attempting_build_rtx5090 ```  Configure bazel ```bash echo ""Configure bazel, these are the settings I used, but I'm not sure if they're correct, or if they just happened to work for me."" export HERMETIC_CUDA_VERSION=12.8.1 export HERMETIC_CUDNN_VERSION=9.8.0 export HERMETIC_CUDA_COMPUTE_CAPABILITIES=compute_120 export LOCAL_CUDA_PATH=/usr/local/cuda12.8 export LOCAL_NCCL_PATH=/usr/lib/x86_64linuxgnu/libnccl.so.2.26.2 export TF_NEED_CUDA=1 export CLANG_CUDA_COMPILER_PATH=""$(which clang)"" python configure.py ```  Build tensorflow ```bash echo ""Good luck building!"" echo ""Note, I have trust issues with bazel now, so I always run 'bazel clean expunge' before building. This may be a personal psychological issue rather than a requirement."" bazel build //tensorflow/tools/pip_package:wheel repo_env=WHEEL_NAME=tensorflow config=cuda config=cuda_wheel copt=Wnognuoffsetofextensions copt=Wnoerror copt=Wnoc23extensions verbose_failures copt=Wnomacroredefined ```  Script for WSL Ubuntu 22.04 This script should let you compile for RTX 5000 series on WSL Ubuntu 22.04. Before running this script, be sure to install the latest drivers for your RTX 5000 series card on the Windows side, install WSL2, and use Ubuntu 22.04. Then reboot your PC, that way, WSL2 will be able to see your GPU. It probably also works on nonWSL Ubuntu 22.04. It might maybe work on other Ubuntu versions. It's not going to work for Windows except in WSL. It may not work at all. Consider copying it line by line and handle errors manually. ```bash mkdir p ""$HOME/rtx5000"" cd ""$HOME/rtx5000"" echo ""Installing essential dev tools"" sudo aptget update sudo aptget install y buildessential wget patchelf echo ""Installing Python 3.10"" sudo apt install y make buildessential libssldev zlib1gdev libbz2dev libreadlinedev libsqlite3dev wget curl llvm libncurses5dev libncursesw5dev xzutils tkdev libffidev liblzmadev curl https://pyenv.run | bash pyenv install 3.10.12 pyenv global 3.10.12 echo ""Restart your shell to use Python 3.10"" echo ""After restarting, confirm this says python 3.10.12"" python version echo ""Make a virtualenv for tensorflow"" python3.10 m venv ~/rtx5000/venv echo ""Activate the python virtualenv"" source ~/rtx5000/venv/bin/activate echo ""Installing LLVM 20.1.0"" wget https://github.com/llvm/llvmproject/releases/download/llvmorg20.1.0/LLVM20.1.0LinuxX64.tar.xz tar xvf LLVM20.1.0LinuxX64.tar.xz echo ""Installing NVIDIA packages"" wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cudakeyring_1.11_all.deb sudo dpkg i cudakeyring_1.11_all.deb sudo aptget update echo ""Installing NVIDIA CUDA 12.8"" sudo aptget y install cudatoolkit128 echo ""Installing NVIDIA cuDNN 9, for CUDA 12"" sudo aptget y install cudnn9cuda12 echo ""Installing NVIDIA NCCL 2"" sudo apt install libnccl2=2.26.21+cuda12.8 libnccldev=2.26.21+cuda12.8 echo ""Installing Bazelisk for Bazel"" mkdir p ~/rtx5000/bin cd ~/rtx5000/bin wget 'https://github.com/bazelbuild/bazelisk/releases/download/v1.25.0/bazelisklinuxamd64' chmod +x bazelisklinuxamd64 mv bazelisklinuxamd64 bazel ``` Add these lines to your `~/.bashrc` or `~/.zshrc` file: ``` export LLVM_HOME=""$HOME/rtx5000/LLVM20.1.0LinuxX64"" export CUDA_HOME=""/usr/local/cuda12.8"" export PATH=""${LLVM_HOME}/bin:${CUDA_HOME}/bin:${HOME}/rtx5000/bin:$PATH"" export LD_LIBRARY_PATH=""$CUDA_HOME/lib64:$LD_LIBRARY_PATH"" export CPATH=""$CUDA_HOME/include:$CPATH"" ``` Restart your terminal. Test that the LLVM installation worked: Make this file in `~/rtx5000/card_details.cu`: ```cpp include  include   // Add cuDNN header include  int main() {     cudaDeviceProp prop;     int device;     cudaGetDevice(&device); // Get the current device ID     cudaGetDeviceProperties(&prop, device); // Get device properties     size_t free_mem, total_mem;     cudaMemGetInfo(&free_mem, &total_mem); // Get VRAM usage     std::cout  GPU Name: ""  Compute Capability: ""  VRAM Usage: ""  cuDNN Version: ""                GPU Name: NVIDIA GeForce RTX 5090 > Compute Capability: 12.0 > VRAM Usage: 1763 MB / 32606 MB > cuDNN Version: 9.8.0 echo ""This should compile the code with clang++"" clang++ std=c++17 cudagpuarch=sm_120 x cuda cudapath=""$CUDA_HOME"" I""$CUDA_HOME/include"" L""$CUDA_HOME/lib64""  lcudart card_details.cu o card_details_clang echo ""This should print your card details again, just the same as before"" ./card_details_clang > GPU Name: NVIDIA GeForce RTX 5090 > Compute Capability: 12.0 > VRAM Usage: 1763 MB / 32606 MB > cuDNN Version: 9.8.0 echo ""This should be Bazel v8.8.1"" bazel version echo ""Activate the python virtualenv"" source ~/rtx5000/venv/bin/activate echo ""This should be Python 3.10.12"" python version echo ""Clone tensorflow"" cd ~/rtx5000 git clone git.com:tensorflow/tensorflow.git cd tensorflow echo ""Add my remote to the repo"" git remote add maludwig 'git.com:maludwig/tensorflow.git' echo ""Fetch my remote"" git fetch all echo ""Checkout my branch"" git checkout ml/attempting_build_rtx5090 echo ""Pull my branch"" git pull maludwig ml/attempting_build_rtx5090 echo ""Configure bazel, these are the settings I used, but I'm not sure if they're correct, or if they just happened to work for me."" export HERMETIC_CUDA_VERSION=12.8.1 export HERMETIC_CUDNN_VERSION=9.8.0 export HERMETIC_CUDA_COMPUTE_CAPABILITIES=compute_120 export LOCAL_CUDA_PATH=/usr/local/cuda12.8 export LOCAL_NCCL_PATH=/usr/lib/x86_64linuxgnu/libnccl.so.2.26.2 export TF_NEED_CUDA=1 export CLANG_CUDA_COMPILER_PATH=""$(which clang)"" python configure.py echo ""Good luck building!"" echo ""Note, I have trust issues with bazel now, so I always run 'bazel clean expunge' before building. This may be a personal psychological issue rather than a requirement."" bazel build //tensorflow/tools/pip_package:wheel repo_env=WHEEL_NAME=tensorflow config=cuda config=cuda_wheel  copt=Wnognuoffsetofextensions copt=Wnoerror copt=Wnoc23extensions verbose_failures copt=Wnomacroredefined ```  NOTE You mayyyybe need to get the very latest cuDNN with this, but I don't think so. ``` cd ~/rtx5000 wget https://developer.download.nvidia.com/compute/cudnn/redist/cudnn/linuxx86_64/cudnnlinuxx86_649.8.0.87_cuda12archive.tar.xz tar xvf cudnnlinuxx86_649.8.0.87_cuda12archive.tar.xz echo add this to your ~/.bashrc export LD_LIBRARY_PATH=""$HOME/rtx5000/cudnnlinuxx86_649.8.0.87_cuda12archive/lib:$LD_LIBRARY_PATH"" ``` NOTE: If this doesn't work for you, let me know which error you got, and maybe I missed something in my environment. Since this was already my dev box, I'm not sure if this is a complete guide, but it's what I did to get it working.","Hey  , just seeing your tags you added. To be clear, this is on tf_nightly, not tf 2.18, and I have no idea really what I'm doing, so I'm not gonna PR my extremely busted and testsfailing branch, even though it does build. I put it here so that someone who knows what they're doing could fold in the new stuff more easily, or so that other normal humans like me could run tensorflow on an RTX 5000, instead of just being unable to run it. An actual human who knows what they're doing should look this over and figure it out.",cd ~/rtx5000 nvcc o card_details_nvcc card_details.cu bash: cd: /home/nicolai/rtx5000: No such file or directory cc1plus: fatal error: card_details.cu: No such file or directory compilation terminated.,"I tryed to let it run on my wsl. Build dosen't work, how can I use a prebuiled nightly build?   Configuration: 8850a00e136a9e8be32c557a177e77f38f3c27b70c44518acb5ba0af47f7836b  Execution platform: @//:platform In file included from external/local_xla/xla/stream_executor/cuda/cuda_status.cc:16: external/local_xla/xla/stream_executor/cuda/cuda_status.h:22:10: fatal error: 'third_party/gpus/cuda/include/cuda.h' file not found    22           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1 error generated. Target //tensorflow/tools/pip_package:wheel failed to build ERROR: /mnt/c/Projekte/tmp/tensorflow/tensorflow/tools/pip_package/BUILD:293:9 Action tensorflow/tools/pip_package/wheel_house/tensorflow2.20.0.dev0+selfbuiltcp312cp312linux_x86_64.whl failed: (Exit 1): clang20 failed: error executing CppCompile command (from target @//xla/stream_executor/cuda:cuda_status)   (cd /root/.cache/bazel/_bazel_root/509ab554767d44265e0030c4731aba07/execroot/org_tensorflow && \   exec env  \     CLANG_CUDA_COMPILER_PATH=/usr/local/bin/clang20 \     PATH=/root/.cache/bazelisk/downloads/sha256/c97f02133adce63f0c28678ac1f21d65fa8255c80429b588aeeba8a1fac6202b/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \     PWD=/proc/self/cwd \     PYTHON_BIN_PATH=/mnt/c/Projekte/env/bin/python3 \     PYTHON_LIB_PATH=/mnt/c/Projekte/env/lib/python3.12/sitepackages \     TF2_BEHAVIOR=1 \   /usr/local/bin/clang20 MD MF bazelout/k8opt/bin/external/local_xla/xla/stream_executor/cuda/_objs/cuda_status/cuda_status.pic.d 'frandomseed=bazelout/k8opt/bin/external/local_xla/xla/stream_executor/cuda/_objs/cuda_status/cuda_status.pic.o' iquote external/local_xla iquote bazelout/k8opt/bin/external/local_xla iquote external/com_google_absl iquote bazelout/k8opt/bin/external/com_google_absl iquote external/local_config_cuda iquote bazelout/k8opt/bin/external/local_config_cuda iquote external/cuda_cudart iquote bazelout/k8opt/bin/external/cuda_cudart iquote external/cuda_cublas iquote bazelout/k8opt/bin/external/cuda_cublas iquote external/cuda_cccl iquote bazelout/k8opt/bin/external/cuda_cccl iquote external/cuda_nvtx iquote bazelout/k8opt/bin/external/cuda_nvtx iquote external/cuda_nvcc iquote bazelout/k8opt/bin/external/cuda_nvcc iquote external/cuda_cusolver iquote bazelout/k8opt/bin/external/cuda_cusolver iquote external/cuda_cufft iquote bazelout/k8opt/bin/external/cuda_cufft iquote external/cuda_cusparse iquote bazelout/k8opt/bin/external/cuda_cusparse iquote external/cuda_curand iquote bazelout/k8opt/bin/external/cuda_curand iquote external/cuda_cupti iquote bazelout/k8opt/bin/external/cuda_cupti iquote external/cuda_nvml iquote bazelout/k8opt/bin/external/cuda_nvml iquote external/cuda_nvjitlink iquote bazelout/k8opt/bin/external/cuda_nvjitlink iquote external/local_tsl iquote bazelout/k8opt/bin/external/local_tsl Ibazelout/k8opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers Ibazelout/k8opt/bin/external/cuda_cudart/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_cublas/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_cccl/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_nvtx/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_nvcc/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_cusolver/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_cufft/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_cusparse/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_curand/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_cupti/_virtual_includes/headers Ibazelout/k8opt/bin/external/cuda_nvml/_virtual_includes/headers Ibaroot199root199P461:/mroot199P461:/mroot199P461:/mroot199P461:/mroot199P461:/mroot199P461:/mnt/c/Projekte/tmp/tensorflow    ", and  is there a build that I can use? (like nightly build),"Hey  , scroll up until you see ""Script for WSL Ubuntu 22.04"" in the comments.  The issue I raised is that there is no build, nightly or otherwise, that supports the latest Blackwell GPUs. I arguably managed to build one myself. You also could. But read through the script I put up above slowly. It looks like you missed some steps. HOPEFULLY the script I wrote will work for someone else, but since I got it working on an old dev box, rather than a brand fresh new black docker container or something, it's likely that I missed a dependency or two."," dosen't work for me. echo ""This should be Bazel v8.8.1"" bazel version here I get only 8.1.1 and I get some Errors for the build. is there any chance when tensorflow will support the 5090 on its own and I can simply use the next version of tensorflow? If so, please give me a date when.","Yes, I feel problem with NVIDIA RTX 5090  32GB Blackwell (not nightly version of PyTorch). I cannot see GPU with TensorFlow success. Can you take a look at https://gist.github.com/donhuvy/6cd637a09b034168d01181d5ce98a5fe  . I catch `Num GPUs Available:  0` . My environment: Windows 11 pro, JupyterLab latest version, Python 3.11.x .",wait so you got it to work 100%. it sucks my system has 2 5090's and i'm using a cpu for training.,"Whenever I could not get drivers to work, it usually resolved after installing, reinstalling and changing versions of different packages, since the shortage I doubt there is overwhelming support for the 5090, I remember all launches to have crashing and minimal error bugs that disappear over a relatively short period of time. I got stuck a while ago similarly on different cards and in general, it might be a tiny thing somewhere with your paths and env. Try on Linux and see if that works, I don't know why you are using Windows as a senior Dev. My speeds on the 4090 doubled on render times for anything AI/ML related and loading times of nearly everything python vanished.",">  dosen't work for me. > echo ""This should be Bazel v8.8.1"" > bazel version here I get only 8.1.1 and I get some Errors for the build. >  >  > is there any chance when tensorflow will support the 5090 on its own and I can simply use the next version of tensorflow? >  > If so, please give me a date when. >  Sorry  , I'm not a tensorflow employee. I'm just some dude. Can't guess when it will be fixed. I just got my build to work and my personal projects running fine. My tests are failing and I assume that needs resolving. If your Bazel version is wrong, try installing Bazelisk. See above for instructions. ","> wait so you got it to work 100%. it sucks my system has 2 5090's and i'm using a cpu for training. >  Yep. For my workflow (training StableDiffusion LoRAs) it works fine. The tests are failing locally, but they must be testing tensorflow components that I am not using. You could presumably try following in my footsteps and use your 5090s. ","> Try on Linux and see if that works, I don't know why you are using Windows as a senior Dev. My speeds on the 4090 doubled on render times for anything AI/ML related and loading times of nearly everything python vanished. I'm also a senior dev, and while I agree in general that Linux is better and faster, Windows is still a perfectly legit OS. In fact, Apple Silicon is quite nice for training too. There's no distinction between RAM and VRAM in arm64a. Huge models run on consumer hardware. Not near as fast as on nvidia, but OSX is a legit OS too. "," I tried following the WSL script and got this error in the final step: ""external/local_tsl/tsl/profiler/lib/nvtx_utils.cc:32:10: fatal error: 'third_party/gpus/cuda/include/cuda.h' file not found"". All previous steps were OK, such as the one building the .cu file using clang. ","  What's your HERMETIC_CUDA_VERSION? It should be 12.8.1 Apart from that, maybe try cleaning the Bazel cache? ```  Double check CUDA echo ""HERMETIC_CUDA_VERSION: $HERMETIC_CUDA_VERSION""  I have trust issues with every cache thing bazel clean expunge ```"," It is 12.8.1 correctly. I also tried cleaning the Bazel cache, the error was same: header files in 'third_party/gpus/cuda/include' cannot be found. "," Some additional info: among the error verbose text, it displayed some environmental variables such as ""LD_LIBRARY_PATH"" ""PATH"", etc, but no ""CPATH"" can be seen. Could this be related to the issue?"
yi,maludwig,Fixing bugs and old code in the tf_env script,"I was trying to make a bug report, and the Github Issues thing told me to run this script, which failed to run and produced a lot of buggy output. I didn't try to make any changes to the script, since I'm not strictly sure what all of these help with, I just tried to stabilize the script, make the code cleaner, and account for common bugs in bash scripts (like a space in the path to python). I'll make comments on the PR to explain each change.",2025-03-15T03:11:04Z,ready to pull size:M,closed,0,7,https://github.com/tensorflow/tensorflow/issues/89271,"Sorry, maybe I should have merged right away rather than making the changes. Not sure what the process is for letting you know, but I've made extremely minor modifications as suggested to the top of the file.","Sorry if I'm doing it wrong, new to contributing to this project, but I added the comment lines you suggested, can you rereview,  ?","Sorry for the delay, I was not able to do much TF reviews over the past few days.","So, now what happens. I can't seem to merge this. Who does the merging?","If you look at https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.mdcontributorlicenseagreements, there's a graph just above the section I just linked to. The PR needs to get imported internally and there are more checks and reviews there. You only see what is above the topmost line.","Oh, ok, I expected it to be like an automated thing, where once it gets approved then it rather quickly gets merged, if tests pass. So now I just wait then I guess? I just found a different PR (unrelated) that you approved and then it got merged like 2 weeks later. Is this normal? https://github.com/tensorflow/tensorflow/pull/73692","Yeah, sadly we only have one single engineer that is pinged when the internal change gets imported, plus the people that review the PR. But if I review the PR I cannot also approve the internal change, so either I need to add someone else or the pinged engineer has to review. The nice thing is that here everything seems to pass, so once we get the internal approval this should be ready to merge."
yi,kaushikn02,A dynamic link library (DLL) initialization routine failed.," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.8  Custom code Yes  OS platform and distribution windows 11  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[3], line 1 > 1 import tensorflow as tf       2 print(tf.__version__) File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\hp\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.  Standalone code to reproduce the issue ```shell ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:73      72 try: > 73   from tensorflow.python._pywrap_tensorflow_internal import *      74  This try catch logic is because there is no bazel equivalent for py_extension.      75  Externally in opensource we must enable exceptions to load the shared object      76  by exposing the PyInit symbols with pybind. This error will only be      77  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      78       79  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[3], line 1 > 1 import tensorflow as tf       2 print(tf.__version__) File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:88      86     sys.setdlopenflags(_default_dlopen_flags)      87 except ImportError: > 88   raise ImportError(      89       f'{traceback.format_exc()}'      90       f'\n\nFailed to load the native TensorFlow runtime.\n'      91       f'See https://www.tensorflow.org/install/errors '      92       f'for some common causes and solutions.\n'      93       f'If you need help, create an issue '      94       f'at https://github.com/tensorflow/tensorflow/issues '      95       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\hp\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. ```  Relevant log output ```shell ```",2025-03-15T01:59:40Z,type:build/install,closed,0,3,https://github.com/tensorflow/tensorflow/issues/89269,please update the MSVC 2019 redistributable，download links: https://download.visualstudio.microsoft.com/download/pr/285b28c73cf947fb9be801cf5323a8df/8F9FB1B3CFE6E5092CF1225ECD6659DAB7CE50B8BF935CB79BFEDE1F3C895240/VC_redist.x64.exe,Please search for duplicates before opening a new issue,Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],Fix parsing for `RaggedDotDimensionNumbersAttr` to correctly parse nested attributes.,Fix parsing for `RaggedDotDimensionNumbersAttr` to correctly parse nested attributes. The issue was that the `dot_dimension_numbers` attribute was parsed like raw structlike element instead of being parsed as an `Attribute`.,2025-03-15T00:13:37Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89266
rag,copybara-service[bot],Lower lax.ragged_dot_general to chlo.ragged_dot in some cases on tpu.,Lower lax.ragged_dot_general to chlo.ragged_dot in some cases on tpu.,2025-03-14T22:54:26Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89262
gpt,sjh0849,Inconsistent results when running tf.keras.layers.InputLayer," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version N\A  GCC/compiler version N\A  CUDA/cuDNN version N\A  GPU model and memory N\A  Current behavior? The expectation is that the API should raise a ValueError, but it does not pass the test.  Standalone code to reproduce the issue ```shell def test_input_layer_with_none_shape(self):          Test with None as input shape         with self.assertRaises(ValueError):             tf.keras.layers.InputLayer(input_shape=None) ```  Relevant log output ```shell Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/zero_shot/tf/tf.keras.layers.InputLayer.py"", line 55, in test_input_layer_with_none_shape     tf.keras.layers.InputLayer(input_shape=None) AssertionError: ValueError not raised ```",2025-03-14T19:41:05Z,stat:awaiting response type:bug stale comp:keras TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/89252,"Hi  , Apologies for the delay, and thank you for your patience. I tried running your code on Colab using TensorFlow version 2.19.0 and nightly, but I did not encounter the error you are facing. I am attaching a gist for your reference. Based on my findings, this issue seems to be more related to Keras. I recommend posting this issue on the kerasteam/keras repository for better support. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.
gpt,sjh0849,Getting AttributeError when running tf.ones_like," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux 22.04  Mobile device N\A  Python version 3.9  Bazel version N\A  GCC/compiler version N\A  CUDA/cuDNN version N\A  GPU model and memory N\A  Current behavior? Getting AttributeError when running tf.ones_like.  Standalone code to reproduce the issue ```shell def test_ones_like_with_name(self):          Test with name         input_tensor = tf.constant([1, 2, 3])         result = tf.ones_like(input_tensor, name=""test_ones_like"")         self.assertEqual(result.op.name, ""test_ones_like"") ```  Relevant log output ```shell Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/basic_rag_apidoc/tf/tf.ones_like.py"", line 66, in test_ones_like_with_name     self.assertEqual(result.op.name, ""test_ones_like"")   File ""/home/user/anaconda3/lib/python3.8/sitepackages/tensorflow/python/framework/ops.py"", line 444, in __getattr__     self.__getattribute__(name)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/tensorflow/python/framework/ops.py"", line 1305, in op     raise AttributeError( AttributeError: Tensor.op is undefined when eager execution is enabled. ```",2025-03-14T19:34:37Z,type:bug comp:ops TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/89250,"Hi  , Apologies for the delay, and thanks for raising your concern here. Could you please provide the full code snippet? This would help debug your issue more accurately. I tried running your code on Colab using TensorFlow versions 2.18.0 and 2.19.0, but I did not encounter any issues. Please find the gist here for your reference. Let me know if you need further assistance. Thank you!","sorry for that again. here is the complete class! ```python import tensorflow as tf import numpy as np import unittest class TestTfOnesLike(unittest.TestCase):     def test_ones_like_with_name(self):          Test with name         input_tensor = tf.constant([1, 2, 3])         result = tf.ones_like(input_tensor, name=""test_ones_like"")         self.assertEqual(result.op.name, ""test_ones_like"") if __name__ == '__main__':     unittest.main() ``` many thanks!"
gpt,sjh0849,The API documentation of tf.no_op specifies that tf.no_op() should return a TensorFlow Operation.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution N\A  Mobile device N\A  Python version 3.9  Bazel version N\A  GCC/compiler version N\A  CUDA/cuDNN version N\A  GPU model and memory N\A  Current behavior? The API documentation of tf.no_op specifies that tf.no_op() should return a TensorFlow Operation.  The tests expect that calling tf.no_op() returns an instance of tf.Operation (and that its name property can be set by providing a name, e.g., ""my_no_op""). The error message indicates that tf.no_op() is returning None rather than an Operation (None has no attribute ""name""), causing the tests to fail. Given that the test suite is properly written according to the API's specification and the expected behavior, the issue stems from the source code implementation.  Standalone code to reproduce the issue ```shell def test_no_op_name(self):         """"""Test that a no_op can be created with a specific name.""""""         no_op = tf.no_op(name=""my_no_op"")         self.assertEqual(no_op.name, ""my_no_op"")    def test_no_op_creation(self):         """"""Test that a no_op can be created without errors.""""""         try:             no_op = tf.no_op()             self.assertIsInstance(no_op, tf.Operation)         except Exception as e:             self.fail(f""tf.no_op raised an exception: {e}"") ```  Relevant log output ```shell Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/basic_rag_apidoc/tf/tf.no_op.py"", line 17, in test_no_op_name     self.assertEqual(no_op.name, ""my_no_op"") AttributeError: 'NoneType' object has no attribute 'name' Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/basic_rag_apidoc/tf/tf.no_op.py"", line 12, in test_no_op_creation     self.fail(f""tf.no_op raised an exception: {e}"") AssertionError: tf.no_op raised an exception: None is not an instance of  ```",2025-03-14T19:01:19Z,type:bug comp:apis comp:ops TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/89248,"Hi  , Apologies for the delay, and thanks for raising your concern here. Could you please provide the full code snippet? This would help debug your issue more accurately. I tried running your code on Colab using TensorFlow versions 2.18.0 and 2.19.0, but I did not encounter any issues. Please find the gist here for your reference. Let me know if you need further assistance. Thank you!","sorry for that. here is the complete class! ```python import unittest import tensorflow as tf class TestNoOpFunctionality(unittest.TestCase):     def test_no_op_name(self):         """"""Test that a no_op can be created with a specific name.""""""         no_op = tf.no_op(name=""my_no_op"")         self.assertEqual(no_op.name, ""my_no_op"")     def test_no_op_creation(self):         """"""Test that a no_op can be created without errors.""""""         try:             no_op = tf.no_op()             self.assertIsInstance(no_op, tf.Operation)         except Exception as e:             self.fail(f""tf.no_op raised an exception: {e}"") if __name__ == '__main__':     unittest.main() ``` many thanks!"
gpt,sjh0849,tf.keras.losses.SparseCategoricalCrossentropy has logical/Doc bug," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? API documentation of tf.keras.losses.SparseCategoricalCrossentropy mentions that one of the parameters can be None, but the implementation does not check None, it checks 'none' which is a string.  Standalone code to reproduce the issue ```shell def test_reduction_none(self):          Test with reduction set to None         y_true = np.array([0, 1, 2])         y_pred = np.array([[0.9, 0.05, 0.05],                            [0.05, 0.9, 0.05],                            [0.05, 0.05, 0.9]])         loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=None)         loss = loss_fn(y_true, y_pred).numpy()         expected_loss = np.log([0.9, 0.9, 0.9])         np.testing.assert_almost_equal(loss, expected_loss, decimal=5) ```  Relevant log output ```shell Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/basic_rag_apidoc/tf/tf.keras.losses.SparseCategoricalCrossentropy.py"", line 49, in test_reduction_none     loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(reduction=None)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/losses.py"", line 1026, in __init__     super().__init__(   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/losses.py"", line 262, in __init__     super().__init__(reduction=reduction, name=name)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/losses.py"", line 93, in __init__     losses_utils.ReductionV2.validate(reduction)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/utils/losses_utils.py"", line 88, in validate     raise ValueError( ValueError: Invalid Reduction Key: None. Expected keys are ""('auto', 'none', 'sum', 'sum_over_batch_size')"" ```",2025-03-14T18:50:50Z,type:bug comp:keras TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/89246,"This should be opened against the keras repository (tf_keras or keras directly). From the TF side, the only change that could be done is to update the documentation of the function, make sure the docstring uses the correct phrasing. Looking at https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy I see an example where `None` is being used instead of the string `""none""`, so if the example was a doctest then some test would have failed. We should convert the examples to be doctests. Probably though all of this would happen on keras side, not TF.", I see! Thanks for the clarification. I will report this to the keras repository. Thanks!
yi,sjh0849,I get an invalid shape error when running tf.keras.losses.BinaryCrossentropy," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux 22.04  Mobile device N\A  Python version 3.9  Bazel version N\A  GCC/compiler version N\A  CUDA/cuDNN version N\A  GPU model and memory N\A  Current behavior? I get an invalid shape error when running ```tf.keras.losses.BinaryCrossentropy```  Standalone code to reproduce the issue ```shell def test_binary_crossentropy_invalid_inputs(self):          Test with invalid inputs         y_true = np.array([0, 1, 0, 1], dtype=np.float32)         y_pred = np.array([0.1, 0.9, 0.2], dtype=np.float32)   Mismatched shape         bce = tf.keras.losses.BinaryCrossentropy()         with self.assertRaises(ValueError):             bce(y_true, y_pred) ```  Relevant log output ```shell Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/basic_rag_apidoc/tf/tf.keras.losses.BinaryCrossentropy.py"", line 70, in test_binary_crossentropy_invalid_inputs     bce(y_true, y_pred)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/losses.py"", line 152, in __call__     losses = call_fn(y_true, y_pred)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/losses.py"", line 284, in call     return ag_fn(y_true, y_pred, **self._fn_kwargs)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/losses.py"", line 2176, in binary_crossentropy     backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),   File ""/home/user/anaconda3/lib/python3.8/sitepackages/keras/backend.py"", line 5688, in binary_crossentropy     bce = target * tf.math.log(output + epsilon()) tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [4] vs. [3] [Op:Mul] ```",2025-03-14T18:42:02Z,type:bug comp:keras TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/89245,"Hi  , Apologies for the delay, and thanks for raising your concern here. I tried running your code on Colab using TensorFlow versions 2.18, 2.19, and the nightly, but I did not encounter any issues. Please find the gist attached for your reference. Thank you!","Hi  , Thanks for getting back to me! I noticed, like the other issue, that the replicable code wasn't sufficient, leading to the failure to call and execute the function. However, I reran the test, but it's not giving me the errors it used to give me. I think it's being flaky."
gpt,sjh0849,AssertionError when calling tf.keras.layers.Conv2DTranspose," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux 22.4  Mobile device N\A  Python version 3.9  Bazel version N\A  GCC/compiler version N\A  CUDA/cuDNN version N\A  GPU model and memory N\A  Current behavior? When running ```tf.keras.layers.Conv2DTranspose```, I get AssertionError. The minimum reproducing example is attached.  Standalone code to reproduce the issue ```shell def test_kernel_initializer():          Test with a custom kernel initializer         model = tf.keras.Sequential([             tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, kernel_initializer='ones', input_shape=(4, 4, 1))         ])         input_data = np.ones((1, 4, 4, 1), dtype=np.float32)         output_data = model(input_data)         expected_output = np.full((1, 6, 6, 1), 9.0)   Since kernel is initialized with ones         np.testing.assert_array_almost_equal(output_data.numpy(), expected_output) ```  Relevant log output ```shell Traceback (most recent call last):   File ""/home/user/projects/api_guided_testgen/out/bug_detect_gpt4o/exec/basic_rag_apidoc/tf/tf.keras.layers.Conv2DTranspose.py"", line 74, in test_kernel_initializer     np.testing.assert_array_almost_equal(output_data.numpy(), expected_output)   File ""/home/user/anaconda3/lib/python3.8/sitepackages/numpy/testing/_private/utils.py"", line 1046, in assert_array_almost_equal     assert_array_compare(compare, x, y, err_msg=err_msg, verbose=verbose,   File ""/home/user/anaconda3/lib/python3.8/sitepackages/numpy/testing/_private/utils.py"", line 844, in assert_array_compare     raise AssertionError(msg) AssertionError:  Arrays are not almost equal to 6 decimals Mismatched elements: 32 / 36 (88.9%) Max absolute difference: 8. Max relative difference: 0.88888889  x: array([[[[1.],          [2.],          [3.],...  y: array([[[[9.],          [9.],          [9.],...  Ran 8 tests in 0.155s FAILED (failures=2) ```",2025-03-14T18:37:22Z,type:bug comp:ops TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/89244,"Hi  , Apologies for the delay, and thanks for raising your concern here. I tried running your code on Colab using TensorFlow versions 2.18, 2.19, and the nightly, but I did not encounter any issues. Please find the gist attached for your reference. Thank you!","> Hi [](https://github.com/sjh0849) , Apologies for the delay, and thanks for raising your concern here. I tried running your code on Colab using TensorFlow versions 2.18, 2.19, and the nightly, but I did not encounter any issues. Please find the gist attached for your reference. >  > Thank you! Hi  , Sorry, I think my replication code earlier was not sufficient. (The colab seems like it's not executing the test.) Here is the updated replicable code. ```python import tensorflow as tf import numpy as np import unittest class TestConv2DTranspose(unittest.TestCase):     def test_kernel_initializer(self):          Test with a custom kernel initializer         model = tf.keras.Sequential([             tf.keras.layers.Conv2DTranspose(filters=1, kernel_size=3, kernel_initializer='ones', input_shape=(4, 4, 1))         ])         input_data = np.ones((1, 4, 4, 1), dtype=np.float32)         output_data = model(input_data)         expected_output = np.full((1, 6, 6, 1), 9.0)   Since kernel is initialized with ones         np.testing.assert_array_almost_equal(output_data.numpy(), expected_output) if __name__ == '__main__':     unittest.main() ``` > Hi [](https://github.com/sjh0849) , Apologies for the delay, and thanks for raising your concern here. I tried running your code on Colab using TensorFlow versions 2.18, 2.19, and the nightly, but I did not encounter any issues. Please find the gist attached for your reference. >  > Thank you!"
rag,copybara-service[bot],Reland: [XLA:GPU] Enable RaggedAllToAll one shot kernel by default.,Reland: [XLA:GPU] Enable RaggedAllToAll one shot kernel by default. Reverts 2931aad06d9d11a6c028e89a5a061d60e3808193,2025-03-14T18:26:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89243
rag,copybara-service[bot],[XLA:GPU] Enable peer access for all collective cliques.,"[XLA:GPU] Enable peer access for all collective cliques. To check for peer access, we need to call CUDA driver for all pairs of devices, so we want to do it only once per clique, if possible. The peer access is currently needed only for oneshot raggedalltoall kernel, but we might want to experiment with other collectives later.",2025-03-14T16:29:21Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89237
yi,copybara-service[bot],[XLA:CPU] Make the small while loop hoisting threshold configurable & increase default to 1024,"[XLA:CPU] Make the small while loop hoisting threshold configurable & increase default to 1024 This change also made an underlying bug apparent where dot ops would call into Eigen runtime and crash, this resolves that by not hoisting while loops which transitively call dot.",2025-03-14T10:01:24Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89223
rag,copybara-service[bot],PR #23688: [ROCm] Triton performance fixes,"PR CC(remove reduce_ from established functions, make it closer to numpy): [ROCm] Triton performance fixes Imported from GitHub PR https://github.com/openxla/xla/pull/23688 Copybara import of the project:  f6998514cd08d018a313294f6974ccab674525bb by Dragan Mladjenovic : [ROCm] Apply precise block size metadata  bdcba45f58f7ad40e6ee8e8d2afd0c04956b34d5 by Dragan Mladjenovic : [ROCm] Pass correct warp size to Triton pipeline Merging this change closes CC(remove reduce_ from established functions, make it closer to numpy) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23688 from ROCm:ci_rocm_triton_perf_fixes bdcba45f58f7ad40e6ee8e8d2afd0c04956b34d5",2025-03-14T09:00:36Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89222
gemma,jiunkaiy,Qualcomm AI Engine Direct - Provide op optimization,Summary:  Support FC>CONV2D optimization  Add CONV2D op builder with CPU transpose Test:  [x] a8w8 Gemma3 compile and execution successfully  [x] qnn_compiler_plugin_test all pass,2025-03-14T07:08:28Z,awaiting review ready to pull size:L,closed,0,2,https://github.com/tensorflow/tensorflow/issues/89210,Any test results?,> Any test results? I have left some comments in the first conversation block. Thanks!
rag,copybara-service[bot],Preserve `mhlo.frontend_attributes` when legalizing to `mhlo.ragged_dot`.,Preserve `mhlo.frontend_attributes` when legalizing to `mhlo.ragged_dot`.,2025-03-13T22:20:33Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89192
yi,copybara-service[bot],Update PyArray::BatchedDevicePut to support zero buffers and destination devices. Use batched_device_put instead of ArrayImpl to build arrays with no local shards.,Update PyArray::BatchedDevicePut to support zero buffers and destination devices. Use batched_device_put instead of ArrayImpl to build arrays with no local shards.,2025-03-13T19:16:26Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89180
yi,copybara-service[bot],[xla:copy_insertion] Fix a problem in handling Send feeding into a while-loop.,"[xla:copy_insertion] Fix a problem in handling Send feeding into a whileloop. Previously, we only make a copy of the operand for rotated Send/SendDone inside a whileloop. We now also make a copy of the operand for the Send feeding into a whileloop so that the buffer for the operand does not have to hold different values with live range interference.",2025-03-13T18:19:36Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89174
rag,copybara-service[bot],[xla:gpu] Remove mentions of NCCL from RaggedAllToAllThunk,[xla:gpu] Remove mentions of NCCL from RaggedAllToAllThunk,2025-03-13T15:36:58Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89155
rag,copybara-service[bot],Revert: [XLA:GPU] Enable RaggedAllToAll one shot kernel by default.,Revert: [XLA:GPU] Enable RaggedAllToAll one shot kernel by default. Breaks internal tests. Reverts a92cc3d7cff250c40fce23067b0a2e32f96a39f7,2025-03-13T14:35:18Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89149
rag,copybara-service[bot],PR #23320: [NVIDIA GPU] Add utility functions for multi-host fast-interconnect domain,"PR CC([Feature Request] Addition of new operation to Tensorflow Lite for ""ENet""): [NVIDIA GPU] Add utility functions for multihost fastinterconnect domain Imported from GitHub PR https://github.com/openxla/xla/pull/23320 On Blackwell and onwards, multiple hosts may be connected by NVLink thus creating a fastinterconnect domain beyond a single node. This PR leverages NVML APIs to detect the actual fastinterconnect domain. Followup PRs will update the logic in PjRt client on top of these utility functions. Copybara import of the project:  ee084714876336243fa3ba52a857d2d41124b730 by Terry Sun : pipe nvml to detect nvl  36e1f71dfabb75dbd0853355a7be8c0d6d103903 by Terry Sun : convert clusterUUID  917eb219a1bdebfc7a12f5849545615c83092c73 by Terry Sun : bake boot id into key  cbd909ab66ccf47f6e140632645fbb4d6c61c7c3 by Terry Sun : use global id and add getter  e487c4718eefe72e77708ffaf2c8cbbf6c979e8e by Terry Sun : use device ordinal and add doc string  2c761da2c04ea39d6cc79314f0dc14efef6d0380 by Terry Sun : merge fabric info into device proto  ed34dfbba07fbc5ffaaa914478381184a90f9cbb by Terry Sun : error handling and cleanup  c62f08691b7e3a59effc0f721948b30baea5b8a8 by Terry Sun : polish doc string  ab9d41e3142a0792859b9d37b99fe3ddfd9bbba8 by Terry Sun : conditional compile  29d857815a55d7df7911625cfeb35047bfbb07cb by Terry Sun : more conditional compile  524b569f1937db51babdaac04b50e9499da81a95 by Terry Sun : fix field designator order  7a0fb0f10be555c32403af4d226e687c650603d2 by Terry Sun : str buffer size  91e28b675b2f25e2b5d6c73732c8dae193b0dff3 by Terry Sun : compute capability condition  48fafb9dc4f44c451ca64bdb8ca15a1678cae398 by Terry Sun : protobuf backward compatibility  90f07569cf64d4d7d957cf4efe16fd2c9142eb4c by Terry Sun : guard cluster uuid size Merging this change closes CC([Feature Request] Addition of new operation to Tensorflow Lite for ""ENet"") FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23320 from terryysun:terryysun/detect_mnnvl 4820e4b53c9a72fe6ee8c08ab29ee640f1697c8d",2025-03-13T11:13:02Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89140
llm,copybara-service[bot],[xla:cpu] enable scatter fusion emitter,"[xla:cpu] enable scatter fusion emitter Known issues:  bf16 performance is poor. This is because in the emitters   we are missing an optimization that we have in XLA thunks.   We will fix this soon.  No parallel scatter. We are leaving this as future work   since the singlethreaded implementation is already bringing   significant performance improvements. Scatter microbenchmarks: ```                                                                            │ fusion_emitters  │          scatter                    │                                                                            │    cpusec/op    │  cpusec/op   vs base               │ BM_ScatterS32_R1/262144/262144/process_time                                       600.1µ ± 1%   206.5µ ±  2%  65.59% (p=0.002 n=6) BM_ScatterS32_R2/512/512/process_time                                             77.45µ ± 1%   49.88µ ±  3%  35.59% (p=0.002 n=6) BM_ScatterS32_R3/64/64/process_time                                               54.28µ ± 0%   50.49µ ±  3%   6.99% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:1/d1:64/d2:8/num_slices:1/process_time            755.0n ± 1%   702.3n ±  4%   6.98% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:50/d1:64/d2:8/num_slices:10/process_time         106.82µ ± 0%   17.66µ ±  3%  83.47% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:500/d1:64/d2:8/num_slices:100/process_time       10.301m ± 2%   2.635m ±  2%  74.42% (p=0.002 n=6) BM_SelectAndScatterF32/128/process_time                                           37.00µ ± 1%   27.76µ ±  3%  24.97% (p=0.002 n=6) BM_SelectAndScatterF32/256/process_time                                          117.86µ ± 2%   86.36µ ±  1%  26.73% (p=0.002 n=6) BM_SelectAndScatterF32/512/process_time                                           1.613m ± 2%   1.528m ± 61%        ~ (p=0.065 n=6) geomean                                                                           134.8µ        73.45µ        45.53% ``` The gap from a few days ago was wider (geomean improvement of 76%), but the recent work on improving performance of small while loops (https://github.com/openxla/xla/commit/db734148ec74) narrowed that to the numbers above. Legacy emitters (""nothunks"") compile all while loops, and are therefore a tougher baseline to compare against. Still, scatter fusion emitters are faster (all singlethreaded): ```                                                                            │ nothunks         │          scatter                    │                                                                            │      sec/op      │    sec/op     vs base               │ BM_ScatterS32_R1/262144/262144/process_time                                      360.4µ ±  1%   203.0µ ±  0%  43.67% (p=0.002 n=6) BM_ScatterS32_R2/512/512/process_time                                            50.03µ ±  2%   49.81µ ±  3%        ~ (p=0.699 n=6) BM_ScatterS32_R3/64/64/process_time                                              49.92µ ±  0%   50.41µ ±  0%   +0.96% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:1/d1:64/d2:8/num_slices:1/process_time           617.5n ±  5%   722.7n ±  1%  +17.03% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:50/d1:64/d2:8/num_slices:10/process_time         17.60µ ±  3%   17.82µ ±  4%        ~ (p=0.937 n=6) BM_SimpleScatterReduceF32_R3/d0:500/d1:64/d2:8/num_slices:100/process_time       2.708m ±  2%   2.657m ±  1%        ~ (p=0.093 n=6) BM_SelectAndScatterF32/128/process_time                                          31.26µ ±  1%   27.90µ ±  2%  10.74% (p=0.002 n=6) BM_SelectAndScatterF32/256/process_time                                         101.54µ ±  1%   86.53µ ±  4%  14.78% (p=0.002 n=6) BM_SelectAndScatterF32/512/process_time                                          850.9µ ± 60%   909.6µ ± 16%        ~ (p=0.240 n=6) geomean                                                                          74.60µ         69.60µ         6.70% ``` For the rest of the microbenchmarks, the scatter emitter does not affect performance, except when bf16 is involved due to the known issue mentioned above.  Microbenchmarks ```                                                                                     │ fusion_emitters  │           scatter                    │                                                                                     │    cpusec/op    │  cpusec/op    vs base               │ BM_ConcatenateTwoR3F32/parallel:0/batch:128/width:64/height:256/axis:0/process_time       618.9µ ±  1%    820.4µ ±  1%  +32.57% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:128/width:64/height:256/axis:1/process_time       636.3µ ±  2%    654.3µ ±  6%        ~ (p=1.000 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:128/width:64/height:256/axis:2/process_time       1.002m ±  0%    1.003m ±  1%        ~ (p=0.485 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:256/width:128/height:64/axis:0/process_time       620.9µ ±  0%    607.5µ ±  2%   2.14% (p=0.009 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:256/width:128/height:64/axis:1/process_time       618.5µ ±  1%    750.9µ ±  3%  +21.42% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:256/width:128/height:64/axis:2/process_time       1.380m ±  5%    1.285m ±  6%   6.86% (p=0.041 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:64/width:256/height:128/axis:0/process_time       627.1µ ±  2%    818.4µ ±  6%  +30.50% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:64/width:256/height:128/axis:1/process_time       620.6µ ±  2%    715.8µ ± 14%  +15.36% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:64/width:256/height:128/axis:2/process_time       1.045m ±  2%    1.020m ±  0%   2.45% (p=0.015 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:128/width:64/height:256/axis:0/process_time       1.780m ± 10%    1.779m ± 12%        ~ (p=1.000 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:128/width:64/height:256/axis:1/process_time       1.703m ±  6%    1.540m ± 25%        ~ (p=0.180 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:128/width:64/height:256/axis:2/process_time       2.573m ± 10%    2.375m ± 10%        ~ (p=0.132 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:256/width:128/height:64/axis:0/process_time       1.671m ±  8%    1.790m ± 10%        ~ (p=0.132 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:256/width:128/height:64/axis:1/process_time       1.682m ±  8%    1.792m ±  7%   +6.56% (p=0.026 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:256/width:128/height:64/axis:2/process_time       2.361m ± 14%    2.190m ± 18%        ~ (p=0.093 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:64/width:256/height:128/axis:0/process_time       1.787m ± 12%    1.787m ± 17%        ~ (p=0.699 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:64/width:256/height:128/axis:1/process_time       1.668m ± 10%    1.751m ±  8%        ~ (p=0.485 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:64/width:256/height:128/axis:2/process_time       2.286m ± 12%    2.227m ± 16%        ~ (p=0.937 n=6) BM_Conv1DStrided/1/129/process_time                                                       53.14m ±  3%    50.15m ±  3%   5.62% (p=0.002 n=6) BM_Conv1DStrided/3/129/process_time                                                       161.4m ±  7%    151.3m ±  7%   6.21% (p=0.041 n=6) BM_Conv1DTransposedStrided/129/1/process_time                                             43.65m ± 16%    50.79m ±  5%  +16.35% (p=0.026 n=6) BM_Conv1DTransposedStrided/129/3/process_time                                             139.1m ± 15%    158.1m ±  5%  +13.68% (p=0.015 n=6) BM_Conv1DTransposedStridedNonDefaultLayout/129/1/process_time                             30.11m ±  7%    32.61m ± 14%        ~ (p=0.093 n=6) BM_Conv1DTransposedStridedNonDefaultLayout/129/3/process_time                             107.6m ±  5%    123.8m ±  5%  +15.06% (p=0.002 n=6) BM_Conv2D/16/32/32/128/1/1/1024/process_time                                         121.6m ± 21%    116.0m ± 22%        ~ (p=0.310 n=6) BM_Conv2D/16/32/32/128/3/3/1024/process_time                                         962.9m ± 10%    985.1m ±  8%        ~ (p=0.589 n=6) BM_Conv2D/32/256/256/4/1/1/16/process_time                                           180.9m ±  7%    196.0m ±  5%   +8.35% (p=0.002 n=6) BM_Conv2D/32/256/256/4/3/3/16/process_time                                           434.8m ± 15%    347.8m ± 13%  20.01% (p=0.009 n=6) BM_Conv2D/32/32/32/128/1/1/1024/process_time                                         235.2m ± 25%    244.3m ± 21%        ~ (p=0.093 n=6) BM_Conv2D/32/32/32/128/3/3/1024/process_time                                          1.922 ±  9%     2.074 ±  1%   +7.92% (p=0.041 n=6) BM_Conv2D/32/32/32/96/1/1/96/process_time                                            24.70m ±  2%    22.88m ±  6%   7.37% (p=0.004 n=6) BM_Conv2D/32/32/32/96/3/3/96/process_time                                            138.0m ±  2%    145.5m ±  9%   +5.45% (p=0.002 n=6) BM_Conv2D/32/64/64/32/1/1/64/process_time                                            30.90m ±  7%    27.09m ±  6%  12.33% (p=0.002 n=6) BM_Conv2D/32/64/64/32/3/3/64/process_time                                            164.0m ±  3%    161.8m ±  2%        ~ (p=0.180 n=6) BM_Conv2D/32/64/64/4/1/1/16/process_time                                             1.232m ±  7%    1.191m ±  4%        ~ (p=0.394 n=6) BM_Conv2D/32/64/64/4/3/3/16/process_time                                             30.67m ±  7%    24.93m ± 16%  18.72% (p=0.002 n=6) BM_Conv2D/8/128/128/4/1/1/8/process_time                                             459.2µ ±  2%    434.1µ ±  3%   5.46% (p=0.002 n=6) BM_Conv2D/8/128/128/4/3/3/8/process_time                                             14.52m ±  4%    14.46m ± 10%        ~ (p=0.699 n=6) BM_Conv2D/8/32/32/128/1/1/1024/process_time                                          53.96m ± 11%    51.73m ±  9%   4.15% (p=0.041 n=6) BM_Conv2D/8/32/32/128/3/3/1024/process_time                                          435.6m ±  4%    471.7m ± 21%   +8.29% (p=0.004 n=6) BM_Conv2D/8/5/5/1/1/1/32/process_time                                                3.260µ ±  2%    3.316µ ±  2%   +1.74% (p=0.004 n=6) BM_Conv2D/8/5/5/1/3/3/32/process_time                                                13.26µ ±  1%    13.34µ ±  0%        ~ (p=0.065 n=6) BM_Conv2D/8/5/5/4/1/1/32/process_time                                                1.794µ ±  1%    1.880µ ±  1%   +4.84% (p=0.002 n=6) BM_Conv2D/8/5/5/4/3/3/32/process_time                                                17.97µ ±  2%    18.02µ ±  1%        ~ (p=0.394 n=6) BM_Conv2DStrided/process_time                                                             56.48m ±  5%    54.79m ± 10%        ~ (p=0.132 n=6) BM_Conv2DTransposedStrided/process_time                                                   43.19m ±  9%    48.14m ±  2%  +11.44% (p=0.002 n=6) BM_GroupedConv2D/1/45/45/1024/5/5/1024/1024/process_time                                  414.7m ±  7%    434.2m ± 10%        ~ (p=0.093 n=6) BM_GroupedConv2DStrided/128/128/128/process_time                                          61.65m ±  9%    59.23m ±  6%        ~ (p=0.180 n=6) BM_GroupedConv2DStrided/128/128/16/process_time                                           59.17m ±  5%    59.62m ±  6%        ~ (p=0.937 n=6) BM_GroupedConv2DTransposedStrided/128/128/128/process_time                                 4.425 ±  7%     4.522 ±  3%        ~ (p=0.240 n=6) BM_GroupedConv2DTransposedStrided/128/128/16/process_time                                  3.878 ± 11%     4.496 ± 18%        ~ (p=0.132 n=6) BM_CustomCall_16FloatBuffers/process_time                                                 1.977µ ±  7%    1.982µ ±  6%        ~ (p=0.937 n=6) BM_CustomCall_16IntAttributes/process_time                                                612.8n ±  2%    657.2n ±  3%   +7.24% (p=0.002 n=6) BM_CustomCall_Minimal/process_time                                                        522.2n ±  1%    564.4n ±  8%   +8.07% (p=0.002 n=6) BM_DagExecution/1024/process_time                                                         7.606m ±  1%    7.259m ±  3%   4.56% (p=0.002 n=6) BM_DagExecution/128/process_time                                                          684.3µ ±  4%    502.5µ ± 21%  26.57% (p=0.002 n=6) BM_DagExecution/16384/process_time                                                        174.0m ± 11%    172.3m ± 27%        ~ (p=0.937 n=6) BM_DagExecution/256/process_time                                                          1.917m ±  3%    1.767m ±  4%   7.84% (p=0.002 n=6) BM_DagExecution/512/process_time                                                          3.464m ±  0%    3.296m ±  1%   4.83% (p=0.002 n=6) BM_DagExecution/8192/process_time                                                         67.37m ± 11%    69.95m ± 15%        ~ (p=0.485 n=6) BM_BatchedDot/11/1/128/process_time                                                       37.65µ ±  0%    37.53µ ±  0%   0.31% (p=0.004 n=6) BM_BatchedDot/11/1/2/process_time                                                         540.1n ±  2%    476.2n ±  7%  11.82% (p=0.002 n=6) BM_BatchedDot/11/1/256/process_time                                                       761.4µ ±  2%    720.0µ ±  7%   5.43% (p=0.026 n=6) BM_BatchedDot/11/1/32/process_time                                                        1.804µ ±  0%    1.713µ ±  2%   5.06% (p=0.002 n=6) BM_BatchedDot/11/1/512/process_time                                                       9.297m ±  4%    9.149m ±  1%        ~ (p=0.310 n=6) BM_BatchedDot/11/1/64/process_time                                                        6.452µ ±  0%    6.385µ ±  1%   1.05% (p=0.002 n=6) BM_BatchedDot/11/2/128/process_time                                                       74.46µ ±  0%    74.51µ ±  0%        ~ (p=0.394 n=6) BM_BatchedDot/11/2/2/process_time                                                         542.4n ±  1%    479.0n ± 14%        ~ (p=0.093 n=6) BM_BatchedDot/11/2/256/process_time                                                       1.702m ±  9%    1.472m ±  4%  13.53% (p=0.002 n=6) BM_BatchedDot/11/2/32/process_time                                                        2.837µ ±  0%    2.820µ ±  1%        ~ (p=0.065 n=6) BM_BatchedDot/11/2/512/process_time                                                       21.84m ±  3%    21.67m ±  2%        ~ (p=0.394 n=6) BM_BatchedDot/11/2/64/process_time                                                        12.11µ ±  1%    12.13µ ±  1%        ~ (p=0.818 n=6) BM_BatchedDot/11/4/128/process_time                                                       148.8µ ±  0%    149.0µ ±  0%   +0.13% (p=0.004 n=6) BM_BatchedDot/11/4/2/process_time                                                         546.2n ±  0%    550.1n ±  1%   +0.72% (p=0.002 n=6) BM_BatchedDot/11/4/256/process_time                                                       3.171m ± 17%    3.177m ± 16%        ~ (p=0.937 n=6) BM_BatchedDot/11/4/32/process_time                                                        4.820µ ±  0%    4.824µ ±  0%        ~ (p=0.394 n=6) BM_BatchedDot/11/4/512/process_time                                                       47.88m ±  2%    49.00m ±  6%        ~ (p=0.394 n=6) BM_BatchedDot/11/4/64/process_time                                                        23.28µ ±  0%    23.46µ ±  1%   +0.78% (p=0.002 n=6) BM_BatchedDot/11/8/128/process_time                                                       298.1µ ±  0%    297.3µ ±  0%   0.28% (p=0.002 n=6) BM_BatchedDot/11/8/2/process_time                                                         556.4n ±  1%    557.5n ±  1%        ~ (p=0.699 n=6) BM_BatchedDot/11/8/256/process_time                                                       6.350m ±  3%    7.168m ±  6%  +12.88% (p=0.002 n=6) BM_BatchedDot/11/8/32/process_time                                                        8.760µ ±  1%    8.830µ ±  1%   +0.80% (p=0.015 n=6) BM_BatchedDot/11/8/512/process_time                                                      101.53m ±  3%    97.02m ±  2%   4.44% (p=0.002 n=6) BM_BatchedDot/11/8/64/process_time                                                        45.88µ ±  0%    45.93µ ±  0%        ~ (p=0.240 n=6) BM_BatchedDot/16/1/128/process_time                                                       40.97µ ±  0%    40.97µ ±  0%        ~ (p=0.937 n=6) BM_BatchedDot/16/1/2/process_time                                                         610.1n ±  1%    603.9n ±  2%   1.00% (p=0.026 n=6) BM_BatchedDot/16/1/256/process_time                                                       1.080m ±  2%    1.125m ± 11%        ~ (p=0.065 n=6) BM_BatchedDot/16/1/32/process_time                                                        2.089µ ±  1%    2.062µ ±  1%   1.28% (p=0.026 n=6) BM_BatchedDot/16/1/512/process_time                                                       11.21m ±  2%    11.05m ±  1%   1.40% (p=0.041 n=6) BM_BatchedDot/16/1/64/process_time                                                        7.380µ ±  1%    7.356µ ±  1%        ~ (p=0.063 n=6) BM_BatchedDot/16/2/128/process_time                                                       81.12µ ±  0%    81.06µ ±  0%        ~ (p=0.240 n=6) BM_BatchedDot/16/2/2/process_time                                                         624.0n ±  1%    613.7n ±  1%   1.65% (p=0.002 n=6) BM_BatchedDot/16/2/256/process_time                                                       2.219m ±  2%    2.085m ±  1%   6.06% (p=0.002 n=6) BM_BatchedDot/16/2/32/process_time                                                        3.371µ ±  1%    3.358µ ±  0%        ~ (p=0.132 n=6) BM_BatchedDot/16/2/512/process_time                                                       25.65m ±  3%    24.98m ±  3%        ~ (p=0.065 n=6) BM_BatchedDot/16/2/64/process_time                                                        13.79µ ±  0%    13.80µ ±  1%        ~ (p=0.310 n=6) BM_BatchedDot/16/4/128/process_time                                                       163.6µ ±  0%    163.9µ ±  0%   +0.23% (p=0.002 n=6) BM_BatchedDot/16/4/2/process_time                                                         636.3n ±  1%    627.1n ±  3%        ~ (p=0.240 n=6) BM_BatchedDot/16/4/256/process_time                                                       4.720m ±  9%    4.489m ±  8%   4.91% (p=0.041 n=6) BM_BatchedDot/16/4/32/process_time                                                        5.752µ ±  1%    5.757µ ±  1%        ~ (p=0.485 n=6) BM_BatchedDot/16/4/512/process_time                                                       53.96m ±  2%    55.37m ±  5%        ~ (p=0.310 n=6) BM_BatchedDot/16/4/64/process_time                                                        26.56µ ±  1%    26.69µ ±  1%   +0.47% (p=0.041 n=6) BM_BatchedDot/16/8/128/process_time                                                       742.6µ ±  2%    896.0µ ± 17%  +20.65% (p=0.002 n=6) BM_BatchedDot/16/8/2/process_time                                                         650.6n ±  1%    649.3n ±  1%        ~ (p=0.818 n=6) BM_BatchedDot/16/8/256/process_time                                                       9.378m ±  6%    9.013m ±  4%   3.89% (p=0.015 n=6) BM_BatchedDot/16/8/32/process_time                                                        10.49µ ±  0%    10.49µ ±  0%        ~ (p=0.937 n=6) BM_BatchedDot/16/8/512/process_time                                                       115.7m ±  4%    110.4m ±  8%        ~ (p=0.132 n=6) BM_BatchedDot/16/8/64/process_time                                                        52.45µ ±  0%    52.64µ ±  0%   +0.37% (p=0.002 n=6) BM_DynamicUpdateSliceF32/1024/process_time                                                25.79µ ±  3%    26.61µ ±  3%        ~ (p=0.093 n=6) BM_DynamicUpdateSliceF32/128/process_time                                                 3.024µ ±  2%    3.085µ ±  1%   +2.02% (p=0.004 n=6) BM_DynamicUpdateSliceF32/16384/process_time                                               788.0µ ±  6%    754.3µ ±  5%   4.28% (p=0.009 n=6) BM_DynamicUpdateSliceF32/256/process_time                                                 5.649µ ±  2%    5.743µ ±  1%   +1.67% (p=0.041 n=6) BM_DynamicUpdateSliceF32/512/process_time                                                 13.40µ ±  4%    13.63µ ±  3%   +1.68% (p=0.041 n=6) BM_DynamicUpdateSliceF32/8192/process_time                                                447.0µ ±  8%    422.9µ ±  4%   5.39% (p=0.041 n=6) BM_AddBF16/1024/process_time                                                              199.3µ ±  3%    166.9µ ±  0%  16.24% (p=0.002 n=6) BM_AddBF16/128/process_time                                                               10.16µ ±  0%    10.15µ ±  0%        ~ (p=0.132 n=6) BM_AddBF16/16384/process_time                                                             2.255m ± 12%    2.279m ± 18%        ~ (p=0.937 n=6) BM_AddBF16/256/process_time                                                               38.19µ ±  4%    31.23µ ±  1%  18.23% (p=0.002 n=6) BM_AddBF16/32768/process_time                                                             6.166m ±  5%    6.915m ± 11%  +12.15% (p=0.009 n=6) BM_AddBF16/512/process_time                                                              105.86µ ±  1%    85.75µ ±  1%  19.00% (p=0.002 n=6) BM_AddBF16/8192/process_time                                                              1.096m ±  7%    1.034m ±  9%        ~ (p=0.310 n=6) BM_AddF32/1024/process_time                                                               322.9µ ±  4%    303.1µ ±  5%   6.13% (p=0.004 n=6) BM_AddF32/128/process_time                                                                21.62µ ±  1%    19.13µ ±  2%  11.51% (p=0.002 n=6) BM_AddF32/16384/process_time                                                              7.754m ± 33%    5.547m ± 35%        ~ (p=0.093 n=6) BM_AddF32/256/process_time                                                                67.31µ ±  1%    58.99µ ±  2%  12.36% (p=0.002 n=6) BM_AddF32/32768/process_time                                                              15.90m ±  9%    15.18m ±  9%        ~ (p=0.180 n=6) BM_AddF32/512/process_time                                                                144.5µ ±  1%    131.3µ ±  1%   9.17% (p=0.002 n=6) BM_AddF32/8192/process_time                                                               1.859m ± 17%    1.755m ± 13%        ~ (p=0.180 n=6) BM_ConvertF32ToBF16/1024/process_time                                                     179.5µ ±  2%    174.6µ ±  1%   2.77% (p=0.002 n=6) BM_ConvertF32ToBF16/128/process_time                                                      5.814µ ±  1%    5.926µ ±  1%   +1.93% (p=0.004 n=6) BM_ConvertF32ToBF16/16384/process_time                                                    1.998m ±  8%    1.992m ± 13%        ~ (p=0.589 n=6) BM_ConvertF32ToBF16/256/process_time                                                      29.26µ ±  1%    28.69µ ±  2%   1.92% (p=0.004 n=6) BM_ConvertF32ToBF16/32768/process_time                                                    6.877m ± 46%    6.017m ± 12%  12.50% (p=0.004 n=6) BM_ConvertF32ToBF16/512/process_time                                                      91.14µ ±  4%    83.40µ ±  1%   8.49% (p=0.002 n=6) BM_ConvertF32ToBF16/8192/process_time                                                     1.091m ± 10%    1.066m ± 13%        ~ (p=0.818 n=6) BM_BcastFusionF32/1024/process_time                                                       294.0µ ±  2%    262.2µ ±  2%  10.80% (p=0.002 n=6) BM_BcastFusionF32/128/process_time                                                        22.16µ ±  4%    16.54µ ±  1%  25.36% (p=0.002 n=6) BM_BcastFusionF32/16384/process_time                                                      3.567m ±  7%    3.486m ± 11%        ~ (p=1.000 n=6) BM_BcastFusionF32/256/process_time                                                        57.94µ ±  3%    47.47µ ±  3%  18.08% (p=0.002 n=6) BM_BcastFusionF32/512/process_time                                                        125.8µ ±  4%    104.9µ ±  4%  16.58% (p=0.002 n=6) BM_BcastFusionF32/8192/process_time                                                       1.779m ±  9%    1.685m ± 13%        ~ (p=0.132 n=6) BM_ChainOfAddF32/1024/process_time                                                        74.55µ ±  3%    71.41µ ±  1%   4.21% (p=0.002 n=6) BM_ChainOfAddF32/128/process_time                                                         12.63µ ±  1%    12.46µ ±  1%   1.36% (p=0.002 n=6) BM_ChainOfAddF32/256/process_time                                                         20.47µ ±  2%    20.09µ ±  2%        ~ (p=0.093 n=6) BM_ChainOfAddF32/512/process_time                                                         37.49µ ±  3%    36.21µ ±  1%   3.42% (p=0.002 n=6) BM_ChainOfAddF32/64/process_time                                                          8.909µ ±  3%    8.844µ ±  2%        ~ (p=0.132 n=6) BM_DynamicUpdateSliceFusionF32/1024/process_time                                          26.50µ ±  3%    25.52µ ±  4%   3.69% (p=0.009 n=6) BM_DynamicUpdateSliceFusionF32/128/process_time                                           2.936µ ±  1%    2.895µ ±  0%   1.40% (p=0.002 n=6) BM_DynamicUpdateSliceFusionF32/16384/process_time                                         786.4µ ±  5%    785.2µ ±  4%        ~ (p=0.937 n=6) BM_DynamicUpdateSliceFusionF32/256/process_time                                           5.539µ ±  2%    5.466µ ±  1%   1.30% (p=0.002 n=6) BM_DynamicUpdateSliceFusionF32/512/process_time                                           13.49µ ±  1%    13.84µ ±  2%   +2.58% (p=0.026 n=6) BM_DynamicUpdateSliceFusionF32/8192/process_time                                          428.0µ ±  4%    409.5µ ±  6%        ~ (p=0.132 n=6) BM_FusionF32/1024/process_time                                                            339.0µ ±  3%    306.2µ ±  1%   9.67% (p=0.002 n=6) BM_FusionF32/128/process_time                                                             26.59µ ± 14%    19.27µ ±  3%  27.55% (p=0.002 n=6) BM_FusionF32/16384/process_time                                                           6.154m ± 20%    6.126m ± 11%        ~ (p=1.000 n=6) BM_FusionF32/256/process_time                                                             73.46µ ±  2%    59.92µ ±  2%  18.43% (p=0.002 n=6) BM_FusionF32/512/process_time                                                             162.4µ ±  1%    132.1µ ±  1%  18.61% (p=0.002 n=6) BM_FusionF32/8192/process_time                                                            2.007m ±  8%    2.039m ± 12%        ~ (p=0.937 n=6) BM_FusionF32_2/160/process_time                                                           1.257µ ±  1%    1.231µ ±  1%   2.05% (p=0.002 n=6) BM_FusionF32_2/240/process_time                                                           1.533µ ±  1%    1.507µ ±  1%   1.66% (p=0.002 n=6) BM_FusionF32_2/40/process_time                                                            848.2n ±  1%    830.0n ±  1%   2.15% (p=0.002 n=6) BM_FusionF32_2/80/process_time                                                            993.7n ±  2%    955.7n ±  3%   3.82% (p=0.004 n=6) BM_GatherS32/10/128/1/process_time                                                        466.3n ± 12%    463.8n ±  1%        ~ (p=0.310 n=6) BM_GatherS32/10/128/2/process_time                                                        473.0n ±  1%    470.3n ±  1%   0.57% (p=0.015 n=6) BM_GatherS32/10/128/32/process_time                                                       648.0n ±  2%    636.9n ±  1%   1.72% (p=0.026 n=6) BM_GatherS32/10/256/1/process_time                                                        473.8n ±  1%    472.5n ±  7%        ~ (p=0.699 n=6) BM_GatherS32/10/256/2/process_time                                                        484.8n ±  1%    480.4n ±  1%   0.91% (p=0.015 n=6) BM_GatherS32/10/256/64/process_time                                                       1.209µ ±  2%    1.215µ ±  3%        ~ (p=0.310 n=6) BM_GatherS32/10/3/1/process_time                                                          457.0n ±  3%    457.0n ±  1%        ~ (p=0.937 n=6) BM_GatherS32/10/3/2/process_time                                                          464.9n ±  3%    459.4n ±  1%        ~ (p=0.132 n=6) BM_GatherS32/10/3/4/process_time                                                          466.6n ±  3%    463.6n ±  1%        ~ (p=0.180 n=6) BM_GatherS32/10/32/1/process_time                                                         460.8n ±  1%    460.7n ±  1%        ~ (p=1.000 n=6) BM_GatherS32/10/32/2/process_time                                                         465.6n ±  2%    460.9n ±  5%        ~ (p=0.180 n=6) BM_GatherS32/10/32/8/process_time                                                         473.4n ±  1%    466.9n ±  0%   1.37% (p=0.002 n=6) BM_GatherS32/10/512/1/process_time                                                        485.7n ±  2%    485.8n ±  9%        ~ (p=0.699 n=6) BM_GatherS32/10/512/128/process_time                                                      3.955µ ±  2%    3.934µ ±  0%        ~ (p=0.240 n=6) BM_GatherS32/10/512/2/process_time                                                        511.5n ±  2%    507.1n ±  1%   0.86% (p=0.002 n=6) BM_GatherS32/10/64/1/process_time                                                         462.4n ±  4%    457.5n ±  3%        ~ (p=0.093 n=6) BM_GatherS32/10/64/16/process_time                                                        501.8n ±  1%    498.0n ±  1%        ~ (p=0.093 n=6) BM_GatherS32/10/64/2/process_time                                                         465.3n ±  2%    463.0n ±  2%        ~ (p=0.240 n=6) BM_GatherS32/100/128/1/process_time                                                       466.7n ±  3%    460.8n ±  1%   1.26% (p=0.026 n=6) BM_GatherS32/100/128/2/process_time                                                       477.7n ±  1%    469.9n ±  2%   1.63% (p=0.015 n=6) BM_GatherS32/100/128/32/process_time                                                      770.8n ±  1%    773.6n ±  1%        ~ (p=0.394 n=6) BM_GatherS32/100/256/1/process_time                                                       475.0n ±  8%    470.7n ±  1%        ~ (p=0.065 n=6) BM_GatherS32/100/256/2/process_time                                                       484.8n ±  2%    478.0n ±  1%   1.39% (p=0.002 n=6) BM_GatherS32/100/256/64/process_time                                                      1.600µ ±  3%    1.596µ ±  0%        ~ (p=0.240 n=6) BM_GatherS32/100/3/1/process_time                                                         460.4n ±  2%    455.0n ±  1%   1.17% (p=0.002 n=6) BM_GatherS32/100/3/2/process_time                                                         463.6n ±  2%    460.4n ±  1%        ~ (p=0.180 n=6) BM_GatherS32/100/3/4/process_time                                                         467.2n ±  1%    463.2n ±  1%   0.86% (p=0.009 n=6) BM_GatherS32/100/32/1/process_time                                                        462.3n ±  1%    460.7n ±  2%        ~ (p=0.310 n=6) BM_GatherS32/100/32/2/process_time                                                        465.3n ±  1%    461.9n ±  1%        ~ (p=0.240 n=6) BM_GatherS32/100/32/8/process_time                                                        476.2n ±  1%    469.4n ±  1%   1.43% (p=0.009 n=6) BM_GatherS32/100/512/1/process_time                                                       488.4n ±  1%    484.6n ±  1%   0.77% (p=0.041 n=6) BM_GatherS32/100/512/128/process_time                                                     5.184µ ±  3%    5.174µ ±  1%        ~ (p=0.589 n=6) BM_GatherS32/100/512/2/process_time                                                       510.9n ±  1%    506.5n ±  1%        ~ (p=0.065 n=6) BM_GatherS32/100/64/1/process_time                                                        462.8n ±  3%    458.6n ±  1%   0.90% (p=0.002 n=6) BM_GatherS32/100/64/16/process_time                                                       507.3n ±  1%    499.3n ±  1%   1.58% (p=0.002 n=6) BM_GatherS32/100/64/2/process_time                                                        466.0n ±  1%    462.6n ±  0%   0.73% (p=0.002 n=6) BM_GatherS32/3/128/1/process_time                                                         465.4n ±  1%    462.0n ±  3%        ~ (p=0.180 n=6) BM_GatherS32/3/128/2/process_time                                                         473.2n ±  2%    469.4n ±  3%        ~ (p=0.132 n=6) BM_GatherS32/3/128/32/process_time                                                        629.8n ±  2%    633.4n ±  5%        ~ (p=0.937 n=6) BM_GatherS32/3/256/1/process_time                                                         472.3n ±  0%    470.1n ±  1%        ~ (p=0.818 n=6) BM_GatherS32/3/256/2/process_time                                                         486.1n ±  1%    479.1n ±  8%        ~ (p=0.180 n=6) BM_GatherS32/3/256/64/process_time                                                        1.100µ ±  1%    1.104µ ±  5%        ~ (p=1.000 n=6) BM_GatherS32/3/3/1/process_time                                                           460.6n ±  1%    460.3n ±  2%        ~ (p=0.818 n=6) BM_GatherS32/3/3/2/process_time                                                           465.4n ±  1%    462.2n ±  7%        ~ (p=0.589 n=6) BM_GatherS32/3/3/4/process_time                                                           466.4n ±  1%    465.6n ±  2%        ~ (p=0.699 n=6) BM_GatherS32/3/32/1/process_time                                                          461.6n ±  2%    460.4n ±  1%        ~ (p=0.240 n=6) BM_GatherS32/3/32/2/process_time                                                          464.6n ±  1%    461.4n ±  5%        ~ (p=0.394 n=6) BM_GatherS32/3/32/8/process_time                                                          475.2n ±  6%    468.5n ±  1%   1.41% (p=0.009 n=6) BM_GatherS32/3/512/1/process_time                                                         484.4n ±  3%    484.6n ±  1%        ~ (p=0.937 n=6) BM_GatherS32/3/512/128/process_time                                                       3.068µ ±  2%    3.070µ ±  1%        ~ (p=0.937 n=6) BM_GatherS32/3/512/2/process_time                                                         512.9n ±  3%    508.1n ±  2%        ~ (p=0.310 n=6) BM_GatherS32/3/64/1/process_time                                                          461.5n ±  2%    457.4n ±  1%   0.88% (p=0.004 n=6) BM_GatherS32/3/64/16/process_time                                                         496.8n ±  1%    498.9n ±  1%        ~ (p=0.589 n=6) BM_GatherS32/3/64/2/process_time                                                          465.5n ±  1%    462.4n ±  1%        ~ (p=0.065 n=6) BM_Optimizer0/1024/process_time                                                           5.001m ±  1%    4.892m ± 11%        ~ (p=0.394 n=6) BM_Optimizer0/128/process_time                                                            460.4µ ± 12%    380.2µ ±  2%  17.41% (p=0.002 n=6) BM_Optimizer0/16384/process_time                                                          62.65m ±  6%    62.65m ± 12%        ~ (p=0.937 n=6) BM_Optimizer0/256/process_time                                                            1.215m ± 10%    1.066m ±  3%  12.21% (p=0.004 n=6) BM_Optimizer0/512/process_time                                                            2.436m ± 18%    2.236m ±  3%   8.21% (p=0.002 n=6) BM_Optimizer0/8192/process_time                                                           35.19m ±  5%    32.69m ±  6%        ~ (p=0.065 n=6) BM_PadF32/1024/process_time                                                               29.85m ±  8%    28.86m ± 10%        ~ (p=0.310 n=6) BM_PadF32/128/process_time                                                                340.1µ ±  1%    318.1µ ±  0%   6.48% (p=0.002 n=6) BM_PadF32/256/process_time                                                                1.178m ±  5%    1.141m ±  4%        ~ (p=0.065 n=6) BM_PadF32/4096/process_time                                                               423.3m ±  0%    423.2m ±  3%        ~ (p=0.937 n=6) BM_PadF32/512/process_time                                                                4.229m ± 10%    4.489m ±  8%        ~ (p=0.240 n=6) BM_ReduceAddBF16/1024/process_time                                                        3.387m ±  3%    3.409m ±  6%        ~ (p=0.310 n=6) BM_ReduceAddBF16/128/process_time                                                         239.0µ ±  0%    239.5µ ±  0%   +0.22% (p=0.002 n=6) BM_ReduceAddBF16/16384/process_time                                                       51.13m ±  1%    53.88m ±  6%        ~ (p=0.132 n=6) BM_ReduceAddBF16/256/process_time                                                         719.8µ ±  8%   1121.9µ ± 13%  +55.87% (p=0.002 n=6) BM_ReduceAddBF16/512/process_time                                                         1.674m ±  2%    2.152m ±  7%  +28.60% (p=0.002 n=6) BM_ReduceAddBF16/8192/process_time                                                        25.97m ±  1%    27.34m ±  8%        ~ (p=0.065 n=6) BM_ReduceAddF32/1024/process_time                                                         487.0µ ±  2%    469.0µ ±  5%   3.70% (p=0.041 n=6) BM_ReduceAddF32/128/process_time                                                          23.40µ ±  0%    23.42µ ±  0%        ~ (p=0.310 n=6) BM_ReduceAddF32/16384/process_time                                                        6.683m ±  0%    6.657m ±  0%   0.39% (p=0.002 n=6) BM_ReduceAddF32/256/process_time                                                          62.92µ ±  4%    60.37µ ±  1%   4.05% (p=0.002 n=6) BM_ReduceAddF32/512/process_time                                                          246.6µ ±  0%    238.0µ ±  0%   3.48% (p=0.002 n=6) BM_ReduceAddF32/8192/process_time                                                         3.471m ±  0%    3.459m ±  1%        ~ (p=0.132 n=6) BM_ScatterS32_R1/262144/262144/process_time                                               600.1µ ±  1%    206.5µ ±  2%  65.59% (p=0.002 n=6) BM_ScatterS32_R2/512/512/process_time                                                     77.45µ ±  1%    49.88µ ±  3%  35.59% (p=0.002 n=6) BM_ScatterS32_R3/64/64/process_time                                                       54.28µ ±  0%    50.49µ ±  3%   6.99% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:1/d1:64/d2:8/num_slices:1/process_time                    755.0n ±  1%    702.3n ±  4%   6.98% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:50/d1:64/d2:8/num_slices:10/process_time                 106.82µ ±  0%    17.66µ ±  3%  83.47% (p=0.002 n=6) BM_SimpleScatterReduceF32_R3/d0:500/d1:64/d2:8/num_slices:100/process_time               10.301m ±  2%    2.635m ±  2%  74.42% (p=0.002 n=6) BM_SelectAndScatterF32/128/process_time                                                   37.00µ ±  1%    27.76µ ±  3%  24.97% (p=0.002 n=6) BM_SelectAndScatterF32/256/process_time                                                  117.86µ ±  2%    86.36µ ±  1%  26.73% (p=0.002 n=6) BM_SelectAndScatterF32/512/process_time                                                   1.613m ±  2%    1.528m ± 61%        ~ (p=0.065 n=6) BM_TanhF16/1024/process_time                                                              687.7n ±  1%    686.2n ±  2%        ~ (p=0.589 n=6) BM_TanhF16/128/process_time                                                               439.0n ±  2%    443.6n ±  1%        ~ (p=0.180 n=6) BM_TanhF16/256/process_time                                                               481.3n ±  1%    482.0n ±  1%        ~ (p=0.240 n=6) BM_TanhF16/4096/process_time                                                              1.522µ ±  0%    1.522µ ±  1%        ~ (p=0.818 n=6) BM_TanhF16/512/process_time                                                               553.5n ±  0%    556.9n ±  2%        ~ (p=0.394 n=6) BM_TanhF32/1024/process_time                                                              751.8n ±  1%    693.2n ±  1%   7.79% (p=0.002 n=6) BM_TanhF32/128/process_time                                                               507.8n ±  0%    451.7n ±  3%  11.05% (p=0.002 n=6) BM_TanhF32/256/process_time                                                               552.0n ±  1%    494.1n ±  1%  10.49% (p=0.002 n=6) BM_TanhF32/4096/process_time                                                              1.608µ ±  2%    1.580µ ±  1%   1.75% (p=0.026 n=6) BM_TanhF32/512/process_time                                                               623.4n ±  1%    559.9n ±  1%  10.18% (p=0.002 n=6) BM_TanhF64/1024/process_time                                                              12.59µ ±  0%    12.60µ ±  0%        ~ (p=0.699 n=6) BM_TanhF64/128/process_time                                                               1.945µ ±  0%    1.947µ ±  0%        ~ (p=0.937 n=6) BM_TanhF64/256/process_time                                                               3.464µ ±  0%    3.471µ ±  1%        ~ (p=0.310 n=6) BM_TanhF64/4096/process_time                                                              49.05µ ±  0%    49.05µ ±  0%        ~ (p=0.937 n=6) BM_TanhF64/512/process_time                                                               6.506µ ±  0%    6.522µ ±  1%        ~ (p=0.132 n=6) geomean                                                                                   91.38µ          88.09µ         3.59% ``` ",2025-03-13T02:19:19Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89124
rag,copybara-service[bot],[xla:cpu] flip xla_cpu_use_fusion_emitters to true,"[xla:cpu] flip xla_cpu_use_fusion_emitters to true Note, however, that no fusion emitter is enabled yet. Flipping this flag does change the HLO pipeline, and is therefore worth submitting as its own CL to get test coverage and measure performance differences. The largest perf difference can be seen in Gather:  Microbenchmarks thunks vs. fusion emitters ```                                                                                     │ thunks           │           fusion_emitters            │                                                                                     │    cpusec/op    │  cpusec/op    vs base               │ BM_ConcatenateTwoR3F32/parallel:0/batch:128/width:64/height:256/axis:0/process_time       602.3µ ±  0%    603.0µ ±  1%        ~ (p=0.485 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:128/width:64/height:256/axis:1/process_time       624.8µ ±  2%    806.0µ ±  1%  +29.00% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:128/width:64/height:256/axis:2/process_time       998.4µ ±  0%   1127.5µ ±  1%  +12.93% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:256/width:128/height:64/axis:0/process_time       605.0µ ±  4%    609.5µ ±  2%        ~ (p=0.132 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:256/width:128/height:64/axis:1/process_time       620.0µ ±  2%    854.8µ ± 28%        ~ (p=0.132 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:256/width:128/height:64/axis:2/process_time       1.284m ±  3%    1.936m ±  7%  +50.79% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:64/width:256/height:128/axis:0/process_time       602.2µ ±  3%    602.8µ ±  1%        ~ (p=0.699 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:64/width:256/height:128/axis:1/process_time       615.2µ ±  0%    828.1µ ±  8%  +34.61% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:0/batch:64/width:256/height:128/axis:2/process_time       1.031m ±  1%    1.175m ±  6%  +13.99% (p=0.002 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:128/width:64/height:256/axis:0/process_time       1.753m ± 13%    1.650m ±  8%        ~ (p=0.180 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:128/width:64/height:256/axis:1/process_time       1.711m ±  6%    1.804m ± 11%        ~ (p=0.310 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:128/width:64/height:256/axis:2/process_time       2.602m ±  8%    2.434m ±  7%   6.47% (p=0.041 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:256/width:128/height:64/axis:0/process_time       1.684m ± 12%    1.730m ± 14%        ~ (p=0.485 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:256/width:128/height:64/axis:1/process_time       1.798m ± 10%    1.668m ±  5%   7.25% (p=0.026 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:256/width:128/height:64/axis:2/process_time       2.287m ± 12%    2.251m ±  7%        ~ (p=0.180 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:64/width:256/height:128/axis:0/process_time       1.703m ±  7%    1.666m ±  6%        ~ (p=0.485 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:64/width:256/height:128/axis:1/process_time       1.727m ±  5%    1.717m ±  6%        ~ (p=0.589 n=6) BM_ConcatenateTwoR3F32/parallel:1/batch:64/width:256/height:128/axis:2/process_time       2.232m ± 11%    2.235m ± 16%        ~ (p=0.818 n=6) BM_Conv1DStrided/1/129/process_time                                                       54.79m ±  8%    54.83m ±  6%        ~ (p=0.699 n=6) BM_Conv1DStrided/3/129/process_time                                                       171.4m ±  9%    170.4m ±  6%        ~ (p=1.000 n=6) BM_Conv1DTransposedStrided/129/1/process_time                                             47.47m ±  3%    53.37m ±  7%  +12.43% (p=0.002 n=6) BM_Conv1DTransposedStrided/129/3/process_time                                             155.8m ±  5%    155.1m ±  9%        ~ (p=0.937 n=6) BM_Conv1DTransposedStridedNonDefaultLayout/129/1/process_time                             37.36m ±  9%    34.52m ±  2%        ~ (p=0.180 n=6) BM_Conv1DTransposedStridedNonDefaultLayout/129/3/process_time                             122.1m ±  5%    128.4m ±  7%        ~ (p=0.132 n=6) BM_Conv2D/16/32/32/128/1/1/1024/process_time                                         123.6m ± 21%    121.2m ± 14%        ~ (p=0.180 n=6) BM_Conv2D/16/32/32/128/3/3/1024/process_time                                         888.2m ± 10%   1032.4m ± 27%        ~ (p=0.093 n=6) BM_Conv2D/32/256/256/4/1/1/16/process_time                                           202.9m ±  8%    190.3m ±  8%   6.24% (p=0.026 n=6) BM_Conv2D/32/256/256/4/3/3/16/process_time                                           427.8m ± 15%    376.0m ±  5%  12.10% (p=0.041 n=6) BM_Conv2D/32/32/32/128/1/1/1024/process_time                                         249.9m ±  4%    249.0m ±  3%        ~ (p=0.937 n=6) BM_Conv2D/32/32/32/128/3/3/1024/process_time                                          1.948 ±  8%     1.890 ±  6%        ~ (p=0.310 n=6) BM_Conv2D/32/32/32/96/1/1/96/process_time                                            21.98m ±  8%    22.39m ±  3%        ~ (p=0.818 n=6) BM_Conv2D/32/32/32/96/3/3/96/process_time                                            141.6m ±  4%    144.9m ±  3%        ~ (p=0.310 n=6) BM_Conv2D/32/64/64/32/1/1/64/process_time                                            29.17m ±  3%    27.90m ±  4%   4.35% (p=0.015 n=6) BM_Conv2D/32/64/64/32/3/3/64/process_time                                            161.0m ±  4%    159.4m ±  3%        ~ (p=0.310 n=6) BM_Conv2D/32/64/64/4/1/1/16/process_time                                             1.202m ±  5%    1.207m ± 14%        ~ (p=0.699 n=6) BM_Conv2D/32/64/64/4/3/3/16/process_time                                             26.16m ±  4%    26.60m ±  3%        ~ (p=0.240 n=6) BM_Conv2D/8/128/128/4/1/1/8/process_time                                             457.0µ ±  4%    453.2µ ±  4%        ~ (p=0.589 n=6) BM_Conv2D/8/128/128/4/3/3/8/process_time                                             14.59m ±  4%    14.81m ±  4%        ~ (p=0.485 n=6) BM_Conv2D/8/32/32/128/1/1/1024/process_time                                          62.50m ± 10%    57.55m ±  8%        ~ (p=0.065 n=6) BM_Conv2D/8/32/32/128/3/3/1024/process_time                                          449.5m ±  6%    451.0m ±  6%        ~ (p=0.937 n=6) BM_Conv2D/8/5/5/1/1/1/32/process_time                                                3.269µ ±  4%    3.262µ ±  1%        ~ (p=0.589 n=6) BM_Conv2D/8/5/5/1/3/3/32/process_time                                                13.38µ ±  9%    13.31µ ±  0%   0.52% (p=0.009 n=6) BM_Conv2D/8/5/5/4/1/1/32/process_time                                                1.821µ ±  1%    1.842µ ±  0%   +1.10% (p=0.041 n=6) BM_Conv2D/8/5/5/4/3/3/32/process_time                                                17.93µ ±  4%    18.00µ ±  2%        ~ (p=0.310 n=6) BM_Conv2DStrided/process_time                                                             57.50m ±  5%    59.22m ±  6%        ~ (p=0.394 n=6) BM_Conv2DTransposedStrided/process_time                                                   47.48m ±  2%    48.09m ±  4%        ~ (p=0.310 n=6) BM_GroupedConv2D/1/45/45/1024/5/5/1024/1024/process_time                                  439.2m ±  5%    425.9m ±  3%        ~ (p=0.093 n=6) BM_GroupedConv2DStrided/128/128/128/process_time                                          65.37m ±  8%    60.74m ±  6%        ~ (p=0.132 n=6) BM_GroupedConv2DStrided/128/128/16/process_time                                           57.54m ±  7%    60.12m ± 11%        ~ (p=0.485 n=6) BM_GroupedConv2DTransposedStrided/128/128/128/process_time                                 4.373 ±  4%     4.342 ±  5%        ~ (p=0.937 n=6) BM_GroupedConv2DTransposedStrided/128/128/16/process_time                                  4.997 ±  5%     4.696 ±  7%   6.02% (p=0.026 n=6) BM_CustomCall_16FloatBuffers/process_time                                                 2.039µ ±  4%    1.916µ ±  4%   5.99% (p=0.004 n=6) BM_CustomCall_16IntAttributes/process_time                                                677.2n ±  2%    642.6n ±  1%   5.10% (p=0.002 n=6) BM_CustomCall_Minimal/process_time                                                        590.2n ±  1%    557.3n ±  1%   5.57% (p=0.002 n=6) BM_DagExecution/1024/process_time                                                         7.481m ±  1%    7.649m ±  9%   +2.24% (p=0.009 n=6) BM_DagExecution/128/process_time                                                          682.5µ ±  5%    689.5µ ±  2%        ~ (p=0.065 n=6) BM_DagExecution/16384/process_time                                                        171.4m ±  9%    197.4m ± 13%  +15.17% (p=0.015 n=6) BM_DagExecution/256/process_time                                                          1.926m ±  4%    1.939m ±  1%        ~ (p=0.699 n=6) BM_DagExecution/512/process_time                                                          3.449m ±  1%    3.467m ±  2%        ~ (p=0.240 n=6) BM_DagExecution/8192/process_time                                                         59.51m ± 15%    62.34m ± 15%        ~ (p=0.310 n=6) BM_BatchedDot/11/1/128/process_time                                                       37.62µ ±  0%    37.50µ ±  0%   0.33% (p=0.002 n=6) BM_BatchedDot/11/1/2/process_time                                                         488.7n ± 11%    458.3n ±  3%   6.21% (p=0.002 n=6) BM_BatchedDot/11/1/256/process_time                                                       766.9µ ±  3%    769.9µ ±  3%        ~ (p=0.818 n=6) BM_BatchedDot/11/1/32/process_time                                                        1.770µ ±  2%    1.716µ ±  0%   3.05% (p=0.002 n=6) BM_BatchedDot/11/1/512/process_time                                                       9.177m ±  1%    9.440m ±  2%   +2.86% (p=0.004 n=6) BM_BatchedDot/11/1/64/process_time                                                        6.431µ ±  2%    6.376µ ±  0%   0.85% (p=0.002 n=6) BM_BatchedDot/11/2/128/process_time                                                       74.44µ ±  0%    74.38µ ±  0%        ~ (p=0.310 n=6) BM_BatchedDot/11/2/2/process_time                                                         495.0n ±  1%    462.9n ±  4%   6.49% (p=0.002 n=6) BM_BatchedDot/11/2/256/process_time                                                       1.623m ± 26%    1.575m ±  3%        ~ (p=1.000 n=6) BM_BatchedDot/11/2/32/process_time                                                        2.804µ ±  0%    2.750µ ±  0%   1.92% (p=0.002 n=6) BM_BatchedDot/11/2/512/process_time                                                       26.11m ±  3%    22.17m ±  2%  15.08% (p=0.002 n=6) BM_BatchedDot/11/2/64/process_time                                                        12.10µ ±  1%    12.00µ ±  1%   0.81% (p=0.015 n=6) BM_BatchedDot/11/4/128/process_time                                                       148.8µ ±  0%    148.6µ ±  0%   0.13% (p=0.002 n=6) BM_BatchedDot/11/4/2/process_time                                                         500.0n ±  1%    465.5n ±  2%   6.91% (p=0.002 n=6) BM_BatchedDot/11/4/256/process_time                                                       3.716m ±  2%    3.192m ±  4%  14.11% (p=0.002 n=6) BM_BatchedDot/11/4/32/process_time                                                        4.818µ ±  1%    4.788µ ±  4%        ~ (p=0.394 n=6) BM_BatchedDot/11/4/512/process_time                                                       47.46m ±  3%    46.98m ±  1%        ~ (p=0.065 n=6) BM_BatchedDot/11/4/64/process_time                                                        23.36µ ±  0%    23.26µ ±  0%   0.45% (p=0.002 n=6) BM_BatchedDot/11/8/128/process_time                                                       298.0µ ±  0%    297.8µ ±  0%   0.05% (p=0.041 n=6) BM_BatchedDot/11/8/2/process_time                                                         514.2n ±  2%    475.1n ±  1%   7.60% (p=0.002 n=6) BM_BatchedDot/11/8/256/process_time                                                       7.223m ±  7%    6.327m ±  4%  12.40% (p=0.002 n=6) BM_BatchedDot/11/8/32/process_time                                                        8.787µ ±  0%    8.739µ ±  0%   0.55% (p=0.002 n=6) BM_BatchedDot/11/8/512/process_time                                                      101.90m ±  5%    98.02m ±  3%        ~ (p=0.180 n=6) BM_BatchedDot/11/8/64/process_time                                                        46.00µ ±  0%    45.93µ ±  0%        ~ (p=0.065 n=6) BM_BatchedDot/16/1/128/process_time                                                       40.95µ ±  0%    40.84µ ±  0%   0.27% (p=0.002 n=6) BM_BatchedDot/16/1/2/process_time                                                         557.7n ±  5%    523.7n ±  6%   6.10% (p=0.004 n=6) BM_BatchedDot/16/1/256/process_time                                                       1.113m ±  4%    1.078m ±  3%        ~ (p=0.093 n=6) BM_BatchedDot/16/1/32/process_time                                                        2.059µ ±  1%    2.001µ ±  1%   2.85% (p=0.002 n=6) BM_BatchedDot/16/1/512/process_time                                                       11.57m ±  2%    11.10m ±  1%   4.02% (p=0.002 n=6) BM_BatchedDot/16/1/64/process_time                                                        7.363µ ±  1%    7.293µ ±  1%   0.95% (p=0.002 n=6) BM_BatchedDot/16/2/128/process_time                                                       81.31µ ±  0%    81.00µ ±  0%   0.38% (p=0.002 n=6) BM_BatchedDot/16/2/2/process_time                                                         594.0n ±  4%    530.4n ±  2%  10.71% (p=0.002 n=6) BM_BatchedDot/16/2/256/process_time                                                       2.270m ±  1%    2.212m ±  4%        ~ (p=0.180 n=6) BM_BatchedDot/16/2/32/process_time                                                        3.348µ ±  1%    3.297µ ±  1%   1.54% (p=0.002 n=6) BM_BatchedDot/16/2/512/process_time                                                       25.68m ±  2%    25.40m ±  2%        ~ (p=0.485 n=6) BM_BatchedDot/16/2/64/process_time                                                        13.89µ ±  1%    13.73µ ±  0%   1.19% (p=0.002 n=6) BM_BatchedDot/16/4/128/process_time                                                       163.8µ ±  0%    163.6µ ±  0%        ~ (p=0.093 n=6) BM_BatchedDot/16/4/2/process_time                                                         607.9n ±  1%    542.8n ±  1%  10.71% (p=0.002 n=6) BM_BatchedDot/16/4/256/process_time                                                       4.782m ±  1%    4.668m ±  2%   2.39% (p=0.009 n=6) BM_BatchedDot/16/4/32/process_time                                                        5.754µ ±  1%    5.675µ ±  2%   1.38% (p=0.041 n=6) BM_BatchedDot/16/4/512/process_time                                                       56.58m ±  3%    55.00m ±  1%   2.78% (p=0.015 n=6) BM_BatchedDot/16/4/64/process_time                                                        26.67µ ±  0%    26.59µ ±  0%        ~ (p=0.093 n=6) BM_BatchedDot/16/8/128/process_time                                                       749.6µ ± 16%    753.7µ ±  4%        ~ (p=0.180 n=6) BM_BatchedDot/16/8/2/process_time                                                         632.7n ±  4%    636.7n ±  1%        ~ (p=0.699 n=6) BM_BatchedDot/16/8/256/process_time                                                       9.479m ±  2%    9.313m ±  2%   1.75% (p=0.009 n=6) BM_BatchedDot/16/8/32/process_time                                                        10.52µ ±  0%    10.53µ ±  0%        ~ (p=0.699 n=6) BM_BatchedDot/16/8/512/process_time                                                       114.5m ±  7%    113.0m ±  4%        ~ (p=0.240 n=6) BM_BatchedDot/16/8/64/process_time                                                        52.56µ ±  0%    52.50µ ±  0%   0.13% (p=0.015 n=6) BM_DynamicUpdateSliceF32/1024/process_time                                                25.78µ ±  1%    25.95µ ±  3%        ~ (p=0.065 n=6) BM_DynamicUpdateSliceF32/128/process_time                                                 3.151µ ±  3%    3.026µ ±  0%   3.97% (p=0.002 n=6) BM_DynamicUpdateSliceF32/16384/process_time                                               798.0µ ±  7%    764.4µ ±  4%   4.22% (p=0.015 n=6) BM_DynamicUpdateSliceF32/256/process_time                                                 5.810µ ±  1%    5.680µ ±  3%        ~ (p=0.065 n=6) BM_DynamicUpdateSliceF32/512/process_time                                                 13.70µ ±  3%    13.65µ ±  3%        ~ (p=0.240 n=6) BM_DynamicUpdateSliceF32/8192/process_time                                                435.5µ ±  2%    427.8µ ±  5%        ~ (p=0.180 n=6) BM_AddBF16/1024/process_time                                                              198.4µ ±  1%    183.6µ ±  2%   7.45% (p=0.002 n=6) BM_AddBF16/128/process_time                                                               10.23µ ±  0%    10.17µ ±  0%   0.56% (p=0.002 n=6) BM_AddBF16/16384/process_time                                                             2.231m ±  4%    2.164m ± 27%        ~ (p=1.000 n=6) BM_AddBF16/256/process_time                                                               37.87µ ±  3%    33.62µ ±  1%  11.23% (p=0.002 n=6) BM_AddBF16/32768/process_time                                                             6.420m ± 15%    5.611m ± 16%  12.61% (p=0.015 n=6) BM_AddBF16/512/process_time                                                              110.95µ ±  1%    95.40µ ±  1%  14.02% (p=0.002 n=6) BM_AddBF16/8192/process_time                                                              1.050m ±  6%    1.022m ±  7%        ~ (p=0.589 n=6) BM_AddF32/1024/process_time                                                               343.5µ ±  5%    320.5µ ±  4%   6.70% (p=0.002 n=6) BM_AddF32/128/process_time                                                                21.95µ ±  1%    21.79µ ±  2%        ~ (p=0.240 n=6) BM_AddF32/16384/process_time                                                              6.284m ± 15%    5.409m ± 11%  13.91% (p=0.002 n=6) BM_AddF32/256/process_time                                                                67.42µ ±  1%    67.63µ ±  1%        ~ (p=0.485 n=6) BM_AddF32/32768/process_time                                                              15.24m ±  6%    14.96m ±  5%        ~ (p=0.394 n=6) BM_AddF32/512/process_time                                                                164.0µ ± 14%    146.4µ ±  1%        ~ (p=0.394 n=6) BM_AddF32/8192/process_time                                                               1.967m ± 19%    1.792m ± 24%   8.90% (p=0.041 n=6) BM_ConvertF32ToBF16/1024/process_time                                                     154.1µ ±  5%    185.0µ ±  1%  +20.04% (p=0.002 n=6) BM_ConvertF32ToBF16/128/process_time                                                      5.918µ ±  1%    5.861µ ±  1%        ~ (p=0.093 n=6) BM_ConvertF32ToBF16/16384/process_time                                                    1.901m ± 10%    1.973m ±  7%        ~ (p=0.589 n=6) BM_ConvertF32ToBF16/256/process_time                                                      25.28µ ±  1%    30.70µ ±  1%  +21.43% (p=0.002 n=6) BM_ConvertF32ToBF16/32768/process_time                                                    5.758m ± 45%    6.767m ± 18%        ~ (p=0.310 n=6) BM_ConvertF32ToBF16/512/process_time                                                      73.36µ ±  1%    91.98µ ±  1%  +25.38% (p=0.002 n=6) BM_ConvertF32ToBF16/8192/process_time                                                     977.4µ ± 10%   1046.1µ ±  9%        ~ (p=0.394 n=6) BM_BcastFusionF32/1024/process_time                                                       279.5µ ±  3%    274.0µ ±  2%   1.96% (p=0.015 n=6) BM_BcastFusionF32/128/process_time                                                        20.29µ ±  2%    19.91µ ±  2%   1.90% (p=0.015 n=6) BM_BcastFusionF32/16384/process_time                                                      3.623m ±  7%    3.459m ±  8%        ~ (p=0.093 n=6) BM_BcastFusionF32/256/process_time                                                        52.64µ ±  3%    52.06µ ±  9%        ~ (p=0.394 n=6) BM_BcastFusionF32/512/process_time                                                        113.9µ ±  1%    117.3µ ±  1%   +2.92% (p=0.002 n=6) BM_BcastFusionF32/8192/process_time                                                       1.739m ±  9%    1.657m ±  6%        ~ (p=0.240 n=6) BM_ChainOfAddF32/1024/process_time                                                        72.65µ ±  1%    71.52µ ±  2%   1.56% (p=0.041 n=6) BM_ChainOfAddF32/128/process_time                                                         12.72µ ±  8%    12.43µ ±  1%        ~ (p=0.394 n=6) BM_ChainOfAddF32/256/process_time                                                         20.55µ ±  1%    20.06µ ±  0%   2.39% (p=0.002 n=6) BM_ChainOfAddF32/512/process_time                                                         37.05µ ±  2%    36.13µ ±  2%   2.50% (p=0.004 n=6) BM_ChainOfAddF32/64/process_time                                                          8.835µ ±  1%    8.864µ ±  1%        ~ (p=0.394 n=6) BM_DynamicUpdateSliceFusionF32/1024/process_time                                          26.06µ ±  2%    25.82µ ±  2%        ~ (p=0.310 n=6) BM_DynamicUpdateSliceFusionF32/128/process_time                                           2.891µ ±  0%    2.952µ ±  2%   +2.12% (p=0.002 n=6) BM_DynamicUpdateSliceFusionF32/16384/process_time                                         780.4µ ±  4%    774.4µ ±  7%        ~ (p=0.394 n=6) BM_DynamicUpdateSliceFusionF32/256/process_time                                           5.538µ ±  1%    5.766µ ±  3%   +4.11% (p=0.002 n=6) BM_DynamicUpdateSliceFusionF32/512/process_time                                           13.23µ ±  2%    13.42µ ±  2%   +1.45% (p=0.041 n=6) BM_DynamicUpdateSliceFusionF32/8192/process_time                                          431.9µ ±  4%    431.0µ ±  5%        ~ (p=0.818 n=6) BM_FusionF32/1024/process_time                                                            322.1µ ±  1%    319.2µ ±  1%        ~ (p=0.310 n=6) BM_FusionF32/128/process_time                                                             22.09µ ±  2%    21.97µ ±  1%        ~ (p=0.240 n=6) BM_FusionF32/16384/process_time                                                           5.473m ± 13%    6.237m ± 10%  +13.95% (p=0.015 n=6) BM_FusionF32/256/process_time                                                             67.53µ ±  2%    68.25µ ±  8%   +1.07% (p=0.009 n=6) BM_FusionF32/512/process_time                                                             146.9µ ±  7%    147.0µ ±  7%        ~ (p=0.818 n=6) BM_FusionF32/8192/process_time                                                            1.855m ± 10%    1.989m ± 16%   +7.25% (p=0.041 n=6) BM_FusionF32_2/160/process_time                                                           1.227µ ±  4%    1.283µ ±  1%   +4.55% (p=0.002 n=6) BM_FusionF32_2/240/process_time                                                           1.501µ ±  3%    1.560µ ±  1%   +3.90% (p=0.002 n=6) BM_FusionF32_2/40/process_time                                                            827.2n ±  2%    873.4n ±  1%   +5.60% (p=0.002 n=6) BM_FusionF32_2/80/process_time                                                            963.5n ±  2%   1009.0n ±  1%   +4.73% (p=0.002 n=6) BM_GatherS32/10/128/1/process_time                                                        564.5n ± 19%    541.5n ±  2%        ~ (p=0.394 n=6) BM_GatherS32/10/128/2/process_time                                                        466.5n ±  3%    549.0n ±  2%  +17.69% (p=0.002 n=6) BM_GatherS32/10/128/32/process_time                                                       639.6n ±  5%    718.4n ±  2%  +12.31% (p=0.002 n=6) BM_GatherS32/10/256/1/process_time                                                        469.1n ±  5%    552.1n ±  0%  +17.70% (p=0.002 n=6) BM_GatherS32/10/256/2/process_time                                                        477.7n ±  1%    562.1n ±  1%  +17.66% (p=0.002 n=6) BM_GatherS32/10/256/64/process_time                                                       1.219µ ±  1%    1.286µ ±  1%   +5.50% (p=0.002 n=6) BM_GatherS32/10/3/1/process_time                                                          558.5n ±  0%    454.7n ±  3%  18.58% (p=0.002 n=6) BM_GatherS32/10/3/2/process_time                                                          565.3n ±  1%    454.6n ±  1%  19.59% (p=0.002 n=6) BM_GatherS32/10/3/4/process_time                                                          566.3n ±  0%    462.2n ±  1%  18.38% (p=0.002 n=6) BM_GatherS32/10/32/1/process_time                                                         561.1n ±  1%    458.6n ±  1%  18.26% (p=0.002 n=6) BM_GatherS32/10/32/2/process_time                                                         561.6n ±  5%    457.5n ± 21%  18.53% (p=0.002 n=6) BM_GatherS32/10/32/8/process_time                                                         573.4n ±  9%    560.8n ±  2%   2.19% (p=0.004 n=6) BM_GatherS32/10/512/1/process_time                                                        489.2n ±  3%    576.0n ±  2%  +17.74% (p=0.002 n=6) BM_GatherS32/10/512/128/process_time                                                     18.982µ ±  2%    4.127µ ±  3%  78.26% (p=0.002 n=6) BM_GatherS32/10/512/2/process_time                                                        506.1n ±  2%    587.1n ±  2%  +15.99% (p=0.002 n=6) BM_GatherS32/10/64/1/process_time                                                         563.9n ±  4%    534.6n ±  1%   5.20% (p=0.002 n=6) BM_GatherS32/10/64/16/process_time                                                        603.1n ±  2%    582.6n ±  1%   3.41% (p=0.002 n=6) BM_GatherS32/10/64/2/process_time                                                         567.9n ±  1%    548.6n ±  1%   3.40% (p=0.002 n=6) BM_GatherS32/100/128/1/process_time                                                       460.2n ±  0%    550.9n ±  1%  +19.71% (p=0.002 n=6) BM_GatherS32/100/128/2/process_time                                                       469.1n ±  3%    562.0n ±  1%  +19.80% (p=0.002 n=6) BM_GatherS32/100/128/32/process_time                                                      768.6n ±  1%    849.3n ±  1%  +10.51% (p=0.002 n=6) BM_GatherS32/100/256/1/process_time                                                       468.1n ±  1%    561.8n ±  1%  +20.02% (p=0.002 n=6) BM_GatherS32/100/256/2/process_time                                                       479.0n ±  1%    567.1n ±  2%  +18.38% (p=0.002 n=6) BM_GatherS32/100/256/64/process_time                                                      1.604µ ±  0%    1.674µ ±  0%   +4.33% (p=0.002 n=6) BM_GatherS32/100/3/1/process_time                                                         452.1n ±  2%    533.6n ±  1%  +18.02% (p=0.002 n=6) BM_GatherS32/100/3/2/process_time                                                         455.0n ±  1%    556.9n ±  3%  +22.40% (p=0.002 n=6) BM_GatherS32/100/3/4/process_time                                                         463.5n ±  4%    537.0n ±  1%  +15.85% (p=0.002 n=6) BM_GatherS32/100/32/1/process_time                                                        460.3n ±  1%    535.5n ±  3%  +16.35% (p=0.002 n=6) BM_GatherS32/100/32/2/process_time                                                        461.6n ±  1%    549.1n ±  1%  +18.96% (p=0.002 n=6) BM_GatherS32/100/32/8/process_time                                                        467.6n ±  0%    566.6n ±  1%  +21.15% (p=0.002 n=6) BM_GatherS32/100/512/1/process_time                                                       479.8n ±  4%    567.8n ±  2%  +18.35% (p=0.002 n=6) BM_GatherS32/100/512/128/process_time                                                    20.158µ ±  3%    5.464µ ±  3%  72.89% (p=0.002 n=6) BM_GatherS32/100/512/2/process_time                                                       507.9n ±  3%    585.8n ±  1%  +15.34% (p=0.002 n=6) BM_GatherS32/100/64/1/process_time                                                        458.4n ±  4%    544.9n ±  3%  +18.87% (p=0.002 n=6) BM_GatherS32/100/64/16/process_time                                                       496.1n ±  2%    594.7n ±  3%  +19.88% (p=0.002 n=6) BM_GatherS32/100/64/2/process_time                                                        461.6n ±  1%    554.9n ±  1%  +20.21% (p=0.002 n=6) BM_GatherS32/3/128/1/process_time                                                         567.6n ±  1%    463.7n ±  5%  18.32% (p=0.002 n=6) BM_GatherS32/3/128/2/process_time                                                         569.7n ±  2%    470.7n ±  1%  17.38% (p=0.002 n=6) BM_GatherS32/3/128/32/process_time                                                        722.9n ±  0%    625.5n ±  2%  13.47% (p=0.002 n=6) BM_GatherS32/3/256/1/process_time                                                         573.1n ±  2%    473.1n ±  2%  17.44% (p=0.002 n=6) BM_GatherS32/3/256/2/process_time                                                         582.2n ±  1%    480.9n ±  2%  17.41% (p=0.002 n=6) BM_GatherS32/3/256/64/process_time                                                        1.202µ ±  1%    1.107µ ±  1%   7.91% (p=0.002 n=6) BM_GatherS32/3/3/1/process_time                                                           566.0n ±  1%    460.1n ± 16%  18.70% (p=0.002 n=6) BM_GatherS32/3/3/2/process_time                                                           564.1n ±  0%    456.7n ±  3%  19.05% (p=0.002 n=6) BM_GatherS32/3/3/4/process_time                                                           567.6n ±  3%    461.9n ±  0%  18.63% (p=0.002 n=6) BM_GatherS32/3/32/1/process_time                                                          563.9n ±  1%    459.4n ±  1%  18.53% (p=0.002 n=6) BM_GatherS32/3/32/2/process_time                                                          562.9n ±  0%    459.0n ±  5%  18.46% (p=0.002 n=6) BM_GatherS32/3/32/8/process_time                                                          572.5n ±  1%    469.5n ±  1%  18.01% (p=0.002 n=6) BM_GatherS32/3/512/1/process_time                                                         585.8n ±  1%    482.0n ±  1%  17.73% (p=0.002 n=6) BM_GatherS32/3/512/128/process_time                                                      18.549µ ±  3%    3.101µ ±  1%  83.28% (p=0.002 n=6) BM_GatherS32/3/512/2/process_time                                                         612.2n ±  7%    505.5n ±  1%  17.42% (p=0.002 n=6) BM_GatherS32/3/64/1/process_time                                                          562.2n ±  3%    457.4n ±  1%  18.63% (p=0.002 n=6) BM_GatherS32/3/64/16/process_time                                                         604.1n ±  4%    494.6n ±  0%  18.13% (p=0.002 n=6) BM_GatherS32/3/64/2/process_time                                                          567.1n ±  1%    463.8n ±  1%  18.22% (p=0.002 n=6) BM_Optimizer0/1024/process_time                                                           5.125m ± 43%    5.046m ±  1%        ~ (p=0.132 n=6) BM_Optimizer0/128/process_time                                                            468.4µ ±  7%    449.4µ ± 12%   4.07% (p=0.026 n=6) BM_Optimizer0/16384/process_time                                                          65.03m ±  5%    62.68m ±  7%        ~ (p=0.485 n=6) BM_Optimizer0/256/process_time                                                            1.219m ±  5%    1.208m ±  7%        ~ (p=0.485 n=6) BM_Optimizer0/512/process_time                                                            3.541m ± 32%    2.392m ±  3%  32.45% (p=0.015 n=6) BM_Optimizer0/8192/process_time                                                           33.71m ±  2%    32.97m ±  5%        ~ (p=0.132 n=6) BM_PadF32/1024/process_time                                                               28.24m ±  9%    28.63m ±  6%        ~ (p=0.485 n=6) BM_PadF32/128/process_time                                                                339.8µ ±  1%    341.0µ ±  0%        ~ (p=0.310 n=6) BM_PadF32/256/process_time                                                                1.192m ±  4%    1.195m ±  3%        ~ (p=0.589 n=6) BM_PadF32/4096/process_time                                                               422.4m ±  1%    423.9m ±  0%        ~ (p=0.310 n=6) BM_PadF32/512/process_time                                                                4.339m ±  6%    4.170m ±  7%        ~ (p=0.065 n=6) BM_ReduceAddBF16/1024/process_time                                                        3.435m ±  2%    3.401m ±  9%        ~ (p=0.180 n=6) BM_ReduceAddBF16/128/process_time                                                         239.5µ ±  0%    239.0µ ±  0%   0.20% (p=0.002 n=6) BM_ReduceAddBF16/16384/process_time                                                       51.15m ±  4%    50.94m ±  2%        ~ (p=0.818 n=6) BM_ReduceAddBF16/256/process_time                                                         914.1µ ± 11%    777.5µ ±  8%  14.94% (p=0.004 n=6) BM_ReduceAddBF16/512/process_time                                                         1.704m ±  6%    1.680m ±  1%        ~ (p=0.093 n=6) BM_ReduceAddBF16/8192/process_time                                                        26.21m ±  3%    25.97m ±  7%        ~ (p=0.699 n=6) BM_ReduceAddF32/1024/process_time                                                         488.1µ ±  1%    487.1µ ±  0%        ~ (p=0.093 n=6) BM_ReduceAddF32/128/process_time                                                          23.36µ ±  0%    23.42µ ±  0%   +0.26% (p=0.026 n=6) BM_ReduceAddF32/16384/process_time                                                        6.756m ±  1%    6.672m ±  0%   1.23% (p=0.002 n=6) BM_ReduceAddF32/256/process_time                                                          62.44µ ±  1%    62.76µ ±  5%        ~ (p=0.132 n=6) BM_ReduceAddF32/512/process_time                                                          246.5µ ±  3%    246.9µ ±  0%        ~ (p=0.310 n=6) BM_ReduceAddF32/8192/process_time                                                         3.479m ±  0%    3.462m ±  0%   0.47% (p=0.004 n=6) BM_ScatterS32_R1/262144/262144/process_time                                               592.3µ ±  1%    590.2µ ±  1%        ~ (p=0.240 n=6) BM_ScatterS32_R2/512/512/process_time                                                     77.23µ ±  2%    77.87µ ±  2%        ~ (p=0.394 n=6) BM_ScatterS32_R3/64/64/process_time                                                       54.41µ ±  0%    54.79µ ±  2%        ~ (p=0.180 n=6) BM_SimpleScatterReduceF32_R3/d0:1/d1:64/d2:8/num_slices:1/process_time                    727.3n ±  1%    720.6n ±  2%   0.92% (p=0.026 n=6) BM_SimpleScatterReduceF32_R3/d0:50/d1:64/d2:8/num_slices:10/process_time                  108.0µ ±  1%    107.3µ ±  3%        ~ (p=0.394 n=6) BM_SimpleScatterReduceF32_R3/d0:500/d1:64/d2:8/num_slices:100/process_time                10.38m ±  1%    10.33m ±  1%        ~ (p=0.132 n=6) BM_SelectAndScatterF32/128/process_time                                                   35.65µ ±  1%    35.72µ ±  4%        ~ (p=0.699 n=6) BM_SelectAndScatterF32/256/process_time                                                   118.7µ ±  1%    117.9µ ±  3%        ~ (p=0.310 n=6) BM_SelectAndScatterF32/512/process_time                                                   1.657m ±  5%    1.640m ±  6%        ~ (p=0.240 n=6) BM_TanhF16/1024/process_time                                                              684.4n ±  1%    716.9n ±  3%   +4.75% (p=0.002 n=6) BM_TanhF16/128/process_time                                                               435.9n ±  2%    466.8n ±  7%   +7.07% (p=0.002 n=6) BM_TanhF16/256/process_time                                                               474.4n ±  2%    504.8n ±  1%   +6.41% (p=0.002 n=6) BM_TanhF16/4096/process_time                                                              1.521µ ±  0%    1.545µ ±  1%   +1.56% (p=0.002 n=6) BM_TanhF16/512/process_time                                                               547.4n ±  1%    578.6n ±  1%   +5.70% (p=0.002 n=6) BM_TanhF32/1024/process_time                                                              688.6n ±  0%    716.3n ±  1%   +4.02% (p=0.002 n=6) BM_TanhF32/128/process_time                                                               446.9n ±  3%    466.9n ±  2%   +4.48% (p=0.002 n=6) BM_TanhF32/256/process_time                                                               476.8n ±  1%    507.2n ±  1%   +6.36% (p=0.002 n=6) BM_TanhF32/4096/process_time                                                              1.580µ ±  0%    1.616µ ±  1%   +2.31% (p=0.002 n=6) BM_TanhF32/512/process_time                                                               556.7n ±  1%    584.9n ±  1%   +5.06% (p=0.002 n=6) BM_TanhF64/1024/process_time                                                              12.60µ ±  2%    12.61µ ±  0%        ~ (p=0.310 n=6) BM_TanhF64/128/process_time                                                               1.944µ ±  0%    1.973µ ±  0%   +1.49% (p=0.002 n=6) BM_TanhF64/256/process_time                                                               3.463µ ±  1%    3.493µ ±  1%   +0.86% (p=0.002 n=6) BM_TanhF64/4096/process_time                                                              49.11µ ±  0%    49.10µ ±  0%        ~ (p=0.394 n=6) BM_TanhF64/512/process_time                                                               6.510µ ±  0%    6.527µ ±  0%   +0.25% (p=0.002 n=6) geomean                                                                                   94.44µ          92.38µ         2.19% ``` ",2025-03-13T02:17:20Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89123
rag,copybara-service[bot],Extending op coverage for TFL,Extending op coverage for TFL,2025-03-12T23:34:49Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89113
rag,copybara-service[bot],Fix grammar mistake and rewrite paragraph,Fix grammar mistake and rewrite paragraph,2025-03-12T23:07:29Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89112
yi,GaganaMD,ImportError: DLL load failed while importing _pywrap_tensorflow_internal on Windows (TensorFlow CPU)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.9  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am facing an issue while trying to import TensorFlow on a CPU machine. The error traceback suggests that a DLL load failed while importing _pywrap_tensorflow_internal, which prevents TensorFlow from initializing properly. Traceback (most recent call last):   File ""C:\Users\gagan\Desktop\EGU_replication\venv\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: Traceback (most recent call last):   File ""C:\Users\gagan\Desktop\EGU_replication\IEEE_TNNLS_EGUNet\EGUNetpw.py"", line 5, in      import tensorflow as tf   File ""C:\Users\gagan\Desktop\EGU_replication\venv\lib\sitepackages\tensorflow\__init__.py"", line 40, in      from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport   File ""C:\Users\gagan\Desktop\EGU_replication\venv\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 88, in      raise ImportError( ImportError: Traceback (most recent call last):   File ""C:\Users\gagan\Desktop\EGU_replication\venv\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 73, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for common causes and solutions.  Standalone code to reproduce the issue ```shell Please test this on your local windows machine https://colab.research.google.com/drive/1PPNyc5LP5ngeVadUCx6vBxmRQN5MhiVq?usp=sharing ```  Relevant log output ```shell ```",2025-03-12T10:23:53Z,type:bug,closed,0,4,https://github.com/tensorflow/tensorflow/issues/89072,TensorFlow version: 2.18.0,Please search for duplicates before opening a new issue,Are you satisfied with the resolution of your issue? Yes No,Update the MSVC like this download link ：https://download.visualstudio.microsoft.com/download/pr/285b28c73cf947fb9be801cf5323a8df/8F9FB1B3CFE6E5092CF1225ECD6659DAB7CE50B8BF935CB79BFEDE1F3C895240/VC_redist.x64.exe
rag,copybara-service[bot],[XLA:GPU] Enable RaggedAllToAll one-shot kernel by default.,[XLA:GPU] Enable RaggedAllToAll oneshot kernel by default. Oneshot kernel is the most performant and stable implementation of RaggedAllToAll that we have right now. NCCL version is currently unstable and sometimes causes deadlocks. Enabling the flag will make singlehost usage of RaggedAllToAll stable by default. Multihost case is currently not well supported.,2025-03-12T09:59:36Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89069
rag,copybara-service[bot],PR #23613: [ROCm] Pass correct warp size to Triton pipeline,PR CC(ERROR: Config value opt is not defined in any .rc file): [ROCm] Pass correct warp size to Triton pipeline Imported from GitHub PR https://github.com/openxla/xla/pull/23613 Copybara import of the project:  dc43a7518d690038398ae3cf301de477d1ca715f by Dragan Mladjenovic : [ROCm] Pass correct warp size to Triton pipeline Merging this change closes CC(ERROR: Config value opt is not defined in any .rc file) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23613 from ROCm:triton_wrap_size dc43a7518d690038398ae3cf301de477d1ca715f,2025-03-12T09:48:48Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/89067
yi,copybara-service[bot],Internal change only,Internal change only,2025-03-12T01:45:22Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89052
yi,copybara-service[bot],Allow appending a custom error message when using error checking macros & other improvements.,"Allow appending a custom error message when using error checking macros & other improvements.  Rename and move `ErrorStatusReturnHelper` to `litert::ErrorStatusBuilder`.  Add extra logging capabilities to `litert::ErrorStatusBuilder`.   It is now possible to stream data to the builder. This creates an extra   message that is appended to the original error message.   ```cpp   LITERT_RETURN_IF_ERROR(expr) << ""Failed while trying to ..."";   ```  Refactor `LITERT_RETURN_IF_ERROR` so that the default `ErrorStatusBuilder`   can be used (see example above).  Refactor `LITERT_ASSIGN_OR_RETURN` so that the return expression can   reference a variable called `_` that holds an `ErrorStatusBuilder` built with   the result of the expression.   ```cpp   LITERT_ASSIGN_OR_RETURN(auto var, expr, _ << ""Failed while trying to ..."");   ```  In functions returning a `LiteRtStatus`, this logs the message automatically   upon conversion.   This makes it possible to easily log messages.   ```cpp   LiteRtStatus LiteRtCFunction(LiteRtEnvironment environment, ...) {     LITERT_RETURN_IF_ERROR(environment, litert::Error(kLiteRtStatusErrorInvalidArgument,                                         ""`environment` handle must not be null.""));   }   ```  The log severity upon conversion can be adjusted with the `Log*()` functions   and silenced with `NoLog()`.",2025-03-11T15:45:00Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89023
yi,18marie05,gemma2-2b SavedModel to tflite conversion,"Hello,  I am trying to convert a Gemma Saved Model in tflite format to run on an edge device.  1. System information I am running my code on a Jupyter Notebook. My tensorflow version is 2.18.0  2. Code  Code Here is the code I used once I have my Saved Model :  Since it is too large to compress and I can't share my Saved Model folder, here is how I got it:  I downloaded the Keras model from Kaggle  Here is the code I used to get de Saved Model Colab link ``` converter = tf.lite.TFLiteConverter.from_saved_model(""gemma22b_model"") converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]  Convert the model tflite_model = converter.convert()  Save the converted model with open('gemma22b_model/gemma2_2b.tflite', 'wb') as f:     f.write(tflite_model) ``` I tried different solutions:   with the converter.target_spec.supported_ops  without the converter.target_spec.supported_ops   only with TFLITE_BUILTINS and only with SELECT_TF_OPS  with an optimization like this converter.optimizations = [tf.lite.Optimize.DEFAULT] And I also tried this code with the method I saw on another resolved issue: ``` converter = tf.lite.TFLiteConverter.from_saved_model(""gemma22b_model"") converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.supported_types = [tf.float16] converter.target_spec.supported_ops = [     tf.lite.OpsSet.TFLITE_BUILTINS,     tf.lite.OpsSet.SELECT_TF_OPS] converter.experimental_new_converter = True converter.allow_custom_ops = True tflite_model = converter.convert()  Save the model. with open('gemma22b_model/test_ops_gemma2_2b.tflite', 'wb') as f:   f.write(tflite_model) ```  3. Failure after conversion After running it, the code produces a .tflite file but the StridedSlice is not supported, making the tflite model impossible to use. Here are the logs:  ``` W0000 00:00:1741686810.500306   38515 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format. W0000 00:00:1741686810.500796   38515 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency. 20250311 10:53:30.505166: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: gemma22b_model 20250311 10:53:30.526521: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve } 20250311 10:53:30.526654: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: gemma22b_model 20250311 10:53:30.741628: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle. 20250311 10:53:36.765240: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: gemma22b_model 20250311 10:53:37.149345: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 6644559 microseconds. 20250311 10:53:39.223577: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3825] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s): Flex ops: FlexStridedSlice Details: 	tf.StridedSlice(tensor, tensor, tensor, tensor) > (tensor) : {begin_mask = 7 : i64, ellipsis_mask = 0 : i64, end_mask = 7 : i64, new_axis_mask = 8 : i64, shrink_axis_mask = 0 : i64} 	tf.StridedSlice(tensor, tensor, tensor, tensor) > (tensor) : {begin_mask = 25 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 25 : i64, new_axis_mask = 6 : i64, shrink_axis_mask = 0 : i64} 	tf.StridedSlice(tensor, tensor, tensor, tensor) > (tensor) : {begin_mask = 25 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 25 : i64, new_axis_mask = 6 : i64, shrink_axis_mask = 0 : i64} See instructions: https://www.tensorflow.org/lite/guide/ops_select ```  I still tried to run the ```tf.lite.Interpreter``` with this code: ``` import numpy as np import tensorflow as tf  Load the TFLite model interpreter = tf.lite.Interpreter(model_path=""gemma22btflite/test_ops_gemma2_2b.tflite"") interpreter.allocate_tensors()  Get input and output details input_details = interpreter.get_input_details() output_details = interpreter.get_output_details()  Print the input and output details print(""Input Details:"", input_details) print(""Output Details:"", output_details)  Prepare input data (match the shape and dtype) input_data = np.array([[1]], dtype=np.int32)   Scalar value as input, matching the shape [1, 1] and dtype int32  Set the input tensor interpreter.set_tensor(input_details[0]['index'], input_data)  Run inference interpreter.invoke()  Get the output tensor output_data = interpreter.get_tensor(output_details[0]['index'])  Print the output print(""Output data:"", output_data ``` and this is what I got :  ``` INFO: Created TensorFlow Lite delegate for select TF ops. INFO: TfLiteFlexDelegate delegate: 52 nodes delegated out of 5669 nodes with 26 partitions. INFO: Created TensorFlow Lite XNNPACK delegate for CPU.  RuntimeError                              Traceback (most recent call last) Cell In[11], line 23      20 interpreter.set_tensor(input_details[0]['index'], input_data)      22  Run inference > 23 interpreter.invoke()      25  Get the output tensor      26 output_data = interpreter.get_tensor(output_details[0]['index']) File ~/Documents/.venv/lib/python3.11/sitepackages/tensorflow/lite/python/interpreter.py:965, in Interpreter.invoke(self)     953 """"""Invoke the interpreter.     954      955 Be sure to set the input sizes, allocate tensors and fill values before    (...)     962   ValueError: When the underlying interpreter fails raise ValueError.     963 """"""     964 self._ensure_safe() > 965 self._interpreter.Invoke() RuntimeError: tensorflow/lite/kernels/read_variable.cc:67 variable != nullptr was not true.Node number 297 (READ_VARIABLE) failed to invoke. ``` I tried to resolve my issue by consulting a few issues like this one  CC(error while converting to tflite) but none of the codes seem to work for my use case. I would be so grateful for your help. Thank you!",2025-03-11T13:38:13Z,comp:lite TFLiteConverter TF 2.18,open,0,1,https://github.com/tensorflow/tensorflow/issues/89018,"Hi, Is there a solution to fix this conversion issue  ? Thank you for your answer"
yi,copybara-service[bot],Remove TF_CUDNN_USE_FRONTEND env var.,"Remove TF_CUDNN_USE_FRONTEND env var. This environment variable has defaulted to true for over three years, and no known users set it to false. There is a lot of code maintaining the nonfrontend legacy cuDNN API which we'd like to delete. Removing the env var is the first step. I don't remove any code relying on the env var yet, in order to make this CL easier to rollback if necessary.",2025-03-11T02:42:19Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/89000
yi,copybara-service[bot],Remove flag --xla_gpu_enable_cudnn_frontend.,"Remove flag xla_gpu_enable_cudnn_frontend. This flag has defaulted to true for over three years, and no known users set it to false. There is a lot of code maintaining the nonfrontend legacy cuDNN API which we'd like to delete. Removing the flag is the first step. I don't remove any code relying on the flag yet, in order to make this CL easier to rollback if necessary.",2025-03-11T00:46:00Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88996
yi,copybara-service[bot],Delete unused IFRT proxy backend factory in `ifrt_proxy_internal.py`,Delete unused IFRT proxy backend factory in `ifrt_proxy_internal.py`,2025-03-10T22:17:51Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88984
rag,copybara-service[bot],Define CAPI and Python API for chlo.ragged_dot.,Define CAPI and Python API for chlo.ragged_dot.,2025-03-10T21:00:44Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88976
rag,nassimus26,could not find registered transfer manager for platform Host -- check target linkage 	 [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_33145]," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.8  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi since I added some conv2D to my model I am getting this error on the Colab TPU  :  ``` NotFoundError: Graph execution error: Detected at node StatefulPartitionedCall defined at (most recent call last):   File """", line 198, in _run_module_as_main   File """", line 88, in _run_code   File ""/usr/local/lib/python3.11/distpackages/colab_kernel_launcher.py"", line 37, in    File ""/usr/local/lib/python3.11/distpackages/traitlets/config/application.py"", line 992, in launch_instance   File ""/usr/local/lib/python3.11/distpackages/ipykernel/kernelapp.py"", line 712, in start   File ""/usr/local/lib/python3.11/distpackages/tornado/platform/asyncio.py"", line 205, in start   File ""/usr/lib/python3.11/asyncio/base_events.py"", line 608, in run_forever   File ""/usr/lib/python3.11/asyncio/base_events.py"", line 1936, in _run_once   File ""/usr/lib/python3.11/asyncio/events.py"", line 84, in _run   File ""/usr/local/lib/python3.11/distpackages/ipykernel/kernelbase.py"", line 510, in dispatch_queue   File ""/usr/local/lib/python3.11/distpackages/ipykernel/kernelbase.py"", line 499, in process_one   File ""/usr/local/lib/python3.11/distpackages/ipykernel/kernelbase.py"", line 406, in dispatch_shell   File ""/usr/local/lib/python3.11/distpackages/ipykernel/kernelbase.py"", line 730, in execute_request   File ""/usr/local/lib/python3.11/distpackages/ipykernel/ipkernel.py"", line 383, in do_execute   File ""/usr/local/lib/python3.11/distpackages/ipykernel/zmqshell.py"", line 528, in run_cell   File ""/usr/local/lib/python3.11/distpackages/IPython/core/interactiveshell.py"", line 2975, in run_cell   File ""/usr/local/lib/python3.11/distpackages/IPython/core/interactiveshell.py"", line 3030, in _run_cell   File ""/usr/local/lib/python3.11/distpackages/IPython/core/async_helpers.py"", line 78, in _pseudo_sync_runner   File ""/usr/local/lib/python3.11/distpackages/IPython/core/interactiveshell.py"", line 3257, in run_cell_async   File ""/usr/local/lib/python3.11/distpackages/IPython/core/interactiveshell.py"", line 3473, in run_ast_nodes   File ""/usr/local/lib/python3.11/distpackages/IPython/core/interactiveshell.py"", line 3553, in run_code   File """", line 48, in    File """", line 47, in train   File """", line 82, in prep   File """", line 78, in train_step   File ""/usr/local/lib/python3.11/distpackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler   File ""/usr/local/lib/python3.11/distpackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit   File ""/usr/local/lib/python3.11/distpackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function   File ""/usr/local/lib/python3.11/distpackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator could not find registered transfer manager for platform Host  check target linkage 	 [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_33145] ```  Standalone code to reproduce the issue Here's the Conv2D which I added before getting this Error :  ``` cnn = layers.Conv2D(300, (3, 3), strides=(3, 3), activation=""relu"")(input) cnn = layers.MaxPooling2D((2, 2))(cnn) cnn = layers.Conv2D(120, (3, 3), strides=(3, 3), activation=""relu"")(cnn) cnn = layers.AveragePooling2D((2, 2))(cnn) cnn = layers.Conv2D(64, (2, 2), strides=(2, 2), activation=""sigmoid"")(cnn) ```",2025-03-10T16:27:36Z,stat:awaiting response type:bug stale comp:dist-strat TF 2.8,closed,0,4,https://github.com/tensorflow/tensorflow/issues/88960,"Hi **** , Apologies for the delay, and thank you for raising your concern here. Could you please share the complete code snippet? This would help us investigate the issue more effectively. Additionally, I noticed that you are using an older version of TensorFlow (2.8). I recommend upgrading to the latest version and checking if the issue persists. If the problem still occurs, please let us know, and we will be happy to assist further. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],PR #23542: [ROCm] Support clang19 as host compiler,PR CC(No C++ symbols exported after built libtensorflow_cc with bazel on windows): [ROCm] Support clang19 as host compiler Imported from GitHub PR https://github.com/openxla/xla/pull/23542 Pass nocanonicalprefixes to clang19 to get old InstalledDir behavior. Copybara import of the project:  03a6958a7ef6fde43ec6c20c8eb984b4afa181ff by Dragan Mladjenovic : [ROCm] Support clang19 as host compiler Merging this change closes CC(No C++ symbols exported after built libtensorflow_cc with bazel on windows) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23542 from ROCm:ci_clang19 03a6958a7ef6fde43ec6c20c8eb984b4afa181ff,2025-03-10T14:05:24Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88952
rag,copybara-service[bot],PR #23552: [ROCm] Add rocm deps for ragged_all_to_all_kernel,"PR CC(if i set the inputshape with (None, None, featdim),how can I split the input by second dimention(axis=1)?): [ROCm] Add rocm deps for ragged_all_to_all_kernel Imported from GitHub PR https://github.com/openxla/xla/pull/23552 Kernel added in https://github.com/openxla/xla/commit/be68e80894862fe97757ea2b6110958ef4244c21. For ROCm build is currently failing with: ``` [20250309T01:01:48.040Z] ERROR: /tf/xla/xla/service/gpu/kernels/BUILD:291:13: Compiling xla/service/gpu/kernels/ragged_all_to_all_kernel.cu.: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing CppCompile command (from target //xla/service/gpu/kernels:ragged_all_to_all_kernel_gpu) external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc U_FORTIFY_SOURCE fstackprotector Wall Wunusedbutsetparameter Wnofreenonheapobject fnoomitframepointer ... (remaining 148 arguments skipped) [20250309T01:01:48.040Z] /root/.cache/bazel/_bazel_root/217377b0e928b171b843eb11ea7bc36e/execroot/xla/external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc:23: DeprecationWarning: 'pipes' is deprecated and slated for removal in Python 3.13 [20250309T01:01:48.040Z]   import pipes [20250309T01:01:48.040Z] xla/service/gpu/kernels/ragged_all_to_all_kernel.cu.cc:52:1: error: ‘__global__’ does not name a type [20250309T01:01:48.040Z]    52     ``` This PR just adds necessary deps for rocm  Copybara import of the project:  80f96ff15de134bf14ff00a4483f7b6707744445 by Milica Makevic : Add rocm deps for ragged_all_to_all_kernel Merging this change closes CC(if i set the inputshape with (None, None, featdim),how can I split the input by second dimention(axis=1)?) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23552 from ROCm:hotfix_250310 80f96ff15de134bf14ff00a4483f7b6707744445",2025-03-10T14:00:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88949
gpt,copybara-service[bot],PR #23468: Ensure PTX version compatibility w/ Clang & ptxas,"PR CC(Add option for inferring op attributes from inputs): Ensure PTX version compatibility w/ Clang & ptxas Imported from GitHub PR https://github.com/openxla/xla/pull/23468 Using the flag `cudafeature=+ptx`, Clang can be instructed to emit a specific PTX version from the NVPTX backend. If this flag is omitted, then Clang might emit a newer version of PTX than what ptxas from Hermetic CUDA can recognize which can lead to compilation errors. This commit adds a mapping from Clang & CUDA version to PTX version in `third_party/gpus/cuda/hermetic/cuda_redist_versions.bzl` which will need to be updated over time. If either the version for Clang or CUDA cannot be mapped to a PTX version, then configuration will fail. Resolves openxla/xla CC(Dataset shard index automatic change in Estimator DistributionStrategy) Copybara import of the project:  49c5940498f608b82539243b286431a74cdfc0dd by Jack Wolfard : Ensure PTX version compatibility w/ Clang & ptxas Using the flag `cudafeature=+ptx`, Clang can be instructed to emit a specific PTX version from the NVPTX backend. If this flag is omitted, then Clang might emit a newer version of PTX than what ptxas from Hermetic CUDA can recognize which can lead to compilation errors. This commit adds a mapping from Clang & CUDA version to PTX version in `third_party/gpus/cuda/hermetic/cuda_redist_versions.bzl` which will need to be updated over time. If either the version for Clang or CUDA cannot be mapped to a PTX version, then configuration will fail. Resolves openxla/xla CC(Dataset shard index automatic change in Estimator DistributionStrategy) Merging this change closes CC(Add option for inferring op attributes from inputs) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23468 from JackWolfard:clangptxasversion 49c5940498f608b82539243b286431a74cdfc0dd",2025-03-10T07:38:33Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88939
yi,copybara-service[bot],Internal change only.,Internal change only.,2025-03-10T06:42:37Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88937
yi,cousteaulecommandant,Fixed-point Softmax() calls exp_on_negative_values() twice,"Fixedpoint `Softmax()` calls `exp_on_negative_values()` twice per element: once to calculate the value of the exp of each element https://github.com/tensorflow/tensorflow/blob/4266e9ab53bb3f7fca0dd816b965b82862b69b4e/tensorflow/lite/kernels/internal/reference/softmax.hL131 and another one a few lines earlier to calculate the sum of all exps https://github.com/tensorflow/tensorflow/blob/4266e9ab53bb3f7fca0dd816b965b82862b69b4e/tensorflow/lite/kernels/internal/reference/softmax.hL109L110 The `exp_on_negative_values()` function can be rather slow, taking most of the time of `Softmax()` (which can be especially concerning in embedded implementations), so calling it twice per element makes the whole `Softmax()` function be about twice as slow as necessary. Could this be optimized so that it is only called once per element?  Store the exp results in a temporary array (for example, reusing `output_data`), computing the sum as they're stored, and then applying the scaling to the precomputed exp results rather than computing them again. (`SoftmaxInt16()` seems to follow a similar approach.)",2025-03-07T21:48:15Z,comp:lite,open,0,0,https://github.com/tensorflow/tensorflow/issues/88861
rag,copybara-service[bot],Deprecate `HloTestBase`.,"Deprecate `HloTestBase`. New tests should utilize `HloPjRtTestBase` where possible. If `RunAndCompare` functionality is required, tests can instantiate `HloPjRtInterpreterReferenceMixin`. Please see `HloRunnerAgnosticTestBase` and `HloRunnerAgnosticReferenceMixin` for generic implementations that can be subclassed for different use cases, if your `HloPjRtTestBase` and/or `HloPjRtInterpreterReferenceMixin` do not meet your needs.",2025-03-07T19:59:23Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88851
yi,copybara-service[bot],#litert Detect memory sanitizers in `cc:litert_shared_library` to disable `RTLD_DEEPBIND`.,"litert Detect memory sanitizers in `cc:litert_shared_library` to disable `RTLD_DEEPBIND`. Trying to load a library using `RTLD_DEEPBIND` is not supported by memory sanitizers. In an effort to enable testing we strip the flag. If this leads to unintended behaviour, either remove the `RTLD_DEEPBIND` flag or run without a memory sanitizer. See https://github.com/google/sanitizers/issues/611 for more information.",2025-03-07T17:47:51Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88843
rag,copybara-service[bot],[XLA:GPU] Add one-shot kernel implementation to RaggedAllToAll.,[XLA:GPU] Add oneshot kernel implementation to RaggedAllToAll. The kernel uses a CUDA kernel for an efficient implementation of ra2a on single host when direct peer access between GPUs is available.,2025-03-07T17:37:52Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88841
rag,copybara-service[bot],PR #23477: [Hermetic CUDA] Skip arch if not in redistrib json,"PR CC(Tensorflow's Estimator stops training): [Hermetic CUDA] Skip arch if not in redistrib json Imported from GitHub PR https://github.com/openxla/xla/pull/23477 Given a custom CUDA redistribution which only specifies a distribution for `linuxx86_64` and not `linuxsbsa` nor `linuxaarch64`, a key error occurs due to `_get_redistribution_urls` expecting all architectures to be present for each subproject. ```json // fragment of the custom CUDA redistribution JSON {     ""cuda_cccl"": {         ""linuxx86_64"": {             ""relative_path"": ""..."",             ""sha256"": ""...""         },     }, } ``` This can be resolved by adding a key for each arch mapping to an empty dict if there is no artifact for that arch. However, this solution is awkward and adds clutter to the custom CUDA redistribution. ```json {   ""cuda_cccl"": {       ""linuxx86_64"": {           ""relative_path"": ""..."",           ""sha256"": ""...""       },       ""linuxaarch64"": {},       ""linuxsbsa"": {},   }, ``` Instead, allow for `_get_redistribution_urls` to skip the arch if it is not present in the redistribution. Copybara import of the project:  2a00755a0aba650588b2ba22340990980f18b472 by Jack Wolfard : [Hermetic CUDA] Skip arch if not in redistrib json Given a custom CUDA redistribution which only specifies a distribution for `linuxx86_64` and not `linuxsbsa` nor `linuxaarch64`, a key error occurs due to `_get_redistribution_urls` expecting all architectures to be present for each subproject. ```json // fragment of the custom CUDA redistribution JSON {     ""cuda_cccl"": {         ""linuxx86_64"": {             ""relative_path"": ""..."",             ""sha256"": ""...""         },     }, } ``` This can be resolved by adding a key for each arch mapping to an empty dict if there is no artifact for that arch. However, this solution is awkward and adds clutter to the custom CUDA redistribution. ```json {   ""cuda_cccl"": {       ""linuxx86_64"": {           ""relative_path"": ""..."",           ""sha256"": ""...""       },       ""linuxaarch64"": {},       ""linuxsbsa"": {},   }, ``` Instead, allow for `_get_redistribution_urls` to skip the arch if it is not present in the redistribution. Merging this change closes CC(Tensorflow's Estimator stops training) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23477 from JackWolfard:hermeticcudaarch 2a00755a0aba650588b2ba22340990980f18b472",2025-03-07T16:38:31Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88836
rag,copybara-service[bot],PR #22541: [ROCm] Cleanup atomics support,"PR CC(Java process crashes during model loading): [ROCm] Cleanup atomics support Imported from GitHub PR https://github.com/openxla/xla/pull/22541 Weaken the ordering barriers to match what atomicAdd does on rocm. Emulate fp16 atomic on top of packed fp16 atomic where possible. Also for bfloat16 atomics, albeit those don't get matched right now due to FloatNormalization. Left in support for fp16 and bfloat16 vector atomics. We might enable the vectorization for them in the future if we can prove the access satisfies 4byte aligment. Copybara import of the project:  06907ef930c76c824788e86db8d3b30eeb141175 by Dragan Mladjenovic : [ROCm] Cleanup atomics support Merging this change closes CC(Java process crashes during model loading) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22541 from ROCm:atomics_cleanup 06907ef930c76c824788e86db8d3b30eeb141175",2025-03-07T14:45:15Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88828
yi,xxHn-pro,cuSteamSynchronize take tons of time," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14  Custom code Yes  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.6  GPU model and memory 4070S  Current behavior? I am trying to benchmark the inference.  A simple code as  ``` // Configure a `CallableHandle` that feeds from and fetches to a device. Status SetupCallable(std::unique_ptr& session,                      std::vector& input_info,                      std::vector& output_info,                      const string& device_name,                      bool input_from_device,                      bool output_to_host,                      tensorflow::Session::CallableHandle* handle) {   tensorflow::CallableOptions opts;   for (const auto& info : input_info) {     const string& name = info.name();     opts.add_feed(name);     if (input_from_device) {       opts.mutable_feed_devices()>insert({name, device_name});     }   }   for (const auto& info : output_info) {     const string& name = info.name();     opts.add_fetch(name);     if (!output_to_host) {       opts.mutable_fetch_devices()>insert({name, device_name});     }   }   opts.set_fetch_skip_sync(true);   return session>MakeCallable(opts, handle); } ``` The inference is run by ``` start_time = std::chrono::steady_clock::now();       TFTRT_ENSURE_OK(         bundle.session>RunCallable(handle, inputs_device, &outputs, nullptr));       // Sync, as `set_fetch_skip_sync(false)` is currently not implemented       TFTRT_ENSURE_OK(device>Sync());       end_time = std::chrono::steady_clock::now(); ``` The profile is collected by `nsys profile w true t cuda,nvtx,cudnn,cublas f true x true o profile_c /opt/tensorflow/tensorflowsource/bazelbin/tensorflow/examples/image_classification/MiniBatch/mini_tftrt model_path=""./resnet50_saved_model_RT"" batch_size=64 output_to_host=False` And I found that cuSteamSynchronize takes most of time, as shown below: profile_c.zip !Image I think the real computation is done and the GPU is wasting its time. Is that right? I don't see any other kernel working. So I try to skip that Sync by setting `opts.set_fetch_skip_sync(true);`. However, the  cuSteamSynchronize  is still on there. No mater whether `device>Sync()` is used or not.  The time consumption and cuSteamSynchronize  are always unchanged even I set the output to host. Here is the code and readme to reproduce the issue. MiniBatch2.zip  Standalone code to reproduce the issue ```shell See the zip file at the end. ```  Relevant log output ```shell ```",2025-03-07T04:27:50Z,type:bug TF2.14,open,0,2,https://github.com/tensorflow/tensorflow/issues/88796,"Hi **pro** , Apologies for the delay, and thanks for raising your concern here.I noticed a version compatibility issue. I am attaching the official documentation for your reference, please verify all compatibility requirements. Additionally, I see that you are using an older version of TensorFlow (2.14). Could you please try updating to the latest version for better results? Thank you!","Hi  , Thanks for your reply. Actually I try the same code at other machine. And there are more information from the new test, which indicate that CUDA kernel is running all the time during the waiting of tensorRT kernel. I think the tensorflow is running asynchronously. It turns out that is not a problem of cuSteamSynchronize !Image PS, the new machine with better GPU uses singularity to run the docker. It runs real CentOS Linux instead of WSL. It is still not clear why I can not get all information at my first try. Anyway, Thanks you. If there is any misunderstand above, pls correct it."
yi,jsuj1th,import error," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.8  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  ImportError                               Traceback (most recent call last) File c:\Users\SUJITH\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[1], line 3       1  !pip install tensorflow > 3 import tensorflow as tf       4 from tensorflow.keras.applications import MobileNetV3Small       5 from tensorflow.keras.models import Model File c:\Users\SUJITH\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File c:\Users\SUJITH\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:85      83     sys.setdlopenflags(_default_dlopen_flags)      84 except ImportError: > 85   raise ImportError(      86       f'{traceback.format_exc()}'      87       f'\n\nFailed to load the native TensorFlow runtime.\n'      88       f'See https://www.tensorflow.org/install/errors '      89       f'for some common causes and solutions.\n'      90       f'If you need help, create an issue '      91       f'at https://github.com/tensorflow/tensorflow/issues '      92       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""c:\Users\SUJITH\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.   Standalone code to reproduce the issue ```shell pip install tensorflow ```  Relevant log output ```shell ```",2025-03-06T23:45:28Z,stat:awaiting response type:build/install stale TF 2.8,closed,0,4,https://github.com/tensorflow/tensorflow/issues/88780,"Hi ****, Apologies for the delay, and thanks for raising your concern here. I noticed that you are using an older version of TensorFlow (2.8). Could you please check with the latest version for better results? Also, please verify all compatibility requirements. I am attaching the official documentation for your reference. Additionally, a similar issue is currently being discussed, please follow that thread for further updates. CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Please always search for duplicate issues. Please do a minimum of effort for that and for properly formatting the issue.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Internal change only.,Internal change only.,2025-03-06T23:30:52Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88777
yi,copybara-service[bot],Internal change only.,Internal change only. FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/88221 from jiunkaiy:dev/weilhuan/more_op_builders 542a108226dcb1c31abc30578cba2b74b20e8e0b,2025-03-06T22:44:44Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88774
yi,copybara-service[bot],PR #21638: Add the hlo verifier before host offloader to check host memory space,"PR CC([XLA] ResourceExhaustedError when trying to define a Sequential model in Keras under jit_scope context manager): Add the hlo verifier before host offloader to check host memory space Imported from GitHub PR https://github.com/openxla/xla/pull/21638 Ensure No Instructions Have Host Memory Space S(5) Before Host Offloader This change verifies that no instruction possesses host memory space S(5) prior to the host offloader pass. It addresses an issue where the HLO passes before the host offloader could inadvertently leak memory space annotations from the entry computation layout to the graph. In PR https://github.com/openxla/xla/pull/20426, the layout assignment pass was corrected to prevent instructions from inheriting memory space S(5) from the entry computation layout. This commit further ensures that such annotations are not propagated, keeping host memory space not changed until the host offloader pass. Copybara import of the project:  a785e186e919d3921a2922caca5fbca1f6eb0f37 by Jane Liu : Add the hlo verifier before host offloader to check host memory space  bebf8b97743e34b59114c1c0966b9cf1c5877b90 by Jane Liu : remove extra std::move and change InvalidArgumentError to Internal  9ac2bf59d93759f67d9a41578cd70dba78498b0f by Jane Liu : use ForEachSubshapeWithStatus Merging this change closes CC([XLA] ResourceExhaustedError when trying to define a Sequential model in Keras under jit_scope context manager) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21638 from zhenyingliu:verifier 9ac2bf59d93759f67d9a41578cd70dba78498b0f",2025-03-06T20:33:45Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88768
yi,copybara-service[bot],PR #23395: [ROCm] gfx950 support,PR CC(deploying the Tensorflow model in Python): [ROCm] gfx950 support Imported from GitHub PR https://github.com/openxla/xla/pull/23395 rotation please have a look Thanks Copybara import of the project:  6c6bfad5a896154c1a21c263cda433253e9f8597 by Chao Chen : gfx950 support Merging this change closes CC(deploying the Tensorflow model in Python) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23395 from ROCm:ci_gfx950 6c6bfad5a896154c1a21c263cda433253e9f8597,2025-03-06T19:48:27Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88765
rag,copybara-service[bot],Define lax.ragged_dot_general and express lax.ragged_dot in terms of it.,Define lax.ragged_dot_general and express lax.ragged_dot in terms of it.,2025-03-06T19:18:28Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88760
rag,copybara-service[bot],[XLA:GPU] Add RaggedAllToAll CUDA kernel.,"[XLA:GPU] Add RaggedAllToAll CUDA kernel. The kernel will be used in RaggedAllToAll thunk for singlehost collectives. Runtime is responsible for communication, synchronization and exchange of pointer. The kernel only need to move the data.",2025-03-06T19:02:08Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88758
yi,copybara-service[bot],#litert Detect address sanitizers in `cc:litert_shared_library` to disable `RTLD_DEEPBIND`.,"litert Detect address sanitizers in `cc:litert_shared_library` to disable `RTLD_DEEPBIND`. Trying to load a library using `RTLD_DEEPBIND` is not supported by address sanitizers. In an effort to enable testing we strip the flag. If this leads to unintended behaviour, either remove the `RTLD_DEEPBIND` flag or run without an address sanitizer. See https://github.com/google/sanitizers/issues/611 for more information.",2025-03-06T15:46:02Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88743
yi,priyanshujiiii,Graph Execution Error," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.18.0dev20240917  Custom code Yes  OS platform and distribution Rocky Linux  Mobile device Rocky Linux  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 9.3.0.  GPU model and memory NIVIDIA SMI 560.28.03  Current behavior? The code is showing a Graph execution error while training a model  Standalone code to reproduce the issue ```shell import os import numpy as np import tensorflow as tf from sklearn.model_selection import train_test_split def load_and_preprocess_data(base_path, batch_size=2, val_split=0.2):     noise_files = []     fullstack_files = []      Collect file paths     for subdir, _, files in os.walk(base_path):         for file in files:             if file.endswith("".npy""):                 full_path = os.path.join(subdir, file)                 if ""noise"" in file:                     noise_files.append(full_path)                 elif ""fullstack"" in file:                     fullstack_files.append(full_path)      Ensure files are in correct order     noise_files.sort()     fullstack_files.sort()      Split data into train and validation sets     noise_train, noise_val, fullstack_train, fullstack_val = train_test_split(         noise_files, fullstack_files, test_size=val_split, random_state=42     )     def create_generator(noise_list, fullstack_list):         def generator():             for noise_path, fullstack_path in zip(noise_list, fullstack_list):                  Load files in memorymapped mode                 noise_data = np.load(noise_path, mmap_mode='r', allow_pickle=True)                 fullstack_data = np.load(fullstack_path, mmap_mode='r', allow_pickle=True)                 for i in range(300):                     x_sample = noise_data[:, :, i]   Only loads this slice into RAM                     y_sample = fullstack_data[:, :, i]                     yield np.expand_dims(x_sample, axis=1), np.expand_dims(y_sample, axis=1)         return generator      Create TensorFlow datasets     train_dataset = tf.data.Dataset.from_generator(         create_generator(noise_train, fullstack_train),         output_signature=(             tf.TensorSpec(shape=(1259, 300, 1), dtype=tf.float32),             tf.TensorSpec(shape=(1259, 300, 1), dtype=tf.float32)         )     ).batch(batch_size).prefetch(tf.data.AUTOTUNE)     val_dataset = tf.data.Dataset.from_generator(         create_generator(noise_val, fullstack_val),         output_signature=(             tf.TensorSpec(shape=(1259, 300, 1), dtype=tf.float32),             tf.TensorSpec(shape=(1259, 300, 1), dtype=tf.float32)         )     ).batch(batch_size).prefetch(tf.data.AUTOTUNE)     return train_dataset, val_dataset  Example Usage base_path = ""/home/simlab120/Denoise_comp/Pragyant/imageimpeccabletraindatapart1"" train_dataset, val_dataset = load_and_preprocess_data(base_path)  Display a sample batch from the training set for x_batch, y_batch in train_dataset.take(1):     import matplotlib.pyplot as plt     plt.subplot(1, 2, 1)     plt.imshow(x_batch[0, :, :, 0], cmap='gray')   Removing channel dimension for visualization     plt.title(""Noisy Image"")     plt.subplot(1, 2, 2)     plt.imshow(y_batch[0, :, :, 0], cmap='gray')     plt.title(""Fullstack Image"")     plt.show()     break Output:  20250306 11:47:58.814180: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250306 11:47:58.827279: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1741241878.841060  263395 cuda_dnn.cc:8321] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1741241878.844820  263395 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250306 11:47:58.859322: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. I0000 00:00:1741241880.476719  263395 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5694 MB memory:  > device: 0, name: NVIDIA T1000 8GB, pci bus id: 0000:52:00.0, compute capability: 7.5 Input:  import tensorflow as tf from tensorflow.keras.layers import Conv2D, Conv2DTranspose, ZeroPadding2D, Cropping2D, BatchNormalization, MaxPooling2D, UpSampling2D from tensorflow.keras import models def build_encdec(input_shape=(1259, 300, 1)):   Ensure it's divisible by 2^6     model = models.Sequential(name=""encoder_decoder"")      Encoder     model.add(ZeroPadding2D(padding=((21, 0), (10, 10)), input_shape=input_shape))   Add extra padding     model.add(Conv2D(16, (3, 3), activation='swish', padding=""same"", strides=1))      model.add(BatchNormalization())     model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))     model.add(UpSampling2D((2, 2)))     model.add(Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same', strides=1))   Change activation to sigmoid     model.add(BatchNormalization())      Remove padding added in encoder     model.add(Cropping2D(cropping=((21, 0), (10, 10))))       return model     def ssim_metric(y_true, y_pred):      Ensure y_true has a channel dimension if missing.     y_true = y_true if len(y_true.shape) == 4 else tf.expand_dims(y_true, 1)     return tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))  Create the autoencoder model instance autoencoder = build_encdec()  Compile the model autoencoder.compile(optimizer=""adam"", loss=""mse"", metrics=[ssim_metric])  Build the model by specifying an input shape (optional) autoencoder.build((None, 1259, 300, 1)) autoencoder.summary() output: Model: ""encoder_decoder"" ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓ ┃ Layer (type)                    ┃ Output Shape           ┃       Param  ┃ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩ │ zero_padding2d_1                │ (None, 1280, 320, 1)   │             0 │ │ (ZeroPadding2D)                 │                        │               │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ conv2d_6 (Conv2D)               │ (None, 1280, 320, 16)  │           160 │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ batch_normalization_12          │ (None, 1280, 320, 16)  │            64 │ │ (BatchNormalization)            │                        │               │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ max_pooling2d_6 (MaxPooling2D)  │ (None, 640, 160, 16)   │             0 │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ up_sampling2d_6 (UpSampling2D)  │ (None, 1280, 320, 16)  │             0 │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ conv2d_transpose_6              │ (None, 1280, 320, 1)   │           145 │ │ (Conv2DTranspose)               │                        │               │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ batch_normalization_13          │ (None, 1280, 320, 1)   │             4 │ │ (BatchNormalization)            │                        │               │ ├─────────────────────────────────┼────────────────────────┼───────────────┤ │ cropping2d_1 (Cropping2D)       │ (None, 1259, 300, 1)   │             0 │ └─────────────────────────────────┴────────────────────────┴───────────────┘  Total params: 373 (1.46 KB)  Trainable params: 339 (1.32 KB)  Nontrainable params: 34 (136.00 B)  import os os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""  history = autoencoder.fit(     train_dataset,   Use the dataset directly     validation_data=val_dataset,   Use validation dataset     epochs=1000,     verbose=1, ) ```  Relevant log output ```shell W0000 00:00:1741242567.222588  263744 assert_op.cc:38] Ignoring Assert operator SSIM/Assert/Assert W0000 00:00:1741242567.222702  263744 assert_op.cc:38] Ignoring Assert operator SSIM/Assert_1/Assert W0000 00:00:1741242567.222812  263744 assert_op.cc:38] Ignoring Assert operator SSIM/Assert_2/Assert W0000 00:00:1741242567.222874  263744 assert_op.cc:38] Ignoring Assert operator SSIM/Assert_3/Assert E0000 00:00:1741242567.262839  263744 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration. E0000 00:00:1741242567.282689  263744 cuda_dnn.cc:522] Loaded runtime CuDNN library: 9.1.0 but source was compiled with: 9.3.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration. 20250306 11:59:27.290025: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.  FailedPreconditionError                   Traceback (most recent call last) Cell In[8], line 3       1 import os       2 os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""  > 3 history = autoencoder.fit(       4     train_dataset,   Use the dataset directly       5     validation_data=val_dataset,   Use validation dataset       6     epochs=1000,       7     verbose=1,       8 ) File ~/anaconda3/envs/tf/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py:122, in filter_traceback..error_handler(*args, **kwargs)     119     filtered_tb = _process_traceback_frames(e.__traceback__)     120      To get the full stack trace, call:     121      `keras.config.disable_traceback_filtering()` > 122     raise e.with_traceback(filtered_tb) from None     123 finally:     124     del filtered_tb File ~/anaconda3/envs/tf/lib/python3.12/sitepackages/tensorflow/python/eager/execute.py:53, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)      51 try:      52   ctx.ensure_initialized() > 53   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,      54                                       inputs, attrs, num_outputs)      55 except core._NotOkStatusException as e:      56   if name is not None: FailedPreconditionError: Graph execution error: Detected at node StatefulPartitionedCall defined at (most recent call last):   File """", line 198, in _run_module_as_main   File """", line 88, in _run_code   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel_launcher.py"", line 18, in    File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/traitlets/config/application.py"", line 1075, in launch_instance   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/kernelapp.py"", line 739, in start   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/tornado/platform/asyncio.py"", line 205, in start   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/asyncio/base_events.py"", line 641, in run_forever   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/asyncio/base_events.py"", line 1986, in _run_once   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/asyncio/events.py"", line 88, in _run   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/kernelbase.py"", line 545, in dispatch_queue   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/kernelbase.py"", line 534, in process_one   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/kernelbase.py"", line 437, in dispatch_shell   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/ipkernel.py"", line 362, in execute_request   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/kernelbase.py"", line 778, in execute_request   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/ipkernel.py"", line 449, in do_execute   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/ipykernel/zmqshell.py"", line 549, in run_cell   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/IPython/core/interactiveshell.py"", line 3075, in run_cell   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/IPython/core/interactiveshell.py"", line 3130, in _run_cell   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/IPython/core/async_helpers.py"", line 128, in _pseudo_sync_runner   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/IPython/core/interactiveshell.py"", line 3334, in run_cell_async   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/IPython/core/interactiveshell.py"", line 3517, in run_ast_nodes   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/IPython/core/interactiveshell.py"", line 3577, in run_code   File ""/tmp/ipykernel_263395/279222490.py"", line 3, in    File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 320, in fit   File ""/home/simlab120/anaconda3/envs/tf/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 121, in one_step_on_iterator DNN library initialization failed. Look at the errors above for more details. 	 [[{{node StatefulPartitionedCall}}]] [Op:__inference_one_step_on_iterator_14559] ```",2025-03-06T06:42:15Z,stat:awaiting response stale type:performance TF 2.18,closed,0,4,https://github.com/tensorflow/tensorflow/issues/88708,"Hi **** , Apologies for the delay, and thanks for raising your concern here. Could you please provide a Colab gist for troubleshooting this issue more accurately? Alternatively, you can share the specific code where you are facing the issue. I attempted to replicate the provided code but encountered a different issue. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],Delete `PjRtClient.Defragment`.,"Delete `PjRtClient.Defragment`. The `Defragment` implementation for GPU is in `py_client.cc`, so this should be a noop.",2025-03-05T19:08:47Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88642
rag,copybara-service[bot],PR #88221: Qualcomm AI Engine Direct - Op Builders for 1P Models,"PR CC(Qualcomm AI Engine Direct  Op Builders for 1P Models): Qualcomm AI Engine Direct  Op Builders for 1P Models Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/88221  WHAT 1. Conv2d 2. DepthwiseConv2d 3. AveragePool 4. MaxPool 5. DepthToSpace 6. SpaceToDepth 7. HardSwish 8. LeakyRelu 9. ResizeBilinear 10. Litert options for these op builders, unit test 11. update qnn_compiler_plugin_test with these op builders  TEST  qnn_compiler_plugin_test ``` [] Global test environment teardown [==========] 115 tests from 5 test suites ran. (3489 ms total) [  PASSED  ] 115 tests. ```  litert_options_test ``` [] Global test environment teardown [==========] 22 tests from 1 test suite ran. (0 ms total) [  PASSED  ] 22 tests ``` Copybara import of the project:  542a108226dcb1c31abc30578cba2b74b20e8e0b by weilhuanquic : Qualcomm AI Engine Direct  Op Builders for 1P Models 1. Conv2d 2. DepthwiseConv2d 3. AveragePool 4. MaxPool 5. DepthToSpace 6. SpaceToDepth 7. HardSwish 8. LeakyRelu 9. ResizeBilinear 10. Litert options for these op builders, unit test 11. update qnn_compiler_plugin_test with these op builders Merging this change closes CC(Qualcomm AI Engine Direct  Op Builders for 1P Models) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/88221 from jiunkaiy:dev/weilhuan/more_op_builders 542a108226dcb1c31abc30578cba2b74b20e8e0b",2025-03-05T00:33:29Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88592
rag,copybara-service[bot],[XLA:GPU] Fix incorrect buffer aliasing in ir_emitter_unnested for RaggedAllToAll.,[XLA:GPU] Fix incorrect buffer aliasing in ir_emitter_unnested for RaggedAllToAll.,2025-03-04T21:45:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88579
rag,copybara-service[bot],[XLA:GPU] Add RaggedAllToAllCanonicalizer pass.,[XLA:GPU] Add RaggedAllToAllCanonicalizer pass. In too many places we need to assume or work around the element type of offset and size operands of raggedalltoall. It's much easier to do an HLO rewrite. The added converts are tiny and will likely be fused with other operation. FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/88412 from tensorflow:dependabot/docker/tensorflow/tools/tf_sig_build_dockerfiles/ubuntued1544e 4b6ba37c2667bdfded35b1774ed8ee438bc5fb25,2025-03-04T13:31:37Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88553
yi,Liu-Jitai,[RNN] tensorflow/lite/kernels/transpose.cc:62 op_context->perm->dims->data[0] != dims (3 != 2)Node number 3 (TRANSPOSE) failed to prepare," 1. System information  Window 10  PyCharm 2024.2.3  TensorFlow 2.13  Python 3.8  2. Code Keras model convert to TFLite model fail, please help find the debug method.  TensorFlow Model Colab (Train a TensorFlow Keras LSTM Model for SIN funtion regression using random generated dataset) ([TensorFlow Model Colab]: (https://colab.research.google.com/gist/LiuJitai/08faad02c37315eb09576e85f6df44eb/tensorflowdatasets.ipynb)  Keras model convert to TFLite model Code [Keras model convert to TFLite model]  Fail at tflite_model_quant = converter.convert()  Import libraries import logging import tensorflow as tf from tensorflow import keras import numpy as np from tensorflow.keras.models import load_model from sklearn.preprocessing import MinMaxScaler  Helper functions def generate_data(seq_length, sequences_num):     x = []     y = []     for _ in range(sequences_num):         start = np.random.rand() * 2 * np.pi         sequence = np.sin(np.linspace(start, start + 3 * np.pi, seq_length + 1))         x.append(sequence[:1])         y.append(sequence[1:])   shift sequence by one to predict next value     return np.array(x), np.array(y) def representative_data_gen():     for k in model_input:         yield [k]  Generate dataset seq_length = 50 num_sequences = 100 model_input, model_output = generate_data(seq_length, num_sequences)  Normalization scaler = MinMaxScaler(feature_range=(0, 1)) model_input = scaler.fit_transform(model_input) model_output = scaler.transform(model_output)    Reshape the data to fit the LSTM input. The LSTM model expects input of shape (batch_size, time_steps, features), which here corresponds to (num_sequences, seq_length, 1). model_input = model_input.reshape((model_input.shape[0], model_input.shape[1], 1)) model_input = np.array(model_input, dtype=np.float32)  Load Keras model model = load_model('LSTM_Sin_model.keras')  coverter converter = tf.lite.TFLiteConverter.from_keras_model(model)  set the ops configuration converter.optimizations = [tf.lite.Optimize.DEFAULT]  converter.target_spec.supported_ops = [     tf.lite.OpsSet.TFLITE_BUILTINS_INT8,       tf.lite.OpsSet.SELECT_TF_OPS       ] converter.inference_input_type = tf.int8  converter.inference_output_type = tf.int8  converter.representative_dataset = representative_data_gen tflite_model_quant = converter.convert() ** **fail at this step: tensorflow/lite/kernels/transpose.cc:62 op_context>perm>dims>data[0] != dims (3 != 2)Node number 3 (TRANSPOSE) failed to prepare****  save .tflite model tflite_model_path = 'LSTM_sin_model.tflite' with open(tflite_model_path, 'wb') as f:     f.write(tflite_model_quant) print(f""Model successfully converted to TFLite format and saved to {tflite_model_path}"")",2025-03-04T12:10:24Z,comp:lite TFLiteConverter TF 2.13,closed,0,3,https://github.com/tensorflow/tensorflow/issues/88549,"Hi, Jitai  Thank you for bringing this issue to our attention, I have been able to replicate the same behavior from my end with your provided code snippet but I think there was issue with directly yields samples without a batch dimension: `yield [k]` This produces data with shape (50, 1) causing a dimension mismatch. The model expects 3D inputs but receives 2D data leading to the TRANSPOSE node error so I've modified your provided code for missing batch dimension in the representative dataset and it seems like working as expected please refer this gistfile. Please give it try from your end and see is it working as expected or not ? If I have missed something here please let me know. Thank you for your cooperation and understanding. ``` import tensorflow as tf import numpy as np from tensorflow.keras.models import load_model from sklearn.preprocessing import MinMaxScaler def generate_data(seq_length, sequences_num):     x, y = [], []     for _ in range(sequences_num):         start = np.random.rand() * 2 * np.pi         sequence = np.sin(np.linspace(start, start + 3 * np.pi, seq_length + 1))         x.append(sequence[:1])         y.append(sequence[1:])     return np.array(x), np.array(y) def representative_data_gen():     for input_value in model_input:         yield [np.array([input_value], dtype=np.float32)]   seq_length = 50 num_sequences = 100 model_input, model_output = generate_data(seq_length, num_sequences) scaler = MinMaxScaler(feature_range=(0, 1)) model_input = scaler.fit_transform(model_input) model_output = scaler.transform(model_output) model_input = model_input.reshape((1, seq_length, 1)).astype(np.float32) model = load_model('/content/LSTM_Sin_model.keras') converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.supported_ops = [     tf.lite.OpsSet.TFLITE_BUILTINS_INT8,       tf.lite.OpsSet.SELECT_TF_OPS      ] converter.representative_dataset = representative_data_gen converter.inference_input_type = tf.int8 converter.inference_output_type = tf.int8 tflite_model_quant = converter.convert() tflite_model_path = '/content/LSTM_sin_model.tflite' with open(tflite_model_path, 'wb') as f:     f.write(tflite_model_quant) print(f""Model successfully converted to TFLite format and saved to {tflite_model_path}"") ```",您好，您所发的邮件我已经收到，我会尽快阅读，祝您工作愉快！,The error was solved. Thank you so much for your help! 
rag,copybara-service[bot],[XLA:GPU] Add ragged-all-to-all tests with multiple replica groups.,"[XLA:GPU] Add raggedalltoall tests with multiple replica groups. As a side effect, we can also support tests where devices in a replica group are not in increasing order.",2025-03-04T10:20:58Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88547
yi,copybara-service[bot],PR #23271: [XLA] Improve GPU memory limit handling and shape size calculation,"PR CC(Improve shape function of tf.sparse_reduce_sum): [XLA] Improve GPU memory limit handling and shape size calculation Imported from GitHub PR https://github.com/openxla/xla/pull/23271 When running MaxText Llama27b with FP16 optimizer state offloading, an out of memory failure occurred. The root cause was the int64_t memory limit being incorrectly calculated and interpreted as a large uint64_t memory limit close to UINT64_MAX, leading to overly aggressive buffer allocation by the LHS. This changelist addresses the out of memory failure by correctly handling the uint64_t memory limit and accurately calculating the device memory limit, excluding host memory space.  Change memory limit type from int64_t to uint64_t to prevent negative values and better represent memory sizes.  Add memory space filtering to exclude host memory when calculating input/output sizes that impact GPU memory usage. This ensures we only count buffers that actually reside in device memory.  Replace direct GetSizeOfShape() calls with ShapeSizeBytesFunction() wrapper, which provides:   * Consistent shape size calculation across the codebase   * Optional memory space filtering capability   * Proper handling of dynamic shapes and their metadata Copybara import of the project:  8b3184065c78f98f62e97e9a94e7d49e1797bd7b by Jane Liu : [XLA] Improve GPU memory limit handling and shape size calculation Merging this change closes CC(Improve shape function of tf.sparse_reduce_sum) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23271 from zhenyingliu:lhsoom 8b3184065c78f98f62e97e9a94e7d49e1797bd7b",2025-03-04T03:53:10Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88523
yi,copybara-service[bot],PR #23271: [XLA] Improve GPU memory limit handling and shape size calculation,"PR CC(Improve shape function of tf.sparse_reduce_sum): [XLA] Improve GPU memory limit handling and shape size calculation Imported from GitHub PR https://github.com/openxla/xla/pull/23271 When running MaxText Llama27b with FP16 optimizer state offloading, an out of memory failure occurred. The root cause was the int64_t memory limit being incorrectly calculated and interpreted as a large uint64_t memory limit close to UINT64_MAX, leading to overly aggressive buffer allocation by the LHS. This changelist addresses the out of memory failure by correctly handling the uint64_t memory limit and accurately calculating the device memory limit, excluding host memory space.  Change memory limit type from int64_t to uint64_t to prevent negative values and better represent memory sizes.  Add memory space filtering to exclude host memory when calculating input/output sizes that impact GPU memory usage. This ensures we only count buffers that actually reside in device memory.  Replace direct GetSizeOfShape() calls with ShapeSizeBytesFunction() wrapper, which provides:   * Consistent shape size calculation across the codebase   * Optional memory space filtering capability   * Proper handling of dynamic shapes and their metadata Copybara import of the project:  8b3184065c78f98f62e97e9a94e7d49e1797bd7b by Jane Liu : [XLA] Improve GPU memory limit handling and shape size calculation Merging this change closes CC(Improve shape function of tf.sparse_reduce_sum) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23271 from zhenyingliu:lhsoom 8b3184065c78f98f62e97e9a94e7d49e1797bd7b",2025-03-03T23:28:36Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88510
agent,copybara-service[bot],Added `WatchJobState` to coordination service agent.,Added `WatchJobState` to coordination service agent.,2025-03-03T22:09:20Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88500
rag,copybara-service[bot],[XLA:GPU] Use rendezvous to exchange pointers and CUDA events in memcpy ragged-all-to-all.,"[XLA:GPU] Use rendezvous to exchange pointers and CUDA events in memcpy raggedalltoall. The previous implementation used NCCL AllGather to exchange target device pointers and synchronize streams at the start of the kernel, but it didn't synchronize streams at the end of the kernel. Since we use push model for memcpy, it could be that one stream progresses before all updates have arrived. FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23351 from ROCm:ci_fix_stringop_trunc_20250304 d039829ba6a45807a13a2230cfb35e17590cd497",2025-03-03T17:12:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88487
rag,dicotom,Tensorflow with C++ Builder 12," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version libtensorflowcpuwindowsx86_64.zip  Custom code Yes  OS platform and distribution windows 10  Mobile device N/A  Python version N/A  Bazel version N/A  GCC/compiler version N/A  CUDA/cuDNN version _No response_  GPU model and memory N/A  Current behavior? this simple c file should compile: bcc64 test6.c D__NO_INLINE DWIN64 I ""N:\DOWNLOADS\FASTEST\26WORKS\TOTEST\include"" L ""N:\DOWNLOADS\FASTEST\26WORKS\TOTEST\lib"" l""tensorflow"" v ``` include  //pragma comment(lib, ""tensorflow.lib"")  //pragma link ""tensorflow.lib"" int main() {     // Your code using TensorFlow's C API functions     TF_Graph* graph = TF_NewGraph();     // More TensorFlow code...     return 0; } ``` but it does not: Embarcadero C++ 7.70 for Win64 Copyright (c) 20122024 Embarcadero Technologies, Inc. test6.c: Turbo Incremental Link64 6.99 Copyright (c) 19972024 Embarcadero Technologies, Inc. Error: Unresolved external 'TF_NewGraph' referenced from C:\USERS\USER\APPDATA\LOCAL\TEMP\TEST6AF147F.O if I add: pragma comment(lib, ""tensorflow.lib"")  I got invalid object file tensorflow.dll  Standalone code to reproduce the issue ```shell include  //pragma comment(lib, ""tensorflow.lib"") ; DOES NOT WORK //pragma link ""tensorflow.lib""          ; DOES NOT WORK int main() {     // Your code using TensorFlow's C API functions     TF_Graph* graph = TF_NewGraph();     // More TensorFlow code...     return 0; } ```  Relevant log output ```shell Embarcadero C++ 7.70 for Win64 Copyright (c) 20122024 Embarcadero Technologies, Inc. test6.c: Turbo Incremental Link64 6.99 Copyright (c) 19972024 Embarcadero Technologies, Inc. Error: Unresolved external 'TF_NewGraph' referenced from C:\USERS\USER\APPDATA\LOCAL\TEMP\TEST6AF147F.O ```",2025-03-02T16:05:15Z,stat:awaiting tensorflower type:bug subtype:windows comp:core,open,0,0,https://github.com/tensorflow/tensorflow/issues/88451
yi,xtrizeShino,Failed to parse TfLiteSettingsJsonParser on TensorFlow Lite C++," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.16.1  Custom code No  OS platform and distribution Debian aarch64   Mobile device VIA VAB5000  Python version Only C++  Bazel version 6.5.0  GCC/compiler version gcc version 12.2.0 (Debian 12.2.014) / Debian clang version 14.0.6  CUDA/cuDNN version None  GPU model and memory MediaTek Genio 700 MDLA  Current behavior? I am trying to use Delegate on VIA VAB5000 (aarch64) by referring to the following site. However, an error occurs when loading the json file to be used for Delegate, and I cannot use Delegate. Do you have any good ideas? I apologize for bothering you during your busy schedule. Thank you in advance. https://mediatek.gitlab.io/genio/doc/tao/npu_acceleration.html Below is the json file I am trying to parse. ``` { 	""stable_delegate_loader_settings"": { 		""delegate_path"": ""/usr/lib/libneuron_stable_delegate.so"" 	}, 	""neuron_delegate_settings"": { 		""execution_priority"": NEURON_PRIORITY_HIGH, 		""optimization_hint"": NEURON_OPTIMIZATION_NONE, 		""execution_preference"": NEURON_FAST_SINGLE_ANSWER, 		""allow_fp16"": true, 		""use_ahwb"": true 	} } ```  Standalone code to reproduce the issue ```shell  move to /home/debian $ cd ~   get TensorFlow v2.16.1 $ wget https://github.com/tensorflow/tensorflow/archive/refs/tags/v2.16.1.zip $ unzip v2.16.1.zip $ mv tensorflow2.16.1 tensorflow   get my source codes $ git.com:xtrizeShino/peoplenet_onnx_to_tflite.git $ cd peoplenet_onnx_to_tflite $ cd cpp_infer_vab5000  remove old source  $ rm rf abseilcpp $ rm rf flatbuffers  get abseil $ wget https://github.com/abseil/abseilcpp/archi ve/refs/tags/20230802.3.zip $ unzip 20230802.3.zip $ mv abseilcpp20230802.3 abseilcpp  get flatbuffers and build  $ wget https://github.com/google/flatbuffers/archive/refs/tags/v23.5.26.zip $ unzip v23.5.26.zip $ mv flatbuffers23.5.26 flatbuffers  $ cd flatbuffers $ mkdir build $ cd build $ cmake .. $ make  $ cd ../../  build my source codes $ mkdir build $ cd build  $ cmake .. $ make  exec $ ./PeopleNetInfer ```  Relevant log output ```shell $ ./PeopleNetInfer  original width=596, height=336 model file name : /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/resnet34_peoplenet_int8.tflite ERROR: Failed to parse the delegate settings file (/home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/stable_delegate_settings.json). Error at /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/peoplenet_main.cpp:235 ```",2025-03-02T05:56:37Z,type:support comp:lite TF 2.16,open,0,3,https://github.com/tensorflow/tensorflow/issues/88435,"The TensorFlow Lite ""*.so"" files were crosscompiled using the following steps. ``` target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libtensorflowlite.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libdelegate_loader.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libtflite_settings_json_parser.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libandroid_info.so) ``` ``` $ bazel build config=elinux_aarch64 c opt //tensorflow/lite/c:libtensorflowlite_c.so $ bazel build config=elinux_aarch64 c opt //tensorflow/lite:libtensorflowlite.so $ bazel build config=elinux_aarch64 c opt //tensorflow/lite/experimental/acceleration/compatibility:android_info $ bazel build config=elinux_aarch64 c opt //tensorflow/lite/delegates/utils/experimental/stable_delegate:tflite_settings_json_parser $ bazel build config=elinux_aarch64 c opt //tensorflow/lite/delegates/utils/experimental/stable_delegate:delegate_loader ``` And I am building it with cmake using the following CMakeLists.txt: ``` cmake_minimum_required(VERSION 2.8) project(PeopleNetInfer)  Create Main project add_executable(PeopleNetInfer 	peoplenet_main.cpp )  For OpenCV find_package(OpenCV REQUIRED) if(OpenCV_FOUND) 	target_include_directories(PeopleNetInfer PUBLIC ${OpenCV_INCLUDE_DIRS}) 	target_link_libraries(PeopleNetInfer ${OpenCV_LIBS}) endif()  Avseil.io (absl) add_subdirectory(abseilcpp) set(protobuf_ABSL_USED_TARGETS absl::absl_check absl::absl_log absl::algorithm absl::base absl::bind_front absl::bits absl::btree absl::cleanup absl::cord absl::core_headers absl::debugging absl::die_if_null absl::dynamic_annotations absl::flags absl::flat_hash_map absl::flat_hash_set absl::function_ref absl::hash absl::layout absl::log_initialize absl::log_severity absl::memory absl::node_hash_map absl::node_hash_set absl::optional absl::span absl::status absl::statusor absl::strings absl::synchronization absl::time absl::type_traits absl::utility absl::variant ) target_link_libraries(PeopleNetInfer ${protobuf_ABSL_USED_TARGETS})  For Tensorflow Lite target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libtensorflowlite.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libdelegate_loader.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libtflite_settings_json_parser.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/crosstf/libandroid_info.so) target_link_libraries(PeopleNetInfer /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/flatbuffers/build/libflatbuffers.a) target_include_directories(PeopleNetInfer PUBLIC /home/debian/tensorflow) target_include_directories(PeopleNetInfer PUBLIC /home/debian/tensorflow/tensorflow) target_include_directories(PeopleNetInfer PUBLIC /home/debian/tensorflow/tensorflow/lite) target_include_directories(PeopleNetInfer PUBLIC /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/flatbuffers/include) set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS}  std=c++17 lstdc++"")  Copy resouce file(COPY ${CMAKE_SOURCE_DIR}/resource/ DESTINATION ${PROJECT_BINARY_DIR}/resource/) add_definitions(DRESOURCE_DIR=""${PROJECT_BINARY_DIR}/resource/"") ```","Hi,   I apologize for the delay in my response, I see after analyzing the error you're encountering with the `TfLiteSettingsJsonParser` maybe the values `NEURON_PRIORITY_HIGH, NEURON_OPTIMIZATION_NONE` and `NEURON_FAST_SINGLE_ANSWER` are not valid JSON as they're not enclosed in quotes. In proper JSON, string values must be enclosed in double quotes. If these are meant to be string constants: ``` { 	""stable_delegate_loader_settings"": { 		""delegate_path"": ""/usr/lib/libneuron_stable_delegate.so"" 	}, 	""neuron_delegate_settings"": { 		""execution_priority"": ""NEURON_PRIORITY_HIGH"", 		""optimization_hint"": ""NEURON_OPTIMIZATION_NONE"", 		""execution_preference"": ""NEURON_FAST_SINGLE_ANSWER"", 		""allow_fp16"": true, 		""use_ahwb"": true 	} } ``` JSON parsing errors can also occur due to file encoding problems. The parser might be failing due to hidden characters or incorrect encoding so create a new file with a text editor (like Notepad++ if available) save it with `UTF8` encoding (not UTF8BOM) and use this new file and see is it resolving your error or not ? Thank you for your cooperation and patience.","Thank you for your reply!! However, I tried the method you taught me, but unfortunately the result did not change. The output is as follows.  When I open the file in Notepad++, it shows as UTF8. ``` $ cat /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/stable_delegate_settings.json  libneuron_stable_delegate.so setting {         ""stable_delegate_loader_settings"": {                 ""delegate_path"": ""/usr/lib/libneuron_stable_delegate.so""         },         ""neuron_delegate_settings"": {                 ""execution_priority"": ""NEURON_PRIORITY_HIGH"",                 ""optimization_hint"": ""NEURON_OPTIMIZATION_NONE"",                 ""execution_preference"": ""NEURON_FAST_SINGLE_ANSWER"",                 ""allow_fp16"": true,                 ""use_ahwb"": true         } } $ ./PeopleNetInfer original width=596, height=336 model file name : /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/resnet34_peoplenet_int8.tflite ERROR: Failed to parse the delegate settings file (/home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/stable_delegate_settings.json). Error at /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/peoplenet_main.cpp:235 ``` Since the character code contains only alphabets, the nkf command displayed it as ""ASCII"". ``` $ sudo apt install nkf $ nkf g /home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/stable_delegate_settings.json ASCII ``` https://github.com/xtrizeShino/peoplenet_onnx_to_tflite/blob/main/cpp_infer_vab5000/peoplenet_main.cppL232 ``` define TFLITE_MINIMAL_CHECK(x) \     if (!(x)) {  \         fprintf(stderr, ""Error at %s:%d\n"", __FILE__, __LINE__); \         exit(1);  \     } ... constexpr char kSettingsPath[] = ""/home/debian/peoplenet_onnx_to_tflite/cpp_infer_vab5000/build/resource/stable_delegate_settings.json"";  ... /* Load settings */ TfLiteSettingsJsonParser parser; const tflite::TFLiteSettings* settings = parser.Parse(kSettingsPath); TFLITE_MINIMAL_CHECK(settings != nullptr); ```"
yi,cybersupersoap,"`tf.compat.v1.linalg.set_diag` aborts with ""Check failed: d < dims() (2 vs. 2)"""," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.20.0dev20250225  Custom code Yes  OS platform and distribution Ubuntu 20.04 LTS   Mobile device _No response_  Python version 3.10.14  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I encountered an aborted issue in TensorFlow when I used API tf.compat.v1.linalg.set_diag . I have confirmed that below code would crash on tfnightly 2.20.0dev20250225 (nightlybuild).  Standalone code to reproduce the issue ```shell import tensorflow as tf input_tensor = tf.random.uniform([5, 4, 4, 4], dtype=tf.float32) input = tf.identity(input_tensor) diagonal_0_0 = 2.0 diagonal_0_1 = 3.0 diagonal_0_2 = 4.0 diagonal_0_3 = 5.0 diagonal_0 = [diagonal_0_0, diagonal_0_1, diagonal_0_2, diagonal_0_3] diagonal_1_0 = 1.0 diagonal_1_1 = 2.0 diagonal_1_2 = 3.0 diagonal_1_3 = 4.0 diagonal_1 = [diagonal_1_0, diagonal_1_1, diagonal_1_2, diagonal_1_3] diagonal = [diagonal_0, diagonal_1] name = 'set_diag' k_0 = 0 k_1 = 1 k = [k_0, k_1] align = 'LEFT_RIGHT' out = tf.compat.v1.linalg.set_diag(input=input, diagonal=diagonal, name=name, k=k, align=align) ```  Relevant log output ```shell 20250302 02:25:05.721633: F tensorflow/core/framework/tensor_shape.cc:359] Check failed: d < dims() (2 vs. 2) Aborted (core dumped) ```",2025-03-02T02:21:06Z,type:bug comp:ops TF 2.18,open,0,1,https://github.com/tensorflow/tensorflow/issues/88426,I was able to reproduce this issue on Colab using TensorFlow 2.18 and the nightly version. Please find the gist attached for your reference. Thank you!
yi,dependabot[bot],Bump the github-actions group with 6 updates,"Bumps the githubactions group with 6 updates:  Updates `peterevans/createpullrequest` from 7.0.6 to 7.0.7  Release notes Sourced from peterevans/createpullrequest's releases.  Create Pull Request v7.0.7 ⚙️ Fixes an issue with commit signing where modifications to the same file in multiple commits squash into the first commit. What's Changed  build(deps): bump @​octokit/core from 6.1.2 to 6.1.3 by @​dependabot in peterevans/createpullrequest CC(How to run custom encoderdecoder in Tensorflow using available APIs?) build(depsdev): bump @​types/node from 18.19.68 to 18.19.70 by @​dependabot in peterevans/createpullrequest CC(Moved eightbit graph trimming to before output_nodes definition) Update distribution by @​actionsbot in peterevans/createpullrequest CC(RC 0.10 3X Slower than 0.9 and Error Compiling From Source Under Certain Conditions) build(depsdev): bump typescript from 5.7.2 to 5.7.3 by @​dependabot in peterevans/createpullrequest CC(Graph optimization and other features) build(deps): bump octokit dependencies by @​peterevans in peterevans/createpullrequest CC(gcc: error: unrecognized command line option 'fnocanonicalsystemheaders') docs: add workflow tip for showing message via workflow command by @​ybiquitous in peterevans/createpullrequest CC(contrib/makefile:  error: conflicting return type) build(depsdev): bump eslintpluginprettier from 5.2.1 to 5.2.3 by @​dependabot in peterevans/createpullrequest CC(Unable to import frozen graph with batchnorm) build(deps): bump nodefetchnative from 1.6.4 to 1.6.6 by @​dependabot in peterevans/createpullrequest CC(Tensorflow inability to kill processes using more than 1 GPU) build(depsdev): bump undici from 6.21.0 to 6.21.1 by @​dependabot in peterevans/createpullrequest CC(TF works in python3.4 for some users but not for others under RedHat7 ) build(depsdev): bump @​types/node from 18.19.70 to 18.19.71 by @​dependabot in peterevans/createpullrequest CC(Problems in ""Implement the gradient in Python"" docs) Update distribution by @​actionsbot in peterevans/createpullrequest CC(Mismatch in gradient of 'abs' for complex values) build(depsdev): bump @​types/node from 18.19.71 to 18.19.74 by @​dependabot in peterevans/createpullrequest CC(0.10.0rc0: Contrib distributions crash when sampling ""n"" is scalar) build(depsdev): bump @​types/node from 18.19.74 to 18.19.75 by @​dependabot in peterevans/createpullrequest CC(Error when using TensorArray and variables in nested loops) build(deps): bump @​octokit/pluginrestendpointmethods from 13.3.0 to 13.3.1 by @​dependabot in peterevans/createpullrequest CC(Update CUDA/cuDNN in Dockerfiles) build(depsdev): bump prettier from 3.4.2 to 3.5.0 by @​dependabot in peterevans/createpullrequest CC(Add layer_norm op to contrib.layers.) Update distribution by @​actionsbot in peterevans/createpullrequest CC(error: can't copy 'tensorflow/models/embedding/gen_word2vec.py': doesn't exist) build(deps): bump @​octokit/requesterror from 6.1.6 to 6.1.7 by @​dependabot in peterevans/createpullrequest CC(Unable to generate signed APK for project based on Android demo) build(deps): bump @​octokit/pluginpaginaterest from 11.4.0 to 11.4.1 by @​dependabot in peterevans/createpullrequest CC(Error when trying to run tensorboard logdir=some_path) build(deps): bump @​octokit/endpoint from 10.1.2 to 10.1.3 by @​dependabot in peterevans/createpullrequest CC(Cuda8) Update distribution by @​actionsbot in peterevans/createpullrequest CC(Benchmarking example for iOS profiling) build(depsdev): bump prettier from 3.5.0 to 3.5.1 by @​dependabot in peterevans/createpullrequest CC(random_uniform for int32 broken on GPU) build(depsdev): bump eslintimportresolvertypescript from 3.7.0 to 3.8.1 by @​dependabot in peterevans/createpullrequest CC(function.Defun can't be applied to tf.Variable) build(deps): bump @​octokit/pluginpaginaterest from 11.4.1 to 11.4.2 by @​dependabot in peterevans/createpullrequest CC(Explanation of blank label in ctc_loss) build(depsdev): bump @​types/node from 18.19.75 to 18.19.76 by @​dependabot in peterevans/createpullrequest CC(gather_nd not working with API examples) build(deps): bump @​octokit/core from 6.1.3 to 6.1.4 by @​dependabot in peterevans/createpullrequest CC(mnist_with_summaries.py error 'module' object has no attribute 'DT_HALF') Update distribution by @​actionsbot in peterevans/createpullrequest CC(Fix typo in TensorFlow Linear Model Tutorial) Use showFileAtRefBase64 to read percommit file contents by @​grahamc in peterevans/createpullrequest CC(extract element from list when py_func's output type is a single tensorflow type)  New Contributors  @​ybiquitous made their first contribution in peterevans/createpullrequest CC(contrib/makefile:  error: conflicting return type) @​grahamc made their first contribution in peterevans/createpullrequest CC(extract element from list when py_func's output type is a single tensorflow type)  Full Changelog: https://github.com/peterevans/createpullrequest/compare/v7.0.6...v7.0.7    Commits  dd2324f fix: use showFileAtRefBase64 to read percommit file contents ( CC(extract element from list when py_func's output type is a single tensorflow type)) 367180c ci: remove testv5 cmd 25575a1 build: update distribution ( CC(Fix typo in TensorFlow Linear Model Tutorial)) a56e7a5 build(deps): bump @​octokit/core from 6.1.3 to 6.1.4 ( CC(mnist_with_summaries.py error 'module' object has no attribute 'DT_HALF')) eac17dc build(depsdev): bump @​types/node from 18.19.75 to 18.19.76 ( CC(gather_nd not working with API examples)) a2e685f build(deps): bump @​octokit/pluginpaginaterest from 11.4.1 to 11.4.2 ( CC(Explanation of blank label in ctc_loss)) 6cfd146 build(depsdev): bump eslintimportresolvertypescript ( CC(function.Defun can't be applied to tf.Variable)) b38e8d3 build(depsdev): bump prettier from 3.5.0 to 3.5.1 ( CC(random_uniform for int32 broken on GPU)) 8a41570 build: update distribution ( CC(Benchmarking example for iOS profiling)) 2e9b4cc build(deps): bump @​octokit/endpoint from 10.1.2 to 10.1.3 ( CC(Cuda8)) Additional commits viewable in compare view    Updates `ossf/scorecardaction` from 2.4.0 to 2.4.1  Release notes Sourced from ossf/scorecardaction's releases.  v2.4.1 What's Changed  This update bumps the Scorecard version to the v5.1.1 release. For a complete list of changes, please refer to the v5.1.0 and v5.1.1 release notes. Publishing results now uses half the API quota as before. The exact savings depends on the repository in question.  use Scorecard library entrypoint instead of Cobra hooking by @​spencerschrock in ossf/scorecardaction CC(Need force_gpu_if_available for tests)   Some errors were made into annotations to make them more visible  Make default branch error more prominent by @​jsoref in ossf/scorecardaction CC(partial_run segfault)   There is now an optional file_mode input which controls how repository files are fetched from GitHub. The default is archive, but git produces the most accurate results for repositories with .gitattributes files at the cost of analysis speed.  add input for specifying filemode by @​spencerschrock in ossf/scorecardaction CC(Fix python3 b)   The underlying container for the action is now hosted on GitHub Container Registry. There should be no functional changes.  :seedling: publish docker images to GitHub Container Registry by @​spencerschrock in ossf/scorecardaction CC(Multidimensional RNN)    Docs  Installation docs update by @​JeremiahAHoward in ossf/scorecardaction CC(ci_build  debian jessie)  New Contributors  @​JeremiahAHoward made their first contribution in ossf/scorecardaction CC(ci_build  debian jessie) @​jsoref made their first contribution in ossf/scorecardaction CC(partial_run segfault) Full Changelog: https://github.com/ossf/scorecardaction/compare/v2.4.0...v2.4.1     Commits  f49aabe bump docker to ghcr v2.4.1 ( CC(Hardcoded bash path)) 30a595b :seedling: Bump github.com/sigstore/cosign/v2 from 2.4.2 to 2.4.3 ( CC(rnn.bidirectional_rnn  cause a problem)) 69ae593 omit vcs info from build ( CC(Bugfix to test/run_and_gather_logs.)) 6a62a1c add input for specifying filemode ( CC(Fix python3 b)) 2722664 :seedling: Bump the githubactions group with 2 updates ( CC(Delete useless directory)) ae0ef31 :seedling: Bump github.com/spf13/cobra from 1.8.1 to 1.9.1 ( CC(some learning decays from Stanford CS231n Karpathy lecture 6)) 3676bbc :seedling: Bump golang from 1.23.6 to 1.24.0 in the dockerimages group ( CC(seems issues with softmax_cross_entropy_with_logits)) ae7548a Limit codeQL push trigger to main branch ( CC(quick python3 fix)) 9165624 upgrade scorecard to v5.1.0 ( CC(Fix python3 breakage (oldstyle exception block))) 620fd28 :seedling: Bump the githubactions group with 2 updates ( CC(typos fix and ign temp files in gitignore)) Additional commits viewable in compare view    Updates `actions/uploadartifact` from 4.6.0 to 4.6.1  Release notes Sourced from actions/uploadartifact's releases.  v4.6.1 What's Changed  Update to use artifact 2.2.2 package by @​yacaovsnc in actions/uploadartifact CC(PoolAlloc: Remove div by zero, demote WARN>INFO)  Full Changelog: https://github.com/actions/uploadartifact/compare/v4...v4.6.1    Commits  4cec3d8 Merge pull request  CC(PoolAlloc: Remove div by zero, demote WARN>INFO) from actions/yacaovsnc/artifact_2.2.2 e9fad96 license cache update for artifact b26fd06 Update to use artifact 2.2.2 package See full diff in compare view    Updates `github/codeqlaction` from 3.28.8 to 3.28.10  Release notes Sourced from github/codeqlaction's releases.  v3.28.10 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.10  21 Feb 2025  Update default CodeQL bundle version to 2.20.5.  CC(Please consider adding flatten) Address an issue where the CodeQL Bundle would occasionally fail to decompress on macOS.  CC(Checkpoint Restore blocked by changed default bias variable name)  See the full CHANGELOG.md for more information. v3.28.9 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.9  07 Feb 2025  Update default CodeQL bundle version to 2.20.4.  CC(C++ compilation of rule '//:sip_hash' failed (Tensorflow serving on Android))  See the full CHANGELOG.md for more information.    Changelog Sourced from github/codeqlaction's changelog.  CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. [UNRELEASED] No user facing changes. 3.28.10  21 Feb 2025  Update default CodeQL bundle version to 2.20.5.  CC(Please consider adding flatten) Address an issue where the CodeQL Bundle would occasionally fail to decompress on macOS.  CC(Checkpoint Restore blocked by changed default bias variable name)  3.28.9  07 Feb 2025  Update default CodeQL bundle version to 2.20.4.  CC(C++ compilation of rule '//:sip_hash' failed (Tensorflow serving on Android))  3.28.8  29 Jan 2025  Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3.  CC(Fix for build issue 2742;)  3.28.7  29 Jan 2025 No user facing changes. 3.28.6  27 Jan 2025  Reenable debug artifact upload for CLI versions 2.20.3 or greater.  CC(Modifying MNIST example to distributed version: could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR)  3.28.5  24 Jan 2025  Update default CodeQL bundle version to 2.20.3.  CC(Branch 124290852)  3.28.4  23 Jan 2025 No user facing changes. 3.28.3  22 Jan 2025  Update default CodeQL bundle version to 2.20.2.  CC(Update roadmap.md) Fix an issue downloading the CodeQL Bundle from a GitHub Enterprise Server instance which occurred when the CodeQL Bundle had been synced to the instance using the CodeQL Action sync tool and the Actions runner did not have Zstandard installed.  CC(Branch 124251558) Uploading debug artifacts for CodeQL analysis is temporarily disabled.  CC(Tensorflow with Pyinstaller)  3.28.2  21 Jan 2025 No user facing changes. 3.28.1  10 Jan 2025  CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see this changelog post.  CC(Import error)    ... (truncated)   Commits  b56ba49 Merge pull request  CC(Isn't current tensorflowgit r0.9? ) from github/updatev3.28.109856c48b1 60c9c77 Update changelog for v3.28.10 9856c48 Merge pull request  CC(Segmentation fault on tensorflow 0.9.0) from github/redsun82/rust 9572e09 Rust: fix log string 1a52936 Rust: special case default setup cf7e909 Merge pull request  CC(Please consider adding flatten) from github/updatebundle/codeqlbundlev2.20.5 b7006aa Merge branch 'main' into updatebundle/codeqlbundlev2.20.5 cfedae7 Rust: throw configuration errors if requested and not correctly enabled 3971ed2 Merge branch 'main' into redsun82/rust d38c6e6 Merge pull request  CC(Bazel fail to resolve submodule tensorflow) from github/angelapwen/bumpoctokit Additional commits viewable in compare view    Updates `docker/setupbuildxaction` from 3.8.0 to 3.10.0  Release notes Sourced from docker/setupbuildxaction's releases.  v3.10.0  Bump @​docker/actionstoolkit from 0.54.0 to 0.56.0 in docker/setupbuildxaction CC(Can't find pngwutil.c building tensorflow)  Full Changelog: https://github.com/docker/setupbuildxaction/compare/v3.9.0...v3.10.0 v3.9.0  Bump @​docker/actionstoolkit from 0.48.0 to 0.54.0 in docker/setupbuildxaction CC(More details of Inception model?) docker/setupbuildxaction CC(gcc4.8.1 is unhappy with usage of auto* in conv_grad_ops.cc)  Full Changelog: https://github.com/docker/setupbuildxaction/compare/v3.8.0...v3.9.0    Commits  b5ca514 Merge pull request  CC(Can't find pngwutil.c building tensorflow) from docker/dependabot/npm_and_yarn/docker/actionsto... 1418a4e chore: update generated content 93acf83 build(deps): bump @​docker/actionstoolkit from 0.54.0 to 0.56.0 f7ce87c Merge pull request  CC(gcc4.8.1 is unhappy with usage of auto* in conv_grad_ops.cc) from docker/dependabot/npm_and_yarn/docker/actionsto... aa1e2a0 chore: update generated content 673e008 build(deps): bump @​docker/actionstoolkit from 0.53.0 to 0.54.0 ba31df4 Merge pull request  CC(More details of Inception model?) from docker/dependabot/npm_and_yarn/docker/actionsto... 5475af1 chore: update generated content acacad9 build(deps): bump @​docker/actionstoolkit from 0.48.0 to 0.53.0 6a25f98 Merge pull request  CC(Cifar10 example bug (batch 5 not loading)) from crazymax/bakev6 Additional commits viewable in compare view    Updates `docker/buildpushaction` from 6.13.0 to 6.15.0  Release notes Sourced from docker/buildpushaction's releases.  v6.15.0  Bump @​docker/actionstoolkit from 0.55.0 to 0.56.0 in docker/buildpushaction CC(Problematic links in official website)  Full Changelog: https://github.com/docker/buildpushaction/compare/v6.14.0...v6.15.0 v6.14.0  Bump @​docker/actionstoolkit from 0.53.0 to 0.55.0 in docker/buildpushaction CC(GLIBC error)  Full Changelog: https://github.com/docker/buildpushaction/compare/v6.13.0...v6.14.0    Commits  471d1dc Merge pull request  CC(Problematic links in official website) from docker/dependabot/npm_and_yarn/docker/actionst... b89ff0a chore: update generated content 1e3ae3a chore(deps): Bump @​docker/actionstoolkit from 0.55.0 to 0.56.0 b16f42f Merge pull request  CC(tf.get_variable() cannot recognize existing variables) from crazymax/buildxedge dc0fea5 ci: update buildx to edge and buildkit to latest 0adf995 Merge pull request  CC(GLIBC error) from docker/dependabot/npm_and_yarn/docker/actionst... d88cd28 chore: update generated content 3d09a6b chore(deps): Bump @​docker/actionstoolkit from 0.53.0 to 0.55.0 See full diff in compare view    Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting ` rebase`. [//]:  (dependabotautomergestart) [//]:  (dependabotautomergeend)   Dependabot commands and options  You can trigger Dependabot actions by commenting on this PR:  ` rebase` will rebase this PR  ` recreate` will recreate this PR, overwriting any edits that have been made to it  ` merge` will merge this PR after your CI passes on it  ` squash and merge` will squash and merge this PR after your CI passes on it  ` cancel merge` will cancel a previously requested merge and block automerging  ` reopen` will reopen this PR if it is closed  ` close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually  ` show  ignore conditions` will show all of the ignore conditions of the specified dependency  ` ignore  major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)  ` ignore  minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)  ` ignore ` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)  ` unignore ` will remove all of the ignore conditions of the specified dependency  ` unignore  ` will remove the ignore condition of the specified dependency and ignore conditions ",2025-03-01T08:27:20Z,ready to pull size:S dependencies github_actions,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88411
yi,copybara-service[bot],litert: LiteRT changes for GPU support,litert: LiteRT changes for GPU support  Update CheckCpuTensors() to check nodes with execution_plan() instead of   checking all nodes_and_registration(). This aligns with SubGraph::Invoke()   and works well after applying a Delegate.  Added ExternalLiteRtBufferContext::RegisterLiteRtBufferRequirement()   to register with C type LiteRtTensorBufferRequirements.  Update visibility,2025-03-01T01:30:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88396
llm,copybara-service[bot],Part2: Remove moved code createLegalizeTFXlaCallModuleToStablehloPass from tensorflow/compiler/mlir/lite/stablehlo,Part2: Remove moved code createLegalizeTFXlaCallModuleToStablehloPass from tensorflow/compiler/mlir/lite/stablehlo,2025-02-28T23:45:12Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88390
rag,copybara-service[bot],Define CAPI and Python API for chlo.ragged_dot.,Define CAPI and Python API for chlo.ragged_dot.,2025-02-28T22:44:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88383
rag,copybara-service[bot],Do not infer return type of chlo.ragged_dot.,Do not infer return type of chlo.ragged_dot.,2025-02-28T22:35:33Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88382
llm,copybara-service[bot],Part1: Migrate createLegalizeTFXlaCallModuleToStablehloPass to tensorflow/compiler/mlir/stablehlo,Part1: Migrate createLegalizeTFXlaCallModuleToStablehloPass to tensorflow/compiler/mlir/stablehlo,2025-02-28T21:37:36Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88378
yi,nassimus26,ERROR: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors,"for this code  (on colab https://colab.research.google.com/drive/1WKSgxQUSZp4Q5dHeq2HgJvjjVzxJUoqA?usp=sharing) :  ``` cnn = tf.keras.applications.EfficientNetV2B3(       include_top=False,       weights='imagenet',       input_tensor=None,       include_preprocessing=True,       input_shape = (300, 300, 3),       pooling=None,       classes = 2   ) def representative_dataset_gen():     for i in range(0):         yield [] converter = tf.lite.TFLiteConverter.from_keras_model(cnn) converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.target_spec.supported_types = [tf.int8]   extra line missing converter.experimental_new_quantizer = True converter.experimental_new_dynamic_range_quantizer = True converter.inference_output_type = tf.uint8 converter.experimental_new_converter = True converter.experimental_mlir_quantizer = True converter.experimental_enable_resource_variables = False converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_dataset_gen tflite_model = converter.convert() open(""cnn.tflite"", ""wb"").write(tflite_model) ``` And then  `!edgetpu_compiler s cnn.tflite` I am getting :  ``` Edge TPU Compiler version 16.0.384591198 Started a compilation timeout timer of 180 seconds. ERROR: Attempting to use a delegate that only supports staticsized tensors with a graph that has dynamicsized tensors. Compilation failed: Model failed in Tflite interpreter. Please ensure model can be loaded/run in Tflite interpreter. Compilation child process completed within timeout period. Compilation failed!  ``` I am fully aware that the Coral Dev Board team release the EdgeTPU Model version (efficientnetedgetpuL_quant_edgetpu.tflite) But I am not interested in the default generated EdgeTPU file, indeed I want to do something like this :  ``` cnn = tf.keras.applications.EfficientNetV2B3(..pooling=None,..) // no pooling  x = cnn(cnn.input) x = layers.AveragePooling2D(pool_size=(5, 5), strides=(5, 5), padding=""same"")(x) x = layers.Flatten()(x) mdl = models.Model(inputs = cnn.input, outputs =x) ``` And then build the TFLite and the EdgeTPU. Unfortunately it doesn't seems possible to do this directly on a TFLite or TFliteEdgeTPU model :        For example : how to apply the code above with this : EfficientB3 EDGE_TPU version ? And it seems the Coral Dev Board Team has rewrite the EfficientNet model from scratch, but they don't explain why or how to import their model implemented here TPU repo  By import I mean how to replace the pretrainded **tf.keras.applications.EfficientNetV2B3** with their model ?",2025-02-28T20:35:22Z,stat:awaiting response stale comp:lite TFLiteConverter,closed,0,5,https://github.com/tensorflow/tensorflow/issues/88361,"Hi,   I apologize for the delay in my response, I have been able to replicate the similar issue with your provided code and I'm also getting same error message please refer this gistfile so we will have to dig more into this issue and will update you. **Here is error log output for reference :** ``` Edge TPU Compiler version 16.0.384591198 Started a compilation timeout timer of 180 seconds. ERROR: Attempting to use a delegate that only supports staticsized tensors with a graph that has dynamicsized tensors. Compilation failed: Model failed in Tflite interpreter. Please ensure model can be loaded/run in Tflite interpreter. Compilation child process completed within timeout period. Compilation failed!  ``` Thank you for your cooperation and patience.","Hi  , thank you, what do you mean by : please refer this [gistfile] ?  What do you want me to do about it ?, I already write you a test case and publish it on this page. And I hope that the Edge compiler project is not dead, most of their converted models has been written with TF 1.x, and the compiler has not been updated since many years, and it seems not Open source.","Hi,  I apologize for the delayed response, sorry for the confusion I mean to say I am able to replicate the same behavior which you reported from my end so for further investigation from our end as reference I added gistfile As per the official documentation of TensorFlow models on the Edge TPU specifically Model requirements section the model must meet these basic requirements:  Tensor parameters are quantized (8bit fixedpoint numbers; int8 or uint8).  Tensor sizes are constant at compiletime (no dynamic sizes).  Model parameters (such as bias tensors) are constant at compiletime.  Tensors are either 1, 2, or 3dimensional. If a tensor has more than 3 dimensions, then only the 3 innermost dimensions may have a size greater than 1.  The model uses only the operations supported by the Edge TPU (see table 1 below). Please use tools like Netron to visualize your model and check for operations that produce dynamicshaped tensors. The Edge TPU requires models to be quantized to (8bit fixedpoint numbers; int8 or uint8). Make sure that the representative_dataset is correctly set and that the model is fully quantized. some layers or operations might not be supported by the Edge TPU. Please make sure that all layers in your model are compatible with Edge TPU. You can refer to the coral documentation for a list of supported operations. In some cases there are no dynamic size tensors in the graph but it has a control flow op, While op which classifies graph as dynamic graph that might be the cause for this. Thank you for your cooperation and understanding.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
rag,copybara-service[bot],[XLA:GPU] Fix RaggedAllToAllDecomposer when input and output buffers have different sizes.,"[XLA:GPU] Fix RaggedAllToAllDecomposer when input and output buffers have different sizes. We were doubling the size of the buffer to be able to use dynamicupdateslice, because by HLO semantics, if the update goes out of bound of the result, the update is not applied at all. The correct solution is to pad to `input_size + output_size`.",2025-02-28T18:21:56Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88350
rag,copybara-service[bot],[XLA:GPU] Constrain ragged-all-to-all layout.,[XLA:GPU] Constrain raggedalltoall layout. We can only support cases when ragged dimension (dim 0) is the most major dimension. This was all update are contiguous in memory. Layout of other dimensions doesn't matter.,2025-02-28T15:53:03Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88340
rag,copybara-service[bot],[XLA:GPU] Cover RaggedAllToAllDecomposer in collective e2e tests.,[XLA:GPU] Cover RaggedAllToAllDecomposer in collective e2e tests.,2025-02-28T13:49:20Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88333
llm,copybara-service[bot],Make Pathways IFRT client get GPU topology as well.,Make Pathways IFRT client get GPU topology as well.,2025-02-27T23:29:27Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88275
yi,copybara-service[bot],Disable `//xla/python/ifrt_proxy/integration_tests:executable_impl_test_tfrt_cpu` on ARM64,Disable `//xla/python/ifrt_proxy/integration_tests:executable_impl_test_tfrt_cpu` on ARM64 This test occasionally times out on ARM builds.,2025-02-27T21:30:51Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88268
yi,copybara-service[bot],Internal change only.,Internal change only.,2025-02-27T20:44:44Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88262
gemma,copybara-service[bot],[XLA] Remove extraneous `gemma2_2b_keras_jax.hlo` argument in wget.,[XLA] Remove extraneous `gemma2_2b_keras_jax.hlo` argument in wget.,2025-02-27T19:18:12Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88249
yi,Unknownuserfrommars,Tensorflow Website Out-of-date," Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2  Custom code Yes  OS platform and distribution Windows 11 24H2  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In tensorflow.org/install, everything is just so out of date. It started when i'm reading the chinese version of the install page (https://www.tensorflow.org/install?hl=zhcn): which is:   我们在以下 64 位系统上测试过 TensorFlow 并且这些系统支持 TensorFlow： Python 3.6–3.9     See the problem? it said: TensorFlow is tested and supported on the following 64bit systems: Python 3.63.9 But 3.6 is EOS like millions of years ago, so i scrolled down and saw the page last updated date: 20210825. But this may be that the people are lazy to translate them to chinese, so i changed my language to english. Better but it said TF supports Python 3.83.11, which is also not true. The date last updated for this is 20230324, almost two years ago. So, my question is: why is this so out of date? Like this is supposed to be the official website for tensorflow! In the main page (tensorflow.org), it said: TF 2.18 released (which is true), but the API docs version is actually v2.16.1, with a datelastupdated of 20240930. This is just so annoying. When people use a google search on 'Tensorflow', the first thing that they see is going to be the website, not the Github repo itself, so please update it. (Okay, if you're just too lazy to stay updated just post a message on the screen saying ""This page is no longer maintained so see the repo (link to repo)"" something like that)  Standalone code to reproduce the issue ```shell No code. ```  Relevant log output ```shell ```",2025-02-27T13:07:47Z,type:docs-bug type:bug,open,0,0,https://github.com/tensorflow/tensorflow/issues/88226
rag,weilhuan-quic,Qualcomm AI Engine Direct - Op Builders for 1P Models," WHAT 1. Conv2d 2. DepthwiseConv2d 3. AveragePool 4. MaxPool 5. DepthToSpace 6. SpaceToDepth 7. HardSwish 8. LeakyRelu 9. ResizeBilinear 10. Litert options for these op builders, unit test 11. update qnn_compiler_plugin_test with these op builders  TEST  qnn_compiler_plugin_test ``` [] Global test environment teardown [==========] 115 tests from 5 test suites ran. (3489 ms total) [  PASSED  ] 115 tests. ```  litert_options_test ``` [] Global test environment teardown [==========] 22 tests from 1 test suite ran. (0 ms total) [  PASSED  ] 22 tests ```",2025-02-27T10:49:15Z,awaiting review comp:lite ready to pull size:L,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88221
yi,clickbaron,Fix TOSA bytecode conversion and improve code readability," Bug Fix This PR fixes a critical bug in the TOSA conversion pipeline where `experimental_tflite_to_tosa_bytecode()` was trying to call `ExperimentalTFLiteToTosaBytecode` directly instead of through the `_pywrap_mlir` module.  Code Improvements Additionally, this PR improves code readability and reduces complexity by:  Adding a helper function for string encoding  Simplifying parameter defaults  Making code more consistent across functions  Testing Verified the fix resolves the original NameError by importing and using the function. Fixes CC([TOSA] NameError: name 'ExperimentalTFLiteToTosaBytecode' is not defined) ",2025-02-27T02:38:09Z,awaiting review size:M comp:lite-tosa,open,0,3,https://github.com/tensorflow/tensorflow/issues/88193,> [!IMPORTANT] > The terms of service for this installation has not been accepted. Please ask the Organization owners to visit the Gemini Code Assist Admin Console to sign it.,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.","Hi , Can you please sign CLA, Thank you !"
yi,copybara-service[bot],[XLA:GPU] Fix post-optimization pipeline parallelism tests,[XLA:GPU] Fix postoptimization pipeline parallelism tests These tests passed earlier (by chance). The underlying issue is the same as for the test fixed in cl/730568729.,2025-02-27T01:14:49Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88191
yi,copybara-service[bot],PR #23020: Bump github/codeql-action from 3.24.9 to 3.28.10,"PR CC(Error in C++ Tensorflow to load model trained by python): Bump github/codeqlaction from 3.24.9 to 3.28.10 Imported from GitHub PR https://github.com/openxla/xla/pull/23020 Bumps github/codeqlaction from 3.24.9 to 3.28.10.  Release notes Sourced from github/codeqlaction's releases.  v3.28.10 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.10  21 Feb 2025  Update default CodeQL bundle version to 2.20.5.  CC(Please consider adding flatten) Address an issue where the CodeQL Bundle would occasionally fail to decompress on macOS.  CC(Checkpoint Restore blocked by changed default bias variable name)  See the full CHANGELOG.md for more information. v3.28.9 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.9  07 Feb 2025  Update default CodeQL bundle version to 2.20.4.  CC(C++ compilation of rule '//:sip_hash' failed (Tensorflow serving on Android))  See the full CHANGELOG.md for more information. v3.28.8 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.8  29 Jan 2025  Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3.  CC(Fix for build issue 2742;)  See the full CHANGELOG.md for more information. v3.28.7 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.7  29 Jan 2025 No user facing changes. See the full CHANGELOG.md for more information. v3.28.6 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs.   ... (truncated)   Changelog Sourced from github/codeqlaction's changelog.  CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. [UNRELEASED] No user facing changes. 3.28.10  21 Feb 2025  Update default CodeQL bundle version to 2.20.5.  CC(Please consider adding flatten) Address an issue where the CodeQL Bundle would occasionally fail to decompress on macOS.  CC(Checkpoint Restore blocked by changed default bias variable name)  3.28.9  07 Feb 2025  Update default CodeQL bundle version to 2.20.4.  CC(C++ compilation of rule '//:sip_hash' failed (Tensorflow serving on Android))  3.28.8  29 Jan 2025  Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3.  CC(Fix for build issue 2742;)  3.28.7  29 Jan 2025 No user facing changes. 3.28.6  27 Jan 2025  Reenable debug artifact upload for CLI versions 2.20.3 or greater.  CC(Modifying MNIST example to distributed version: could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR)  3.28.5  24 Jan 2025  Update default CodeQL bundle version to 2.20.3.  CC(Branch 124290852)  3.28.4  23 Jan 2025 No user facing changes. 3.28.3  22 Jan 2025  Update default CodeQL bundle version to 2.20.2.  CC(Update roadmap.md) Fix an issue downloading the CodeQL Bundle from a GitHub Enterprise Server instance which occurred when the CodeQL Bundle had been synced to the instance using the CodeQL Action sync tool and the Actions runner did not have Zstandard installed.  CC(Branch 124251558) Uploading debug artifacts for CodeQL analysis is temporarily disabled.  CC(Tensorflow with Pyinstaller)  3.28.2  21 Jan 2025 No user facing changes. 3.28.1  10 Jan 2025  CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see this changelog post.  CC(Import error)    ... (truncated)   Commits  b56ba49 Merge pull request  CC(Isn't current tensorflowgit r0.9? ) from github/updatev3.28.109856c48b1 60c9c77 Update changelog for v3.28.10 9856c48 Merge pull request  CC(Segmentation fault on tensorflow 0.9.0) from github/redsun82/rust 9572e09 Rust: fix log string 1a52936 Rust: special case default setup cf7e909 Merge pull request  CC(Please consider adding flatten) from github/updatebundle/codeqlbundlev2.20.5 b7006aa Merge branch 'main' into updatebundle/codeqlbundlev2.20.5 cfedae7 Rust: throw configuration errors if requested and not correctly enabled 3971ed2 Merge branch 'main' into redsun82/rust d38c6e6 Merge pull request  CC(Bazel fail to resolve submodule tensorflow) from github/angelapwen/bumpoctokit Additional commits viewable in compare view    ![Dependabot compatibility score](https://docs.github.com/en/github/managingsecurityvulnerabilities/aboutdependabotsecurityupdatesaboutcompatibilityscores) Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting ` rebase`. [//]:  (dependabotautomergestart) [//]:  (dependabotautomergeend)   Dependabot commands and options  You can trigger Dependabot actions by commenting on this PR:  ` rebase` will rebase this PR  ` recreate` will recreate this PR, overwriting any edits that have been made to it  ` merge` will merge this PR after your CI passes on it  ` squash and merge` will squash and merge this PR after your CI passes on it  ` cancel merge` will cancel a previously requested merge and block automerging  ` reopen` will reopen this PR if it is closed  ` close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually  ` show  ignore conditions` will show all of the ignore conditions of the specified dependency  ` ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)  ` ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)  ` ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)  Copybara import of the project:  62ccec95e0caa348151e04d97d944e4bdee3dd58 by dependabot[bot] : Bump github/codeqlaction from 3.24.9 to 3.28.10 Bumps github/codeqlaction from 3.24.9 to 3.28.10.  Release notes  Changelog  Commits  updateddependencies:  dependencyname: github/codeqlaction   dependencytype: direct:production   updatetype: versionupdate:semverminor ... Signedoffby: dependabot[bot]  Merging this change closes CC(Error in C++ Tensorflow to load model trained by python) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23020 from openxla:dependabot/github_actions/github/codeqlaction3.28.10 62ccec95e0caa348151e04d97d944e4bdee3dd58",2025-02-26T23:40:00Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88180
yi,copybara-service[bot],PR #23018: Bump ossf/scorecard-action from 2.3.1 to 2.4.1,"PR CC(.): Bump ossf/scorecardaction from 2.3.1 to 2.4.1 Imported from GitHub PR https://github.com/openxla/xla/pull/23018 Bumps ossf/scorecardaction from 2.3.1 to 2.4.1.  Release notes Sourced from ossf/scorecardaction's releases.  v2.4.1 What's Changed  This update bumps the Scorecard version to the v5.1.1 release. For a complete list of changes, please refer to the v5.1.0 and v5.1.1 release notes. Publishing results now uses half the API quota as before. The exact savings depends on the repository in question.  use Scorecard library entrypoint instead of Cobra hooking by @​spencerschrock in ossf/scorecardaction CC(Need force_gpu_if_available for tests)   Some errors were made into annotations to make them more visible  Make default branch error more prominent by @​jsoref in ossf/scorecardaction CC(partial_run segfault)   There is now an optional file_mode input which controls how repository files are fetched from GitHub. The default is archive, but git produces the most accurate results for repositories with .gitattributes files at the cost of analysis speed.  add input for specifying filemode by @​spencerschrock in ossf/scorecardaction CC(Fix python3 b)   The underlying container for the action is now hosted on GitHub Container Registry. There should be no functional changes.  :seedling: publish docker images to GitHub Container Registry by @​spencerschrock in ossf/scorecardaction CC(Multidimensional RNN)    Docs  Installation docs update by @​JeremiahAHoward in ossf/scorecardaction CC(ci_build  debian jessie)  New Contributors  @​JeremiahAHoward made their first contribution in ossf/scorecardaction CC(ci_build  debian jessie) @​jsoref made their first contribution in ossf/scorecardaction CC(partial_run segfault) Full Changelog: https://github.com/ossf/scorecardaction/compare/v2.4.0...v2.4.1  v2.4.0 What's Changed This update bumps the Scorecard version to the v5 release. For a complete list of changes, please refer to the v5.0.0 release notes. Of special note to Scorecard Action is the Maintainer Annotation feature, which can be used to suppress some Code Scanning false positives. Alerts will not be generated for any Scorecard Check with an annotation.  :seedling: Bump github.com/ossf/scorecard/v5 from v5.0.0rc2 to v5.0.0 by @​spencerschrock in ossf/scorecardaction CC(tensorflor cond(pred, fn1, fn2) evaluate fn1 and fn2 together regardless of pred) :bug: lower license sarif alert threshold to 9 by @​spencerschrock in ossf/scorecardaction CC(Mac OS;import error ""ImportError: cannot import name _message"")  Documentation  docs: dogfooding badge by @​jkowalleck in ossf/scorecardaction CC(Error using tf.image.random._ : 'numpy.ndarray' object has no attribute 'get_shape')  New Contributors  @​jkowalleck made their first contribution in ossf/scorecardaction CC(Error using tf.image.random._ : 'numpy.ndarray' object has no attribute 'get_shape')  Full Changelog: https://github.com/ossf/scorecardaction/compare/v2.3.3...v2.4.0 v2.3.3  [!NOTE] There is no v2.3.2 release as a step was skipped in the release process. This was fixed and rereleased under the v2.3.3 tag  What's Changed  :seedling: Bump github.com/ossf/scorecard/v4 (v4.13.1) to github.com/ossf/scorecard/v5 (v5.0.0rc1) by @​spencerschrock in ossf/scorecardaction CC(Implement the Special Functions incbet,igam,igamc for CPU+GPU for float & double.) :seedling: Bump github.com/ossf/scorecard/v5 from v5.0.0rc1 to v5.0.0rc2 by @​spencerschrock in ossf/scorecardaction CC(Document trick with slash in scope names) :seedling: Bump github.com/ossf/scorecard/v5 from v5.0.0rc2 to v5.0.0rc2.0.202405091827347ce860946928 by @​spencerschrock in ossf/scorecardaction CC(Tensorflow Website : Missing Mathjax results in broken equations)  For a full changelist of what these include, see the v5.0.0rc1 and v5.0.0rc2 release notes. Documentation  :book: Move token discussion out of main README. by @​spencerschrock in ossf/scorecardaction CC(Arch doesn't support it)    ... (truncated)   Commits  f49aabe bump docker to ghcr v2.4.1 ( CC(Hardcoded bash path)) 30a595b :seedling: Bump github.com/sigstore/cosign/v2 from 2.4.2 to 2.4.3 ( CC(rnn.bidirectional_rnn  cause a problem)) 69ae593 omit vcs info from build ( CC(Bugfix to test/run_and_gather_logs.)) 6a62a1c add input for specifying filemode ( CC(Fix python3 b)) 2722664 :seedling: Bump the githubactions group with 2 updates ( CC(Delete useless directory)) ae0ef31 :seedling: Bump github.com/spf13/cobra from 1.8.1 to 1.9.1 ( CC(some learning decays from Stanford CS231n Karpathy lecture 6)) 3676bbc :seedling: Bump golang from 1.23.6 to 1.24.0 in the dockerimages group ( CC(seems issues with softmax_cross_entropy_with_logits)) ae7548a Limit codeQL push trigger to main branch ( CC(quick python3 fix)) 9165624 upgrade scorecard to v5.1.0 ( CC(Fix python3 breakage (oldstyle exception block))) 620fd28 :seedling: Bump the githubactions group with 2 updates ( CC(typos fix and ign temp files in gitignore)) Additional commits viewable in compare view    ![Dependabot compatibility score](https://docs.github.com/en/github/managingsecurityvulnerabilities/aboutdependabotsecurityupdatesaboutcompatibilityscores) Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting ` rebase`. [//]:  (dependabotautomergestart) [//]:  (dependabotautomergeend)   Dependabot commands and options  You can trigger Dependabot actions by commenting on this PR:  ` rebase` will rebase this PR  ` recreate` will recreate this PR, overwriting any edits that have been made to it  ` merge` will merge this PR after your CI passes on it  ` squash and merge` will squash and merge this PR after your CI passes on it  ` cancel merge` will cancel a previously requested merge and block automerging  ` reopen` will reopen this PR if it is closed  ` close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually  ` show  ignore conditions` will show all of the ignore conditions of the specified dependency  ` ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)  ` ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)  ` ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)  Copybara import of the project:  c459d962aa2a508b6d8c33dafe7cbf7ed8e8a034 by dependabot[bot] : Bump ossf/scorecardaction from 2.3.1 to 2.4.1 Bumps ossf/scorecardaction from 2.3.1 to 2.4.1.  Release notes  Changelog  Commits  updateddependencies:  dependencyname: ossf/scorecardaction   dependencytype: direct:production   updatetype: versionupdate:semverminor ... Signedoffby: dependabot[bot]  Merging this change closes CC(.) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/23018 from openxla:dependabot/github_actions/ossf/scorecardaction2.4.1 c459d962aa2a508b6d8c33dafe7cbf7ed8e8a034",2025-02-26T23:37:18Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88178
rag,copybara-service[bot],[XLA:GPU] Fix RaggedAllToAllDecomposer pass.,[XLA:GPU] Fix RaggedAllToAllDecomposer pass. There were two issues that are happening: 1. Update slice logic was not correct and would overwrite values outside of the update. 2. RaggedAllToAll API was extended to allow multiple updates per replica.,2025-02-26T22:46:55Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88170
gemma,copybara-service[bot],Update cpu_benchmarks.yml and gpu_benchmarks.yml to run the Gemma2-2B HLO.,Update cpu_benchmarks.yml and gpu_benchmarks.yml to run the Gemma22B HLO.,2025-02-26T21:40:45Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88164
llm,copybara-service[bot],[XlaCallModule] Add better error message to computation deserialization failures.,[XlaCallModule] Add better error message to computation deserialization failures.,2025-02-26T20:11:22Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/88158
yi,copybara-service[bot],[IFRT] Add short form for specifying platform_names for IFRT IR passes.,"[IFRT] Add short form for specifying platform_names for IFRT IR passes. Some IFRT IR passes require a list of platform names to be given as an option. Currently, a platform names list requires an entry for each device, which makes  manually running the passes on modules with many devices tedious. This change introduces a short form for specifying platform names with the format  platform_name:number_of_occurrences. For example, tpu:2,cpu:3 is expanded to tpu,tpu,cpu,cpu,cpu.",2025-02-25T19:48:59Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88071
yi,copybara-service[bot],Introduce `TPUDummyInput` as a specialization of `Fill` for ICI weight distribution.,"Introduce `TPUDummyInput` as a specialization of `Fill` for ICI weight distribution. The new op has a few benefits over the previous version: * We can generate a single op instead of three ops for each dummy input. * The new op is marked as `DoNotOptimize` and `TF_NoConstantFold`, so it will never be accidentally constantfolded to a large memory footprint.",2025-02-25T18:07:25Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/88059
rag,copybara-service[bot],Bump the priority of CHLO->MHLO ragged dot pass to highest.,Bump the priority of CHLO>MHLO ragged dot pass to highest.,2025-02-25T04:28:59Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87997
yi,diddlywob,Help with reference," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version 3.12.3  Bazel version _No response_  GCC/compiler version gcc (Ubuntu 13.3.06ubuntu2~24.04) 13.3.0  CUDA/cuDNN version CUDA 12.0  GPU model and memory NVIDIA GeForce RTX 4050  Current behavior? I am expecting my model to run without giving any type of warnings. I know for certain that my data does not have any NaN values in it, so I am not sure why am I getting the warning I am receiving. My output should look something like the below: 2138/14403 ━━━━━━━━━━━━━━━━━━━━ 2:45 14ms/step  accuracy: 0.7590  loss: 1.1440E0000 00:00:1740370043.647457  Standalone code to reproduce the issue ```shell I know the issue has to do with this part of the code. I am just not sure where. import os os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async' import math import pyarrow.parquet as pq import pandas as pd import numpy as np import tensorflow as tf from tensorflow.keras.regularizers import l2 from scipy.sparse import hstack, csr_matrix from tensorflow.keras.models import Model from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import OneHotEncoder from itertools import combinations   Initialize Encoders & Scaler  onehot_encoder = OneHotEncoder(handle_unknown=""ignore"", sparse_output=False) scaler = StandardScaler()   Stream Train/Test Split in Chunks  def stream_split_data(parquet_files, categorical_columns, numeric_columns):     """"""Splits merged data into training and testing sets dynamically in chunks.""""""     for chunk in stream_merged_data(parquet_files, categorical_columns, numeric_columns, merge_key):         mask = np.random.rand(len(chunk)) = end_idx:                 return   Stop when we reach end index             X_batch = X_chunk[i:i + batch_size]             y_batch = y_chunk[i:i + batch_size]             yield X_batch, y_batch             current_idx += batch_size   Create `tf.data.Dataset` Using the Chunked Generator  train_dataset = tf.data.Dataset.from_generator(     lambda: preprocess_dense_batches(parquet_files, categorical_columns, numeric_columns, batch_size, end_idx=int(train_ratio * total_rows)),     output_signature=(         tf.TensorSpec(shape=(None, one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model)), dtype=tf.float32),         tf.TensorSpec(shape=(None,), dtype=tf.float32)     ) ).repeat().prefetch(buffer_size=tf.data.AUTOTUNE) test_dataset = tf.data.Dataset.from_generator(     lambda: preprocess_dense_batches(parquet_files, categorical_columns, numeric_columns, batch_size, end_idx=total_rows),     output_signature=(         tf.TensorSpec(shape=(None, one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model)), dtype=tf.float32),         tf.TensorSpec(shape=(None,), dtype=tf.float32)     ) ).prefetch(buffer_size=tf.data.AUTOTUNE) class_weight_dict = {     0: 1.0,      1: 2.0,       2: 3.0    } steps_per_epoch = math.ceil((train_ratio * total_rows) / batch_size) test_steps = math.ceil(((1  train_ratio) * total_rows) / batch_size) print(""Datasets created dynamically."") input_all_data = Input(shape=(one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model),), name='all_data_input') print(""Creating the dense layers..."") x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(input_all_data) x = BatchNormalization()(x) x = Dropout(0.3)(x) x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x) x = BatchNormalization()(x) x = Dropout(0.3)(x) output = Dense(3, activation='softmax')(x)   3 neurons, softmax for multiclass  Compile the model model = Model(inputs=input_all_data, outputs=output) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) print(""\nBegin training the model.\n"") history_all_data = model.fit(     train_dataset,                         validation_data=test_dataset,          epochs=1,                         steps_per_epoch=steps_per_epoch,     validation_steps=test_steps,     class_weight=class_weight_dict,   Pass class weights     verbose=1 ) ```  Relevant log output ```shell WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1740371136.641692   17996 service.cc:148] XLA service 0x7f9fc4004850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: I0000 00:00:1740371136.642763   17996 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9 20250223 23:25:36.704967: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable. I0000 00:00:1740371136.874435   17996 cuda_dnn.cc:529] Loaded cuDNN version 90300 I0000 00:00:1740371138.351218   17996 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.  1490/14403 ━━━━━━━━━━━━━━━━━━━━ 3:33 17ms/step  accuracy: 0.5462  loss: 2.3473E0000 00:00:1740371164.392105   17996 buffer_comparator.cc:157] Difference at 0: nan, expected 1.65142 E0000 00:00:1740371164.392245   17996 buffer_comparator.cc:157] Difference at 1: nan, expected 1.48098 E0000 00:00:1740371164.392259   17996 buffer_comparator.cc:157] Difference at 2: nan, expected 1.67361 E0000 00:00:1740371164.392283   17996 buffer_comparator.cc:157] Difference at 3: nan, expected 3.16466 E0000 00:00:1740371164.392288   17996 buffer_comparator.cc:157] Difference at 4: nan, expected 2.17621 E0000 00:00:1740371164.392296   17996 buffer_comparator.cc:157] Difference at 5: nan, expected 3.38546 E0000 00:00:1740371164.392319   17996 buffer_comparator.cc:157] Difference at 6: nan, expected 1.67085 E0000 00:00:1740371164.392324   17996 buffer_comparator.cc:157] Difference at 7: nan, expected 1.38643 E0000 00:00:1740371164.392342   17996 buffer_comparator.cc:157] Difference at 8: nan, expected 1.76836 E0000 00:00:1740371164.392347   17996 buffer_comparator.cc:157] Difference at 9: nan, expected 3.48673 20250223 23:26:04.392363: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.  2967/14403 ━━━━━━━━━━━━━━━━━━━━ 2:58 16ms/step  accuracy: 0.5747  loss: 2.0899E0000 00:00:1740371185.763887   17997 buffer_comparator.cc:157] Difference at 0: nan, expected 3.13696 E0000 00:00:1740371185.764129   17997 buffer_comparator.cc:157] Difference at 1: nan, expected 3.33544 E0000 00:00:1740371185.764148   17997 buffer_comparator.cc:157] Difference at 2: nan, expected 2.92697 E0000 00:00:1740371185.764155   17997 buffer_comparator.cc:157] Difference at 3: nan, expected 2.59307 E0000 00:00:1740371185.764161   17997 buffer_comparator.cc:157] Difference at 4: nan, expected 2.88114 E0000 00:00:1740371185.764169   17997 buffer_comparator.cc:157] Difference at 5: nan, expected 2.56242 E0000 00:00:1740371185.764175   17997 buffer_comparator.cc:157] Difference at 6: nan, expected 2.62881 E0000 00:00:1740371185.764181   17997 buffer_comparator.cc:157] Difference at 7: nan, expected 2.84552 E0000 00:00:1740371185.764234   17997 buffer_comparator.cc:157] Difference at 8: nan, expected 2.49929 E0000 00:00:1740371185.764246   17997 buffer_comparator.cc:157] Difference at 9: nan, expected 2.47989 20250223 23:26:25.764275: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision. ```",2025-02-24T05:00:27Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/87925,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Internal change for visibility,Internal change for visibility,2025-02-24T04:42:53Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87920
yi,diddlywob,Results Do Not Match Reference," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version 3.12.3  Bazel version _No response_  GCC/compiler version gcc (Ubuntu 13.3.06ubuntu2~24.04) 13.3.0  CUDA/cuDNN version CUDA 12.0  GPU model and memory NVIDIA GeForce RTX 4050  Current behavior? I am expecting my model to run without giving any type of warnings. I know for certain that my data does not have any NaN values in it, so I am not sure why am I getting the warning I am receiving. My output should look something like the below: 2138/14403 ━━━━━━━━━━━━━━━━━━━━ 2:45 14ms/step  accuracy: 0.7590  loss: 1.1440E0000 00:00:1740370043.647457  Standalone code to reproduce the issue ```shell import os os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async' import math import pyarrow.parquet as pq import pandas as pd import numpy as np import tensorflow as tf from tensorflow.keras.regularizers import l2 from scipy.sparse import hstack, csr_matrix from tensorflow.keras.models import Model from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import OneHotEncoder from itertools import combinations   Initialize Encoders & Scaler  onehot_encoder = OneHotEncoder(handle_unknown=""ignore"", sparse_output=False) scaler = StandardScaler()   Stream Train/Test Split in Chunks  def stream_split_data(parquet_files, categorical_columns, numeric_columns):     """"""Splits merged data into training and testing sets dynamically in chunks.""""""     for chunk in stream_merged_data(parquet_files, categorical_columns, numeric_columns, merge_key):         np.random.seed(42)   Ensures the split is always the same upon restarting         mask = np.random.rand(len(chunk)) = end_idx:                 return   Stop when we reach end index             X_batch = X_chunk[i:i + batch_size]             y_batch = y_chunk[i:i + batch_size]             yield X_batch, y_batch             current_idx += batch_size   Create `tf.data.Dataset` Using the Chunked Generator  train_dataset = tf.data.Dataset.from_generator(     lambda: preprocess_dense_batches(parquet_files, categorical_columns, numeric_columns, batch_size, end_idx=int(train_ratio * total_rows)),     output_signature=(         tf.TensorSpec(shape=(None, one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model)), dtype=tf.float32),         tf.TensorSpec(shape=(None,), dtype=tf.float32)     ) ).repeat().prefetch(buffer_size=tf.data.AUTOTUNE) test_dataset = tf.data.Dataset.from_generator(     lambda: preprocess_dense_batches(parquet_files, categorical_columns, numeric_columns, batch_size, end_idx=total_rows),     output_signature=(         tf.TensorSpec(shape=(None, one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model)), dtype=tf.float32),         tf.TensorSpec(shape=(None,), dtype=tf.float32)     ) ).prefetch(buffer_size=tf.data.AUTOTUNE)   Class Weights Handling  class_weight_dict = {     0: 1.0,   Pushes (0.5)     1: 2.0,   Misses (0)     2: 3.0    Hits (1) }   Calculate Steps per Epoch  steps_per_epoch = math.ceil((train_ratio * total_rows) / batch_size) test_steps = math.ceil(((1  train_ratio) * total_rows) / batch_size) print(""Datasets created dynamically."")   Define Your Neural Network (Unchanged)  input_all_data = Input(shape=(one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model),), name='all_data_input') print(""Creating the dense layers..."")  Create the dense layers x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(input_all_data) x = BatchNormalization()(x) x = Dropout(0.3)(x) x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x) x = BatchNormalization()(x) x = Dropout(0.3)(x) output = Dense(3, activation='softmax')(x)   3 neurons, softmax for multiclass print(""Compiling the model..."")  Compile the model model = Model(inputs=input_all_data, outputs=output) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])   Train Model Using Existing Training Loop  print(""\nBegin training the model.\n"") history_all_nfl_data = model.fit(     train_dataset,                     Training dataset     validation_data=test_dataset,      Testing dataset     epochs=1,                         steps_per_epoch=steps_per_epoch,     validation_steps=test_steps,     class_weight=class_weight_dict,   Pass class weights     verbose=1 ) ```  Relevant log output ```shell WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1740371136.641692   17996 service.cc:148] XLA service 0x7f9fc4004850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: I0000 00:00:1740371136.642763   17996 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9 20250223 23:25:36.704967: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable. I0000 00:00:1740371136.874435   17996 cuda_dnn.cc:529] Loaded cuDNN version 90300 I0000 00:00:1740371138.351218   17996 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.  1490/14403 ━━━━━━━━━━━━━━━━━━━━ 3:33 17ms/step  accuracy: 0.5462  loss: 2.3473E0000 00:00:1740371164.392105   17996 buffer_comparator.cc:157] Difference at 0: nan, expected 1.65142 E0000 00:00:1740371164.392245   17996 buffer_comparator.cc:157] Difference at 1: nan, expected 1.48098 E0000 00:00:1740371164.392259   17996 buffer_comparator.cc:157] Difference at 2: nan, expected 1.67361 E0000 00:00:1740371164.392283   17996 buffer_comparator.cc:157] Difference at 3: nan, expected 3.16466 E0000 00:00:1740371164.392288   17996 buffer_comparator.cc:157] Difference at 4: nan, expected 2.17621 E0000 00:00:1740371164.392296   17996 buffer_comparator.cc:157] Difference at 5: nan, expected 3.38546 E0000 00:00:1740371164.392319   17996 buffer_comparator.cc:157] Difference at 6: nan, expected 1.67085 E0000 00:00:1740371164.392324   17996 buffer_comparator.cc:157] Difference at 7: nan, expected 1.38643 E0000 00:00:1740371164.392342   17996 buffer_comparator.cc:157] Difference at 8: nan, expected 1.76836 E0000 00:00:1740371164.392347   17996 buffer_comparator.cc:157] Difference at 9: nan, expected 3.48673 20250223 23:26:04.392363: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.  2967/14403 ━━━━━━━━━━━━━━━━━━━━ 2:58 16ms/step  accuracy: 0.5747  loss: 2.0899E0000 00:00:1740371185.763887   17997 buffer_comparator.cc:157] Difference at 0: nan, expected 3.13696 E0000 00:00:1740371185.764129   17997 buffer_comparator.cc:157] Difference at 1: nan, expected 3.33544 E0000 00:00:1740371185.764148   17997 buffer_comparator.cc:157] Difference at 2: nan, expected 2.92697 E0000 00:00:1740371185.764155   17997 buffer_comparator.cc:157] Difference at 3: nan, expected 2.59307 E0000 00:00:1740371185.764161   17997 buffer_comparator.cc:157] Difference at 4: nan, expected 2.88114 E0000 00:00:1740371185.764169   17997 buffer_comparator.cc:157] Difference at 5: nan, expected 2.56242 E0000 00:00:1740371185.764175   17997 buffer_comparator.cc:157] Difference at 6: nan, expected 2.62881 E0000 00:00:1740371185.764181   17997 buffer_comparator.cc:157] Difference at 7: nan, expected 2.84552 E0000 00:00:1740371185.764234   17997 buffer_comparator.cc:157] Difference at 8: nan, expected 2.49929 E0000 00:00:1740371185.764246   17997 buffer_comparator.cc:157] Difference at 9: nan, expected 2.47989 20250223 23:26:25.764275: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision. ```",2025-02-24T04:41:34Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/87919,Are you satisfied with the resolution of your issue? Yes No
yi,diddlywob,Results do not match the reference. This is likely a bug/unexpected loss of precision.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version 3.12.3  Bazel version _No response_  GCC/compiler version gcc (Ubuntu 13.3.06ubuntu2~24.04) 13.3.0  CUDA/cuDNN version CUDA 12.0  GPU model and memory NVIDIA GeForce RTX 4050  Current behavior? I am simply expecting my model to run without giving any type of warnings. I know for certain that my data does not have any NaN values in it, so I am not sure why am I getting the warning I am receiving. My output should look something like the below:  2138/14403 ━━━━━━━━━━━━━━━━━━━━ 2:45 14ms/step  accuracy: 0.7590  loss: 1.1440E0000 00:00:1740370043.647457    Standalone code to reproduce the issue ```shell import os os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async' import math import pyarrow.parquet as pq import pandas as pd import numpy as np import tensorflow as tf from tensorflow.keras.regularizers import l2 from scipy.sparse import hstack, csr_matrix from tensorflow.keras.models import Model from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import OneHotEncoder from itertools import combinations   Initialize Encoders & Scaler  onehot_encoder = OneHotEncoder(handle_unknown=""ignore"", sparse_output=False) scaler = StandardScaler()   Stream Train/Test Split in Chunks  def stream_split_data(parquet_files, categorical_columns, numeric_columns):     """"""Splits merged data into training and testing sets dynamically in chunks.""""""     for chunk in stream_merged_data(parquet_files, categorical_columns, numeric_columns, merge_key):         np.random.seed(42)   Ensures the split is always the same upon restarting         mask = np.random.rand(len(chunk)) = end_idx:                 return   Stop when we reach end index             X_batch = X_chunk[i:i + batch_size]             y_batch = y_chunk[i:i + batch_size]             yield X_batch, y_batch             current_idx += batch_size   Create `tf.data.Dataset` Using the Chunked Generator  train_dataset = tf.data.Dataset.from_generator(     lambda: preprocess_dense_batches(parquet_files, categorical_columns, numeric_columns, batch_size, end_idx=int(train_ratio * total_rows)),     output_signature=(         tf.TensorSpec(shape=(None, one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model)), dtype=tf.float32),         tf.TensorSpec(shape=(None,), dtype=tf.float32)     ) ).repeat().prefetch(buffer_size=tf.data.AUTOTUNE) test_dataset = tf.data.Dataset.from_generator(     lambda: preprocess_dense_batches(parquet_files, categorical_columns, numeric_columns, batch_size, end_idx=total_rows),     output_signature=(         tf.TensorSpec(shape=(None, one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model)), dtype=tf.float32),         tf.TensorSpec(shape=(None,), dtype=tf.float32)     ) ).prefetch(buffer_size=tf.data.AUTOTUNE)   Class Weights Handling  class_weight_dict = {     0: 1.0,   Pushes (0.5)     1: 2.0,   Misses (0)     2: 3.0    Hits (1) }   Calculate Steps per Epoch  steps_per_epoch = math.ceil((train_ratio * total_rows) / batch_size) test_steps = math.ceil(((1  train_ratio) * total_rows) / batch_size) print(""Datasets created dynamically."")   Define Your Neural Network (Unchanged)  input_all_data = Input(shape=(one_hot_encoder.transform(pd.DataFrame([[""0""] * len(categorical_columns)], columns=categorical_columns)).shape[1] + len(numeric_columns_for_model),), name='all_data_input') print(""Creating the dense layers..."")  Create the dense layers x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(input_all_data) x = BatchNormalization()(x) x = Dropout(0.3)(x) x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x) x = BatchNormalization()(x) x = Dropout(0.3)(x) output = Dense(3, activation='softmax')(x)   3 neurons, softmax for multiclass classification (hit, miss, push) print(""Compiling the model..."")  Compile the model model = Model(inputs=input_all_nfl_data, outputs=output) model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])   Train Model Using Existing Training Loop  print(""\nBegin training the model.\n"") history_all_nfl_data = model.fit(     train_dataset,                     Training dataset     validation_data=test_dataset,      Testing dataset     epochs=1,                         steps_per_epoch=steps_per_epoch,     validation_steps=test_steps,     class_weight=class_weight_dict,   Pass class weights     verbose=1 ) ```  Relevant log output ```shell WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1740371136.641692   17996 service.cc:148] XLA service 0x7f9fc4004850 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: I0000 00:00:1740371136.642763   17996 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4050 Laptop GPU, Compute Capability 8.9 20250223 23:25:36.704967: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable. I0000 00:00:1740371136.874435   17996 cuda_dnn.cc:529] Loaded cuDNN version 90300 I0000 00:00:1740371138.351218   17996 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.  1490/14403 ━━━━━━━━━━━━━━━━━━━━ 3:33 17ms/step  accuracy: 0.5462  loss: 2.3473E0000 00:00:1740371164.392105   17996 buffer_comparator.cc:157] Difference at 0: nan, expected 1.65142 E0000 00:00:1740371164.392245   17996 buffer_comparator.cc:157] Difference at 1: nan, expected 1.48098 E0000 00:00:1740371164.392259   17996 buffer_comparator.cc:157] Difference at 2: nan, expected 1.67361 E0000 00:00:1740371164.392283   17996 buffer_comparator.cc:157] Difference at 3: nan, expected 3.16466 E0000 00:00:1740371164.392288   17996 buffer_comparator.cc:157] Difference at 4: nan, expected 2.17621 E0000 00:00:1740371164.392296   17996 buffer_comparator.cc:157] Difference at 5: nan, expected 3.38546 E0000 00:00:1740371164.392319   17996 buffer_comparator.cc:157] Difference at 6: nan, expected 1.67085 E0000 00:00:1740371164.392324   17996 buffer_comparator.cc:157] Difference at 7: nan, expected 1.38643 E0000 00:00:1740371164.392342   17996 buffer_comparator.cc:157] Difference at 8: nan, expected 1.76836 E0000 00:00:1740371164.392347   17996 buffer_comparator.cc:157] Difference at 9: nan, expected 3.48673 20250223 23:26:04.392363: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision.  2967/14403 ━━━━━━━━━━━━━━━━━━━━ 2:58 16ms/step  accuracy: 0.5747  loss: 2.0899E0000 00:00:1740371185.763887   17997 buffer_comparator.cc:157] Difference at 0: nan, expected 3.13696 E0000 00:00:1740371185.764129   17997 buffer_comparator.cc:157] Difference at 1: nan, expected 3.33544 E0000 00:00:1740371185.764148   17997 buffer_comparator.cc:157] Difference at 2: nan, expected 2.92697 E0000 00:00:1740371185.764155   17997 buffer_comparator.cc:157] Difference at 3: nan, expected 2.59307 E0000 00:00:1740371185.764161   17997 buffer_comparator.cc:157] Difference at 4: nan, expected 2.88114 E0000 00:00:1740371185.764169   17997 buffer_comparator.cc:157] Difference at 5: nan, expected 2.56242 E0000 00:00:1740371185.764175   17997 buffer_comparator.cc:157] Difference at 6: nan, expected 2.62881 E0000 00:00:1740371185.764181   17997 buffer_comparator.cc:157] Difference at 7: nan, expected 2.84552 E0000 00:00:1740371185.764234   17997 buffer_comparator.cc:157] Difference at 8: nan, expected 2.49929 E0000 00:00:1740371185.764246   17997 buffer_comparator.cc:157] Difference at 9: nan, expected 2.47989 20250223 23:26:25.764275: E external/local_xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:987] Results do not match the reference. This is likely a bug/unexpected loss of precision. ```",2025-02-24T04:27:53Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/87918,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Clear out XLA computations from compilation caches after finalizing the TensorFlow session.,"Clear out XLA computations from compilation caches after finalizing the TensorFlow session. After compiling a TF Graph into an XLA HLO program and after compiling the HLO into an executable, we keep around a `std::shared_ptrcomputation`. When the compiled HLO contains many constants, its heap memory consumption is significant and otherwise unreferenced after initialization. This CL adds an entrypoint `DeviceCompilationCache::Finalize`, which is exposed as `DeviceCompiler::Finalize`, which is an implementation of the virtual function `ResourceBase::Finalize`. `ResourceBase::Finalize` returns `absl::AnyInvocable` so that we can defer destruction of finalized objects owned by `ResourceBase` until after we release the lock `ResourceMgr::mu_`.",2025-02-24T00:17:54Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87909
yi,JacksonDivakar,Inconsistent Behavior When Using tf.keras.metrics.Accuracy with F1-Score and Precision," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux Ubuntu 24.0  Mobile device _No response_  Python version 3.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? !Image !Image !Image  Standalone code to reproduce the issue ```shell 1)Compile a model using tf.keras.metrics.Accuracy() along with custom F1score and precision metrics. 2)Observe the incorrect behavior in the reported accuracy. 3)Compare with behavior when using ""accuracy"" in the metrics list. Link : https://github.com/JacksonDivakarProjects/Others/blob/main/accuracy_issue%20(2).ipynb ```  Relevant log output ```shell ```",2025-02-23T06:34:05Z,stat:awaiting response type:bug stale type:others comp:keras TF 2.18,closed,0,4,https://github.com/tensorflow/tensorflow/issues/87893,"Hi **** , Please post this issue on kerasteam/keras repo. as this issue is more related to keras Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Internal change of visibility,Internal change of visibility,2025-02-22T20:22:04Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87879
llm,copybara-service[bot],"Move the sharding axes from dimensions that need replication to batch dimensions, such that we replace an `all-gather` with an `all-to-all`.","Move the sharding axes from dimensions that need replication to batch dimensions, such that we replace an `allgather` with an `alltoall`. Given the following input ``` ENTRY entry {   %param0 = f32[14,257] parameter(0), sharding={devices=[1,2]0,1}   %param1 = f32[14,116] parameter(1), sharding={devices=[1,2]0,1}   ROOT %concatenate = f32[14,373] concatenate(%param0, %param1),     dimensions={1}, sharding={devices=[1,2]0,1} } ``` Previously, we (1) replicate the input along the concat dimension, (2) apply concat, (3) partition the result with dynamicslice. With this change, we (1) use alltoall to move sharding axis from the concat dim to batch dim for operands, (2) apply concat, and then (3) use alltoall to reshard the result. Reverts 81b0a48fcf8618fdab0a03907b05a65413399585",2025-02-22T01:34:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87841
rag,LaithMustafa,spam," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible). ``` (You can paste links or attach files by dragging & dropping them below)  Provide links to your updated versions of the above two colab notebooks.  Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model. ```  Option B: Paste your code here or provide a link to a custom endtoend colab ``` (You can paste links or attach files by dragging & dropping them below)  Include code to invoke the TFLite Converter Python API and the errors.  Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model. ```  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2025-02-21T18:02:20Z,invalid TFLiteConverter,closed,0,1,https://github.com/tensorflow/tensorflow/issues/87796,Please don't spam.
yi,copybara-service[bot],Internal change for visibility,Internal change for visibility,2025-02-21T05:49:16Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87734
yi,copybara-service[bot],"Adds visibility restriction to some XLA bzl files to prevent them from being used outside of XLA, as they are internal implementation details.","Adds visibility restriction to some XLA bzl files to prevent them from being used outside of XLA, as they are internal implementation details. This CL is not complete. It's the first step that establishes the mechanism. Once I get buyin on the approach, I'll follow up with more CLs to add visibility restriction to the other XLA bazl files.",2025-02-20T23:21:27Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87718
yi,copybara-service[bot],[tsl:concurrency] Micro optimizations for AsyncValue::AndThen,"[tsl:concurrency] Micro optimizations for AsyncValue::AndThen Instead of relying on absl::AnyInvocable keep Waiter directly in the linked list node, this improves performance by: 1. Avoiding one extra heap allocation for the absl::AnyInvocable 2. Remove one pointer indirection in RunWaiters BEFORE:  Benchmark                      Time             CPU   Iterations  BM_AddAndThenCallback       20.3 ns         20.3 ns     34354892 AFTER:  Benchmark                      Time             CPU   Iterations  BM_AddAndThenCallback       12.2 ns         12.2 ns     57932249",2025-02-20T22:58:49Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87714
rag,Schnipper24,Direction Problem after creating model / So after sucsessfully creating my Model and saving it automatic in the folder i need i get this message," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64Bit  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source): abslpy==1.0.0 appdirs==1.4.4 astunparse==1.6.3 attrs==22.1.0 audioread==3.0.0 cachetools==5.2.0 certifi==2022.9.24 cffi==1.15.1 chardet==5.0.0 charsetnormalizer==2.1.1 colorama==0.4.5 contourpy==1.0.5 cycler==0.11.0 Cython==0.29.32 dataclasses==0.6 decorator==5.1.1 dill==0.3.5.1 dmtree==0.1.7 etils==0.8.0 fire==0.4.0 flatbuffers==1.12 fonttools==4.37.4 gast==0.4.0 ginconfig==0.5.0 googleapicore==2.8.2 googleapipythonclient==2.64.0 googleauth==2.12.0 googleauthhttplib2==0.1.0 googleauthoauthlib==0.4.6 googlecloudbigquery==3.3.3 googlecloudbigquerystorage==2.16.0 googlecloudcore==2.3.2 googlecrc32c==1.5.0 googlepasta==0.2.0 googleresumablemedia==2.4.0 googleapiscommonprotos==1.56.4 grpcio==1.48.2 grpciostatus==1.48.2 h5py==3.1.0 httplib2==0.20.4 idna==3.4 importlibmetadata==5.0.0 importlibresources==5.9.0 joblib==1.2.0 kaggle==1.5.12 keras==2.9.0 kerasnightly==2.5.0.dev2021032900 KerasPreprocessing==1.1.2 kiwisolver==1.4.4 labelImg==1.8.6 libclang==14.0.6 librosa==0.8.1 llvmlite==0.36.0 lml==0.1.0 lxml==4.9.1 Markdown==3.4.1 MarkupSafe==2.1.1 matplotlib==3.4.3 neuralstructuredlearning==1.4.0 numba==0.53.0  2. Code Provide code to help us reproduce your issues using one of the following options:  https://www.tensorflow.org/lite/tutorials/model_maker_object_detection  https://github.com/tzutalin/labelImg import sys, getopt, time, pathlib from tflite_model_maker.config import ExportFormat from tflite_model_maker.config import QuantizationConfig from tflite_model_maker import model_spec from tflite_model_maker import object_detector def main(argv):     dir = None     batch_size = 8     epochs = 50     try:         opts, _ = getopt.getopt(argv, ""hd:b:e:"", [""help"",""directory="",""batchSize="",""epochs=""])         for opt, arg in opts:             print(opt + "":"" + arg)             if opt == ""h, help"":                 raise Exception()             elif opt in (""d"", ""directory""):                 dir = str(arg)             elif opt in (""b"", ""batchSize""):                 batch_size = int(arg)             elif opt in (""e"", ""epochs""):                 epochs = int(arg)         if (dir is None):             raise Exception()     except Exception:         print(""Specify a directory that contains your dataset."")         print(""createmodel.py d "")         sys.exit(2)     start = round(time.time() * 1000)      select object recognition model architecture     spec = model_spec.get(""efficientdet_lite0"")     spec.config.var_freeze_expr = ""(efficientnetresample_p6)""     spec.config.tflite_max_detections = 25     print(spec.config)      load input data specific to an ondevice ML app     train_data, validation_data, test_data = object_detector.DataLoader.from_csv(dir + ""/dataset.csv"")      customize the TensorFlow model     model = object_detector.create(         train_data,         model_spec=spec,         batch_size=batch_size,         epochs=epochs,         train_whole_model=False     )     model.summary()      evaluate the model     print(model.evaluate(test_data))      export to Tensorflow Lite model and label file in `export_dir`     path = pathlib.PurePath(dir)     model.export(export_dir=""build/"" + path.name + ""/"")     model.export(export_dir=""build/"" + path.name + ""/"", export_format=ExportFormat.LABEL)      evaluate the tensorflow lite model     print(model.evaluate_tflite(""build/"" + path.name + ""/model.tflite"", test_data))     stop = round(time.time() * 1000)     print(""process image: {} ms"".format(stop  start)) if __name__ == ""__main__"":    main(sys.argv[1:]) **So after sucsessfully creating my Model and saving it automatic in the folder i need i get this message:** Traceback (most recent call last):   File ""C:\Users\Robert\Desktop\IT_FischerTechnik_Klotz\Robert_KI\machinelearning\objectdetection\createmodel.py"", line 75, in      main(sys.argv[1:])   File ""C:\Users\Robert\Desktop\IT_FischerTechnik_Klotz\Robert_KI\machinelearning\objectdetection\createmodel.py"", line 69, in main     print(model.evaluate_tflite(""build/"" + path.name + ""/model.tflite"", test_data))   File ""C:\Users\Robert\AppData\Local\Programs\Python\Python39\lib\sitepackages\tensorflow_examples\lite\model_maker\core\task\object_detector.py"", line 155, in evaluate_tflite     return self.model_spec.evaluate_tflite(tflite_filepath, ds, len(data),   File ""C:\Users\Robert\AppData\Local\Programs\Python\Python39\lib\sitepackages\tensorflow_examples\lite\model_maker\core\task\model_spec\object_detector_spec.py"", line 373, in evaluate_tflite     lite_runner = eval_tflite.LiteRunner(tflite_filepath, only_network=False)   File ""C:\Users\Robert\AppData\Local\Programs\Python\Python39\lib\sitepackages\tensorflow_examples\lite\model_maker\third_party\efficientdet\keras\eval_tflite.py"", line 67, in __init__     self.interpreter = tf.lite.Interpreter(tflite_model_path)   File ""C:\Users\Robert\AppData\Local\Programs\Python\Python39\lib\sitepackages\tensorflow\lite\python\interpreter.py"", line 455, in __init__     _interpreter_wrapper.CreateWrapperFromFile( ValueError: Could not open 'build/ALLE_Klötze/model.tflite'. **I can even see the saved Model but still it says there is no file. I really dont know how to make it. (ROOKIE)** !Image",2025-02-20T22:29:17Z,TFLiteConverter,closed,0,1,https://github.com/tensorflow/tensorflow/issues/87708,I Guess i found the Answer by myself and changed the folder from Klötze to Kloetze and it was done .
yi,copybara-service[bot],#litert Add a automatically added accelerator compilation structure.,litert Add a automatically added accelerator compilation structure. This structure allows passing metadata that is generated during the model compilation onto accelerators when they alter the underlying runtime.,2025-02-20T21:54:55Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87705
rag,copybara-service[bot],[XLA] Partial rollback to the previous implementation so that hlo casting utils does not use tsl::down_cast and we can insert better debug information regarding which HLO and what subclasses are involved. Performance is identical to using tsl::down_cast since both implementations only call dynamic_cast under debug build. Updated comments and added test coverage are kept.,[XLA] Partial rollback to the previous implementation so that hlo casting utils does not use tsl::down_cast and we can insert better debug information regarding which HLO and what subclasses are involved. Performance is identical to using tsl::down_cast since both implementations only call dynamic_cast under debug build. Updated comments and added test coverage are kept.,2025-02-20T07:22:07Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87648
yi,copybara-service[bot],xla::ShardingPropagation. Avoid applying sharding constraints if the operand is used by multiple sharding constraints with different shardings.,"xla::ShardingPropagation. Avoid applying sharding constraints if the operand is used by multiple sharding constraints with different shardings. With `B = customcall(A), custom_call_target=""Sharding""`, we can set the sharding for A when all the three conditions are true. 1. Unspecified dims are empty. Otherwise, the sharding is open and can be further modified. 2. A has no sharding. We cannot overwrite the existing one. 3. A does not have other sharding constraints. A can have multiple sharding constraints with the same sharding. The first two conditions are checked before this cl. This cl add the third condition.",2025-02-20T00:20:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87611
rag,copybara-service[bot],Add a test for the `rng-bit-generator-expander` HLO optimization pass.,Add a test for the `rngbitgeneratorexpander` HLO optimization pass. This increases `rngbitgeneratorexpander` coverage from about 4% to about 89%.,2025-02-19T23:59:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87609
yi,Teun2305,Importerror keras," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.18  Custom code Yes  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When importing from keras I get an importerror. Reinstalling tensorflow does not work?  Standalone code to reproduce the issue ```shell from tensorflow.keras.models import Sequential ```  Relevant log output ```shell ImportError                               Traceback (most recent call last) File ~\anaconda3\envs\ml\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[14], line 1 > 1 from tensorflow.keras.models import Sequential       2 from tensorflow.keras.layers import Dense File ~\anaconda3\envs\ml\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\envs\ml\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:85      83     sys.setdlopenflags(_default_dlopen_flags)      84 except ImportError: > 85   raise ImportError(      86       f'{traceback.format_exc()}'      87       f'\n\nFailed to load the native TensorFlow runtime.\n'      88       f'See https://www.tensorflow.org/install/errors '      89       f'for some common causes and solutions.\n'      90       f'If you need help, create an issue '      91       f'at https://github.com/tensorflow/tensorflow/issues '      92       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\teunh_8dnilsp\anaconda3\envs\ml\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found. ```",2025-02-19T12:21:05Z,type:build/install,closed,0,2,https://github.com/tensorflow/tensorflow/issues/87565,Please search for similar issues before opening duplicates,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],"Use ""common"" instead of ""build"" for some flags in .bazelrc","Use ""common"" instead of ""build"" for some flags in .bazelrc Setting ""build"" options in the RC file prevents applying the flags to the query command. ""common"" works for both build and query commands. Flags like `experimental_cc_shared_library` changes the starlark semantics which forces refetching all repo rules when switching between commands. Ideally, more flags should be common instead of build.",2025-02-19T11:28:07Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87564
rag,copybara-service[bot],Update libtpu installation index path,"Update libtpu installation index path Update the libtpu installation index to https://storage.googleapis.com/libtpuwheels/index.html, which includes both stable and nightly libtpu versions, as per the cloud libtpu team's guidance. Also update the libtpu version in the setup.py. It starts to differ from the TF version to support JAX, and it requires manual updates for new releases for now.",2025-02-19T04:47:45Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87524
yi,knebojsa11,[RNN] Conversion of model containing GRU layer to quantized TFLite causes Segmentation Fault," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 22.04  TensorFlow installation (pip package or built from source): both pip package and built from source  TensorFlow library (version, if pip package or github SHA, if built from source): 2.18  2. Code import os os.environ[""TF_USE_LEGACY_KERAS""] = ""1"" import tensorflow as tf import numpy as np import tf_keras as keras def gru_model():     """"""Factory method for gru model.""""""     gru_input = keras.layers.Input(batch_input_shape=(1, 1, 64),                                     name=""gru_input"")     gru_state_in = keras.layers.Input(batch_input_shape=(1, 128),                                        name=""gru_state_in"")     gru_output, gru_state_out = keras.layers.GRU(128,                                                  activation=""tanh"",                                                  recurrent_activation=""sigmoid"",                                                  use_bias=True,                                                  return_sequences=False,                                                  bias_initializer=""random_uniform"",                                                  return_state=True)([gru_input, gru_state_in])     keras_model = keras.Model(inputs=[gru_input, gru_state_in], outputs=[gru_output, gru_state_out])     return keras_model model = gru_model() train_inputs = [tf.random.uniform((1, 1, 64), minval=1.0, maxval=32767.0/32768.0, dtype=tf.dtypes.float32),                 tf.random.uniform((1, 128), minval=1.0, maxval=32767.0/32768.0, dtype=tf.dtypes.float32)] train_outputs = tf.random.uniform((1, 128), minval=1.0, maxval=32767.0/32768.0, dtype=tf.dtypes.float32) model.compile(optimizer='adam', loss='mse', metrics=['mse']) model.fit([train_inputs], train_outputs, batch_size=1, epochs=1) model.summary() model.save(""ticket_gru.keras"") print(""Converting to floating point Tensorflow Lite"") converter_fp = tf.lite.TFLiteConverter.from_keras_model(model) converter_fp.optimizations = [tf.lite.Optimize.DEFAULT] converter_fp.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS] tflite_model_fp = converter_fp.convert() with open(""ticket_gru_fp.tflite"",""wb"") as f: f.write(tflite_model_fp) print(""Success converting to floating point Tensorflow Lite containing WHILE operator in \ subgraph 0 and cell implementation in subgraph 1"") print(""Converting to quantized Tensorflow Lite"") def representative_data():   for _ in range(10):     yield {model.inputs[0].name:tf.random.uniform((1, 1, 64), minval=1.0, maxval=32767.0/32768.0, dtype=tf.dtypes.float32, seed=None, name=None),            model.inputs[1].name:tf.random.uniform((1, 128), minval=1.0, maxval=32767.0/32768.0, dtype=tf.dtypes.float32, seed=None, name=None)} converter_q = tf.lite.TFLiteConverter.from_keras_model(model) converter_q.optimizations = [tf.lite.Optimize.DEFAULT] converter_q.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS] converter_q.inference_input_type = tf.int8 converter_q.inference_output_type = tf.int8 converter_q._experimental_disable_per_channel = True converter_q.representative_dataset = representative_data print(""Call to convert method of the converter_q will cause SEGFAULT during model calibration"") tflite_model_q = converter_q.convert() print(""This line is never reached"") with open(""ticket_gru_8_8.tflite"",""wb"") as f: f.write(tflite_model_q)  3. Failure after conversion Converter fails with throwing Segmentation fault. The fault is tracked down to the Calibration phase where the representative dataset is fead to the floating point model inferred by the interpreter instantiated by the converter. The main subgraph processing causes nested subgraph processing as a part of the WHILE operator invoke. All the operator in the nested subgraph are invoked, but the return from the model invoke ends with Segmentation Fault. The segmentation fault can be traced down to Tensorflow 2.14. Tensorflow 2.13 handles the quantized conversion properly. Conversion to floating point TFLite model works fine, and the floating point inference with same data that is used as representative dataset in quantized conversion does complete without problems  4. (optional) RNN conversion support Yes  RNN conversion support. Prefixed in the title as [RNN]  5. (optional) Any other info / logs 20250218 11:45:02.889542: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used. 20250218 11:45:04.329812: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303) 1/1 [==============================]  ETA: 0s  loss: 1.0199  gru_loss: 0.5099  gru_1_loss: 0.5099  gru_mse: 0.5099  gru_1_mse: 1/1 [==============================]  1s 1s/step  loss: 1.0199  gru_loss: 0.5099  gru_1_loss: 0.5099  gru_mse: 0.5099  gru_1_mse: 0.5099 Model: ""model"" __________________________________________________________________________________________________  Layer (type)                Output Shape                 Param    Connected to                   ==================================================================================================  gru_input (InputLayer)      [(1, 1, 64)]                 0         []                              gru_state_in (InputLayer)   [(1, 128)]                   0         []                              gru (GRU)                   [(1, 128),                   74496     ['gru_input[0][0]',                                          (1, 128)]                              'gru_state_in[0][0]']         ================================================================================================== Total params: 74496 (291.00 KB) Trainable params: 74496 (291.00 KB) Nontrainable params: 0 (0.00 Byte) __________________________________________________________________________________________________ Converting to floating point Tensorflow Lite WARNING: All log messages before absl::InitializeLog() is called are written to STDERR W0000 00:00:1739875508.650404  896323 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format. W0000 00:00:1739875508.650452  896323 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency. 20250218 11:45:08.650993: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp96nzf981 20250218 11:45:08.656672: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve } 20250218 11:45:08.656711: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmp96nzf981 I0000 00:00:1739875508.691084  896323 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled 20250218 11:45:08.698338: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle. 20250218 11:45:08.768960: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmp96nzf981 20250218 11:45:08.807201: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 156213 microseconds. 20250218 11:45:09.144839: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable. 20250218 11:45:09.264954: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 0.174 M  ops, equivalently 0.087 M  MACs Success converting to floating point Tensorflow Lite containing WHILE operator in subgraph 0 and cell implementation in subgraph 1 Converting to quantized Tensorflow Lite Call to convert method of the converter_q will cause SEGFAULT during model calibration /opt/samba/nxf35112/keras2_experiments/venv/lib/python3.10/sitepackages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.   warnings.warn( W0000 00:00:1739875512.496385  896323 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format. W0000 00:00:1739875512.496430  896323 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency. 20250218 11:45:12.496633: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpfx3q8bul 20250218 11:45:12.501629: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve } 20250218 11:45:12.501670: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpfx3q8bul 20250218 11:45:12.542409: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle. 20250218 11:45:12.609623: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpfx3q8bul 20250218 11:45:12.649789: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 153160 microseconds. 20250218 11:45:13.053211: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3893] Estimated count of arithmetic ops: 0.174 M  ops, equivalently 0.087 M  MACs Segmentation fault",2025-02-18T11:08:09Z,type:support comp:lite TFLiteConverter TF 2.18,open,0,3,https://github.com/tensorflow/tensorflow/issues/87468,"Hi,   I apologize for the delay in my response, I have been able to replicate the similar behavior from my end for reference here is gistfile so we'll have to dig more into this issue and will update you, thank you for bringing this issue to our attention. Thank you for your cooperation and patience.","Hi,  I apologize for the delay in my response, The error occurs because GRU layers have complex state management that conflicts with full integer quantization so if full integer quantization is not compulsary for your use case/ project you can go with either float16 Quantization or dynamic range quantization which is more compatible with RNN layers.  This is a limitation in the TensorFlow Lite quantization system when dealing with complex recurrent structures. GRU and LSTM layers involve internal states and complex cell implementations that the quantization process sometimes cannot properly handle resulting in segmentation faults during model calibration. I have tried from my end with float16 Quantization and dynamic range quantization it's working as expected for your reference here is gistfile Thank you for your cooperation and patience.",Dear   I really need the model to be fully quantized so I am interested if there are plans to fix the broken feature in the converter. Best Regards
agent,jwnhy,[CUDA] illegal memory read in ShuffleInTensor3Simple," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.18  Custom code Yes  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuDNN 90300  GPU model and memory H100 80G  Current behavior? computesanitizer detects invalid memory read.  Standalone code to reproduce the issue ```shell import tensorflow as tf from keras import layers import os os.environ[""TF_DISABLE_RZ_CHECK""] = ""1"" os.environ[""TF_GPU_ALLOCATOR""] = ""cuda_malloc_async"" tf.keras.backend.set_image_data_format('channels_first') gpus = tf.config.experimental.list_physical_devices('GPU') for gpu in gpus:     tf.config.experimental.set_memory_growth(gpu, True) tensor = tf.random.uniform([1, 79768, 2]) model = layers.Conv1D(filters=65470, kernel_size=1, strides=32827, groups=1) model(tensor) ```  Relevant log output ```shell ========= COMPUTESANITIZER ========= Invalid __global__ read of size 4 bytes =========     at void tensorflow::functor::ShuffleInTensor3Simple(int, const T1 *, tensorflow::functor::Dimension, T1 *)+0x630 =========     by thread (64,0,0) in block (84,0,0) =========     Address 0x32f9d8d188 is out of bounds =========     and is 5,845,702,776 bytes before the nearest allocation at 0x3456472a00 of size 20,889,643,840 bytes =========     Saved host backtrace up to driver entry point at kernel launch time =========     Host Frame: [0x37f187] =========                in /lib/x86_64linuxgnu/libcuda.so.1 =========     Host Frame: [0x15a13] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../../nvidia/cuda_runtime/lib/libcudart.so.12 =========     Host Frame:cudaLaunchKernel [0x75750] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../../nvidia/cuda_runtime/lib/libcudart.so.12 =========     Host Frame:absl::lts_20230802::Status tensorflow::GpuLaunchKernel, float*, int, float const*, tensorflow::functor::Dimension, float*>(void (*)(int, float const*, tensorflow::functor::Dimension, float*), dim3, dim3, unsigned long, CUstream_st*, int, float const*, tensorflow::functor::Dimension, float*) [0x2b5018e4] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::functor::TransformFilter::operator()(Eigen::GpuDevice const&, tensorflow::FilterTensorFormat, Eigen::TensorMap, 16, Eigen::MakePointer>, Eigen::TensorMap, 16, Eigen::MakePointer>) [0x2b5015ff] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:void tensorflow::LaunchConvOpImpl(tensorflow::OpKernelContext*, bool, tensorflow::Tensor const&, tensorflow::Tensor const&, absl::lts_20230802::InlinedVector > const&, absl::lts_20230802::InlinedVector > const&, tensorflow::Padding const&, std::vector > const&, tensorflow::TensorFormat, tensorflow::Tensor*) [0x29a96f55] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::Conv2DOp::Compute(tensorflow::OpKernelContext*) [0x29c03560] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) [0x6d474d4] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::(anonymous namespace)::SingleThreadedExecutorImpl::Run(tensorflow::Executor::Args const&) [0x6df8f47] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::FunctionLibraryRuntimeImpl::RunSync(tensorflow::FunctionLibraryRuntime::Options, unsigned long, absl::lts_20230802::Span, std::vector >*) [0x6db8723] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::ProcessFunctionLibraryRuntime::RunMultiDeviceSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, std::vector, std::allocator > >*, std::function) const [0x6dc572f] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::ProcessFunctionLibraryRuntime::RunSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, absl::lts_20230802::Span, std::vector >*) const [0x6dcbb7c] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector, std::allocator > >*, tsl::CancellationManager*, std::optional const&, std::optional const&, tsl::CoordinationServiceAgent*) [0x24f3ddef] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_20230802::InlinedVector > const&, std::optional const&, tsl::core::RefCountPtr const&, tensorflow::GraphCollector*, tsl::CancellationManager*, absl::lts_20230802::Span, std::optional const&) [0x24ee98d5] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::ExecuteNode::Run() [0x24ef33af] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) [0x24f39243] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) [0x24ee925a] ```",2025-02-18T05:14:25Z,type:bug comp:gpu TF 2.8,open,0,3,https://github.com/tensorflow/tensorflow/issues/87454,"Hi **** , Apologies for the delay, and thanks for raising your concern here. I observed that you are using an older version TensorFlow 2.8 which might be causing the issue. Could you please try using the latest version for better results? I ran your code on Colab using TensorFlow 2.18.0 with GPU, and it produced the following proper error message: ` ResourceExhaustedError: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[1,79768,65470] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0 [Op:StatelessRandomUniformV2] name:  ` This error indicates that the GPU is running out of memory (OOM) due to large tensor allocations. To resolve this, I reduced the memory requirements based on the model, and it worked fine for me. I am providing a gist here for your reference. Thank you!",Sorry I mistyped the version number... I found this issue on the latest tensorflow 2.18. I am using an H100 with 80GiB ram to find this issue. Can you try to reproduce this on a card with more ram?,The following is the environment I am using. ``` nvidiacublascu12        12.5.3.2                 pypi_0    pypi nvidiacudacupticu12    12.5.82                  pypi_0    pypi nvidiacudanvcccu12     12.5.82                  pypi_0    pypi nvidiacudanvrtccu12    12.5.82                  pypi_0    pypi nvidiacudaruntimecu12  12.5.82                  pypi_0    pypi nvidiacudnncu12         9.3.0.75                 pypi_0    pypi nvidiacufftcu12         11.2.3.61                pypi_0    pypi nvidiacurandcu12        10.3.6.82                pypi_0    pypi nvidiacusolvercu12      11.6.3.83                pypi_0    pypi nvidiacusparsecu12      12.5.1.3                 pypi_0    pypi nvidiancclcu12          2.21.5                   pypi_0    pypi nvidianvjitlinkcu12     12.5.82                  pypi_0    pypi openssl                   3.0.15               h5eee18b_0 opteinsum                3.4.0                    pypi_0    pypi optree                    0.14.0                   pypi_0    pypi packaging                 24.2                     pypi_0    pypi pexpect                   4.9.0                    pypi_0    pypi pip                       25.0            py312h06a4308_0 protobuf                  5.29.3                   pypi_0    pypi ptyprocess                0.7.0                    pypi_0    pypi pygments                  2.19.1                   pypi_0    pypi python                    3.12.9               h5148396_0 readline                  8.2                  h5eee18b_0 requests                  2.32.3                   pypi_0    pypi rich                      13.9.4                   pypi_0    pypi setuptools                75.8.0          py312h06a4308_0 six                       1.17.0                   pypi_0    pypi sqlite                    3.45.3               h5eee18b_0 tensorboard               2.18.0                   pypi_0    pypi tensorboarddataserver   0.7.2                    pypi_0    pypi tensorflow                2.18.0                   pypi_0    pypi ```
agent,jwnhy,[CUDA] illegal memory write in ShuffleInTensor3Simple," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.8.1  Custom code Yes  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version 3.12.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuDNN: 90300  GPU model and memory H100 80G  Current behavior? computesanitizer reports Illegal Memory Access. Expect: no IMA should occur.  Standalone code to reproduce the issue ```shell import tensorflow as tf from keras import layers import os os.environ[""TF_DISABLE_RZ_CHECK""] = ""1"" tf.keras.backend.set_image_data_format('channels_first') gpus = tf.config.experimental.list_physical_devices('GPU') for gpu in gpus:     tf.config.experimental.set_memory_growth(gpu, True) tensor = tf.random.uniform([2, 1, 392366]) model = layers.Conv1D(filters=2147483647, kernel_size=1, strides=392366, groups=1) model(tensor) ```  Relevant log output ```shell ========= COMPUTESANITIZER ========= Invalid __global__ write of size 4 bytes =========     at void tensorflow::functor::ShuffleInTensor3Simple(int, const T1 *, tensorflow::functor::Dimension, T1 *)+0x660 =========     by thread (128,0,0) in block (8,0,0) =========     Address 0x2e9c2ff600 is out of bounds =========     and is 517 bytes after the nearest allocation at 0x2c9c2ff400 of size 8,589,934,588 bytes =========     Saved host backtrace up to driver entry point at kernel launch time =========     Host Frame: [0x37f187] =========                in /lib/x86_64linuxgnu/libcuda.so.1 =========     Host Frame: [0x15a13] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../../nvidia/cuda_runtime/lib/libcudart.so.12 =========     Host Frame:cudaLaunchKernel [0x75750] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../../nvidia/cuda_runtime/lib/libcudart.so.12 =========     Host Frame:absl::lts_20230802::Status tensorflow::GpuLaunchKernel, float*, int, float const*, tensorflow::functor::Dimension, float*>(void (*)(int, float const*, tensorflow::functor::Dimension, float*), dim3, dim3, unsigned long, CUstream_st*, int, float const*, tensorflow::functor::Dimension, float*) [0x2b5018e4] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::functor::TransformFilter::operator()(Eigen::GpuDevice const&, tensorflow::FilterTensorFormat, Eigen::TensorMap, 16, Eigen::MakePointer>, Eigen::TensorMap, 16, Eigen::MakePointer>) [0x2b5015ff] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:void tensorflow::LaunchConvOpImpl(tensorflow::OpKernelContext*, bool, tensorflow::Tensor const&, tensorflow::Tensor const&, absl::lts_20230802::InlinedVector > const&, absl::lts_20230802::InlinedVector > const&, tensorflow::Padding const&, std::vector > const&, tensorflow::TensorFormat, tensorflow::Tensor*) [0x29a96f55] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::Conv2DOp::Compute(tensorflow::OpKernelContext*) [0x29c03560] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) [0x6d474d4] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::(anonymous namespace)::SingleThreadedExecutorImpl::Run(tensorflow::Executor::Args const&) [0x6df8f47] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::FunctionLibraryRuntimeImpl::RunSync(tensorflow::FunctionLibraryRuntime::Options, unsigned long, absl::lts_20230802::Span, std::vector >*) [0x6db8723] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::ProcessFunctionLibraryRuntime::RunMultiDeviceSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, std::vector, std::allocator > >*, std::function) const [0x6dc572f] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::ProcessFunctionLibraryRuntime::RunSync(tensorflow::FunctionLibraryRuntime::Options const&, unsigned long, absl::lts_20230802::Span, std::vector >*) const [0x6dcbb7c] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_framework.so.2 =========     Host Frame:tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector, std::allocator > >*, tsl::CancellationManager*, std::optional const&, std::optional const&, tsl::CoordinationServiceAgent*) [0x24f3ddef] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::lts_20230802::InlinedVector > const&, std::optional const&, tsl::core::RefCountPtr const&, tensorflow::GraphCollector*, tsl::CancellationManager*, absl::lts_20230802::Span, std::optional const&) [0x24ee98d5] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::ExecuteNode::Run() [0x24ef33af] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) [0x24f39243] =========                in /opt/ext/jwnhy/miniconda3/envs/tf218/lib/python3.12/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 =========     Host Frame:tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) [0x24ee925a] ```",2025-02-18T04:22:19Z,type:bug comp:gpu TF 2.8,open,0,2,https://github.com/tensorflow/tensorflow/issues/87438,"Hi **** , Apologies for the delay, and thanks for your patience. I ran your code on Colab using TensorFlow 2.18.0, and it threw the following error: ``` ResourceExhaustedError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name:  ``` This error occurs because the program is trying to allocate more GPU memory than is available. The issue seems to be caused by the large number of filters used in your model. To resolve this, I reduced the number of filters, and it worked fine for me. I am attaching a gist here for your reference. Thank you!",Sorry I mistyped the version number... I found this issue on the latest tensorflow 2.18. I am using an H100 with 80GiB ram to find this issue. Can you try to reproduce this on a card with more ram?
yi,datasciantle,NaN loss on multi-gpu training," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v1.12.1122039g784fed5357b 2.20.0dev20250211  Custom code Yes  OS platform and distribution Amazon Linux 2  Mobile device _No response_  Python version 3.10.14  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA 12.3 (Build V12.3.107)  GPU model and memory GPU Model: NVIDIA A10G Memory per GPU: 24 GB  Current behavior? I find that training a distributed model  with either MirroredStrategy or MultiWorkerMirroredStrategy  that the loss jumps to NaN on the 61st batch. The problem vanishes if I train on a single GPU (no distribute strategy), or if I use tf 2.13.1. The problem also vanishes if I set the number of steps per epoch to be less than 61. I've attached some reproducible code but note that I find the exact same finding (the role of batch 61, single GPU, v.2.13) on other datasets, other model architectures, and with different batch sizes.  Standalone code to reproduce the issue ```shell call this test.py  these pass python3 test.py steps_per_epoch 60 strategy None python3 test.py steps_per_epoch 60 strategy MirroredStrategy python3 test.py steps_per_epoch 60 strategy MultiWorkerMirroredStrategy python3 test.py steps_per_epoch 61 strategy None  these fail python3 test.py steps_per_epoch 61 strategy MirroredStrategy python3 test.py steps_per_epoch 61 strategy MultiWorkerMirroredStrategy import tensorflow as tf import numpy as np import argparse parser = argparse.ArgumentParser() parser.add_argument('batch_size', type=int, default=64) parser.add_argument('steps_per_epoch', type=int, default=128) parser.add_argument('strategy', type=str, default='None') args = parser.parse_args()  For reproducibility tf.random.set_seed(42) np.random.seed(42)  Parameters n_string = 256       used for the CLS token value n_features = 256    length of the output label vector dim_model = 64 batch_size = int(args.batch_size) steps_per_epoch = int(args.steps_per_epoch) def random_input(n_features, n_string):     """"""     Generate random input features in the integer domain.     """"""     return tf.random.uniform(shape=(n_features,), minval=0, maxval=n_string, dtype=tf.int32) def random_mask(input_features, batch_masking_rate):     """"""     Randomly mask input features in the integer domain.     Each element is retained with probability (1  batch_masking_rate) and zeroed otherwise.     """"""      Generate random values for each element in the same shape as input_features.     rand_vals = tf.random.uniform(shape=tf.shape(input_features), minval=0.0, maxval=1.0)      Create a binary mask: retain element if random value >= masking_rate, else 0.      This yields 1 with probability (1  batch_masking_rate) and 0 with probability batch_masking_rate.     mask = tf.cast(rand_vals >= batch_masking_rate, dtype=tf.int32)     return input_features * mask def process_example(output_label):     """"""     Given an output_label vector, generate a random masking rate,     apply random masking to produce input_features, and prepend a CLS token.     All operations remain in the integer domain.     """"""      Draw a random masking rate uniformly between 0 and 0.5.      (Note: masking_rate is used only for the masking decision and is not passed on.)     masking_rate = tf.random.uniform([], minval=0.0, maxval=0.5)      output_label is already an integer tensor.     masked_input = random_mask(output_label, masking_rate)      Return a features dictionary and a labels dictionary.     features = {""input_features"": masked_input}     labels = {""the_label"": output_label}     return features, labels def make_dataset(num_examples, n_features, n_string, batch_size):     """"""     Create a tf.data.Dataset of random output labels.     Each output label is a random integer tensor of shape (n_features,).     """"""      Create a dataset of num_examples random output labels.     dummy_examples = [random_input(n_features, n_string) for _ in range(num_examples)]      Build a tf.data.Dataset from the dummy output labels.     dataset = tf.data.Dataset.from_tensor_slices(dummy_examples)     dataset = dataset.map(process_example)     dataset = dataset.batch(batch_size)     return dataset.repeat() def make_the_model(n_features, n_string, dim_model):     """"""     Build a simple model that takes input_features and predicts the_label.     """"""     input_features = tf.keras.layers.Input(shape=(n_features,), dtype=tf.int32, name=""input_features"")     embedding = tf.keras.layers.Embedding(n_string, dim_model)(input_features)     mha = tf.keras.layers.MultiHeadAttention(         num_heads=8,         key_dim=dim_model//8,         dropout=0.,         name='mha_0'     )(embedding, embedding)     mha = tf.keras.layers.MultiHeadAttention(         num_heads=8,         key_dim=dim_model//8,         dropout=0.,         name='mha_1'     )(mha, mha)      Flatten the embedding and apply a dense layer to predict the_label.     the_label = tf.keras.layers.Dense(n_features, activation=None, name=""the_label"")(mha)     model = tf.keras.Model(inputs={'input_features': input_features}, outputs={'the_label': the_label})     optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)     loss_dict = {'the_label': tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)}     model.compile(optimizer=optimizer, loss=loss_dict)     return model training_data = make_dataset(1024, n_features, n_string, batch_size) validation_data = make_dataset(256, n_features, n_string, batch_size)  print an example of the training data  for batch in training_data.take(1):      print(batch)  Build the model if args.strategy == 'MirroredStrategy':     print(""Using MirroredStrategy."")     strategy = tf.distribute.MirroredStrategy()     with strategy.scope():         this_model = make_the_model(n_features, n_string, dim_model)         this_model.summary()         print(f'Training with batch size {batch_size} and steps per epoch {steps_per_epoch} with {strategy.num_replicas_in_sync} replicas.') if args.strategy == 'MultiWorkerMirroredStrategy':     print(""Using MultiWorkerMirroredStrategy."")     strategy = tf.distribute.MultiWorkerMirroredStrategy()     with strategy.scope():         this_model = make_the_model(n_features, n_string, dim_model)         this_model.summary()         print(f'Training with batch size {batch_size} and steps per epoch {steps_per_epoch} with {strategy.num_replicas_in_sync} replicas.') if args.strategy == 'None':     print(""No strategy."")     this_model = make_the_model(n_features, n_string, dim_model)     this_model.summary()     print(f'Training with batch size {batch_size} and steps per epoch {steps_per_epoch} with 1 GPU.')  Train the model call_backs = tf.keras.callbacks.TerminateOnNaN() this_model.fit(training_data, validation_data=validation_data, epochs=100, steps_per_epoch=steps_per_epoch, validation_steps=4, callbacks=[call_backs])```  Relevant log output ```shell ```",2025-02-17T21:04:11Z,stat:awaiting response type:bug stale comp:gpu TF 2.18,closed,0,4,https://github.com/tensorflow/tensorflow/issues/87432,"Hi **** , Apologies for the delay, and thanks for raising your concern here. I tried running your code using TensorFlow 2.18.0 (stable) on VM instances, but I did not encounter any issues. I am attaching the output below for your reference. And I recommend using stable versions for better results. ``` [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')] ``` ``` (tf_env) maayaragpu1:~$ python3 test.py steps_per_epoch 61 strategy MultiWorkerMirroredStrategy 20250305 11:01:28.725763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1741172488.746097   33345 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1741172488.752394   33345 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250305 11:01:28.774422: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. I0000 00:00:1741172491.290716   33345 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  > device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5 I0000 00:00:1741172491.293431   33345 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13764 MB memory:  > device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5 Using MultiWorkerMirroredStrategy. Model: ""functional"" ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ Layer (type)                  ┃ Output Shape              ┃         Param  ┃ Connected to               ┃ ┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ input_features (InputLayer)   │ (None, 256)               │               0 │                           │ ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤ │ embedding (Embedding)         │ (None, 256, 64)           │          16,384 │ input_features[0][0]       │ ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤ │ mha_0 (MultiHeadAttention)    │ (None, 256, 64)           │          16,640 │ embedding[0][0],           │ │                               │                           │                 │ embedding[0][0]            │ ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤ │ mha_1 (MultiHeadAttention)    │ (None, 256, 64)           │          16,640 │ mha_0[0][0], mha_0[0][0]   │ ├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤ │ the_label (Dense)             │ (None, 256, 256)          │          16,640 │ mha_1[0][0]                │ └───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘  Total params: 66,304 (259.00 KB)  Trainable params: 66,304 (259.00 KB)  Nontrainable params: 0 (0.00 B) Training with batch size 64 and steps per epoch 61 with 2 replicas. Epoch 1/100 61/61 ━━━━━━━━━━━━━━━━━━━━ 10s 48ms/step  loss: 5.5452  val_loss: 5.5454 Epoch 2/100 61/61 ━━━━━━━━━━━━━━━━━━━━ 2s 38ms/step  loss: 5.5448  val_loss: 5.5454 . . . . Epoch 97/100 61/61 ━━━━━━━━━━━━━━━━━━━━ 2s 40ms/step  loss: 1.3885  val_loss: 1.3389 Epoch 98/100 61/61 ━━━━━━━━━━━━━━━━━━━━ 2s 38ms/step  loss: 1.4202  val_loss: 1.3394 Epoch 99/100 61/61 ━━━━━━━━━━━━━━━━━━━━ 3s 44ms/step  loss: 1.3504  val_loss: 1.3385 Epoch 100/100 61/61 ━━━━━━━━━━━━━━━━━━━━ 3s 44ms/step  loss: 1.4391  val_loss: 1.3389 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,uri-granta,Memory leak when compiling tfp.util.TransformedVariable since TF 2.14 (worked fine before!)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.14+ (present in 2.14, 2.16, 2.18; not an issue in 2.11, 2.12, 2.13)  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Upgrading a GPflowbased workflow to use TF 2.14 is showing memory leaks where none previously occurred. Preliminary investigations connected this to the compilation of GPflow models: in the code snippet below the memory usage increases over time (by around 1MB per iteration for a total of ~200MB) when run with TF 2.14, 2.16 or 2.18, but not when run with TF 2.11, 2.12 or 2.13. Raising as a TF bug as code that was previously executing fine is now appearing to leak memory, though there is also a chance that this is an issue in GPflow. Any suggestions for helping identify the leaked memory would be very welcome!  Standalone code to reproduce the issue ```shell import gc import gpflow import keras.backend import numpy as np import os import psutil import tensorflow as tf  define simple GPflow model X = np.array([[0.865], [0.666], [0.804], [0.771], [0.147], [0.866], [0.007], [0.026], [0.171], [0.889], [0.243], [0.028]]) Y = np.array([[1.57], [3.48], [3.12], [3.91], [3.07], [1.35], [3.80], [3.82], [3.49], [1.30], [4.00], [3.82]]) model = gpflow.models.GPR((X, Y), kernel=gpflow.kernels.SquaredExponential())  repeatedly compile and evaluate the model's log marginal likelihood for i in range(200):      garbage collect to remove some of the noise     keras.backend.clear_session(); gc.collect()      compile and evaluate closure     tf.function(model.log_marginal_likelihood)()      track memory usage     print(f""[{i+1}] Memory usage: {psutil.Process(os.getpid()).memory_info().rss / 1024 **2} MiB"") ```  Relevant log output ```shell ```",2025-02-17T11:48:58Z,type:bug type:performance TF 2.18,open,0,5,https://github.com/tensorflow/tensorflow/issues/87414,"Hi **granta** , Apologies for the delay, and thanks for raising your concern here. I tried running your code on Colab using TensorFlow 2.13.0 it is working as expected and 2.18.0 faced the same issue like you. The main cause might be version compatibility. When using GPflow, you need to install the GPflow package along with its dependencies TensorFlow and TensorFlow Probability ensuring all versions are compatible. According to the GPflow documentation, compatibility is mentioned only up to TensorFlow 2.12. Therefore, the exact TensorFlow Probability version required for the latest TensorFlow versions is unknown. I recommend first confirming the compatibility versions in the GPflow documentation. It would be best to check with GPflow for the correct compatibility versions for the latest TensorFlow releases. Thank you!","Hi , Thanks for looking into this! **I've since managed to reproduce the issue without using `gpflow` at all, just with a `TransformedVariable` from `tensorflowprobability`.** (Also FYI `gpflow` does actually support tensorflow up to 2.16, though it looks like the docs aren't up to date!) As before, the following script shows continually increasing memory usage when run with TF 2.1418 but not when run with TF 2.1113, though the memory increase is smaller than before (only around 0.1MB per iteration) and takes a few iterations to get going. ```python import gc import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' import psutil import keras.backend import tensorflow as tf import tensorflow_probability as tfp class Kernel:     def __init__(self):          note that using tfp.bijectors.Identity() instead doesn't leak (though tfp.bijectors.Exp() does)         self._variance = tfp.util.TransformedVariable(tf.constant(1.), tfp.bijectors.Softplus())     def variance(self):          note that just returning self.variance doesn't leak         return tf.squeeze(self._variance) kernel = Kernel() for i in range(400):      garbage collect to remove noise     keras.backend.clear_session(); gc.collect()      compile and evaluate closure     tf.function(lambda: kernel.variance())()      track memory usage     print(f""[{i+1}] Memory usage: {psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2} MiB"") ```","FYI here's an even simpler class that can be used in the previous example: ```python class Kernel:     def __init__(self):         self._variance = tfp.util.DeferredTensor(tf.Variable(1.), tfp.bijectors.Shift(0.0))     def variance(self):         return tf.convert_to_tensor(self._variance) ``` As before, setting the bijector to `tfp.bijectors.Identity()` removes the leak. However, changing this bijector's `_forward(self, x)` method to return `x + 0` rather than `x` reintroduces it. AFAICT the bijector is never evaluated in the test, so this is presumably all to do with compilation.","So it looks like the issue in this particular example is that in every compilation, a pair of weak references to the input and output `SymbolicTensor`'s aren't being garbage collected, which in turn means that their cleanup callbacks aren't being called to remove them from the global `BijectorCache` (`tfp.bijectors.bijector._cache`). By contrast, both in TF=2.14 both references *are* garbage collected and the callbacks *are* called. Note that the `BijectorCache` code in tfp hasn't changed in the last 4 years, and the `gpflow` example from the beginning continues to show issues even after manually disabling the cache, so I suspect the cache is just a symptom and the underlying cause is somehow connected to why the compiled graphs aren't being garbage collected (or at least why their cleanup callbacks aren't being called).","So I'm pretty sure the `BijectoCache` issue is due to https://github.com/tensorflow/tensorflow/commit/333ee99ecb9bd8f122c683defa74281bb3bd1664. Before this change, when initialising a `Function`, TF used to call `TracingCompiler._get_concrete_function_internal_garbage_collected`, which ended up creating and deleting a `ConcreteFunctionGarbageCollector`, dismantling the function graph at the end. After this change, when initialising a `Function`, TF now calls `tracing_compilation.trace_function`, which similarly creates a `ConcreteFunctionGarbageCollector`. However, because `tracing_options.bind_graph_to_function` is `False` (the default value, unchanged by `Function._generate_tracing_options`) it also calls `release` on the garbage collector before deleting it, preventing it from dismantling the function graph (and therefore from cleaning up the bijector cache). Note though that this probably isn't the whole story. Changing `Function._initialize` to use `dataclasses.replace(self._variable_creation_config, bind_graph_to_function=True)` instead does fix the memory leak in the two bijector examples above. However, it doesn't fix the original leaks discovered in `gpflow` (which based on profiling may now be connected to the `gradient_registry` somehow)."
yi,AD-lite24,Warning in XNNPACK: unable to enable JIT: not compiled with JIT enabled," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.17.1  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version GCC 9 aarch cross compiler  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Upon updating our tflite service to 2.17.1, XNNPACK fails to apply with this cryptic error  `Warning in XNNPACK: unable to enable JIT: not compiled with JIT enabled` I don't understand this error at all, there is really only way to build XNNPACK while building TFLite as described in CMake, so I have no idea what this is referring to. We didn't face this issue with earlier versions (2.7.0)  Standalone code to reproduce the issue ```shell Just applying XNNPACK delegate to any model ```  Relevant log output ```shell ```",2025-02-16T14:38:54Z,stat:awaiting response type:support stale comp:lite comp:lite-xnnpack 2.17,open,0,9,https://github.com/tensorflow/tensorflow/issues/87385,"Hi, lite24  Thank you for bringing this issue to our attention, I believe you followed this official documentation Build LiteRT with CMake, if possible could you please help me with exact steps before encountering mentioned warning to replicate the same behavior from my end ? Thank you for your cooperation and understanding.","Hi   Please find the CMakeLists.txt we use to build the project (tflite is built alongside it) ```cmake cmake_minimum_required(VERSION 3.10) SET(TARGET voxltfliteserver) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(TFLITE_ENABLE_GPU ON CACHE BOOL ""Enable GPU delegate support"") set(TFLITE_ENABLE_NNAPI ON CACHE BOOL ""Enable NNAPI delegate support"") set(XNNPACK_ENABLE_ARM_BF16 OFF CACHE BOOL) set(XNNPACK_ENABLE_ARM_I8MM OFF CACHE BOOL) set(TENSORFLOW_SOURCE_DIR ""~/tensorflow_src"" CACHE PATH ""Directory with checkout of tensorflow"") add_subdirectory(""${TENSORFLOW_SOURCE_DIR}/tensorflow/lite"" ""${CMAKE_CURRENT_BINARY_DIR}/tensorflowlite"" EXCLUDE_FROM_ALL) option(BUILD_QRB5165 ""Build the qrb5165 binary"" OFF) if(BUILD_QRB5165)     add_definitions(DBUILD_QRB5165) endif() if(CMAKE_BUILD_TYPE STREQUAL ""DEBUG"")     set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} g3 Wall Wuninitialized Wmaybeuninitialized fnoomitframepointer"") elseif(CMAKE_BUILD_TYPE STREQUAL ""RELEASE"")     set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} O3 fsee fomitframepointer fnosignedzeros fnomatherrno funrollloops"") endif()  Enable compile optimizations  Enable debug flags (use if you want to debug in gdb)  Build from all source files file(GLOB_RECURSE all_src_files *.c*) add_executable(${TARGET} 	${all_src_files} ) include_directories(     ../include/     ../include/model_helper/     /usr/include/opencv4/       apq8096 SPECIFIC      /usr/include/tensorflow/lite/tools/make/downloads/absl/      /usr/include/tensorflow/lite/tools/make/downloads/flatbuffers/include/      qrb5165 SPECIFIC     /usr/include/flatbuffers/include/     /usr/include/abseilcpp/     /usr/include/ruy/ ) set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} Wnoimplicitfallthrough"") if (BUILD_QRB5165) set(LINK_LIBS ""modal_pipe""     ""modal_json""     ""glib2.0""     ""dl""     ""stdc++""     ""pthread""     ""z""     ""cutils""     ""log""     ""sync""     ""gthread2.0""     ""pcre""     ""modal_pipe""     ""modal_json""     ""opencv_core""     ""opencv_highgui""     ""opencv_imgproc""     ""opencv_imgcodecs""     ""opencv_dnn""     ""gsl""     ""llvmqcom""     ""adreno_utils""     ""OpenCL""     ""CB""     ""EGL_adreno""     ""GLESv2_adreno""     ""pthreadpool""     ""rt"") endif() target_link_libraries(${TARGET}     Wl,rpathlink,/usr/lib64/     L/usr/lib64/     ${LINK_LIBS}     tensorflowlite )  make sure everything is installed where we want  LIB_INSTALL_DIR comes from the parent cmake file install( 	TARGETS			${TARGET} 	LIBRARY			DESTINATION ${LIB_INSTALL_DIR} 	RUNTIME			DESTINATION /usr/bin 	PUBLIC_HEADER	DESTINATION /usr/include ) ``` and our build script ```shell echo ""Applying MAI Patches"" patch uN ~/tensorflow_src/tensorflow/lite/CMakeLists.txt i ~/patches/cmake_fix.patch echo ""Done Applying Patches"" mkdir p build cd build   cmake DCMAKE_TOOLCHAIN_FILE=${TOOLCHAIN_QRB5165} DCMAKE_BUILD_TYPE=DEBUG DBUILD_QRB5165=${BUILD_QRB5165} DCMAKE_VERBOSE_MAKEFILE=ON DCMAKE_CXX_FLAGS=""${CMAKE_CXX_FLAGS} std=c++17 march=armv8a"" ${EXTRA_OPTS} ../ make j5 VERBOSE=1 cd ../ ``` with patches ```  tensorflow/tensorflow/lite/CMakeLists.txt.orig	20220209 08:54:18.370750801 0800 +++ tensorflow/tensorflow/lite/CMakeLists.txt	20220209 08:43:51.505795653 0800 @@ 59,13 +59,13 @@    ${CMAKE_PREFIX_PATH}  )  include(CMakeDependentOption) option(TFLITE_ENABLE_RUY ""Enable experimental RUY integration"" OFF) +option(TFLITE_ENABLE_RUY ""Enable experimental RUY integration"" ON)  option(TFLITE_ENABLE_RESOURCE ""Enable experimental support for resources"" ON)  option(TFLITE_ENABLE_NNAPI ""Enable NNAPI (Android only)."" ON) cmake_dependent_option(TFLITE_ENABLE_NNAPI_VERBOSE_VALIDATION ""Enable NNAPI verbose validation."" OFF +cmake_dependent_option(TFLITE_ENABLE_NNAPI_VERBOSE_VALIDATION ""Enable NNAPI verbose validation."" ON                         ""TFLITE_ENABLE_NNAPI"" ON)  option(TFLITE_ENABLE_MMAP ""Enable MMAP (unsupported on Windows)"" ON) option(TFLITE_ENABLE_GPU ""Enable GPU"" OFF) +option(TFLITE_ENABLE_GPU ""Enable GPU"" ON)  option(TFLITE_ENABLE_METAL ""Enable Metal delegate (iOS only)"" OFF)  option(TFLITE_ENABLE_XNNPACK ""Enable XNNPACK backend"" ON) @@ 86,7 +86,7 @@  endif()  set(_TFLITE_ENABLE_NNAPI ""${TFLITE_ENABLE_NNAPI}"")  if(NOT ""${CMAKE_SYSTEM_NAME}"" STREQUAL ""Android"")   set(_TFLITE_ENABLE_NNAPI OFF) +  set(_TFLITE_ENABLE_NNAPI ON)  endif()  set(_TFLITE_ENABLE_MMAP ""${TFLITE_ENABLE_MMAP}"")  if(${CMAKE_SYSTEM_NAME} MATCHES ""Windows"") ``` Once the project is built, the entry point simply invokes the interpreter in a standard manner and tries to apply the delegate. There is a an issue in the cross compilation process with respect to protobuf where the protobuf library built is built for the target but the host tries to use it. We resolved it by manually building protobuf for the host architecture and setting the appropriate system paths.", Was there any update on this? ,"Hi, lite24  If possible could you please add this `set(XNNPACK_ENABLE_JIT ON CACHE BOOL ""Enable JIT in XNNPACK"")` in CMakeLists.txt and see is it resolving your issue or not ? after updating the CMake configuration clean your build directory and recompile to apply the changes. Thank you for your cooperation and patience.","Hi   Thank you for the reply I was not aware that such a flag existed. Yes that error was resolved but a new error has popped up ``` INFO: Created TensorFlow Lite XNNPACK delegate for CPU. INFO: XNNPack weight cache not enabled. VERBOSE: Replacing 94 out of 144 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 21 partitions for the whole graph. ERROR: /home/root/tensorflow_src/tensorflow/lite/core/subgraph.cc:600 tensor>delegate == nullptr  tensor>delegate == delegate was not true. ERROR: Restored original execution plan after delegate application failure. INFO: Error in applying the default TensorFlow Lite delegate indexed at 0, and all previously applied delegates are reverted. Inference time: 115846 ms Output: 6.30584e43 ``` This error also did not used to occur earlier and has only come up once we upgraded tflite. Could you please tell us why this might be occuring","Hi, lite24 Good to hear that initial reported issue got resolved, Troubleshooting TFLite delegate application failures can be challenging.  I recommend the following approaches: Increase logging verbosity to obtain more detailed information about the delegate application process and also verify the model compatibility with the chosen delegate. You can run the model without any delegates to ensure that the model itself is functioning correctly. This helps isolate whether the issue is with the model or the delegate.  Please check if the tensors are already owned by another delegate. The error message `tensor>delegate == nullptr  tensor>delegate == delegate was not true` indicates a conflict please ensure that tensors are not being shared between delegates.You can do this by inspecting the tensor's delegate before applying a new one.  Please check for unsupported operations some operations in your model may not be supported by the delegate. For XNNPACK, you can find the list of supported operations in the XNNPACK documentation and for GPU delegates  Thank you for your cooperation and understanding."," As you said it likely fails due to tensors being owned by two delegates. The issue occurs due to a failure to apply GPU delegate (which is a separate issue), and it then falls back to XNNPACK to run on CPU. If I don't apply GPU delegates XNNPACK works fine.  This I believe is a bug that did not occur in older versions, the fallback to XNNPACK is likely not changing ownership of the tensors.","Hi, lite24  I apologize for the delayed response, if possible could you please give it try with latest stable version of `TensorFlow 2.19.0` and `tfnightly` and see is it resolving your issue or not ? Thank you for your cooperation and patience.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.
transformer,khangtruong2252314,Colab TPU crash on transformer import," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.18  Custom code No  OS platform and distribution Google colab default  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Import transformer module get crash on a colab notebook with TPU   Standalone code to reproduce the issue ```shell from transformers import TFT5ForConditionalGeneration ''' This will crash the TPU session ''' ```  Relevant log output ```shell ""Crashed for unknown reason"" ```",2025-02-16T13:13:48Z,type:bug,closed,0,5,https://github.com/tensorflow/tensorflow/issues/87383,Are there any error messages during the installation process? It could help identify what is causing the issue,"No, sorry. I just open the colab and import, then crash. Perhaps you now can recreate it quickly as it is the default colab session. There are some session log that might be useful.","Is there something in the error message that points to Tensorflow? Or, in other words, should this be opened on Colab repo or on transformers repo?","Ah, sorry, I was working with tensorflow that I didn’t realize it was colab’s fault. ",Are you satisfied with the resolution of your issue? Yes No
rag,MoritzKronberger,GPU and CPU utilization dropping to 0% during long training runs," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.18.0  Custom code Yes  OS platform and distribution Ubuntu 24.04.1 LTS  Mobile device _No response_  Python version 3.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA 2.14  GPU model and memory _No response_  Current behavior? When running the attached test script for longer, at some point during the training GPU and CPU utilization will both fall to 0%, although neither VRAM nor RAM are exhausted. The training on my NVIDIA L40S vGPU slows from ~35ms/step with batch size 256 to minutes per step. Training speed only recovers on reboot. Larger batch sizes will make the error occurr later during training. I am unsure if this is an issue of my machine/the vGPU configuration.  Standalone code to reproduce the issue ```shell import tensorflow as tf print(""TensorFlow version:"", tf.__version__) print(""CPU devices:"", tf.config.list_physical_devices(""CPU"")) print(""GPU devices:"", tf.config.list_physical_devices(""GPU"")) print(""Using cuDNN:"", tf.test.is_built_with_cuda()) gpus = tf.config.list_physical_devices(""GPU"") for gpu in gpus:     tf.config.experimental.set_memory_growth(gpu, True) with tf.device(""GPU:0""):     num_samples = 18_000     input_length = 480     input_channels = 1     X = tf.random.normal((num_samples, input_length, input_channels), dtype=tf.float32)     Y = tf.random.normal((num_samples, input_length, input_channels), dtype=tf.float32)     input = tf.keras.layers.Input(shape=(input_length, input_channels))     conv = tf.keras.layers.Conv1D(         filters=256,         kernel_size=5,         strides=1,         padding='same',         activation=None,         input_shape=(input_length, input_channels)     )(input)     pool = tf.keras.layers.AveragePooling1D(         pool_size=2,         strides=2     )(conv)     deconv = tf.keras.layers.Conv1DTranspose(         filters=256,         kernel_size=4,         strides=2,         padding='same',         activation=None     )(pool)     dense = tf.keras.layers.Dense(2048*2, activation='tanh')(deconv)     out = tf.keras.layers.Dense(input_channels, activation='linear')(dense)     model = tf.keras.models.Model(         inputs=input,         outputs=out     )   type: ignore     model.summary()     model.compile(optimizer='adam', loss='mse', jit_compile=True)     dataset = tf.data.Dataset.from_tensor_slices((X, Y))     dataset = dataset.batch(256).prefetch(tf.data.AUTOTUNE)     model.fit(dataset, epochs=500, verbose=1) ```  Relevant log output ```shell 20250216 06:35:01.114446: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250216 06:35:01.824571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1739687702.107514    2941 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1739687702.197108    2941 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250216 06:35:02.874809: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. TensorFlow version: 2.18.0 CPU devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')] GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] Using cuDNN: True I0000 00:00:1739687707.790282    2941 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5117 MB memory:  > device: 0, name: NVIDIA L40S8C, pci bus id: 0000:03:04.0, compute capability: 8.9 20250216 06:35:07.832778: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:07.838416: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. /home/mokro1/canilm/venv/lib/python3.12/sitepackages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.   super().__init__(activity_regularizer=activity_regularizer, **kwargs) 20250216 06:35:07.899661: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing Cast input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:07.903310: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.228058: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.228711: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.230774: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing StatelessRandomGetKeyCounter input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.249462: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.260795: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing Cast input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.263365: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.264361: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.265277: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing StatelessRandomGetKeyCounter input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.274980: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing Cast input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.276006: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.276518: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.276878: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing StatelessRandomGetKeyCounter input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.285657: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing Cast input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.286505: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.286793: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing _EagerConst input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:GPU:0 but is actually on /job:localhost/replica:0/task:0/device:CPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. 20250216 06:35:09.287169: W tensorflow/core/common_runtime/eager/execute.cc:197] before computing StatelessRandomGetKeyCounter input CC(未找到相关数据) was expected to be on /job:localhost/replica:0/task:0/device:CPU:0 but is actually on /job:localhost/replica:0/task:0/device:GPU:0 (operation running on /job:localhost/replica:0/task:0/device:GPU:0). This triggers a copy which can be a performance bottleneck. ```",2025-02-15T21:12:30Z,type:bug TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/87366,"Hi **** , Thanks for raising your concern here. Could you please provide information about the cuDNN version you are using? There might be a mismatch in version compatibility. Please check all the compatible versions to avoid issues. I am providing the documentation for your reference. I also tried with reduced sizes, and it worked fine for me. Please find gist1 and gist2 here for your reference. Thank you!","I forgot to add `tf.config.experimental.set_device_policy(""warn"")` to the standalone code, which produces the log output on my local machine. Trying this in Colab did not produce the same logs, but I am usure if Colab is filtering logs. The crash happens after ~200 epochs on my machine (without reduced sizes), 10 epochs are not an issue. Regarding cuDNN: `nvidiacudnncu12=9.3.0.75` and `nvidiacudnncu11=8.5.0.96` are installed, according to TF logs 9.3.0.75 is used."
rag,copybara-service[bot],Regenerate tf_generated_ops.td after adding a new attribute to the WriteTrainingPredictions custom op to support writing vector predictions to file storage.,Regenerate tf_generated_ops.td after adding a new attribute to the WriteTrainingPredictions custom op to support writing vector predictions to file storage.,2025-02-15T01:13:46Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87343
yi,copybara-service[bot],Use seprate collective resource when scheduling p2p communication,Use seprate collective resource when scheduling p2p communication This is in preparation of removing all the 4 existing p2p resources. We are simplifying the pipeline parallelism implementation here.,2025-02-13T23:09:57Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87272
yi,copybara-service[bot],[xla:python] Remove unused _single_device_array_to_np_array on ArrayImpl.,[xla:python] Remove unused _single_device_array_to_np_array on ArrayImpl.,2025-02-13T19:18:29Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87256
yi,KeskoPreeti,Tensorflow in pycharm setup issue," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution windows 11  Mobile device windows11  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? error while running the file predeiction.py                                                                                                                                                      (c) Microsoft Corporation. All rights reserved. (venv_new) C:\analytics_driven_enginemaster\analytics_driven_enginemaster>python m analysis.prediction [20250213 15:38:26,485] INFO  Starting prediction pipeline... ['Number' 'Opened' 'State' 'Symptom category' 'Short description' 'State'] Traceback (most recent call last):   File ""C:\analytics_driven_enginemaster\analytics_driven_enginemaster\venv_new\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 62, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The paging file is too small for this operation to complete. During handling of the above exception, another exception occurred: Traceback (most recent call last):   File """", line 1, in    File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\multiprocessing\spawn.py"", line 116, in spawn_main     exitcode = _main(fd, parent_sentinel)   File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\multiprocessing\spawn.py"", line 125, in _main     prepare(preparation_data)   File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\multiprocessing\spawn.py"", line 234, in prepare     _fixup_main_from_name(data['init_main_from_name'])   File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\multiprocessing\spawn.py"", line 258, in _fixup_main_from_name     main_content = runpy.run_module(mod_name,   File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 225, in run_module     return _run_module_code(code, init_globals, run_name, mod_spec)   File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 97, in _run_module_code     _run_code(code, mod_globals, init_globals,   File ""C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\lib\runpy.py"", line 87, in _run_code     exec(code, run_globals)   File ""C:\analytics_driven_enginemaster\analytics_driven_enginemaster\analysis\prediction.py"", line 3, in      import tensorflow as tf   File ""C:\analytics_driven_enginemaster\analytics_driven_enginemaster\venv_new\lib\sitepackages\tensorflow\__init__.py"", line 37, in      from tensorflow.python.tools import module_util as _module_util   File ""C:\analytics_driven_enginemaster\analytics_driven_enginemaster\venv_new\lib\sitepackages\tensorflow\python\__init__.py"", line 36, in      from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   File ""C:\analytics_driven_enginemaster\analytics_driven_enginemaster\venv_new\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 77, in      raise ImportError( ImportError: Traceback (most recent call last):   File ""C:\analytics_driven_enginemaster\analytics_driven_enginemaster\venv_new\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 62, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The paging file is too small for this operation to complete. expected  to process ticket analytics output files based on input  Standalone code to reproduce the issue ```shell import datetime import logging import tensorflow as tf import numpy as np from analysis.data_helpers import add_analyser, find_keywords, add_translated_data from analysis.save_and_get_models import get_model, load_tokeniser, load_vectorizer, decode_data as decode, get_encoder from config.config import output_col, input_path, unique_col, columns_for_parsing, output_path, output_col_apps, data  from TA_semantic_approach.main import predict_semantic_cti import gc import os import torch torch.set_num_threads(1)   Limits PyTorch parallelism to avoid excessive memory usage torch.cuda.empty_cache()   Clears unused GPU memory (if using CUDA)  Reduce TensorFlow memory usage os.environ[""TF_FORCE_GPU_ALLOW_GROWTH""] = ""true"" os.environ[""CUDA_VISIBLE_DEVICES""] = ""1""   Forces CPU processing tf.config.threading.set_intra_op_parallelism_threads(1) tf.config.threading.set_inter_op_parallelism_threads(1) def predict_output_gartner_cti_infra(df, col=[], name='', path='', flag=''):     models = get_model(flag)      tokenize = load_tokeniser()     vectorizer = load_vectorizer(flag)     df = add_analyser(df, path=path, columns_for_parsing=col)      data = tokenize.texts_to_matrix(df['Analysis'])     value = vectorizer.transform(df['Analysis'].values).toarray()     for key, model in models.items():         input = {}         for col in output_col[key]['input']:             if col != 'Analysis':                 input[col.replace('/ ', '').replace(' ', '_').replace('/', '')] = tf.keras.utils.to_categorical(                     get_encoder(list(df[col]), col.replace('/ ', '').replace(' ', '_').replace('/', '')))             else:                 input[col] = value         data = model.predict([val for x, val in input.items()])         for i, col in enumerate(output_col[key]['output']):             if len(output_col[key]['output']) > 1:                 df[col] = decode([tf.argmax(x) for x in data[i]],                                  col.replace('/ ', '').replace(' ', '_').replace('/', ''))             else:                 df[col] = decode([tf.argmax(x) for x in data],                                  col.replace('/ ', '').replace(' ', '_').replace('/', ''))     print(df)     df[['Category', 'Type', 'Item']] = df['Intent'].str.split(',', 3, expand=True)      cti_df = pd.read_excel('resources\CTI Model.xlsx', sheet_name='Sheet2')           df.fillna('', inplace=True)      cti_df.fillna('', inplace=True)           df = find_keywords(df, [i.lower() for i in list(cti_df['Type'])], mapp=list(cti_df['Category']),                         columns=['Type', 'Category'])      df = find_keywords(df, [i.lower() for i in list(cti_df['Item']) if i != ''], mapp=list(cti_df['Item_Replace']),                         columns=['Item'])     return df def predict_output_gartner_apps(df, col=[], name='', path='', flag=''):     models = get_model(flag)      tokenize = load_tokeniser()     vectorizer = load_vectorizer(flag)     df = add_translated_data(df, path=path, columns_for_parsing=col)     df = add_analyser(df, path=path, columns_for_parsing=col)      data = tokenize.texts_to_matrix(df['Analysis'])     df = df[df['Analysis'].notna()]     value = vectorizer.transform(df['Analysis'].values).toarray()     for key, model in models.items():         input = {}         for col in output_col_apps[key]['input']:             if col != 'Analysis':                 input[col.replace('/ ', '').replace(' ', '_').replace('/', '')] = tf.keras.utils.to_categorical(                     get_encoder(list(df[col]), col.replace('/ ', '').replace(' ', '_').replace('/', '')))             else:                 input[col] = value         data = model.predict([val for x, val in input.items()])         for i, col in enumerate(output_col_apps[key]['output']):             if len(output_col_apps[key]['output']) > 1:                 df[col] = decode([tf.argmax(x) for x in data[i]],                                  col.replace('/ ', '').replace(' ', '_').replace('/', ''))             else:                 df[col] = decode([tf.argmax(x) for x in data],                                  col.replace('/ ', '').replace(' ', '_').replace('/', ''))      df[['Category', 'Type','Item']] = df['Intent'].str.split(',', 3, expand=True)      cti_df = pd.read_excel('resources\CTI Model.xlsx', sheet_name='Sheet2')           df.fillna('', inplace=True)      cti_df.fillna('', inplace=True)           df = find_keywords(df, [i.lower() for i in list(cti_df['Type'])], mapp=list(cti_df['Category']),                         columns=['Type', 'Category'])      df = find_keywords(df, [i.lower() for i in list(cti_df['Item']) if i != ''], mapp=list(cti_df['Item_Replace']),                         columns=['Item'])     return df if __name__ == '__main__':     logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s  %(message)s')     logging.info(""Starting prediction pipeline..."")     gc.garbage.clear()     import pandas as pd     import os      df=pd.read_excel('C:\\Users\\sabatank\\Desktop\\test_new_data\\Training_input_20210715T03_21_12.xlsx')      df.fillna('', inplace=True)      df['Intent'] = df.apply(lambda x: '' if x['Analysis'] == '' else x['Analysis'], axis=1)      df.to_excel('C:\\Users\\sabatank\\Desktop\\test_new_data\\Training_input_20210715_12.xlsx')     for file in os.listdir(input_path):         gc.garbage.clear()         try:             if data == 'both':                 df = pd.read_excel(input_path + file)                 df = df[df[unique_col].notna()]                 df.fillna('', inplace=True)                 grouped_data = df.groupby(df.Area)                 df_apps = grouped_data.get_group(""Apps"")                 df_infra = grouped_data.get_group(""Infra"")                 df_out_infra = predict_output_gartner_cti_infra(df_infra, columns_for_parsing, file.split('.')[0],                                                                 input_path + file, 'infra')                 df_out_apps = predict_output_gartner_apps(df_apps, columns_for_parsing, file.split('.')[0],                                                           input_path + file, 'apps')                  df_out_apps_cti=predict_semantic_cti(df_out_apps,['Analysis'],file.split('.')[0], input_path+file)                  df_out_apps_cti[['Category', 'Type','Item']] = df_out_apps_cti['Intent'].str.split(',', 3, expand=True)                 final_df = pd.concat([df_out_infra, df_out_apps])             if data == 'apps':                 df = pd.read_excel((input_path + file), sheet_name='Page 1')                 df = df[['Number', 'Opened', 'State', 'Symptom category', 'Short description', 'State']]                 df = df[df[unique_col].notna()]                 df_apps = df[df[columns_for_parsing[0]].notna()]                  df_apps = df_apps.head(10)                 tickets_per_request = 1000                 final_df = pd.DataFrame()                 count = 0                  final_df=predict_output_gartner_apps(df_apps,columns_for_parsing, file.split('.')[0], input_path+file,'apps')                 for index, sub_df in df_apps.groupby(                         np.arange(len(df_apps)) // tickets_per_request):   post request with 100 records                     try:                         output = predict_output_gartner_apps(sub_df, columns_for_parsing, file.split('.')[0],                                                              input_path + file, 'apps')                         if output is None:                             continue                         nowTime = str(datetime.datetime.now().replace(microsecond=0).isoformat()).replace(':', '_')                         output = output.applymap(lambda x: x.encode('unicode_escape').                                                  decode('utf8') if isinstance(x, str) else x)                         output.to_excel(output_path + file.split('.')[0].replace(' ', '') + '.xlsx', index=False)                          output.to_excel(output_path + file.split('.')[0].replace(' ', '') + '_' + nowTime + '.xlsx',                                            index=False)                         final_df = pd.DataFrame(output)                         count = count + 5000                     except Exception as e:                         logging.error(f""Exception occurred: {e}"")                         logging.info(""Remaining files are stored in output path."")                         nowTime = str(datetime.datetime.now().replace(microsecond=0).isoformat()).replace(':', '_')                         df_success = final_df.drop(                             ['Debt Classification', 'Avoidable', 'Intent', 'Category', 'Type', 'Item', 'Translated_data',                              'Analysis'], axis=1, inplace=True, errors='ignore')                         df_remaining = pd.concat([df_apps, df_success]).drop_duplicates(keep=False)                         df_remaining.to_excel(                             output_path + 'remaining\\' + file.split('.')[0].replace(' ', '') + '_' + nowTime + '.xlsx',                             index=False)                         logging.error(""Exception encountered. Stopping process."")                         print(str(e))                     print(count)                 nowTime = str(datetime.datetime.now().replace(microsecond=0).isoformat()).replace(':', '_')                 final_df.to_excel(output_path + file.split('.')[0].replace(' ', '') + '_final' + nowTime + '.xlsx',                                   index=False)                  final_df=predict_semantic_cti(df_out_apps, 'Analysis', file.split('.')[0], input_path + file)                  final_df[['Category', 'Type','Item']] = final_df['Intent'].str.split(',', 3, expand=True)             if data == 'infra':                 df = pd.read_excel(input_path + file)                 df = df[df[unique_col].notna()]                 df_infra = df[df[columns_for_parsing[0]].notna()]                 final_df = predict_output_gartner_cti_infra(df_infra, columns_for_parsing, file.split('.')[0],                                                             input_path + file, 'infra')             nowTime = str(datetime.datetime.now().replace(microsecond=0).isoformat()).replace(':', '_')              final_df.to_excel(output_path + file.split('.')[0].replace(' ','') + '_' + nowTime + '.xlsx', index=False)             logging.info(""Prediction process completed successfully."")         except Exception as e:             print(e)             break ```  Relevant log output ```shell ```",2025-02-13T10:24:36Z,stat:awaiting response type:build/install subtype:windows TF 2.12,closed,0,3,https://github.com/tensorflow/tensorflow/issues/87226,", Could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios: ```  You need to install the MSVC 2019 redistributable  Your CPU does not support AVX2 instructions  Your CPU/Python is on 32 bits  There is a library that is in a different location/not installed on your system that cannot be loaded. ``` Also kindly provide the environment details and the steps followed to install the tensorflow. CC(Tensorflow failed build due to ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.) Also this is a duplicate of https://github.com/tensorflow/tensorflow/issues/19584 Thank you!",Please always search for similar issues before opening duplicates,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],[Function runtime] Avoid copying reachable function definitions when graph collection is disabled.,"[Function runtime] Avoid copying reachable function definitions when graph collection is disabled. Additionally, avoid copying each function during the `UpdateTPUEmbeddingModePass` for the common case where the function does not include any TPUEmbedding layer ops.",2025-02-13T07:32:47Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87219
yi,copybara-service[bot],internal BUILD rule visibility,internal BUILD rule visibility,2025-02-13T06:28:01Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87217
yi,copybara-service[bot],Enable `bazel build --nobuild` to prevent network flakes for TensorFlow builds,Enable `bazel build nobuild` to prevent network flakes for TensorFlow builds Removes the usage of their `py_cpp_test_filters` config which is incompatible with `bazel build nobuild` and instead replicate the effect of the config by specifying bazel options explicitly.,2025-02-13T00:19:56Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87200
yi,copybara-service[bot],Split `CompileOnlyIfRtClient` into its own directory,Split `CompileOnlyIfRtClient` into its own directory,2025-02-12T23:29:37Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87196
yi,copybara-service[bot],Ensure InterpreterFactoryImpl's constructor is kept,"Ensure InterpreterFactoryImpl's constructor is kept Add  annotation to the constructor, ensuring it's kept even if `keep class X` rule semantics change as it relates to keeping the default (empty) constructor.",2025-02-12T19:36:04Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87180
yi,copybara-service[bot],"Add subgraph_input_names(), subgraph_output_names() to the SignatureRunner","Add subgraph_input_names(), subgraph_output_names() to the SignatureRunner In LiteRT, it assumes that the order of names are aligned with Subgraph. But the existing input_names(), output_names() API doesn't follow it, also there are customers who rely on the legacy order. This cl creates these new methods which returns the names which reflects the underlying Subgraph I/O order.",2025-02-12T19:06:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87175
yi,raphael10-collab,"CMake Error: install(EXPORT ""tensorflow-liteTargets"" ...) includes target ""tensorflow-lite"" which requires target ""pthreadpool"" that is not in any export set."," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.20.0  Custom code No  OS platform and distribution Linux Ubuntu 24.04  Mobile device _No response_  Python version 3.12.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following the indications found here: https://ai.google.dev/edge/litert/build/cmakebuild_installable_package I'm trying to build tensorflowlite as installable package:     (base) raphy:~/Grasp/tflite_build$ cmake ../../tensorflow_src/tensorflow/lite/ \     > DTFLITE_ENABLE_INSTALL=ON \     > DCMAKE_FIND_PACKAGE_PREFER_CONFIG=ON \     > DSYSTEM_FARMHASH=ON \     > DSYSTEM_PTHREADPOOL=ON \     > DEigen3_DIR=/home/raphy/Grasp/eigen/share/eigen3/cmake \     > DFlatBuffers_DIR=/home/raphy/Grasp/flatbuffers/lib/cmake/flatbuffers \     > Dcpuinfo_DIR=/home/raphy/Grasp/cpuinfo/share/cpuinfo \     > Druy_DIR=/home/raphy/Grasp/ruy/lib/cmake/ruy \     > DNEON_2_SSE_DIR=/home/raphy/Grasp/NEON_2_SSE/lib/cmake/NEON_2_SSE \     > Dabsl_DIR=/home/raphy/Grasp/abseilcpp/lib/cmake/absl \     > Dgemmlowp_DIR=/usr/lib/x86_64linuxgnu/cmake/gemmlowp \     > Wnodev      Setting build type to Release, for debug builds use'DCMAKE_BUILD_TYPE=Debug'.      The C compiler identification is GNU 13.3.0      The CXX compiler identification is GNU 14.2.0      Detecting C compiler ABI info      Detecting C compiler ABI info  done      Check for working C compiler: /usr/bin/: /usr/bin/c++  skipped      Detecting CXX compile features      Detecting CXX compile features  done      Performing Test CMAKE_HAVE_LIBC_PTHREAD      Performing Test CMAKE_HAVE_LIBC_PTHREAD  Success      Found Threads: TRUE      Found farmhash: /usr/lib/x86_64linuxgnu/libfarmhash.so      Downloading FP16 to /home/raphy/Grasp/tflite_build/FP16source (define FP16_SOURCE_DIR to avoid it)     CMake Deprecation Warning at CMakeLists.txt:16 (CMAKE_MINIMUM_REQUIRED):       Compatibility with CMake  value.  Or, use the ... syntax       to tell CMake that the project requires at least  but has been updated       to work with policies introduced by  or earlier.      Configuring done (0.0s)      Generating done (0.0s)      Build files have been written to: /home/raphy/Grasp/tflite_build/FP16download     [ 11%] Creating directories for 'fp16'     [ 22%] Performing download step (download, verify and extract) for 'fp16'      Downloading...        dst='/home/raphy/Grasp/tflite_build/FP16download/fp16prefix/src/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'        timeout='none'        inactivity timeout='none'      Using src='https://github.com/Maratyszcza/FP16/archive/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'      [download 7% complete]      [download 14% complete]      [download 32% complete]      [download 44% complete]      [download 62% complete]      [download 81% complete]      [download 99% complete]      [download 100% complete]      verifying file...            file='/home/raphy/Grasp/tflite_build/FP16download/fp16prefix/src/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'      Downloading... done      extracting...          src='/home/raphy/Grasp/tflite_build/FP16download/fp16prefix/src/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'          dst='/home/raphy/Grasp/tflite_build/FP16source'      extracting... [tar xfz]      extracting... [analysis]      extracting... [rename]      extracting... [clean up]      extracting... done     [ 33%] No update step for 'fp16'     [ 44%] No patch step for 'fp16'     [ 55%] No configure step for 'fp16'     [ 66%] No build step for 'fp16'     [ 77%] No install step for 'fp16'     [ 88%] No test step for 'fp16'     [100%] Completed 'fp16'     [100%] Built target fp16      The ASM compiler identification is GNU      Found assembler: /usr/bin/: /usr/bin/ccache      Building for XNNPACK_TARGET_PROCESSOR: x86_64      Downloading cpuinfo to /home/raphy/Grasp/tflite_build/cpuinfosource (define CPUINFO_SOURCE_DIR to avoid it)     CMake Deprecation Warning at CMakeLists.txt:9 (CMAKE_MINIMUM_REQUIRED):       Compatibility with CMake  value.  Or, use the ... syntax       to tell CMake that the project requires at least  but has been updated       to work with policies introduced by  or earlier.      Configuring done (0.0s)      Generating done (0.0s)      Build files have been written to: /home/raphy/Grasp/tflite_build/cpuinfodownload     [ 11%] Creating directories for 'cpuinfo'     [ 22%] Performing download step (download, verify and extract) for 'cpuinfo'      Downloading...        dst='/home/raphy/Grasp/tflite_build/cpuinfodownload/cpuinfoprefix/src/8a1772a0c5c447df2d18edf33ec4603a8c9c04a6.zip'        timeout='none'        inactivity timeout='none'      Using src='https://github.com/pytorch/cpuinfo/archive/8a1772a0c5c447df2d18edf33ec4603a8c9c04a6.zip'      [download 0% complete]      [download 1% complete]      [download 2% complete]      [download 3% complete]      [download 4% complete]      [download 5% complete]      [download 6% complete]      [download 7% complete]      [download 8% complete]      [download 9% complete]      [download 10% complete]      [download 11% complete]      [download 12% complete]      [download 13% complete]      [download 14% complete]      [download 15% complete]      [download 16% complete]      [download 17% complete]      [download 18% complete]      [download 19% complete]      [download 20% complete]      [download 21% complete]      [download 22% complete]      [download 23% complete]      [download 24% complete]      [download 25% complete]      [download 26% complete]      [download 27% complete]      [download 28% complete]      [download 29% complete]      [download 30% complete]      [download 31% complete]      [download 32% complete]      [download 33% complete]      [download 34% complete]      [download 35% complete]      [download 36% complete]      [download 37% complete]      [download 38% complete]      [download 39% complete]      [download 40% complete]      [download 41% complete]      [download 42% complete]      [download 43% complete]      [download 44% complete]      [download 45% complete]      [download 46% complete]      [download 47% complete]      [download 48% complete]      [download 49% complete]      [download 50% complete]      [download 51% complete]      [download 52% complete]      [download 53% complete]      [download 54% complete]      [download 55% complete]      [download 56% complete]      [download 57% complete]      [download 58% complete]      [download 59% complete]      [download 60% complete]      [download 61% complete]      [download 62% complete]      [download 63% complete]      [download 64% complete]      [download 65% complete]      [download 66% complete]      [download 67% complete]      [download 68% complete]      [download 69% complete]      [download 70% complete]      [download 71% complete]      [download 72% complete]      [download 73% complete]      [download 74% complete]      [download 75% complete]      [download 76% complete]      [download 77% complete]      [download 78% complete]      [download 79% complete]      [download 80% complete]      [download 81% complete]      [download 82% complete]      [download 83% complete]      [download 84% complete]      [download 85% complete]      [download 86% complete]      [download 87% complete]      [download 88% complete]      [download 89% complete]      [download 90% complete]      [download 91% complete]      [download 92% complete]      [download 93% complete]      [download 94% complete]      [download 95% complete]      [download 96% complete]      [download 97% complete]      [download 98% complete]      [download 99% complete]      [download 100% complete]      verifying file...            file='/home/raphy/Grasp/tflite_build/cpuinfodownload/cpuinfoprefix/src/8a1772a0c5c447df2d18edf33ec4603a8c9c04a6.zip'      Downloading... done      extracting...          src='/home/raphy/Grasp/tflite_build/cpuinfodownload/cpuinfoprefix/src/8a1772a0c5c447df2d18edf33ec4603a8c9c04a6.zip'          dst='/home/raphy/Grasp/tflite_build/cpuinfosource'      extracting... [tar xfz]      extracting... [analysis]      extracting... [rename]      extracting... [clean up]      extracting... done     [ 33%] No update step for 'cpuinfo'     [ 44%] No patch step for 'cpuinfo'     [ 55%] No configure step for 'cpuinfo'     [ 66%] No build step for 'cpuinfo'     [ 77%] No install step for 'cpuinfo'     [ 88%] No test step for 'cpuinfo'     [100%] Completed 'cpuinfo'     [100%] Built target cpuinfo      Downloading FXdiv to /home/raphy/Grasp/tflite_build/FXdivsource (define FXDIV_SOURCE_DIR to avoid it)     CMake Deprecation Warning at CMakeLists.txt:9 (CMAKE_MINIMUM_REQUIRED):       Compatibility with CMake  value.  Or, use the ... syntax       to tell CMake that the project requires at least  but has been updated       to work with policies introduced by  or earlier.      Configuring done (0.0s)      Generating done (0.0s)      Build files have been written to: /home/raphy/Grasp/tflite_build/FXdivdownload     [ 11%] Creating directories for 'fxdiv'     [ 22%] Performing download step (download, verify and extract) for 'fxdiv'      Downloading...        dst='/home/raphy/Grasp/tflite_build/FXdivdownload/fxdivprefix/src/b408327ac2a15ec3e43352421954f5b1967701d1.zip'        timeout='none'        inactivity timeout='none'      Using src='https://github.com/Maratyszcza/FXdiv/archive/b408327ac2a15ec3e43352421954f5b1967701d1.zip'      [download 78% complete]      [download 100% complete]      verifying file...            file='/home/raphy/Grasp/tflite_build/FXdivdownload/fxdivprefix/src/b408327ac2a15ec3e43352421954f5b1967701d1.zip'      Downloading... done      extracting...          src='/home/raphy/Grasp/tflite_build/FXdivdownload/fxdivprefix/src/b408327ac2a15ec3e43352421954f5b1967701d1.zip'          dst='/home/raphy/Grasp/tflite_build/FXdivsource'      extracting... [tar xfz]      extracting... [analysis]      extracting... [rename]      extracting... [clean up]      extracting... done     [ 33%] No update step for 'fxdiv'     [ 44%] No patch step for 'fxdiv'     [ 55%] No configure step for 'fxdiv'     [ 66%] No build step for 'fxdiv'     [ 77%] No install step for 'fxdiv'     [ 88%] No test step for 'fxdiv'     [100%] Completed 'fxdiv'     [100%] Built target fxdiv      Downloading pthreadpool to /home/raphy/Grasp/tflite_build/pthreadpoolsource (define PTHREADPOOL_SOURCE_DIR to avoid it)     CMake Deprecation Warning at CMakeLists.txt:9 (CMAKE_MINIMUM_REQUIRED):       Compatibility with CMake  value.  Or, use the ... syntax       to tell CMake that the project requires at least  but has been updated       to work with policies introduced by  or earlier.      Configuring done (0.0s)      Generating done (0.0s)      Build files have been written to: /home/raphy/Grasp/tflite_build/pthreadpooldownload     [ 11%] Creating directories for 'pthreadpool'     [ 22%] Performing download step (download, verify and extract) for 'pthreadpool'      Downloading...        dst='/home/raphy/Grasp/tflite_build/pthreadpooldownload/pthreadpoolprefix/src/4e80ca24521aa0fb3a746f9ea9c3eaa20e9afbb0.zip'        timeout='none'        inactivity timeout='none'      Using src='https://github.com/google/pthreadpool/archive/4e80ca24521aa0fb3a746f9ea9c3eaa20e9afbb0.zip'      verifying file...            file='/home/raphy/Grasp/tflite_build/pthreadpooldownload/pthreadpoolprefix/src/4e80ca24521aa0fb3a746f9ea9c3eaa20e9afbb0.zip'      Downloading... done      extracting...          src='/home/raphy/Grasp/tflite_build/pthreadpooldownload/pthreadpoolprefix/src/4e80ca24521aa0fb3a746f9ea9c3eaa20e9afbb0.zip'          dst='/home/raphy/Grasp/tflite_build/pthreadpoolsource'      extracting... [tar xfz]      extracting... [analysis]      extracting... [rename]      extracting... [clean up]      extracting... done     [ 33%] No update step for 'pthreadpool'     [ 44%] No patch step for 'pthreadpool'     [ 55%] No configure step for 'pthreadpool'     [ 66%] No build step for 'pthreadpool'     [ 77%] No install step for 'pthreadpool'     [ 88%] No test step for 'pthreadpool'     [100%] Completed 'pthreadpool'     [100%] Built target pthreadpool      Found Python: /home/raphy/miniconda3/bin/python3.12 (found version ""3.12.8"") found components: Interpreter      Generating microkernels.cmake     No microkernel found in src/reference/unaryelementwise./reference/binaryelementwise./reference/packing.: /usr/bin/ccache           3.21.9.0      Performing Test protobuf_HAVE_LD_VERSION_SCRIPT      Performing Test protobuf_HAVE_LD_VERSION_SCRIPT  Success      Performing Test protobuf_HAVE_BUILTIN_ATOMICS      Performing Test protobuf_HAVE_BUILTIN_ATOMICS  Success      Configuring done (45.5s)     CMake Error: install(EXPORT ""tensorflowliteTargets"" ...) includes target ""tensorflowlite"" which requires target ""pthreadpool"" that is not in any export set.     CMake Error: install(EXPORT ""tensorflowliteTargets"" ...) includes target ""tensorflowlite"" which requires target ""xnnpackdelegate"" that is not in any export set.     CMake Error: install(EXPORT ""tensorflowliteTargets"" ...) includes target ""tensorflowlite"" which requires target ""XNNPACK"" that is not in any export set.      Generating done (0.7s)     CMake Generate step failed.  Build files cannot be regenerated correctly.  Standalone code to reproduce the issue ```shell (base) raphy:~/Grasp/tflite_build$ cmake ../../tensorflow_src/tensorflow/lite/ \     > DTFLITE_ENABLE_INSTALL=ON \     > DCMAKE_FIND_PACKAGE_PREFER_CONFIG=ON \     > DSYSTEM_FARMHASH=ON \     > DSYSTEM_PTHREADPOOL=ON \     > DEigen3_DIR=/home/raphy/Grasp/eigen/share/eigen3/cmake \     > DFlatBuffers_DIR=/home/raphy/Grasp/flatbuffers/lib/cmake/flatbuffers \     > Dcpuinfo_DIR=/home/raphy/Grasp/cpuinfo/share/cpuinfo \     > Druy_DIR=/home/raphy/Grasp/ruy/lib/cmake/ruy \     > DNEON_2_SSE_DIR=/home/raphy/Grasp/NEON_2_SSE/lib/cmake/NEON_2_SSE \     > Dabsl_DIR=/home/raphy/Grasp/abseilcpp/lib/cmake/absl \     > Dgemmlowp_DIR=/usr/lib/x86_64linuxgnu/cmake/gemmlowp \     > Wnodev  The C compiler identification is GNU 13.3.0  The CXX compiler identification is GNU 14.2.0  Detecting C compiler ABI info  Detecting C compiler ABI info  done  Check for working C compiler: /usr/bin/: /usr/bin/c++  skipped  Detecting CXX compile features  Detecting CXX compile features  done  Performing Test CMAKE_HAVE_LIBC_PTHREAD  Performing Test CMAKE_HAVE_LIBC_PTHREAD  Success  Found Threads: TRUE  Found farmhash: /usr/lib/x86_64linuxgnu/libfarmhash.so ```  Relevant log output ```shell ```",2025-02-12T18:05:05Z,type:build/install comp:lite subtype: ubuntu/linux,open,0,3,https://github.com/tensorflow/tensorflow/issues/87172,"Hi, collab I apologize for the delayed response, I see a similar issue please refer this workaround mentioned in this comment and see is it resolving your issue or not ? If issue still persists please let us know with updated error log for further investigation from our end.  Thank you for your cooperation and patience.","Hi   I did everything from scratch      (base) raphy:~$ mkdir NEW     (base) raphy:~$ cd NEW     (base) raphy:~/NEW$ git clone recursesubmodules https://github.com/tensorflow/tensorflow.git     Cloning into 'tensorflow'...     remote: Enumerating objects: 1977738, done.     remote: Counting objects: 100% (1682/1682), done.     remote: Compressing objects: 100% (758/758), done.     remote: Total 1977738 (delta 1298), reused 936 (delta 924), packreused 1976056 (from 3)     Receiving objects: 100% (1977738/1977738), 1.08 GiB | 31.86 MiB/s, done.     Resolving deltas: 100% (1627307/1627307), done.     Updating files: 100% (34863/34863), done.     (base) raphy:~/NEW$ mkdir tflite_build According to the comment https://github.com/tensorflow/tensorflow/issues/57658issuecomment1534245153 I should modify the XNNPACK's CMakeLists.txt and the ptreadpool's CMakeLists.txt files :       (base) raphy:~/NEW/tensorflow$ find name  ""CMakeLists.txt""     ./tensorflow/lite/kernels/CMakeLists.txt     ./tensorflow/lite/CMakeLists.txt     ./tensorflow/lite/examples/minimal/CMakeLists.txt     ./tensorflow/lite/examples/label_image/CMakeLists.txt     ./tensorflow/lite/profiling/proto/CMakeLists.txt     ./tensorflow/lite/tools/benchmark/CMakeLists.txt     ./tensorflow/lite/tools/cmake/modules/ml_dtypes/CMakeLists.txt     ./tensorflow/lite/tools/cmake/modules/farmhash/CMakeLists.txt     ./tensorflow/lite/tools/cmake/modules/fft2d/CMakeLists.txt     ./tensorflow/lite/tools/cmake/modules/xnnpack/CMakeLists.txt     ./tensorflow/lite/tools/cmake/native_tools/flatbuffers/CMakeLists.txt     ./tensorflow/lite/c/CMakeLists.txt     ./tensorflow/tools/pip_package/xla_build/CMakeLists.txt     ./tensorflow/tools/pip_package/xla_build/pip_test/CMakeLists.txt     ./tensorflow/core/example/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/cmake/modules/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/utils/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/mhlo/IR/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/mhlo/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/mhlo/analysis/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/mhlo/utils/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/mhlo/transforms/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/tools/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/tools/mlirhloopt/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/transforms/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/deallocation/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/deallocation/utils/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/deallocation/transforms/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/stablehlo_ext/IR/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/stablehlo_ext/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/bindings/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/bindings/c/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/bindings/python/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/tests/CMakeLists.txt     ./third_party/xla/xla/mlir_hlo/tests/python/CMakeLists.txt But the XNNPACK's CMakeLists.txt file contains just these lines :      (base) raphy:~/NEW/tensorflow$ cat ./tensorflow/lite/tools/cmake/modules/xnnpack/CMakeLists.txt           Copyright 2022 The TensorFlow Authors. All Rights Reserved.           Licensed under the Apache License, Version 2.0 (the ""License"");      you may not use this file except in compliance with the License.      You may obtain a copy of the License at                https://www.apache.org/licenses/LICENSE2.0           Unless required by applicable law or agreed to in writing, software      distributed under the License is distributed on an ""AS IS"" BASIS,      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.      See the License for the specific language governing permissions and      limitations under the License.      The ""mcpu="" switch might be introduced externaly into CMake: either in _FLAGS or      as part of CC, CXX, ASM environmental variables (to be stored in CMAKE__COMPILER_ARG1).      This switch is not compatible with XNNPACK build mechanism and causes the XNNPACK compilation      break due to ""unsupported instructions"". This switch needs to be removed for XNNPACK      In order to isolate the changes only for XNNPACK and its depencencies, a subfolder is      introduced.     foreach(FLAG IN ITEMS CMAKE_ASM_FLAGS CMAKE_ASM_COMPILER_ARG1 CMAKE_C_FLAGS CMAKE_C_COMPILER_ARG1 CMAKE_CXX_FLAGS CMAKE_CXX_COMPILER_ARG1)       if(${FLAG})         string(REGEX REPLACE ""mcpu=[azAZ09_.^$*+?]*"" """" _tmp ${${FLAG}})         set(${FLAG} ${_tmp})       endif()     endforeach()     add_subdirectory(       ""${xnnpack_SOURCE_DIR}""       ""${xnnpack_BINARY_DIR}"" and not the lines that, according to the comment, should be modified And, as you can see from the list of CMakeLists.txt files, the CMakeLists.txt file for pthreadpool is not present What am I missing and/or doing wrong? How to make it work?",after i finished cross compiling it seems like there is a symbol missing ``` Error relocating libtensorflowlite.so: TfLiteXNNPackDelegateOptionsDefault: symbol not found Error relocating libtensorflowlite.so: TfLiteXNNPackDelegateCreateWithThreadpool: symbol not found Error relocating libtensorflowlite.so: TfLiteXNNPackDelegateDelete: symbol not found ```
rag,copybara-service[bot],PR #22541: [ROCm] Cleanup atomics support,"PR CC(Java process crashes during model loading): [ROCm] Cleanup atomics support Imported from GitHub PR https://github.com/openxla/xla/pull/22541 Weaken the ordering barriers to match what atomicAdd does on rocm. Emulate fp16 atomic on top of packed fp16 atomic where possible. Also for bfloat16 atomics, albeit those don't get matched right now due to FloatNormalization. Left in support for fp16 and bfloat16 vector atomics. We might enable the vectorization for them in the future if we can prove the access satisfies 4byte aligment. Copybara import of the project:  b4ac2bc984b40bb33f287a4ed351b6c1560e6895 by Dragan Mladjenovic : [ROCm] Cleanup atomics support Merging this change closes CC(Java process crashes during model loading) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22541 from ROCm:atomics_cleanup b4ac2bc984b40bb33f287a4ed351b6c1560e6895",2025-02-12T14:48:27Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87158
gemma,copybara-service[bot],[XLA:GPU] Add a debug option `xla_gpu_unsupported_force_triton_gemm` for use,[XLA:GPU] Add a debug option `xla_gpu_unsupported_force_triton_gemm` for use in tests. This is to work around issues of test parametrization while `xla_gpu_enable_triton_gemm_any` needs to be worked around in the main compiler path for A100.,2025-02-12T09:32:01Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87148
gemma,copybara-service[bot],[XLA:GPU] Add a debug option `xla_gpu_unsupported_force_triton_gemm` for use,[XLA:GPU] Add a debug option `xla_gpu_unsupported_force_triton_gemm` for use in tests. This is to work around issues of test parametrization while `xla_gpu_enable_triton_gemm_any` needs to be worked around in the main compiler path for A100.,2025-02-12T09:23:38Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87143
gemma,copybara-service[bot],[XLA:GPU] Add a debug option `xla_gpu_unsupported_force_triton_gemm` for use,[XLA:GPU] Add a debug option `xla_gpu_unsupported_force_triton_gemm` for use in tests. This is to work around issues of test parametrization while `xla_gpu_enable_triton_gemm_any` needs to be worked around in the main compiler path for A100.,2025-02-12T07:51:52Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87109
yi,copybara-service[bot],Internal change only.,Internal change only.,2025-02-11T23:41:41Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87090
yi,copybara-service[bot],internal BUILD rule visibility,internal BUILD rule visibility,2025-02-11T23:29:57Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/87088
gemma,copybara-service[bot],[XLA:GPU] Disable `--xla_gpu_triton_gemm_any` on Ampere.,"[XLA:GPU] Disable `xla_gpu_triton_gemm_any` on Ampere. Triton's conversion logic from `f16` to `f8e5m2` is wrong preHopper. Disabling this wholesale is a bit overkill, but easiestsince this flag flip is what surfaced the issue in the first place.",2025-02-11T19:30:30Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87077
rag,copybara-service[bot],PR #22509: [ROCm] Avoid hardcoding hipcc compiler includes,PR CC(Make sure broken tests are filtered out in XLA tests suites.): [ROCm] Avoid hardcoding hipcc compiler includes Imported from GitHub PR https://github.com/openxla/xla/pull/22509 Copybara import of the project:  f4e7d6d91fa349eab54478a9f03875159378f237 by Dragan Mladjenovic : [ROCm] Avoid hardcoding hipcc compiler includes Merging this change closes CC(Make sure broken tests are filtered out in XLA tests suites.) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22509 from ROCm:automatic_include f4e7d6d91fa349eab54478a9f03875159378f237,2025-02-11T14:02:22Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87055
rag,copybara-service[bot],PR #22452: [ROCm] Fix missing header in hipblaslt_wrapper.h,PR CC(Documentation for tf.train.init_from_checkpoint doesn't say what it does when): [ROCm] Fix missing header in hipblaslt_wrapper.h Imported from GitHub PR https://github.com/openxla/xla/pull/22452 Copybara import of the project:  225a63f3d9596e8827bf04904d9b8691de2b0bc7 by Dragan Mladjenovic : [ROCm] Fix missing header in hipblaslt_wrapper.h Merging this change closes CC(Documentation for tf.train.init_from_checkpoint doesn't say what it does when) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22452 from ROCm:hipblaslt_wrapper 225a63f3d9596e8827bf04904d9b8691de2b0bc7,2025-02-11T11:05:44Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87045
yi,copybara-service[bot],[IFRT] Fully support the dtype arg to AssembleArrayFromSingleDeviceArrays in IFRT Proxy.,[IFRT] Fully support the dtype arg to AssembleArrayFromSingleDeviceArrays in IFRT Proxy.,2025-02-11T05:26:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/87006
transformer,copybara-service[bot],PR #85477: Integrate Op Builder with LiteRT Compile Part,"PR CC(Integrate Op Builder with LiteRT Compile Part): Integrate Op Builder with LiteRT Compile Part Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/85477  WHAT We replace the compiler part with Qualcomm implementations. This PR include commits in 3 PRs below. Follow these PRs or commit should help you review. You can get more details in the PR descriptions. 1. https://github.com/jiunkaiy/tensorflow/pull/1 2. https://github.com/jiunkaiy/tensorflow/pull/3 3. https://github.com/jiunkaiy/tensorflow/pull/5  TEST You can checkout this branch and run this test: ``` bazel build  c opt cxxopt=std=c++20 //tensorflow/lite/experimental/litert/vendors/qualcomm/compiler:qnn_compiler_plugin_test ./bazelbin/tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compiler_plugin_test ``` I disable these models because I don't have them.  kFeedForwardModel,  kKeyEinsumModel,  kQueryEinsumModel,  kValueEinsumModel,  kAttnVecEinsumModel,  kROPEModel,  kLookUpROPEModel,  kRMSNormModel,  kSDPAModel,  kAttentionModel,  kTransformerBlockModel,  kQSimpleMul16x16Model,  kQMulAdd16x16Model,  kQQueryEinsum16x8Model,  kQKeyEinsum16x8Model,  kQVauleEinsum16x8Model,  kQAttnVecEinsum16x8Model And you will see ``` [] Global test environment teardown [==========] 55 tests from 3 test suites ran. (338 ms total) [  PASSED  ] 54 tests. [  FAILED  ] 1 test, listed below: [  FAILED  ] SupportedOpsTest/QnnPluginOpValidationTest.SupportedOpsTest/4, where GetParam() = ""simple_slice_op.tflite"" ``` There are some bugs in simple_slice_op.mlir so the op validation will fail. Copybara import of the project:  b89672b2c477564b7dbcf0a327d860810461c151 by weilhuanquic : 1. Replace compiler part with op builders in core module 2. Support Op validation 3. Add unit tests for partition and compile Merging this change closes CC(Integrate Op Builder with LiteRT Compile Part) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85477 from jiunkaiy:dev/weilhuan/integrate_litert b89672b2c477564b7dbcf0a327d860810461c151",2025-02-10T19:51:41Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86971
rag,copybara-service[bot],This change:,"This change:   creates an empty class HloCustomCallInstruction::PerInstructionStorage, with a getter and a locked setter on the parent class that will act exactly once.   tests for above",2025-02-10T15:03:48Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86952
gemma,copybara-service[bot],[XLA:GPU] Turn `--xla_gpu_triton_gemm_any` on by default.,[XLA:GPU] Turn `xla_gpu_triton_gemm_any` on by default.,2025-02-10T10:16:28Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86946
agent,epokrso,Bug sur TensorFlow 2.13 multi-GPU : freeze lors du fitting," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Macos 15.3 (worker 0) Macos 12.7.6(worker 1)  Mobile device _No response_  Python version 3.8.20  Bazel version ...  GCC/compiler version 16.0.0 (apple M3) 14.0.0 (intel iris)  CUDA/cuDNN version _No response_  GPU model and memory Apple M3 and Intel Iris Graphics 6100  Current behavior? When I train a TensorFlow model on several GPUs (with tf.distribute.MultiWorkerMirroredStrategy), the execution is blocked at  Build the model under the strategy No error message is displayed, but the process no longer progresses after •	 I followed the recommendations of the official documentation, but the problem persists.  Standalone code to reproduce the issue ```shell import json import os import numpy as np import tensorflow as tf TF_CONFIG = {     ""cluster"": {         ""worker"": [""192.168.0.68:12345"", ""192.168.0.68:12346""]     },     ""task"": {""type"": ""worker"", ""index"": 0}   Modifier index pour chaque worker } os.environ[""TF_CONFIG""] = json.dumps(TF_CONFIG)  Manually Load the MNIST dataset data = np.load(""mnist.npz"") x_train, y_train = data[""x_train""], data[""y_train""] x_test, y_test = data[""x_test""], data[""y_test""]  Normalize images x_train, x_test = x_train / 255.0, x_test / 255.0  Add a dimension to match TensorFlow's expectations x_train = x_train[..., np.newaxis] x_test = x_test[..., np.newaxis]  Define the distribution strategy strategy = tf.distribute.MultiWorkerMirroredStrategy()  Build the model under the strategy with strategy.scope():     model = tf.keras.Sequential([         tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),         tf.keras.layers.MaxPooling2D((2, 2)),         tf.keras.layers.Flatten(),         tf.keras.layers.Dense(128, activation='relu'),         tf.keras.layers.Dense(10, activation='softmax')     ])     model.compile(optimizer='adam',                   loss='sparse_categorical_crossentropy',                   metrics=['accuracy']) model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test)) test_loss, test_acc = model.evaluate(x_test, y_test) print(f""Test accuracy: {test_acc:.4f}"") ```  Relevant log output ```shell 20250208 12:29:20.630247: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 20250208 12:29:20.630286: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB 20250208 12:29:20.630293: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB 20250208 12:29:20.630324: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 20250208 12:29:20.630338: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) > physical PluggableDevice (device: 0, name: METAL, pci bus id: ) 20250208 12:29:20.631249: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 20250208 12:29:20.631259: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 0 MB memory) > physical PluggableDevice (device: 0, name: METAL, pci bus id: ) 20250208 12:29:20.632347: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:449] Started server with target: grpc://192.168.0.68:12345 20250208 12:29:20.637550: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:535] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 14287335759644278642 20250208 12:29:20.637654: I tensorflow/tsl/distributed_runtime/coordination/coordination_service_agent.cc:298] Coordination agent has successfully connected. 20250208 12:29:37.728182: I tensorflow/tsl/distributed_runtime/coordination/coordination_service.cc:535] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 15227140312468372989 ```",2025-02-08T11:40:33Z,stat:awaiting tensorflower type:bug comp:gpu TF 2.13,open,0,1,https://github.com/tensorflow/tensorflow/issues/86897,"I was able to reproduce the same issue with a single GPU using TensorFlow 2.13. Below, I am attaching the output for your reference. ``` python multiworker_train.py TF_CONFIG: {'cluster': {'worker': ['192.168.0.68:12345', '192.168.0.68:12346']}, 'task': {'type': 'worker', 'index': 1}} 20250210 10:59:31.700945: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro 20250210 10:59:31.700969: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB 20250210 10:59:31.700978: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB 20250210 10:59:31.701009: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 20250210 10:59:31.701023: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) > physical PluggableDevice (device: 0, name: METAL, pci bus id: ) 20250210 10:59:31.702173: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 20250210 10:59:31.702184: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:worker/replica:0/task:1/device:GPU:0 with 0 MB memory) > physical PluggableDevice (device: 0, name: METAL, pci bus id: ) 20250210 10:59:31.704488: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:449] Started server with target: grpc://192.168.0.68:12346 ``` Thank you!"
yi,copybara-service[bot],Fixes a build failure in macos_arm64 environment that disallows `static_cast`ing 'const npy_intp *' (aka 'const long *') to 'const int64_t *' (aka 'const long long *').,Fixes a build failure in macos_arm64 environment that disallows `static_cast`ing 'const npy_intp *' (aka 'const long *') to 'const int64_t *' (aka 'const long long *'). This is fixed by explicitly iterating and building the int64_t Span.,2025-02-07T20:19:07Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86854
rag,copybara-service[bot],"[XLA:GPU] Add triton support test for ragged-all-to-all, rng-x and complex","[XLA:GPU] Add triton support test for raggedalltoall, rngx and complex",2025-02-07T10:57:40Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86830
gemma,copybara-service[bot],[xla:cpu] Add run and setup scripts for e2e gemma2 pyTorch,[xla:cpu] Add run and setup scripts for e2e gemma2 pyTorch,2025-02-06T21:27:26Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86785
rag,copybara-service[bot],Remove Thunk::Cleanup method.,"Remove Thunk::Cleanup method. The method was effectively unused, since it wasn't overridden by SequentialThunk, and so SequentialThunk wouldn't call Cleanup on its subthunks. NcclRaggedAllToAllStartThunk overrode Cleanup to free some device buffers, but these were never freed since Cleanup was not called. The memory is now stored in DeviceMemoryHandles, which automatically free the buffers in the destructor.",2025-02-06T21:14:48Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86783
yi,copybara-service[bot],Internal change only.,Internal change only.,2025-02-06T21:08:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86782
yi,copybara-service[bot],[XLA:GPU] Do not regard the 'fusion' op as part of the `HloComputationFusion`.,"[XLA:GPU] Do not regard the 'fusion' op as part of the `HloComputationFusion`. Instead, check for this case in `ResolveUsers` and `ResolveOperand`, by querying whether the `fused_expression_root` is part of the `HloFusionAdaptor`. This prevents us from stepping into nested fusions.",2025-02-06T16:46:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86762
yi,copybara-service[bot],Fix race condition in FenceInsertionPass,"Fix race condition in FenceInsertionPass It looks like the idea here was to add some basic memoization so we don't end up with a ton of recursive calls, and potentially deadlock. However, doing that through a static variable is problematic both because it's not threadsafe, and because it's a silent memory leak, since we never free up the set (so a longrunning program would just continue adding stuff to it as we compile new kernels indefinitely). I'm still trying to get a good upstreamable reproducer, but this should fix the issue for now so we don't crash in production.",2025-02-06T16:15:22Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86760
yi,copybara-service[bot],[xla:emitters] fix type mismatch for several passes,[xla:emitters] fix type mismatch for several passes I've seen Windows failures because of these after applying some upcoming changes. Fix them.,2025-02-06T15:36:16Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86757
yi,AlanBogarin,unexpected import during stub creation from mypy-protobuf," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version master  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.12.8  Bazel version 6.5.0  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm doing a stub distribution for tensorflow, and when I used mypyprotobuf to create stubs for .proto files, it resulted in an import that I didn't expect The format it should create is: ```python import tensorflow.tsl.protobuf.histogram_pb2 ``` but it does ```python import xla.tsl.protobuf.histogram_pb2 ``` I don't really understand how they structure the configurations to compile from Bazel Is there a setting I'm missing, or should I make the change manually? Is there a way for tensorflow to automatically create the stubs files from the compiled proto files? Here I leave you the code to speed up your analysis. third_party\xla\xla\tsl\protobuf\histogram.proto ```proto syntax = ""proto3""; package tensorflow; option cc_enable_arenas = true; option java_multiple_files = true; option java_package = ""org.tensorflow.framework""; option go_package = ""github.com/google/tsl/tsl/go/core/protobuf/summary_go_proto""; // Serialization format for histogram module in // tsl/lib/histogram/histogram.h message HistogramProto {   double min = 1;   double max = 2;   double num = 3;   double sum = 4;   double sum_squares = 5;   // Parallel arrays encoding the bucket boundaries and the bucket values.   // bucket(i) is the count for the bucket i.  The range for   // a bucket is:   //   i == 0:  DBL_MAX .. bucket_limit(0)   //   i != 0:  bucket_limit(i1) .. bucket_limit(i)   repeated double bucket_limit = 6 [packed = true];   repeated double bucket = 7 [packed = true]; } ``` tensorflow\core\framework\summary.proto ```proto syntax = ""proto3""; package tensorflow; import public ""xla/tsl/protobuf/histogram.proto""; import ""tensorflow/core/framework/tensor.proto""; option cc_enable_arenas = true; option java_outer_classname = ""SummaryProtos""; option java_multiple_files = true; option java_package = ""org.tensorflow.framework""; option go_package = ""github.com/tensorflow/tensorflow/tensorflow/go/core/framework/summary_go_proto""; // Metadata associated with a series of Summary data message SummaryDescription {   // Hint on how plugins should process the data in this series.   // Supported values include ""scalar"", ""histogram"", ""image"", ""audio""   string type_hint = 1; } // A SummaryMetadata encapsulates information on which plugins are able to make // use of a certain summary value. message SummaryMetadata {   message PluginData {     // The name of the plugin this data pertains to.     string plugin_name = 1;     // The content to store for the plugin. The best practice is for this to be     // a binary serialized protocol buffer.     bytes content = 2;   }   // Data that associates a summary with a certain plugin.   PluginData plugin_data = 1;   // Display name for viewing in TensorBoard.   string display_name = 2;   // Longform readable description of the summary sequence. Markdown supported.   string summary_description = 3;   // Class of data stored in this time series. Required for compatibility with   // TensorBoard's generic data facilities (`DataProvider`, et al.). This value   // imposes constraints on the dtype and shape of the corresponding tensor   // values. See `DataClass` docs for details.   DataClass data_class = 4; } enum DataClass {   // Unknown data class, used (implicitly) for legacy data. Will not be   // processed by data ingestion pipelines.   DATA_CLASS_UNKNOWN = 0;   // Scalar time series. Each `Value` for the corresponding tag must have   // `tensor` set to a rank0 tensor of type `DT_FLOAT` (float32).   DATA_CLASS_SCALAR = 1;   // Tensor time series. Each `Value` for the corresponding tag must have   // `tensor` set. The tensor value is arbitrary, but should be small to   // accommodate direct storage in database backends: an upper bound of a few   // kilobytes is a reasonable rule of thumb.   DATA_CLASS_TENSOR = 2;   // Blob sequence time series. Each `Value` for the corresponding tag must   // have `tensor` set to a rank1 tensor of bytestring dtype.   DATA_CLASS_BLOB_SEQUENCE = 3; } // A Summary is a set of named values to be displayed by the // visualizer. // // Summaries are produced regularly during training, as controlled by // the ""summary_interval_secs"" attribute of the training operation. // Summaries are also produced at the end of an evaluation. message Summary {   message Image {     // Dimensions of the image.     int32 height = 1;     int32 width = 2;     // Valid colorspace values are     //   1  grayscale     //   2  grayscale + alpha     //   3  RGB     //   4  RGBA     //   5  DIGITAL_YUV     //   6  BGRA     int32 colorspace = 3;     // Image data in encoded format.  All image formats supported by     // image_codec::CoderUtil can be stored here.     bytes encoded_image_string = 4;   }   message Audio {     // Sample rate of the audio in Hz.     float sample_rate = 1;     // Number of channels of audio.     int64 num_channels = 2;     // Length of the audio in frames (samples per channel).     int64 length_frames = 3;     // Encoded audio data and its associated RFC 2045 content type (e.g.     // ""audio/wav"").     bytes encoded_audio_string = 4;     string content_type = 5;   }   message Value {     // This field is deprecated and will not be set.     string node_name = 7;     // Tag name for the data. Used by TensorBoard plugins to organize data. Tags     // are often organized by scope (which contains slashes to convey     // hierarchy). For example: foo/bar/0     string tag = 1;     // Contains metadata on the summary value such as which plugins may use it.     // Take note that many summary values may lack a metadata field. This is     // because the FileWriter only keeps a metadata object on the first summary     // value with a certain tag for each tag. TensorBoard then remembers which     // tags are associated with which plugins. This saves space.     SummaryMetadata metadata = 9;     // Value associated with the tag.     oneof value {       float simple_value = 2;       bytes obsolete_old_style_histogram = 3;       Image image = 4;       HistogramProto histo = 5;       Audio audio = 6;       TensorProto tensor = 8;     }   }   // Set of values for the summary.   repeated Value value = 1; } ```  Standalone code to reproduce the issue ```shell Commands to recreate >>> git clone https://github.com/tensorflow/tensorflow.git >>> cd tensorflow >>> mkdir out >>> protoc tensorflow/core/framework/summary.proto mypy_out=out/ I=""."" I=""third_party/xla/"" ```  Relevant log output ```shell ```",2025-02-06T14:03:17Z,type:build/install type:support,open,0,3,https://github.com/tensorflow/tensorflow/issues/86752,", Could you please provide the error log which you are facing the issue. It helps to analyse the issue in an effective way. Thank you!","> [](https://github.com/AlanBogarin), Could you please provide the error log which you are facing the issue. It helps to analyse the issue in an effective way. Thank you! ``` PS D:\Alan\github> git clone https://github.com/tensorflow/tensorflow.git Cloning into 'tensorflow'... remote: Enumerating objects: 1972623, done. remote: Counting objects: 100% (428/428), done. remote: Compressing objects: 100% (280/280), done. remote: Total 1972623 (delta 289), reused 169 (delta 148), packreused 1972195 (from 2) Receiving objects: 100% (1972623/1972623), 1.07 GiB  None = ...,     ) > None: ...     def ClearField(self, field_name: typing.Literal[""value"", b""value""]) > None: ... global___Summary = Summary ```","When I install tensorflow with pip, tsl is inside tensorflow ``` tensorflow/     tsl/         profiler/             ...         protobuf/             histogram_pb2.py             ...         ...     ... ```"
yi,copybara-service[bot],Fix GatherClientLibraryTest under PjRt.,"Fix GatherClientLibraryTest under PjRt. It was unclear to me what this test was actually trying to achieve because it is not clearly documented. If it is trying to exercise a specific behavior with the old nonPjRt `Client`, then that should probably live elsewhere. I've converted it to something that can just run on top of `HloPjRtTestBase` directly. I added some boilerplate to allow the `XlaBuilder` code to remain, though it might be better to just use a HLO string directly.",2025-02-05T23:49:41Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86697
yi,copybara-service[bot],Removing some patches by:,Removing some patches by:  Upstreaming internal testto remove file entirely. Also removing patch with redundant (already upstream) tests.  Verifying an issue is already fixed.  Attempting to upstream 2 changes. Added comments to remove 2 more patches in a followup if they land successfully.,2025-02-05T13:29:55Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86642
yi,copybara-service[bot],internal change for visibilily,internal change for visibilily,2025-02-05T07:06:29Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86609
yi,copybara-service[bot],"In literal_util.cc, use absl::uniform_int_distribution.","In literal_util.cc, use absl::uniform_int_distribution. absl::uniform_int_distribution is faster than std::uniform_int_distribution. This makes initializing literals in run_hlo_module faster. In particular, I tested the following HLO:     ENTRY f {       arg = s8[2000000000] parameter(0)       ROOT add_result = s8[2000000000] add(arg, arg)     } It takes 7.8 seconds to initialize the input literal with the absl function, and 18.2 with the std function. I had to change several tests, which were sensitive to the exact values randomlyinitialized Literals were initialized to. Literals are initialized to a fixed seed, but this change causes such literals to be initialized to different values than before. Unfortunately the absl version of uniform_real_distribution is not faster. It takes 25.5 seconds with absl and 8.3 with std on the HLO when s8 is replaced with f16. The function does become faster if we use an absl::BitGen instead of an std::minstd_rand0, but this is considerable more work to implement as it will affect many places in the codebase which currently use an std::minstd_rand0. Also, changing the floatingpoint RNG algorithm will likely cause many more tests to fail which are inadvertently reliant on the current specific values literals are initialized to. Maybe I'll do this in the future, maybe not.",2025-02-05T03:37:18Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86599
yi,copybara-service[bot],Return arrays from `ArrayImpl._check_and_rearrange`.,"Return arrays from `ArrayImpl._check_and_rearrange`. This is in preparation for a larger change, so that input buffers can be checked before Array creation in XLA and the user gets more helpful JAX error messages instead of XLA errors. Reverts 135a67d02fc6282a323fc4ad42ef7d8a687995e6",2025-02-04T21:54:04Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86583
yi,copybara-service[bot],Stop modifying the TraceEventsContainer in DoStoreAsLevelDbTable. This behavior,Stop modifying the TraceEventsContainer in DoStoreAsLevelDbTable. This behavior is not intuitive (modifying a const value that was passed in) and unnecessary. Reverts changelist 723246423 FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805,2025-02-04T19:55:53Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/86577
yi,copybara-service[bot],[xla:copy_insertion] Avoid adding a redundant control dependence from a,"[xla:copy_insertion] Avoid adding a redundant control dependence from a pipelined RecvDone to its previous Recv in a whileloop. When we add a copy of the RecvDone, we also add a control dependence from the copy to the Recv. If the copy is later on remove, the control dependence from the RecvDone to the Recv becomes the only side effect of the pass, which is not intended.",2025-02-04T19:13:28Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/86576
rag,copybara-service[bot],[XLA:GPU] Add support for multiple updates per replica in RaggedAllToAll.,[XLA:GPU] Add support for multiple updates per replica in RaggedAllToAll. A recent proposal suggested to extend the API of ra2a to allow to send multiple updates in one op. Before we would need to emit multiple chained ra2a to achieve the same effect.,2025-02-04T18:57:28Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86573
rag,copybara-service[bot],Add memcpy implementation of ragged-all-to-all.,Add memcpy implementation of raggedalltoall. The implementation is similar to the memcpy implementation of alltoall.,2025-02-04T03:48:58Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86507
yi,copybara-service[bot],[XLA:GPU] move DotDecompose out of simplification pipeline,"[XLA:GPU] move DotDecompose out of simplification pipeline That seems to be a better approach then moving TransposeFold to simplification2 in 961e5c25fbd4082a1ac4f2e0865ad28163d12f7d: 1. There is a report that previous change has resulted in perf degradation https://github.com/openxla/xla/pull/22081 2. I have found another case when DotDecompose is competing with algsimp. Added a test for that. Overall, having an pass that expands operation together with passes that are trying to do the simplification asks for such infinite loops.  For archeologists:   passes DotDimensionSorter and DotDecomposer were added along with GpuAlgebraicSimplifier as it previously could have added multiple contracting dimensions to dot. But cudnn does not support dots with 2+ dimensions, forcing us to use a less efficient loop emitter.  That what ""// AlgebraicSimplifier may add contracting dimensions to a dot."" comment was about. After a while simplifier started to use supports_non_canonical_dots to guard against this case. So it should be safe to remove dot decomposer and friends. Reverts changelist 723246423 FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22258 from openxla:schedule_vlog 025352635a155e447559d83c471369559aad5981",2025-02-03T09:16:59Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/86443
rag,Cloudberrydotdev,User Guide: Deprecated Nvidia Docker Link," Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version any  Custom code No  OS platform and distribution Linux GPU  Mobile device _No response_  Python version any  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The link to the Nvidia Docker github https://github.com/NVIDIA/nvidiadocker?tab=readmeovfile Reports: This repository has been archived by the owner on Jan 22, 2024. It is now readonly.  and provides a link to: https://github.com/NVIDIA/nvidiacontainertoolkit Titled: Build and run containers leveraging NVIDIA GPUs   Standalone code to reproduce the issue ```shell This is a documentation bug and no code errors are involved. ```  Relevant log output ```shell See above ```",2025-02-02T09:16:37Z,type:docs-bug stat:awaiting response type:build/install stale,closed,0,9,https://github.com/tensorflow/tensorflow/issues/86407,https://www.tensorflow.org/install/docker Sorry I meant to include this url for the documentation page that holds the error link.,The relevant text is: Docker is the easiest way to enable TensorFlow GPU support on Linux since only the NVIDIA® GPU driver is required on the host machine (the NVIDIA® CUDA® Toolkit does not need to be installed). The link is in the text: NVIDIA® GPU driver,  您好，邮件已经收到，我会尽快处理的。谢谢,"Sam, Thanks for picking this up. I'm not sure what happens now. Do I wait for a reply from the Tensorflow documentation team before closing this issue? Regards Ian Berry On Sun, 2 Feb 2025, 16:35 Sam Fletcher, ***@***.***> wrote: > The issue is that the TensorFlow documentation still links to the > nowarchived NVIDIA Docker repository. Instead, it should link to the new, > active repository: > > Solution: > >    1. The TensorFlow documentation team needs to update the incorrect >    link. >    2. The old link: > >    https://github.com/NVIDIA/nvidiadocker?tab=readmeovfile > >    Should be replaced with: > >    https://github.com/NVIDIA/nvidiacontainertoolkit > >    3. If you're relying on the old NVIDIA Docker setup, transition to >    using the *NVIDIA Container Toolkit* as per the new repository. You >    can follow their official setup guide: > > For now, you can manually install TensorFlow with GPU support using the > NVIDIA Container Toolkit instead of the deprecated NVIDIA Docker. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >",", Thank you for reporting the issue. I have raised the internal request for the mentioned change and will be updated once it gets submitted. Thank you!",", The raised request was submitted and also the changes are reflected in the official document. https://www.tensorflow.org/install/dockertensorflow_docker_requirements reflecting to https://github.com/NVIDIA/nvidiacontainertoolkit !Image Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
text generation,dependabot[bot],Bump the github-actions group with 8 updates,"Bumps the githubactions group with 8 updates:  Updates `google/osvscanneraction` from 1.9.0 to 1.9.2  Release notes Sourced from google/osvscanneraction's releases.  v1.9.2 What's Changed  Update to v1.9.2 by @​hogo6002 in google/osvscanneraction CC(Can't install on ubuntu 12.04.5 LTS)  Full Changelog: https://github.com/google/osvscanneraction/compare/v1.9.1...v1.9.2 v1.9.1 What's Changed  Update to use osvscanner v1.9.1 chore(deps): update workflows by @​renovatebot in google/osvscanneraction CC(Integration with blaze ecosystem numba python to llvm compiler?) Update to v1.9.1 by @​anotherrex in google/osvscanneraction CC(error __init__() got an unexpected keyword argument 'syntax') chore(deps): update workflows by @​renovatebot in google/osvscanneraction CC(Object Detection)  Full Changelog: https://github.com/google/osvscanneraction/compare/v1.9.0...v1.9.1    Commits  764c918 Merge pull request  CC(Can't install on ubuntu 12.04.5 LTS) from google/updatetov1.9.2 af3118a Update unified workflow example to point to v1.9.2 reusable workflows e994fd8 Update reusable workflows to point to v1.9.2 actions f8115f2 Update actions to use v1.9.2 osvscanner image daa2c68 Merge pull request  CC(Object Detection) from renovatebot/renovate/workflows af00d40 chore(deps): update workflows c411404 Merge pull request  CC(error __init__() got an unexpected keyword argument 'syntax') from google/updatetov1.9.1 1ab2a61 Update unified workflow example to point to v1.9.1 reusable workflows 8bd1ce1 Update reusable workflows to point to v1.9.1 actions cbb0295 Update actions to use v1.9.1 osvscanner image Additional commits viewable in compare view    Updates `actions/setuppython` from 5.3.0 to 5.4.0  Release notes Sourced from actions/setuppython's releases.  v5.4.0 What's Changed Enhancements:  Update cache error message by @​aparnajyothiy in actions/setuppython CC(tensorflow.bzl.bzl doesn't exist, unsurprisingly) Enhance Workflows: Add Ubuntu24, Remove Python 3.8  by @​priyakinthali in actions/setuppython CC(Wrong file dimension when calling maybe_download function) Configure Dependabot settings by @​HarithaVattikuti in actions/setuppython CC(Minor comment spelling fix.)  Documentation changes:  Readme update  recommended permissions by @​benwells in actions/setuppython CC(Example code for SummaryIterator using `tf.train.summary_iterator`.) Improve Advanced Usage examples by @​lrq3000 in actions/setuppython CC(Casting int64 to int8 is not supported)  Dependency updates:  Upgrade undici from 5.28.4 to 5.28.5 by @​dependabot in actions/setuppython CC(pip installation failing on fedora) Upgrade urllib3 from 1.25.9 to 1.26.19 in /tests/data by @​dependabot in actions/setuppython CC(Udacity example 1: import urllib for download) Upgrade actions/publishimmutableaction from 0.0.3 to 0.0.4 by @​dependabot in actions/setuppython CC(Fix merge gone wrong) Upgrade /httpclient from 2.2.1 to 2.2.3 by @​dependabot in actions/setuppython CC(Fixed tensorboard installation for pip) Upgrade requests from 2.24.0 to 2.32.2 in /tests/data by @​dependabot in actions/setuppython CC(Tensorflow Android not building for nonarm architectures.) Upgrade /cache to ^4.0.0 by @​priyagupta108 in actions/setuppython CC(TensorFlow: fix word2vec timeouts on GPU by pinning model on CPU)  New Contributors  @​benwells made their first contribution in actions/setuppython CC(Example code for SummaryIterator using `tf.train.summary_iterator`.) @​HarithaVattikuti made their first contribution in actions/setuppython CC(Minor comment spelling fix.) @​lrq3000 made their first contribution in actions/setuppython CC(Casting int64 to int8 is not supported)  Full Changelog: https://github.com/actions/setuppython/compare/v5...v5.4.0    Commits  4237552 Improve Advanced Usage examples ( CC(Casting int64 to int8 is not supported)) 709bfa5 Bump requests from 2.24.0 to 2.32.2 in /tests/data ( CC(Tensorflow Android not building for nonarm architectures.)) ceb20b2 Bump @​actions/httpclient from 2.2.1 to 2.2.3 ( CC(Fixed tensorboard installation for pip)) 0dc2d2c Bump actions/publishimmutableaction from 0.0.3 to 0.0.4 ( CC(Fix merge gone wrong)) feb9c6e Bump urllib3 from 1.25.9 to 1.26.19 in /tests/data ( CC(Udacity example 1: import urllib for download)) d0b4fc4 Bump undici from 5.28.4 to 5.28.5 ( CC(pip installation failing on fedora)) e3dfaac Configure Dependabot settings ( CC(Minor comment spelling fix.)) b8cf3eb Use the new cache service: upgrade /cache to ^4.0.0 ( CC(TensorFlow: fix word2vec timeouts on GPU by pinning model on CPU)) 1928ae6 Update README.md ( CC(Example code for SummaryIterator using `tf.train.summary_iterator`.)) 3fddbee Enhance Workflows: Add Ubuntu24, Remove Python 3.8  ( CC(Wrong file dimension when calling maybe_download function)) Additional commits viewable in compare view    Updates `peterevans/createpullrequest` from 7.0.5 to 7.0.6  Release notes Sourced from peterevans/createpullrequest's releases.  Create Pull Request v7.0.6 ⚙️ Fixes an issue with commit signing where unicode characters in file paths were not preserved. What's Changed  build(depsdev): bump @​vercel/ncc from 0.38.1 to 0.38.2 by @​dependabot in peterevans/createpullrequest CC(Remove read_analogies() from word2vec class initialization) Update distribution by @​actionsbot in peterevans/createpullrequest CC(Tests for examples/learn) build(deps): bump @​octokit/pluginrestendpointmethods from 13.2.4 to 13.2.5 by @​dependabot in peterevans/createpullrequest CC(wrong use of sequence_loss_by_example in ptb_word_lm.py?) build(depsdev): bump @​types/node from 18.19.50 to 18.19.54 by @​dependabot in peterevans/createpullrequest CC(Elementwise tf.cond (like theano switch)) build(deps): bump @​octokit/pluginpaginaterest from 11.3.3 to 11.3.5 by @​dependabot in peterevans/createpullrequest CC(Moving data from CPU to GPU is slow ) Update distribution by @​actionsbot in peterevans/createpullrequest CC(Bug: Exception ignored in BaseSession.__del__) build(depsdev): bump @​types/node from 18.19.54 to 18.19.55 by @​dependabot in peterevans/createpullrequest CC(new stacks) build(deps): bump @​actions/core from 1.10.1 to 1.11.1 by @​dependabot in peterevans/createpullrequest CC(Run a TensorFlow demo model : IOError: CRC check failed) build(deps): bump @​octokit/pluginrestendpointmethods from 13.2.5 to 13.2.6 by @​dependabot in peterevans/createpullrequest CC(A link in tensorflow's website is ineffective) build(depsdev): bump eslintpluginimport from 2.30.0 to 2.31.0 by @​dependabot in peterevans/createpullrequest CC(Given one input tensor, why tf.nn.max_pool generate two tensors?) build(deps): bump @​octokit/pluginthrottling from 9.3.1 to 9.3.2 by @​dependabot in peterevans/createpullrequest CC(Can't create placeholder with partially defined shape e.g. (1, 10)) Update distribution by @​actionsbot in peterevans/createpullrequest CC(Fix few warnings that I see on macosxclang compilation) build(depsdev): bump typescript from 5.6.2 to 5.6.3 by @​dependabot in peterevans/createpullrequest CC(Documentation for 'Adding a new op') build(deps): bump undici from 6.19.8 to 6.20.1 by @​dependabot in peterevans/createpullrequest CC(Error malloc(): memory corruption) Update distribution by @​actionsbot in peterevans/createpullrequest CC(retrain.py validation and testing evaluation seems incorrect) build(depsdev): bump @​types/node from 18.19.55 to 18.19.58 by @​dependabot in peterevans/createpullrequest CC(Problem in distributed tensorflow demo?) build(depsdev): bump @​types/jest from 29.5.13 to 29.5.14 by @​dependabot in peterevans/createpullrequest CC(Correction in Dequantize comments) build(depsdev): bump @​types/node from 18.19.58 to 18.19.60 by @​dependabot in peterevans/createpullrequest CC(Dev request  LSTM RNN) chore: don't bundle undici by @​benmccann in peterevans/createpullrequest CC(Device placement error while using multi gpus on single machine by distributed version) Update distribution by @​actionsbot in peterevans/createpullrequest CC(How to restore a distributed model and continue to train it with more workers?) chore: use nodefetchnative support for proxy env vars by @​peterevans in peterevans/createpullrequest CC(Slicing error: Using a `tf.Tensor` as a Python `bool` is not allowed) build(depsdev): bump @​types/node from 18.19.60 to 18.19.64 by @​dependabot in peterevans/createpullrequest CC(minor typo fix) build(depsdev): bump undici from 6.20.1 to 6.21.0 by @​dependabot in peterevans/createpullrequest CC(Placeholder names are inconsistent when reentering a scope) build(depsdev): bump @​vercel/ncc from 0.38.2 to 0.38.3 by @​dependabot in peterevans/createpullrequest CC(Replaced _logger.warn with _logger.warning) docs: note pushtorepo classic PAT workflow scope requirement by @​scop in peterevans/createpullrequest CC(Branch 128485842) docs: spelling fixes by @​scop in peterevans/createpullrequest CC(Branch 128492931) build(depsdev): bump typescript from 5.6.3 to 5.7.2 by @​dependabot in peterevans/createpullrequest CC(Fix an error message.) build(depsdev): bump prettier from 3.3.3 to 3.4.0 by @​dependabot in peterevans/createpullrequest CC(Error when running distributed MNIST example) build(depsdev): bump @​types/node from 18.19.64 to 18.19.66 by @​dependabot in peterevans/createpullrequest CC(Update version string to 0.10.0rc0) docs(README): clarify that an existing open PR is managed by @​caugner in peterevans/createpullrequest CC('tensorflow.contrib.learn' has no attribute 'infer_real_valued_columns_from_input') Update distribution by @​actionsbot in peterevans/createpullrequest CC(Fixed typo:) build(deps): bump @​octokit/pluginpaginaterest from 11.3.5 to 11.3.6 by @​dependabot in peterevans/createpullrequest CC(Fix go build errors) build(depsdev): bump @​types/node from 18.19.66 to 18.19.67 by @​dependabot in peterevans/createpullrequest CC(boolean_mask failed in iOS: Running model failed:Invalid argument: No OpKernel was registered to support Op 'Gather' with these attrs) build(depsdev): bump prettier from 3.4.0 to 3.4.1 by @​dependabot in peterevans/createpullrequest CC(Should *.pb.h files be generated in crosscompile cases?) build(depsdev): bump eslintimportresolvertypescript from 3.6.3 to 3.7.0 by @​dependabot in peterevans/createpullrequest CC(Can I add a py_func to a queue?) build(depsdev): bump prettier from 3.4.1 to 3.4.2 by @​dependabot in peterevans/createpullrequest CC(Inception retraining / transfer learning fails when running with GPU) build(depsdev): bump @​types/node from 18.19.67 to 18.19.68 by @​dependabot in peterevans/createpullrequest CC(word2vec_basic.py : to prevent possible issue with libpng) build(deps): bump plimit from 6.1.0 to 6.2.0 by @​dependabot in peterevans/createpullrequest CC(Branch 128859117) Update distribution by @​actionsbot in peterevans/createpullrequest CC(Dying Threads?) fix: preserve unicode in filepaths when commit signing by @​peterevans in peterevans/createpullrequest CC(Branch 128894163)  New Contributors  @​benmccann made their first contribution in peterevans/createpullrequest CC(Device placement error while using multi gpus on single machine by distributed version) @​scop made their first contribution in peterevans/createpullrequest CC(Branch 128485842) @​caugner made their first contribution in peterevans/createpullrequest CC('tensorflow.contrib.learn' has no attribute 'infer_real_valued_columns_from_input')    ... (truncated)   Commits  67ccf78 fix: preserve unicode in filepaths when commit signing ( CC(Branch 128894163)) bb88e27 build: update distribution ( CC(Dying Threads?)) b378ed5 build(deps): bump plimit from 6.1.0 to 6.2.0 ( CC(Branch 128859117)) fa9200e build(depsdev): bump @​types/node from 18.19.67 to 18.19.68 ( CC(word2vec_basic.py : to prevent possible issue with libpng)) 16e0059 build(depsdev): bump prettier from 3.4.1 to 3.4.2 ( CC(Inception retraining / transfer learning fails when running with GPU)) 5bffd5a build(depsdev): bump eslintimportresolvertypescript ( CC(Can I add a py_func to a queue?)) a22a0dd build(depsdev): bump prettier from 3.4.0 to 3.4.1 ( CC(Should *.pb.h files be generated in crosscompile cases?)) b27ce37 build(depsdev): bump @​types/node from 18.19.66 to 18.19.67 ( CC(boolean_mask failed in iOS: Running model failed:Invalid argument: No OpKernel was registered to support Op 'Gather' with these attrs)) 4e0cc19 build(deps): bump @​octokit/pluginpaginaterest from 11.3.5 to 11.3.6 ( CC(Fix go build errors)) 25b6871 docs: update scopes for pushtofork Additional commits viewable in compare view    Updates `actions/uploadartifact` from 4.4.3 to 4.6.0  Release notes Sourced from actions/uploadartifact's releases.  v4.6.0 What's Changed  Expose env vars to control concurrency and timeout by @​yacaovsnc in actions/uploadartifact CC(optimize slice_input_producer)  Full Changelog: https://github.com/actions/uploadartifact/compare/v4...v4.6.0 v4.5.0 What's Changed  fix: deprecated Node.js version in action by @​hamirmahal in actions/uploadartifact CC(Fixed random_contrast link in the Deep CNN tutorial) Add new artifactdigest output by @​bdehamer in actions/uploadartifact CC(Tiny fix to API docs)  New Contributors  @​hamirmahal made their first contribution in actions/uploadartifact CC(Fixed random_contrast link in the Deep CNN tutorial) @​bdehamer made their first contribution in actions/uploadartifact CC(Tiny fix to API docs)  Full Changelog: https://github.com/actions/uploadartifact/compare/v4.4.3...v4.5.0    Commits  65c4c4a Merge pull request  CC(optimize slice_input_producer) from actions/yacaovsnc/add_variable_for_concurrency_a... 0207619 move files back to satisfy licensed ci 1ecca81 licensed cache updates 9742269 Expose env vars to controll concurrency and timeout 6f51ac0 Merge pull request  CC(Tiny fix to API docs) from bdehamer/bdehamer/artifactdigest c40c16d add new artifactdigest output 735efb4 bump @​actions/artifact from 2.1.11 to 2.2.0 184d73b Merge pull request  CC(Fixed random_contrast link in the Deep CNN tutorial) from hamirmahal/fix/deprecatednodejsusageinaction b4a0a98 Merge branch 'main' into fix/deprecatednodejsusageinaction See full diff in compare view    Updates `github/codeqlaction` from 3.27.5 to 3.28.8  Release notes Sourced from github/codeqlaction's releases.  v3.28.8 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.8  29 Jan 2025  Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3.  CC(Fix for build issue 2742;)  See the full CHANGELOG.md for more information. v3.28.7 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.7  29 Jan 2025 No user facing changes. See the full CHANGELOG.md for more information. v3.28.6 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.6  27 Jan 2025  Reenable debug artifact upload for CLI versions 2.20.3 or greater.  CC(Modifying MNIST example to distributed version: could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR)  See the full CHANGELOG.md for more information. v3.28.5 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.5  24 Jan 2025  Update default CodeQL bundle version to 2.20.3.  CC(Branch 124290852)  See the full CHANGELOG.md for more information. v3.28.4 CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. 3.28.4  23 Jan 2025   ... (truncated)   Changelog Sourced from github/codeqlaction's changelog.  CodeQL Action Changelog See the releases page for the relevant changes to the CodeQL CLI and language packs. [UNRELEASED] No user facing changes. 3.28.8  29 Jan 2025  Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3.  CC(Fix for build issue 2742;)  3.28.7  29 Jan 2025 No user facing changes. 3.28.6  27 Jan 2025  Reenable debug artifact upload for CLI versions 2.20.3 or greater.  CC(Modifying MNIST example to distributed version: could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR)  3.28.5  24 Jan 2025  Update default CodeQL bundle version to 2.20.3.  CC(Branch 124290852)  3.28.4  23 Jan 2025 No user facing changes. 3.28.3  22 Jan 2025  Update default CodeQL bundle version to 2.20.2.  CC(Update roadmap.md) Fix an issue downloading the CodeQL Bundle from a GitHub Enterprise Server instance which occurred when the CodeQL Bundle had been synced to the instance using the CodeQL Action sync tool and the Actions runner did not have Zstandard installed.  CC(Branch 124251558) Uploading debug artifacts for CodeQL analysis is temporarily disabled.  CC(Tensorflow with Pyinstaller)  3.28.2  21 Jan 2025 No user facing changes. 3.28.1  10 Jan 2025  CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see this changelog post.  CC(Import error) Update default CodeQL bundle version to 2.20.1.  CC(Fix broken link to Anaconda installation)  3.28.0  20 Dec 2024  Bump the minimum CodeQL bundle version to 2.15.5.  CC(Feature Request: Support for YARN cluster manager for Distributed TensorFlow) Don't fail in the unusual case that a file is on the search path.  CC(Max Pooling NCHW).  3.27.9  12 Dec 2024   ... (truncated)   Commits  dd74661 Merge pull request  CC(Missing pywrap_tensorflow) from github/updatev3.28.8a91a3f767 3210a3c Fix Kotlin version in changelog 72f9d02 Update changelog for v3.28.8 a91a3f7 Merge pull request  CC(Fix for build issue 2742;) from github/igfoo/kot2.1.10 c520fb5 Merge pull request  CC(running digits.py) from github/mergeback/v3.28.7tomain6e545590 3879c57 Add changelog entry 0c21937 Run &quot;npm run build&quot; 5a61bf0 Kotlin: The 2.20.3 release supports Kotlin 2.1.10. 163d119 Update checkedin dependencies bcf5cec Update changelog and version after v3.28.7 Additional commits viewable in compare view    Updates `docker/setupbuildxaction` from 3.7.1 to 3.8.0  Release notes Sourced from docker/setupbuildxaction's releases.  v3.8.0  Make cloud prefix optional to download buildx if driver is cloud by @​crazymax in docker/setupbuildxaction CC(parse_example can be _much_ faster than parse_single_example) Bump @​actions/core from 1.10.1 to 1.11.1 in docker/setupbuildxaction CC(convert_to_records.py don't write all values into .tfrecords file) Bump @​docker/actionstoolkit from 0.39.0 to 0.48.0 in docker/setupbuildxaction CC(Cifar10 eval script verbose output) Bump crossspawn from 7.0.3 to 7.0.6 in docker/setupbuildxaction CC(Failed to bazel build when executing label_image example )  Full Changelog: https://github.com/docker/setupbuildxaction/compare/v3.7.1...v3.8.0    Commits  6524bf6 Merge pull request  CC(parse_example can be _much_ faster than parse_single_example) from crazymax/buildxcloudlatest 8d5e074 chore: update generated content 7199e57 make cloud prefix optional to download buildx if driver is cloud db63cee Merge pull request  CC(Failed to bazel build when executing label_image example ) from docker/dependabot/github_actions/codecov/codecov... 043ebe1 Merge pull request  CC(Cifar10 eval script verbose output) from docker/dependabot/npm_and_yarn/docker/actionsto... 686da90 chore: update generated content a3d7487 Merge pull request  CC(Failed to bazel build when executing label_image example ) from docker/dependabot/npm_and_yarn/crossspawn7.0.6 4dcdbce build(deps): bump @​docker/actionstoolkit from 0.39.0 to 0.48.0 1a8ac74 ci: fix deprecated input for codecovaction e827ebe build(deps): bump crossspawn from 7.0.3 to 7.0.6 Additional commits viewable in compare view    Updates `docker/buildpushaction` from 6.10.0 to 6.13.0  Release notes Sourced from docker/buildpushaction's releases.  v6.13.0  Bump @​docker/actionstoolkit from 0.51.0 to 0.53.0 in docker/buildpushaction CC(ImportError: cannot import name server)  Full Changelog: https://github.com/docker/buildpushaction/compare/v6.12.0...v6.13.0 v6.12.0  Bump @​docker/actionstoolkit from 0.49.0 to 0.51.0 in docker/buildpushaction CC(Support for halffloats (float16/fp16))  Full Changelog: https://github.com/docker/buildpushaction/compare/v6.11.0...v6.12.0 v6.11.0  Handlebar defaultContext support for buildcontexts input by @​crazymax in docker/buildpushaction CC(DEFINE_bool alias not working on Mac Python testoninstall) Bump @​docker/actionstoolkit from 0.46.0 to 0.49.0 in docker/buildpushaction CC(ImportError: cannot import name tensorboard_server )  Full Changelog: https://github.com/docker/buildpushaction/compare/v6.10.0...v6.11.0    Commits  ca877d9 Merge pull request  CC(ImportError: cannot import name server) from docker/dependabot/npm_and_yarn/docker/actionst... d2fe919 chore: update generated content f0fc9ec chore(deps): Bump @​docker/actionstoolkit from 0.51.0 to 0.53.0 67a2d40 Merge pull request  CC(Support for halffloats (float16/fp16)) from docker/dependabot/npm_and_yarn/docker/actionst... 0b1b1c9 chore: update generated content b6a7c2c chore(deps): Bump @​docker/actionstoolkit from 0.49.0 to 0.51.0 31ca4e5 Merge pull request  CC(did grammatical clean up) from crazymax/bakev6 e613db9 update bakeaction to v6 b32b51a Merge pull request  CC(ImportError: cannot import name tensorboard_server ) from docker/dependabot/npm_and_yarn/docker/actionst... 594bf46 Merge pull request  CC(Automated Docker image build and test) from crazymax/fixe2e Additional commits viewable in compare view    Updates `actions/stale` from 9.0.0 to 9.1.0  Release notes Sourced from actions/stale's releases.  v9.1.0 What's Changed  Documentation update by @​Marukome0743 in actions/stale CC(keep numpy version in pip.sh) Add workflow file for publishing releases to immutable action package by @​Jcambass in actions/stale CC(libcuda suffix issue) Update undici from 5.28.2 to 5.28.4 by @​dependabot in actions/stale CC(tensorflow 0.7.0 gpuenabled version crashes bad on import) Update actions/checkout from 3 to 4 by @​dependabot in actions/stale CC(Adding summaries changes random number generation) Update actions/publishaction from 0.2.2 to 0.3.0 by @​dependabot in actions/stale CC(Python 3 test failure: //tensorflow/tensorboard/backend:server_test) Update tsjest from 29.1.1 to 29.2.5 by @​dependabot in actions/stale CC(fix broken links in docs) Update @​actions/core from 1.10.1 to 1.11.1 by @​dependabot in actions/stale CC(Build of pip package with current HEAD of bazel fails) Update @​types/jest from 29.5.11 to 29.5.14 by @​dependabot in actions/stale CC('utf8' codec can't decode byte (in tutorial)) Update @​actions/cache from 3.2.2 to 4.0.0 by @​dependabot in actions/stale CC(Fixed spelling)  New Contributors  @​Marukome0743 made their first contribution in actions/stale CC(keep numpy version in pip.sh) @​Jcambass made their first contribution in actions/stale CC(libcuda suffix issue)  Full Changelog: https://github.com/actions/stale/compare/v9...v9.1.0    Commits  5bef64f build(deps): bump @​actions/cache from 3.2.2 to 4.0.0 ( CC(Fixed spelling)) fa77dfd build(depsdev): bump @​types/jest from 29.5.11 to 29.5.14 ( CC('utf8' codec can't decode byte (in tutorial))) f04443d build(deps): bump @​actions/core from 1.10.1 to 1.11.1 ( CC(Build of pip package with current HEAD of bazel fails)) 5c715b0 build(depsdev): bump tsjest from 29.1.1 to 29.2.5 ( CC(fix broken links in docs)) f691222 build(deps): bump actions/publishaction from 0.2.2 to 0.3.0 ( CC(Python 3 test failure: //tensorflow/tensorboard/backend:server_test)) df990c2 build(deps): bump actions/checkout from 3 to 4 ( CC(Adding summaries changes random number generation)) 6e472ce Merge pull request  CC(libcuda suffix issue) from actions/Jcambasspatch1 d10ba64 Merge pull request  CC(tensorflow 0.7.0 gpuenabled version crashes bad on import) from actions/dependabot/npm_and_yarn/undici5.28.4 bbf3da5 resolve check failures 6a2e61d Add workflow file for publishing releases to immutable action package Additional commits viewable in compare view    Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting ` rebase`. [//]:  (dependabotautomergestart) [//]:  (dependabotautomergeend)   Dependabot commands and options  You can trigger Dependabot actions by commenting on this PR:  ` rebase` will rebase this PR  ` recreate` will recreate this PR, overwriting any edits that have been made to it  ` merge` will merge this PR after your CI passes on it  ` squash and merge` will squash and merge this PR after your CI passes on it  ` cancel merge` will cancel a previously requested merge and block automerging  ` reopen` will reopen this PR if it is closed  ` close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually  ` show  ignore conditions` will show all of the ignore conditions of the specified dependency  ` ignore  major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)  ` ignore  minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)  ` ignore ` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)  ` unignore ` will remove all of the ignore conditions of the specified dependency  ` unignore  ` will remove the ignore condition of the specified dependency and ignore conditions ",2025-02-01T08:42:19Z,ready to pull size:S dependencies github_actions,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86354
rag,harshaljanjani,fix(kernels): Handle empty values with non-empty row splits in RaggedTensorToTensor,This commit addresses a segmentation fault in the `RaggedTensorToTensor` op when processing empty values with nonempty row splits:  Checking for empty values before processing.  Ensuring consistent handling of dimension sizes.  Providing clear error messages for invalid input configurations. Might fix CC(Segmentation fault (core dumped) in `RaggedTensorToTensor`).,2025-02-01T06:51:34Z,ready to pull size:M comp:core,open,0,2,https://github.com/tensorflow/tensorflow/issues/86349,"> Please make sure to not include irrelevant spacing changes. Understood, it's my first time contributing here; thanks for the information! Will take care of the linting next time around.","> Can you please make sure to run all tests and make sure they pass? Hello , thanks for the reply. Actually, I'm not quite able to figure out why my local setup's failing with these `bash r not found` errors. Besides, I tried converting the CRLF endings to LF endings (given that I'm running the bazel tests in WSL). I wished to ask if there's a better way to set up and run tests locally that you'd recommend with WSL, as I've read the CONTRIBUTING.md file and set it up to the tee but am still facing these issues that impede my progress; thanks!"
yi,copybara-service[bot],"Return arrays from `ArrayImpl._check_and_rearrange`. Build IFRT shardings with both addressable and non-addressable devices, instead of only addressable devices.","Return arrays from `ArrayImpl._check_and_rearrange`. Build IFRT shardings with both addressable and nonaddressable devices, instead of only addressable devices. This is a rollforward of two previous rollbacks after fixing breakages.",2025-01-31T23:55:17Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/86334
rag,copybara-service[bot],Update RaggedAllToAll API to clarify supported shapes for offsets/sizes operands.,Update RaggedAllToAll API to clarify supported shapes for offsets/sizes operands.,2025-01-31T23:38:37Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86332
yi,copybara-service[bot],[HLO] Use llvm::StringRef when building MHLO string attributes instead of relying on implicit casting,[HLO] Use llvm::StringRef when building MHLO string attributes instead of relying on implicit casting,2025-01-31T19:44:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86319
llm,ceschi,Stateful LSTM bug with batch size," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.18  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When running a stateful LSTM one needs to fix a batch size. Previously this was achieved with the `batch_input_shape=(batch_size, sequence_length, num_features)` argument, but with the most recent version of TF batch_input_shape is not recognised as valid.  Basically the error is the same as this https://github.com/tensorflow/tensorflow/issues/64061 Below is some LLM generated code to reproduce the behaviour. Also, the `model.reset_states()` bit appears broken.  Standalone code to reproduce the issue ```shell import numpy as np import tensorflow as tf  Set a fixed batch size batch_size = 32  Create some random training data  We'll have sequences of length 5, with 1 feature per time step sequence_length = 5 num_features = 1 num_samples = 100   Total number of samples (must be divisible by batch_size)  Ensure num_samples is a multiple of batch_size num_samples = (num_samples // batch_size) * batch_size X_train = np.random.rand(num_samples, sequence_length, num_features) y_train = np.random.rand(num_samples, 1)   Example target values  Reshape y_train to match expected output shape if needed y_train = y_train.reshape(1,1)  Create the stateful LSTM model model = tf.keras.models.Sequential() model.add(tf.keras.layers.LSTM(units=64,   Number of LSTM units                                batch_input_shape=(batch_size, sequence_length, num_features),                                stateful=True,                                return_sequences=False)) often false for a final prediction model.add(tf.keras.layers.Dense(units=1))  Output layer with 1 unit  Compile the model model.compile(optimizer='adam', loss='mse')  Train the model epochs = 10 for epoch in range(epochs):      Shuffle data indices for each epoch (important for stateful LSTMs)     indices = np.arange(num_samples)     np.random.shuffle(indices)     X_train = X_train[indices]     y_train = y_train[indices]     model.fit(X_train, y_train, batch_size=batch_size, epochs=1, shuffle=False)  Shuffle must be false      Reset states after each epoch (essential for stateful LSTMs)     model.reset_states() ```  Relevant log output ```shell ```",2025-01-31T18:07:07Z,stat:awaiting response type:bug stale comp:keras TF 2.18,closed,0,7,https://github.com/tensorflow/tensorflow/issues/86310,"Hello Jordan, thanks for the reply. I am indeed using TF 2.18 (and Python 3.11.0 on Win11), though if I run your code I get precisely the error I referred to in the first place: `ValueError: Unrecognized keyword arguments passed to LSTM: {'batch_input_shape': (32, 5, 1)}`",", Hi, By default the colab notebook is using tensorflow v2.17 which contains keras3.0 which was causing the error. Could you please try to import keras2.0 with the below commands. ``` !pip install tfkeras import tf_keras as keras ``` Also I have modified some steps and then the code was executed without error/fail. Kindly find the gist of it here. Take a look at this issue for reference. https://github.com/kerasteam/keras/issues/20106 Thank you!","  Hello, thanks for the pointers. I am prototyping on TF 2.18 and Keras 3.8, to then do the training on TF 2.13. If I understand correctly this post, an Input layer with `batch_shape` does the trick. Would this work in both versions of TF? Thanks a ton for the help, the documentation is quite confusing currently.",", As per above comments, I can sense that you tried the code in tensorflow 2.18, keras 3.8 and then training in TF 2.13. In such a scenario, the code might be having compatible issues with both 2.18 and 2.13 which wouldn't be suggestible.  Tensorflow v2.18 contains Keras3.0 version and tensorflow v2.13 contains keras2.0. where both versions are different. https://keras.io/keras_3/ And also the code is working in tf_keras(keras2.0), and provided the error in keras3.0. So, please feel free to raise the issue in Kerasteam/keras repo for the further inputs. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],PR #21886: [ROCM][NFC] BlasLt interface refactoring & simplifying: part I,"PR CC(Tensorflow 1.10.0 MKL build (win64) with bazel throws linker error): [ROCM][NFC] BlasLt interface refactoring & simplifying: part I Imported from GitHub PR https://github.com/openxla/xla/pull/21886 After this PR https://github.com/tensorflow/tensorflow/pull/73926 is merged, we can remove unnecessary lowlevel DoMatmul functions from GpuBlasLt interface (which otherwise looks scary and unnecessarily complicated). Furthermore, we can also remove **ValidateInputs** function from the interface and derived classes since a highlevel **ExecuteOnStream** function already handles datatypes correctly. This also greatly simplifies the code. Also, I have packed the input arguments of ExecuteOnStream calls to a struct **MemoryArgs** to simplify arguments passing in derived classes and improve code readability. Finally, in the original GpuBlasLt PR: https://github.com/openxla/xla/pull/5911, I made a sort of mistake by adding a reference to **blas_lt** to the MatmulPlan class here, thereby making MatmulPlans bound to a **particular BlasLt instance**. This resulted in some further bugfixes and, most importantly, complicated GpuBlasLt cache design in gpublas_lt_matmul_thunk.cc/.h. In this PR, I remove this reference again from MatmulPlan class and in the next NFC PR the cache mechanics can also be simplified.  Unfortunately, this change also requires a tandem PR for Tensorflow: https://github.com/tensorflow/tensorflow/pull/85835 rotation Would you please have a look Copybara import of the project:  e96bb2fbedab3f53b31ef0e1748582c76e9fb105 by Pavel Emeliyanenko : blaslt interface refactoring: removing blas_lt_ref added cuda adaptions cudaside adaptions cuda side adaptions fix fixing pointers Merging this change closes CC(Tensorflow 1.10.0 MKL build (win64) with bazel throws linker error) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21886 from ROCm:ci_gpublas_lt_refactor_1 e96bb2fbedab3f53b31ef0e1748582c76e9fb105",2025-01-31T17:49:17Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86308
transformer,Alexey234432,DRQ  (Dynamic Range Quantization) - which ops are affected?,"Hi,  I am performing DRQ (Dynamic Range Quantization) using https://ai.google.dev/edge/litert/models/post_training_quant  how to get more details on which ops will be affected(and what exactly will happen with these ops)? My understanding that in case of transformers only fully connected layers will be affected, is this correct? What would be the impact on op computations  would computations be happening with int8 (ie both weights and activations)? Thank you.",2025-01-31T14:46:34Z,stat:awaiting response comp:lite TFLiteConverter,closed,0,7,https://github.com/tensorflow/tensorflow/issues/86293,"Hi,   I apologize for the delayed response, As far I know during DRQ the weights are quantized to `int8` but the activations remain in `float32`. This means that the multiplication is int8 * float32. You're correct in your understanding that fully connected layers are major focus in transformers. Transformers heavily rely on fully connected layers (in the Feed Forward Network(FFN) and in the attention mechanism). The query, key and value transformations within the attention mechanism often use fully connected layers. The FFN which is typically a multilayer perceptron (MLP) consists of multiple fully connected layers.Therefore DRQ will primarily affect the fully connected operations in these parts of the transformer architecture. I would suggest you to please use these tools modelexplorer and Netron to visualize the architecture of your TensorFlow Lite (TFLite) model including the changes made by Dynamic Range Quantization (DRQ) Thank you for your cooperation and patience.","Thank you for your reply   Yes, thanks for suggestion  I use these tools and they are extremely useful but to be honest I am still confused (let's concentrate on fully connected ops behaviour for the sake of simplicity) whether actual computations (mat muls) are happening in int8 or fp32. Looking into docs from https://ai.google.dev/edge/litert/models/post_training_quant ```The activations are always stored in floating point. For ops that support quantized kernels, the activations are quantized to 8 bits of precision dynamically prior to processing and are dequantized to float precision after processing. Depending on the model being converted, this can give a speedup over pure floating point computation.``` this per my understanding implies that compute is happening in int8. Also inference time of DRQ quantized llama3 model vs Float TFLite llama3 model was ~2 times faster (on CPU using TFlite interpreter with 1 cpu only)  this is also a weak evidence of compute using different approach under the hood. Any chance you could please help me understand what's happening on lower level? Thank you.","Hi,  You're correct in your understanding, Dynamic Range Quantization (DRQ) in TensorFlow Lite stores activations in `float32` for range and precision. However, for operations with quantized kernels (like matrix multiplications) activations are dynamically quantized to `int8` immediately before computation.  The actual computation (e.g. matrix multiplication) happens in `int8` precision using both the `int8` quantized weights and the dynamically `int8` quantized activations.  Results are then dequantized back to `float32`.  Thus, the core computations occur in `int8` providing performance benefits despite `float32` activation storage. Thank you for your understanding and cooperation.",Thank you  this is really helpful and detailed answer. Do you know how could I come to this conclusion on my own? ie any links to the relevant inference or quantization code (which I assume will be somewhere inside TFLite source code?) Thanks!,"Hi,   Unfortunately, the exact source code for Dynamic Range Quantization (DRQ) within TensorFlow Lite is not readily available in a single, easily isolated file. This is because DRQ is implemented across several components of the TensorFlow Lite framework. However, I can point you to the key areas and files where the relevant logic resides  1. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/quantization_util.h 2. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/quantization_util., including dynamic quantization. They handle the scaling and conversion between `float32` and `int8` representations. 3. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/quantization_util.h 4. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/quantization_util.. The actual DRQ logic is implemented within the individual kernel implementations for the operations that support quantization (e.g. fully connected layers, convolutions). You can find these kernels in the tensorflow/lite/kernels directory. Within these kernel files you'll find code that uses the quantization utilities mentioned above to dynamically quantize the activations before performing the computation. If I have missed something here please let me know. If you notice any omissions or discrepancies between the official documentation and the source code implementation,  we welcome a pull request (PR).  Our team will review your submission and facilitate its integration provided the changes align with our contribution guidelines. Thank you for your understand and cooperation.",Thank you for your help!,"Hi,   You're welcome, Could you please confirm if this issue is resolved for you now? Please feel free to close the issue if it is resolved ? If need any further help in future w.r.t TFLite now renamed to LiteRT please feel free to post your issue in dedicated repo for LiteRT  Thank you for your cooperation and understanding."
rag,copybara-service[bot],[XLA:GPU] Extract more fragments into the smaller functions.,[XLA:GPU] Extract more fragments into the smaller functions. It is noop change.,2025-01-31T10:58:21Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86280
yi,copybara-service[bot],[XLA:LatencyHidingScheduler] Let `GetResourcesFromInstruction` return a complete list of resources used by instructions in a while loop. This will make async `done` and while ops have similar priority (in terms of occupying resource types) and avoid delaying the while loops only because they cross the overlap limit (even though they have a higher async depth).,[XLA:LatencyHidingScheduler] Let `GetResourcesFromInstruction` return a complete list of resources used by instructions in a while loop. This will make async `done` and while ops have similar priority (in terms of occupying resource types) and avoid delaying the while loops only because they cross the overlap limit (even though they have a higher async depth). This CL also fixes the double counting of a resource in `GetNumResourcesPerInstruction` because of multiple async `done` ops in the while body.,2025-01-30T22:59:54Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86242
yi,copybara-service[bot],litert: Use BuiltinOpResolver to enable lazy applying Xnnpack delegate,"litert: Use BuiltinOpResolver to enable lazy applying Xnnpack delegate Now, getting a signature runner before applying delegate isn't needed. So we can use BuiltinOpResolver safely.",2025-01-30T18:50:48Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86226
yi,copybara-service[bot],[XLA:CPU][roll forward] Underlying ObjectLoader dylibs are using DefinitionGenerator now.,[XLA:CPU][roll forward] Underlying ObjectLoader dylibs are using DefinitionGenerator now. Reverts changelist 721389214,2025-01-30T17:23:08Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86218
yi,copybara-service[bot],"[XLA/Triton] Don't restrict contracting dimension tiling for predicate inputs in a GEMM during autotuning. Historically, the restriction was acceptable until a change to FMA landed from Triton upstream that started spilling registers for such configurations. The more correct way to handle this is to lift the restriction on predicates rather than applying it to small dots.","[XLA/Triton] Don't restrict contracting dimension tiling for predicate inputs in a GEMM during autotuning. Historically, the restriction was acceptable until a change to FMA landed from Triton upstream that started spilling registers for such configurations. The more correct way to handle this is to lift the restriction on predicates rather than applying it to small dots.",2025-01-30T17:06:31Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86217
text generation,bog739,Tensorflow_datasets - image_classification - cats_vs_dogs.py file," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tensorflow2.18.0  Custom code No  OS platform and distribution Edition: Windows 10 Pro, Version: 22H2, OS Build: 19045.5371  Mobile device _No response_  Python version 3.11.3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I used a dataset named cats_vs_dogs for studying and training a model, MobileNet v2. Upon loading this dataset by using tensorflow_datasets.load() function which does the fetching too, the first image from arhive that should have been extracted throws an error that it cannot be found. I solved easily `_generate_examples()` from cats_vs_dogs.py by eliminating the context manager with ZipFile object and the one after. I suppose that attaching one ZipFile object to a BytesIO object does work in the context manger scope, but it crashes if another ZipFile object wraps it outside the context manager. I think that one object ZipFile should be used. I managed to do what I wanted with a simple modification, I will post the code separately. In the log some text is in Romanian in paths.  Standalone code to reproduce the issue ```shell def _generate_examples(self, archive):     """"""Generate Cats vs Dogs images and labels given a directory path.""""""     num_skipped = 0     for fname, fobj in archive:       res = _NAME_RE.match(fname)       if not res:   README file, ...         continue       label = res.group(1).lower()       if tf.compat.as_bytes(""JFIF"") not in fobj.peek(10):         num_skipped += 1         continue        Some images caused 'Corrupt JPEG data...' messages during training or        any other iteration recoding them once fixes the issue (discussion:        https://github.com/tensorflow/datasets/issues/2188).        Those messages are now displayed when generating the dataset instead.       img_data = fobj.read()       img_tensor = tf.image.decode_image(img_data)       img_recoded = tf.io.encode_jpeg(img_tensor)        Converting the recoded image back into a zip file container.       buffer = io.BytesIO()       with zipfile.ZipFile(buffer, ""w"") as new_zip:         new_zip.writestr(fname, img_recoded.numpy())       new_zip = zipfile.ZipFile(buffer, ""w"")       new_zip.writestr(fname, img_recoded.numpy())       new_fobj = zipfile.ZipFile(buffer).open(fname)       record = {           ""image"": img_recoded.numpy(), new_fobj,           ""image/filename"": fname,           ""label"": label,       }       yield fname, record     if num_skipped != _NUM_CORRUPT_IMAGES:       raise ValueError(           ""Expected %d corrupt images, but found %d""           % (_NUM_CORRUPT_IMAGES, num_skipped)       )     logging.warning(""%d images were corrupted and were skipped"", num_skipped) ```  Relevant log output ```shell (setups) E:\Facultate_etti\An_1_csi\ElemAI\setups>py ""E:\Facultate_etti\An_1_csi\ElemAI\setups\src\copy_of_06_exercise_transferlearning&finetuning.py""  20250130 03:49:43.258005: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250130 03:49:44.359191: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\Users\stane\tensorflow_datasets\cats_vs_dogs\4.0.1... 20250130 03:50:03.247352: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\src\copy_of_06_exercise_transferlearning&finetuning.py"", line 542, in      train_ds, validation_ds, test_ds = tfds.load(                                        ^^^^^^^^^^   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\logging\__init__.py"", line 176, in __call__     return function(*args, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^^^^   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\load.py"", line 661, in load     _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\load.py"", line 517, in _download_and_prepare_builder     dbuilder.download_and_prepare(**download_and_prepare_kwargs)   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\logging\__init__.py"", line 176, in __call__     return function(*args, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^^^^   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\dataset_builder.py"", line 756, in download_and_prepare     self._download_and_prepare(   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\dataset_builder.py"", line 1752, in _download_and_prepare     split_infos = self._generate_splits(dl_manager, download_config)                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\dataset_builder.py"", line 1727, in _generate_splits     future = split_builder.submit_split_generation(              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\split_builder.py"", line 436, in submit_split_generation     return self._build_from_generator(**build_kwargs)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\core\split_builder.py"", line 496, in _build_from_generator     for key, example in utils.tqdm(   File ""E:\Facultate_etti\An_1_csi\ElemAI\setups\Lib\sitepackages\tensorflow_datasets\image_classification\cats_vs_dogs.py"", line 119, in _generate_examples     new_fobj = zipfile.ZipFile(buffer).open(fname)                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""C:\Users\stane\AppData\Local\Programs\Python\Python311\Lib\zipfile.py"", line 1546, in open     zinfo = self.getinfo(name)             ^^^^^^^^^^^^^^^^^^   File ""C:\Users\stane\AppData\Local\Programs\Python\Python311\Lib\zipfile.py"", line 1475, in getinfo     raise KeyError( KeyError: ""There is no item named 'PetImages\\\\Cat\\\\0.jpg' in the archive"" ```",2025-01-30T01:53:39Z,type:bug awaiting PR merge TF 2.18,closed,0,3,https://github.com/tensorflow/tensorflow/issues/86177,"Hi **** , Welcome to TensorFlow. This is a known issue, and a fix has already been merged. Once a new release is available, the problem should be resolved. I am providing a link to a similar issue here—please follow it for further updates: CC(KeyError: ""There is no item named 'PetImages\\Cat\\0.jpg' in the archive"" When Running TensorFlow Locally(CPU) on Anaconda in VS Code.) Thank you!","Hi , Thank you for suggestion, I will keep an eye on newer releases!",Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],Add an ICYU pragma to silence linters.,Add an ICYU pragma to silence linters.,2025-01-29T22:07:05Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/86159
yi,zainZayam,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.," Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version  2.18.0  Custom code Yes  OS platform and distribution Windows 11  Mobile device _No response_  Python version Python version: 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I encountered an error when trying to import TensorFlow. The error message is: ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Multiple times reinstalled it Downgraded my Python, still no sucess.  Standalone code to reproduce the issue ```shell Traceback (most recent call last):   File ""C:\Users\SAM\anaconda3\envs\tf_env\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: Traceback (most recent call last):   File """", line 1, in    File ""C:\Users\SAM\anaconda3\envs\tf_env\lib\sitepackages\tensorflow\__init__.py"", line 40, in      from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport   File ""C:\Users\SAM\anaconda3\envs\tf_env\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 85, in      raise ImportError( ImportError: Traceback (most recent call last):   File ""C:\Users\SAM\anaconda3\envs\tf_env\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. ```  Relevant log output ```shell ```",2025-01-29T19:28:01Z,stat:awaiting response type:build/install type:others TF 2.18,closed,0,2,https://github.com/tensorflow/tensorflow/issues/86111,", Could you please provide the tensorflow and the compatible version which you are trying to install. Also there are at least 3 possible scenarios: ```  You need to install the MSVC 2019 redistributable  Your CPU does not support AVX2 instructions  Your CPU/Python is on 32 bits  There is a library that is in a different location/not installed on your system that cannot be loaded. ``` Also kindly provide the environment details and the steps followed to install the tensorflow. CC(Tensorflow failed build due to ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.) Also this is a duplicate of https://github.com/tensorflow/tensorflow/issues/19584 Thank you!",Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],PR #21825: Exclude the usage of CPU memory from the GPU memory scheduler,"PR CC(TensorFlow lite android example simply does not sync or build.): Exclude the usage of CPU memory from the GPU memory scheduler Imported from GitHub PR https://github.com/openxla/xla/pull/21825 In the MaxText optimizer state offloading, we observed no memory savings when switching from f16 to f32. The root cause is that the GPU memory scheduler does not distinguish between CPU memory and GPU memory. This commit modifies the scheduler to exclude CPU memory. Copybara import of the project:  c77eefa1b4e31724dbfa40f4ab2aa7aff16e0840 by Jane Liu : Exclude the usage of CPU memory from the GPU memory scheduler  1c5720711c6a7d8173e132922b67eee6e2e8b9dd by Jane Liu : Add the explicit return type for the closure Merging this change closes CC(TensorFlow lite android example simply does not sync or build.) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21825 from zhenyingliu:scheduler 1c5720711c6a7d8173e132922b67eee6e2e8b9dd",2025-01-29T18:09:29Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86070
rag,copybara-service[bot],Add an ICYU pragma to silence linters.,Add an ICYU pragma to silence linters.,2025-01-29T17:52:40Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86068
yi,copybara-service[bot],[xla:gpu] [cleanup] Pull out some logic into IterableInput,"[xla:gpu] [cleanup] Pull out some logic into IterableInput This both simplifies the giant EmitMatmul function & makes it more generic, simplifying the TMA change (see CL chain).",2025-01-29T13:47:36Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/86053
yi,AD-lite24,Tensorflow lite cross compilation to aarch64 failing," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.17.1  Custom code No  OS platform and distribution Host: x86 Ubuntu 20.04  Mobile device target: aarch64  Python version N/A  Bazel version N/A  GCC/compiler version gcc 9  CUDA/cuDNN version N/A  GPU model and memory N/A  Current behavior? Build fails due to an exec format error with `protoc` ``` [ 97%] Built target protoc /usr/bin/make  f profiling/proto/CMakeFiles/profiling_info_proto.dir/build.make profiling/proto/CMakeFiles/profiling_info_proto.dir/depend make[2]: Entering directory '/home/root/build64' [ 98%] Generating profiling_info.pb.cc, profiling_info.pb.h cd /home/root/build64/profiling/proto && protoc cpp_out=/home/root/build64/profiling/proto proto_path=/home/root/tensorflow/tensorflow/lite/profiling/proto /home/root/tensorflow/tensorflow/lite/profiling/proto/profiling_info.proto /bin/sh: 1: protoc: Exec format error make[2]: *** [profiling/proto/CMakeFiles/profiling_info_proto.dir/build.make:75: profiling/proto/profiling_info.pb.cc] Error 2 make[2]: Leaving directory '/home/root/build64' make[1]: *** [CMakeFiles/Makefile2:7385: profiling/proto/CMakeFiles/profiling_info_proto.dir/all] Error 2 make[1]: Leaving directory '/home/root/build64' make: *** [Makefile:136: all] Error 2 ``` The only possible explanation for this seems to be that that the cmake build process is attempting to use `protoc` for this step  ``` [ 98%] Generating profiling_info.pb.cc, profiling_info.pb.h cd /home/root/build64/profiling/proto && protoc cpp_out=/home/root/build64/profiling/proto proto_path=/home/root/tensorflow/tensorflow/lite/profiling/proto /home/root/tensorflow/tensorflow/lite/profiling/proto/profiling_info.proto ``` But since `protoc` was built using the cross compiler tool chain it is meant for aarch64 while my host machine is trying to run it. This is likely a bug with the cross compilation process and in that case, please suggest a fix. I am not sure to what extent `protoc` is used in the build so any fix I would make cannot be completely correct.  Edit: I installed the x86 version for `protoc` separately, specifically the version 3.21.x which is the exact version that the tflite build process creates (3.21.9) and I am still facing version incompatibility issues  ``` /home/root/build64/profiling/proto/profiling_info.pb.h:17:2: error: error This file was generated by an older version of protoc which is    17   ^~~~~ ```  Standalone code to reproduce the issue ```shell `cmake DCMAKE_TOOLCHAIN_FILE=/opt/cross_toolchain/aarch64gnu9.toolchain.cmake DTFLITE_ENABLE_GPU=ON DTFLITE_ENABLE_NNAPI=ON DXNNPACK_ENABLE_ARM_BF16=OFF DXNNPACK_ENABLE_ARM_I8MM=OFF DCMAKE_CXX_FL<CXX_FLAGS=""${CMAKE_CXX_FLAGS} std=c++11"" ../tensorflow/tensorflow/lite` Using the default Cmake build process. ```  Relevant log output ```shell ```",2025-01-29T11:42:26Z,type:build/install comp:lite subtype: ubuntu/linux 2.17,closed,0,2,https://github.com/tensorflow/tensorflow/issues/86044,"Figured it out. Apparently protobuf 3.21.12 is significantly different from 3.21.9 and there is no release for 3.21.9 so need to build it from source. Still there is a bug with with the cross compilation process that should be resolved. I will try to create a PR if I end up writing a seamless solution, but for now the workaround of manually building protobuf works. Closing the issue for now but the issue has not been resolved.",Are you satisfied with the resolution of your issue? Yes No
yi,DamarXCV,Input pipeline with RaggedTensor no longer working in +2.16 - No registered 'RaggedTensorToVariant' OpKernel for XLA_GPU_JIT," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.18.0  Custom code Yes  OS platform and distribution Ubuntu 24.04.1 LTS  Mobile device _No response_  Python version 3.11 & 3.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In version 2.15 and earlier i was able to have a batched `tf.data.Dataset` with `tf.RaggedTensor` as input for `model.fit` and `model.predict`, with `tf.keras.layers.Resizing` as the first layer of the model. This is no longer works in +2.16 and Keras 3 (Edit: not Keras 2). The error log contains `RaggedTensorToVariant (No registered 'RaggedTensorToVariant' OpKernel for XLA_GPU_JIT devices compatible`, which implies a missing implementation.  Standalone code to reproduce the issue ```shell import tensorflow as tf ds = tf.data.Dataset.from_tensor_slices(range(10)) \     .map(lambda x: (         tf.RaggedTensor.from_tensor(tf.zeros((x + 1, x + 1, 1))),         0,     )) \     .batch(batch_size=4) \     .prefetch(tf.data.AUTOTUNE) model = tf.keras.Sequential([     tf.keras.layers.Resizing(height=10, width=10),     tf.keras.layers.GlobalMaxPool2D(),     tf.keras.layers.Softmax(), ]) model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy()) model.fit(ds) ```  Relevant log output ```shell I0000 00:00:1738149672.657535   10590 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7070 MB memory:  > device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:0b:00.0, compute capability: 6.1 [...]/.venv/lib/python3.12/sitepackages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis 1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?   warnings.warn( [...]/.venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.   warnings.warn(""The model does not have any trainable weights."") WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1738149672.931281   10665 service.cc:148] XLA service 0x79b50c0038a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: I0000 00:00:1738149672.931302   10665 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1 20250129 12:21:12.940706: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at if_op.cc:291 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[] on XLA_GPU_JIT: RaggedTensorToVariant (No registered 'RaggedTensorToVariant' OpKernel for XLA_GPU_JIT devices compatible with node {{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}}){{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}} The op is created at:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	tf2xla conversion failed while converting sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. Stack trace for op definition:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 20250129 12:21:12.940972: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[] on XLA_GPU_JIT: RaggedTensorToVariant (No registered 'RaggedTensorToVariant' OpKernel for XLA_GPU_JIT devices compatible with node {{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}}){{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}} The op is created at:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	tf2xla conversion failed while converting sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. Stack trace for op definition:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	 [[sequential_1/resizing_1/RaggedResizeImages/cond]] 	tf2xla conversion failed while converting __inference_one_step_on_data_290[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. 20250129 12:21:12.941007: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: Detected unsupported operations when trying to compile graph sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[] on XLA_GPU_JIT: RaggedTensorToVariant (No registered 'RaggedTensorToVariant' OpKernel for XLA_GPU_JIT devices compatible with node {{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}}){{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}} The op is created at:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	tf2xla conversion failed while converting sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. Stack trace for op definition:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	 [[sequential_1/resizing_1/RaggedResizeImages/cond]] 	tf2xla conversion failed while converting __inference_one_step_on_data_290[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. 	 [[StatefulPartitionedCall]] Traceback (most recent call last):   File ""[...]/test.py"", line 43, in      model.fit(ds)   File ""[...]/.venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 122, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""[...]/.venv/lib/python3.12/sitepackages/tensorflow/python/eager/execute.py"", line 53, in quick_execute     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error: Detected at node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant defined at (most recent call last):  Detected at node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant defined at (most recent call last):  Detected unsupported operations when trying to compile graph sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[] on XLA_GPU_JIT: RaggedTensorToVariant (No registered 'RaggedTensorToVariant' OpKernel for XLA_GPU_JIT devices compatible with node {{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}}){{node sequential_1/resizing_1/RaggedResizeImages/cond/map/RaggedToVariant/RaggedTensorToVariant}} The op is created at:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	tf2xla conversion failed while converting sequential_1_resizing_1_RaggedResizeImages_cond_false_141_const_0[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. Stack trace for op definition:  File ""test.py"", line 43, in  File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 371, in fit File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 219, in function File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 132, in multi_step_on_iterator File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 113, in one_step_on_data File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/trainer.py"", line 57, in train_step File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/models/sequential.py"", line 213, in call File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 182, in call File "".venv/lib/python3.12/sitepackages/keras/src/ops/function.py"", line 171, in _run_through_graph File "".venv/lib/python3.12/sitepackages/keras/src/models/functional.py"", line 637, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/tf_data_layer.py"", line 43, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/layer.py"", line 908, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 117, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/ops/operation.py"", line 46, in __call__ File "".venv/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 156, in error_handler File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/base_image_preprocessing_layer.py"", line 208, in call File "".venv/lib/python3.12/sitepackages/keras/src/layers/preprocessing/image_preprocessing/resizing.py"", line 103, in transform_images File "".venv/lib/python3.12/sitepackages/keras/src/backend/tensorflow/image.py"", line 293, in resize 	 [[sequential_1/resizing_1/RaggedResizeImages/cond]] 	tf2xla conversion failed while converting __inference_one_step_on_data_290[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and vmodule=xla_compiler=2 to obtain a dump of the compiled functions. 	 [[StatefulPartitionedCall]] [Op:__inference_multi_step_on_iterator_298] ```",2025-01-29T11:40:28Z,type:bug comp:keras TF 2.18,closed,0,4,https://github.com/tensorflow/tensorflow/issues/86043,"Hi **** , Apologies for the delay, and thank you for raising your concern here. The main cause of your issue is the Keras installation. Starting from TensorFlow version 2.16.0, it defaults to Keras 3. If you want to use Keras 2, you need to install it manually. This is also mentioned in the documentation. I installed everything as required, and it is working fine for me. Here, I am providing a gist for your reference. Thank you!"," Thank you for your reply. Sorry, i meant Keras 3 not Keras 2, i corrected it in my original post. If i console log the version it prints `3.8.0` for Keras with the following code ``` import tensorflow as tf print(tf.__version__) print(tf.keras.__version__) ds = tf.data.Dataset.from_tensor_slices(range(10)) \     .map(lambda x: (         tf.RaggedTensor.from_tensor(tf.zeros((x + 1, x + 1, 1))),         0,     )) \     .batch(batch_size=4) \     .prefetch(tf.data.AUTOTUNE) model = tf.keras.Sequential([     tf.keras.layers.Resizing(height=10, width=10),     tf.keras.layers.GlobalMaxPool2D(),     tf.keras.layers.Softmax(), ]) model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy()) model.fit(ds) ``` I know i should use the standalone keras import, as documented in the migration guide, but even i do so it still crashes with the error from my initial post ``` import keras import tensorflow as tf print(tf.__version__) print(keras.__version__) ds = tf.data.Dataset.from_tensor_slices(range(10)) \     .map(lambda x: (         tf.RaggedTensor.from_tensor(tf.zeros((x + 1, x + 1, 1))),         0,     )) \     .batch(batch_size=4) \     .prefetch(tf.data.AUTOTUNE) model = keras.Sequential([     keras.layers.Resizing(height=10, width=10),     keras.layers.GlobalMaxPool2D(),     keras.layers.Softmax(), ]) model.compile(loss=keras.losses.SparseCategoricalCrossentropy()) model.fit(ds) ``` The printed versions are in both code snipets `2.18.0` and `3.8.0`. If i install tfkeras (aka Keras 2) with `pip install tfkeras` the following code works ``` import tf_keras import tensorflow as tf print(tf.__version__) print(tf_keras.__version__) ds = tf.data.Dataset.from_tensor_slices(range(10)) \     .map(lambda x: (         tf.RaggedTensor.from_tensor(tf.zeros((x + 1, x + 1, 1))),         0,     )) \     .batch(batch_size=4) \     .prefetch(tf.data.AUTOTUNE) model = tf_keras.Sequential([     tf_keras.layers.Resizing(height=10, width=10),     tf_keras.layers.GlobalMaxPool2D(),     tf_keras.layers.Softmax(), ]) model.compile(loss=tf_keras.losses.SparseCategoricalCrossentropy()) model.fit(ds) ``` But i would like to use Keras 3 and not the outdated Keras 2, which seems to not support `tf.RaggedTensor` as input for `keras.layers.Resizing`",I found kerasteam/keras CC(Add missing semicolon) which mentions  > No RaggedTensor support. We may add it back later. I guess that means that my input pipeline is not supported in Keras 3 for now.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Refactor XLA's common.bara.sky to make copying of top level files and dirs more terse,"Refactor XLA's common.bara.sky to make copying of top level files and dirs more terse This is in preparation for introducing the concept of a ""moveonly"" file explicitly",2025-01-29T00:58:35Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85996
yi,copybara-service[bot],Use efficient packed flatbuffer api to handle underlying tfl models.,Use efficient packed flatbuffer api to handle underlying tfl models.,2025-01-28T23:43:48Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85991
yi,copybara-service[bot],Return arrays from `ArrayImpl._check_and_rearrange`.,"Return arrays from `ArrayImpl._check_and_rearrange`. This is in preparation for a larger change, so that `_check_arrays` can be called before Array creation in XLA and the user gets more helpful JAX error messages instead of XLA errors. Reverts changelist 721179542 FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e",2025-01-28T22:27:18Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85985
rag,copybara-service[bot],Remove `UpdateEntryComputationLayout` from `HloRunnerAgnosticTestBase`,Remove `UpdateEntryComputationLayout` from `HloRunnerAgnosticTestBase` Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b,2025-01-28T19:55:34Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85969
yi,copybara-service[bot],PR #21886: [ROCM][NFC] BlasLt interface refactoring & simplifying: part I,"PR CC(Tensorflow 1.10.0 MKL build (win64) with bazel throws linker error): [ROCM][NFC] BlasLt interface refactoring & simplifying: part I Imported from GitHub PR https://github.com/openxla/xla/pull/21886 After this PR https://github.com/tensorflow/tensorflow/pull/73926 is merged, we can remove unnecessary lowlevel DoMatmul functions from GpuBlasLt interface (which otherwise looks scary and unnecessarily complicated). Furthermore, we can also remove **ValidateInputs** function from the interface and derived classes since a highlevel **ExecuteOnStream** function already handles datatypes correctly. This also greatly simplifies the code. Also, I have packed the input arguments of ExecuteOnStream calls to a struct **MemoryArgs** to simplify arguments passing in derived classes and improve code readability. Finally, in the original GpuBlasLt PR: https://github.com/openxla/xla/pull/5911, I made a sort of mistake by adding a reference to **blas_lt** to the MatmulPlan class here, thereby making MatmulPlans bound to a **particular BlasLt instance**. This resulted in some further bugfixes and, most importantly, complicated GpuBlasLt cache design in gpublas_lt_matmul_thunk.cc/.h. In this PR, I remove this reference again from MatmulPlan class and in the next NFC PR the cache mechanics can also be simplified.  Unfortunately, this change also requires a tandem PR for Tensorflow: https://github.com/tensorflow/tensorflow/pull/85835 rotation Would you please have a look Copybara import of the project:  e96bb2fbedab3f53b31ef0e1748582c76e9fb105 by Pavel Emeliyanenko : blaslt interface refactoring: removing blas_lt_ref added cuda adaptions cudaside adaptions cuda side adaptions fix fixing pointers Merging this change closes CC(Tensorflow 1.10.0 MKL build (win64) with bazel throws linker error) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21886 from ROCm:ci_gpublas_lt_refactor_1 e96bb2fbedab3f53b31ef0e1748582c76e9fb105",2025-01-28T14:45:31Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85948
rag,copybara-service[bot],"Replace ""external_buffer"" nomenclature with ""op_asset"" and leverage the unified buffer management approach.","Replace ""external_buffer"" nomenclature with ""op_asset"" and leverage the unified buffer management approach.",2025-01-28T00:13:25Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85901
rag,copybara-service[bot],Unify metadata storage with unified buffer management.,Unify metadata storage with unified buffer management.,2025-01-27T21:11:25Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85886
yi,copybara-service[bot],PR #21845: [ROCM] Add missing triton MLIR int4 -> int8 rewrite pass for ROCM,PR CC(未找到相关数据): [ROCM] Add missing triton MLIR int4 > int8 rewrite pass for ROCM Imported from GitHub PR https://github.com/openxla/xla/pull/21845 ``` TritonTest.DotWithInt4WeightsOnLhsFusedWithMultiplyByChannelScales TritonTest.NonstandardLayoutInt4 TritonTest.DotWithI4WeightsOnLhsWithBitcastTo3dTensor TritonTest.DotWithI4WeightsOnLhsWithNonStandardLayoutAndMultplyInEpilogue TritonTest.LHSWithMinorDimEqualTo1 TritonTest.RHSWithMinorDimEqualTo1 TritonTest.LHSNonMinorContractingDim TritonTest.LHSNonMinorContractingDimWithBatchDim0 TritonTest.LHSMinorContractingDim TritonTest.ConvertPlusNegate TritonTest.LHSMinorContractingDimWithBatchDim0 TritonTest.RHSTestWithNotMinorContractingDim TritonTest.RHSTestWithMinorContractingDim TritonTest.RHSTestWithMinorContractingDimWithBatchDim TritonTest.RHSTestWithNotMinorContractingDimWithBatchDim0 ParametrizedTritonTest.Int4WeightsOnTheLhs ParametrizedTritonTest.Int4WeightsOnTheLhsWithBatchDim ParametrizedTritonTest.Int4WeightsOnTheRhs ``` Tests above are failing on ROCm side after int4 rewriting was moved from legacy matmul emitter to MLIR pass. This MLIR pass is now missing in ROCm triton pipeline and I'm adding it in the place. rotation: would you please take a look?  Copybara import of the project:  75e78ad365a9d55f6e299c7b64400447ceebb26d by Jian Li : [ROCM] Add missing triton MLIR int4 > int8 rewrite pass for ROCM Merging this change closes CC(未找到相关数据) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21845 from ROCm:ci_fix_rocm_triton_test 75e78ad365a9d55f6e299c7b64400447ceebb26d,2025-01-27T18:14:47Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85867
yi,copybara-service[bot],[xla:cpu] Remove code for computing optimal number of workers at run time,"[xla:cpu] Remove code for computing optimal number of workers at run time Instead of trying to figure out optimal number of workers at run time, we'd better have a cost model that can make this decision at compile time based on the XNNPACK fusion.",2025-01-26T18:21:26Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85772
rag,copybara-service[bot],Support `mhlo.sharding` attr inside `backend_config` of ragged_all_to_all,Support `mhlo.sharding` attr inside `backend_config` of ragged_all_to_all,2025-01-24T21:11:40Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85692
llm,LinuxPersonEC,"TF 2.18 with GPU does not detect GPU, Cannot dlopen some GPU libraries, in a container"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18  Custom code Yes  OS platform and distribution Linux Centos 7.9, RHEL 8, RHEL 9  Mobile device _No response_  Python version 3.11.0rc1  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 550.90.07  GPU model and memory _No response_  Current behavior? After discussing this on the Apptainer Git we determined the latest TFGPU running 2.18.0 does not register any GPUs. Older versions like 2.7.1gpu work just fine. `apptainer run nv  /apps/Miniforge/lib/python3.12/sitepackages/containers/tensorflow/tensorflow/latestgpu/tensorflowtensorflowlatestgpusha256\:1f16fbd9be8bb84891de12533e332bbd500511caeb5cf4db501dbe39d422f9c7.sif python` ``` import tensorflow as tf 20250124 15:03:27.629215: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1737749008.639844   35316 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1737749008.847756   35316 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250124 15:03:31.499335: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. ``` ``` print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU'))) W0000 00:00:1737749068.599039   35316 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform. Skipping registering GPU devices... Num GPUs Available:  0 ``` ``` >>> print(tf.__version__) 2.18.0 ```  Standalone code to reproduce the issue ```shell shpc install tensorflow/tensorflow:latestgpu or apptainer pull docker://tensorflow/tensorflow:latestgpu apptainer run nv  /apps/Miniforge/lib/python3.12/sitepackages/containers/tensorflow/tensorflow/latestgpu/tensorflowtensorflowlatestgpusha256\:1f16fbd9be8bb84891de12533e332bbd500511caeb5cf4db501dbe39d422f9c7.sif python python import tensorflow as tf print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU'))) ```  Relevant log output ```shell apptainer debug exec nv  /apps/Miniforge/lib/python3.12/sitepackages/containers/tensorflow/tensorflow/latestgpu/tensorflowtensorflowlatestgpusha256:1f16fbd9be8bb84891de12533e332bbd500511caeb5cf4db501dbe39d422f9c7.sif python DEBUG   [U=0,P=1355208]    persistentPreRun()            Apptainer version: 1.3.61 DEBUG   [U=0,P=1355208]    persistentPreRun()            Parsing configuration file /etc/apptainer/apptainer.conf DEBUG   [U=0,P=1355208]    SetBinaryPath()               Setting binary path to /usr/libexec/apptainer/bin:/usr/share/Modules/bin:/usr/local/sbin:/sbin:/bin:/usr/sbin:/usr/bin:/opt/TurboVNC/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin DEBUG   [U=0,P=1355208]    SetBinaryPath()               Using that path for all binaries DEBUG   [U=0,P=1355208]    handleConfDir()               /root/.apptainer already exists. Not creating. DEBUG   [U=0,P=1355208]    handleRemoteConf()            Ensuring file permission of 0600 on /root/.apptainer/remote.yaml DEBUG   [U=0,P=1355208]    setUmask()                    Saving umask 0002 for propagation into container DEBUG   [U=0,P=1355208]    checkEncryptionKey()          Checking for encrypted system partition DEBUG   [U=0,P=1355208]    Init()                        Image format detection DEBUG   [U=0,P=1355208]    Init()                        Check for sandbox image format DEBUG   [U=0,P=1355208]    Init()                        sandbox format initializer returned: not a directory image DEBUG   [U=0,P=1355208]    Init()                        Check for sif image format DEBUG   [U=0,P=1355208]    Init()                        sif image format detected VERBOSE [U=0,P=1355208]    SetGPUConfig()                'always use nv = yes' found in apptainer.conf DEBUG   [U=0,P=1355208]    setNVLegacyConfig()           Using legacy binds for nv GPU setup VERBOSE [U=0,P=1355208]    NvidiaIpcsPath()              persistenced socket /var/run/nvidiapersistenced/socket not found DEBUG   [U=0,P=1355208]    findOnPath()                  Found ""ldconfig"" at ""/sbin/ldconfig"" DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SHELL environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SUDO_GID environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding HISTCONTROL environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding no_proxy environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding HOSTNAME environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding HISTSIZE environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SBATCH_PARTITION environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding GUESTFISH_OUTPUT environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SLURM_PARTITION environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SUDO_COMMAND environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SUDO_USER environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LMOD_DIR environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding PWD environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LOGNAME environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MODULESHOME environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MANPATH environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding GUESTFISH_RESTORE environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding __MODULES_SHARE_MANPATH environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SSH_ASKPASS environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LANG environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LS_COLORS environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LMOD_SETTARG_FULL_SUPPORT environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding GUESTFISH_PS1 environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding https_proxy environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LMOD_VERSION environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MODULEPATH_ROOT environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LMOD_PKG environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding TERM environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LESSOPEN environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding USER environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding NO_PROXY environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MODULES_RUN_QUARANTINE environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LOADEDMODULES environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SHLVL environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding BASH_ENV environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LMOD_sys environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding HTTPS_PROXY environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding GUESTFISH_INIT environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding HTTP_PROXY environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding http_proxy environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding S_COLORS environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding __MODULES_LMINIT environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding which_declare environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding XDG_DATA_DIRS environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MODULEPATH environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding SUDO_UID environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding LMOD_CMD environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MAIL environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding MODULES_CMD environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding BASH_FUNC_ml%% environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding BASH_FUNC_which%% environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding BASH_FUNC_module%% environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding BASH_FUNC_scl%% environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding BASH_FUNC__module_raw%% environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding _ environment variable VERBOSE [U=0,P=1355208]    SetContainerEnv()             Not forwarding APPTAINER_DEBUG environment variable DEBUG   [U=0,P=1355208]    SetContainerEnv()             Forwarding USER_PATH environment variable VERBOSE [U=0,P=1355208]    SetContainerEnv()             Setting HOME=/root VERBOSE [U=0,P=1355208]    SetContainerEnv()             Setting PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin DEBUG   [U=0,P=1355208]    InitImageDrivers()            Skipping installing fuseapps image driver because running as root DEBUG   [U=0,P=1355208]    SetuidMountAllowed()          Kernel squashfs mount allowed because running as root DEBUG   [U=0,P=1355208]    init()                        Use starter binary /usr/libexec/apptainer/bin/starter VERBOSE [U=0,P=1355208]    print()                       Set messagelevel to: 5 VERBOSE [U=0,P=1355208]    init()                        Starter initialization VERBOSE [U=0,P=1355208]    is_suid()                     Check if we are running as setuid: 0 DEBUG   [U=0,P=1355208]    read_engine_config()          Read engine configuration DEBUG   [U=0,P=1355208]    init()                        Wait completion of stage1 DEBUG   [U=0,P=1355224]    set_parent_death_signal()     Set parent death signal to 9 VERBOSE [U=0,P=1355224]    init()                        Spawn stage 1 DEBUG   [U=0,P=1355224]    func1()                       executablePath is /usr/libexec/apptainer/bin/starter DEBUG   [U=0,P=1355224]    func1()                       starter was not relocated from /usr/libexec DEBUG   [U=0,P=1355224]    func1()                       Install prefix is /usr DEBUG   [U=0,P=1355224]    startup()                     apptainer runtime engine selected VERBOSE [U=0,P=1355224]    startup()                     Execute stage 1 DEBUG   [U=0,P=1355224]    StageOne()                    Entering stage 1 DEBUG   [U=0,P=1355224]    InitImageDrivers()            Skipping installing fuseapps image driver because running as root DEBUG   [U=0,P=1355224]    prepareRootCaps()             Root full capabilities DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/proc/sys/fs/binfmt_misc"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/home"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/share"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/misc"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/net"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/mnt/smb/locker"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/mnt/smb/labshare"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Found ""/mnt/smb/staging"" as autofs mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Could not keep file descriptor for bind path /etc/localtime: no mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Could not keep file descriptor for bind path /etc/hosts: no mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Could not keep file descriptor for home directory /root: no mount point DEBUG   [U=0,P=1355224]    prepareAutofs()               Could not keep file descriptor for current working directory /root: no mount point DEBUG   [U=0,P=1355224]    Init()                        Image format detection DEBUG   [U=0,P=1355224]    Init()                        Check for sandbox image format DEBUG   [U=0,P=1355224]    Init()                        sandbox format initializer returned: not a directory image DEBUG   [U=0,P=1355224]    Init()                        Check for sif image format DEBUG   [U=0,P=1355224]    Init()                        sif image format detected DEBUG   [U=0,P=1355224]    setSessionLayer()             Using overlay because it is not disabled DEBUG   [U=0,P=1355224]    PrepareConfig()               image driver is  VERBOSE [U=0,P=1355208]    wait_child()                  stage 1 exited with status 0 DEBUG   [U=0,P=1355208]    cleanup_fd()                  Close file descriptor 4 DEBUG   [U=0,P=1355208]    cleanup_fd()                  Close file descriptor 5 DEBUG   [U=0,P=1355208]    cleanup_fd()                  Close file descriptor 6 DEBUG   [U=0,P=1355208]    init()                        Set child signal mask DEBUG   [U=0,P=1355208]    init()                        Create socketpair for master communication channel DEBUG   [U=0,P=1355208]    init()                        Create RPC socketpair for communication between stage 2 and RPC server VERBOSE [U=0,P=1355208]    init()                        Spawn master process DEBUG   [U=0,P=1355230]    set_parent_death_signal()     Set parent death signal to 9 VERBOSE [U=0,P=1355230]    create_namespace()            Create mount namespace VERBOSE [U=0,P=1355208]    enter_namespace()             Entering in mount namespace DEBUG   [U=0,P=1355208]    enter_namespace()             Opening namespace file ns/mnt VERBOSE [U=0,P=1355230]    create_namespace()            Create mount namespace VERBOSE [U=0,P=1355231]    init()                        Spawn RPC server DEBUG   [U=0,P=1355208]    func1()                       executablePath is /usr/libexec/apptainer/bin/starter DEBUG   [U=0,P=1355208]    func1()                       starter was not relocated from /usr/libexec DEBUG   [U=0,P=1355208]    func1()                       Install prefix is /usr DEBUG   [U=0,P=1355231]    func1()                       executablePath is /usr/libexec/apptainer/bin/starter DEBUG   [U=0,P=1355231]    func1()                       starter was not relocated from /usr/libexec DEBUG   [U=0,P=1355231]    func1()                       Install prefix is /usr DEBUG   [U=0,P=1355208]    startup()                     apptainer runtime engine selected VERBOSE [U=0,P=1355208]    startup()                     Execute master process DEBUG   [U=0,P=1355231]    startup()                     apptainer runtime engine selected VERBOSE [U=0,P=1355231]    startup()                     Serve RPC requests DEBUG   [U=0,P=1355208]    InitImageDrivers()            Skipping installing fuseapps image driver because running as root DEBUG   [U=0,P=1355208]    setupSessionLayout()          Using Layer system: overlay DEBUG   [U=0,P=1355208]    setupOverlayLayout()          Creating overlay SESSIONDIR layout DEBUG   [U=0,P=1355208]    addRootfsMount()              Mount rootfs in readonly mode DEBUG   [U=0,P=1355208]    addRootfsMount()              Image type is 4096 DEBUG   [U=0,P=1355208]    addRootfsMount()              Mounting block [squashfs] image: /share/apps/Miniforge/lib/python3.12/sitepackages/containers/tensorflow/tensorflow/latestgpu/tensorflowtensorflowlatestgpusha256:1f16fbd9be8bb84891de12533e332bbd500511caeb5cf4db501dbe39d422f9c7.sif DEBUG   [U=0,P=1355208]    addKernelMount()              Checking configuration file for 'mount proc' DEBUG   [U=0,P=1355208]    addKernelMount()              Adding proc to mount list VERBOSE [U=0,P=1355208]    addKernelMount()              Default mount: /proc:/proc DEBUG   [U=0,P=1355208]    addKernelMount()              Checking configuration file for 'mount sys' DEBUG   [U=0,P=1355208]    addKernelMount()              Adding sysfs to mount list VERBOSE [U=0,P=1355208]    addKernelMount()              Default mount: /sys:/sys DEBUG   [U=0,P=1355208]    addDevMount()                 Checking configuration file for 'mount dev' DEBUG   [U=0,P=1355208]    addDevMount()                 Adding dev to mount list VERBOSE [U=0,P=1355208]    addDevMount()                 Default mount: /dev:/dev DEBUG   [U=0,P=1355208]    addHostMount()                Not mounting host file systems per configuration VERBOSE [U=0,P=1355208]    addBindsMount()               Found 'bind path' = /etc/localtime, /etc/localtime VERBOSE [U=0,P=1355208]    addBindsMount()               Found 'bind path' = /etc/hosts, /etc/hosts DEBUG   [U=0,P=1355208]    addHomeStagingDir()           Staging home directory (/root) at /var/lib/apptainer/mnt/session/root DEBUG   [U=0,P=1355208]    addHomeMount()                Adding home directory mount [/var/lib/apptainer/mnt/session/root:/root] to list using layer: overlay DEBUG   [U=0,P=1355208]    addTmpMount()                 Checking for 'mount tmp' in configuration file DEBUG   [U=0,P=1355208]    addScratchMount()             Not mounting scratch directory: Not requested DEBUG   [U=0,P=1355208]    addLibsMount()                Checking for 'user bind control' in configuration file DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libOpenCL.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libOpenGL.so.0 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiacfg.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libEGL.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaeglcore.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaml.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvcuvid.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiagtk3.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaglvkspirv.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libcudadebugger.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLESv2.so.2 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaptxjitcompiler.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLESv2.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGL.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLX_nvidia.so.0 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLESv1_CM.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiatls.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLdispatch.so.0 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaencode.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libOpenCL.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaptxjitcompiler.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaencode.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidianvvm.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaglsi.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaopticalflow.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaopencl.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaeglwayland.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLX.so.0 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvoptix.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiagpucomp.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGL.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLESv2_nvidia.so.2 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLESv1_CM_nvidia.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidianvvm.so.4 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libEGL.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiagtk2.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaml.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiafbc.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiafbc.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvcuvid.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaopticalflow.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLX.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLESv1_CM.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiacfg.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libcuda.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libvdpau_nvidia.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiartcore.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libcuda.so.1 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libOpenGL.so to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libEGL_nvidia.so.0 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libnvidiaglcore.so.550.120 to mount list DEBUG   [U=0,P=1355208]    addLibsMount()                Add library /lib64/libGLdispatch.so to mount list DEBUG   [U=0,P=1355208]    addFilesMount()               Checking for 'user bind control' in configuration file DEBUG   [U=0,P=1355208]    addFilesMount()               Adding file /bin/nvidiapersistenced:/usr/bin/nvidiapersistenced to mount list DEBUG   [U=0,P=1355208]    addFilesMount()               Adding file /bin/nvidiacudampscontrol:/usr/bin/nvidiacudampscontrol to mount list DEBUG   [U=0,P=1355208]    addFilesMount()               Adding file /bin/nvidiacudampsserver:/usr/bin/nvidiacudampsserver to mount list DEBUG   [U=0,P=1355208]    addFilesMount()               Adding file /bin/nvidiasmi:/usr/bin/nvidiasmi to mount list DEBUG   [U=0,P=1355208]    addFilesMount()               Adding file /bin/nvidiadebugdump:/usr/bin/nvidiadebugdump to mount list DEBUG   [U=0,P=1355208]    addResolvConfMount()          Adding /etc/resolv.conf to mount list VERBOSE [U=0,P=1355208]    addResolvConfMount()          Default mount: /etc/resolv.conf:/etc/resolv.conf DEBUG   [U=0,P=1355208]    addHostnameMount()            Skipping hostname mount, not virtualizing UTS namespace on user request DEBUG   [U=0,P=1355208]    create()                      Mount all DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting tmpfs to /var/lib/apptainer/mnt/session DEBUG   [U=0,P=1355208]    mountImage()                  Mounting loop device /dev/loop0 to /var/lib/apptainer/mnt/session/rootfs of type squashfs DEBUG   [U=0,P=1355208]    createCwdDir()                Using /root as current working directory DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting overlay to /var/lib/apptainer/mnt/session/final DEBUG   [U=0,P=1355208]    mountGeneric()                Unmounting and remounting overlay DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final DEBUG   [U=0,P=1355208]    setPropagationMount()         Set RPC mount propagation flag to SLAVE VERBOSE [U=0,P=1355208]    Passwd()                      Checking for template passwd file: /var/lib/apptainer/mnt/session/rootfs/etc/passwd VERBOSE [U=0,P=1355208]    Passwd()                      Creating passwd content VERBOSE [U=0,P=1355208]    Passwd()                      Creating template passwd file and injecting user data: /var/lib/apptainer/mnt/session/rootfs/etc/passwd DEBUG   [U=0,P=1355208]    addIdentityMount()            Adding /etc/passwd to mount list VERBOSE [U=0,P=1355208]    addIdentityMount()            Default mount: /etc/passwd:/etc/passwd VERBOSE [U=0,P=1355208]    Group()                       Checking for template group file: /var/lib/apptainer/mnt/session/rootfs/etc/group VERBOSE [U=0,P=1355208]    Group()                       Creating group content DEBUG   [U=0,P=1355208]    addIdentityMount()            Adding /etc/group to mount list VERBOSE [U=0,P=1355208]    addIdentityMount()            Default mount: /etc/group:/etc/group DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /dev to /var/lib/apptainer/mnt/session/final/dev DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /etc/localtime to /var/lib/apptainer/mnt/session/final/etc/localtime DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/etc/localtime DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /etc/hosts to /var/lib/apptainer/mnt/session/final/etc/hosts DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/etc/hosts DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /proc to /var/lib/apptainer/mnt/session/final/proc DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/proc DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting sysfs to /var/lib/apptainer/mnt/session/final/sys DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /root to /var/lib/apptainer/mnt/session/root DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/root DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /var/lib/apptainer/mnt/session/root to /var/lib/apptainer/mnt/session/final/root DEBUG   [U=0,P=1355208]    func1()                       Container /tmp resolves to ""/tmp"" DEBUG   [U=0,P=1355208]    func1()                       Container /var/tmp resolves to ""/var/tmp"" VERBOSE [U=0,P=1355208]    func1()                       Default mount: /tmp:/tmp VERBOSE [U=0,P=1355208]    func1()                       Default mount: /var/tmp:/var/tmp DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /tmp to /var/lib/apptainer/mnt/session/final/tmp DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/tmp DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /var/tmp to /var/lib/apptainer/mnt/session/final/var/tmp DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/var/tmp DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libOpenCL.so to /var/lib/apptainer/mnt/session/libs/libOpenCL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libOpenCL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libOpenGL.so.0 to /var/lib/apptainer/mnt/session/libs/libOpenGL.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libOpenGL.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiacfg.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiacfg.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiacfg.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libEGL.so.1 to /var/lib/apptainer/mnt/session/libs/libEGL.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libEGL.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaeglcore.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiaeglcore.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaeglcore.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaml.so to /var/lib/apptainer/mnt/session/libs/libnvidiaml.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaml.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvcuvid.so.1 to /var/lib/apptainer/mnt/session/libs/libnvcuvid.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvcuvid.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiagtk3.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiagtk3.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiagtk3.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaglvkspirv.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiaglvkspirv.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaglvkspirv.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libcudadebugger.so.1 to /var/lib/apptainer/mnt/session/libs/libcudadebugger.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libcudadebugger.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLESv2.so.2 to /var/lib/apptainer/mnt/session/libs/libGLESv2.so.2 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLESv2.so.2 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaptxjitcompiler.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiaptxjitcompiler.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaptxjitcompiler.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLESv2.so to /var/lib/apptainer/mnt/session/libs/libGLESv2.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLESv2.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGL.so to /var/lib/apptainer/mnt/session/libs/libGL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLX_nvidia.so.0 to /var/lib/apptainer/mnt/session/libs/libGLX_nvidia.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLX_nvidia.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLESv1_CM.so.1 to /var/lib/apptainer/mnt/session/libs/libGLESv1_CM.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLESv1_CM.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiatls.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiatls.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiatls.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLdispatch.so.0 to /var/lib/apptainer/mnt/session/libs/libGLdispatch.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLdispatch.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaencode.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiaencode.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaencode.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libOpenCL.so.1 to /var/lib/apptainer/mnt/session/libs/libOpenCL.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libOpenCL.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaptxjitcompiler.so to /var/lib/apptainer/mnt/session/libs/libnvidiaptxjitcompiler.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaptxjitcompiler.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaencode.so to /var/lib/apptainer/mnt/session/libs/libnvidiaencode.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaencode.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidianvvm.so to /var/lib/apptainer/mnt/session/libs/libnvidianvvm.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidianvvm.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaglsi.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiaglsi.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaglsi.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaopticalflow.so to /var/lib/apptainer/mnt/session/libs/libnvidiaopticalflow.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaopticalflow.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaopencl.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiaopencl.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaopencl.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaeglwayland.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiaeglwayland.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaeglwayland.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLX.so.0 to /var/lib/apptainer/mnt/session/libs/libGLX.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLX.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvoptix.so.1 to /var/lib/apptainer/mnt/session/libs/libnvoptix.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvoptix.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiagpucomp.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiagpucomp.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiagpucomp.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGL.so.1 to /var/lib/apptainer/mnt/session/libs/libGL.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGL.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLESv2_nvidia.so.2 to /var/lib/apptainer/mnt/session/libs/libGLESv2_nvidia.so.2 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLESv2_nvidia.so.2 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLESv1_CM_nvidia.so.1 to /var/lib/apptainer/mnt/session/libs/libGLESv1_CM_nvidia.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLESv1_CM_nvidia.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidianvvm.so.4 to /var/lib/apptainer/mnt/session/libs/libnvidianvvm.so.4 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidianvvm.so.4 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libEGL.so to /var/lib/apptainer/mnt/session/libs/libEGL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libEGL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiagtk2.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiagtk2.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiagtk2.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaml.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiaml.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaml.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiafbc.so to /var/lib/apptainer/mnt/session/libs/libnvidiafbc.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiafbc.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiafbc.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiafbc.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiafbc.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvcuvid.so to /var/lib/apptainer/mnt/session/libs/libnvcuvid.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvcuvid.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaopticalflow.so.1 to /var/lib/apptainer/mnt/session/libs/libnvidiaopticalflow.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaopticalflow.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLX.so to /var/lib/apptainer/mnt/session/libs/libGLX.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLX.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLESv1_CM.so to /var/lib/apptainer/mnt/session/libs/libGLESv1_CM.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLESv1_CM.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiacfg.so to /var/lib/apptainer/mnt/session/libs/libnvidiacfg.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiacfg.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libcuda.so to /var/lib/apptainer/mnt/session/libs/libcuda.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libcuda.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libvdpau_nvidia.so to /var/lib/apptainer/mnt/session/libs/libvdpau_nvidia.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libvdpau_nvidia.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiartcore.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiartcore.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiartcore.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libcuda.so.1 to /var/lib/apptainer/mnt/session/libs/libcuda.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libcuda.so.1 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libOpenGL.so to /var/lib/apptainer/mnt/session/libs/libOpenGL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libOpenGL.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libEGL_nvidia.so.0 to /var/lib/apptainer/mnt/session/libs/libEGL_nvidia.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libEGL_nvidia.so.0 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libnvidiaglcore.so.550.120 to /var/lib/apptainer/mnt/session/libs/libnvidiaglcore.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libnvidiaglcore.so.550.120 DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /lib64/libGLdispatch.so to /var/lib/apptainer/mnt/session/libs/libGLdispatch.so DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/libs/libGLdispatch.so DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /var/lib/apptainer/mnt/session/libs to /var/lib/apptainer/mnt/session/final/.singularity.d/libs DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/.singularity.d/libs DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /bin/nvidiapersistenced to /var/lib/apptainer/mnt/session/final/usr/bin/nvidiapersistenced DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/usr/bin/nvidiapersistenced DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /bin/nvidiacudampscontrol to /var/lib/apptainer/mnt/session/final/usr/bin/nvidiacudampscontrol DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/usr/bin/nvidiacudampscontrol DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /bin/nvidiacudampsserver to /var/lib/apptainer/mnt/session/final/usr/bin/nvidiacudampsserver DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/usr/bin/nvidiacudampsserver DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /bin/nvidiasmi to /var/lib/apptainer/mnt/session/final/usr/bin/nvidiasmi DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/usr/bin/nvidiasmi DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /bin/nvidiadebugdump to /var/lib/apptainer/mnt/session/final/usr/bin/nvidiadebugdump DEBUG   [U=0,P=1355208]    mountGeneric()                Remounting /var/lib/apptainer/mnt/session/final/usr/bin/nvidiadebugdump DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /var/lib/apptainer/mnt/session/etc/resolv.conf to /var/lib/apptainer/mnt/session/final/etc/resolv.conf DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /var/lib/apptainer/mnt/session/etc/passwd to /var/lib/apptainer/mnt/session/final/etc/passwd DEBUG   [U=0,P=1355208]    mountGeneric()                Mounting /var/lib/apptainer/mnt/session/etc/group to /var/lib/apptainer/mnt/session/final/etc/group VERBOSE [U=0,P=1355208]    addCwdMount()                 /root found within container DEBUG   [U=0,P=1355208]    create()                      Chroot into /var/lib/apptainer/mnt/session/final DEBUG   [U=0,P=1355231]    Chroot()                      Hold reference to host / directory DEBUG   [U=0,P=1355231]    Chroot()                      Called pivot_root on /var/lib/apptainer/mnt/session/final DEBUG   [U=0,P=1355231]    Chroot()                      Change current directory to host / directory DEBUG   [U=0,P=1355231]    Chroot()                      Apply slave mount propagation for host / directory DEBUG   [U=0,P=1355231]    Chroot()                      Called unmount(/, syscall.MNT_DETACH) DEBUG   [U=0,P=1355231]    Chroot()                      Changing directory to / to avoid getpwd issues DEBUG   [U=0,P=1355208]    create()                      Chdir into / to avoid errors VERBOSE [U=0,P=1355230]    wait_child()                  rpc server exited with status 0 DEBUG   [U=0,P=1355230]    init()                        Set container privileges DEBUG   [U=0,P=1355230]    apply_privileges()            Effective capabilities:   0x000001ffffffffff DEBUG   [U=0,P=1355230]    apply_privileges()            Permitted capabilities:   0x000001ffffffffff DEBUG   [U=0,P=1355230]    apply_privileges()            Bounding capabilities:    0x000001ffffffffff DEBUG   [U=0,P=1355230]    apply_privileges()            Inheritable capabilities: 0x000001ffffffffff DEBUG   [U=0,P=1355230]    apply_privileges()            Ambient capabilities:     0x000001ffffffffff DEBUG   [U=0,P=1355230]    apply_privileges()            Set user ID to 0 DEBUG   [U=0,P=1355230]    set_parent_death_signal()     Set parent death signal to 9 DEBUG   [U=0,P=1355230]    func1()                       executablePath is /usr/libexec/apptainer/bin/starter DEBUG   [U=0,P=1355230]    func1()                       executablePath does not exist, assuming default prefix DEBUG   [U=0,P=1355230]    startup()                     apptainer runtime engine selected VERBOSE [U=0,P=1355230]    startup()                     Execute stage 2 DEBUG   [U=0,P=1355230]    StageTwo()                    Entering stage 2 DEBUG   [U=0,P=1355230]    StartProcess()                Setting umask in container to 0002 DEBUG   [U=0,P=1355230]    func4()                       Not exporting ""BASH_FUNC__module_raw%%"" to container environment: invalid key DEBUG   [U=0,P=1355230]    func4()                       Not exporting ""BASH_FUNC_ml%%"" to container environment: invalid key DEBUG   [U=0,P=1355230]    func4()                       Not exporting ""BASH_FUNC_module%%"" to container environment: invalid key DEBUG   [U=0,P=1355230]    func4()                       Not exporting ""BASH_FUNC_scl%%"" to container environment: invalid key DEBUG   [U=0,P=1355230]    func4()                       Not exporting ""BASH_FUNC_which%%"" to container environment: invalid key DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/01base.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/10docker2singularity.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/90environment.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/94appsbase.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/95apps.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/99base.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Sourcing /.singularity.d/env/99runtimevars.sh DEBUG   [U=0,P=1355230]    sylogBuiltin()                Running action command exec DEBUG   [U=0,P=1355208]    PostStartProcess()            Post start process Python 3.11.0rc1 (main, Aug 12 2022, 10:02:14) [GCC 11.2.0] on linux Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. ```",2025-01-24T20:16:31Z,stat:awaiting tensorflower type:build/install comp:gpu TF 2.18,open,0,3,https://github.com/tensorflow/tensorflow/issues/85689,The docker  TF container tries to load libcudnn.so.9 However the container has only been built with libcudnn.so.8 More detail here: tensorflow 2.18 requires libcudnn.so.9,"> The docker TF container tries to load libcudnn.so.9 However the container has only been built with libcudnn.so.8 >  > More detail here: tensorflow 2.18 requires libcudnn.so.9 Thanks, how do we get the maintained to flx if?",", I request you to take a look at this issue where a similar feature has been proposed and it is still open. Also I request to follow the similar feature which has been proposed to have the updates on the similar issue. Thank you!"
transformer,Chuan1937,tensorflow takes a long time to prepare before the first iteration," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version TF 2.10.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.4/8.9.1  GPU model and memory Nvidia Tesla K20m  Current behavior? tensorflow takes a long time to prepare before the first iteration.I used my custom model for training, but it took 4060 minutes from the time the data was ready to the first iteration. This was true even for a very small dataset. And my model only had 835,620 parameters. This model is used to pick up the phase of seismic data. If an experiment is conducted, the data can be fabricated by itself.  Standalone code to reproduce the issue ```shell import numpy as np import matplotlib matplotlib.use('agg') import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'   Suppress TensorFlow logs from tensorflow.python import keras from tensorflow.keras import backend as K from tensorflow.keras.layers import (     Add, Activation, LSTM, Conv1D, MaxPooling1D, UpSampling1D,     Cropping1D, SpatialDropout1D, Bidirectional, BatchNormalization,add,InputSpec, LayerNormalization,Layer, Dense, Dropout,Layer ) from tensorflow.keras.optimizers import Adam from tensorflow import keras import tensorflow as tf from tensorflow.keras import initializers, regularizers, constraints, activations def f1(y_true, y_pred):     def recall(y_true, y_pred):         '''Recall metric. Computes the recall, a metric for multilabel classification.'''         true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))         possible_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true, 0, 1)))         recall = true_positives / (possible_positives + tf.keras.backend.epsilon())         return recall     def precision(y_true, y_pred):         '''Precision metric. Computes the precision, a metric for multilabel classification.'''         true_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_true * y_pred, 0, 1)))         predicted_positives = tf.reduce_sum(tf.round(tf.clip_by_value(y_pred, 0, 1)))         precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())         return precision     precision_val = precision(y_true, y_pred)     recall_val = recall(y_true, y_pred)      F1 score calculation     return 2 * (precision_val * recall_val) / (precision_val + recall_val + tf.keras.backend.epsilon()) class LayerNormalization(keras.layers.Layer):     def __init__(self,                  center=True,                  scale=True,                  epsilon=None,                  gamma_initializer='ones',                  beta_initializer='zeros',                  **kwargs):         super(LayerNormalization, self).__init__(**kwargs)         self.supports_masking = True         self.center = center         self.scale = scale         if epsilon is None:             epsilon = K.epsilon() * K.epsilon()         self.epsilon = epsilon         self.gamma_initializer = keras.initializers.get(gamma_initializer)         self.beta_initializer = keras.initializers.get(beta_initializer)     def get_config(self):         config = {             'center': self.center,             'scale': self.scale,             'epsilon': self.epsilon,             'gamma_initializer': keras.initializers.serialize(self.gamma_initializer),             'beta_initializer': keras.initializers.serialize(self.beta_initializer),         }         base_config = super(LayerNormalization, self).get_config()         return dict(list(base_config.items()) + list(config.items()))     def compute_output_shape(self, input_shape):         return input_shape     def compute_mask(self, inputs, input_mask=None):         return input_mask     def build(self, input_shape):         self.input_spec = InputSpec(shape=input_shape)         shape = input_shape[1:]         if self.scale:             self.gamma = self.add_weight(                 shape=shape,                 initializer=self.gamma_initializer,                 name='gamma',             )         if self.center:             self.beta = self.add_weight(                 shape=shape,                 initializer=self.beta_initializer,                 name='beta',             )         super(LayerNormalization, self).build(input_shape)     def call(self, inputs, training=None):         mean = K.mean(inputs, axis=1, keepdims=True)         variance = K.mean(K.square(inputs  mean), axis=1, keepdims=True)         std = K.sqrt(variance + self.epsilon)         outputs = (inputs  mean) / std         if self.scale:             outputs *= self.gamma         if self.center:             outputs += self.beta         return outputs class FeedForward(keras.layers.Layer):     def __init__(self,                  units,                  activation='relu',                  use_bias=True,                  kernel_initializer='glorot_normal',                  bias_initializer='zeros',                  dropout_rate=0.0,                  **kwargs):         self.supports_masking = True         self.units = units         self.activation = keras.activations.get(activation)         self.use_bias = use_bias         self.kernel_initializer = keras.initializers.get(kernel_initializer)         self.bias_initializer = keras.initializers.get(bias_initializer)         self.dropout_rate = dropout_rate         self.W1, self.b1 = None, None         self.W2, self.b2 = None, None         super(FeedForward, self).__init__(**kwargs)     def get_config(self):         config = {             'units': self.units,             'activation': keras.activations.serialize(self.activation),             'use_bias': self.use_bias,             'kernel_initializer': keras.initializers.serialize(self.kernel_initializer),             'bias_initializer': keras.initializers.serialize(self.bias_initializer),             'dropout_rate': self.dropout_rate,         }         base_config = super(FeedForward, self).get_config()         return dict(list(base_config.items()) + list(config.items()))     def compute_output_shape(self, input_shape):         return input_shape     def compute_mask(self, inputs, input_mask=None):         return input_mask     def build(self, input_shape):         feature_dim = int(input_shape[1])         self.W1 = self.add_weight(             shape=(feature_dim, self.units),             initializer=self.kernel_initializer,             name='{}_W1'.format(self.name),         )         if self.use_bias:             self.b1 = self.add_weight(                 shape=(self.units,),                 initializer=self.bias_initializer,                 name='{}_b1'.format(self.name),             )         self.W2 = self.add_weight(             shape=(self.units, feature_dim),             initializer=self.kernel_initializer,             name='{}_W2'.format(self.name),         )         if self.use_bias:             self.b2 = self.add_weight(                 shape=(feature_dim,),                 initializer=self.bias_initializer,                 name='{}_b2'.format(self.name),             )         super(FeedForward, self).build(input_shape)     def call(self, x, mask=None, training=None):         h = K.dot(x, self.W1)         if self.use_bias:             h = K.bias_add(h, self.b1)         if self.activation is not None:             h = self.activation(h)         if 0.0  0.0:             self.add_loss(self._attention_regularizer(a))         if self.return_attention:             return [v, a]         return v     def _call_additive_emission(self, inputs):         input_shape = K.shape(inputs)         batch_size = input_shape[0]         input_len = inputs.get_shape().as_list()[1]          h_{t, t'} = \tanh(x_t^T W_t + x_{t'}^T W_x + b_h)         q = K.expand_dims(K.dot(inputs, self.Wt), 2)         k = K.expand_dims(K.dot(inputs, self.Wx), 1)         if self.use_additive_bias:             h = K.tanh(q + k + self.bh)         else:             h = K.tanh(q + k)          e_{t, t'} = W_a h_{t, t'} + b_a         if self.use_attention_bias:             e = K.reshape(K.dot(h, self.Wa) + self.ba, (batch_size, input_len, input_len))         else:             e = K.reshape(K.dot(h, self.Wa), (batch_size, input_len, input_len))         return e     def _call_multiplicative_emission(self, inputs):          e_{t, t'} = x_t^T W_a x_{t'} + b_a         e = K.batch_dot(K.dot(inputs, self.Wa), K.permute_dimensions(inputs, (0, 2, 1)))         if self.use_attention_bias:             e += self.ba[0]         return e     def compute_output_shape(self, input_shape):         output_shape = input_shape         if self.return_attention:             attention_shape = (input_shape[0], output_shape[1], input_shape[1])             return [output_shape, attention_shape]         return output_shape     def compute_mask(self, inputs, mask=None):         if self.return_attention:             return [mask, None]         return mask     def _attention_regularizer(self, attention):         batch_size = K.cast(K.shape(attention)[0], K.floatx())         input_len = K.shape(attention)[1]         indices = K.expand_dims(K.arange(0, input_len), axis=0)         diagonal = K.expand_dims(K.arange(0, input_len), axis=1)         eye = K.cast(K.equal(indices, diagonal), K.floatx())         return self.attention_regularizer_weight * K.sum(K.square(K.batch_dot(             attention,             K.permute_dimensions(attention, (0, 2, 1)))  eye)) / batch_size          def get_custom_objects():         return {'SeqSelfAttention': SeqSelfAttention} def _block_BiLSTM(filters, drop_rate, padding, inpR):     'Returns LSTM residual block'         prev = inpR      x_rnn = Bidirectional(LSTM(filters, return_sequences=True, dropout=drop_rate, recurrent_dropout=drop_rate))(prev)     符合使用cudnn核心的LSTM     x_rnn = Bidirectional(LSTM(filters, return_sequences=True, dropout=drop_rate, recurrent_dropout=0, activation='tanh', recurrent_activation='sigmoid', use_bias=True, unroll=False))(prev)     NiN = Conv1D(filters, 1, padding = padding)(x_rnn)          res_out = BatchNormalization()(NiN)     return res_out def _block_CNN_1(filters, ker, drop_rate, activation, padding, inpC):      ' Returns CNN residual blocks '     prev = inpC     layer_1 = BatchNormalization()(prev)      act_1 = Activation(activation)(layer_1)      act_1 = SpatialDropout1D(drop_rate)(act_1, training=True)     conv_1 = Conv1D(filters, ker, padding = padding)(act_1)      layer_2 = BatchNormalization()(conv_1)      act_2 = Activation(activation)(layer_2)      act_2 = SpatialDropout1D(drop_rate)(act_2, training=True)     conv_2 = Conv1D(filters, ker, padding = padding)(act_2)     res_out = add([prev, conv_2])     return res_out  def _transformer(drop_rate, width, name, inpC):      ' Returns a transformer block containing one addetive attention and one feed  forward layer with residual connections '     x = inpC     att_layer, weight = SeqSelfAttention(return_attention =True,                                                                                 attention_width = width,                                          name=name)(x)   att_layer = Dropout(drop_rate)(att_layer, training=True)         att_layer2 = add([x, att_layer])         norm_layer = LayerNormalization()(att_layer2)     FF = FeedForward(units=128, dropout_rate=drop_rate)(norm_layer)     FF_add = add([norm_layer, FF])         norm_out = LayerNormalization()(FF_add)     return norm_out, weight  def _encoder(filter_number, filter_size, depth, drop_rate, ker_regul, bias_regul, activation, padding, inpC):     ' Returns the encoder that is a combination of residual blocks and maxpooling.'             e = inpC     for dp in range(depth):         e = Conv1D(filter_number[dp],                     filter_size[dp],                     padding = padding,                     activation = activation,                    kernel_regularizer = ker_regul,                    bias_regularizer = bias_regul,                    )(e)                      e = MaxPooling1D(2, padding = padding)(e)                 return(e)  def _decoder(filter_number, filter_size, depth, drop_rate, ker_regul, bias_regul, activation, padding, inpC):     ' Returns the dencoder that is a combination of residual blocks and upsampling. '                d = inpC     for dp in range(depth):                 d = UpSampling1D(2)(d)          if dp == 2:             d = Cropping1D(cropping=(1, 1))(d)                    d = Conv1D(filter_number[dp],                     filter_size[dp],                     padding = padding,                     activation = activation,                    kernel_regularizer = ker_regul,                    bias_regularizer = bias_regul,                    )(d)             return(d)   def _lr_schedule(epoch):     ' Learning rate is scheduled to be reduced after 40, 60, 80, 90 epochs.'     lr = 1e3     if epoch > 90:         lr *= 0.5e3     elif epoch > 60:         lr *= 1e3     elif epoch > 40:         lr *= 1e2     elif epoch > 20:         lr *= 1e1     print('Learning rate: ', lr)     return lr class cred2():     def __init__(self,                  nb_filters=[8, 16, 16, 32, 32, 96, 96, 128],                  kernel_size=[11, 9, 7, 7, 5, 5, 3, 3],                  padding='same',                  activationf='relu',                  endcoder_depth=7,                  decoder_depth=7,                  cnn_blocks=5,                  BiLSTM_blocks=3,                  drop_rate=0.1,                  loss_weights=[0.2, 0.3, 0.5],                  loss_types=['binary_crossentropy', 'binary_crossentropy', 'binary_crossentropy'],                                                   kernel_regularizer=keras.regularizers.l1(1e4),                  bias_regularizer=keras.regularizers.l1(1e4),                  ):         self.kernel_size = kernel_size         self.nb_filters = nb_filters         self.padding = padding         self.activationf = activationf         self.endcoder_depth= endcoder_depth         self.decoder_depth= decoder_depth         self.cnn_blocks= cnn_blocks         self.BiLSTM_blocks= BiLSTM_blocks              self.drop_rate= drop_rate         self.loss_weights= loss_weights           self.loss_types = loss_types                self.kernel_regularizer = kernel_regularizer              self.bias_regularizer = bias_regularizer      def __call__(self, inp):         x = inp         x = _encoder(self.nb_filters,                      self.kernel_size,                      self.endcoder_depth,                      self.drop_rate,                      self.kernel_regularizer,                      self.bias_regularizer,                     self.activationf,                      self.padding,                     x)             for cb in range(self.cnn_blocks):             x = _block_CNN_1(self.nb_filters[6], 3, self.drop_rate, self.activationf, self.padding, x)             if cb > 2:                 x = _block_CNN_1(self.nb_filters[6], 2, self.drop_rate, self.activationf, self.padding, x)         for bb in range(self.BiLSTM_blocks):             x = _block_BiLSTM(self.nb_filters[1], self.drop_rate, self.padding, x)         x, weightdD0 = _transformer(self.drop_rate, None, 'attentionD0', x)                      encoded, weightdD = _transformer(self.drop_rate, None, 'attentionD', x)                      decoder_D = _decoder([i for i in reversed(self.nb_filters)],                               [i for i in reversed(self.kernel_size)],                               self.decoder_depth,                               self.drop_rate,                               self.kernel_regularizer,                               self.bias_regularizer,                              self.activationf,                               self.padding,                                                           encoded)         d = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='detector')(decoder_D)         '''         The requirements to use the cuDNN implementation are:         activation == tanh         recurrent_activation == sigmoid         recurrent_dropout == 0         unroll is False         use_bias is True         Inputs, if use masking, are strictly rightpadded.         Eager execution is enabled in the outermost context.         '''          PLSTM = LSTM(self.nb_filters[1], return_sequences=True, dropout=self.drop_rate, recurrent_dropout=self.drop_rate)(encoded)          假设 self.nb_filters 和 self.drop_rate 已经定义         PLSTM = LSTM(self.nb_filters[1],                      return_sequences=True,                      dropout=self.drop_rate,                      recurrent_dropout=0,                      activation='tanh',                      recurrent_activation='sigmoid',                      use_bias=True,                      unroll=False)(encoded)         norm_layerP, weightdP = SeqSelfAttention(return_attention=True,                                                  attention_width= 3,                                                  name='attentionP')(PLSTM)         decoder_P = _decoder([i for i in reversed(self.nb_filters)],                              [i for i in reversed(self.kernel_size)],                              self.decoder_depth,                              self.drop_rate,                              self.kernel_regularizer,                              self.bias_regularizer,                             self.activationf,                              self.padding,                                                         norm_layerP)         P = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='picker_P')(decoder_P)          SLSTM = LSTM(self.nb_filters[1], return_sequences=True, dropout=self.drop_rate, recurrent_dropout=self.drop_rate)(encoded)          SLSTM = LSTM(self.nb_filters[1],               return_sequences=True,               dropout=self.drop_rate,               recurrent_dropout=0,               activation='tanh',               recurrent_activation='sigmoid',               use_bias=True,               unroll=False)(encoded)         norm_layerS, weightdS = SeqSelfAttention(return_attention=True,                                                  attention_width= 3,                                                  name='attentionS')(SLSTM)         decoder_S = _decoder([i for i in reversed(self.nb_filters)],                              [i for i in reversed(self.kernel_size)],                             self.decoder_depth,                              self.drop_rate,                              self.kernel_regularizer,                              self.bias_regularizer,                             self.activationf,                              self.padding,                                                         norm_layerS)          S = Conv1D(1, 11, padding = self.padding, activation='sigmoid', name='picker_S')(decoder_S)         model = keras.models.Model(inputs=inp, outputs=[d, P, S])         model.compile(loss=self.loss_types, loss_weights=self.loss_weights,                 optimizer=Adam(lr=_lr_schedule(0)), metrics=[f1])         return model  input=keras.layers.Input(shape=(12000,3))  model=cred2()(input)  model.summary() ```  Relevant log output ```shell ```",2025-01-24T13:47:24Z,stat:awaiting response stale type:performance TF 2.10,closed,4,7,https://github.com/tensorflow/tensorflow/issues/85667,This is likely the time spent JITing the Python imperative code to the graph representation that TF uses.,"How can I speed it up? Otherwise, I have to wait for nearly 60 minutes every time.","I think that that's too much. You could try writing TF code in graph mode directly (or switching to JAX for even more performance gains  since you use Keras, use Keras 3 and switch to Jax backend).","It is normal for the first epoch to take longer to train than subsequent epochs, as TensorFlow needs to compile the model and allocate resources. However, an hour does seem like a long time.  **Here are a few things that could be causing the slow training time:** * Larger models with more parameters will take longer to train. * Training on a larger dataset will take longer. * The speed of your CPU, GPU, and available RAM will all affect training speed. * If you are using custom code in your training loop, it could be slowing things down. **Here are some tips to improve training speed:** * If you are just starting out, try using a smaller model with fewer parameters. * If you have a large dataset, try using a smaller subset for training. * If you have a GPU, you can use it to accelerate training. * Use a profiler to identify bottlenecks in your training code. * A smaller batch size can sometimes improve training speed.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
llm,intelav,LiteRT build for Android failing," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.17.0  Custom code No  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version bazel 6.5.0  GCC/compiler version NDK26,NDK28  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following this link https://ai.google.dev/edge/litert/build/android for building libtensorflowlite.so for my android JNI project, but its failing all  the time with below error snapshot **Initial Steps** git clone https://github.com/tensorflow/tensorflow.git cd tensorflow git checkout v2.17.0 ./configure ( For Android Environment) **Below is the content of .tf_configure.bazelrc in my build environment** build action_env PYTHON_BIN_PATH=""/usr/bin/python3"" build action_env PYTHON_LIB_PATH=""/usr/lib/python3.10/distpackages"" build python_path=""/usr/bin/python3"" build action_env CLANG_COMPILER_PATH=""/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linuxx86_64/bin/clang17"" build repo_env=CC=/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linuxx86_64/bin/clang17 build repo_env=BAZEL_COMPILER=/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linuxx86_64/bin/clang17 build copt=Wnognuoffsetofextensions build:opt copt=Wnosigncompare build:opt host_copt=Wnosigncompare build action_env ANDROID_NDK_HOME=""/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/"" build action_env ANDROID_NDK_VERSION=""26"" build action_env ANDROID_NDK_API_LEVEL=""21"" build action_env ANDROID_BUILD_TOOLS_VERSION=""35.0.0"" build action_env ANDROID_SDK_API_LEVEL=""35"" build action_env ANDROID_SDK_HOME=""/media/avaish/aiwork/Androidsdk/"" test test_size_filters=small,medium test:v1 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial test:v1 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu test:v2 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial,v1only test:v2 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,v1only **Expected Output**  libtensorflowlite.so should get built successfully.   Standalone code to reproduce the issue ```shell **Build Command** avaishdekstop:/media/avaish/linuxgames/litebuild/tensorflow$ bazel build c opt cxxopt=std=c++17 config=android_arm64   fat_apk_cpu=x86,x86_64,arm64v8a,armeabiv7a   define=android_dexmerger_tool=d8_dexmerger   define=android_incremental_dexing_tool=d8_dexbuilder   //tensorflow/lite/java:tensorflowlite ```  Relevant log output ```shell INFO: Reading 'startup' options from /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc: windows_enable_symlinks INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=153 INFO: Reading rc options for 'build' from /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive features=force_no_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility INFO: Reading rc options for 'build' from /media/avaish/linuxgames/litebuild/tensorflow/.tf_configure.bazelrc:   'build' options: action_env PYTHON_BIN_PATH=/usr/bin/python3 action_env PYTHON_LIB_PATH=/usr/lib/python3.10/distpackages python_path=/usr/bin/python3 action_env CLANG_COMPILER_PATH=/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linuxx86_64/bin/clang17 repo_env=CC=/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linuxx86_64/bin/clang17 repo_env=BAZEL_COMPILER=/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/toolchains/llvm/prebuilt/linuxx86_64/bin/clang17 copt=Wnognuoffsetofextensions action_env ANDROID_NDK_HOME=/media/avaish/aiwork/Androidsdk/ndk/26.1.10909125/ action_env ANDROID_NDK_VERSION=26 action_env ANDROID_NDK_API_LEVEL=21 action_env ANDROID_BUILD_TOOLS_VERSION=35.0.0 action_env ANDROID_SDK_API_LEVEL=35 action_env ANDROID_SDK_HOME=/media/avaish/aiwork/Androidsdk/ INFO: Found applicable config definition build:short_logs in file /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:android_arm64 in file /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc: config=android cpu=arm64v8a fat_apk_cpu=arm64v8a INFO: Found applicable config definition build:android in file /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc: crosstool_top=//external:android/crosstool host_crosstool_top=//tools/cpp:toolchain dynamic_mode=off define=xnn_enable_avxvnniint8=false noenable_platform_specific_config copt=w cxxopt=std=c++17 host_cxxopt=std=c++17 define=with_xla_support=false config=no_tfrt INFO: Found applicable config definition build:no_tfrt in file /media/avaish/linuxgames/litebuild/tensorflow/.bazelrc: deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/ir,tensorflow/compiler/mlir/tfrt/ir/mlrt,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ifrt,tensorflow/compiler/mlir/tfrt/tests/mlrt,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/compiler/mlir/tfrt/transforms/mlrt,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/runtime_fallback/test,tensorflow/core/runtime_fallback/test/gpu,tensorflow/core/runtime_fallback/test/saved_model,tensorflow/core/runtime_fallback/test/testdata,tensorflow/core/tfrt/stubs,tensorflow/core/tfrt/tfrt_session,tensorflow/core/tfrt/mlrt,tensorflow/core/tfrt/mlrt/attribute,tensorflow/core/tfrt/mlrt/kernel,tensorflow/core/tfrt/mlrt/bytecode,tensorflow/core/tfrt/mlrt/interpreter,tensorflow/compiler/mlir/tfrt/translate/mlrt,tensorflow/compiler/mlir/tfrt/translate/mlrt/testdata,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils,tensorflow/core/tfrt/utils/debug,tensorflow/core/tfrt/saved_model/python,tensorflow/core/tfrt/graph_executor/python,tensorflow/core/tfrt/saved_model/utils INFO: Analyzed target //tensorflow/lite/java:tensorflowlite (2 packages loaded, 8416 targets configured). INFO: Found 1 target... ERROR: /media/avaish/linuxgames/litebuild/tensorflow/tensorflow/lite/c/jni/BUILD:12:43: Compiling tensorflow/lite/c/jni/jni_utils.: undeclared inclusion(s) in rule '//tensorflow/lite/c/jni:jni_utils': this rule is missing dependency declarations for the following files included by 'tensorflow/lite/c/jni/jni_utils.cc':   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stdarg.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stdint.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stddef.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/__stddef_max_align_t.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stdbool.h' Target //tensorflow/lite/java:tensorflowlite failed to build Use verbose_failures to see the command lines of failed build steps. ```",2025-01-24T05:07:38Z,stat:awaiting response type:build/install stale comp:lite 2.17,closed,0,5,https://github.com/tensorflow/tensorflow/issues/85631,"If I run the same build command again , similiar errors apperas from compiling other files ERROR: /home/avaish/.cache/bazel/_bazel_avaish/d98cf14fd195122b7f9fe191efe765ef/external/ruy/ruy/BUILD:423:11: Compiling ruy/denormal.: undeclared inclusion(s) in rule '//ruy:denormal': this rule is missing dependency declarations for the following files included by 'ruy/denormal.cc':   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stdint.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stddef.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/__stddef_max_align_t.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/xmmintrin.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/mmintrin.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/mm_malloc.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/stdarg.h'   'external/androidndk/toolchains/llvm/prebuilt/linuxx86_64/lib/clang/17/include/emmintrin.h' Target //tensorflow/lite/java:tensorflowlite failed to build Use verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 0.903s, Critical Path: 0.12s INFO: 12 processes: 12 internal. FAILED: Build did NOT complete successfully","Hi,  I apologize for the delay in my response, I was trying to replicate the same behavior from my end but I'm getting different error and Build did NOT complete successfully so I have added error log below for reference please let me know if Am I missing something here to replicate same behavior which you reported here ? ``` (base) gaikwadrahuln1standard1gput4x1tfliteubuntu22:~/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow$ bazel build c opt cxxopt=std=c++17 config=android_arm64   fat_apk_cpu=x86,x86_64,arm64v8a,armeabiv7a   define=android_dexmerger_tool=d8_dexmerger   define=android_incremental_dexing_tool=d8_dexbuilder   //tensorflow/lite/java:tensorflowlite Extracting Bazel installation... Starting local Bazel server and connecting to it... INFO: Reading 'startup' options from /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc: windows_enable_symlinks INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=190 INFO: Reading rc options for 'build' from /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive features=force_no_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility INFO: Reading rc options for 'build' from /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.tf_configure.bazelrc:   'build' options: action_env PYTHON_BIN_PATH=/home/gaikwadrahul/miniconda3/bin/python3 action_env PYTHON_LIB_PATH=/home/gaikwadrahul/miniconda3/lib/python3.12/sitepackages python_path=/home/gaikwadrahul/miniconda3/bin/python3 action_env CLANG_COMPILER_PATH=/usr/bin/clang17 repo_env=CC=/usr/bin/clang17 repo_env=BAZEL_COMPILER=/usr/bin/clang17 copt=Wnognuoffsetofextensions action_env ANDROID_NDK_HOME=/home/gaikwadrahul/androidndkr25b action_env ANDROID_NDK_VERSION=25 action_env ANDROID_NDK_API_LEVEL=21 action_env ANDROID_BUILD_TOOLS_VERSION=34.0.0 action_env ANDROID_SDK_API_LEVEL=33 action_env ANDROID_SDK_HOME=/home/gaikwadrahul/Android/Sdk INFO: Found applicable config definition build:short_logs in file /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:android_arm64 in file /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc: config=android cpu=arm64v8a fat_apk_cpu=arm64v8a INFO: Found applicable config definition build:android in file /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc: crosstool_top=//external:android/crosstool host_crosstool_top=//tools/cpp:toolchain dynamic_mode=off noenable_platform_specific_config copt=w cxxopt=std=c++17 host_cxxopt=std=c++17 define=with_xla_support=false config=no_tfrt INFO: Found applicable config definition build:no_tfrt in file /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/.bazelrc: deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/ir,tensorflow/compiler/mlir/tfrt/ir/mlrt,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ifrt,tensorflow/compiler/mlir/tfrt/tests/mlrt,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/compiler/mlir/tfrt/transforms/mlrt,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/runtime_fallback/test,tensorflow/core/runtime_fallback/test/gpu,tensorflow/core/runtime_fallback/test/saved_model,tensorflow/core/runtime_fallback/test/testdata,tensorflow/core/tfrt/stubs,tensorflow/core/tfrt/tfrt_session,tensorflow/core/tfrt/mlrt,tensorflow/core/tfrt/mlrt/attribute,tensorflow/core/tfrt/mlrt/kernel,tensorflow/core/tfrt/mlrt/bytecode,tensorflow/core/tfrt/mlrt/interpreter,tensorflow/compiler/mlir/tfrt/translate/mlrt,tensorflow/compiler/mlir/tfrt/translate/mlrt/testdata,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils,tensorflow/core/tfrt/utils/debug,tensorflow/core/tfrt/saved_model/python,tensorflow/core/tfrt/graph_executor/python,tensorflow/core/tfrt/saved_model/utils DEBUG: /home/gaikwadrahul/TFLiteIssue CC(LiteRT build for Android failing)/tensorflow/tensorflow/tools/toolchains/python/python_repo.bzl:32:14:  TF_PYTHON_VERSION environment variable was not set correctly; using Python 3.11. To set Python version, run: export TF_PYTHON_VERSION=3.11 INFO: Analyzed target //tensorflow/lite/java:tensorflowlite (146 packages loaded, 15447 targets configured). INFO: Found 1 target... ERROR: /home/gaikwadrahul/.cache/bazel/_bazel_gaikwadrahul/17e9d465a5125118a485d68d85fbf68a/external/flatbuffers/src/BUILD.bazel:19:11: Compiling src/code_generators.cpp [for tool] failed: (Exit 1): clang17 failed: error executing command (from target //src:code_generators) /usr/bin/clang17 U_FORTIFY_SOURCE fstackprotector Wall Wthreadsafety Wselfassign Wunusedbutsetparameter Wnofreenonheapobject fcolordiagnostics fnoomitframepointer g0 O2 ... (remaining 27 arguments skipped) In file included from external/flatbuffers/src/code_generators.cpp:17: bazelout/k8optexec50AE0418/bin/external/flatbuffers/src/_virtual_includes/code_generators/flatbuffers/code_generators.h:20:10: fatal error: 'map' file not found    20           ^~~~~ 1 error generated. Target //tensorflow/lite/java:tensorflowlite failed to build Use verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 126.844s, Critical Path: 12.54s INFO: 84 processes: 61 internal, 23 local. FAILED: Build did NOT complete successfully ``` Thank you for your cooperation and patience.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
llm,copybara-service[bot],"Make the TF shape inference update the XlaCallModule's StableHLO module when the shapes are refined, if enabled by `enable_stablehlo_propagation`. It is disabled by default for now.","Make the TF shape inference update the XlaCallModule's StableHLO module when the shapes are refined, if enabled by `enable_stablehlo_propagation`. It is disabled by default for now.",2025-01-24T02:42:42Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85630
yi,ghinaaraf,Can not import tensorflow as tf," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.11.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense  Standalone code to reproduce the issue ```shell i always use python with VS Code, and yesterday my code finally success. but today when I run these code ""import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense"" . it always become error, even I had uninstall and install the tensorflow again, it not helped ```  Relevant log output ```shell ImportError                               Traceback (most recent call last) File c:\Users\Ghinaa\AppData\Local\Programs\Python\Python311\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[52], line 1 > 1 import tensorflow as tf       2 from tensorflow.keras.models import Sequential       3 from tensorflow.keras.layers import Dense File c:\Users\Ghinaa\AppData\Local\Programs\Python\Python311\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 ... Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. ```",2025-01-24T02:39:30Z,type:performance,closed,0,2,https://github.com/tensorflow/tensorflow/issues/85629,Please search for duplicates before opening a new issue,Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],#sdy add sharding rules for ragged_all_to_all custom call,sdy add sharding rules for ragged_all_to_all custom call,2025-01-23T23:56:35Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85623
yi,copybara-service[bot],Internal change only.,Internal change only.,2025-01-23T23:46:03Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85622
yi,copybara-service[bot],[ODML] Pass expand-tuple : Migrate from MHLO to StableHLO,[ODML] Pass expandtuple : Migrate from MHLO to StableHLO FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21825 from zhenyingliu:scheduler 1c5720711c6a7d8173e132922b67eee6e2e8b9dd,2025-01-23T22:38:06Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85606
rag,copybara-service[bot],[cpp23] Remove std::aligned_storage<> in tensorflow,[cpp23] Remove std::aligned_storage in tensorflow std::aligned_storage is deprecated in cpp23.,2025-01-23T17:21:04Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85586
yi,Redoxon33,Compatibility table for TensorFlow 2.18 with CUDA and cuDNN is missing on the official website,"In previous versions of TensorFlow, the official documentation included a clear compatibility table specifying which versions of TensorFlow worked with specific versions of CUDA and cuDNN. However, upon reviewing the documentation for TensorFlow 2.18, I noticed this information is no longer available. These tables were  helpful for users, as they prevented installation and compatibility issues when setting up the development environment. It would be great if this compatibility table could be brought back to the official documentation. If it was removed due to any updates or errors that have been identified, it would also be helpful to notify users of such changes. If you're reading this issue, I kindly ask that you notify users if any updates or changes regarding this topic are implemented.",2025-01-23T10:09:06Z,,closed,0,1,https://github.com/tensorflow/tensorflow/issues/85560,"After further investigation, I discovered that the issue is specific to the Spanish versions of the documentation (both Latin American and European Spanish), which appear to be outdated compared to the English version. The compatibility table is available in the English documentation, but it is not present in the Spanish translations. It would be helpful if an indicator could be added to show that the Spanish documentation is outdated or missing specific information, to prevent confusion for users relying on these versions."
rag,cj401-amd,[RFC] rocprof insights for rocprof data," RFC for rocprof insights  Introduction `rocprof`, `rocprofv2`, and `rocprofv3` (rocprofilersdk) are the profiling tools that can be used to collect AMD hardware performance data when running applications with ROCm/HIP. The collected timeline trace data, which are JSON format for `rocprof` and `rocprofv2` and `pftrace` format for `rocprofv3`, can be visualized via `https://ui.perfetto.dev/` to guide the loop of profiling, analysis and optimization. To gain deep insights into specific running kernels, API launch and memory copy, it is necessary to obtain more statistics about them. rocprof insights, which is developed as a Python package, aims to provide the following functionalities: 1. Data loading, including loading CSV and JSON files saved from `rocprof v1/v2/v3` 2. Data analysis, providing:     Total running time     Number of calls (instances)     Average time     Median time     Min/max time     StdDev time    For each:     Kernel     HIP/HSA API calls     H2D, D2H, D2D memcopy     Checking private/group segment size (scratch/local memory, register spillage, shared local memory) 3. Data visualization, providing:     Pie chart plot of latency (running time)     Histogram of latency     Bar plot for kernels, API calls, etc. Other features we would like to explore are: 1. Can we overlay the latency on top of the original operators in the computational graph (latency per op/node)? 2. Can we trace the input/output values of every node in the computational graph for checking accuracy (mismatch) per node?",2025-01-23T10:00:14Z,size:XL,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85559
llm,copybara-service[bot],"Move the sharding axes from dimensions that need replication to batch dimensions, such that we replace an `all-gather` with an `all-to-all`.","Move the sharding axes from dimensions that need replication to batch dimensions, such that we replace an `allgather` with an `alltoall`. Given the following input ``` ENTRY entry {   %param0 = f32[14,257] parameter(0), sharding={devices=[1,2]0,1}   %param1 = f32[14,116] parameter(1), sharding={devices=[1,2]0,1}   ROOT %concatenate = f32[14,373] concatenate(%param0, %param1),     dimensions={1}, sharding={devices=[1,2]0,1} } ``` The partitioner generates allgather before this change ``` ENTRY %entry_spmd (param: f32[14,129], param.1: f32[14,58]) > f32[14,187] {   %param = f32[14,129]{1,0} parameter(0), sharding={devices=[1,2] f32[14,187] {   %param = f32[14,129]{1,0} parameter(0), sharding={devices=[1,2]<=[2]}   %reshape.1 = f32[2,7,129]{2,1,0} reshape(f32[14,129]{1,0} %param)   %alltoall = f32[2,7,129]{2,1,0} alltoall(f32[2,7,129]{2,1,0} %reshape.1), channel_id=1, replica_groups={{0,1}}, dimensions={0}   %transpose = f32[7,2,129]{2,0,1} transpose(f32[2,7,129]{2,1,0} %alltoall), dimensions={1,0,2}   %reshape.2 = f32[7,258]{1,0} reshape(f32[7,2,129]{2,0,1} %transpose)   %slice = f32[7,257]{1,0} slice(f32[7,258]{1,0} %reshape.2), slice={[0:7], [0:257]}   %param.1 = f32[14,58]{1,0} parameter(1), sharding={devices=[1,2]<=[2]}   %reshape.5 = f32[2,7,58]{2,1,0} reshape(f32[14,58]{1,0} %param.1)   %alltoall.1 = f32[2,7,58]{2,1,0} alltoall(f32[2,7,58]{2,1,0} %reshape.5), channel_id=2, replica_groups={{0,1}}, dimensions={0}   %transpose.1 = f32[7,2,58]{2,0,1} transpose(f32[2,7,58]{2,1,0} %alltoall.1), dimensions={1,0,2}   %reshape.6 = f32[7,116]{1,0} reshape(f32[7,2,58]{2,0,1} %transpose.1)   %concatenate.1 = f32[7,373]{1,0} concatenate(f32[7,257]{1,0} %slice, f32[7,116]{1,0} %reshape.6), dimensions={1}   %constant.20 = f32[] constant(0)   %pad = f32[7,374]{1,0} pad(f32[7,373]{1,0} %concatenate.1, f32[] %constant.20), padding=0_0x0_1   %reshape.9 = f32[7,2,187]{2,1,0} reshape(f32[7,374]{1,0} %pad)   %alltoall.2 = f32[7,2,187]{2,1,0} alltoall(f32[7,2,187]{2,1,0} %reshape.9), channel_id=3, replica_groups={{0,1}}, dimensions={1}   %transpose.2 = f32[2,7,187]{2,0,1} transpose(f32[7,2,187]{2,1,0} %alltoall.2), dimensions={1,0,2}   ROOT %reshape.10 = f32[14,187]{1,0} reshape(f32[2,7,187]{2,0,1} %transpose.2) } ```",2025-01-22T23:48:03Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85519
transformer,weilhuan-quic,Integrate Op Builder with LiteRT Compile Part," WHAT We replace the compiler part with Qualcomm implementations. This PR include commits in 3 PRs below. Follow these PRs or commit should help you review. You can get more details in the PR descriptions. 1. https://github.com/jiunkaiy/tensorflow/pull/1 2. https://github.com/jiunkaiy/tensorflow/pull/3 3. https://github.com/jiunkaiy/tensorflow/pull/5  TEST You can checkout this branch and run this test: ``` bazel build  c opt cxxopt=std=c++20 //tensorflow/lite/experimental/litert/vendors/qualcomm/compiler:qnn_compiler_plugin_test ./bazelbin/tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compiler_plugin_test ``` I disable these models because I don't have them.  kFeedForwardModel,  kKeyEinsumModel,  kQueryEinsumModel,  kValueEinsumModel,  kAttnVecEinsumModel,  kROPEModel,  kLookUpROPEModel,  kRMSNormModel,  kSDPAModel,  kAttentionModel,  kTransformerBlockModel,  kQSimpleMul16x16Model,  kQMulAdd16x16Model,  kQQueryEinsum16x8Model,  kQKeyEinsum16x8Model,  kQVauleEinsum16x8Model,  kQAttnVecEinsum16x8Model And you will see ``` [] Global test environment teardown [==========] 55 tests from 3 test suites ran. (338 ms total) [  PASSED  ] 54 tests. [  FAILED  ] 1 test, listed below: [  FAILED  ] SupportedOpsTest/QnnPluginOpValidationTest.SupportedOpsTest/4, where GetParam() = ""simple_slice_op.tflite"" ``` There are some bugs in simple_slice_op.mlir so the op validation will fail.",2025-01-22T10:19:36Z,comp:lite size:XL,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85477
rag,copybara-service[bot],Update the external buffer storage to use an ID based approach,Update the external buffer storage to use an ID based approach,2025-01-22T07:40:38Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85448
yi,copybara-service[bot],[MHLO] Handle dynamic dimensions in HLO<->MHLO,"[MHLO] Handle dynamic dimensions in HLOMHLO  Fix creating constant zero for ConvertOp HLO>MHLO translation  Fix broadcast in dim bounded lowering from MHLO>HLO  Don't use StableHLO verification methods on MHLO ReshapeOp with bounded dynamic outputs ``` $ cat /tmp/t.hlo  HloModule main, entry_computation_layout={(pred[pred[ pred[>) > tensor> {   %0 = mhlo.constant dense : tensor   %1 = ""mhlo.get_dimension_size""(%arg0)  : (tensor>) > tensor   %2 = ""mhlo.set_dimension_size""(%0, %1)  : (tensor, tensor) > tensor>   %3 = mhlo.compare  NE, %arg0, %2 : (tensor>, tensor>) > tensor>   return %3 : tensor> } ``` Currently this fails when trying to create the `mhlo.constant dense` that gets fed into compare since constants cannot have a bounded size.",2025-01-22T03:54:44Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85441
rag,copybara-service[bot],[XLA] Add ragged-all-to-all support to latency hiding scheduler.,[XLA] Add raggedalltoall support to latency hiding scheduler.,2025-01-21T23:08:38Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85434
rag,copybara-service[bot],Add HLO `RaggedAllToAll` --> `mhlo.custom_call @ragged_all_to_all` translation,"Add HLO `RaggedAllToAll` > `mhlo.custom_call ` translation Since `channel_handle` is used by select few ops, it's recommended to not import this attribute generally. Instead, just extract `channel_id` (`channel_type` is not used in this op) and set it as an `IntegerAttr` for roundtripping.",2025-01-21T20:18:24Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85420
yi,primski,How do you install this using poetry on macos ?,"This still doesn't work  ``` [project] name = ""tf001"" version = ""0.1.0"" description = """" authors = [     {name = ""Me""} ] readme = ""README.md"" requirespython = "">=3.11"" [tool.poetry.dependencies] python = ""~3.11"" tensorflow = ""*"" [buildsystem] requires = [""poetrycore>=2.0.0,<3.0.0""] buildbackend = ""poetry.core.masonry.api"" ``` ```    Installing tensorflow (2.18.0): Failed   RuntimeError   Unable to find installation candidates for tensorflow (2.18.0)   at ~/Library/Application Support/pypoetry/venv/lib/python3.11/sitepackages/poetry/installation/chooser.py:86 in choose_for        82│         83│             links.append(link)        84│         85│         if not links:     →  86│             raise RuntimeError(f""Unable to find installation candidates for {package}"")        87│         88│          Get the best link        89│         chosen = max(links, key=lambda link: self._sort_key(package, link))        90│  Cannot install tensorflow. ``` ``` $ poetry version  Poetry (version 2.0.0) ``` So how do I install this ?",2025-01-21T20:05:28Z,stat:awaiting response type:support stale,closed,0,5,https://github.com/tensorflow/tensorflow/issues/85418,"I removed it from pyproject.toml and used pip, it works with that. ","TF is developed with pip in mind, no one has tested if it can be installed with other systems (although likely it should, to the extent that they are compatible)",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],[XLA:GPU] Remove simplify_int4_dots pass from gpu_compiler passes.,[XLA:GPU] Remove simplify_int4_dots pass from gpu_compiler passes. It is not in use anymore.,2025-01-20T14:40:54Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85354
agent,Chadster766,"Tutorial ""Multi-worker training with Keras"" fails to complete"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v1.12.1120353gc5bd67bc56f 2.19.0dev20250107  Custom code No  OS platform and distribution Debian 6.1.1231 (20250102) x86_64 GNU/Linux  Mobile device _No response_  Python version Python 3.12.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following the tutorial everything goes well until you start the second worker. Then the below failure occures. 20250120 07:19:35.283801: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250120 07:19:35.290192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1737379175.297785    4595 cuda_dnn.cc:8501] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1737379175.300054    4595 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250120 07:19:35.307721: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20250120 07:19:36.510476: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDAcapable device is detected 20250120 07:19:36.510494: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:167] env: CUDA_VISIBLE_DEVICES=""1"" 20250120 07:19:36.510499: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] CUDA_VISIBLE_DEVICES is set to 1  this hides all GPUs from CUDA 20250120 07:19:36.510501: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually v=1 or vmodule=cuda_diagnostics=1) to get more diagnostic output from this module 20250120 07:19:36.510505: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: michael 20250120 07:19:36.510507: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: michael 20250120 07:19:36.510562: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 565.77.0 20250120 07:19:36.510572: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 565.77.0 20250120 07:19:36.510574: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 565.77.0 20250120 07:19:36.519175: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:637] Initializing CoordinationService WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1737379176.519611    4595 grpc_server_lib.cc:465] Started server with target: grpc://localhost:12345 20250120 07:19:36.524874: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:378] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 4677280066871850635 20250120 07:19:36.524894: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:816] Waiting for 1/2 tasks to connect. 20250120 07:19:36.524898: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:819] Example stragglers: /job:worker/replica:0/task:1 I0000 00:00:1737379176.525022    4595 coordination_service_agent.cc:369] Coordination agent has successfully connected. 20250120 07:22:27.996664: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:378] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 13530699364709055870 20250120 07:22:27.996686: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:816] Waiting for 0/2 tasks to connect. /home/chad/anaconda3/lib/python3.12/sitepackages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.   warnings.warn( 20250120 07:22:28.461733: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. Traceback (most recent call last):   File ""/home/chad/Documents/McCueFiles/NeuralNetworks/TensorFlowProject/TensorFlowDocExample/main.py"", line 21, in      multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)   File ""/home/chad/anaconda3/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 122, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""/home/chad/anaconda3/lib/python3.12/sitepackages/tensorflow/python/framework/constant_op.py"", line 108, in convert_to_eager_tensor     return ops.EagerTensor(value, ctx.device_name, dtype)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ValueError: Attempt to convert a value (PerReplica:{   0:  }) with an unsupported type () to a Tensor.  Standalone code to reproduce the issue ```shell python main.py &> job_1.log ```  Relevant log output ```shell 20250120 07:19:35.283801: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250120 07:19:35.290192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1737379175.297785    4595 cuda_dnn.cc:8501] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1737379175.300054    4595 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250120 07:19:35.307721: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20250120 07:19:36.510476: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDAcapable device is detected 20250120 07:19:36.510494: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:167] env: CUDA_VISIBLE_DEVICES=""1"" 20250120 07:19:36.510499: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] CUDA_VISIBLE_DEVICES is set to 1  this hides all GPUs from CUDA 20250120 07:19:36.510501: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:178] verbose logging is disabled. Rerun with verbose logging (usually v=1 or vmodule=cuda_diagnostics=1) to get more diagnostic output from this module 20250120 07:19:36.510505: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] retrieving CUDA diagnostic information for host: michael 20250120 07:19:36.510507: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] hostname: michael 20250120 07:19:36.510562: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:197] libcuda reported version is: 565.77.0 20250120 07:19:36.510572: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:201] kernel reported version is: 565.77.0 20250120 07:19:36.510574: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:291] kernel version seems to match DSO: 565.77.0 20250120 07:19:36.519175: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:637] Initializing CoordinationService WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1737379176.519611    4595 grpc_server_lib.cc:465] Started server with target: grpc://localhost:12345 20250120 07:19:36.524874: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:378] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 4677280066871850635 20250120 07:19:36.524894: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:816] Waiting for 1/2 tasks to connect. 20250120 07:19:36.524898: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:819] Example stragglers: /job:worker/replica:0/task:1 I0000 00:00:1737379176.525022    4595 coordination_service_agent.cc:369] Coordination agent has successfully connected. 20250120 07:22:27.996664: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:378] /job:worker/replica:0/task:1 has connected to coordination service. Incarnation: 13530699364709055870 20250120 07:22:27.996686: I external/local_xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:816] Waiting for 0/2 tasks to connect. /home/chad/anaconda3/lib/python3.12/sitepackages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.   warnings.warn( 20250120 07:22:28.461733: W tensorflow/core/framework/dataset.cc:993] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations. Traceback (most recent call last):   File ""/home/chad/Documents/McCueFiles/NeuralNetworks/TensorFlowProject/TensorFlowDocExample/main.py"", line 21, in      multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)   File ""/home/chad/anaconda3/lib/python3.12/sitepackages/keras/src/utils/traceback_utils.py"", line 122, in error_handler     raise e.with_traceback(filtered_tb) from None   File ""/home/chad/anaconda3/lib/python3.12/sitepackages/tensorflow/python/framework/constant_op.py"", line 108, in convert_to_eager_tensor     return ops.EagerTensor(value, ctx.device_name, dtype)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ValueError: Attempt to convert a value (PerReplica:{   0:  }) with an unsupported type () to a Tensor. ```",2025-01-20T14:03:18Z,type:bug TF 2.18,open,0,2,https://github.com/tensorflow/tensorflow/issues/85351,"Hi **** , Apologies for the delay, and thank you for raising your concern here. Could you please provide more details, such as the versions of TensorFlow and any other relevant libraries you are using? Additionally, sharing your code would make it easier for us to troubleshoot the issue effectively. In the meantime, please ensure that all compatibility requirements are met. For your reference, here is the relevant documentation. Thank you!","Hi  , I think I've provided the info regarding versions of TensorFlow and any other relevant libraries in the issue creation. I'm not running any of my code I'm just using the jupyter notebook of the tutorial."
yi,NLLAPPS,Cannot use GpuDelegate - java.lang.IllegalArgumentException: Internal error: Cannot create interpreter,"Hi, I get ""Cannot use GpuDelegate  java.lang.IllegalArgumentException: Internal error: Cannot create interpreter"" when attempting to use GpuDelegate I have seen a couple of issue related to this but all seems to be abandoned. I have created a repo replicating the issue.  You can see the config at https://github.com/NLLAPPS/WhisperOffline/blob/d075a84aa42adc4a05a02ce64b0fcda9416f0e8c/app/src/main/java/com/whispertflite/engine/WhisperEngineJava.javaL114 **System information**  Android Device information: Samsung S23  TensorFlow Lite in Play Services SDK version : 16.4.0  Google Play Services version: 24.50.34 **Standalone code to reproduce the issue** Clone and run project from https://github.com/NLLAPPS/WhisperOffline/ **Any other info / logs** `Created TensorFlow Lite delegate for GPU. Created interpreter. Created interpreter. java.lang.IllegalArgumentException: Internal error: Cannot create interpreter:  at com.google.android.gms.tflite.NativeInterpreterWrapper.createInterpreter(Native Method) at com.google.android.gms.tflite.NativeInterpreterWrapper.zzs(com.google.android.gms:playservicestflitejava@.4.0:34) at com.google.android.gms.tflite.NativeInterpreterWrapper.(com.google.android.gms:playservicestflitejava@.4.0:14) at com.google.android.gms.tflite.zzd.(com.google.android.gms:playservicestflitejava@.4.0:3) at com.google.android.gms.tflite.InterpreterFactoryImpl.create(com.google.android.gms:playservicestflitejava@.4.0:4) at org.tensorflow.lite.InterpreterApi.create(InterpreterApi.java:373) at com.whispertflite.engine.WhisperEngineJava.loadModel(WhisperEngineJava.java:131) at com.whispertflite.engine.WhisperEngineJava.initialize(WhisperEngineJava.java:44) at com.whispertflite.asr.WhisperJava.loadModel(WhisperJava.java:72) at com.whispertflite.asr.WhisperJava.loadModel(WhisperJava.java:67) at com.whispertflite.MainActivity.initModel(MainActivity.java:247) at com.whispertflite.MainActivity.lambda$onCreate$3$comwhispertfliteMainActivity(MainActivity.java:155) at com.whispertflite.MainActivity$$ExternalSyntheticLambda0.run(D8$$SyntheticClass:0) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:644) at java.lang.Thread.run(Thread.java:1012)`",2025-01-19T22:01:13Z,comp:lite TFLiteGpuDelegate,open,0,12,https://github.com/tensorflow/tensorflow/issues/85313,"there is an issue with the configuration of the GpuDelegate or its compatibility with your environment, Test with CPUonly execution to confirm whether the issue is specific to the GPU Delegate","Hi and thank you. I have tested CPU only it works fine. What is the ""configuration of the GpuDelegate""? My configuration can be seen at https://github.com/NLLAPPS/WhisperOffline/blob/d075a84aa42adc4a05a02ce64b0fcda9416f0e8c/app/src/main/java/com/whispertflite/engine/WhisperEngineJava.javaL114","'GpuDelegateFactory.Options' in your code uses generic settings. For better control, you can configure options like precision or inference preference. try this or Run a compatibility check  GpuDelegateFactory.Options gpuOptions = new GpuDelegateFactory.Options(); gpuOptions.setInferencePreference(GpuDelegateFactory.Options.INFERENCE_PREFERENCE_FAST_SINGLE_ANSWER); gpuOptions.setPrecisionLossAllowed(true); ","Thanks, regarding ""compatibility check"". Is it possible to provide link to documentation for compatibility checking?",check out these links : https://stackoverflow.com/questions/50622525/whichtensorflowandcudaversioncombinationsarecompatible https://docs.nvidia.com/cuda/cudatoolkitreleasenotes/index.html https://docs.nvidia.com/deeplearning/cudnn/latest/reference/supportmatrix.html,"Your links seem to be related to PCs. Have I misunderstood what GpuDelegateFactory does. I thought it would be for using GPU on the phone since the artifact is ""playservicestflitegpu""",I also just noticed you are not related to this project. Do you have experience on implementing tflite on Android?,"you are correct in assuming that GpuDelegateFactory is intended for mobile devices to leverage the GPU for TensorFlow Lite inference, especially in Android using the playservicestflitegpu artifact. If you're targeting mobile platforms, this is the correct path to enable GPU acceleration dependencies {     implementation 'org.tensorflow:tensorflowlite:2.x.x'     implementation 'org.tensorflow:tensorflowlitegpu:2.x.x' } GpuDelegate delegate = new GpuDelegate(); Interpreter.Options options = new Interpreter.Options().addDelegate(delegate); Interpreter interpreter = new Interpreter(modelFile, options);","yes i am not a part of this project yet , im trying to contribute as much possible to be recognized by the organization before gsoc 2025","> yes i am not a part of this project yet , i'm trying to contribute as much possible to be recognized by the organization before gsoc 2025 I don't think you will be able to help me in this case. Issue seems to be related to actual SDK/API. Hopefully  will have a look at it.","Hi,   I apologize for the delayed response, I was trying to reproduce the similar issue from my end after cloning your provided repo but I'm getting below error message, if possible could you please help me to replicate the same issue from my end which you reported in the issue template to investigate this issue further from our end ? **Here is error log for reference :** ``` FAILURE: Build failed with an exception. * What went wrong: A problem occurred configuring root project 'WhisperOffline'. > Could not resolve all files for configuration ':classpath'.    > Could not find com.android.tools.build:gradle:8.10.2.      Searched in the following locations:         https://dl.google.com/dl/android/maven2/com/android/tools/build/gradle/8.10.2/gradle8.10.2.pom         https://repo.maven.apache.org/maven2/com/android/tools/build/gradle/8.10.2/gradle8.10.2.pom      Required by:          project : * Try: > Run with stacktrace option to get the stack trace. > Run with info or debug option to get more log output. > Run with scan to get full insights. > Get more help at https://help.gradle.org. BUILD FAILED in 829ms ``` Thank you for your cooperation and patience.","Hi, project is using com.android.tools.build:gradle:8.8.0 there is no com.android.tools.build:gradle:8.10.2. 8.10.2 is a Gradle version, not Android build tools version. Have you changed anything? This stack overflow post seems to suggest it may be related to Android Studio Gradle Settings.  Here is mine attached for the project !Image"
yi,maxima120,Force TF to log GPU memory allocation, Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.18.0  Custom code No  OS platform and distribution Debian 12  Mobile device _No response_  Python version 3.11.2  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.2  GPU model and memory RTX 3060 12Gb  Current behavior? If I ran out of GPU memory I get error saying `Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.78GiB` But if allocation succeeded there is no real way to know what the allocator did/doing.. I know that you can use nvidiasmi etc but this is an indirect way to estimate very crudely whats going on. What I believe would be very beneficial (because I dont know about you guys but I run out of memory so very often and I cant affort 128Gb card)  is to be able to force TF to log every and single one GPU memory allocation.  So I can see whats going on my healthy models and whats in the failing.,2025-01-19T13:50:42Z,stat:awaiting tensorflower type:feature comp:gpu,open,0,0,https://github.com/tensorflow/tensorflow/issues/85303
rag,LongZE666,Aborted  in `tf.raw_ops.RaggedGather`," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.17  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? On specific inputs, `tf.raw_ops.RaggedGather` triggers crash.  Standalone code to reproduce the issue ```shell params_nested_splits = tf.constant(0, shape=[3], dtype=tf.int64) params_dense_values = tf.constant(1, shape=[0], dtype=tf.float32) indices = tf.constant(0, shape=[], dtype=tf.int64) OUTPUT_RAGGED_RANK = 1 PARAMS_RAGGED_RANK = 1 tf.raw_ops.RaggedGather(     params_nested_splits=[params_nested_splits],     params_dense_values=params_dense_values,     indices=indices,     OUTPUT_RAGGED_RANK=1,     name=None ) ```  Relevant log output ```shell 20250118 09:30:00.549762: F tensorflow/core/framework/tensor.cc:844] Check failed: dtype() == expected_dtype (9 vs. 1) float expected, got int64 Aborted (core dumped) ```",2025-01-18T09:32:16Z,type:bug comp:ops 2.17,open,0,1,https://github.com/tensorflow/tensorflow/issues/85242,I was able to reproduce the issue on Colab using TensorFlow v2.18.0 and TFnightly. Please find the gist here for your reference. Thank you!
rag,LongZE666,Segmentation fault (core dumped) in `RaggedTensorToTensor`," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.17  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? On specific inputs, `tf.raw_ops.RaggedTensorToTensor` triggers crash.  Standalone code to reproduce the issue ```shell import tensorflow as tf shape = tf.constant(1, shape=[], dtype=tf.int64) values = tf.constant(0, shape=[0], dtype=tf.int32) default_value = tf.constant(0, shape=[], dtype=tf.int32) row_partition_tensors = tf.constant([0, 1, 6], shape=[3], dtype=tf.int64) row_partition_types = [""ROW_SPLITS""] tf.raw_ops.RaggedTensorToTensor(     shape=shape,     values=values,     default_value=default_value,     row_partition_tensors=[row_partition_tensors],     row_partition_types=row_partition_types) ```  Relevant log output ```shell Segmentation fault (core dumped) ```",2025-01-18T09:27:19Z,type:bug comp:ops 2.17,open,0,1,https://github.com/tensorflow/tensorflow/issues/85240,I was able to reproduce the issue on Colab using TensorFlow v2.18.0 and TFnightly. Please find the gist here for your reference. Thank you!
yi,copybara-service[bot],internal change only,internal change only,2025-01-17T17:32:39Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85178
yi,copybara-service[bot],internal change only,internal change only,2025-01-17T15:18:11Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85175
yi,henghamao,Could not get sample weight from customized loss," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.1  Custom code Yes  OS platform and distribution CentOS 7.9  Mobile device _No response_  Python version 3.8.3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We used customized loss for the model training, and would like to get sample weight to calculate the loss. However, sample weight does not pass to loss function as expected.  Standalone code to reproduce the issue ```shell Here are the code to reproduce the issue. import tensorflow as tf from tensorflow.keras.layers import Dense import numpy as np def weighted_zero_mean_r2_loss(y_true, y_pred, sample_weight=None):     y_true = tf.cast(y_true, tf.float32)     y_pred = tf.cast(y_pred, tf.float32)     sample_weight = tf.cast(sample_weight, tf.float32)     weighted_squared_error = sample_weight * (y_true  y_pred) ** 2     weighted_true_squared = sample_weight * y_true ** 2     numerator = tf.reduce_sum(weighted_squared_error)     denominator = tf.reduce_sum(weighted_true_squared)     r2_score = 1  numerator / denominator     return r2_score def build_model():     metrics = 'mae'     loss = weighted_zero_mean_r2_loss 'mse'     output_num = 1     inputs = tf.keras.layers.Input(shape=(40, 36))     lstm_out = tf.keras.layers.LSTM(32, return_sequences=False)(inputs)     output = Dense(output_num, activation='linear')(lstm_out)     model = tf.keras.Model(inputs, output)     model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(), metrics=metrics)     model.summary()     return model def data_gen(class_weights):     while True:         x_batch = np.random.rand(128, 40, 36)         y_batch = np.random.randint(0, 3, (128, 1))          Apply class weights to the labels         sample_weights = np.vectorize(lambda x: class_weights[x])(y_batch)         yield x_batch, y_batch, sample_weights model = build_model() cw = {0: 0.3, 1: 2.5, 2: 3.2} model.fit(data_gen(cw), epochs=2, steps_per_epoch=10) ```  Relevant log output ```shell Error messages: File ""/root/.virtualenvs/infinity_stock/lib/python3.8/sitepackages/keras/src/engine/training.py"", line 1338, in train_function  *         return step_function(self, iterator)     File ""/data/release/kagglejanestreet/scripts/python/test.py"", line 8, in weighted_zero_mean_r2_loss  *         sample_weight = tf.cast(sample_weight, tf.float32)     ValueError: None values not supported. ```",2025-01-17T15:16:39Z,type:feature comp:keras TF 2.13,closed,0,9,https://github.com/tensorflow/tensorflow/issues/85174,"I was able to reproduce the issue on Colab using TensorFlow v2.13 and TFnightly. Please find the gist1, gist2 here for your reference. Thank you!","Hi   When you are building a custom loss function, the loss function should have a signature of **```custom_loss_fn(y_true, y_pred)```** (source). When doing this, you are essentially trying to override the `call()` function in `class Loss` in keras/src/losses/loss/py.  You can still pass in a `sample_weight` parameter to the `model.fit()` call with the custom loss function, but sample_weight will be multiplied elementwise with the loss terms in the reduce_weighted_values() call. So it won't work the way you want it to for the r2 loss. One observation about your code is that sample_weight only depends on y_true, so you could move the sample_weight computation inside your function.  The following code would work: ``` def weighted_zero_mean_r2_loss(y_true, y_pred):     y_pred = tf.cast(y_pred, tf.float32)     y_true = tf.cast(y_true, tf.float32)     table = tf.lookup.StaticHashTable(         tf.lookup.KeyValueTensorInitializer(             keys=tf.constant([0, 1, 2], dtype=tf.int32),              values=tf.constant([0.3, 2.5, 3.2], dtype=tf.float32)),         default_value=1)     sample_weight = table.lookup(tf.cast(y_true, tf.int32))     weighted_squared_error = sample_weight * (y_true  y_pred) ** 2     weighted_true_squared = sample_weight * y_true ** 2     numerator = tf.reduce_sum(weighted_squared_error)     denominator = tf.reduce_sum(weighted_true_squared)     r2_score = 1  numerator / denominator     return r2_score ``` If you want to use a custom logic for applying sample_weights, there's another way to do it by subclassing the `keras.losses.Loss` class. You would have to override the `__init__` and `call` functions. You can pass in a custom function during `__init__` and use it during `call()`. For example: ``` class WeightedZeroMeanR2Loss((keras.losses.Loss):   def __init__(self, custom_weight_multiplier_fn, name='weighted_zero_mean_r2_loss'):     super().__init__(name=name)     self._custom_weight_multiplier_fn = custom_weight_multiplier_fn   def call(self, y_true, y_pred):      sample_weight = self._custom_weight_multiplier_fn(y_true)     weighted_squared_error = sample_weight * (y_true  y_pred) ** 2     weighted_true_squared = sample_weight * y_true ** 2     numerator = tf.reduce_sum(weighted_squared_error)     denominator = tf.reduce_sum(weighted_true_squared)     r2_score = 1  numerator / denominator     return r2_score ``` Note that you would probably need to use tensorflow operations and not python operations, since the loss function gets converted to a tf.function during the graph execution. You can initialize the model with the loss class above as follows: ```     model.compile(loss=WeightedZeroMeanR2Loss(custom_fn), optimizer=tf.keras.optimizers.Adam(), metrics=metrics) ``` I hope this explanation helps. Please let me know if you have any questions. ","Hi  , Thanks for the reply. The code is to reproduce the issue. And in real scenario, the sample weight could not refer by y_ture value.  The problme is the regression for multiple categories of data. The sample weight is to apply for different categories. y_ture is the data point at time stamp t. If it is a classify problem, we could refer sample weight by category label of y_ture value. However, for regression problems, we could not do that. In torch, we could easily use customize loss to calcualte weighted_r2_loss. Example code as below ``` class WeightedR2Loss(nn.Module):     """"""PyTorch loss function for weighted R².""""""     def __init__(self, epsilon: float = 1e38) > None:         """"""         Initialize the WeightedR2Loss class.         Args:             epsilon (float, optional): Small constant added to the denominator                  for numerical stability. Defaults to 1e38.         """"""         super(WeightedR2Loss, self).__init__()         self.epsilon = epsilon     def forward(         self,         y_pred: torch.Tensor,         y_true: torch.Tensor,         weights: torch.Tensor) > torch.Tensor:         """"""Compute the weighted R² loss.         Args:             y_true (torch.Tensor): Ground truth tensor.             y_pred (torch.Tensor): Predicted tensor.             weights (torch.Tensor): Weights for each observation (same shape as y_true).         Returns:             torch.Tensor: Computed weighted R² loss.         """"""         numerator = torch.sum(weights * (y_pred  y_true) ** 2)         denominator = torch.sum(weights * (y_true) ** 2) + 1e38         loss = numerator / denominator         return loss ``` Hope tf could provide similar solution to solve the problem.","  Thank you for going over your use case in detail. You can do this in Tensorflow by subclassing `keras.Model` and overriding the `compute_loss()` function. ``` class CustomModel(keras.Model):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)     def compute_loss(self, x, y_true, y_pred, sample_weight):         y_true = tf.cast(y_true, tf.float32)         y_pred = tf.cast(y_pred, tf.float32)         sample_weight = tf.cast(sample_weight, tf.float32)         weighted_squared_error = sample_weight * (y_true  y_pred) ** 2         weighted_true_squared = sample_weight * y_true ** 2         numerator = tf.reduce_sum(weighted_squared_error)         denominator = tf.reduce_sum(weighted_true_squared)         r2_score = 1  numerator / denominator         return r2_score def build_model():     metrics = ['mae']     output_num = 1     inputs = tf.keras.layers.Input(shape=(40, 36))     lstm_out = tf.keras.layers.LSTM(32, return_sequences=False)(inputs)     output = Dense(output_num, activation='linear')(lstm_out)     model = CustomModel(inputs, output)     class_weights = {0: 0.3, 1: 2.5, 2: 3.2}     model.compile(optimizer=tf.keras.optimizers.Adam(), metrics=metrics)     model.summary()     return model def data_gen(class_weights):     while True:         x_batch = np.random.rand(128, 40, 36)         y_batch = np.random.randint(0, 3, (128, 1))          Apply class weights to the labels         sample_weights = np.vectorize(lambda x: class_weights[x])(y_batch)         yield x_batch, y_batch, sample_weights model = build_model() cw = {0: 0.3, 1: 2.5, 2: 3.2} model.fit(data_gen(cw), epochs=2, steps_per_epoch=10) ```","  Great thanks for providing the solution. It works for our problems. BTW, there is another issue about class weight and sample weight with the similar code to reproduce the issue. https://github.com/tensorflow/tensorflow/issues/77958 We submited the issue a few months ago, and it did not get any further updates.",Happy to help!  Let me take a look at https://github.com/tensorflow/tensorflow/issues/77958.,"  Hi SanjaySG, We found a problem with the code. By using comput_loss(), the model tend to maximize the loss, rather than minimize the loss. Here is the code to repoduce the issue: ``` import tensorflow as tf from tensorflow.keras.layers import Dense import numpy as np class CustomModel(tf.keras.Model):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)     def compute_loss(self, x, y_true, y_pred, sample_weight):         y_true = tf.cast(y_true, tf.float32)         y_pred = tf.cast(y_pred, tf.float32)         sample_weight = tf.cast(sample_weight, tf.float32)         weighted_squared_error = sample_weight * (y_true  y_pred) ** 2         weighted_true_squared = sample_weight * y_true ** 2         numerator = tf.reduce_sum(weighted_squared_error)         denominator = tf.reduce_sum(weighted_true_squared)         r2_score = 1  numerator / denominator         return r2_score def build_model():     metrics = ['mae']     output_num = 1     inputs = tf.keras.layers.Input(shape=(40, 36))     lstm_out = tf.keras.layers.LSTM(32, return_sequences=False)(inputs)     output = Dense(output_num, activation='linear')(lstm_out)     model = CustomModel(inputs, output)     class_weights = {0: 0.3, 1: 2.5, 2: 3.2}     model.compile(optimizer=tf.keras.optimizers.Adam(), metrics=metrics)     model.summary()     return model def data_gen(class_weights):     while True:         x_batch = np.random.rand(128, 40, 36)         y_batch = np.random.randint(0, 3, (128, 1))          Apply class weights to the labels         sample_weights = np.vectorize(lambda x: class_weights[x])(y_batch)         yield x_batch, y_batch, sample_weights model = build_model() cw = {0: 0.3, 1: 2.5, 2: 3.2} model.fit(data_gen(cw), epochs=50, steps_per_epoch=10, verbose=2) ``` We observed the metric 'mae' keep growing, and the loss grows as well.","  This is down to the objective chosen for optimization. The model.fit() call tries to **minimize** the loss. r2 on the other hand should increase when the model performs better. A naive way to do this is by providing the negative of r2.  More importantly, r2 is not differentiable. So ideally, it shouldn't be used as a loss function for gradient descent, but it can be used as a metric. Something like MSE or MAE would be a better loss function. ",Great thanks for the explanations.
yi,copybara-service[bot],internal change only,internal change only,2025-01-17T15:11:39Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85173
yi,copybara-service[bot],Add some clarifying comments for Dockerfiles.,Add some clarifying comments for Dockerfiles.,2025-01-17T14:59:30Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85172
yi,copybara-service[bot],internal changes only,internal changes only,2025-01-17T13:07:46Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85161
llm,copybara-service[bot],Add LLM inference engine based on CompiledModel APIs,Add LLM inference engine based on CompiledModel APIs The new pipeline is only enabled with `use_compiled_model` flag to the script. It will define `USE_LITERT_COMPILED_MODEL` for the executor builds. The KV Cache management logic is implemented in LlmLiteRtCompiledModelExecutor with TensorBuffers.,2025-01-16T21:22:05Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/85088
rag,copybara-service[bot],Add a test for the `cholesky_expander` pass.,"Add a test for the `cholesky_expander` pass. There was some test coverage for `cholesky_expander`, but it wasn't located within the `hlo/` component and wasn't exactly a unit test as such.",2025-01-16T19:26:57Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85081
yi,SankuriJeyaSanjana,Tensorflow related issue," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Collecting tensorflowNote: you may need to restart the kernel to use updated packages.   Using cached tensorflow2.18.0cp310cp310win_amd64.whl.metadata (3.3 kB) Requirement already satisfied: tensorflowintel==2.18.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflow) (2.18.0) Requirement already satisfied: abslpy>=1.0.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (2.1.0) Requirement already satisfied: astunparse>=1.6.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.6.3) Requirement already satisfied: flatbuffers>=24.3.25 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (24.12.23) Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (0.4.0) Requirement already satisfied: googlepasta>=0.1.1 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (0.2.0) Requirement already satisfied: libclang>=13.0.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (18.1.1) Requirement already satisfied: opteinsum>=2.3.2 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (3.4.0) Requirement already satisfied: packaging in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (24.2) Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,=3.20.3 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (5.29.3) Requirement already satisfied: requests=2.21.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (2.32.3) Requirement already satisfied: setuptools in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (57.4.0) Requirement already satisfied: six>=1.12.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.17.0) Requirement already satisfied: termcolor>=1.1.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (2.5.0) Requirement already satisfied: typingextensions>=3.6.6 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (4.12.2) Requirement already satisfied: wrapt>=1.11.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.17.2) Requirement already satisfied: grpcio=1.24.3 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.69.0) Requirement already satisfied: tensorboard=2.18 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (2.18.0) Requirement already satisfied: keras>=3.5.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (3.8.0) Requirement already satisfied: numpy=1.26.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (2.0.2) Requirement already satisfied: h5py>=3.11.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (3.12.1) Requirement already satisfied: mldtypes=0.4.0 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (0.4.1) ... Requirement already satisfied: mdurl~=0.1 in c:\users\avs mani\desktop\project\venv\lib\sitepackages (from markdownitpy>=2.2.0>rich>keras>=3.5.0>tensorflowintel==2.18.0>tensorflow) (0.1.2) Using cached tensorflow2.18.0cp310cp310win_amd64.whl (7.5 kB) Installing collected packages: tensorflow Successfully installed tensorflow2.18.0 Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings... WARNING: Error parsing dependencies of tensorflowgpu: [Errno 2] No such file or directory: 'c:\\users\\avs mani\\desktop\\project\\venv\\lib\\sitepackages\\tensorflow_gpu2.10.1.distinfo\\METADATA'  ImportError                               Traceback (most recent call last) File c:\Users\AVS MANI\Desktop\Project\venv\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The operation completed successfully. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[1], line 5       1  Install tensorflow package       3 get_ipython().run_line_magic('pip', 'install tensorflow') > 5 import tensorflow as tf   type: ignore       7 from tensorflow.keras.models import Sequential  type: ignore       9 from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  type: ignore File c:\Users\AVS MANI\Desktop\Project\venv\lib\sitepackages\tensorflow\__init__.py:40 ... Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...  Standalone code to reproduce the issue ```shell import tensorflow as tf   type: ignore from tensorflow.keras.models import Sequential  type: ignore from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  type: ignore from tensorflow.keras.datasets import mnist  type: ignore ```  Relevant log output ```shell ```",2025-01-16T15:24:33Z,type:build/install,closed,0,2,https://github.com/tensorflow/tensorflow/issues/85064,"Please use \`\`\` to quote error messages to make them more readable. Also, please search previous issues, this issue has been discussed multiple times.",Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],PR #20274: [ROCm] Emit allocas on function entry in lower_tensors.cc,PR CC(Error:Execution failed for task ':buildNativeBazel'. > A problem occurred starting process 'command '/usr/local/bin/bazel''): [ROCm] Emit allocas on function entry in lower_tensors.://github.com/openxla/xla/pull/20274 This fixes //tensorflow/compiler/tests:segment_reduction_ops_test_gpu Copybara import of the project:  6553059e8d5bf039ef526b2b904808b55051cab9 by Dragan Mladjenovic : [ROCm] Emit allocas on function entry in lower_tensors.(Error:Execution failed for task ':buildNativeBazel'. > A problem occurred starting process 'command '/usr/local/bin/bazel'') FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20274 from ROCm:c64_atomics 6553059e8d5bf039ef526b2b904808b55051cab9,2025-01-16T15:23:19Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/85063
yi,user-redans,Issues on trying to compile TensorFlow C API for JETSON AGX Xavier using Bazel,"On my JETSON AGX Xavier, with: cuda: 11.4.315 cuDNN: 8.6.0 tensorrt: 8.5.2.2 jetpack: 5.1.3 python3 c “import tensorflow as tf; print(‘TensorFlow version:’, tf.version)” TensorFlow version: 2.11.0 I can’t compile tf with bazel ( bazel version: bazel 5.3.0 ) , error: ~/tensorflow$ bazel build config=opt config=cuda //tensorflow:libtensorflow.so Starting local Bazel server and connecting to it… WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior. INFO: Reading ‘startup’ options from /home/redans/tensorflow/.bazelrc: windows_enable_symlinks INFO: Options provided by the client: Inherited ‘common’ options: isatty=1 terminal_columns=237 INFO: Reading rc options for ‘build’ from /home/redans/tensorflow/.bazelrc: Inherited ‘common’ options: experimental_repo_remote_exec INFO: Reading rc options for ‘build’ from /home/redans/tensorflow/.bazelrc: ‘build’ options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive features=force_no_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility INFO: Reading rc options for ‘build’ from /home/redans/tensorflow/.tf_configure.bazelrc: ‘build’ options: action_env PYTHON_BIN_PATH=/usr/bin/python3.9 action_env PYTHON_LIB_PATH=/usr/local/lib/python3.9/distpackages python_path=/usr/bin/python3.9 action_env PYTHONPATH=/usr/local/lib/python3.9/distpackages:/usr/local/lib/python3.9/distpackages:/home/redans/ros2_ws/install/yolov8_ros/lib/python3.9/sitepackages:/home/redans/ros2_ws/install/yolov8_msgs/lib/python3.9/sitepackages:/home/redans/ros2_ws/install/realsense2_camera_msgs/lib/python3.9/sitepackages:/opt/ros/humble/lib/python3.9/sitepackages action_env LD_LIBRARY_PATH=/usr/local/cuda11.4/lib64:/home/redans/local/lib/python3.8/distpackages/tensorflow:/home/redans/ros2_ws/install/yolov8_msgs/lib:/home/redans/ros2_ws/install/realsense2_camera/lib:/home/redans/ros2_ws/install/realsense2_camera_msgs/lib:/opt/ros/humble/opt/rviz_ogre_vendor/lib:/opt/ros/humble/lib/aarch64linuxgnu:/opt/ros/humble/lib:/usr/local/cuda11.4/lib64: action_env GCC_HOST_COMPILER_PATH=/usr/bin/aarch64linuxgnugcc9 config=cuda INFO: Found applicable config definition build:short_logs in file /home/redans/tensorflow/.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file /home/redans/tensorflow/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:cuda in file /home/redans/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true INFO: Found applicable config definition build:cuda in file /home/redans/tensorflow/.tf_configure.bazelrc: repo_env HERMETIC_CUDA_COMPUTE_CAPABILITIES=7.2 INFO: Found applicable config definition build:opt in file /home/redans/tensorflow/.tf_configure.bazelrc: copt=Wnosigncompare host_copt=Wnosigncompare INFO: Found applicable config definition build:cuda in file /home/redans/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true INFO: Found applicable config definition build:cuda in file /home/redans/tensorflow/.tf_configure.bazelrc: repo_env HERMETIC_CUDA_COMPUTE_CAPABILITIES=7.2 INFO: Found applicable config definition build:linux in file /home/redans/tensorflow/.bazelrc: host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels experimental_guard_against_concurrent_changes INFO: Found applicable config definition build:dynamic_kernels in file /home/redans/tensorflow/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS ERROR: Traceback (most recent call last): File “/home/redans/.cache/bazel/_bazel_redans/e3bb405f92452fe8b27464d0b3fdd1a7/external/rules_python/python/versions.bzl”, line 734, column 32, in PLATFORMS = _generate_platforms() File “/home/redans/.cache/bazel/_bazel_redans/e3bb405f92452fe8b27464d0b3fdd1a7/external/rules_python/python/versions.bzl”, line 723, column 15, in _generate_platforms }  dict INFO: Found applicable config definition build:cuda in file /home/redans/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true INFO: Found applicable config definition build:cuda in file /home/redans/tensorflow/.bazelrc: repo_env TF_NEED_CUDA=1 crosstool_top=//crosstool:toolchain //:enable_cuda repo_env=HERMETIC_CUDA_VERSION=12.5.1 repo_env=HERMETIC_CUDNN_VERSION=9.3.0 //cuda:include_cuda_libs=true WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior. ERROR: //:enable_cuda :: Error loading option //:enable_cuda: error loading package ‘’: at /home/redans/.cache/bazel/_bazel_redans/e3bb405f92452fe8b27464d0b3fdd1a7/external/local_tsl/third_party/py/python_init_repositories.bzl:3:6: at /home/redans/.cache/bazel/_bazel_redans/e3bb405f92452fe8b27464d0b3fdd1a7/external/rules_python/python/repositories.bzl:24:6: at /home/redans/.cache/bazel/_bazel_redans/e3bb405f92452fe8b27464d0b3fdd1a7/external/rules_python/python/private/python_register_multi_toolchains.bzl:22:6: initialization of module ‘python/versions.bzl’ failed Do you have any suggestions?",2025-01-16T10:26:30Z,stat:awaiting response type:build/install stale subtype:bazel TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/85034,"redans, Tensorflow v2.11 is a pretty older version which is not actively supported. Every TensorFlow release is compatible with a certain version, for more information please take a look at the tested build configurations.In this case, can you please try installing TensorFlow v2.11 which the respective configurations. https://www.tensorflow.org/install/source Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
yi,rogerci91,tf.config.LogicalDeviceConfiguration() not able to set the memory limit but tf.config.experimental.VirtualDeviceConfiguration() is able to," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.17.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.4 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.2  GPU model and memory RTX A5000 24Gb  Current behavior? I was trying to set the memory limit of 10Gb on the virtual device using tf.config.LogicalDeviceConfiguration(), but when I trained the model it was taking way more than 10Gb of memory. Eventually I was able to set the memory limit using tf.config.experimental.VirtualDeviceConfiguration() but I'm not sure why  Standalone code to reproduce the issue ```shell  this was not able to set the memory limit gpus = tf.config.list_physical_devices('GPU') if gpus:     try:         tf.config.set_visible_devices(gpus[0], 'GPU')         tf.config.set_logical_device_configuration(gpus[0],         [tf.config.LogicalDeviceConfiguration(memory_limit=10*1024)])         logical_gpus = tf.config.list_logical_devices('GPU')     except RuntimeError as e:         print(e)   this was able to set the memory limit gpus = tf.config.list_physical_devices('GPU') if gpus:     try:         tf.config.experimental.set_virtual_device_configuration(             gpus[0],             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=10*1024)]         )     except RuntimeError as e:         print(e) ```  Relevant log output ```shell ```",2025-01-16T07:37:49Z,stat:awaiting response type:bug stale 2.17,closed,0,5,https://github.com/tensorflow/tensorflow/issues/85026,"TensorFlow's tf.config.experimental.set_virtual_device_configuration is more focused on managing device resources at a lower level, such as limiting memory and managing the allocation between multiple virtual devices. This is why it worked for you while the tf.config.LogicalDeviceConfiguration did not.If you need to limit memory usage, you should use tf.config.experimental.set_virtual_device_configuration() to ensure the desired memory cap is respected.","Hi **** , Hi **** Thank you for your pointers. Apologies for the delay, and thank you for raising your concern here. As  mentioned, `tf.config.experimental.set_virtual_device_configuration()` works by managing resource allocation at a lower level, including limiting memory usage and handling allocation across multiple virtual devices. Therefore, `tf.config.LogicalDeviceConfiguration()` will not achieve the desired results in this scenario. It is recommended to use `tf.config.experimental.set_virtual_device_configuration()` for better outcomes. Here is the relevant TensorFlow documentation for your reference. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,chandu464,Failed to load native TensorFlow Lite methods,"Hi, I'm trying to use tensorflow lite version 2.15.0 to run my tflite model and I'm getting an error when initializing the interpreter. I'm adding the tensor flow libraries in the gradle file  `implementation('org.tensorflow:tensorflowlite') { version { strictly(""2.15.0"") } }` Code:  ``` isLibraryLoaded = false private fun initInterpreter(): Interpreter? {         val tfliteOptions = Interpreter.Options()         tfliteOptions.setNumThreads(2)         if (!isLibraryLoaded) {             System.loadLibrary(""tensorflowlite_jni"")             ARLog.d(""OmniSenseMLDepthImageProcessor"",""Tensor flow lite Library load successful"")             isLibraryLoaded = true         }         return try {             Log.d(""InterpreterDelegate"", ""Thread id getInterpreter ==  ${Thread.currentThread().name}"")             val interpreter = org.tensorflow.lite.Interpreter(loadModelFile(resolveModelFilePath()), tfliteOptions)             Log.d(""InterpreterDelegate"", ""Interpreter initialized successfully"")             return interpreter         } catch (e: Exception) {             Log.e(""InterpreterDelegate"", ""Error: Could not initialize $tfLiteModel interpreter!: ${e.message}"")             e.printStackTrace()             null         }     } ``` TFLite version: 2.15.0 Device: Samsung S20 Error:  ```  E  FATAL EXCEPTION: pool140thread1                                                                                                     Process: com.amazon.mShop.android.shopping, PID: 14755                                                                                                     java.lang.UnsatisfiedLinkError: Failed to load native TensorFlow Lite methods. Check that the correct native libraries are present, and, if using a custom native library, have been properly loaded via System.loadLibrary():                                                                                                       java.lang.UnsatisfiedLinkError: dlopen failed: library ""libtensorflowlite_jni_gms_client.so"" not found                                                                                                     	at org.tensorflow.lite.TensorFlowLite.init(TensorFlowLite.java:137)                                                                                                     	at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:62)                                                                                                     	at org.tensorflow.lite.NativeInterpreterWrapperExperimental.(NativeInterpreterWrapperExperimental.java:36)                                                                                                     	at org.tensorflow.lite.Interpreter.(Interpreter.java:232)                                                                                                     	at com.a9.fez.tflite.TFLiteInterpreterDelegate.initInterpreter(TFLiteInterpreterDelegate.kt:50)                                                                                                     	at com.a9.fez.tflite.TFLiteInterpreterDelegate.getValue(TFLiteInterpreterDelegate.kt:29)  Caused by: java.lang.UnsatisfiedLinkError: No implementation found for void org.tensorflow.lite.TensorFlowLite.nativeDoNothing() (tried Java_org_tensorflow_lite_TensorFlowLite_nativeDoNothing and Java_org_tensorflow_lite_TensorFlowLite_nativeDoNothing__)  is the library loaded, e.g. System.loadLibrary?                                                                                                     	at org.tensorflow.lite.TensorFlowLite.nativeDoNothing(Native Method)                                                                                                     	at org.tensorflow.lite.TensorFlowLite.init(TensorFlowLite.java:132)                                                                                                     	... 14 more ```",2025-01-15T17:27:48Z,stat:awaiting response type:support stale comp:lite TF 2.15,closed,0,4,https://github.com/tensorflow/tensorflow/issues/84976,"Hi,   I apologize for the delayed response, if possible could you please help us with your Github repo along with TFLite model and complete steps to replicate the same behavior from our end to investigate this issue further from our end ? Thank you for your cooperation and patience.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Pass in pointer instead of Shape object to InstructionValueSet constructor,Pass in pointer instead of Shape object to InstructionValueSet constructor Avoids the copying of the shape object.,2025-01-15T15:24:28Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84972
yi,copybara-service[bot],PR #21437: [ds-fusion] Fix algebraic simplifier error in debug mode.,"PR CC(Resnet50 applying last pooling layer regardless pooling parameter): [dsfusion] Fix algebraic simplifier error in debug mode. Imported from GitHub PR https://github.com/openxla/xla/pull/21437 This error was observed while trying to land CC(Raspberry Pi install command not properly formatted.) (which is needed for the dsfusion work). This error occurs when there is a constant operation that can be converted into a scalar broadcast, but some other operation is a successor for the constant operation (via control dependency). Such a dependency is not relayed and so the operation is not converted even after the `ReplaceWithNewInstruction` function call. This causes a runtime error in debug mode testing. Fixing this by relaying this control dependency. Copybara import of the project:  9601c96d468a0d56d9f3ed0a925186ab49a4341b by Shraiysh Vaishay : [dsfusion] Fix algebraic simplifier error in debug mode. This error was observed while trying to land CC(Raspberry Pi install command not properly formatted.) (which is needed for the dsfusion work). This error occurs when there is a constant operation that can be converted into a scalar broadcast, but some other operation is a successor for the constant operation (via control dependency). Such a dependency is not relayed and so the operation is not converted even after the `ReplaceWithNewInstruction` function call. This causes a runtime error in debug mode testing. Fixing this by relaying this control dependency.  3a7ab58814f35a8c7f22cb46248cead3c5cdca50 by Shraiysh Vaishay : Change the function in dfs_hlo_visitor to always relay control deps. Merging this change closes CC(Resnet50 applying last pooling layer regardless pooling parameter) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21437 from shraiysh:algebraic_simplifier_fix 3a7ab58814f35a8c7f22cb46248cead3c5cdca50",2025-01-15T07:03:35Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84926
yi,copybara-service[bot],Add HasProperty to HloRunnerInterface and implementations.,Add HasProperty to HloRunnerInterface and implementations. `HasProperty` allows us to opaquely communicate the presence of arbitrary facts that may or may not be backenddependent. The runner (or underlying client  at the runner's discretion) returns `true` when called with an appropriate property tag if that predicate is true. One key usecase for this feature is to decouple our tests from specific backends/runner implementations. Some of our test cases only work on specific configurations and have predicates to skip execution when not supported. Property tags provide a way for that predicate to be implemented at the runner level and outside of the test.,2025-01-15T01:34:55Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84912
rag,copybara-service[bot],Support expanding ragged all-to-all dims similar to all-to-alls.,Support expanding ragged alltoall dims similar to alltoalls.,2025-01-14T22:27:07Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84899
yi,Yadan-Wei,Seg Fault when iterate dataset created from data service," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Segfault when trying to iterate dataset get from data service.  Standalone code to reproduce the issue ```shell  start the data service file start_dataservice.py import tensorflow as tf dispatcher = tf.data.experimental.service.DispatchServer(     tf.data.experimental.service.DispatcherConfig(port=50050), start=True ) dispatcher_address = dispatcher.target.split(""://"")[1] worker = tf.data.experimental.service.WorkerServer(     tf.data.experimental.service.WorkerConfig(dispatcher_address=dispatcher_address), start=True ) print(""Starting Worker"") worker.join()  test file test_dataset_service.py import tensorflow as tf import numpy as np flags = tf.compat.v1.app.flags flags.DEFINE_bool(""local"", False, ""Run data service in process"") flags.DEFINE_bool(""distribute"", False, ""Run data service in distributed_epoch mode"") FLAGS = flags.FLAGS def local_service():     print(""Starting Local Service"")     dispatcher = tf.data.experimental.service.DispatchServer(         tf.data.experimental.service.DispatcherConfig(port=50050), start=True     )     dispatcher_address = dispatcher.target.split(""://"")[1]     worker = tf.data.experimental.service.WorkerServer(         tf.data.experimental.service.WorkerConfig(dispatcher_address=dispatcher_address), start=True     )     print(""Dispatcher target is "", dispatcher.target)     return dispatcher, worker, dispatcher.target def apply_transformations(ds_train):     ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)     ds_train = ds_train.cache()     ds_train = ds_train.shuffle(60000)     ds_train = ds_train.batch(128)     ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)     return ds_train (x_train, y_train), _ = tf.keras.datasets.mnist.load_data() x_train = x_train / np.float32(255) y_train = y_train.astype(np.int64) ds_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)) def normalize_img(image, label):     """"""Normalizes images: `uint8` > `float32`.""""""     return tf.cast(image, tf.float32) / 255.0, label ds_train = apply_transformations(ds_train)  Create dataset however you were before using the tf.data service. dataset = ds_train if FLAGS.local:     dispatcher, worker, service = local_service() else:     dispatcher_address = ""localhost""     dispatcher_port = ""50050""     service = ""grpc://{}:{}"".format(dispatcher_address, dispatcher_port) if FLAGS.distribute:     processing_mode = ""distributed_epoch"" else:     processing_mode = ""parallel_epochs""  This will register the dataset with the tf.data service cluster so that  tf.data workers can run the dataset to produce elements. The dataset returned  from applying `distribute` will fetch elements produced by tf.data workers. dataset = dataset.apply(     tf.data.experimental.service.distribute(processing_mode=processing_mode, service=service) ) for (x1, y1), (x2, y2) in zip(dataset, ds_train):     np.allclose(x1, x2)     np.allclose(y1, y2) print(""verified mnist dataset locally vs over service"")  script to run  python m pip install upgrade pip python m pip install tensorflow==2.18.0 python m pip install 'protobuf device: 0, name: NVIDIA A100SXM440GB, pci bus id: 0000:10:1c.0, compute capability: 8.0 I0000 00:00:1736891783.520395    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 37945 MB memory:  > device: 1, name: NVIDIA A100SXM440GB, pci bus id: 0000:10:1d.0, compute capability: 8.0 I0000 00:00:1736891783.522012    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 37945 MB memory:  > device: 2, name: NVIDIA A100SXM440GB, pci bus id: 0000:20:1c.0, compute capability: 8.0 I0000 00:00:1736891783.523626    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 37945 MB memory:  > device: 3, name: NVIDIA A100SXM440GB, pci bus id: 0000:20:1d.0, compute capability: 8.0 I0000 00:00:1736891783.525222    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 37945 MB memory:  > device: 4, name: NVIDIA A100SXM440GB, pci bus id: 0000:90:1c.0, compute capability: 8.0 I0000 00:00:1736891783.526807    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 37945 MB memory:  > device: 5, name: NVIDIA A100SXM440GB, pci bus id: 0000:90:1d.0, compute capability: 8.0 I0000 00:00:1736891783.528377    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 37945 MB memory:  > device: 6, name: NVIDIA A100SXM440GB, pci bus id: 0000:a0:1c.0, compute capability: 8.0 I0000 00:00:1736891783.529933    9168 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 37945 MB memory:  > device: 7, name: NVIDIA A100SXM440GB, pci bus id: 0000:a0:1d.0, compute capability: 8.0 /test/bin/testDataservice: line 5:  9168 Segmentation fault      (core dumped) python ${BIN_DIR}/test_dataset_service.py local=False ```",2025-01-14T21:57:20Z,type:bug comp:ops TF 2.18,open,0,0,https://github.com/tensorflow/tensorflow/issues/84897
yi,copybara-service[bot],[XLA:GPU] Add `RewritePattern`s for binary elementwise ops in `SimplifyAffinePass`.,"[XLA:GPU] Add `RewritePattern`s for binary elementwise ops in `SimplifyAffinePass`. The rewrites allow us to concretize `index` computations into computations on integers with fixed widths. Triton forces `index`es to concretize to 32bitwide integers, forcing us to concretize early in order to work around an integer overflow when we use `ApplyIndexingOp`s to compute a linear offset into an array with more than `2^32` elements. Eventually, the concretization should be made into a proper passbut we start with a set of `RewritePattern`s to fix the existing integer overflow.",2025-01-14T19:52:37Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84891
rag,copybara-service[bot],[HLO Componentization] Add deprecation timeline to aliased build targets.,[HLO Componentization] Add deprecation timeline to aliased build targets. This step towards encouraging extrenal projects to migrate to the already migrated hlo subcomponents.,2025-01-14T18:40:54Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84878
yi,fsamekl,Yolov8-seg.pt segmentation model is deployed on Android after training,"**System information**  Android Device information (use `adb shell getprop ro.build.fingerprint`   if possible): ”“” vivo/PD2020/PD2020:10/QP1A.190711.020/compiler10141555:user/releasekeys “”“  TensorFlow Lite in Play Services SDK version (found in `build.gradle`): ”“”     implementation 'org.tensorflow:tensorflowlitetaskvision:0.4.0'     implementation 'org.tensorflow:tensorflowlitegpudelegateplugin:0.4.0'     implementation 'org.tensorflow:tensorflowlitegpu:2.9.0' “”“  Google Play Services version   (`Settings` > `Apps` > `Google Play Services` > `App details`): **Standalone code to reproduce the issue** ”“Here is the full code of the program”“ """""" public class MainActivity extends AppCompatActivity {     private String MODEL = ""best_float32_metadata.tflite"";          protected void onCreate(Bundle savedInstanceState) {         super.onCreate(savedInstanceState);         setContentView(R.layout.activity_main);         Bitmap bitmap = BitmapFactory.decodeResource(getResources(), R.drawable.a3);         bitmap = imageScale(bitmap, 640, 640);         TensorImage tensorImage = TensorImage.fromBitmap(bitmap);         Log.e(""HENG"", String.valueOf(tensorImage.getBuffer()));         Log.e(""HENG"", String.valueOf(tensorImage.getTensorBuffer()));         Log.e(""HENG"", String.valueOf(tensorImage.getDataType()));         Log.e(""HENG"", String.valueOf(tensorImage.getColorSpaceType()));         ImageSegmenter.ImageSegmenterOptions options = ImageSegmenter.ImageSegmenterOptions.builder()                 .setBaseOptions(BaseOptions.builder().build())                 .setOutputType(OutputType.CONFIDENCE_MASK)                 .build();         ImageSegmenter imageSegmenter = null;         try {             imageSegmenter = ImageSegmenter.createFromFileAndOptions(this, MODEL, options);         } catch (IOException e) {             throw new RuntimeException(e);         }         List results = imageSegmenter.segment(tensorImage);         Log.e(""HENG"", ""HELLO: ""+results.toString());     }     // 图像缩放方法     public static Bitmap imageScale(Bitmap bitmap, int new_w, int new_h) {         Bitmap scaledBitmap = Bitmap.createScaledBitmap(bitmap, new_w, new_h, true);         return scaledBitmap;     } } """""" **Any other info / logs** Please allow me to repeat my question. Thank you, First, (I may have solved the first problem, but I am not sure) I trained my data set with yolov8seg.pt to get a model. I converted it to tflite format, copied the 32bit model generated by best_float32.tflite into asssets in Android, and then modified the path of model to run the following original code. I got two error messages: ""1 Input tensor has type kTfLiteFloat32: it requires specifying NormalizationOptions metadata to preprocess input images.2、java.lang.IllegalStateException: Error getting native address of native library: task_vision_jni”, After I searched, I found“ https://stackoverflow.com/questions/66727627/failedtoinitializedetectorinputtensorhastypektflitefloat32mlkit ”I got a copy of the code in this link. After I tried to run it, I put the model I got into assets again. After running, it was not the above error message (the error message is the second problem). Second, (from the followup to the first question), I also got two errors after running the modified model ""best_float32_metadata.tflite"". The first one is ""java.lang.illegalargumentexception: error occurred when initializing imagesegment: image segmentation models are expected to have only 1 output, found 2"". It says that the model actually returns two outputs, which is a very important question. The second one seems to be the same as the first one, ""java.lang.runtimeexception: unable to start action""activity componentinfo{com.example.yoloseg_android/com.example.yoloseg_android.mainactivity}: java.lang.illegalstateexception: error getting native address of native library: task_vision_jni "", I don't understand this. These are my two problems. I think the second problem should be solved.  Note: I can use the deeplabv3.tflite model officially provided by tensorflow to get the output smoothly",2025-01-14T08:50:42Z,type:support comp:lite Android,open,0,3,https://github.com/tensorflow/tensorflow/issues/84829,I uploaded the project to GitHub. Thank you for your help“https://github.com/fsamekl/Yolov8segAndroidtflite/tree/master”,"Hi,   I apologize for the delayed response, The first issue, `Input tensor has type kTfLiteFloat32: it requires specifying NormalizationOptions metadata to preprocess input images` it requires specifying `NormalizationOptions` metadata to preprocess input images."", was due to lack of metadata. To be more specific, floating models require metadata information of NormalizationOptions. LiteRT Metadata Writer API provides an easytouse API to create Model Metadata for popular ML tasks supported by the TFLite Task Library. You can add metadata using Image segmenters, Please refer TensorFlow Lite Image Segmentation Demo example which may help you to solve your issue. Thank you for your understanding and patience.","> Hi, [](https://github.com/fsamekl) I apologize for the delayed response, The first issue, `Input tensor has type kTfLiteFloat32: it requires specifying NormalizationOptions metadata to preprocess input images` it requires specifying `NormalizationOptions` metadata to preprocess input images."", was due to lack of metadata. To be more specific, floating models require metadata information of NormalizationOptions. >  > LiteRT Metadata Writer API provides an easytouse API to create Model Metadata for popular ML tasks supported by the TFLite Task Library. You can add metadata using Image segmenters, Please refer TensorFlow Lite Image Segmentation Demo example which may help you to solve your issue. >  > Thank you for your understanding and patience. The second question you didn't answer me. I used the segmentation model trained by yolov8. It has two outputs, but imagesegment=imagesegment.createfromfileandoptions (this, model, options); This can only accept one output. What should I do? I uploaded the code to GitHub. I hope you can help solve it"
yi,copybara-service[bot],PR #21104: [NVIDIA GPU] Preserve backend config when folding transpose,PR CC(Feature Request: 5D rot90 (for voxel grid rotations)): [NVIDIA GPU] Preserve backend config when folding transpose Imported from GitHub PR https://github.com/openxla/xla/pull/21104 Transpose folding pass doesn't preserve backend config when creating the new dot with transpose folded. Changing the behavior to copy the old dot's config to the new dot. Copybara import of the project:  d2d6b628af1cab777a210e4ac62184e52fe9f4a9 by TJ Xu : Preserve backend config when folding transpose  6b5fa3a1cb70a790803e3ac57ff8329690e88e5e by TJ Xu : use SetupDerivedInstruction instead of just copying the backend config Merging this change closes CC(Feature Request: 5D rot90 (for voxel grid rotations)) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21104 from Tixxx:tixxx/transpose_folding 6b5fa3a1cb70a790803e3ac57ff8329690e88e5e,2025-01-14T02:30:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84811
yi,copybara-service[bot],PR #21380: Add F4E2M1FN and F8E8M0FNU types,"PR CC(tf.GradientTape.gradient raise error with tf.nn.relu6): Add F4E2M1FN and F8E8M0FNU types Imported from GitHub PR https://github.com/openxla/xla/pull/21380 Previous PR https://github.com/openxla/xla/pull/19096 was rolled back, retrying. This PR adds F4E2M1FN primitive type (4bit float with 2 bits exponent and 1 bit mantissa), F8E8M0FNU primitive type (8bit float with 8 bits exponent, no mantissa and no sign) and enables loads/stores in the same way S4/U4 type is implemented. This will enable using microscaling (MX) formats (RFC), such as MXFP4. ```c F4E2M1FN  Exponent bias: 1  Maximum stored exponent value: 3 (binary 11)  Maximum unbiased exponent value: 3  1 = 2  Minimum stored exponent value: 1 (binary 01)  Minimum unbiased exponent value: 1 − 1 = 0  Has Positive and Negative zero  Doesn't have infinity  Doesn't have NaNs Additional details:  Zeros (+/): S.00.0  Max normal number: S.11.1 = ±2^(2) x (1 + 0.5) = ±6.0  Min normal number: S.01.0 = ±2^(0) = ±1.0  Min subnormal number: S.00.1 = ±2^(0) x 0.5 = ±0.5 F8E8M0FNU  Exponent bias: 127  Maximum stored exponent value: 254 (binary 1111'1110)  Maximum unbiased exponent value: 254  127 = 127  Minimum stored exponent value: 0 (binary 0000'0000)  Minimum unbiased exponent value: 0 − 127 = 127  Doesn't have zero  Doesn't have infinity  NaN is encoded as binary 1111'1111 Additional details:  Zeros cannot be represented  Negative values cannot be represented  Mantissa is always 1 ``` Related PRs:  https://github.com/openxla/stablehlo/pull/2582  https://github.com/jaxml/ml_dtypes/pull/181  https://github.com/llvm/llvmproject/pull/95392  https://github.com/llvm/llvmproject/pull/108877  https://github.com/jaxml/ml_dtypes/pull/166  https://github.com/llvm/llvmproject/pull/107127  https://github.com/llvm/llvmproject/pull/111028 Copybara import of the project:  d7e00c49a4b4f26c06266d6bb941275e67464c01 by Sergey Kozub : Add F4E2M1FN and F8E8M0FNU types Merging this change closes CC(tf.GradientTape.gradient raise error with tf.nn.relu6) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21380 from openxla:skozub/e2m1_e8m0 d7e00c49a4b4f26c06266d6bb941275e67464c01",2025-01-14T01:51:38Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84809
yi,copybara-service[bot],Create copy if the operands of gather/scatter instructions overlap.,"Create copy if the operands of gather/scatter instructions overlap. A gather has two operands, input and indices. If they point to the same instruction, create a copy for indices. A scatter has n inputs, 1 indices, and n updates (2n+1 operands in total). We allow overlap between n inputs. We also allow overlap between n updates. We need to create a copy if * indices overlap with any input or update * update overlap with any input The added copy will be removed if it is redundant in the following memory related passes (e.g., CopyInsertion).",2025-01-13T23:26:00Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84805
rag,copybara-service[bot],Generate a build identifier for external tensor rearragement files,Generate a build identifier for external tensor rearragement files,2025-01-13T20:05:53Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/84789
yi,copybara-service[bot],Regenerate pyi stubs with absl::Span imports included,Regenerate pyi stubs with absl::Span imports included,2025-01-13T18:24:35Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84782
rag,copybara-service[bot],Implement CHLO->StableHLO ragged_dot mode 1 decomposition.,Implement CHLO>StableHLO ragged_dot mode 1 decomposition.,2025-01-13T17:34:35Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84776
agent,copybara-service[bot],Perform Set key operation first in the Exchange Topology to keep existing behavior unchanged.,"Perform Set key operation first in the Exchange Topology to keep existing behavior unchanged. Only when coordination_agent_recoverable is set, it tries to reconnect to the cluster and would lead to AlreadyExists error. In this case the already_existing error can be handled by checking the existing topology is same as the new one.",2025-01-13T16:22:52Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84769
yi,copybara-service[bot],PR #20633: Improve the error message of the host out-of-memory,"PR CC(Delete 3_datasets.ipynb): Improve the error message of the host outofmemory Imported from GitHub PR https://github.com/openxla/xla/pull/20633 When working on weight offloading and activation offloading for MaxText Llama27B on a GH200, a host memory Out of Memory (OOM) error occurred as a large amount of memory was offloaded from the device to host memory. This CL clarifies that it was a host OOM, not a device OOM, and suggests using the environment variable XLA_PJRT_GPU_HOST_MEMORY_LIMIT_GB to increase the host memory limit. Copybara import of the project:  e38fac1d00c13185cbb96972814ddc45b0508cd8 by Jane Liu : Improve the error message of the host outofmemory. Merging this change closes CC(Delete 3_datasets.ipynb) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20633 from zhenyingliu:hostOOM e38fac1d00c13185cbb96972814ddc45b0508cd8",2025-01-13T13:56:18Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84764
yi,copybara-service[bot],PR #20633: Improve the error message of the host out-of-memory,"PR CC(Delete 3_datasets.ipynb): Improve the error message of the host outofmemory Imported from GitHub PR https://github.com/openxla/xla/pull/20633 When working on weight offloading and activation offloading for MaxText Llama27B on a GH200, a host memory Out of Memory (OOM) error occurred as a large amount of memory was offloaded from the device to host memory. This CL clarifies that it was a host OOM, not a device OOM, and suggests using the environment variable XLA_PJRT_GPU_HOST_MEMORY_LIMIT_GB to increase the host memory limit. Copybara import of the project:  e38fac1d00c13185cbb96972814ddc45b0508cd8 by Jane Liu : Improve the error message of the host outofmemory. Merging this change closes CC(Delete 3_datasets.ipynb) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20633 from zhenyingliu:hostOOM e38fac1d00c13185cbb96972814ddc45b0508cd8",2025-01-13T10:53:24Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/84751
yi,copybara-service[bot],PR #19451: Setting xla_gpu_multi_streamed_windowed_einsum to true by default,PR CC(Feature Request: evaluate both train_data and test_data using tf.contrib.learn.Experiment?): Setting xla_gpu_multi_streamed_windowed_einsum to true by default Imported from GitHub PR https://github.com/openxla/xla/pull/19451 We are trying to deprecate xla_gpu_multi_streamed_windowed_einsum  since we always have better perf with it enabled. This is the first pr to enable it by default to test for stability. Copybara import of the project:  808a9cc0af8901d36a3c219bdf19f38323d01bf3 by Tj Xu : Turn xla_gpu_multi_streamed_windowed_einsum on by default  8221fc4481773f457f5e0235625be22f255fe75b by TJ Xu : Add an option to StreamAttributeAnnotator to skip annotating copystart and async DUS Don't annotate copystart and async DUS when the pass is run before remat  352c1c593b9dcd895f123dea4f7c38e44a787ae6 by TJ Xu : Remove the option to skip annotating copy start and inpect if the module has schedule  257ff6768b59fc7c47c04fa5faa524399f74c80e by TJ Xu : Address rollback by disabling a2a rewrite by default  d3bafebdc0961d61384a49616c29cb9bb6c59db9 by TJ Xu : reverted new flag changes Merging this change closes CC(Feature Request: evaluate both train_data and test_data using tf.contrib.learn.Experiment?) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19451 from Tixxx:tixxx/remove_multi_stream_flag d3bafebdc0961d61384a49616c29cb9bb6c59db9,2025-01-13T09:13:48Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84738
rag,axlrommel,enhancement: add sonargit pr metrics,"This PR introduces a GitHub workflow that leverages the SonarGit Action to collect pull request metrics such as open times, merge rates, and change failure rates. These metrics provide actionable insights to help improve the repository's development workflow. Currently, the workflow logs PR information to the console. Optionally, SonarGit offers a dashboard to visualize the data for deeper analysis—and it’s completely free for life! I’m doing this to help the developer community and to get my name out there. If you’d like more information or assistance in setting this up, feel free to reach out.",2025-01-12T22:41:52Z,size:S,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84696
yi,Cyprian-igban,tensorflow," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.8  Custom code Yes  OS platform and distribution windows  Mobile device windows  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? unable to load tensorflow as tf  Standalone code to reproduce the issue ```shell  Import necessary libraries import tensorflow as tf from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense from tensorflow.keras.datasets import fashion_mnist from tensorflow.keras.utils import to_categorical  Load and preprocess the dataset (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255 x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255 y_train = to_categorical(y_train, 10) y_test = to_categorical(y_test, 10)  Define the CNN model model = Sequential([     Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),     MaxPooling2D((2, 2)),     Conv2D(64, (3, 3), activation='relu'),     MaxPooling2D((2, 2)),     Flatten(),     Dense(128, activation='relu'),     Dense(10, activation='softmax') ])  Compile the model model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  Train the model model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)  Evaluate the model test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2) print(f""Test Accuracy: {test_acc:.2f}"") ```  Relevant log output ```shell ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[1], line 1 > 1 import tensorflow as tf       3 a = tf.constant(2)       4 b = tf.constant(3) File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:85      83     sys.setdlopenflags(_default_dlopen_flags)      84 except ImportError: > 85   raise ImportError(      86       f'{traceback.format_exc()}'      87       f'\n\nFailed to load the native TensorFlow runtime.\n'      88       f'See https://www.tensorflow.org/install/errors '      89       f'for some common causes and solutions.\n'      90       f'If you need help, create an issue '      91       f'at https://github.com/tensorflow/tensorflow/issues '      92       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\lenovo\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. ```",2025-01-12T10:37:11Z,type:build/install,closed,0,3,https://github.com/tensorflow/tensorflow/issues/84692,hey igban check out CC(ImportError: DLL load failed while importing _pywrap_tensorflow_internal:),Duplicate of CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.),Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],"Makes keyword arguments of functions loaded from TF1 SavedModels be treated as `POSITIONAL_OR_KEYWROD` (instead of `KEYWORD_ONLY`) arguments by `FunctionType`, so that `FunctionType` won't mistakenly change their order (which can lead to an order mismatch with the underlying TF Graph when calling or re-saving the function).","Makes keyword arguments of functions loaded from TF1 SavedModels be treated as `POSITIONAL_OR_KEYWROD` (instead of `KEYWORD_ONLY`) arguments by `FunctionType`, so that `FunctionType` won't mistakenly change their order (which can lead to an order mismatch with the underlying TF Graph when calling or resaving the function).",2025-01-11T20:44:49Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84685
yi,copybara-service[bot],Internal relative changes only,Internal relative changes only,2025-01-11T04:54:31Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84649
yi,copybara-service[bot],internal change only to update dependency visibility,internal change only to update dependency visibility FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19066 from Inteltensorflow:mabuzain/handleonednnscalar 576e244530ce0698de0b7137d8e93965fef9d528,2025-01-10T22:45:39Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84613
yi,copybara-service[bot],[XLA:Python] Make sure we hold the lock on cache_ when destroying executables_ in PjitFunction.,"[XLA:Python] Make sure we hold the lock on cache_ when destroying executables_ in PjitFunction. cache_'s object lock protects executables_ under freethreading mode, so we have to hold the lock.",2025-01-10T22:14:19Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84611
yi,copybara-service[bot],[XLA:GPU][Emitters] Allow unrolling loops that yield values defined above.,[XLA:GPU][Emitters] Allow unrolling loops that yield values defined above. The change upstream has been integrated.,2025-01-10T17:32:27Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84599
yi,copybara-service[bot],#sdy fix bug due to tensor dialect being introduced,"sdy fix bug due to tensor dialect being introduced When investigating a bug, I discovered this fails in JAX: ```py NS = jax.sharding.NamedSharding P = jax.sharding.PartitionSpec mesh = jax.sharding.Mesh(         np.reshape(np.array(jax.devices()), (4,2)), ('data', 'model')) in_avals = (jax.ShapeDtypeStruct((4, 8), jnp.float32),) shardings = (NS(mesh, P('data',)),) (jax.jit, out_shardings=shardings) def gen_dummy_inputs():   return tuple(       jax.random.normal(           jax.random.key(42), shape=in_aval.shape       ).astype(in_aval.dtype)       for in_aval in in_avals   ) gen_dummy_inputs() ``` with the error ``` LLVM ERROR: Building op `tensor.cast` but it isn't known in this MLIRContext: the dialect may not be loaded or this operation hasn't been added by the dialect. See also https://mlir.llvm.org/getting_started/Faq/registeredloadeddependentwhatsupwithdialectsmanagement ``` This was because the sdyroundtripimport introduces the tensor dialect. I'm unsure which pass adds it, but overall what I see is it is actually undone. The details shouldn't matter as long as the pass doesn't crash and the dialect doesn't show up during propagation.",2025-01-10T15:51:50Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84593
yi,johnnkp,gen_quantized_function_library: clang-cl compilation file path error," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.19 nightly  Custom code Yes  OS platform and distribution Windows 11 24H2  Mobile device _No response_  Python version Anaconda 2024.101  Bazel version 6.5.0  GCC/compiler version Visual Studio 2022 (build tools 14.42) + LLVM 19.1.6 + msys2x86_6420241208  CUDA/cuDNN version CUDA 12.6.3 + CUDNN 9.6.0  GPU model and memory GTX 1050 Ti 4GB  Current behavior? `gen_quantized_function_library` is trying to read `'C:\\msys64\\home\\*\\_bazel_*\\*\\execroot\\org_tensorflow\\bazelout\\x64_windowsoptexec*\\bin\\tensorflow\\compiler\\mlir\\quantization\\tensorflow\\gen_quantized_function_library.exe.runfiles\\org_tensorflow\\tensorflow\\compiler\\mlir\\quantization\\tensorflow\\gen_quantized_function_library.py'` on Windows. However, `os.path.exists()` cannot resolve `\\` symbol. Correct path is just like: `'C:/msys64/home/AMD/_bazel_amd/2oea4ayg/execroot/org_tensorflow/bazelout/x64_windowsoptexecBB41B15F/bin/tensorflow/compiler/mlir/quantization/tensorflow/gen_quantized_function_library'`  Standalone code to reproduce the issue ```shell 1. download https://github.com/johnnkp/tensorflowwgputest/archive/refs/heads/default_memory_space_description.zip and extract 2. run `python configure.py` to configure Windows CUDA build 3. run `bazel build config=win_clang config=cuda_wheel config=opt define=no_tensorflow_py_deps=true repo_env=TF_PYTHON_VERSION=3.12 //tensorflow/tools/pip_package:wheel repo_env=WHEEL_NAME=tensorflow_gpu` ```  Relevant log output ```shell ERROR: C:/users/amd/downloads/tensorflowwgputest/tensorflow/compiler/mlir/quantization/tensorflow/BUILD:38:8: Executing genrule //tensorflow/compiler/mlir/quantization/tensorflow:quantized_function_library failed: (Exit 1): bash.exe failed: error executing command (from target //tensorflow/compiler/mlir/quantization/tensorflow:quantized_function_library)   cd /d C:/msys64/home/amd/_bazel_amd/2oea4ayg/execroot/org_tensorflow   SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Windows;C:\Windows\System32;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\extras\CUPTI\lib64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.6\bin;C:\Program Files\LLVM\bin;C:\Users\AMD\anaconda3\Scripts;C:\Users\AMD\anaconda3;C:\msys64\usr\local\bin;C:\msys64\usr\bin;C:\msys64\usr\bin;C:\msys64\opt\bin;C:\Windows\System32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\msys64\usr\bin\site_perl;C:\msys64\usr\bin\vendor_perl;C:\msys64\usr\bin\core_perl     SET PYTHON_BIN_PATH=C:/Users/AMD/anaconda3/python.exe     SET PYTHON_LIB_PATH=C:/Users/AMD/anaconda3/Lib/sitepackages     SET TF2_BEHAVIOR=1   C:\msys64\usr\bin\bash.exe c source external/bazel_tools/tools/genrule/genrulesetup.sh; bazelout/x64_windowsoptexecBB41B15F/bin/tensorflow/compiler/mlir/quantization/tensorflow/gen_quantized_function_library.exe output_file bazelout/x64_windowsopt/bin/tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library.h src 'tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library_uniform_quantized.mlir tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library.mlir tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library_uniform_quantized_drq.mlir tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library_tf_drq.mlir tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library_xla_weight_only.mlir'  Configuration: bb43855b4d3a8365141a732926c882a21d79a321eb57928ec09cdaf313f3403c  Execution platform: //tensorflow/tools/toolchains/win:x64_windowsclangcl Traceback (most recent call last):   File ""C:\msys64\home\AMD\_bazel_amd\2oea4ayg\execroot\org_tensorflow\bazelout\x64_windowsoptexecBB41B15F\bin\tensorflow\compiler\mlir\quantization\tensorflow\gen_quantized_function_library"", line 559, in      Main()   File ""C:\msys64\home\AMD\_bazel_amd\2oea4ayg\execroot\org_tensorflow\bazelout\x64_windowsoptexecBB41B15F\bin\tensorflow\compiler\mlir\quantization\tensorflow\gen_quantized_function_library"", line 490, in Main     assert os.path.exists(main_filename), \            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ AssertionError: Cannot exec() 'C:\\msys64\\home\\AMD\\_bazel_amd\\2oea4ayg\\execroot\\org_tensorflow\\bazelout\\x64_windowsoptexecBB41B15F\\bin\\tensorflow\\compiler\\mlir\\quantization\\tensorflow\\gen_quantized_function_library.exe.runfiles\\org_tensorflow\\tensorflow\\compiler\\mlir\\quantization\\tensorflow\\gen_quantized_function_library.py': file not found. Target //tensorflow/tools/pip_package:wheel failed to build INFO: Elapsed time: 65.631s, Critical Path: 5.13s INFO: 30 processes: 13 disk cache hit, 8 internal, 9 local. FAILED: Build did NOT complete successfully ```",2025-01-10T07:01:31Z,stat:awaiting response type:build/install subtype:windows TF 2.18,closed,0,4,https://github.com/tensorflow/tensorflow/issues/84558,"I found out `rules_python` provide the python file template, but modify `python/private/python_bootstrap_template.txt` will not affect the generated `.py`.","Hi **** , Apologies for the delay, and thank you for raising your issue here. The main cause appears to be related to your file path. On Windows, path handling is different, and the error suggests that os.path.exists() cannot correctly resolve the path due to the use of backslashes (`\`). These are standard in Windows paths but need to be properly managed in Python. To resolve this, configure your setup to use forward slashes (`/`) instead of backslashes (`\`) for Windows paths. Python, especially when running in environments like MSYS2 or Git Bash, often handles forward slashes more consistently. If you have already tried this, please rebuild the Bazel target that generates the `.py` file. If the issue persists, let us know so we can further assist you. Thank you!","Although I already found out a fix for this issue, I am not going to create a pull request because my compilation failed with nvcc error in windows. And my fix seems unnecessary for other builds.",Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],Internal change only,Internal change only,2025-01-10T00:59:41Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84525
rag,Catakang,Memory Allocation Issues," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18.0  Custom code Yes  OS platform and distribution Ubuntu 24.04.1 LTS on WSL2  Mobile device _No response_  Python version 3.12.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 90300  GPU model and memory RTX 4070 12GB  Current behavior? I create a virtual gpu with a hard limit of 10GB. I start training the network and it works for bit but then says out of memory and tries to allocate more than the set limit. What I expect to happen is that is stays within the 10GB limit and can train the network successfully.  Standalone code to reproduce the issue ```shell import numpy as np import keras from keras import layers import tensorflow as tf import tensorflow_datasets as tfds import matplotlib.pyplot as plt %matplotlib inline tfds.disable_progress_bar() gpus = tf.config.list_physical_devices('GPU') if gpus:    Restrict TensorFlow to only allocate 1GB of memory on the first GPU   try:     tf.config.set_logical_device_configuration(         gpus[0],         [tf.config.LogicalDeviceConfiguration(memory_limit=10240)])     logical_gpus = tf.config.list_logical_devices('GPU')     print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")   except RuntimeError as e:      Virtual devices must be set before GPUs have been initialized     print(e) train_ds, validation_ds, test_ds = tfds.load(     ""cats_vs_dogs"",      Reserve 10% for validation and 10% for test     split=[""train[:40%]"", ""train[40%:50%]"", ""train[50%:60%]""],     as_supervised=True,   Include labels ) resize_fn = keras.layers.Resizing(150, 150) train_ds = train_ds.map(lambda x, y: (resize_fn(x), y)) validation_ds = validation_ds.map(lambda x, y: (resize_fn(x), y)) test_ds = test_ds.map(lambda x, y: (resize_fn(x), y)) augmentation_layers = [     layers.RandomFlip(""horizontal""),     layers.RandomRotation(0.1), ] def data_augmentation(x):     for layer in augmentation_layers:         x = layer(x)     return x train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y)) from tensorflow import data as tf_data batch_size = 16 train_ds = train_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache() validation_ds = validation_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache() test_ds = test_ds.batch(batch_size).prefetch(tf_data.AUTOTUNE).cache() base_model = keras.applications.Xception(     weights=""imagenet"",   Load weights pretrained on ImageNet.     input_shape=(150, 150, 3),     include_top=False, )   Do not include the ImageNet classifier at the top.  Freeze the base_model base_model.trainable = False  Create new model on top inputs = keras.Input(shape=(150, 150, 3))  Pretrained Xception weights requires that input be scaled  from (0, 255) to a range of (1., +1.), the rescaling layer  outputs: `(inputs * scale) + offset` scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=1) x = scale_layer(inputs)  The base model contains batchnorm layers. We want to keep them in inference mode  when we unfreeze the base model for finetuning, so we make sure that the  base_model is running in inference mode here. x = base_model(x, training=False) x = keras.layers.GlobalAveragePooling2D()(x) x = keras.layers.Dropout(0.2)(x)   Regularize with dropout outputs = keras.layers.Dense(1)(x) model = keras.Model(inputs, outputs) model.summary(show_trainable=True) model.compile(     optimizer=keras.optimizers.Adam(),     loss=keras.losses.BinaryCrossentropy(from_logits=True),     metrics=[keras.metrics.BinaryAccuracy()], ) epochs = 2 print(""Fitting the top layer of the model"") model.fit(train_ds, epochs=epochs, validation_data=validation_ds) ```  Relevant log output ```shell 20250109 19:39:57.953074: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1736469597.967544   14431 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered E0000 00:00:1736469597.971752   14431 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20250109 19:39:57.986195: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 1 Physical GPUs, 1 Logical GPUs I0000 00:00:1736469600.052169   14431 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10240 MB memory:  > device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:0a:00.0, compute capability: 8.9 Fitting the top layer of the model Epoch 1/2 20250109 19:40:04.479339: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:376] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608 WARNING: All log messages before absl::InitializeLog() is called are written to STDERR I0000 00:00:1736469604.583055   14486 service.cc:148] XLA service 0x7f8df8002230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices: I0000 00:00:1736469604.583109   14486 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9 20250109 19:40:04.722034: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable. I0000 00:00:1736469605.234339   14486 cuda_dnn.cc:529] Loaded cuDNN version 90300   7/582 ━━━━━━━━━━━━━━━━━━━━ 12s 22ms/step  binary_accuracy: 0.5658  loss: 0.6950  I0000 00:00:1736469608.599510   14486 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process. 243/582 ━━━━━━━━━━━━━━━━━━━━ 16s 48ms/step  binary_accuracy: 0.8715  loss: 0.2755 20250109 19:40:20.475756: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 1073741824 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469620.475821   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 1073741824 20250109 19:40:20.615636: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 966367744 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469620.615700   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 966367744 20250109 19:40:20.769033: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 869731072 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469620.769095   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 869731072 20250109 19:40:20.906909: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 782758144 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469620.906973   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 782758144 20250109 19:40:21.048863: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 704482304 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.048940   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 704482304 20250109 19:40:21.229614: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 634034176 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.229682   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 634034176 20250109 19:40:21.371940: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 570630912 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.372000   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 570630912 20250109 19:40:21.510751: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 513568000 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.510817   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 513568000 20250109 19:40:21.650945: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 462211328 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.651034   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 462211328 20250109 19:40:21.814945: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 415990272 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.815035   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 415990272 20250109 19:40:21.954790: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 374391296 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469621.954851   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 374391296 20250109 19:40:22.094150: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 336952320 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469622.094219   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 336952320 20250109 19:40:22.267664: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 303257088 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory ... 20250109 19:40:23.128022: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 161164032 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469623.128090   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 161164032 20250109 19:40:23.296856: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1253] failed to alloc 145047808 bytes on host: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory W0000 00:00:1736469623.296940   14537 device_host_allocator.h:61] could not allocate pinned host memory of size: 145047808 Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings... ```",2025-01-10T00:49:17Z,stat:awaiting response type:bug stale TF 2.18,closed,1,7,https://github.com/tensorflow/tensorflow/issues/84523,"I am facing exactly the same issue for a while now on two slightly different systems:  It even shows the warnings when setting `os.environ['TF_CPP_MIN_LOG_LEVEL'] = ""3""`. In my case, my code runs through despite these error messages, but on the one hand they are annoying and also a bit worrying and on the other hand I have the feeling that they affect the execution time, because I often observe strange behaviour regarding the execution times.","It does affect execution time and my code does not run to completion with the errors as I let it run for an hour to see what happened and it finished with a message saying '0 successful operations'. I don't know why I am running into this error as I am just trying to follow a tutorial on the keras website. I may not have a multi GPU setup to train a bunch of networks in an optimized fashion but surely 10gb on my 4070 should be plenty to run 2 epochs with a batch size of 10. This is ridiculous and from what I am reading from other GitHub issues, this has been an issue for years on certain systems that they have simply not fixed(if I understand everything right) and I really just want to figure out tensorflow for my science fair project.","I will mention I have tried growing the memory, I tried the malloc cuda async flag, I tried slowly reducing the batch size smaller and smaller, this really shouldn't be that complicated.","Hi **** , Apologies for the delay, and thank you for raising your concern here. I attempted to run your code on Colab using the TensorFlow nightly version but encountered a different issue. I have attached a gist for your review—could you please check and let me know if I made any mistakes while executing your code? Additionally, in your setup, consider disabling XLA to potentially reduce memory usage. Let us know if you are still encountering the same issue. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,copybara-service[bot],This is the first step in unifying the various StreamExecutor::Allocate and ::Deallocate methods.  (e.g. HostMemoryAllocate & HostMemoryDeallocate),This is the first step in unifying the various StreamExecutor::Allocate and ::Deallocate methods.  (e.g. HostMemoryAllocate & HostMemoryDeallocate) Future CLs will make use of these new classes to eliminate the need for adding bespoke Allocate/Deallocate pairs as new MemoryTypes are added.,2025-01-09T22:42:17Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84508
gemma,copybara-service[bot],[xla:cpu:benchmarks] Add scripts to run Gemma2 Keras model.,[xla:cpu:benchmarks] Add scripts to run Gemma2 Keras model.,2025-01-09T10:29:14Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84465
yi,MoFHeka,GPU Profiling: MemoryProfile do not contain memory events when profile remote worker.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version nightly  Custom code No  OS platform and distribution Ubuntu 22.04  Python version Python 3.12  CUDA/cuDNN version CUDA 12.4  GPU model and memory A100 80GB  Current behavior? Start a simple any collective training with Tensorflow cluster config. And then use RPC client capture_profile in Tensorboard or tf.profiler.experimental.client.trace.  No any memory profile events or OP profiler, but only trace view.  Standalone code to reproduce the issue **tf_allreduce.py** ```python import tensorflow as tf from tensorflow.python.ops.collective_ops import all_reduce, all_reduce_v2 from tensorflow.python.eager import context from tensorflow.core.protobuf import config_pb2 from tensorflow.python.distribute import cluster_resolver as cluster_resolver_lib cluster_resolver = cluster_resolver_lib.TFConfigClusterResolver() cluster = cluster_resolver.cluster_spec() task_type = cluster_resolver.task_type task_id = cluster_resolver.task_id experimental_config = config_pb2.ConfigProto.Experimental(     share_cluster_devices_in_session=False,     share_session_state_in_clusterspec_propagation=False ) config = config_pb2.ConfigProto(experimental=experimental_config) config.experimental.collective_group_leader = '/job:worker/replica:0/task:0' server = tf.distribute.Server(cluster,                               job_name=task_type,                               task_index=task_id,                               protocol=""grpc"",  ""grpc+verbs""                               config=config) run_options = config_pb2.RunOptions() with tf.compat.v1.Session(target=server.target, config=config) as sess:     tensor = tf.Variable(tf.ones([2, 2]), dtype=tf.float32)     init = tf.compat.v1.global_variables_initializer()     sess.run(init)     sess.run(tf.print([""tensor:"",tensor]))     reduced_tensor = all_reduce(tensor, group_size=2, group_key=4321, instance_key=1234, merge_op='Add', final_op='Id', communication_hint='auto')     run_options.experimental.collective_graph_key = 6     while True:         sess.run(tf.print([""reduced_tensor:"",reduced_tensor]), options=run_options) ``` Run script to start server. ```bash CUDA_VISIBLE_DEVICES=0 TF_CONFIG='{""cluster"":{""worker"":[""localhost:2223"",""localhost:2224""]},""task"":{""type"":""worker"",""index"":0}}' python tf_allreduce.py& CUDA_VISIBLE_DEVICES=1 TF_CONFIG='{""cluster"":{""worker"":[""localhost:2223"",""localhost:2224""]},""task"":{""type"":""worker"",""index"":1}}' python tf_allreduce.py& ```  use capture_profile in Tensorboard or tf.profiler.experimental.client.trace. ```python tf.profiler.experimental.client.trace(   'grpc://localhost:2223,grpc://localhost:2224',    '/tmp/my_tb_dir',    2000, ) ``` Try to convert xplane.pb to memory_profile, nothing show. ```python from tensorflow.python.profiler.internal import _pywrap_profiler as profiler_wrapper json = profiler_wrapper.xspace_to_tools_data([""xxx.xplane""], ""memory_profile"") ``` **Relevant log output** ``` {""memoryProfilePerAllocator"":{},""numHosts"":1,""memoryIds"":[]} ``` Relative issue: CC(GPU Profiling: MemoryProfile do not contain memory events.) ",2025-01-09T09:26:20Z,stat:awaiting tensorflower type:bug comp:core TF 2.18,open,0,0,https://github.com/tensorflow/tensorflow/issues/84460
yi,copybara-service[bot],Internal change only,Internal change only,2025-01-09T03:02:00Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84428
yi,copybara-service[bot],Internal change. Need to write more words to keep the presubmit happy.,Internal change. Need to write more words to keep the presubmit happy.,2025-01-09T01:11:59Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84423
rag,copybara-service[bot],Add `ClientLibraryTestRunnerMixin`.,"Add `ClientLibraryTestRunnerMixin`. `ClientLibraryTestRunnerMixin` is a sortof replacement for `ClientLibraryTestBase` to run tests on top of `HloTestBase` and friends (e.g. `HloRunnerAgnosticTestBase`).  This is to enable a future migration to PjRt and TFRT. Due to `ClientLibraryTestBase` containing many clientspecific calls, moving tests is not as trivial as simply dropping in a new base class. The idea with this class is just to make that migration simpler and to reduce (but not eliminate) the amount of code changes required in tests. Migration timeline for `ClientLibraryTestBase` tests: 1. `class XYZ: ClientLibraryTestBase` (starting point) 2. `class XYZ: ClientLibraryTestRunnerMixin` (intermediate state) 3. `class XYZ: ClientLibraryTestRunnerMixin>` (end state)",2025-01-09T00:32:15Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84414
yi,nathom,Unable to connect to TPU through Cloud VM (metadata issue?)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.18.0rc24g6550e4bd802 2.18.0  Custom code Yes  OS platform and distribution tpuubuntu2204base  Mobile device _No response_  Python version 3.11.2  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am on a VM instance trying to connect to a tpu v432 using a test script. I installed tensorflowtpu on both the VM (in venv) and TPU (globally) as per the instructions from the google website. It seems like there is an issue with getting TPU metadata. It is able to connect to the metadata server when I request manually from the VM: ``` $ curl http://169.254.169.254/computeMetadata/v1/ H ""MetadataFlavor: Google"" instance/ oslogin/ project/ ``` Any help would be appreciated!  Standalone code to reproduce the issue ```shell resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_name) tf.config.experimental_connect_to_cluster(resolver) try:     tf.tpu.experimental.initialize_tpu_system(resolver)     print(""TPU initialized:"", resolver.master()) except Exception as e:     print(""Failed to initialize TPU:"", e) ```  Relevant log output ```shell $ python hello.py 20250108 23:49:33.189260: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250108 23:49:33.221197: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:95] Opening library: /home/ucsdwanglab/test_tpu/.venv/lib/python3.11/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2 20250108 23:49:33.221290: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:121] Libtpu path is: /home/ucsdwanglab/test_tpu/.venv/lib/python3.11/sitepackages/libtpu/libtpu.so Failed to get TPU metadata (tpuenv) from instance metadata for variable CHIPS_PER_HOST_BOUNDS: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 learning/45eac/tfrc/runtime/env_var_utils.cc:50 Failed to get TPU metadata (tpuenv) from instance metadata for variable HOST_BOUNDS: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 learning/45eac/tfrc/runtime/env_var_utils.cc:50 Failed to get TPU metadata (tpuenv) from instance metadata for variable ALT: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 learning/45eac/tfrc/runtime/env_var_utils.cc:50 Failed to get TPU metadata (tpuenv) from instance metadata for variable WRAP: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 learning/45eac/tfrc/runtime/env_var_utils.cc:50 Failed to get TPU metadata (acceleratortype) from instance metadata for variable TPU_ACCELERATOR_TYPE: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 Failed to find host bounds for accelerator type: WARNING: could not determine TPU accelerator type, please set env var `TPU_ACCELERATOR_TYPE` manually, otherwise libtpu.so may not properly initialize. Failed to get TPU metadata (agentworkernumber) from instance metadata for variable TPU_WORKER_ID: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 Failed to get TPU metadata (workernetworkendpoints) from instance metadata for variable TPU_WORKER_HOSTNAMES: INTERNAL: Failed to fetch URL after 30 tries (http status: 404); curl status: No error === Source Location Trace: ===  learning/45eac/tfrc/runtime/gcp_metadata_utils.cc:93 WARNING: Logging before InitGoogle() is written to STDERR E0000 00:00:1736380405.363400    3192 common_lib.cc:511] INVALID_ARGUMENT: Error: unexpected worker hostname 'WARNING: could not determine TPU worker hostnames or IP addresses' from env var TPU_WORKER_HOSTNAMES. Expecting a valid hostname or IP address without port number. (Full TPU workers' addr string: WARNING: could not determine TPU worker hostnames or IP addresses, please set env var `TPU_WORKER_HOSTNAMES` manually, otherwise libtpu.so may not properly initialize.) === Source Location Trace: ===  learning/45eac/tfrc/runtime/libtpu_init_utils.cc:173 20250108 23:56:48.526584: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. WARNING: All log messages before absl::InitializeLog() is called are written to STDERR E0000 00:00:1736380609.730442    3192 context_distributed_manager.cc:762] unknown service tensorflow.WorkerService Additional GRPC error information from remote target /job:worker/replica:0/task:0 while calling /tensorflow.WorkerService/GetStatus: :{""created"":"".730372913"",""description"":""Error received from peer ipv4:10.130.0.3:8470"",""file"":""external/com_github_grpc_grpc/src/core/lib/surface/call.cc"",""file_line"":1056,""grpc_message"":""unknown service tensorflow.WorkerService"",""grpc_status"":12} E0108 23:56:49.730822322    3192 completion_queue.cc:244]    assertion failed: queue.num_items() == 0 https://symbolize.stripped_domain/r/?trace=7f1ccaf5cebc,7f1ccaf0e04f&map=  *** SIGABRT received by PID 3192 (TID 3192) on cpu 4 from PID 3192; stack trace: *** PC: @     0x7f1ccaf5cebc  (unknown)  (unknown)     @     0x7f1caa302841       1888  (unknown)     @     0x7f1ccaf0e050   18460496  (unknown)     @     0x7f1ccaed1c60  (unknown)  (unknown) https://symbolize.stripped_domain/r/?trace=7f1ccaf5cebc,7f1caa302840,7f1ccaf0e04f,7f1ccaed1c5f&map=  E0108 23:56:49.732558    3192 coredump_hook.cc:316] RAW: Remote crash data gathering hook invoked. E0108 23:56:49.732569    3192 coredump_hook.cc:355] RAW: Skipping coredump since rlimit was 0 at process start. E0108 23:56:49.732575    3192 client.cc:269] RAW: Coroner client retries enabled, will retry for up to 30 sec. E0108 23:56:49.732580    3192 coredump_hook.cc:411] RAW: Sending fingerprint to remote end. E0108 23:56:49.732595    3192 coredump_hook.cc:420] RAW: Cannot send fingerprint to Coroner: [NOT_FOUND] stat failed on crash reporting socket /var/google/services/logmanagerd/remote_coredump.socket (Is the listener running?): No such file or directory E0108 23:56:49.732601    3192 coredump_hook.cc:472] RAW: Dumping core locally. E0108 23:56:49.745981    3192 process_state.cc:805] RAW: Raising signal 6 with default behavior Aborted ```",2025-01-09T00:04:51Z,stat:awaiting response type:bug comp:tpus TF 2.18,closed,0,4,https://github.com/tensorflow/tensorflow/issues/84413,", Could you please provide more information and also steps you have followed to use the TPU's which helps to debug the issue in an effective way. Thank you!","I think this was my mistake. I was using a Google Cloud VM and trying to connect to the TPU pods from there. I was able to resolve the issue by connecting directly to one of the TPU hosts, and running commands on all workers using `gcloud`. Maybe the error messages could be made more helpful, though.",", Glad the issue was resolved by connecting the TPU hosts. Could you please feel free to move this issue to closed status. Thank you!",Are you satisfied with the resolution of your issue? Yes No
rag,rizkyy702,bug," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible). ``` (You can paste links or attach files by dragging & dropping them below)  Provide links to your updated versions of the above two colab notebooks.  Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model. ```  Option B: Paste your code here or provide a link to a custom endtoend colab ``` (You can paste links or attach files by dragging & dropping them below)  Include code to invoke the TFLite Converter Python API and the errors.  Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model. ```  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2025-01-09T00:02:56Z,TFLiteConverter,closed,0,1,https://github.com/tensorflow/tensorflow/issues/84412,Nothing provided in the template.
rag,copybara-service[bot],Split `RunAndCompare` with reference backend functionality into a mixin.,"Split `RunAndCompare` with reference backend functionality into a mixin. Many users don't require `RunAndCompare` functionality, but are forced to select and initialize a reference backend anyway. With this change, users can opt to extend their specific `HloRunnerAgnosticTestBase` implementation to add `RunAndCompare` functionality. The mixin acts as a wrapper around any `HloRunnerAgnosticTestBase` implementation, allowing a high degree of customization.",2025-01-08T17:34:31Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84390
rag,copybara-service[bot],Remove `RunAndCompare` functionality from `HloRunnerAgnosticTestBase`.,"Remove `RunAndCompare` functionality from `HloRunnerAgnosticTestBase`. This functionality is now fully contained in `HloRunnerAgnosticReferenceMixin` and therefore is no longer needed in `HloRunnerAgnosticTestBase`. This change temporarily adds the mixin to `HloPjRtTestBase`. Next, we'll go through all tests that extend these base classes and will move the uses of the mixins to the leaves.",2025-01-08T02:01:34Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84321
rag,copybara-service[bot],Add `HloPjRtInterpreterReferenceMixin` wrapper around `HloRunnerAgnosticReferenceMixin`.,Add `HloPjRtInterpreterReferenceMixin` wrapper around `HloRunnerAgnosticReferenceMixin`. This mixin provides a default way to run comparison tests against an interpreter reference via the PjRtbased interpreter.,2025-01-08T01:58:40Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84320
rag,copybara-service[bot],Split `RunAndCompare` with reference backend functionality into a mixin.,"Split `RunAndCompare` with reference backend functionality into a mixin. Many users don't require `RunAndCompare` functionality, but are forced to select and initialize a reference backend anyway. With this change, users can opt to extend their specific `HloRunnerAgnosticTestBase` implementation to add `RunAndCompare` functionality. The mixin acts as a wrapper around any `HloRunnerAgnosticTestBase` implementation, allowing a high degree of customization.",2025-01-08T01:56:58Z,,open,0,0,https://github.com/tensorflow/tensorflow/issues/84318
yi,copybara-service[bot],[XLA:Python] Fix three concurrency problems.,"[XLA:Python] Fix three concurrency problems. These problems can be reproduced even with the GIL enabled, they are not noGIL bugs. In pmap_lib.cc, defend against a use after free in the following scenario: * thread A misses in the compilation cache and calls `cache_miss()` to populate the cache, relying on the new entry in executables_ remaining alive. * thread B calls `cache_clear()`, which erases the contents of `executables_` Use a std::shared_ptr to keep the entry alive. In pjit.cc, refactor PjitFunctionStore to use a doublylinked list of PjitFunctionObject entries. When consuming the list of functions in the store, take strong references to them. This prevents a useafterfree if the cache is cleared concurrently multiple times. In pjit.cc, do not add functions to the PjitFunctionStore until executables_ is populated. This avoids a null pointer dereference from a concurrent call to `cache_clear`. Problems found with some upcoming test infrastructure that runs JAX test cases in parallel.",2025-01-07T21:07:38Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84296
yi,copybara-service[bot],Fold `xla::PjRtXlaLayout` into `xla::PjRtLayout` for simplification,"Fold `xla::PjRtXlaLayout` into `xla::PjRtLayout` for simplification `xla::PjRtLayout` was designed as an abstract class so that it leaves options to represent layouts without depending on `xla::Layout`. In reality, `xla::PjRtXlaLayout` is the only concrete layout representation that will exist in the foreseeable future, and the lack of a proper typeerased layout creation interface forces everyone to use unsafe downcast to access the underlying layout. This causes an unnecessary code bloat without much extensibility because too many downcasts practically prevent new layout representations from being easily introduced. This CL folds `xla::PjRtXlaLayout` into `xla::PjRtLayout` and make `xla::PjRtLayout` a nonabstract class. Like `xla::Shape` that is used pervasively in PjRt, this CL makes layouts a concrete type based on `xla::Layout`. The benefit is that it simplifies many callers that use PjRt layouts: `xla::GetXlaLayoutUnsafe()` is now replaced with the `pjrt_layout>xla_layout()` accessor, no more `down_cast`/`dynamic_cast` to access `xla::PjRtXlaLayout`, etc. `xla::ifrt::BasicStringArrayLayout` was the only other implementation of `xla::PjRtLayout` and this is now removed. Since string arrays are supported only in IFRT and not in PjRt, its layout representation should also live only in IFRT. Since no one depends on string array layouts, this CL simply removes its implementation so that we can add a proper one once a proper IFRT layout type is added.",2025-01-07T03:53:35Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84242
yi,copybara-service[bot],PR #21037: Typo Fix,PR CC(tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory): Typo Fix Imported from GitHub PR https://github.com/openxla/xla/pull/21037 Copybara import of the project:  588990f2fee70a9237faeff6e1ed17161c770163 by flyingcat : Typo Fix Merging this change closes CC(tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory) FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21037 from knightXun:knightXunpatch1 588990f2fee70a9237faeff6e1ed17161c770163,2025-01-07T01:28:17Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84236
rag,copybara-service[bot],Fix `HloRunnerAgnosticTestBase` includes.,Fix `HloRunnerAgnosticTestBase` includes. Many of the tests that extend `HloTestBase` rely on symbols included transitively.  The main ones are:  `PlatformUtil`  `LiteralUtil`  `LiteralTestUtil` This patch adds includes for these explicitly.,2025-01-06T22:34:28Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84225
text generation,phandat128,Encountered unresolved custom op: XlaDynamicSlice,"Hi, i am doing a task in converting T5 model to TFLite for Android. Currently, i am using T5ModelForConditionalGeneration from Huggingface to convert. The conversion is done with some below logging but when load the `generator` from Interpretor, and run an inference example, i have faced this error. You can reproduce with the colab provided below. AFAIK, this XlaDynamicSlice is in TF ops but why this op cannot be resolved in this cases.  **System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04  TensorFlow installed from (source or binary): PyPI 24.0 on Python 3.11.5  TensorFlow version (or github SHA if from source): 2.18.0 **Provide the text output from tflite_convert** In colab version, tflite_convert doesn't log anything, below log is in my local version ``` INFO:tensorflow:Assets written to: /tmp/tmpaxxybw9x/assets INFO:tensorflow:Assets written to: /tmp/tmpaxxybw9x/assets W0000 00:00:1736157114.568747 1061359 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format. W0000 00:00:1736157114.568765 1061359 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency. 20250106 16:51:54.568997: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpaxxybw9x 20250106 16:51:54.645325: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve } 20250106 16:51:54.645352: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpaxxybw9x 20250106 16:51:55.085153: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle. 20250106 16:51:56.061632: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpaxxybw9x 20250106 16:51:56.517300: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 1948307 microseconds. 20250106 16:52:30.233639: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3825] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s): Flex ops: FlexStridedSlice Details: 	tf.StridedSlice(tensor, tensor, tensor, tensor) > (tensor) : {begin_mask = 13 : i64, device = """", ellipsis_mask = 0 : i64, end_mask = 13 : i64, new_axis_mask = 2 : i64, shrink_axis_mask = 0 : i64} See instructions: https://www.tensorflow.org/lite/guide/ops_select 20250106 16:52:30.233666: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:3836] The following operation(s) need TFLite custom op implementation(s): Custom ops: XlaDynamicSlice Details: 	tf.XlaDynamicSlice(tensor, tensor, tensor) > (tensor) : {device = """"} See instructions: https://www.tensorflow.org/lite/guide/ops_custom ``` **Standalone code to reproduce the issue**  Provide a reproducible test case that is the bare minimum necessary to generate the problem. If possible, please share a link to Colab/Jupyter/any notebook. My reproduce code in Colab: https://colab.research.google.com/drive/1Rmhc_vpJSa7M1Vt4ugV5uORaEfRJMOw?usp=sharing Also, please include a link to a GraphDef or the model if possible. **Any other info / logs** Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2025-01-06T10:46:54Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.18,closed,0,5,https://github.com/tensorflow/tensorflow/issues/84203,"Hi,   I apologize for the delayed response, I tried to replicate the same behavior from my end with your Google colab notebook and I'm also getting the same error message `RuntimeError: Encountered unresolved custom op: XlaDynamicSlice.` for reference here is gistfile so we'll have to dig more into this issue and will update you, thank you for bringing this issue to our attention Thank you for your cooperation and patience.","Hi,   I apologize for the delayed response, I see in provided output log it says : `The following operation(s) need TFLite custom op implementation(s):Custom ops: XlaDynamicSlice` so it's unsupported ops since the LiteRT( Formerly knowns as TFLite) builtin operator library only supports a limited number of TensorFlow operators, not every model is convertible. For details, refer to operator compatibility. To allow conversion, you'll have to provide their own custom implementation of an unsupported TensorFlow operator in LiteRT, known as a custom operator in your case `XlaDynamicSlice` Op for more details please refer this official documentation If it's not mandatory to use T5 model in your use case or project then you can give it try with other models which can fulfill your usecase/project need the alternatives to the T5 model, some prominent options include: GPT3 (and its variants like GPT3.5 and GPT4), BERT, RoBERTa, XLNet, FlanT5 (an enhanced version of T5) Thank you for your cooperation and patience.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
rag,copybara-service[bot],Improve signature runner test coverage by adding some tests of out-of-range cases.,Improve signature runner test coverage by adding some tests of outofrange cases.,2025-01-05T23:18:25Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84172
yi,copybara-service[bot],[stream_executor] Always return non-const pointer to device memory from DeviceMemory/DeviceMemoryBase,[stream_executor] Always return nonconst pointer to device memory from DeviceMemory/DeviceMemoryBase Constness of DeviceMemoryBase does not imply constness of underlying device memory (similar to how constness of absl::Span is not related to constness of underlying data),2025-01-04T04:22:01Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84132
yi,copybara-service[bot],Change IFRT and PjRt layout API to return `std::shared_ptr<const xla::PjRtLayout>` instead of `std::unique_ptr<xla::PjRtLayout>`,"Change IFRT and PjRt layout API to return `std::shared_ptr` instead of `std::unique_ptr` The current API design that uses `std::unique_ptr` has several issues: * The API requires `xla::PjRtLayout` to be copied in some scenarios, e.g., `xla::ifrt::Array` internally stores a layout and returns its copy every time `layout()` is called. This forces implementations to break the abstraction boundary because `xla::PjRtLayout` is an abstract class and `std::unique_ptr` is not copyable. The current implementation either stores `xla::Layout` and creates `xla::PjRtLayout` every time, or downcasts `xla::PjRtLayout` to `xla::PjRtXlaLayout` to perform the copy. * `xla::Layout` is expensive to copy (`sizeof(xla::Layout)` is 248 bytes as of 20250103) and copying `xla::PjRtXlaLayout` requires copying or moving `xla::Layout`. To address these two problems, this CL changes PjRt and IFRT APIs that return `xla::PjRtLayout` to instead use `std::shared_ptr`, so that PjRt layouts can be cheaply copied. Similar patterns have been used in other places such as `xla::ifrt::Sharding` and `xla::PjRtExecutable::GetHloModules()`. Some implementations have been updated to take advantage of this change. For example, `PjRtCApiBuffer::layout()` no longer performs a layout copy and instead reuses an internally cached instance of `std::shared_ptr`.",2025-01-04T01:34:43Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/84124
yi,dnmaster1,Tensortflow import issue after installation," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.18  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I resintalled Python and my Anaconda environment and reinstalled using pip from notebook. Please see attached installation log and then import logs  Standalone code to reproduce the issue ```shell pip install tensorflow Collecting tensorflow   Using cached tensorflow2.18.0cp312cp312win_amd64.whl.metadata (3.3 kB) Collecting tensorflowintel==2.18.0 (from tensorflow)   Using cached tensorflow_intel2.18.0cp312cp312win_amd64.whl.metadata (4.9 kB) Collecting abslpy>=1.0.0 (from tensorflowintel==2.18.0>tensorflow)   Using cached absl_py2.1.0py3noneany.whl.metadata (2.3 kB) Collecting astunparse>=1.6.0 (from tensorflowintel==2.18.0>tensorflow)   Using cached astunparse1.6.3py2.py3noneany.whl.metadata (4.4 kB) Collecting flatbuffers>=24.3.25 (from tensorflowintel==2.18.0>tensorflow)   Using cached flatbuffers24.12.23py2.py3noneany.whl.metadata (876 bytes) Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflowintel==2.18.0>tensorflow)   Using cached gast0.6.0py3noneany.whl.metadata (1.3 kB) Collecting googlepasta>=0.1.1 (from tensorflowintel==2.18.0>tensorflow)   Using cached google_pasta0.2.0py3noneany.whl.metadata (814 bytes) Collecting libclang>=13.0.0 (from tensorflowintel==2.18.0>tensorflow)   Using cached libclang18.1.1py2.py3nonewin_amd64.whl.metadata (5.3 kB) Collecting opteinsum>=2.3.2 (from tensorflowintel==2.18.0>tensorflow)   Using cached opt_einsum3.4.0py3noneany.whl.metadata (6.3 kB) Requirement already satisfied: packaging in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (24.1) Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,=3.20.3 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (4.25.3) Requirement already satisfied: requests=2.21.0 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (2.32.3) Requirement already satisfied: setuptools in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (75.1.0) Requirement already satisfied: six>=1.12.0 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.16.0) Collecting termcolor>=1.1.0 (from tensorflowintel==2.18.0>tensorflow)   Using cached termcolor2.5.0py3noneany.whl.metadata (6.1 kB) Requirement already satisfied: typingextensions>=3.6.6 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (4.11.0) Requirement already satisfied: wrapt>=1.11.0 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.14.1) Collecting grpcio=1.24.3 (from tensorflowintel==2.18.0>tensorflow)   Using cached grpcio1.68.1cp312cp312win_amd64.whl.metadata (4.0 kB) Collecting tensorboard=2.18 (from tensorflowintel==2.18.0>tensorflow)   Using cached tensorboard2.18.0py3noneany.whl.metadata (1.6 kB) Collecting keras>=3.5.0 (from tensorflowintel==2.18.0>tensorflow)   Using cached keras3.7.0py3noneany.whl.metadata (5.8 kB) Requirement already satisfied: numpy=1.26.0 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (1.26.4) Requirement already satisfied: h5py>=3.11.0 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorflowintel==2.18.0>tensorflow) (3.11.0) Collecting mldtypes=0.4.0 (from tensorflowintel==2.18.0>tensorflow)   Using cached ml_dtypes0.4.1cp312cp312win_amd64.whl.metadata (20 kB) Requirement already satisfied: wheel=0.23.0 in c:\users\dhima\anaconda3\lib\sitepackages (from astunparse>=1.6.0>tensorflowintel==2.18.0>tensorflow) (0.44.0) Requirement already satisfied: rich in c:\users\dhima\anaconda3\lib\sitepackages (from keras>=3.5.0>tensorflowintel==2.18.0>tensorflow) (13.7.1) Collecting namex (from keras>=3.5.0>tensorflowintel==2.18.0>tensorflow)   Using cached namex0.0.8py3noneany.whl.metadata (246 bytes) Collecting optree (from keras>=3.5.0>tensorflowintel==2.18.0>tensorflow)   Using cached optree0.13.1cp312cp312win_amd64.whl.metadata (48 kB) Requirement already satisfied: charsetnormalizer=2 in c:\users\dhima\anaconda3\lib\sitepackages (from requests=2.21.0>tensorflowintel==2.18.0>tensorflow) (3.3.2) Requirement already satisfied: idna=2.5 in c:\users\dhima\anaconda3\lib\sitepackages (from requests=2.21.0>tensorflowintel==2.18.0>tensorflow) (3.7) Requirement already satisfied: urllib3=1.21.1 in c:\users\dhima\anaconda3\lib\sitepackages (from requests=2.21.0>tensorflowintel==2.18.0>tensorflow) (2.2.3) Requirement already satisfied: certifi>=2017.4.17 in c:\users\dhima\anaconda3\lib\sitepackages (from requests=2.21.0>tensorflowintel==2.18.0>tensorflow) (2024.12.14) Requirement already satisfied: markdown>=2.6.8 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorboard=2.18>tensorflowintel==2.18.0>tensorflow) (3.4.1) Collecting tensorboarddataserver=0.7.0 (from tensorboard=2.18>tensorflowintel==2.18.0>tensorflow)   Using cached tensorboard_data_server0.7.2py3noneany.whl.metadata (1.1 kB) Requirement already satisfied: werkzeug>=1.0.1 in c:\users\dhima\anaconda3\lib\sitepackages (from tensorboard=2.18>tensorflowintel==2.18.0>tensorflow) (3.0.3) Requirement already satisfied: MarkupSafe>=2.1.1 in c:\users\dhima\anaconda3\lib\sitepackages (from werkzeug>=1.0.1>tensorboard=2.18>tensorflowintel==2.18.0>tensorflow) (2.1.3) Requirement already satisfied: markdownitpy>=2.2.0 in c:\users\dhima\anaconda3\lib\sitepackages (from rich>keras>=3.5.0>tensorflowintel==2.18.0>tensorflow) (2.2.0) Requirement already satisfied: pygments=2.13.0 in c:\users\dhima\anaconda3\lib\sitepackages (from rich>keras>=3.5.0>tensorflowintel==2.18.0>tensorflow) (2.15.1) Requirement already satisfied: mdurl~=0.1 in c:\users\dhima\anaconda3\lib\sitepackages (from markdownitpy>=2.2.0>rich>keras>=3.5.0>tensorflowintel==2.18.0>tensorflow) (0.1.0) Using cached tensorflow2.18.0cp312cp312win_amd64.whl (7.5 kB) Using cached tensorflow_intel2.18.0cp312cp312win_amd64.whl (390.3 MB) Using cached absl_py2.1.0py3noneany.whl (133 kB) Using cached astunparse1.6.3py2.py3noneany.whl (12 kB) Using cached flatbuffers24.12.23py2.py3noneany.whl (30 kB) Using cached gast0.6.0py3noneany.whl (21 kB) Using cached google_pasta0.2.0py3noneany.whl (57 kB) Using cached grpcio1.68.1cp312cp312win_amd64.whl (4.4 MB) Using cached keras3.7.0py3noneany.whl (1.2 MB) Using cached libclang18.1.1py2.py3nonewin_amd64.whl (26.4 MB) Using cached ml_dtypes0.4.1cp312cp312win_amd64.whl (127 kB) Using cached opt_einsum3.4.0py3noneany.whl (71 kB) Using cached tensorboard2.18.0py3noneany.whl (5.5 MB) Using cached termcolor2.5.0py3noneany.whl (7.8 kB) Using cached tensorboard_data_server0.7.2py3noneany.whl (2.4 kB) Using cached namex0.0.8py3noneany.whl (5.8 kB) Using cached optree0.13.1cp312cp312win_amd64.whl (292 kB) Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboarddataserver, optree, opteinsum, mldtypes, grpcio, googlepasta, gast, astunparse, abslpy, tensorboard, keras, tensorflowintel, tensorflow Successfully installed abslpy2.1.0 astunparse1.6.3 flatbuffers24.12.23 gast0.6.0 googlepasta0.2.0 grpcio1.68.1 keras3.7.0 libclang18.1.1 mldtypes0.4.1 namex0.0.8 opteinsum3.4.0 optree0.13.1 tensorboard2.18.0 tensorboarddataserver0.7.2 tensorflow2.18.0 tensorflowintel2.18.0 termcolor2.5.0 ```  Relevant log output ```shell import tensorflow as tf O/p  ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[2], line 1 > 1 import tensorflow as tf File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:85      83     sys.setdlopenflags(_default_dlopen_flags)      84 except ImportError: > 85   raise ImportError(      86       f'{traceback.format_exc()}'      87       f'\n\nFailed to load the native TensorFlow runtime.\n'      88       f'See https://www.tensorflow.org/install/errors '      89       f'for some common causes and solutions.\n'      90       f'If you need help, create an issue '      91       f'at https://github.com/tensorflow/tensorflow/issues '      92       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\dhima\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. ```",2025-01-03T19:35:37Z,type:bug,closed,0,7,https://github.com/tensorflow/tensorflow/issues/84119,"check python version ,I think it need 3.10 version because it was giving the similar type of error in 3.12 if still error persists try with gpu","Hi Manoj  I tried 3.10 ad 3.12. I don't believe they are now available for download. I also tried tensorflowcpu, but it didn't help. Where do you find tensorflowgpu? I don't have a GPU, but my CPU is ARM arch. Thanks Dhimant On Sat, Jan 4, 2025 at 6:22 AM Manoj Nayak ***@***.***> wrote: > check python version ,I think it need 3.10 version because it was giving > the similar type of error in 3.12 > if still error persists try with gpu > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >",Duplicate of https://github.com/tensorflow/tensorflow/issues/19584. Please do a search before opening new issues. Please only open new issues if there is information (like your CPU specs) that make your problem different than the existing one.,Are you satisfied with the resolution of your issue? Yes No,"I did search. You closed my previous issue. On Sun, Jan 5, 2025 at 9:37 AM Mihai Maruseac ***@***.***> wrote: > Duplicate of CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) > . Please do a > search before opening new issues. Please only open new issues if there is > information (like your CPU specs) that make your problem different than the > existing one. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >","Please reopen. This is not closed. On Sun, Jan 5, 2025 at 9:37 AM Mihai Maruseac ***@***.***> wrote: > Closed CC(Tensortflow import issue after installation)  as > completed. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >",Opening multiple issues can be considered as spam. Let's move discussion to just one issue.
yi,zzzHou01,"KeyError: ""There is no item named 'PetImages\\Cat\\0.jpg' in the archive"" When Running TensorFlow Locally(CPU) on Anaconda in VS Code."," Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.17.1  Custom code Yes  OS platform and distribution window11  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am a beginner and encountering an issue while trying to run TensorFlow locally using Anaconda in VS Code. The same code runs smoothly on Google Colab, but when executed locally, it fails during the dataset download process with the following error. What I've Tried Redownloading TensorFlow and TensorFlow Datasets to ensure they are up to date. Manually Unzipping the Dataset and verifying if 'PetImages/Cat/0.jpg' exists in the archive. Readjusting Python, TensorFlow, and TensorFlow Datasets Versions to match those in Colab by using Python 3.10.11 instead of Python 3.10.12. Recreating the Virtual Environment in Anaconda to ensure a clean setup. Downloading the Cats vs Dogs Dataset from Different Sources, but the issue persists. Asking ChatGPT for assistance, but the issue remains unresolved. Additional Information On Google Colab, the same code runs without any issues, and the dataset downloads successfully. In VS Code, the error consistently occurs during the dataset download process, indicating that 'PetImages/Cat/0.jpg' is missing from the archive. Network Stability: I have a stable internet connection, and downloads complete without interruption, but the error persists. Questions Why does the KeyError occur in VS Code but not in Google Colab? Could this be related to the way the dataset is being downloaded or unzipped locally? Are there any compatibility issues between the Python/TensorFlow versions and the dataset? Request for Help I would greatly appreciate any guidance or suggestions on how to resolve this issue. Thank you in advance for your assistance!  Standalone code to reproduce the issue ```shell import tensorflow_datasets as tfds import tensorflow as tf import numpy as np CatsVsDogs_OrgData, info=tfds.load(name='cats_vs_dogs', with_info=True,                   split=tfds.Split.TRAIN) ```  Relevant log output ```shell PS C:\Users\jbb86\桌面\圖樣辨識> & C:/Users/jbb86/桌面/圖樣辨識/.venv/Scripts/python.exe c:/Users/jbb86/桌面/圖樣辨識/.venv/CatsVsDogs.py 20250103 22:38:53.599253: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. 20250103 22:38:54.247816: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floatingpoint roundoff errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`. Downloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\Users\jbb86\tensorflow_datasets\cats_vs_dogs\4.0.1... Dl Size...: 100% 824887076/824887076 [00:00     CatsVsDogs_OrgData, info=tfds.load(name='cats_vs_dogs', with_info=True,   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\logging\__init__.py"", line 176, in __call__     return function(*args, **kwargs)   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\load.py"", line 661, in load     _download_and_prepare_builder(dbuilder, download, download_and_prepare_kwargs)   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\load.py"", line 517, in _download_and_prepare_builder     dbuilder.download_and_prepare(**download_and_prepare_kwargs)   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\logging\__init__.py"", line 176, in __call__     return function(*args, **kwargs)   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\dataset_builder.py"", line 756, in download_and_prepare     self._download_and_prepare(   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\dataset_builder.py"", line 1752, in _download_and_prepare     split_infos = self._generate_splits(dl_manager, download_config)   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\dataset_builder.py"", line 1727, in _generate_splits     future = split_builder.submit_split_generation(   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\split_builder.py"", line 436, in submit_split_generation     return self._build_from_generator(**build_kwargs)   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\core\split_builder.py"", line 496, in _build_from_generator     for key, example in utils.tqdm(   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tqdm\std.py"", line 1181, in __iter__     for obj in iterable:   File ""C:\Users\jbb86\桌面\圖樣辨識\.venv\lib\sitepackages\tensorflow_datasets\image_classification\cats_vs_dogs.py"", line 117, in _generate_examples     new_fobj = zipfile.ZipFile(buffer).open(fname)   File ""C:\Users\jbb86\AppData\Local\Programs\Python\Python310\lib\zipfile.py"", line 1516, in open     zinfo = self.getinfo(name)   File ""C:\Users\jbb86\AppData\Local\Programs\Python\Python310\lib\zipfile.py"", line 1443, in getinfo     raise KeyError( KeyError: ""There is no item named 'PetImages\\\\Cat\\\\0.jpg' in the archive"" ```",2025-01-03T14:48:36Z,type:others awaiting PR merge 2.17,open,0,7,https://github.com/tensorflow/tensorflow/issues/84104,", Could you please provide the document which you are following to execute the code so that it helps to debug the issue. Thank you!","> , Could you please provide the document which you are following to execute the code so that it helps to debug the issue. Thank you! Thank you for your response! I am following the TensorFlow Cats vs Dogs tutorial provided on the official TensorFlow website. Source:https://www.tensorflow.org/tutorials/images/transfer_learning","I can replicate the issue on Windows 10 with TF 2.18, python 3.12 and tensorflowdatasets 4.9.7. It doesn't happen on Colab or MacOS.  I believe the issue has to do with how the file path is parsed in Windows vs Unix/Linux. I'll send out a CL to fix this shortly. This fix is going to be in tensorflow/datasets by the way.  Also, this is probably a duplicate of issues/3918 in tensorflow/datasets.  There is a hacky fix available in the issuecomment1892835410 in the meantime.","This fix for this was merged to tensorflow/datasets through https://github.com/tensorflow/datasets/commit/9969ce542f4b0e1cbf0a085e8e0df11bccea5c17. Once there is a new release, the problem should be fixed.","> I can replicate the issue on Windows 10 with TF 2.18, python 3.12 and tensorflowdatasets 4.9.7. It doesn't happen on Colab or MacOS. >  > I believe the issue has to do with how the file path is parsed in Windows vs Unix/Linux. I'll send out a CL to fix this shortly. This fix is going to be in tensorflow/datasets by the way. >  > Also, this is probably a duplicate of issues/3918 in tensorflow/datasets. [](https://github.com/zzzHou01) There is a hacky fix available in the issuecomment1892835410 in the meantime. > 此修復已透過 tensorflow/datasets @ 9969ce5合併到 tensorflow/datasets 。一旦有新版本發布，該問題就會解決。 Thanks a lot for your detailed explanation! It helped me solve my problem. I really appreciate your support.",> 我可以在裝有 TF 2.18、python 3.12 和 tensorflowdatasets 4.9.7 的 Windows 10 上複製該問題。這在 Colab 或 MacOS 上不會發生。 >  > 我相信這個問題與 Windows 和 Unix/Linux 中檔案路徑的解析方式有關。我將很快發送 CL 來修復此問題。順便說一下，這個修復將在tensorflow/datasets中進行。 >  > 此外，這可能是tensorflow/datasets 中issues/3918的重複。[](https://github.com/zzzHou01)同時，issuecomment1892835410中有一個可用的駭客修復程序。 Thanks a lot for your detailed explanation! It helped me solve my problem. I really appreciate your support.,"> This fix for this was merged to tensorflow/datasets through tensorflow/datasets. Once there is a new release, the problem should be fixed. Thanks a lot for your detailed explanation! It helped me solve my problem. I really appreciate your support."
yi,dnmaster1,Tensorflow not supported on Windows + ARM CPUs," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.18  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I can't import tensorflow  Standalone code to reproduce the issue ```shell I can't import tensorflow. Installation is successful. I uninstalled and reinstalled ```  Relevant log output ```shell  ImportError                               Traceback (most recent call last) File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:70      69 try: > 70   from tensorflow.python._pywrap_tensorflow_internal import *      71  This try catch logic is because there is no bazel equivalent for py_extension.      72  Externally in opensource we must enable exceptions to load the shared object      73  by exposing the PyInit symbols with pybind. This error will only be      74  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      75       76  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[9], line 1 > 1 import tensorflow as tf File ~\anaconda3\Lib\sitepackages\tensorflow\__init__.py:40      37 _os.environ.setdefault(""ENABLE_RUNTIME_UPTIME_TELEMETRY"", ""1"")      39  Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596 > 40 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   pylint: disable=unusedimport      41 from tensorflow.python.tools import module_util as _module_util      42 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader File ~\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:85      83     sys.setdlopenflags(_default_dlopen_flags)      84 except ImportError: > 85   raise ImportError(      86       f'{traceback.format_exc()}'      87       f'\n\nFailed to load the native TensorFlow runtime.\n'      88       f'See https://www.tensorflow.org/install/errors '      89       f'for some common causes and solutions.\n'      90       f'If you need help, create an issue '      91       f'at https://github.com/tensorflow/tensorflow/issues '      92       f'and include the entire stack trace above this error message.') ImportError: Traceback (most recent call last):   File ""C:\Users\dhima\anaconda3\Lib\sitepackages\tensorflow\python\pywrap_tensorflow.py"", line 70, in      from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed. Failed to load the native TensorFlow runtime. See https://www.tensorflow.org/install/errors for some common causes and solutions. If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message. ```",2025-01-03T14:33:01Z,stat:awaiting tensorflower type:feature type:build/install subtype:windows TF 2.18,open,0,21,https://github.com/tensorflow/tensorflow/issues/84102,Duplicate of https://github.com/tensorflow/tensorflow/issues/19584. Please do a search before opening new issues. This is a very old issue and manifests because old PCs with Windows cannot load libraries needed by TF because they have very old architecture sets.,Are you satisfied with the resolution of your issue? Yes No,"I have brand new PC with snapdragon X plus. It is not working. It is in fact working on my old pc On Fri, Jan 3, 2025, 11:59 AM Mihai Maruseac ***@***.***> wrote: > Duplicate of CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) > . Please do a > search before opening new issues. This is a very old issue and manifests > because old PCs with Windows cannot load libraries needed by TF because > they have very old architecture sets. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >","Please don't close the issue. Yourassumotion is incorrect On Fri, Jan 3, 2025, 11:59 AM Mihai Maruseac ***@***.***> wrote: > Closed CC(Tensorflow not supported on Windows + ARM CPUs)  as > completed. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >",What are your CPU specs?,"[image: image.png] On Sat, Jan 4, 2025 at 12:09 PM Mihai Maruseac ***@***.***> wrote: > What are your CPU specs? > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >",The image is not getting displayed. Can you paste them instead as text?,"Device name Master2024 Processor Snapdragon(R) X Plus  X1P42100  Qualcomm(R) Oryon(TM) CPU 3.24 GHz Installed RAM 16.0 GB (15.6 GB usable) Device ID BE82051361FA4460944DDA3541AEED2D Product ID 003422133297204AAOEM System type 64bit operating system, ARMbased processor Pen and touch Pen and touch support with 10 touch points Windows specs Edition Windows 11 Home Version 24H2 Installed on ‎12/‎30/‎2024 OS build 26100.2605 Serial number YX0ECPSK Experience Windows Feature Experience Pack 1000.26100.36.0 On Sun, Jan 5, 2025 at 9:31 AM Mihai Maruseac ***@***.***> wrote: > The image is not getting displayed. Can you paste them instead as text? > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >","I think TensorFlow on Windows is only supported on Intel, not ARM. But this is indeed different than the other one, so reopening.","Confirmed that Windows support only exists for Intel CPUs. On https://pypi.org/project/tensorflow/files there is no Windows + ARM wheel. On https://pypi.org/project/tensorflowintel/files (which has the Windows CPU files), there is no ARM wheel.","This is also weird, because the pip installer should not have proceeded due to missing wheels. But, can you try installing the linux wheel, via WSL? Not guaranteed to work, but it might.","So my CPU configuration is not supported? On Mon, Jan 6, 2025, 8:36 AM Mihai Maruseac ***@***.***> wrote: > This is also weird, because the pip installer should not have proceeded > due to missing wheels. > > But, can you try installing the linux wheel, via WSL? Not guaranteed to > work, but it might. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >","What is ""missing wheels""? I will try WSL now and get back to you. On Mon, Jan 6, 2025, 8:36 AM Mihai Maruseac ***@***.***> wrote: > This is also weird, because the pip installer should not have proceeded > due to missing wheels. > > But, can you try installing the linux wheel, via WSL? Not guaranteed to > work, but it might. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >","> So my CPU configuration is not supported? It looks like that. It is different than CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) in that that issue refers to Intel CPUs that are too old and don't have AVX/AVX2 extensions, whereas here your CPU is ARM, which is a completely different instruction set. It needs files compiled specifically for this architecture and we currently only do that for Linux and Apple (due to Mac M* family). > What is ""missing wheels""? The unit of shipping a Python package is called a wheel. For most projects, there is just one single file for any combination of Python, operating system, architecture. But, since TF needs to compile C++ extensions and link to C Python code, TensorFlow needs to ship different files for different supported configurations. In this case, there is no file that can be served for Windows + ARM CPU. When installing a Python package (via `pip install`, but other installers should follow a relatively similar process), `pip` is looking at the list of files for the specified version and tries to find the one that matches all the architecture tags it knows (Python version, operating system, CPU architecture, GLIB version, manylinux standard, etc.). This ensures that what gets installed works on the system. There in an exception to the above process with CPU extensions: there is no tag for them (since they are quite a lot and can result in exponential explosion of configurations) so `pip` cannot determine them before downloading. This is why CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) exists: people have been trying to use TF on very old CPUs and the Windows error message is very confusing (compared to Linux/Mac where it states clearly that the instruction set is not supported). In your case, it is very weird that an ARM CPU and a Windows OS did result in a successful download, even though there is no wheel that matches these tags. > I will try WSL now and get back to you. I hope that works, but note that WSL support is best effort, added just so that people on Windows can run TF with some GPU support. Alternatively, and something I would recommend, is to use Colab. I'm actually using that for a lot of experiments and it's really nice.","I'm marking this as a subissue of CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) since it has the same behavior: CPUs that don't support AVX instructions sets (includes ARM ones) are not able to run TF. The only difference, and why this is not marked as duplicate, is that this is a totally different family of CPUs, and likely compiling from source on your own system will produce a wheel that works.","Thank you Mihai! When can I expect resolution? Also, is this something I can compile on my computer? If so, do you have instructions to compile? Thank you again for your help. Dhimant On Thu, Jan 16, 2025 at 4:35 PM Mihai Maruseac ***@***.***> wrote: > I'm marking this as a subissue of CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) >  since it has the > same behavior: CPUs that don't support AVX instructions sets (includes ARM > ones) are not able to run TF. The only difference, and why this is not > marked as duplicate, is that this is a totally different family of CPUs, > and likely compiling from source on your own system will produce a wheel > that works. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >","It is unclear when support will come. There is/was some work to support ARM CPUs on Mac, I think it might come to Linux and maybe windows later but unclear.  might have more details on the plan. Regarding compiling on own computer, that should definitely be possible. There are some instructions at https://www.tensorflow.org/install/source_windows but I haven't checked how up to date they are.","> There is/was some work to support ARM CPUs on Mac, I think it might come to Linux and maybe windows later but unclear To my knowledge there are no current plans to support arm on windows natively.  We do currently publish wheels for Linux and macOS arm64. ","> > So my CPU configuration is not supported? >  > It looks like that. It is different than  CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) in that that issue refers to Intel CPUs that are too old and don't have AVX/AVX2 extensions, whereas here your CPU is ARM, which is a completely different instruction set. It needs files compiled specifically for this architecture and we currently only do that for Linux and Apple (due to Mac M* family). >  > > What is ""missing wheels""? >  > The unit of shipping a Python package is called a wheel. For most projects, there is just one single file for any combination of Python, operating system, architecture. But, since TF needs to compile C++ extensions and link to C Python code, TensorFlow needs to ship different files for different supported configurations. In this case, there is no file that can be served for Windows + ARM CPU. >  > When installing a Python package (via `pip install`, but other installers should follow a relatively similar process), `pip` is looking at the list of files for the specified version and tries to find the one that matches all the architecture tags it knows (Python version, operating system, CPU architecture, GLIB version, manylinux standard, etc.). This ensures that what gets installed works on the system. >  > There in an exception to the above process with CPU extensions: there is no tag for them (since they are quite a lot and can result in exponential explosion of configurations) so `pip` cannot determine them before downloading. This is why  CC(Prebuilt binaries do not work with CPUs that do not have AVX instruction sets.) exists: people have been trying to use TF on very old CPUs and the Windows error message is very confusing (compared to Linux/Mac where it states clearly that the instruction set is not supported). >  > In your case, it is very weird that an ARM CPU and a Windows OS did result in a successful download, even though there is no wheel that matches these tags. >  > > I will try WSL now and get back to you. >  > I hope that works, but note that WSL support is best effort, added just so that people on Windows can run TF with some GPU support. >  > Alternatively, and something I would recommend, is to use Colab. I'm actually using that for a lot of experiments and it's really nice. I have the same issue. I am trying to use TensorFlow in a Windows VM running on my M2 Mac. Would you recommend collab for inference in production?", Were you able to compile Tensorflow yourself in your arm+windows setup as  suggested?,"No, I couldnt On Sun, Feb 9, 2025, 5:09 PM Sakhile Mamba ***@***.***> wrote: >   Were you able to compile > Tensorflow yourself in your arm+windows setup as  >  suggested? > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >"
yi,Myre29,Error occured when compling TensorFlow C++ interface with Bazel," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.15  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 6.1  GCC/compiler version 8.9  CUDA/cuDNN version 12.2 / 8.9.6.50  GPU model and memory _No response_  Current behavior? I want to install Tensorflow C++ interface, and have followed the version matching and procedure using Bazel. Previously I have encountered the error for rules_python file. The corresponding file has been downloaded and the corresponding url link has been revised in the WORKSPACE for this file. But when fetching repository  and unknownlinuxgnu, the following error occured. But I cannot find the url or the command for these two file that I can revise the link with the location of the corresponding file stated in the error information. The configuration information is as follows: ./configure You have bazel 6.1.0 installed. Please specify the location of python. [Default is /home/workspace/anaconda3/bin/python3]:  Found possible Python library paths:   /home/workspace/anaconda3/lib/python3.10/sitepackages Please input the desired Python library path to use.  Default is [/home/workspace/anaconda3/lib/python3.10/sitepackages] Do you wish to build TensorFlow with ROCm support? [y/N]: N No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]: y CUDA support will be enabled for TensorFlow. Do you wish to build TensorFlow with TensorRT support? [y/N]: N No TensorRT support will be enabled for TensorFlow. Found CUDA 12.2 in:     /usr/local/cuda12.2/targets/x86_64linux/lib     /usr/local/cuda12.2/targets/x86_64linux/include Found cuDNN 8 in:     /usr/local/cuda12.2/targets/x86_64linux/lib     /usr/local/cuda12.2/targets/x86_64linux/include Please specify a list of commaseparated CUDA compute capabilities you want to build with. You can find the compute capability of your device at: https://developer.nvidia.com/cudagpus. Each capability can be specified as ""x.y"" or ""compute_xy"" to include both virtual and binary GPU code, or as ""sm_xy"" to only include the binary code. Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 8.9]:  Do you want to use clang as CUDA compiler? [Y/n]: n nvcc will be used as CUDA compiler. Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:  Please specify optimization flags to use during compilation when bazel option ""config=opt"" is specified [Default is Wnosigncompare]:  Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N Not configuring the WORKSPACE for Android builds. Preconfigured Bazel build configs. You can use any of the below by adding ""config="" to your build command. See .bazelrc for more details. 	config=mkl         	 Build with MKL support. 	config=mkl_aarch64 	 Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	config=monolithic  	 Config for mostly static monolithic build. 	config=numa        	 Build with NUMA support. 	config=dynamic_kernels	 (Experimental) Build kernels into separate shared objects. 	config=v1          	 Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features: 	config=nogcp       	 Disable GCP support. 	config=nonccl      	 Disable NVIDIA NCCL support. Configuration finished  Standalone code to reproduce the issue ```shell bazel build config=opt config=cuda verbose_failures //tensorflow:libtensorflow_cc.so ```  Relevant log output ```shell WARNING: Download from https://github.com/indygreg/pythonbuildstandalone/releases/download/20231002/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz failed: class java.io.IOException connect timed out ERROR: An error occurred during the fetch of repository 'python_x86_64unknownlinuxgnu':    Traceback (most recent call last): 	File ""/home/workspace/.cache/bazel/_bazel_think/2d2d375446b702059350bd230a24520a/external/rules_python/python/repositories.bzl"", line 175, column 34, in _python_repository_impl 		rctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error downloading [https://github.com/indygreg/pythonbuildstandalone/releases/download/20231002/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz] to /home/workspace/.cache/bazel/_bazel_think/2d2d375446b702059350bd230a24520a/external/python_x86_64unknownlinuxgnu/temp11172848094686838309/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz: connect timed out ERROR: /home/workspace/Desktop/software/tensorflow2.15.0/WORKSPACE:36:27: fetching python_repository rule //external:python_x86_64unknownlinuxgnu: Traceback (most recent call last): 	File ""/home/workspace/.cache/bazel/_bazel_think/2d2d375446b702059350bd230a24520a/external/rules_python/python/repositories.bzl"", line 175, column 34, in _python_repository_impl 		rctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error downloading [https://github.com/indygreg/pythonbuildstandalone/releases/download/20231002/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz] to /home/workspace/.cache/bazel/_bazel_think/2d2d375446b702059350bd230a24520a/external/python_x86_64unknownlinuxgnu/temp11172848094686838309/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz: connect timed out ERROR: Error computing the main repository mapping: Encountered error while reading extension file 'requirements.bzl': no such package '//': no such package 'unknownlinuxgnu//': java.io.IOException: Error downloading [https://github.com/indygreg/pythonbuildstandalone/releases/download/20231002/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz] to /home/workspace/.cache/bazel/_bazel_think/2d2d375446b702059350bd230a24520a/external/python_x86_64unknownlinuxgnu/temp11172848094686838309/cpython3.10.13+20231002x86_64unknownlinuxgnuinstall_only.tar.gz: connect timed out Loading:      Fetching repository ; Restarting. 55s ```",2025-01-03T07:21:59Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.15,closed,0,4,https://github.com/tensorflow/tensorflow/issues/84042,", According to the official document, for tensorflow v2.15, the compiler is Clang 16.0.0. Every TensorFlow release is compatible with a certain version, for more information please take a look at the tested build configurations. https://www.tensorflow.org/install/sourcegpu Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
yi,jonasrsv42,Mixing Keras Layers and TF modules.," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.17  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tf.Module can trace tf.Variable but it cannot trace variables from tf.keras or tf.keras.Variable.   Standalone code to reproduce the issue ```shell class MockLayer(tf.Module):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)         self.m = tf.keras.Variable(tf.random.normal([5, 5]), name=""m"")         self.w = tf.keras.Variable(tf.random.normal([5, 5]), name=""w"")     def __call__(self, inputs):         return self.m * inputs layer1 = MockLayer() print([v.name for v in layer1.trainable_variables]) ``` is empty. ``` class MockLayer(tf.Module):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)         self.m = tf.Variable(tf.random.normal([5, 5]), name=""m"")         self.w = tf.Variable(tf.random.normal([5, 5]), name=""w"")     def __call__(self, inputs):         return self.m * inputs layer1 = MockLayer() print([v.name for v in layer1.trainable_variables]) ``` Works. Specifically I am more interested in keras layers like  ``` class MockLayer(tf.Module):     def __init__(self, *args, **kwargs):         super().__init__(*args, **kwargs)         self.norm = tf.keras.layers.LayerNormalization(*args, **kwargs)     def __call__(self, inputs):         return self.norm(inputs) ``` For which tracing does not appear to work.  I am interested in trying https://github.com/google/sequencelayers but they seem mostly broken on this TF version and python version due to the tracing issues.  I am curious to try fixing it, but not sure what's a supported path. Using keras layers in tf.Module does not work due to tracing issues.. and using Keras layers only does not work because Keras is missing many features like composite tensors.  Is there a way around this? :) ```  Relevant log output _No response_",2025-01-02T10:46:55Z,stat:awaiting response type:support stale comp:keras 2.17,closed,1,7,https://github.com/tensorflow/tensorflow/issues/84019,"I just hit the same issue trying to upgrade some code that was previously working on tensorflow 2.14; My setup is the same as described:    Top level `tf.Module`    Submodules are `keras.Model`s The kerasbased submodules are now not being detected at the `tf.Module` level because the reflection based implementation is explicitly looking for submodules that extend `tf.Module` (here). It appears that since the 2.16 release that switched to keras 3.X, `keras.Model` / `keras.layers.Layer` no longer extends `tf.Module` but instead only extends the underlying `AutoTrackable` class via its own `TFLayer` class (here). This contradicts / invalidates the tensorflow documentation here: > tf.keras.layers.Layer is the base class of all Keras layers, and it inherits from tf.Module. Looking through some issues in the keras repo, it appears this is intentional, unfortunately. Specifically this comment. There is a section in the keras documentation  about this and gives some direction for downgrading keras to v2 in order to support this structure.",", By default Tensorflow v2.17, v2.18 contains the Keras3.0.  As mentioned in this comment, Keras 3 design supports multiple backends (like JAX and PyTorch) in addition to TensorFlow. To achieve this, core classes like Model and Layer no longer rely on TensorFlow `tf.Module`. As a result, variable tracking within models and layers is no longer automatic. As this issue is more related to Keras, Kindly raise the request in the Kerasteam/keras repo for further discussion. Thank you!","I can raise it in Keras. But out of curiousity, I am trying to use tensorflow without Keras because Keras is missing features I want. (E.g Composite objects for Tensors)  But it seems with this split Tensorflow loses implementations for many common layers? Is there some intended replacement implementation of these layers for tensorflow if Keras will no longer work?  Or is the expectation that we should roll our own using tensorflow primitives for all the layers that used to be in tf.keras? ",It is unlikely that TF would get these layers.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
