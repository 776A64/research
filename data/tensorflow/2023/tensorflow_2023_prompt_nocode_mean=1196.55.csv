1161,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow在尝试将数据从CPU复制到GPU时遇到了问题)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.10  Custom code Yes  OS platform and distribution Window 10  Mobile device _No response_  Python version 3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA11.2和cuDNN8.1  GPU model and memory NVIDIA Tesla V100SXM232GB   Current behavior? 这是我RNN模型一运行代码运行的错误：InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized, 对于网上提出的解决方案1.GPU内存不足，我试过换成4个显卡的，还是出现同样的错误。2. TensorFlow版本问题：我现在的版本是2.10，但是我试过更换为2.4，2.5，2.6都是不行。3.减小你的批量大小（batch size），我试过改到batch size=2，也是同样的错误，4.我的TensorFlow和我的CUDA,cuDNN都是匹配的。5.关键是我这个模型的代码在CPU下运行是非常良好的，只是速度慢。改为GPU运行是为了提高速度，但是在GPU上一运行就出现这个错误。  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,starxinyi,TensorFlow在尝试将数据从CPU复制到GPU时遇到了问题," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.10  Custom code Yes  OS platform and distribution Window 10  Mobile device _No response_  Python version 3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA11.2和cuDNN8.1  GPU model and memory NVIDIA Tesla V100SXM232GB   Current behavior? 这是我RNN模型一运行代码运行的错误：InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized, 对于网上提出的解决方案1.GPU内存不足，我试过换成4个显卡的，还是出现同样的错误。2. TensorFlow版本问题：我现在的版本是2.10，但是我试过更换为2.4，2.5，2.6都是不行。3.减小你的批量大小（batch size），我试过改到batch size=2，也是同样的错误，4.我的TensorFlow和我的CUDA,cuDNN都是匹配的。5.关键是我这个模型的代码在CPU下运行是非常良好的，只是速度慢。改为GPU运行是为了提高速度，但是在GPU上一运行就出现这个错误。  Standalone code to reproduce the issue   Relevant log output _No response_",2023-12-28T12:20:44Z,stat:awaiting response type:build/install stale subtype:windows TF 2.10,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62703,MirroredStrategy策略默认使用NCCL进行通讯，NCCL是不支持Windows的。你可以尝试使用tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())代替。 当然，如果你不需要使用多卡并行计算，你可以直接去掉strategy = tf.distribute.MirroredStrategy()相关的代码。,"Hi **** , Check GPU Availability: Ensure that your machine has a GPU available, and TensorFlow correctly recognizes the GPU. You can use the following code to verify:  Make sure you can see the list of GPU devices without errors. Memory Settings: In your code, you've already set GPU memory growth, but sometimes it might be necessary to explicitly set GPU memory allocation. You can try the following code:  This ensures that TensorFlow allocates only the required GPU memory. TensorFlow Version Compatibility: Ensure that your TensorFlow version is compatible with your GPU drivers. Sometimes, specific TensorFlow and GPU driver versions need to be matched for stability. Thank you!","> 你好****, >  > 检查 GPU 可用性： 确保您的机器有可用的 GPU，并且 TensorFlow 可以正确识别 GPU。您可以使用以下代码来验证： >  >  >  > 确保您可以看到 GPU 设备列表且没有错误。 内存设置： 在代码中，您已经设置了 GPU 内存增长，但有时可能需要显式设置 GPU 内存分配。您可以尝试以下代码： >  >  >  > 这可确保 TensorFlow 仅分配所需的 GPU 内存。 TensorFlow 版本兼容性： 确保您的 TensorFlow 版本与 GPU 驱动程序兼容。有时，需要匹配特定的 TensorFlow 和 GPU 驱动程序版本以确保稳定性。 >  > 谢谢你！  我有可用的 GPU，你给的这个代码我本身也有，也确保TensorFlow 版本与 GPU 驱动程序兼容了",> MirroredStrategy策略默认使用NCCL进行通讯，NCCL是不支持Windows的。你可以尝试使用tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())代替。 当然，如果你不需要使用多卡资源计算，你可以直接去掉strategy = tf.distribute.MirroredStrategy()相关的代码。 我按照您说的进行修改，得到的还是这个问题InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.无法解决,您好，请问问题解决了吗?我也遇到了相同的问题,> TensorFlow Version Compatibility: 您好 请问解决了吗 我的代码也遇到了这个问题 而且在报错以前GPU会突然从百分之十左右飙升到100%的峰值，然后报错，我是nividia的T1000 4GB,", With the error mentioned, I suspect the issue might be due to memory growth. Could you please try limiting GPU memory growth using any of the methods listed in this guide. https://www.tensorflow.org/guide/gpulimiting_gpu_memory_growth Also could you please try using the latest Tensorflow version for windows which can be installed with WSL2. Refer the document here for installation instructions https://www.tensorflow.org/install/pip and let us know if you observe the same behavior in the latest Tensorflow version.  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1879,"以下是一个github上的tensorflow下的一个issue, 标题是(Model conversion crashed when feed data during quantization)， 内容是 ( 1. System information  OS Platform and Distribution: Ubuntu 22.04  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source):  install tensorflow==2.15.0  2. Code  Option B: Paste your code here or provide a link to a custom endtoend colab  Summary on the nonconverted ops:   * Accepted dialects: tfl, builtin, func  * NonConverted Ops: 317, Total Ops 1095, % nonconverted = 28.95 %  * 314 ARITH ops, 3 TF ops  arith.constant:  314 occurrences  (f32: 244, i1: 1, i32: 69)   (i1: 1, i32: 1)  tf.If:    3 occurrences  (f32: 3)   (f32: 114, i32: 8)   (i32: 1)   (f32: 35)   (f32: 1, i32: 1)   (f32: 8)   (f32: 2)   (i32: 1)   (f32: 8, i32: 1)   (i1: 2)   (f32: 85)   (f32: 2)   (f32: 13)   (i1: 2)   (i1: 1)   (i1: 1)   (i1: 1)   (i1: 1)   (f32: 60)   (f32: 94, i32: 7)   (i32: 4)   (f32: 8)   (i1: 1)   (i1: 1)   (f32: 110, i32: 6)   (f32: 30)   (f32: 6, i32: 2)   (f32: 17)   (f32: 30)   (f32: 18, i32: 6)   (f32: 34, i32: 5)   (f32: 25)   (i32: 1) 20231227 22:09:12.621978: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 30.250 G  ops, equivalently 15.125 G  MACs It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug. Traceback (most recent call last):   File ""/home/houcheng/workspace/whisper.play/tryforcedidsquantizedofficial/try3withgmconversionlite.py"", line 44, in      tflite_model_bin = converter.convert()     , args) was not true.tensorflow/lite/kernels/reduce.cc:445 std::apply(optimi)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,houcheng,Model conversion crashed when feed data during quantization," 1. System information  OS Platform and Distribution: Ubuntu 22.04  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source):  install tensorflow==2.15.0  2. Code  Option B: Paste your code here or provide a link to a custom endtoend colab  Summary on the nonconverted ops:   * Accepted dialects: tfl, builtin, func  * NonConverted Ops: 317, Total Ops 1095, % nonconverted = 28.95 %  * 314 ARITH ops, 3 TF ops  arith.constant:  314 occurrences  (f32: 244, i1: 1, i32: 69)   (i1: 1, i32: 1)  tf.If:    3 occurrences  (f32: 3)   (f32: 114, i32: 8)   (i32: 1)   (f32: 35)   (f32: 1, i32: 1)   (f32: 8)   (f32: 2)   (i32: 1)   (f32: 8, i32: 1)   (i1: 2)   (f32: 85)   (f32: 2)   (f32: 13)   (i1: 2)   (i1: 1)   (i1: 1)   (i1: 1)   (i1: 1)   (f32: 60)   (f32: 94, i32: 7)   (i32: 4)   (f32: 8)   (i1: 1)   (i1: 1)   (f32: 110, i32: 6)   (f32: 30)   (f32: 6, i32: 2)   (f32: 17)   (f32: 30)   (f32: 18, i32: 6)   (f32: 34, i32: 5)   (f32: 25)   (i32: 1) 20231227 22:09:12.621978: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2989] Estimated count of arithmetic ops: 30.250 G  ops, equivalently 15.125 G  MACs It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug. Traceback (most recent call last):   File ""/home/houcheng/workspace/whisper.play/tryforcedidsquantizedofficial/try3withgmconversionlite.py"", line 44, in      tflite_model_bin = converter.convert()     , args) was not true.tensorflow/lite/kernels/reduce.cc:445 std::apply(optimi",2023-12-27T14:16:18Z,stat:awaiting tensorflower type:bug comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.15,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62701,"Hi , I have reproduced the issue. It's getting crashed at the time of conversion. Here is the gist. The sampling rate recommendation in the error log is fixed by setting  and passed to the processor. Thank You","I was able to reproduce with the same gist, , can you please take a look? Thanks.","Hi all, is there anything can do for helping the progress? Thank you a lot.","Hi , thanks for your interest. It probably depends on your familiarity, if you're comfortable with C++ & Bazel please review these BUILD files: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/BUILD, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/BUILD. The binaries here effectively use the same codepaths as when you do converter.convert, you'll have to figure out how to use them properly for your use case, then you can use lldb/gdb with these binaries to try and debug this. Alternatively you can research how to attach lldb/gdb to a python process (the one that gets launched when you do `python your_script.py`) and set a breakpoint somewhere above `tensorflow/lite/kernels/reduce.cc:445`, and then dig into why that error is being thrown. Both of these require good C++ knowledge, so if you don't have that, you'll have to learn at least the basics first.","Hi , Thank you for kindly reply my questions. I've tried the bazel in my ubuntu before and it can compile okay by the default build script and works well. I think maybe I include too much code into the model code and there is some non primities python code caused the problem. I think I'll either reduce the features of the model or using the gdb breakpoints you mentioned for finding the exact problem, later.",", np, you may also want to directly use the converter CLT: https://www.tensorflow.org/lite/models/convert/convert_modelscommand_line_tool_, this is essentially an entry point into what converter.convert does but it skips the python wrappers.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/89 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
878,"以下是一个github上的tensorflow下的一个issue, 标题是(Adding new feature to perform reverse operation of tf.image.extract_patches)， 内容是 (Need of feature :  Will increase use of transformers in Computer Vision task, we need a way to efficient apply attention mechanism for images (unlike vision transformer which calculate attention for entire image). Here we can calculate attention over extracted patches for **purpose of Image Superresolution, Image Restoration**. Currently there is no feature in Tensorflow to do reverse operation of tf.image.extract_patches, hence I would like to contribute to this feature. Inspiration for feature :  Swin Transformer I would like to contribute for this feature. Could you please assign this task to me. Thank you)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,ash-S26,Adding new feature to perform reverse operation of tf.image.extract_patches,"Need of feature :  Will increase use of transformers in Computer Vision task, we need a way to efficient apply attention mechanism for images (unlike vision transformer which calculate attention for entire image). Here we can calculate attention over extracted patches for **purpose of Image Superresolution, Image Restoration**. Currently there is no feature in Tensorflow to do reverse operation of tf.image.extract_patches, hence I would like to contribute to this feature. Inspiration for feature :  Swin Transformer I would like to contribute for this feature. Could you please assign this task to me. Thank you",2023-12-26T17:36:13Z,stat:awaiting response type:feature stale comp:ops,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62697,"S26  Yes, TensorFlow doesn't offer a direct inverse function for tf.image.extract_patches, here are several approaches to reconstruct an image or approximate the reverse operation as GradientBased Reconstruction: 1. Use Gradient Tape: Employ tf.GradientTape to compute gradients of a loss function with respect to the extracted patches. 2. Update Patches: Iteratively update the patches to minimize the loss, aiming to reconstruct the original image. Please let us know more on the feature request you are proposing here with its usecase.   Thank you!","I conceived the idea when combining the patch merging concept from the Swin Transformer paper (https://arxiv.org/pdf/2103.14030.pdf) with the SwinIR Transformer (https://arxiv.org/pdf/2108.10257.pdf). **Background Explanation: ** The Swin Transformer is an architecture designed for image classification. It starts with an image, for example, of size (224,224,3), divides it into patches of size (4,4), creating a new dimensional vector of shape (56,56,344). Attention is then calculated within small windows of size 7. In the next stage, patch merging combines adjacent patches (e.g., at indices [0,0], [0,1], [1,0], [1,1]), resulting in an output shape of (56/2,56/2,344*4). The process is repeated, and the final stage includes flattening the layers. Currently, the SwinIR Transformer, designed for image superresolution, does not utilize the patch merging concept. It maintains the same image size while calculating attention within a single window of size 7 and a small shifted window. **UseCase (Why this feature came to my mind): ** The goal is to integrate the benefits of patch merging into SwinIR, enabling the capture of globallevel attention with reduced computation cost, thus enhancing the model. During the implementation, I observed an easy way to reach the last merging step but lacked a tool in TensorFlow to reverse the process (i.e., unpatch the image), placing pixels back in their original positions. This approach results in the next block containing pixels in their original positions but with more context/attention captured over the image. I raised this issue to propose the addition of this feature. Also I am enthusiastic about contributing to the implementation of Swin Transformer and SwinIR Transformer for the official TensorFlow repository. I would appreciate the opportunity to create and contribute this feature.  Please let me know if you need additional information on this topic. Thank you!","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. For simple patch extraction methods (e.g., nonoverlapping patches), you might be able to reshape the extracted patches back into the original image dimensions The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1946,"以下是一个github上的tensorflow下的一个issue, 标题是(Reduce TensorFlow Lite binary size(Build custom C/C++ shared libraries on android) For the models with the Select TF ops fail.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tflite 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version 6.3.2homebrew  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I follow the document(https://www.tensorflow.org/lite/guide/reduce_binary_size), want to build the reduce android tensorflowlite_flex so. But occur some error. Repository rule _tf_http_archive defined at:   /Users/qinlong/android/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository boringssl instantiated at:   /Users/qinlong/android/tensorflow/WORKSPACE:15:14: in    /Users/qinlong/android/tensorflow/tensorflow/workspace2.bzl:938:21: in workspace   /Users/qinlong/android/tensorflow/tensorflow/workspace2.bzl:562:20: in _tf_repositories   /Users/qinlong/android/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   /Users/qinlong/android/tensorflow/third_party/repo.bzl:89:35: in  ERROR: /private/var/tmp/_bazel_qinlong/4d0b12327583c8b4e37f0824509a394f/external/llvmproject/llvm/BUILD.bazel:154:11: Illegal ambiguous match on configurable attribute ""defines"" in project//llvm:config: project//llvm:macos_arm64 //src/conditions:darwin Multiple matches are not allowed unless one is unambiguously more specialized or they resolve to the same value. See https://bazel.build/reference/be/functionsselect. ERROR: Analysis of target '//tmp:tensorflowlite_flex' failed; build abort)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Qinlong275,Reduce TensorFlow Lite binary size(Build custom C/C++ shared libraries on android) For the models with the Select TF ops fail.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tflite 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version 6.3.2homebrew  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I follow the document(https://www.tensorflow.org/lite/guide/reduce_binary_size), want to build the reduce android tensorflowlite_flex so. But occur some error. Repository rule _tf_http_archive defined at:   /Users/qinlong/android/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository boringssl instantiated at:   /Users/qinlong/android/tensorflow/WORKSPACE:15:14: in    /Users/qinlong/android/tensorflow/tensorflow/workspace2.bzl:938:21: in workspace   /Users/qinlong/android/tensorflow/tensorflow/workspace2.bzl:562:20: in _tf_repositories   /Users/qinlong/android/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   /Users/qinlong/android/tensorflow/third_party/repo.bzl:89:35: in  ERROR: /private/var/tmp/_bazel_qinlong/4d0b12327583c8b4e37f0824509a394f/external/llvmproject/llvm/BUILD.bazel:154:11: Illegal ambiguous match on configurable attribute ""defines"" in project//llvm:config: project//llvm:macos_arm64 //src/conditions:darwin Multiple matches are not allowed unless one is unambiguously more specialized or they resolve to the same value. See https://bazel.build/reference/be/functionsselect. ERROR: Analysis of target '//tmp:tensorflowlite_flex' failed; build abort",2023-12-26T02:20:55Z,stat:awaiting response type:bug type:build/install stale comp:lite TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62692, Please ensure your models are compatible with the Select TF ops feature. Register any custom ops with the selective build system. Make sure to use Bazel to build an AAR file containing the selective TensorFlow Lite library and include the AAR in your Android project. Please let us know if it works? Thank you!,">  Please ensure your models are compatible with the Select TF ops feature. Register any custom ops with the selective build system. Make sure to use Bazel to build an AAR file containing the selective TensorFlow Lite library and include the AAR in your Android project. Please let us know if it works? >  > Thank you!  I just follw the link https://www.tensorflow.org/lite/guide/reduce_binary_size, want to build the reduce libtensorflowlite_flex.so, use these code: load(     ""//tensorflow/lite/delegates/flex:build_def.bzl"",     ""tflite_flex_shared_library"" )  Shared lib target for convenience, pulls in the standard set of TensorFlow  ops and kernels. The output library name is platform dependent:     Linux/Android: `libtensorflowlite_flex.so`     Mac: `libtensorflowlite_flex.dylib`     Windows: `libtensorflowlite_flex.dll` tflite_flex_shared_library(   name = ""tensorflowlite_flex"",   models = [       "":FRCRN_model.tflite"",   ], ) bazel build c opt cxxopt='std=c++17' \       config=android_arm \       config=monolithic \       host_crosstool_top=//tools/cpp:toolchain \       //tmp:tensorflowlite_flex And my model is transfer with select op use the link https://www.tensorflow.org/lite/guide/ops_select?hl=zhcn: import tensorflow as tf converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) converter.target_spec.supported_ops = [   tf.lite.OpsSet.TFLITE_BUILTINS,  enable TensorFlow Lite ops.   tf.lite.OpsSet.SELECT_TF_OPS  enable TensorFlow ops. ] tflite_model = converter.convert() open(""converted_model.tflite"", ""wb"").write(tflite_model)","Hi , can you share your /tmp/BUILD file? It's created here as part of the instructions: https://www.tensorflow.org/lite/guide/reduce_binary_sizeadvanced_usages_build_custom_cc_shared_libraries",> 你好，你能分享你的 /tmp/BUILD 文件吗？它是作为说明的一部分在此处创建的： https: //www.tensorflow.org/lite/guide/reduce_binary_sizeadvanced_usages_build_custom_cc_shared_libraries [Uploading tmp.zip…](),This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1889,"以下是一个github上的tensorflow下的一个issue, 标题是(Numerical precision of tf.math.cumsum operation on float32 vs float64)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Linux, MacOS M1 Chip  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I would like to report an interesting observation regarding numerical precision of cumsum operations implemented by Tensorflow (`tensorflow==2.15.0`), PyTorch (`torch==2.1.0`), and NumPy (`numpy==1.26.2`). I have tested the example script (pasted in the Standalone code to reproduce the issue)  that compares the cumulative sum of  a large array of numbers. On MacOS Sonoma 14.1.1, MacBook Pro 2021 Apple M1 Pro machine, I have obtained the following results:  On Colab with CPU (Linux OS) instance using the same versions of the library, I have  Both are saying, on CPU, Tensorflow obtains the same result as NumPy, which loses certain degree of numerical precision in the result of cumsum with float32 inputs. PyTorch, however, does not lose much of the precision. However, if I run the same code on Colab with GPU (with Linux OS), using identical versions of the library, I have:  This shows that Tensorflow does not lose much precision on GPU, though slightly more than PyTorch. NumPy still loses precision (since it still uses CPU). This is an interesting observation. The behavior of PyTorch's cumsum seems more desirable, since it can significantly cut down memory during inference time while retaining certain numerical precisi)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sapphire008,Numerical precision of tf.math.cumsum operation on float32 vs float64," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Linux, MacOS M1 Chip  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I would like to report an interesting observation regarding numerical precision of cumsum operations implemented by Tensorflow (`tensorflow==2.15.0`), PyTorch (`torch==2.1.0`), and NumPy (`numpy==1.26.2`). I have tested the example script (pasted in the Standalone code to reproduce the issue)  that compares the cumulative sum of  a large array of numbers. On MacOS Sonoma 14.1.1, MacBook Pro 2021 Apple M1 Pro machine, I have obtained the following results:  On Colab with CPU (Linux OS) instance using the same versions of the library, I have  Both are saying, on CPU, Tensorflow obtains the same result as NumPy, which loses certain degree of numerical precision in the result of cumsum with float32 inputs. PyTorch, however, does not lose much of the precision. However, if I run the same code on Colab with GPU (with Linux OS), using identical versions of the library, I have:  This shows that Tensorflow does not lose much precision on GPU, though slightly more than PyTorch. NumPy still loses precision (since it still uses CPU). This is an interesting observation. The behavior of PyTorch's cumsum seems more desirable, since it can significantly cut down memory during inference time while retaining certain numerical precisi",2023-12-24T05:14:53Z,stat:awaiting response type:bug stale comp:ops TF 2.15,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62687,"Hi **** ,  I was able to reproduce this issue on Colab using TF v2.15, TFnightly, Please find the gist, gist1 here for reference.  Thank you!","Hi , I reproduced this issue with latest versions of all libraries, could you please refer to this gist file. TensorFlow matches NumPy in precision for `float32` on the CPU because may be they use similar internal approaches. However, TensorFlow achieves better precision on the GPU. PyTorch consistently delivers the best precision for `float32` on both CPU and GPU. NumPy, being limited to CPUbased computation, shows the most significant precision loss for `float32`. For critical operations that demand high precision, it's best to use `float64` across all libraries. If you're restricted to `float32`, PyTorch or TensorFlow on GPU is the better choice for maintaining accuracy. Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1290,"以下是一个github上的tensorflow下的一个issue, 标题是(model detects hand as a face. I cant retrieve confidence score from  tfjs-models/face-detection)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version last version  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In mediapipe model documentation (see: https://drive.google.com/file/d/1d4xJP9PVzOvMBDgIjz6NhvpnlG9_i0S/preview) it says that alongside with bounding box coordinates and keypoints, confidence score should be also returned.  But there is no info about that in facedetection github repo and in the code.  In facedetection Demo, you can see for yourself that fists are displayed as faces. I need confidence score to prevent this action. https://storage.googleapis.com/tfjsmodels/demos/facedetection/index.html?model=mediapipe_face_detector  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,DiannaShonia,model detects hand as a face. I cant retrieve confidence score from  tfjs-models/face-detection," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version last version  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In mediapipe model documentation (see: https://drive.google.com/file/d/1d4xJP9PVzOvMBDgIjz6NhvpnlG9_i0S/preview) it says that alongside with bounding box coordinates and keypoints, confidence score should be also returned.  But there is no info about that in facedetection github repo and in the code.  In facedetection Demo, you can see for yourself that fists are displayed as faces. I need confidence score to prevent this action. https://storage.googleapis.com/tfjsmodels/demos/facedetection/index.html?model=mediapipe_face_detector  Standalone code to reproduce the issue   Relevant log output _No response_",2023-12-22T13:50:35Z,stat:awaiting response type:bug stale,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62683," Please ensure that you're using a model version that provides confidence scores. Some older versions might not provide the same. Also try to raise the minimum confidence score required for a detection to be considered a face. This can filter out less confident detections, potentially reducing false positives. This issue is related to tfjs so for any further questions , could you please post this issue in tfjs repository? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
782,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistance tensor shape led to code can't execute properly )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.10.0  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The code led to inconsistance tensor shape addition and can't run properly ,please help   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gpt,xsmilingtoast,Inconsistance tensor shape led to code can't execute properly ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.10.0  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The code led to inconsistance tensor shape addition and can't run properly ,please help   Standalone code to reproduce the issue   Relevant log output ",2023-12-22T09:58:37Z,stat:awaiting response type:bug stale comp:apis TF 2.10,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62681,"Hi **** , Could you provide a proper link. You already provide one link but it is not opening. In order to expedite the troubleshooting process, please provide a code snippet to reproduce the issue reported here. And here you are using the old version, Try to update your version. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1838,"以下是一个github上的tensorflow下的一个issue, 标题是(LLVM Errors on pre-built tensorflow)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8/8.9.7  GPU model and memory NVIDIA RTX3090 (24GB)  Current behavior? While trying to train an SAC reinforcement learner on Continual World  a spinoff of the Farama Foundation MetaWorld  I am getting what looks like an LLVM build error any time a .function decorator is used. Specifically the error is:   It seems like this type of error exists in a lot of other ecosystems, but almost always is an issue with code built from source. Mine is a binary, installed through pip in an environment managed by conda, so I would expect that it would work  Standalone code to reproduce the issue  shell 20231221 16:11:30.774908: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalidaddress errors. 20231221 16:11:30.776085: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver. if not exploring : CommandLine Error: Option 'helplist' registered more than once! LLVM ERROR: inconsistency in registered CommandLine options [1]    1542478 abort (core dumped)  /home/balloch/miniconda3/envs/meta_world/bin/python ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,balloch,LLVM Errors on pre-built tensorflow," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8/8.9.7  GPU model and memory NVIDIA RTX3090 (24GB)  Current behavior? While trying to train an SAC reinforcement learner on Continual World  a spinoff of the Farama Foundation MetaWorld  I am getting what looks like an LLVM build error any time a .function decorator is used. Specifically the error is:   It seems like this type of error exists in a lot of other ecosystems, but almost always is an issue with code built from source. Mine is a binary, installed through pip in an environment managed by conda, so I would expect that it would work  Standalone code to reproduce the issue  shell 20231221 16:11:30.774908: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalidaddress errors. 20231221 16:11:30.776085: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver. if not exploring : CommandLine Error: Option 'helplist' registered more than once! LLVM ERROR: inconsistency in registered CommandLine options [1]    1542478 abort (core dumped)  /home/balloch/miniconda3/envs/meta_world/bin/python ```",2023-12-21T22:02:00Z,stat:awaiting response type:bug comp:ops TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62678, Could you please review your environment for other libraries that might conflict with LLVM or TensorFlow's build configuration and try to reinstall TensorFlow using `pip install forcereinstall tensorflow `to ensure clean installation and proper linking. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,tried with `forcereinstall` . No change,"Hi  , From the log I see an error related to `ptxas` version compatibility. This is generally associated with cuda toolkit. From Tf2.14v TF provides CUDA packaged tensorflow with the command `pip install tensorflow[andcuda]==2.14`. Can you try installing cuda package using above command and let us know the outcome. Thanks! Note: Please try with fresh installation of tensorflow deleting previously installed packages.","I think I figured it out...ish. If I use `conda` to first install the `cuda 11.8` toolkit first then the following tf install works, but its odd that just installing tf doesn't work. for anyone interested in the future, the specific command was:  where for the conda channel (`c`), XX is the major cuda version, YY is the minor cuda version, and ZZ is the patchfix version. For me because of my NDIVIA driver version, I need to work with cuda<12, so for me the command that worked was: ",Are you satisfied with the resolution of your issue? Yes No
1520,"以下是一个github上的tensorflow下的一个issue, 标题是(How to determine next token indices and slice output tensor in concrete function utilizing model prediction via model(prompt))， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):    Mac, so running this via Google Colab  TensorFlow installation (pip package or built from source):    built via `pip install https://github.com/kerasteam/kerasnlp.gitio2023`  TensorFlow library (version, if pip package or github SHA, if built from source):    `tensorflowtext==2.12`  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab  I haven't included my export/conversion to TFLite but everything there is working fine. In the concrete function I'm topk sampling (25) which means my output of this function is 255*25 tokens long. My question is to how I could understand where the next token lies in this 255 output sequence and only return that, making my output an int32[] of size 25? If I was to do this outside of the `tf.function`, I would manually tokenize the input prompt, get the shape of the resulting tensor, and slice the model's output using that shape. However I understand that I cannot due this inside the `tf.function`. Is it possible to perform the same kind of logic using tf builtins?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gpt,andrew-lyons,How to determine next token indices and slice output tensor in concrete function utilizing model prediction via model(prompt)," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):    Mac, so running this via Google Colab  TensorFlow installation (pip package or built from source):    built via `pip install https://github.com/kerasteam/kerasnlp.gitio2023`  TensorFlow library (version, if pip package or github SHA, if built from source):    `tensorflowtext==2.12`  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab  I haven't included my export/conversion to TFLite but everything there is working fine. In the concrete function I'm topk sampling (25) which means my output of this function is 255*25 tokens long. My question is to how I could understand where the next token lies in this 255 output sequence and only return that, making my output an int32[] of size 25? If I was to do this outside of the `tf.function`, I would manually tokenize the input prompt, get the shape of the resulting tensor, and slice the model's output using that shape. However I understand that I cannot due this inside the `tf.function`. Is it possible to perform the same kind of logic using tf builtins?",2023-12-21T21:37:18Z,stat:awaiting response type:build/install stale comp:keras subtype:macOS TFLiteConverter TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62677,"Hi **lyons** , Could you consider techniques like:Optimizing tensor slicing operations. Using XLA (Accelerated Linear Algebra) compilation for faster computations. I hope it will be useful to you. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
784,"以下是一个github上的tensorflow下的一个issue, 标题是(When converting to tflite Input/Output tensor names are present in the signature but not maintained)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 22.04  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.15  2. Code   Returns:    5. Ideal result Input/Output names same as the ones in the signature def.  Is this something that can be done (as when converting with the Ambarella toolchain for CV25 this appears to be an issue due to the extra :0 tag) ?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,fixedit-dimitris,When converting to tflite Input/Output tensor names are present in the signature but not maintained," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 22.04  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.15  2. Code   Returns:    5. Ideal result Input/Output names same as the ones in the signature def.  Is this something that can be done (as when converting with the Ambarella toolchain for CV25 this appears to be an issue due to the extra :0 tag) ?",2023-12-21T15:24:45Z,stat:awaiting response comp:lite subtype: ubuntu/linux TFLiteConverter TF 2.15,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62674,"Hi dimitris , Could you please provide  model to reproduce the code. Thank You","> Hi dimitris , Could you please provide `reshape_v2_finetuned` model to reproduce the code. Thank You Hi there, unfortunately i cannot share that. However I managed to solve the issue by converting using a concrete function.   This gives the following outputs:  "
911,"以下是一个github上的tensorflow下的一个issue, 标题是(CMake Error in linux alpine/Ubuntu)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15.0  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When trying to install tflite C++ using CMake, am getting errors such as absl_flags, absl_hash, etc...  However using bazel these libraries are installed automatically internally. How to achieve same using CMake? Requesting help on same. Thanks  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,acode-x,CMake Error in linux alpine/Ubuntu," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15.0  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When trying to install tflite C++ using CMake, am getting errors such as absl_flags, absl_hash, etc...  However using bazel these libraries are installed automatically internally. How to achieve same using CMake? Requesting help on same. Thanks  Standalone code to reproduce the issue   Relevant log output ",2023-12-20T10:52:11Z,stat:awaiting response type:support stale comp:lite TF 2.15,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62668,"If I need to install them manually, what all libraries I need to download?","x Include paths shouldn't be relative to the build directory, as this can cause issues when installing or using the library elsewhere. So try to locate the line in tools/cmake/modules/ml_dtypes/CMakeLists.txt setting the INTERFACE_INCLUDE_DIRECTORIES property. Please refer to this doc to refer to the TensorFlow Lite CMake documentation for specific instructions and examples. Please modify it to use absolute or relative paths not tied to the build directory. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1306,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite conversion (w/ int8 quantization) from ConcreteFunction is broken)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 22H2 (but reproducible elsewhere)  TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source): 2.14.0  2. Code Provide code to help us reproduce your issues using one of the following options: `https://colab.research.google.com/drive/1amt2AeayTFDpZRcUzdROH1Jf7K03gF_`  3. Failure after conversion N/A  4. (optional) RNN conversion support N/A  5. (optional) Any other info / logs TFLite converter fails on calibration step when trying to convert ConcreteFunctions with int8 quantization.  It seems that somewhere during the process it generates a saved model without any signatures, which leads to fail on calibration.  I tried toggling `converter.experimental_lower_to_saved_model`, it does nothing in this case.  As a workaround, `tf.lite.TFLiteConverter.from_keras_model()` does work as intended, but I'd like the dedicated CF conversion pipeline to be fixed.  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DLumi,TFLite conversion (w/ int8 quantization) from ConcreteFunction is broken," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 22H2 (but reproducible elsewhere)  TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source): 2.14.0  2. Code Provide code to help us reproduce your issues using one of the following options: `https://colab.research.google.com/drive/1amt2AeayTFDpZRcUzdROH1Jf7K03gF_`  3. Failure after conversion N/A  4. (optional) RNN conversion support N/A  5. (optional) Any other info / logs TFLite converter fails on calibration step when trying to convert ConcreteFunctions with int8 quantization.  It seems that somewhere during the process it generates a saved model without any signatures, which leads to fail on calibration.  I tried toggling `converter.experimental_lower_to_saved_model`, it does nothing in this case.  As a workaround, `tf.lite.TFLiteConverter.from_keras_model()` does work as intended, but I'd like the dedicated CF conversion pipeline to be fixed.  ",2023-12-19T09:29:22Z,stat:awaiting tensorflower type:support comp:lite TFLiteConverter TF2.14,closed,0,16,https://github.com/tensorflow/tensorflow/issues/62664,"  Please ensure you provide a representative dataset during conversion for accurate calibration and doublecheck quantization parameters, especially those related to calibration. Also try different quantization options to find optimal settings. In order to expedite the troubleshooting process, please provide a code snippet to reproduce the issue reported here. Thank you!"," Can you please explain to me how providing a dataset of actual data instead of randomized dummy would actually help with a conversion error?  Edit: Apparently, github does not like links that end with an underscore, so I formatted it as a code block, please, try to access the file once again. Please disregard whatever was there regarding you accessing the colab file","Hi  , Sorry for the delay. The error with code is due to incorrect representative dataset usage. Please find the corrected code. Please let us know if problem persists. Thank You.", Could you please point me out what part was / needs to be changed?  I compared my colab notebook with yours cell by cell and couldn't really spot the corrected part. ,"Hi ,  In my previous post, code link is not redirecting to corrected code. Please find the corrected code below. Here is the detailed gist.  Thank You"," so, basically, the main change is to yield a list of tensors instead of a dict? But that's more of a workaround than a fix, don't you think?  Because as far as I'm concerned, TFLite is meant to be fed with dictionaries as well. You can run inference on dictionaries with TFLite, and the converter initialized from keras model can digest representative datasets that yield dictionaries as well.  So I guess, thanks for the workaround, but can we probably have an actual fix for this so that the behavior of the converter is consistent?  P.S. I've updated the initial code at `https://colab.research.google.com/drive/1amt2AeayTFDpZRcUzdROH1Jf7K03gF_` to add cells representing conversion from keras model (just in case you need this context, although, it's just one line of the difference)","Hi  , Yes, you are right, the TFlite models initialized from Keras model works with representative datasets that yield dictionaries also.  In the code, as the concrete function with signature  is used, it is suggestible to pass concrete function to converter rather than a base keras model. Thank You"," I dunno about what's suggestible and what is not, but if there is a public API that helps me do stuff I want  I use it. And if there are multiple APIs for the same thing I assume they are consistent, which is not the case here. To achieve consistency I'd propose to either fix the bug preventing calibration process (CF converter) to feed on dictionaries, or to prohibit dictionaries altogether, i.e. disallowing the use of them in `from_keras_model` API and providing a clear understandable error message instead of confusing error that is present now.  In either case, I'd also correct documentation to explicitly say what data structures are expected to be yielded from representative datasets, as now it's not as clear as it potentially could be. ","Hi , Please look into the issue. Thank You","Hi, , is there a resource/documentation which shows that the dictionary workflow is supported? I'm trying to figure out if this a regression or an API change,  https://www.tensorflow.org/lite/models/convert/convert_modelsconvert_concrete_functions_ is the current way that is supported/recommended. Thanks for your help.","  Actually, now that I remember, it was per documentation, yes. https://www.tensorflow.org/lite/performance/post_training_quantizationfull_integer_quantization > Since TensorFlow 2.7 version, we recommend using the signaturebased approach over the input tensor listbased approach because the input tensor ordering can be easily flipped. So, since documentation on that is a little vague, I assumed that ""signaturebased approach"" basically means that my representative dataset is supposed to yield dicts. I kind of forgot that the list option also existed as I spent quite a while setting this whole thing up (given the errors and stuff). ","Hi , this might be related to https://github.com/tensorflow/tensorflow/issues/62620, the signature seems to get removed in certain situations Hi , can you please take a look? Thanks.","Hi,   Thanks for raising this issue. Are you aware of AIEdgeTorch? As we believe this issue is better supported by and more relevant to AIEdgeTorch we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/aiedgetorch/issues/389 Let us know if you have any questions. Thanks.","  I'm sorry, but what? You advising me to direct my issue with a TF+Keras2 model that I try to convert to TFLite to a project dedicated to running PyTorch on Edge devices?  This is completely unrelated to this issue. But now that you mention it, I see that TF is clearly dying, and maybe I need to switch to torch after all","Hi , Whichever work flow works best for you, we will support. The TFLite code base in general is moving out of Tensorflow and into LiteRT. If changing to PyTorch and using AIEdgeTorch will accomplish your goals faster then we recommend doing so. If you really need this current workflow to work then I recommend you move the issue from AIEdgeTorch to LiteRT.",Are you satisfied with the resolution of your issue? Yes No
1471,"以下是一个github上的tensorflow下的一个issue, 标题是(Failure in building with GPU support from source specifically in 2.7.0)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.7.0  Custom code No  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.8  Bazel version 3.7.2  GCC/compiler version 11.4.0  CUDA/cuDNN version 11.8  GPU model and memory Nvidia RTX A6000  Current behavior? I am trying to build this custom code , but has encountered error when building with GPU support. I have followed the documentation and have set up proper configuration as seen below, setting cuda==Y and confirming the environment path auto detected are indeed valid.  I thought it is an issue from the custom code but i found out that the same issue persists even in the main repository, r2.7 branch. Moreover, after upgrading bazel to 6.1.0 and build the master branch with same configurations, it was successful.  I'm convinced this is likely an issue linked to version 2.7.0, though I'm not sure how to tackle this issue. As i don't see a easy way of bypassing this old version since this repo that i want to try out is dependent on it.  Any assistance on it is greatly appreciated!  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,darthnoward,Failure in building with GPU support from source specifically in 2.7.0," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.7.0  Custom code No  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.8  Bazel version 3.7.2  GCC/compiler version 11.4.0  CUDA/cuDNN version 11.8  GPU model and memory Nvidia RTX A6000  Current behavior? I am trying to build this custom code , but has encountered error when building with GPU support. I have followed the documentation and have set up proper configuration as seen below, setting cuda==Y and confirming the environment path auto detected are indeed valid.  I thought it is an issue from the custom code but i found out that the same issue persists even in the main repository, r2.7 branch. Moreover, after upgrading bazel to 6.1.0 and build the master branch with same configurations, it was successful.  I'm convinced this is likely an issue linked to version 2.7.0, though I'm not sure how to tackle this issue. As i don't see a easy way of bypassing this old version since this repo that i want to try out is dependent on it.  Any assistance on it is greatly appreciated!  Standalone code to reproduce the issue   Relevant log output ",2023-12-19T09:05:06Z,type:build/install comp:gpu subtype: ubuntu/linux TF 2.7,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62663,"after some debugging, i found out that it might have something to do with find_cuda_config.py not able to locate `/usr/local/cuda11.8/targets/x86_64linux/lib/libcusolver.so.11` so i manually specified `cusolver_version = ""11""`. Now my cuda config looks like this `struct(compute_capabilities = [""compute_86""], config = {""cublas_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""cublas_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""cublas_version"": ""11.11.3"", ""cuda_binary_dir"": ""/usr/local/cuda11.8/bin"", ""cuda_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""cuda_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""cudnn_include_dir"": ""/usr/include"", ""cudnn_library_dir"": ""/usr/lib/x86_64linuxgnu"", ""cufft_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""cufft_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""cufft_version"": ""10.9.0"", ""cupti_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""cupti_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""curand_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""curand_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""curand_version"": ""10.3.0"", ""cusolver_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""cusolver_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""cusolver_version"": ""11"", ""cusparse_include_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/include"", ""cusparse_library_dir"": ""/usr/local/cuda11.8/targets/x86_64linux/lib"", ""cusparse_version"": ""11.7.5"", ""nvvm_library_dir"": ""/usr/local/cuda11.8/nvvm/libdevice""}, cpu_value = ""Linux"", cublas_version = ""11"", cuda_toolkit_path = ""/usr/local/cuda11.8"", cuda_version = ""11.8"", cuda_version_major = ""11"", cudart_version = ""11.0"", cudnn_version = ""8"", cufft_version = ""10"", curand_version = ""10"", cusolver_version = ""11"", cusparse_version = ""11"")` And it managed to start compiling but in the end when `executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1` it gives error as well  ","issue resolved by adding flag  `cxxopt=""D_GLIBCXX_USE_CXX11_ABI=0""` during build",Are you satisfied with the resolution of your issue? Yes No,"Issue occurs also at TensorFlow 2.9. Modifying `tensorflow/third_party/gpus/cuda_configure.bzl:713` and adding flag  `cxxopt=""D_GLIBCXX_USE_CXX11_ABI=0""` can solve it."
1429,"以下是一个github上的tensorflow下的一个issue, 标题是(TF2.15 Tensorboard-Profiler Errors in Jupyter Notebook)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version TF2.15  Custom code No  OS platform and distribution Linux Mint 21.2 / Anaconda 23.11  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.2 / 8.9 (""bundled"" versions with tensorflow[andcuda])  GPU model and memory RTX 3080 10GB  Current behavior? I installed TF2.15 in a fresh AnacondaInstall as described in the ""Install TensorFlow with pip"" section. Installation runs smoothly and the example model runs smoothly as well. The only other installations were:  conda update conda  conda install c ""nvidia/label/cuda12.2.2"" cudatoolkit However on compiling the model with TensorboardCallback in Jupyter Notebook and subsequently fitting the model I get multiple errors.  First there are the ""cuptiGetTimestamp: error 999"" and subsequent errors in the logs. Second, when trying to load the Profiletab in Tensorboard, I get to select Profile, some data is loaded, but it says ""Failed to load libcupti (is it installed and accessible?)""  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Te-eMster,TF2.15 Tensorboard-Profiler Errors in Jupyter Notebook," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version TF2.15  Custom code No  OS platform and distribution Linux Mint 21.2 / Anaconda 23.11  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.2 / 8.9 (""bundled"" versions with tensorflow[andcuda])  GPU model and memory RTX 3080 10GB  Current behavior? I installed TF2.15 in a fresh AnacondaInstall as described in the ""Install TensorFlow with pip"" section. Installation runs smoothly and the example model runs smoothly as well. The only other installations were:  conda update conda  conda install c ""nvidia/label/cuda12.2.2"" cudatoolkit However on compiling the model with TensorboardCallback in Jupyter Notebook and subsequently fitting the model I get multiple errors.  First there are the ""cuptiGetTimestamp: error 999"" and subsequent errors in the logs. Second, when trying to load the Profiletab in Tensorboard, I get to select Profile, some data is loaded, but it says ""Failed to load libcupti (is it installed and accessible?)""  Standalone code to reproduce the issue   Relevant log output ",2023-12-18T15:51:29Z,comp:tensorboard stat:awaiting response type:bug stale TF 2.15,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62660,"eMster Could you please verify CUPTI Installation and Compatibility using the following: `conda list cupti` also please ensure `LD_LIBRARY_PATH `includes the path to CUPTI libraries(e.g.,/usr/local/cuda/extras/CUPTI/lib64). Thank you!"," Thanks for your help. Here are the relevant outputs from terminal: **conda list cupti in kernelenvironment:** packages in environment at /home/matai/anaconda3/envs/tf2.15py3.11:           Name                    		Version                   Build  	Channel               cudacupti                		12.2.142                      0    	nvidia/label/cuda12.2.2                                                                            cudacuptistatic         		12.2.142                      0    	nvidia/label/cuda12.2.2                                                                            nvidiacudacupticu12    	12.2.142                 pypi_0    	pypi    **""os.environ.__getitem__('LD_LIBRARY_PATH‘)"" executed in the Notebook:** '/home/user/anaconda3/envs/tf2.15py3.11/lib' **""ls | grep libcupti"" executed in the LD_LIBRARY_PATH directory:** libcupti.so libcupti.so.12 libcupti.so.2023.2.2 libcupti_static.a",eMster Could you please have a look at this colab gist where I was able to run the provided code successfully ? Please create a new environment and try again. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"I was having the same issue. I had installed tensorlow[andcuda] using pipenv on a Ubuntu 22.04 machine. I solved it by adding ""_env_path_/lib/python3.10/sitepackages/nvidia/cuda_cupti/lib/"" to LD_LIBRARY_PATH.  Is there a way to avoid manually setting LD_LIBRARY_PATH ?"
847,"以下是一个github上的tensorflow下的一个issue, 标题是(Build failure on PPC)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution RedHat 8.8, ppc64le  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Unable to build Tensorflow on ppc64le.  Using hermetic python is likely the cause  https://github.com/tensorflow/tensorflow/commit/e85860e8382a460a0dd8547a536e5eaaf9096a9f.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cdeepali,Build failure on PPC," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution RedHat 8.8, ppc64le  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Unable to build Tensorflow on ppc64le.  Using hermetic python is likely the cause  https://github.com/tensorflow/tensorflow/commit/e85860e8382a460a0dd8547a536e5eaaf9096a9f.  Standalone code to reproduce the issue   Relevant log output ",2023-12-18T15:11:46Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale subtype: ubuntu/linux TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62659,"Although I have seen this issue with TF v2.14, I think this is a general issue with versions >2.14 because all use the new hermetic python for builds.  Is there a way by which one can avoid using hermetic python can run build the old way?","I also meet this problem, and can not  Collecting numpy==1.23.5 when build tf2.14  by source code.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. TensorFlow now supports and is compiled with NumPy 2.0 by default. Please see the NumPy 2 release notes and the NumPy 2 migration guide. https://github.com/tensorflow/tensorflow/releases The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1335,"以下是一个github上的tensorflow下的一个issue, 标题是(TFlite Model Maker installation successfull - but error on import)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.8.2  Custom code No  OS platform and distribution WSL Ubuntu 20.04 on Windows 10  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I thought I have successfully installed TFLite model maker but I can an error when trying to test code which happens on some imports. It seems to be scann related which is installed at version 1.2.6 by pip which should be compatible. One important thing might be that I installed tensorflow 2.8.2 using anaconda because the pip packages are built requiring AVX which my CPU does not have. I verified that my GPU is used correctly within the anaconda environment with this installed package though. The following error happens on imports e.g. :  Is it related that I use tensorflow from conda and not from pip?  Standalone code to reproduce the issue  ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,alexw92,TFlite Model Maker installation successfull - but error on import, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.8.2  Custom code No  OS platform and distribution WSL Ubuntu 20.04 on Windows 10  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I thought I have successfully installed TFLite model maker but I can an error when trying to test code which happens on some imports. It seems to be scann related which is installed at version 1.2.6 by pip which should be compatible. One important thing might be that I installed tensorflow 2.8.2 using anaconda because the pip packages are built requiring AVX which my CPU does not have. I verified that my GPU is used correctly within the anaconda environment with this installed package though. The following error happens on imports e.g. :  Is it related that I use tensorflow from conda and not from pip?  Standalone code to reproduce the issue  ```  Relevant log output _No response_,2023-12-18T13:41:19Z,stat:awaiting response type:bug stale comp:lite TF 2.8 TFLiteModelMaker,closed,0,15,https://github.com/tensorflow/tensorflow/issues/62658,I could also reproduce the issue when installing model maker from pip (version 0.4.2)  Then the error like above:  ,", This issue is unlikely to be resolved soon, Could you please use mediapipe model maker instead for now. Here is also a gist that runs through some image classification examples with mediapipe model maker, including quantization: gist. If you can't accomplish your goals with mediapipemodelmaker please let us know and we'll see if there is a way to accomplish your goals. https://github.com/tensorflow/tensorflow/issues/60431 Thank you!"," Hello and thanks for your response. Yes it looks interesting and I thing it will work! But how do I install it? When I try to install mediapipe model maker via pip, pip ignores my already installed conda tensorflow 2.10 environment and loads tf 2.15 from pip which wont work for me since it uses AVX. I think even the old model maker will work if I can find out the reason for the error above."," Could you consider creating a new, clean conda environment specifically for the mediapipemodelmaker to avoid conflicts with other packages or TensorFlow versions. Thank you!", Sure thats what I have been doing for the last couple of days. I always started within a new conda environment and tried so many different configurations and package versions. I was not able to create one single environment where mediapipemodelmaker was using the already installed (installed within conda using conda install of course not globally) tensorflow version. So I wonder if this is even possible. Btw for this I created another issue since this one is referring to the traditional model maker while the other issue  is in the mediapipe repo , Could you doublecheck the import statement for accuracy and ensure you're using the correct path to the model maker module? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.," I checked the import statement and yes it is correct definetly! The import is actually from the samples page of tf lite model maker.  By the way, is tf lite model maker about to be substituted completly by mediapipe model maker? So is there a recommendation by Google to always use mediapipe model maker instead of the one in this repo?","Hi ,  Please look into the issue Thank You","Hi , you have a couple of options: 1. Just use mediapipe model maker in colab (You can use a GPU/TPU here as well though there are potential limitations) https://research.google.com/colaboratory/faq.html 2. Attempt to fix your current setup, can you try `pip install scann`? 3. Build Tensorflow from source w/o AVX support and with Cuda(Nvidia GPUs)/RocM(AMD GPUs) support https://www.tensorflow.org/install/source (For WSL you would follow linux instructions), then try to simultaneously install all your required packages with the built package so that they have the best chance to play nicely together 4. Use a lower level API and skip tflitemodelmaker/mediapipemodelmaker and use keras/TF directly I think b/c you don't have AVX support and we essentially aren't supporting older versions, these are your best choices, let me know if any of them work and we can try to pursue those choices further.","   1) Yes I am aware of this thanks. 2) I did and this did not work unfortunately. Also uninstalling and reinstalling scann did not work 3) This is what I am afraid of. I have no experience in building from source. 4) That would mean throwing thousands lines of code away I already wrote for working with modelmaker What I did in the end was borrowing another system which an AVXcapable CPU. It is really sad that newer TF versions are build to require AVX even though the majority of users will use their GPU anyway. I will update my system with a new CPU then since it seems to be the quickest solution.  By the way could you please tell me: **Maintenance Status:** Is the Model Maker located in the examples directory of the TensorFlow repository still actively maintained? Or has it been superseded by the MediaPipe Model Maker? **Official Recommendation:** For developing models, especially with a focus on mobile and edge devices, does Google currently recommend transitioning to the MediaPipe Model Maker?","Hi , Be careful with motherboard compatibility if you go that route. > Maintenance Status: Is the Model Maker located in the examples directory of the TensorFlow repository still actively maintained? Or has it been superseded by the MediaPipe Model Maker? Model Maker is currently still active but is running into the problems you have seen, so that's why we are diverting users to MediaPipe Model Maker. Effectively and practically if you want anything done right now, yes ... I can't say if that will continue to be the case in the future. > Official Recommendation: For developing models, especially with a focus on mobile and edge devices, does Google currently recommend transitioning to the MediaPipe Model Maker? Yes or TFLite directly, as always, the lower you go in the API the more customizability you have at the cost of developer experience. > 3. This is what I am afraid of. I have no experience in building from source. Of course you know the best use of your own time, but the only way to get experience is to try 😄. Your experience here will be smoother on linux/WSL. Building from source is generally the most reliable way to support unique configurations/combinations  or see why that configuration/combination is not supported.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
847,"以下是一个github上的tensorflow下的一个issue, 标题是(Observer with TFUniformReplayBuffer)， 内容是 (""Hello everybody, How can I create a TFUniformReplayBufferObserver to use in an actor? I created a buffer as follows:   and then tried to create an observer like this: replay_observer = [replay_buffer.add_batch], which is consistent with the TensorFlow documentation. However, it is not used for an actor there. I attempted the following:  When I debug, there is an error report that I do not know how to handle because I thought my approach should work. Does anyone have a solution, approach, or inspiration for me to deal with this problem? I would be extremely grateful, many thanks for your approaches and creative ideas.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,MarleneBs,Observer with TFUniformReplayBuffer,"""Hello everybody, How can I create a TFUniformReplayBufferObserver to use in an actor? I created a buffer as follows:   and then tried to create an observer like this: replay_observer = [replay_buffer.add_batch], which is consistent with the TensorFlow documentation. However, it is not used for an actor there. I attempted the following:  When I debug, there is an error report that I do not know how to handle because I thought my approach should work. Does anyone have a solution, approach, or inspiration for me to deal with this problem? I would be extremely grateful, many thanks for your approaches and creative ideas.",2023-12-18T10:20:29Z,stat:awaiting response stale,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62656,This is part of the report  ,"Hi, I think the issue is that you are passing a list in list to ""observers"" argument of ""initial_collect_actor"". You should either change the line observers=[replay_observer] to observers=replay_observer or replay_observer = [replay_buffer.add_batch] to replay_observer = replay_buffer.add_batch. I am not sure but I hope both versions should work.","Yes I changed that and and then it has worked up to this point, but afterwards this line of code then caused problems. I also agree with you that both variants should work . initial_collect_actor.run() A ops.Py file opens during debug, which has an error in the following. def raise_from_not_ok_status(e, name) > NoReturn:   e.message += ("" name: "" + str(name if name is not None else """"))   raise core._status_to_exception(e) from None   pylint: disable=protectedaccess In the Debug Console it says: raplay_observer: {NameError]NameError(""name 'replay_observer' is not defined) But I already thought that I had defined it, and with: replay_observer = [replay_buffer.add_batch]","   In order to expedite the troubleshooting process, please provide a complete code snippet to reproduce the issue and TF version you are using?   Could you please have a look at this TFAgents documentation for more details and examples? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1070,"以下是一个github上的tensorflow下的一个issue, 标题是(How to pass zipped Tensors and RaggedTensors to .fit()?)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I can't use zipped dataset with Tensors as labels and RaggedTensors as tokens with this error.  TypeError: Some of the inputs are not tf.RaggedTensor. Input received: [, tf.RaggedTensor(values=Tensor(""sequential_3/dense_8/Softmax:0"", shape=(None, 15), dtype=float32), row_splits=Tensor(""sequential_3/rnn_10/RaggedFromTensor/concat:0"", shape=(None,), dtype=int64))]  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,mihalt,How to pass zipped Tensors and RaggedTensors to .fit()?," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I can't use zipped dataset with Tensors as labels and RaggedTensors as tokens with this error.  TypeError: Some of the inputs are not tf.RaggedTensor. Input received: [, tf.RaggedTensor(values=Tensor(""sequential_3/dense_8/Softmax:0"", shape=(None, 15), dtype=float32), row_splits=Tensor(""sequential_3/rnn_10/RaggedFromTensor/concat:0"", shape=(None,), dtype=int64))]  Standalone code to reproduce the issue   Relevant log output _No response_",2023-12-17T15:12:01Z,stat:awaiting response type:bug stale comp:apis TF2.14,closed,0,13,https://github.com/tensorflow/tensorflow/issues/62655,"Hi **** , Sorry for the delay, Unpack the zipped data in your training loop: This is the simplest approach and works well for small datasets or when you need more control over the individual Tensors and RaggedTensors. Inside your training loop, unpack the zipped data into separate variables for your features and labels. Thank you!","> Hi **** , Sorry for the delay, Unpack the zipped data in your training loop: This is the simplest approach and works well for small datasets or when you need more control over the individual Tensors and RaggedTensors. Inside your training loop, unpack the zipped data into separate variables for your features and labels. >  > Thank you! oh, do you offer to do custom training loop? Really not happy with this. Do you think is it a bug? Do you plan to fix it in near releases of tensorflow? I would better prefer to wait when you do it. ","Hi  , The `fit` method indeed takes input as `tf.data.Dataset` object which can accept Ragged Tensors as input also. From the error it seems you are passing `rank1` scalar values as input.Ragged tensors should have atleast rank2. > oh, do you offer to do custom training loop? Really not happy with this. Do you think is it a bug? Do you plan to fix it in near releases of tensorflow? I would better prefer to wait when you do it. For passing Ragged input there is no need of custom loop. You can pass it directly to model.fit . But the ragged input should be qualified as `>= rank2 `","What my colleague is trying to say is that by using the `Dataset` class he gets a set of **input data** and **target**. In this case, the `dataset `has shapes `[batch_size, ragged_rank1, ragged_rank2, embedding_dim]`. According to it, the **targets data** have shapes `[batch_size, ragged_rank1, class_num]`. When we try to call one element for inspection/processing via` .take(1)` we get **input data** shapes `[1, singe_fixed_rank1, ragged_rank2, embedding_dim]`, so there is only one ragged rank. In this case, for the **target data**, the data shapes `[1, singe_fixed_rank1, class_num]`, which is not a ragged tensor. After processing the **input data**, the model returns a RaggedTensor and the target is stay Tensor. An error occurs at the loss processing stage, which says that RaggedTensor and Tensor cannot be compared. The simplest thing is to fix the data output in the `Dataset `class so that when `ragged=True`, all data sets are returned in shapes of a RaggedTensor, despite the absence of ragged_rank in any set. The second option is to add a check to the loss calculation for the same sizes of RaggedTensor and Tensor before processing. Allow such losses to be calculated for tensors with identical shapes. As typed in the start of topic, using `.map()` to fix Tensor to RaggedTensor  in target return the error...","Yes, and I would not like to do manually something like this, because it will be very temporal solution due to a bag of tensorflow (by my  opinion)  > The second option is to add a check to the loss calculation for the same sizes of RaggedTensor and Tensor before processing. Allow such losses to be calculated for tensors with identical shapes. So, I would prefer to wait while this problem will be resolved on tensorflow side. ","Hi  , Could you please submit a minimal code snippet with dummy data to replicate the reported issue? Thanks!"," console gave this^ batch _ (, ) (, ) element_iter (, ) (, ) (, )_ So, only X become ragged, all Y is Tensor.","Hi  , Thanks for repro snippet. I have replicated the issue and attached gist. Need to check with SME for this behaviour.","> Hi  , >  > Thanks for repro snippet. I have replicated the issue and attached gist. Need to check with SME for this behaviour. any news about this issue? ","Hi , And I can't convert Tensors in dataset to Ragged through map due to error ValueError: The rank of a RaggedTensor must be greater than 1, i.e., a list of scalars won't have ragged dimensions. Received argument `tensor` with rank 1. =====> I was reproduced the mentioned error. The error happens because `tf.RaggedTensor` requires tensors to have a rank greater than 1. Scalars or rank1 tensors don’t have ragged dimensions by nature, so trying to convert them into a `RaggedTensor` will fail.  To fix this, you can ""wrap"" the scalar into a higherrank tensor, like a 2D tensor, by adding an extra dimension. This makes it compatible with `tf.RaggedTensor`. Make sure that both labels and tags should be either dense tensors or RaggedTensors then you can zip and pass to fit function. Won't get an any error. Could you please refer to the gist file. Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1396,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to build object_tracking Example for Android with TensorFlow Lite)， 内容是 (Android studio is not able to build object_tracking Example from TensorFlow/examples. I am very much new with Android app development, java and gradle, so it is more likely that I am doing something wrong. From readme, It should work out of the box, but it doesn't, hence I am writing here. Maybe there is a more detailed description somewhere on how to get this running? Thank you! What I tried:  Changing Android Tools version (suggested on Object Detection Tutorial); didn't help. The tutorial is for an older version of repo though :/, so I wasn't expecting much.  Android Studio version I am using: > Android Studio Hedgehog | 2023.1.1 > Build AI231.9392.1.2311.11076708, built on November 9, 2023 > Runtime version: 17.0.7+017.0.7b1000.610550314 x86_64 > VM: OpenJDK 64Bit Server VM by JetBrains s.r.o. > macOS 13.1 > GC: G1 Young Generation, G1 Old Generation > Memory: 2048M > Cores: 16 > Metal Rendering is ON > Registry: >     external.system.auto.import.disabled=true >     debugger.new.tool.window.layout=true >     ide.text.editor.with.preview.show.floating.toolbar=false >     ide.experimental.ui=true Error message I get: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",text generation,ArnasVysniauskas,Unable to build object_tracking Example for Android with TensorFlow Lite,"Android studio is not able to build object_tracking Example from TensorFlow/examples. I am very much new with Android app development, java and gradle, so it is more likely that I am doing something wrong. From readme, It should work out of the box, but it doesn't, hence I am writing here. Maybe there is a more detailed description somewhere on how to get this running? Thank you! What I tried:  Changing Android Tools version (suggested on Object Detection Tutorial); didn't help. The tutorial is for an older version of repo though :/, so I wasn't expecting much.  Android Studio version I am using: > Android Studio Hedgehog | 2023.1.1 > Build AI231.9392.1.2311.11076708, built on November 9, 2023 > Runtime version: 17.0.7+017.0.7b1000.610550314 x86_64 > VM: OpenJDK 64Bit Server VM by JetBrains s.r.o. > macOS 13.1 > GC: G1 Young Generation, G1 Old Generation > Memory: 2048M > Cores: 16 > Metal Rendering is ON > Registry: >     external.system.auto.import.disabled=true >     debugger.new.tool.window.layout=true >     ide.text.editor.with.preview.show.floating.toolbar=false >     ide.experimental.ui=true Error message I get: ",2023-12-17T10:20:39Z,stat:awaiting response type:bug stale comp:lite TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62654,"Just tried bumping down gradle version in gradlewrapper.properties from 8.4 to 7.2 (lowest for JAVA 11), and everything worked from there perfectly","Hi ,  It's a known issue , the error occurs due to upgradation of gradle 8.4 version. As a temporary  fix, you can use your solution. Engineering team is working on this issue. Thank You.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,I've just bumped into the same issue. As that's the first sample that shows up when try tensorflow life it would be great to fix it,"Similar issue here, I followed the fix from earlier by replacing the distributionUrl in gradlewrapper.properties to  distributionUrl=https\://services.gradle.org/distributions/gradle7.3.3bin.zip"
1813,"以下是一个github上的tensorflow下的一个issue, 标题是(Didn't find op for builtin opcode 'PAD' version '1')， 内容是 ( Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.8.0  Custom code Yes  OS platform and distribution Windows, ESP32cam  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I wrote a code to read a **.tflite model** file from inbuilt SD Card of **ESP32CAM** and use it to do detection.  Error> Didn't find op for builtin opcode 'PAD' version '1'  **Serial Monitor**   **My Code**   Standalone code to reproduce the issue  shell [   464][I][esp32halpsram.c:96] psramInit(): PSRAM enabled Didn't find op for builtin opcode 'PAD' version '1' Failed to get registration from op code  d AllocateTensors() failed Guru Meditation Error: Core  1 panic'ed (LoadProhibited). Exception was unhandled. Core  1 register dump: PC      : 0x400d2d5c  PS      : 0x00060830  A0      : 0x800e94f4  A1      : 0x3ffdaf70   A2      : 0x3ffd6234  A3      : 0x00000000  A4      : 0x3ffc3970  A5      : 0x3ffc3978   A6      : 0x3ffbd720  A7      : 0x80000001  A8      : 0x800d2f8c  A9      : 0x3ffdaf30   A10     : 0x00000000  A11     : 0x00000060  A12     : 0x00000060  A13     : 0x00000001   A14     : 0x00011800  A15     : 0x3ffc3978  SAR     : 0x0000001e  EXCCAUSE: 0x0000001c   EXCVADDR: 0x00000004  LBEG    : 0x4008a02d  LEND    : 0x4008a03d  LCOUNT  : 0xffffffff   Backtrace: 0x400d2d59:0x3ffdaf70 0x400e94f1:0x3ffdaf90 ELF file SHA256: 95a2e245985e3dfa Rebooting... ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Hacktiv8or,Didn't find op for builtin opcode 'PAD' version '1'," Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.8.0  Custom code Yes  OS platform and distribution Windows, ESP32cam  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I wrote a code to read a **.tflite model** file from inbuilt SD Card of **ESP32CAM** and use it to do detection.  Error> Didn't find op for builtin opcode 'PAD' version '1'  **Serial Monitor**   **My Code**   Standalone code to reproduce the issue  shell [   464][I][esp32halpsram.c:96] psramInit(): PSRAM enabled Didn't find op for builtin opcode 'PAD' version '1' Failed to get registration from op code  d AllocateTensors() failed Guru Meditation Error: Core  1 panic'ed (LoadProhibited). Exception was unhandled. Core  1 register dump: PC      : 0x400d2d5c  PS      : 0x00060830  A0      : 0x800e94f4  A1      : 0x3ffdaf70   A2      : 0x3ffd6234  A3      : 0x00000000  A4      : 0x3ffc3970  A5      : 0x3ffc3978   A6      : 0x3ffbd720  A7      : 0x80000001  A8      : 0x800d2f8c  A9      : 0x3ffdaf30   A10     : 0x00000000  A11     : 0x00000060  A12     : 0x00000060  A13     : 0x00000001   A14     : 0x00011800  A15     : 0x3ffc3978  SAR     : 0x0000001e  EXCCAUSE: 0x0000001c   EXCVADDR: 0x00000004  LBEG    : 0x4008a02d  LEND    : 0x4008a03d  LCOUNT  : 0xffffffff   Backtrace: 0x400d2d59:0x3ffdaf70 0x400e94f1:0x3ffdaf90 ELF file SHA256: 95a2e245985e3dfa Rebooting... ```",2023-12-16T08:47:12Z,stat:awaiting response type:build/install stale comp:lite comp:ops subtype:windows TF 2.8,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62651,"Hi ,  Could you please confirm you are getting the same error with PADV2() op instead of PAD(). Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1799,"以下是一个github上的tensorflow下的一个issue, 标题是(Modifications to Debugging Functionality Tests)， 内容是 (**Report on Modifications to Debugging Functionality Tests** *Objective:* The aim of the modifications is to extend the existing debugging functionality tests to cover a variety of variable types, specifically tensors with different shapes and dtypes. This ensures that the debugging infrastructure works consistently across diverse data types. *Modifications:* 1. **Variable and Tensor Declarations:**     Added new variables and tensors to represent different variable types.     Introduced variables with different dtypes, including float32, int32, float64, and int64.     Created tensors with varying shapes, such as scalar, 3x3, and 2x4.  2. **Session Initialization:**     Extended the session initialization to include the new variables and tensors.     Initialized variables and tensors before running test operations.  3. **Test Methods:**     Modified the existing test methods (`testWrapperSessionVariableTypes` and `testHookVariableTypes`) to include operations for the new variables and tensors.     Ensured that each variable type is tested with the debugging wrappers and hooks.  *Conclusion:* The modifications successfully extended the existing debugging functionality tests to cover a variety of variable types. The inclusion of tensors with different shapes and dtypes ensures a more comprehensive evaluation of the debugging infrastructure's consistency and effectiveness across diverse data scenarios. The modified tests contribute to a more robust and reliable debugging solution, providing confidence in its applicability to various use cases.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AbhisekOmkar,Modifications to Debugging Functionality Tests,"**Report on Modifications to Debugging Functionality Tests** *Objective:* The aim of the modifications is to extend the existing debugging functionality tests to cover a variety of variable types, specifically tensors with different shapes and dtypes. This ensures that the debugging infrastructure works consistently across diverse data types. *Modifications:* 1. **Variable and Tensor Declarations:**     Added new variables and tensors to represent different variable types.     Introduced variables with different dtypes, including float32, int32, float64, and int64.     Created tensors with varying shapes, such as scalar, 3x3, and 2x4.  2. **Session Initialization:**     Extended the session initialization to include the new variables and tensors.     Initialized variables and tensors before running test operations.  3. **Test Methods:**     Modified the existing test methods (`testWrapperSessionVariableTypes` and `testHookVariableTypes`) to include operations for the new variables and tensors.     Ensured that each variable type is tested with the debugging wrappers and hooks.  *Conclusion:* The modifications successfully extended the existing debugging functionality tests to cover a variety of variable types. The inclusion of tensors with different shapes and dtypes ensures a more comprehensive evaluation of the debugging infrastructure's consistency and effectiveness across diverse data scenarios. The modified tests contribute to a more robust and reliable debugging solution, providing confidence in its applicability to various use cases.",2023-12-16T07:32:25Z,size:M,closed,0,0,https://github.com/tensorflow/tensorflow/issues/62650
1884,"以下是一个github上的tensorflow下的一个issue, 标题是(Problems replacing reverb with TFUniformbuffers in a sample code)， 内容是 (Have a nice day,  I have two questions. I am currently trying to adapt the code from this example so that it can also run on a Windows PC: https://www.tensorflow.org/agents/tutorials/7_SAC_minitaur_tutorial  In this code example, reverb is used, but it only runs on Linux. I have now decided to use the TF uniform buffer as a replacement, is that a good decision, but I haven't got it 100% right yet.  Ich habe den replay Buffer einfach beim Kreieren wie folgt ersetzt:   Does that make sense? But I wonder how the dataset is always kept up to date? The experience_dataset_fn is called in the Learner, but where is it kept up to date?  Then I used a collect function from this example: https://github.com/tensorflow/agents/blob/master/docs/tutorials/9_c51_tutorial.ipynb  This is called up during training to store experience, isn't it? As this:   But there are definitely two problems left: I do not know how to change the way how the actors are created, i just commented the connection to reverb out and think the interaction between the actor an the replay buffer is ow just made with the collect_stepFunction:   And the learner accesses the dataset as follows and the learner is also called up in the training:   I am now wondering whether the dataset that is used for learning within the training process is always the current one and whether my settings of Reverb with TFUniform are now good and sufficient? The problem is also that I should not make any major changes to the basic code. I would be infinitely grateful if someone could take a look at this and point out errors, omissions or something like that or give me a sol)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MarleneBs,Problems replacing reverb with TFUniformbuffers in a sample code,"Have a nice day,  I have two questions. I am currently trying to adapt the code from this example so that it can also run on a Windows PC: https://www.tensorflow.org/agents/tutorials/7_SAC_minitaur_tutorial  In this code example, reverb is used, but it only runs on Linux. I have now decided to use the TF uniform buffer as a replacement, is that a good decision, but I haven't got it 100% right yet.  Ich habe den replay Buffer einfach beim Kreieren wie folgt ersetzt:   Does that make sense? But I wonder how the dataset is always kept up to date? The experience_dataset_fn is called in the Learner, but where is it kept up to date?  Then I used a collect function from this example: https://github.com/tensorflow/agents/blob/master/docs/tutorials/9_c51_tutorial.ipynb  This is called up during training to store experience, isn't it? As this:   But there are definitely two problems left: I do not know how to change the way how the actors are created, i just commented the connection to reverb out and think the interaction between the actor an the replay buffer is ow just made with the collect_stepFunction:   And the learner accesses the dataset as follows and the learner is also called up in the training:   I am now wondering whether the dataset that is used for learning within the training process is always the current one and whether my settings of Reverb with TFUniform are now good and sufficient? The problem is also that I should not make any major changes to the basic code. I would be infinitely grateful if someone could take a look at this and point out errors, omissions or something like that or give me a sol",2023-12-15T10:46:05Z,stat:awaiting response stat:awaiting tensorflower type:support stale comp:dist-strat TF 2.15,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62644,or is it also possible to omit the collect steps function in the training and simply enter the following as observer in the actors:  `replay_observer = [replay_buffer.add_batch]` debug has failed here  if I try to debug this:   it takes so so long and doesnt make anything ,"  In order to reproduce the issue reported here, could you please provide the complete code and tensorflow version you are using. Thank you!", And tensorflow 2.15.0  Thank you very very much!,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1601,"以下是一个github上的tensorflow下的一个issue, 标题是(Performance Discrepancy Between pip install tensorflow and Building from Source)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf v2.15.0  Custom code No  OS platform and distribution ubuntu 22.04.1 on aarch64   Mobile device _No response_  Python version Python 3.11.0  Bazel version 6.1.0  GCC/compiler version clang version 16.0.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have observed a notable difference in the execution time between TensorFlow installed via pip install tensorflow and TensorFlow built from source. The sourcebuilt TensorFlow appears to take longer to run hugging face models like resnet50, bert etc, compared to the pipinstalled version. The build commands used are given below: bazel build s config=mkl_aarch64 features=layering_check copt=O3 copt=march=armv8a+sve copt=msvevectorbits=256 copt=Wnognuoffsetofextensions copt=Wnounusedbutsetvariable  local_cpu_resources=16 //tensorflow/tools/pip_package:build_pip_package verbose_failures  ./bazelbin/tensorflow/tools/pip_package/build_pip_package /home/vishwas/Graviton/tensorflow pip install /home/vishwas/Graviton/tensorflow/tensorflow_wheelfile.whl It will be great if people help me to provide actual build commands used for aarch64 machine with sve_256.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,vishwascm,Performance Discrepancy Between pip install tensorflow and Building from Source," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf v2.15.0  Custom code No  OS platform and distribution ubuntu 22.04.1 on aarch64   Mobile device _No response_  Python version Python 3.11.0  Bazel version 6.1.0  GCC/compiler version clang version 16.0.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have observed a notable difference in the execution time between TensorFlow installed via pip install tensorflow and TensorFlow built from source. The sourcebuilt TensorFlow appears to take longer to run hugging face models like resnet50, bert etc, compared to the pipinstalled version. The build commands used are given below: bazel build s config=mkl_aarch64 features=layering_check copt=O3 copt=march=armv8a+sve copt=msvevectorbits=256 copt=Wnognuoffsetofextensions copt=Wnounusedbutsetvariable  local_cpu_resources=16 //tensorflow/tools/pip_package:build_pip_package verbose_failures  ./bazelbin/tensorflow/tools/pip_package/build_pip_package /home/vishwas/Graviton/tensorflow pip install /home/vishwas/Graviton/tensorflow/tensorflow_wheelfile.whl It will be great if people help me to provide actual build commands used for aarch64 machine with sve_256.  Standalone code to reproduce the issue   Relevant log output ",2023-12-15T06:10:36Z,stat:awaiting response type:support stale TF 2.15,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62642,", The difference in code execution time between a TensorFlow installation from **source** and a prebuilt binary installed using **pip install tensorflow** can be influenced by several factors.  When you are trying to build TensorFlow from source, there is an option to customize compiler flags and optimizations. If the compilation is not configured optimally for your hardware, it might result in performance. Also the speed of the storage device where TensorFlow is installed can affect the loading and execution times. If the source build is on a slower storage medium compared to the system where the prebuilt binary is installed, it can contribute to differences in execution time. To improve the execution time for TensorFlow built from source, consider the following:  TensorFlow build from source can sometimes lead to increased code execution time compared to using pip install tensorflow. While building from source offers certain advantages like customization and access to the new features, it can also introduce performance drawbacks if not done correctly. Thank you!","Hi , Is there any place where I can see the build command along with all configuration used and flags used for official tf v2.15.0 wheel file available in pypi.org for aarch64 machine (graviton) with  sve_256?","Hi  , Is there any place where I can see the build command along with all configuration used and flags used for official tf v2.15.0 wheel file available in pypi.org for aarch64 machine (graviton) with sve_256?",", Apologies for the delay. You can directly install the tensorflow v2.15 on aarch64 using **pip install tensorflowaarch64** where the flags are not required.  https://pypi.org/project/tensorflowaarch64/ If you are trying to install the tensorflow using a build source, then we will use the flags based upon the requirement. https://www.tensorflow.org/install/sourcebuild_the_package Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi , Thanks for the reply. I am looking for some more detail about building tensorflow from source, specific to aarch64 architecture with vector length 256 (Graviton) machine, including clang version, ubuntu version, build tags to use aarch64 etc. Just like how official wheel files are built.  Are these details available in tensorflow git repository itself? If available how to use it. Thanks, Vishwas",", Could you please take a look at this official build from the source document where you can find the clang version, flags required to install the tensorflow. https://www.tensorflow.org/install/source `sudo aptget update && sudo aptget install y llvm16 clang16` You can try to specify the flags for aarch64 as per the requirement to install the tensorflow from build. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1196,"以下是一个github上的tensorflow下的一个issue, 标题是(MatMul transformed to FullyConnected)， 内容是 ( 1. System information ubuntu22.04  tensorflow 2.15  2. Code import tensorflow as tf import numpy as np def representative_data_gen():     input_value2 = np.random.normal(size=(1, 40, 20, 2048)).astype(np.float32)     yield {       ""input_0"": input_value2,     } converter = tf.lite.TFLiteConverter.from_saved_model('convpart2/saved_model/') converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_data_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.inference_type = tf.int8 tflite_model_quant = converter.convert() with open(""convpart2_int8.tflite"", 'wb') as f:     f.write(tflite_model_quant)  3. Failure after conversion In my model, The MatMul or MatMul+Add or MatMul+Add+Relu are fusion and transformed to FullyConnected. My device doesn't support FullyConnected very well. So I want keep the origin operator(MatMul, Add, Relu), how can I stop this fusion optimization ?  Thanks)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,zxros10,MatMul transformed to FullyConnected," 1. System information ubuntu22.04  tensorflow 2.15  2. Code import tensorflow as tf import numpy as np def representative_data_gen():     input_value2 = np.random.normal(size=(1, 40, 20, 2048)).astype(np.float32)     yield {       ""input_0"": input_value2,     } converter = tf.lite.TFLiteConverter.from_saved_model('convpart2/saved_model/') converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_data_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] converter.inference_type = tf.int8 tflite_model_quant = converter.convert() with open(""convpart2_int8.tflite"", 'wb') as f:     f.write(tflite_model_quant)  3. Failure after conversion In my model, The MatMul or MatMul+Add or MatMul+Add+Relu are fusion and transformed to FullyConnected. My device doesn't support FullyConnected very well. So I want keep the origin operator(MatMul, Add, Relu), how can I stop this fusion optimization ?  Thanks",2023-12-15T05:14:19Z,stat:awaiting response comp:lite TFLiteConverter TF 2.15,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62641,"Hi , You can set  the   to FALSE in the converter to control certain operations like ""MatMul, Add, and Relu""  without getting fused. Please try the following.  If not resolved please provide a saved model towards issue resolution. Thank You","The saved_model is generated by onnx2tf, the code convert model is https://github.com/PINTO0309/onnx2tf/blob/main/onnx2tf/onnx2tf.py:1249       tflite_model = converter.convert() In this convet, the matmul convert to fullyconnected already.  I add       converter.experimental_use_mlir_converter = False befor this line, but unuseless. So I modify tensorflow/lite/python/convert.py：931      enable_mlir_converter = kwargs.get(""enable_mlir_converter"", True) to      enable_mlir_converter = False Then execute onnx2tf, has error: saved_model output started ========================================================== saved_model output complete! Traceback (most recent call last):   File ""/usr/local/bin/onnx2tf"", line 8, in      sys.exit(main())   File ""/usr/local/lib/python3.10/distpackages/onnx2tf/onnx2tf.py"", line 2321, in main     model = convert(   File ""/usr/local/lib/python3.10/distpackages/onnx2tf/onnx2tf.py"", line 1247, in convert     tflite_model = converter.convert()   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py"", line 2185, in convert     return super(TFLiteConverterV2, self).convert()   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py"", line 1139, in wrapper     return self._convert_and_export_metrics(convert_func, *args, **kwargs)   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py"", line 1093, in _convert_and_export_metrics     result = convert_func(self, *args, **kwargs)   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py"", line 1792, in convert     return super(TFLiteFrozenGraphConverterV2, self).convert(   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py"", line 1371, in convert     result = _convert_graphdef(   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert_phase.py"", line 212, in wrapper     raise converter_error from None   Rethrows the exception.   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert_phase.py"", line 205, in wrapper     return func(*args, **kwargs)   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert.py"", line 985, in convert_graphdef     data = convert(   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert.py"", line 368, in convert     return _run_deprecated_conversion_binary(   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert_phase.py"", line 212, in wrapper     raise converter_error from None   Rethrows the exception.   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert_phase.py"", line 205, in wrapper     return func(*args, **kwargs)   File ""/usr/local/lib/python3.10/distpackages/tensorflow/lite/python/convert.py"", line 482, in _run_deprecated_conversion_binary     raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr)) tensorflow.lite.python.convert_phase.ConverterError: See console for info. 20231219 13:16:03.380213: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1677] Check failed: op>start_indices.size() <= num_input_axes (6 vs. 3)StridedSlice op with output ""model_14/tf.strided_slice_1/StridedSlice"", requires no more than 3 start indices Fatal Python error: Aborted There are slice operators in my model: !8df2c14039f04b80934e9f6b15156a33 But if I don't modify the convert.py, has no this error. This perhaps a bug, for my slice node start indices parameter is a one dimension tensor, and input feature map is 3dim. Then I remove th Slice node from my model, the convert execute successful, but the MatMul still convert to FullyConnected, even I set unfold_batch_matmul to false in onnx2tf.py so, converter.experimental_use_mlir_converter = False is not work","Hi , Please look into the  issue. Thank You","Hi , currently there is no way to do the conversion w/o this optimization, why do you say that your device doesn't support fully connected well?","> Hi , currently there is no way to do the conversion w/o this optimization, why do you say that your device doesn't support fully connected well? In my device, the FullyConnected will bring in reshap、transpose and expanddim operator node, which exhaust time close to FullyConnected compute time. I resolve in other way, so close this"
696,"以下是一个github上的tensorflow下的一个issue, 标题是(The problem with input data after quantifying the model with Int8)， 内容是 ( 1. System information  Linux Ubuntu 16.04  TensorFlow installation (pip package or built from source):  TensorFlow library  Option A: Reference colab notebooks I would like to ask how to process my model as input after quantifying it with int8 and setting the inputoutput of tflite to int8, when my input is int16 data and it has undergone rfft. Because if only simple int8 type conversion is used, a large amount of data will become 127 or 0.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,panhu,The problem with input data after quantifying the model with Int8," 1. System information  Linux Ubuntu 16.04  TensorFlow installation (pip package or built from source):  TensorFlow library  Option A: Reference colab notebooks I would like to ask how to process my model as input after quantifying it with int8 and setting the inputoutput of tflite to int8, when my input is int16 data and it has undergone rfft. Because if only simple int8 type conversion is used, a large amount of data will become 127 or 0.",2023-12-15T04:01:08Z,stat:awaiting response stale TFLiteConverter,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62640," Before quantization, could you try to scale your int16 data to a smaller range centered around 0. This will ensure a wider distribution within the limited int8 range, reducing the risk of values becoming 0 or 127 after conversion. You can use techniques like minmax scaling or standard normalization. Please save the scaling factors and apply them in reverse during inference to recover the original data values. Thank you!","Thanks，I have an important question about the convolution calculation method used by tflite. The following is the convolution calculation method I used, but with the same weights and biases, the results obtained are different? Can you help me take a look？ void convolve_HWC_q7_nonsquare(const q7_t *Im_in,                // input image 	const uint16_t dim_im_in_x,                                        // input image dimention x 	const uint16_t dim_im_in_y,                                        // input image dimention y 	const uint16_t ch_im_in,                                           // number of input image channels 	const q7_t *wt,                                                    // kernel weights 	const uint16_t ch_im_out,                                          // number of filters, i.e., output image channels 	const uint16_t dim_kernel_x,                                       // filter kernel size x 	const uint16_t dim_kernel_y,                                       // filter kernel size y 	const uint16_t padding_x,                                          // padding sizes x 	const uint16_t padding_y,                                          // padding sizes y 	const uint16_t stride_x,                                           // stride x 	const uint16_t stride_y,                                           // stride y     const uint16_t dilation_x,                                         // dilation x 	const uint16_t dilation_y,                                         // dilation y 	const q31_t *bias,                                                  // bias 	const nnom_qformat_param_t *bias_shift,                                        // bias shifts     const nnom_qformat_param_t *out_shift,                                         // output shift     const nnom_qtype_t q_type,                                         // per channel or per tensor     q7_t *Im_out,                                                      // output image 	const uint16_t dim_im_out_x,                                       // output image dimension x 	const uint16_t dim_im_out_y,                                       // output image dimension y 	q15_t *bufferA,                                                    //buffer space for input 	q7_t *bufferB                                                      //buffer space for output ) {     int i, j, k, l, m, n;     int conv_out;     int in_row, in_col;     int in_pix_loc, wt_loc;     int shift_idx, shift_steps;     if(q_type == NNOM_QTYPE_PER_AXIS)         shift_steps = 1;     else         shift_steps = 0;     for (i = 0, shift_idx = 0; i > out_shift[shift_idx]), 8);             }         }     } }", Please refer to the official TFLite documentation for detailed descriptions of its convolution operations . Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1879,"以下是一个github上的tensorflow下的一个issue, 标题是(Compiling mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp failed)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution loongarch64  Mobile device _No response_  Python version _No response_  Bazel version 5.3.1  GCC/compiler version 8.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? INFO: Found applicable config definition build:short_logs in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:linux in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch copt=Wnoerror=unusedbutsetvariable define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels distinct_host_configuration=false experimental_guard_against_concurrent_changes INFO: Found applicable config definition build:dynamic_kernels in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured). INFO: Found 1 target... ERROR: /ro)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,yangy996,Compiling mlir/lib/Dialect/SPIRV/IR/SPIRVDialect.cpp failed," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution loongarch64  Mobile device _No response_  Python version _No response_  Bazel version 5.3.1  GCC/compiler version 8.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? INFO: Found applicable config definition build:short_logs in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:linux in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch copt=Wnoerror=unusedbutsetvariable define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels distinct_host_configuration=false experimental_guard_against_concurrent_changes INFO: Found applicable config definition build:dynamic_kernels in file /home/sunwayclouddampy/tensorflow2.12/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured). INFO: Found 1 target... ERROR: /ro",2023-12-14T08:32:25Z,stat:awaiting response type:bug stale TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62635," Please make sure you have all the necessary dependencies installed for building MLIR, including SPIRV libraries and tools. Also verify that your compiler and build tools are uptodate. Please try to use TF v2.15 which is the latest one and let us know? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1903,"以下是一个github上的tensorflow下的一个issue, 标题是(During trainning model with gpu,  randomly stucked and got windows bluescreen crash)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.10.1 git_version v2.10.076gfdfc646704c  Custom code Yes  OS platform and distribution Windows 10 22H2  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA 11.8.0, cuDNN8.9.6.50  GPU model and memory RTXA4000 16G Memory  Current behavior? I was trying to train a StegaStamp model, which is coded by TF1. I modified it into the code of TF2(with compat.v1, disable eager excution and disable v2 behavior etc.) and the code can run in CPU mode (tens of thousands of epochs). But when I try to use the GPU for training, the program will get stuck when running for a few hundred or less than 2,000 epochs, and Windows will restart with a blue screen after dozens of seconds. I also tried  downgrade the version of tf cuda cudnn etc. like tf2.7.0 cuda11.6 cudnn8.3.2(Available combinations given on the web). but the program just exits with ""Process finished with exit code 1073740791 (0xC0000409)"" and didn't raise any exception.  Standalone code to reproduce the issue   Relevant log output WARNING:tensorflow:From D:\work\project\StegaStamp\venv\lib\sitepackages\tensorflow\python\compat\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version. Instructions for updating: nonresource variables are not supported in the long term 20231214 13:26:10.184254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized wit)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Map1e0823,"During trainning model with gpu,  randomly stucked and got windows bluescreen crash"," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.10.1 git_version v2.10.076gfdfc646704c  Custom code Yes  OS platform and distribution Windows 10 22H2  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA 11.8.0, cuDNN8.9.6.50  GPU model and memory RTXA4000 16G Memory  Current behavior? I was trying to train a StegaStamp model, which is coded by TF1. I modified it into the code of TF2(with compat.v1, disable eager excution and disable v2 behavior etc.) and the code can run in CPU mode (tens of thousands of epochs). But when I try to use the GPU for training, the program will get stuck when running for a few hundred or less than 2,000 epochs, and Windows will restart with a blue screen after dozens of seconds. I also tried  downgrade the version of tf cuda cudnn etc. like tf2.7.0 cuda11.6 cudnn8.3.2(Available combinations given on the web). but the program just exits with ""Process finished with exit code 1073740791 (0xC0000409)"" and didn't raise any exception.  Standalone code to reproduce the issue   Relevant log output WARNING:tensorflow:From D:\work\project\StegaStamp\venv\lib\sitepackages\tensorflow\python\compat\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version. Instructions for updating: nonresource variables are not supported in the long term 20231214 13:26:10.184254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized wit",2023-12-14T05:01:48Z,stat:awaiting response type:support stale comp:gpu subtype:windows,closed,0,13,https://github.com/tensorflow/tensorflow/issues/62633,"The memory and video memory did not overflow, Windows Task Manager shows that the trend of memory and video memory is very stable.(about 60% of the max, I guess? it shows a straight line.)",I checked the dump file with WinDbg. KEY_VALUES_STRING: 1     Key  : Analysis.CPU.mSec     Value: 3015     Key  : Analysis.DebugAnalysisManager     Value: Create     Key  : Analysis.Elapsed.mSec     Value: 124272     Key  : Analysis.Init.CPU.mSec     Value: 406     Key  : Analysis.Init.Elapsed.mSec     Value: 56593     Key  : Analysis.Memory.CommitPeak.Mb     Value: 82     Key  : WER.OS.Branch     Value: vb_release     Key  : WER.OS.Timestamp     Value: 20191206T14:06:00Z     Key  : WER.OS.Version     Value: 10.0.19041.1 BUGCHECK_CODE:  133 BUGCHECK_P1: 1 BUGCHECK_P2: 1e00 BUGCHECK_P3: fffff8024c8fb320 BUGCHECK_P4: 0 DPC_TIMEOUT_TYPE:  DPC_QUEUE_EXECUTION_TIMEOUT_EXCEEDED TRAP_FRAME:  fffff80251b19310  (.trap 0xfffff80251b19310) NOTE: The trap frame does not contain all registers. Some register values may be zeroed or incorrect. rax=0000000000000000 rbx=0000000000000000 rcx=fffff8026cadbab8 rdx=fffff80251b195e0 rsi=0000000000000000 rdi=0000000000000000 rip=fffff8026bfa2b28 rsp=fffff80251b194a8 rbp=fffff80251b195e0  r8=fffff80251b19630  r9=000000000000001f r10=00000000ffffffff r11=000000000000000c r12=0000000000000000 r13=0000000000000000 r14=0000000000000000 r15=0000000000000000 iopl=0         nv up ei ng nz na pe nc nvlddmkm+0x192b28: fffff802`6bfa2b28 4053            push    rbx Resetting default scope CUSTOMER_CRASH_COUNT:  1 PROCESS_NAME:  System STACK_TEXT:   fffff802`51b28e18 fffff802`4c037996     : 00000000`00000133 00000000`00000001 00000000`00001e00 fffff802`4c8fb320 : nt!KeBugCheckEx fffff802`51b28e20 fffff802`4be539e3     : 0000024f`dd929daf fffff802`490b4180 00000000`00000000 fffff802`490b4180 : nt!KeAccumulateTicks+0x1e1756 fffff802`51b28e80 fffff802`4be534ca     : fffff802`4c8f3940 fffff802`51b19390 fffff802`4ab81500 00000000`00008101 : nt!KeClockInterruptNotify+0x453 fffff802`51b28f30 fffff802`4bf00825     : fffff802`4c8f3940 fffff802`51b28f40 00000000`00000010 ffff6fa3`9b8ce98a : nt!HalpTimerClockIpiRoutine+0x1a fffff802`51b28f60 fffff802`4bfff6da     : fffff802`51b19390 fffff802`4c8f3940 fffff802`51b195e0 00000000`00000000 : nt!KiCallInterruptServiceRoutine+0xa5 fffff802`51b28fb0 fffff802`4bfffee7     : 00000000`00000000 fffff802`6cadbac0 fffff802`51b19650 fffff802`6cadbac0 : nt!KiInterruptSubDispatchNoLockNoEtw+0xfa fffff802`51b19310 fffff802`6bfa2b28     : fffff802`6bebf451 fffff802`51b19630 ffff980c`cd530000 ffffc7ad`1671fa95 : nt!KiInterruptDispatchNoLockNoEtw+0x37 fffff802`51b194a8 fffff802`6bebf451     : fffff802`51b19630 ffff980c`cd530000 ffffc7ad`1671fa95 ffff980c`cd530000 : nvlddmkm+0x192b28 fffff802`51b194b0 fffff802`51b19630     : ffff980c`cd530000 ffffc7ad`1671fa95 ffff980c`cd530000 fffff802`490b4180 : nvlddmkm+0xaf451 fffff802`51b194b8 ffff980c`cd530000     : ffffc7ad`1671fa95 ffff980c`cd530000 fffff802`490b4180 fffff802`6beabf05 : 0xfffff802`51b19630 fffff802`51b194c0 ffffc7ad`1671fa95     : ffff980c`cd530000 fffff802`490b4180 fffff802`6beabf05 ffff980c`cd430000 : 0xffff980c`cd530000 fffff802`51b194c8 ffff980c`cd530000     : fffff802`490b4180 fffff802`6beabf05 ffff980c`cd430000 ffff980c`cd530000 : 0xffffc7ad`1671fa95 fffff802`51b194d0 fffff802`490b4180     : fffff802`6beabf05 ffff980c`cd430000 ffff980c`cd530000 ffff980c`cd430000 : 0xffff980c`cd530000 fffff802`51b194d8 fffff802`6beabf05     : ffff980c`cd430000 ffff980c`cd530000 ffff980c`cd430000 ffff980c`cd530000 : 0xfffff802`490b4180 fffff802`51b194e0 ffff980c`cd430000     : ffff980c`cd530000 ffff980c`cd430000 ffff980c`cd530000 00000000`00000004 : nvlddmkm+0x9bf05 fffff802`51b194e8 ffff980c`cd530000     : ffff980c`cd430000 ffff980c`cd530000 00000000`00000004 00000000`000100ee : 0xffff980c`cd430000 fffff802`51b194f0 ffff980c`cd430000     : ffff980c`cd530000 00000000`00000004 00000000`000100ee 000000ff`00000100 : 0xffff980c`cd530000 fffff802`51b194f8 ffff980c`cd530000     : 00000000`00000004 00000000`000100ee 000000ff`00000100 00000000`00000001 : 0xffff980c`cd430000 fffff802`51b19500 00000000`00000004     : 00000000`000100ee 000000ff`00000100 00000000`00000001 fffff802`4c927a00 : 0xffff980c`cd530000 fffff802`51b19508 00000000`000100ee     : 000000ff`00000100 00000000`00000001 fffff802`4c927a00 fffff802`4bf8dea9 : 0x4 fffff802`51b19510 000000ff`00000100     : 00000000`00000001 fffff802`4c927a00 fffff802`4bf8dea9 fffff802`4c927a00 : 0x100ee fffff802`51b19518 00000000`00000001     : fffff802`4c927a00 fffff802`4bf8dea9 fffff802`4c927a00 00000000`0c5792a5 : 0x000000ff`00000100 fffff802`51b19520 fffff802`4c927a00     : fffff802`4bf8dea9 fffff802`4c927a00 00000000`0c5792a5 00000096`5b8fdfd0 : 0x1 fffff802`51b19528 fffff802`4bf8dea9     : fffff802`4c927a00 00000000`0c5792a5 00000096`5b8fdfd0 00000096`795d44d0 : nt!KiInitialThread fffff802`51b19530 00000096`d2c573d0     : 00000000`00000000 00000000`00000000 00000000`00000000 00000022`00000000 : nt!HvlGetReferenceTime+0x21 fffff802`51b19560 00000000`00000000     : 00000000`00000000 00000000`00000000 00000022`00000000 00000000`00000000 : 0x00000096`d2c573d0 SYMBOL_NAME:  nvlddmkm+192b28 MODULE_NAME: nvlddmkm IMAGE_NAME:  nvlddmkm.sys STACK_COMMAND:  .thread ; .cxr ; kb BUCKET_ID_FUNC_OFFSET:  192b28 FAILURE_BUCKET_ID:  0x133_ISR_nvlddmkm!unknown_function OS_VERSION:  10.0.19041.1 BUILDLAB_STR:  vb_release OSPLATFORM_TYPE:  x64 OSNAME:  Windows 10 FAILURE_ID_HASH:  {f97493a5ea2b23caa8088602773c2a86} Followup:     MachineOwner,"Hi  , If you are using TF2.10v then supported CUDA and cuDNN are 11.2 and 8.1 respectively. Please refer source. It seems your environment have higher versions and it may raise compatibility errors. Please downgrade them to suitable tested versions. Thanks!",Hi I just tried lowering the version of CUDA11.2.2 and cuDNN8.1.1 but the program still crashes. ;_;,Anyone normally uses A4000 to train tf? ;_;,"Hi  , Since the model is migrated from TF1.x which we are not supporting now. I would recommend to Debug the model code using this guide on migration_debugging. ? Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"hello   did you fix this issue? I'm now also training  StegaStamp ,Would you give more information? Thanks.","> hello  did you fix this issue? I'm now also training StegaStamp ,Would you give more information? Thanks. Maybe it's a problem with the power supply. I used nvidiasmi to limit the maximum power of the graphics card, which may improve the situation, but it's not a 100% solution","I'm studying the StegaStamp. And I'm training the model by the project code . The code is very old, and it is very slow cause it trained by CPU. Can you open the code by TF2? Thank you very much.","> I'm studying the StegaStamp. And I'm training the model by the project code . The code is very old, and it is very slow cause it trained by CPU. Can you open the code by TF2? Thank you very much. ""tf.compat.v1"" I used this code. it's a temporary resolution. i didn't completely change it into TF2. u can change the tf.xxx to tf.compat.v1.xxx when the ide says xxx is not in tf"
974,"以下是一个github上的tensorflow下的一个issue, 标题是(Textfile initializer sharing bug)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.15  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The logic here for TextFileInitializer sharing does not consider key/value dtype. If two text file initializers are made for same vocab file but with different dtypes (tf.int64/tf.string), then sharing will cause one of them to fail and crash. The fix should be small change to add dtypes to shared_name.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",chat,hmc-cs-mdrissi,Textfile initializer sharing bug," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.15  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The logic here for TextFileInitializer sharing does not consider key/value dtype. If two text file initializers are made for same vocab file but with different dtypes (tf.int64/tf.string), then sharing will cause one of them to fail and crash. The fix should be small change to add dtypes to shared_name.  Standalone code to reproduce the issue   Relevant log output ",2023-12-13T19:51:16Z,stat:awaiting tensorflower type:bug comp:ops TF 2.15,open,0,4,https://github.com/tensorflow/tensorflow/issues/62631,"Hello, csmdrissi! Thank you for the suggestions! We need to thoroughly test any modifications to ensure correct functionality and address potential edge cases. Please let us know that if you want to modify the logic to include dtypes in the shared_name calculation. This ensures initializers with different dtypes get distinct shared names, preventing conflicts. `Example: shared_name = f""{vocab_filename}_{key_dtype}_{value_dtype}""` Please let us know the exact changes you are suggesting for documentations which would be helpful to fix it. Thank you!",Yes I think modifying logic to include dtypes in shared names would be a good fix and is enough. I should have time tomorrow and can make a small PR.,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",The bug described refers to specific function in TextFileInitializer. That code has not changed and still has same issue. The code sample I gave should still crash on tensorflow master. Nothing has changed for this issue.
861,"以下是一个github上的tensorflow下的一个issue, 标题是([oneDNN]: Added support for quantized types in Enter and Exit ops on CPU)， 内容是 (Fixes https://github.com/tensorflow/tensorflow/issues/61761. TF removed support for quantized types in `Enter` and `Exit` ops for CPU from r2.13. This causes issues when quantizing models such as TransformerMLPerf using Intel(R) Neural Compressor. An example workflow for using these ops is as follows: `Const (float32) > Identity > Enter (float32) > MatMul` would be quantized into `Const (qint8) > Enter (qint8) > QuantizedMatMul` Here, the `Const` node refers to the weights input of `MatMul`. This PR fixes the above issue by adding back registrations for quantized types in `Enter` and `Exit` ops.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,bhavani-subramanian,[oneDNN]: Added support for quantized types in Enter and Exit ops on CPU,"Fixes https://github.com/tensorflow/tensorflow/issues/61761. TF removed support for quantized types in `Enter` and `Exit` ops for CPU from r2.13. This causes issues when quantizing models such as TransformerMLPerf using Intel(R) Neural Compressor. An example workflow for using these ops is as follows: `Const (float32) > Identity > Enter (float32) > MatMul` would be quantized into `Const (qint8) > Enter (qint8) > QuantizedMatMul` Here, the `Const` node refers to the weights input of `MatMul`. This PR fixes the above issue by adding back registrations for quantized types in `Enter` and `Exit` ops.",2023-12-11T20:52:07Z,awaiting review ready to pull size:XS prtype:bugfix comp:core,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62619,Hi  Can you please review this PR ? Thank you!, Thanks for reviewing this PR. I have addressed your review comments. Please take a look.
1886,"以下是一个github上的tensorflow下的一个issue, 标题是(Why does my full integer quantized tflite model crash when loaded?)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.16.0dev20231211  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device Linux Ubuntu 22.04  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version  CUDA Version: 11.7  GPU model and memory NVIDIA GeForce 3080  Current behavior? It should not crash when loading the model  Standalone code to reproduce the issue   (gdb) bt CC(未找到相关数据)  __pthread_kill_implementation (no_tid=0, signo=6, threadid=140737352685376) at ./nptl/pthread_kill.c:44 CC(Add support for Python 3.x)  __pthread_kill_internal (signo=6, threadid=140737352685376) at ./nptl/pthread_kill.c:78 CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"")  __GI___pthread_kill (threadid=140737352685376, signo=signo=6) at ./nptl/pthread_kill.c:89 CC(JVM, .NET Language Support)  0x00007ffff7c42476 in __GI_raise (sig=sig=6) at ../sysdeps/posix/raise.c:26 CC(Installation over pip fails to import with protobuf 2.6.1)  0x00007ffff7c287f3 in __GI_abort () at ./stdlib/abort.c:79 CC(Java interface)  0x00007fff7cc99961 in tflite::QuantizeMultiplierSmallerThanOneExp(double, int*, int*) () from /home/huddly/anaconda3/envs/onnx2tf/lib/python3.11/sitepackages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so CC(Pretrained models)  0x00007fff7c8e3439 in tflite::ops::builtin::add::Prepare(TfLiteContext*, TfLiteNode*) () from /home/huddly/anaconda3/envs/onnx2tf/lib/python3.11/sitepackages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tenso)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,spacycoder,Why does my full integer quantized tflite model crash when loaded?," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.16.0dev20231211  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device Linux Ubuntu 22.04  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version  CUDA Version: 11.7  GPU model and memory NVIDIA GeForce 3080  Current behavior? It should not crash when loading the model  Standalone code to reproduce the issue   (gdb) bt CC(未找到相关数据)  __pthread_kill_implementation (no_tid=0, signo=6, threadid=140737352685376) at ./nptl/pthread_kill.c:44 CC(Add support for Python 3.x)  __pthread_kill_internal (signo=6, threadid=140737352685376) at ./nptl/pthread_kill.c:78 CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"")  __GI___pthread_kill (threadid=140737352685376, signo=signo=6) at ./nptl/pthread_kill.c:89 CC(JVM, .NET Language Support)  0x00007ffff7c42476 in __GI_raise (sig=sig=6) at ../sysdeps/posix/raise.c:26 CC(Installation over pip fails to import with protobuf 2.6.1)  0x00007ffff7c287f3 in __GI_abort () at ./stdlib/abort.c:79 CC(Java interface)  0x00007fff7cc99961 in tflite::QuantizeMultiplierSmallerThanOneExp(double, int*, int*) () from /home/huddly/anaconda3/envs/onnx2tf/lib/python3.11/sitepackages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so CC(Pretrained models)  0x00007fff7c8e3439 in tflite::ops::builtin::add::Prepare(TfLiteContext*, TfLiteNode*) () from /home/huddly/anaconda3/envs/onnx2tf/lib/python3.11/sitepackages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tenso",2023-12-11T20:45:48Z,stat:awaiting tensorflower type:bug comp:lite TFLiteConverter,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62618,I have attached the model here (I had to zip it since github doesn't accept .tflite files).  full_integer_quant_model.zip,I have a suspicion that this PR might fix it. Any idea how I can mitigate this before a fix is merged? How can I ensure real_output_multiplier is under 1?,"Hi  , I have reproduced the issue in colab on both CPU and GPU. The session has crashed. Please look into the issue Thank You","Hi , you'll have to get TF source code, make the same modifications as the PR, rebuild TF from source: https://www.tensorflow.org/install/source, install the newly built TF package then try again on your system. Let us know if that resolves the issue or not so that we can prioritize that PR further if it solves more issues. Thanks for your help! To ""make the same modifications as the PR"" to your local repository please apply this patch:  61698.patch","I applied the patch and built tensorflow. However, it still doesn't work. ","Hi , can you ensure you have installed a TFcuda package? i.e.  and  also please ensure it is working properly:  Does the above occur with `tensorflow[andcuda]`?","It doesn't work with ""tensorflow[andcuda]"" at least. I'm currently having some issues installing tfnightly with GPU support. So I haven't been able to test that yet.","I am able to replicate with tensorflow[andcuda], , can you please take a look? Thanks.",Are you satisfied with the resolution of your issue? Yes No,Closed this issue since it seems to have been an issue with onnx2tf and my specific environment
1896,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite Mobile Benchmarking compilation fails because of the hexagon delegate)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version NIL  Custom code Yes  OS platform and distribution Arch Linux  Mobile device Samsung S22 Plus  Python version 3.9  Bazel version 6.1.0  GCC/compiler version clang 16.0.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?   Standalone code to reproduce the issue  shell `.tf_configure.bazelrc` build action_env PYTHON_BIN_PATH=""/home/hellofriend/miniconda3/bin/python3"" build action_env PYTHON_LIB_PATH=""/home/hellofriend/miniconda3/lib/python3.9/sitepackages"" build python_path=""/home/hellofriend/miniconda3/bin/python3"" build action_env CLANG_COMPILER_PATH=""/usr/bin/clang16"" build repo_env=CC=/usr/bin/clang16 build repo_env=BAZEL_COMPILER=/usr/bin/clang16 build copt=Wnognuoffsetofextensions build:opt copt=Wnosigncompare build:opt host_copt=Wnosigncompare build action_env ANDROID_NDK_HOME=""/opt/androidndk"" build action_env ANDROID_NDK_VERSION=""26"" build action_env ANDROID_NDK_API_LEVEL=""21"" build action_env ANDROID_BUILD_TOOLS_VERSION=""34.0.0"" build action_env ANDROID_SDK_API_LEVEL=""34"" build action_env ANDROID_SDK_HOME=""/home/hellofriend/Android/Sdk"" test test_size_filters=small,medium test:v1 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial test:v1 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu test:v2 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial,v1only test:v2 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,v1only ``` I tried `bazel clean expunge` but that didn't help. According to the docs, the hexagon delegate)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,hello-fri-end,TFLite Mobile Benchmarking compilation fails because of the hexagon delegate," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version NIL  Custom code Yes  OS platform and distribution Arch Linux  Mobile device Samsung S22 Plus  Python version 3.9  Bazel version 6.1.0  GCC/compiler version clang 16.0.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?   Standalone code to reproduce the issue  shell `.tf_configure.bazelrc` build action_env PYTHON_BIN_PATH=""/home/hellofriend/miniconda3/bin/python3"" build action_env PYTHON_LIB_PATH=""/home/hellofriend/miniconda3/lib/python3.9/sitepackages"" build python_path=""/home/hellofriend/miniconda3/bin/python3"" build action_env CLANG_COMPILER_PATH=""/usr/bin/clang16"" build repo_env=CC=/usr/bin/clang16 build repo_env=BAZEL_COMPILER=/usr/bin/clang16 build copt=Wnognuoffsetofextensions build:opt copt=Wnosigncompare build:opt host_copt=Wnosigncompare build action_env ANDROID_NDK_HOME=""/opt/androidndk"" build action_env ANDROID_NDK_VERSION=""26"" build action_env ANDROID_NDK_API_LEVEL=""21"" build action_env ANDROID_BUILD_TOOLS_VERSION=""34.0.0"" build action_env ANDROID_SDK_API_LEVEL=""34"" build action_env ANDROID_SDK_HOME=""/home/hellofriend/Android/Sdk"" test test_size_filters=small,medium test:v1 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial test:v1 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu test:v2 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial,v1only test:v2 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,v1only ``` I tried `bazel clean expunge` but that didn't help. According to the docs, the hexagon delegate",2023-12-11T15:39:35Z,stat:awaiting response type:bug stale comp:lite,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62616,friend Could you manually add dependency declarations for the missing header files in the BUILD file for //tensorflow/lite/profiling:time. This would involve specifying the paths to these files relative to the Android NDK root directory.  You can try using a prebuilt Android NDK version that already has the necessary dependencies included in the toolchain.  Please make sure to use the latest TF version. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1722,"以下是一个github上的tensorflow下的一个issue, 标题是(Slower inference since TensorFlow Lite 2.12)， 内容是 (**System information**  Android Device information: `samsung/dm3qxeea/dm3q:14/UP1A.231005.007/S918BXXS3BWK5:user/releasekeys` (reproduced on any device I tested)  Bundled TFLite version from Maven: `2.12.0` and later  TensorFlow Lite in Play Services SDK version: `16.1.0`  Google Play Services version: `23.45.23 (190400587848529)` **Standalone code to reproduce the issue** I used the TensorFlow Lite Pose Estimation Android Demo where I changed the TensorFlow Lite version **Any other info / logs** With any bundled version of TFLite >= 2.12.0, the inference time of some model is twice the inference time with TFLite v2.11.0. This issue is **not** reproduced with the TFLite from the Play Services. Especially when I compared last week the bundled 2.13.0 against the 2.13.0 from the Play Services. The bundled version inference times were twice the ones of the Play Services. (I can't test it anymore since the version from the Play Services has been updated to 2.15.0 and this one is not available on Maven) For example, on a Samsung Galaxy S23 ultra, the PoseNet model from the example app: TFLite version: `2.11.0 (bundled)` Average inference time: `12.28ms` TFLite version: `2.12.0 (bundled)` Average inference time: `25.93ms` TFLite version: `2.13.0 (bundled)` Average inference time: `26.03ms` TFLite version: `2.14.0 (bundled)` Average inference time: `25.86ms` TFLite version: `2.15.0 (Google Play Services)` Average inference time: `12.12ms` Any idea where that could come from ?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Qheb,Slower inference since TensorFlow Lite 2.12,"**System information**  Android Device information: `samsung/dm3qxeea/dm3q:14/UP1A.231005.007/S918BXXS3BWK5:user/releasekeys` (reproduced on any device I tested)  Bundled TFLite version from Maven: `2.12.0` and later  TensorFlow Lite in Play Services SDK version: `16.1.0`  Google Play Services version: `23.45.23 (190400587848529)` **Standalone code to reproduce the issue** I used the TensorFlow Lite Pose Estimation Android Demo where I changed the TensorFlow Lite version **Any other info / logs** With any bundled version of TFLite >= 2.12.0, the inference time of some model is twice the inference time with TFLite v2.11.0. This issue is **not** reproduced with the TFLite from the Play Services. Especially when I compared last week the bundled 2.13.0 against the 2.13.0 from the Play Services. The bundled version inference times were twice the ones of the Play Services. (I can't test it anymore since the version from the Play Services has been updated to 2.15.0 and this one is not available on Maven) For example, on a Samsung Galaxy S23 ultra, the PoseNet model from the example app: TFLite version: `2.11.0 (bundled)` Average inference time: `12.28ms` TFLite version: `2.12.0 (bundled)` Average inference time: `25.93ms` TFLite version: `2.13.0 (bundled)` Average inference time: `26.03ms` TFLite version: `2.14.0 (bundled)` Average inference time: `25.86ms` TFLite version: `2.15.0 (Google Play Services)` Average inference time: `12.12ms` Any idea where that could come from ?",2023-12-11T14:13:35Z,stat:awaiting tensorflower comp:lite type:performance TFLiteGooglePlayServices Android TF 2.12,closed,0,17,https://github.com/tensorflow/tensorflow/issues/62615,"Hi , Could you please look into the issue Thank you","Hi , I'm looking into this, do you know what Android SDK and API Level you are using?","Hi  , thanks for looking into this. I reproduced the issue while compiling & targeting the Android SDK 34.",", Thanks!, by API version I meant which version of Android are you using? !image Thanks for your help.","Oh, sorry! I tested it on two devices:  Samsung Galaxy s23 Ultra (`samsung/dm3qxeea/dm3q:14/UP1A.231005.007/S918BXXS3BWK5:user/releasekeys`) running Android 14 (API level 34)  Samsung Galaxy A51 (`samsung/a51nseea/a51:13/TP1A.220624.014/A515FXXU8HWI1:user/releasekeys`) running Android 13 (API level 33)","Hi , have you tried Google play services versions 2.12 through 2.14? I don't see it above. Additionally how are you making these measurements? Custom code to measure? A benchmarking tool of some sort? Something else in Android Studio? As I currently see this, it seems like there is no issue with version 2.15 which is the latest... as such while it does seem peculiar, I don't really see this as an issue worth investigating.","Hi , Is there a way to choose which TFLite version I can use through the Google Play Services ? I seems to me that I can only use the one currently available on the device. The week before I opened this issue, it was `2.13.0`, right now it is `2.15.0`. And with both I have ""normal"" inference times. About the measurements, I am using the measurements logged into the example app:  Were you able to test it on a bundled `2.15` version ? I can only have up to the `2.14` on Maven Central. But I tried the nightly build, which is a `2.16` and it still haves the issue: TFLite version: `2.16.0nightly` (bundled) Average inference time: `24.09ms` It seems to me that there is a difference between the Google Play Services builds, and the one from the bundled version. Is this possible ? About Maven Central, is this normal that the `2.15.0` hasn't been published on it ? Thank you for your time.","Hi , just to make sure we're talking about the same environment, how are you bundling 2.16.0nightly? As you said, 2.15.0 is not currently published in Maven Central. Are you building an .aar and bundling that with your project? Like here? https://www.tensorflow.org/lite/android/lite_builduse_nightly_snapshots or are you doing something else? If that is performing poorly then we can look into it, as it's currently underperforming. Thanks for your help and any additional information you can provide.","Hello , I am **not** building the nightly .aar myself. Instead I use, the `ossrhsnapshot` Maven repository, like in the link you provided, and I set the tflite dependencies to: ","Hi , I was able to test on a Galaxy S23 Ultra, with the nightly snapshot:  To use Google Play Services, it seems I have to change some code in the demo, do you have the changes you made to use Google Play Services? so that I can replicate your environment exactly? (or did you change to GPS some other way?) Thanks for your help.","Hi , here are the two commits I used for running the Google Play Services: 1. 1updateeverything.txt: Blindly update dependencies so I can run the project (I suppose you've already done it on your side) 2. 2TfLitegps.txt: GMS dependency + Initialize TFLite before creating the pose estimator + set TFLite runtime to FROM_SYSTEM_ONLY","Thanks , I was able to apply your patches directly and am seeing the same performance improvement:  At least 2, sometimes 3x the speed on the same device, , can you please take a look? Thanks.","Hello, sorry to insist, but is there any news about this ?","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/91 Let us know if you have any questions. Thanks.","Hi  , Thanks for notifying me, I will follow the new issue on the LiteRT Github repo. :+1: ","> Is there a way to choose which TFLite version I can use through the Google Play Services ? No. When using TF Lite in Play services, you always get the latest available version of the LiteRT (TF Lite) runtime library shipped with Play services.  This is intentional and benefits system health since we only need to have one version installed on the device. If you want to use a specific version, or if you want to test with different versions, then you need to use bundled TFLite rather than TF Lite in Play services.",Are you satisfied with the resolution of your issue? Yes No
673,"以下是一个github上的tensorflow下的一个issue, 标题是(pywrap)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15  Custom code Yes  OS platform and distribution windows 11 64 biit  Mobile device windows 11  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  Standalone code to reproduce the issue   Relevant log output  it always show when i run the code)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,milkkywayss,pywrap, Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15  Custom code Yes  OS platform and distribution windows 11 64 biit  Mobile device windows 11  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  Standalone code to reproduce the issue   Relevant log output  it always show when i run the code,2023-12-11T02:42:20Z,stat:awaiting response type:support stale TF 2.15,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62612,"In order to expedite the troubleshooting process, please provide all the dependencies to reproduce the issue reported here. I have faced a different issue for replicating the same as reported,please have a look. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1312,"以下是一个github上的tensorflow下的一个issue, 标题是(Problem converting from saved model to tflite model)， 内容是 (Hi, I'm trying to convert my model (saved in 'saved model' format) to a tflite model but I get an error, this is my code:  `converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') tflite_model = converter.convert() with open('model.tflite', 'wb') as f:   f.write(tflite_model)` The error is this: _**loc(fused[""ReadVariableOp:"", ""sequential_1/conv2d_1/ReadVariableOp""]): error: missing attribute 'value' LLVM ERROR: Failed to infer result type(s).**_ I read the tensorflow page related to the topic and it explains that a refactoring of my model is probably necessary, so I tried to follow the indication but the error I get is the same (my other code is this:) ` import tensorflow as tf converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') converter.target_spec.supported_ops = [   tf.lite.OpsSet.TFLITE_BUILTINS,  enable TensorFlow Lite ops.   tf.lite.OpsSet.SELECT_TF_OPS  enable TensorFlow ops. ] tflite_model = converter.convert() open(""converted_model.tflite"", ""wb"").write(tflite_model) ` I hope someone is able to help me, thanks in advance)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gelminaio,Problem converting from saved model to tflite model,"Hi, I'm trying to convert my model (saved in 'saved model' format) to a tflite model but I get an error, this is my code:  `converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') tflite_model = converter.convert() with open('model.tflite', 'wb') as f:   f.write(tflite_model)` The error is this: _**loc(fused[""ReadVariableOp:"", ""sequential_1/conv2d_1/ReadVariableOp""]): error: missing attribute 'value' LLVM ERROR: Failed to infer result type(s).**_ I read the tensorflow page related to the topic and it explains that a refactoring of my model is probably necessary, so I tried to follow the indication but the error I get is the same (my other code is this:) ` import tensorflow as tf converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') converter.target_spec.supported_ops = [   tf.lite.OpsSet.TFLITE_BUILTINS,  enable TensorFlow Lite ops.   tf.lite.OpsSet.SELECT_TF_OPS  enable TensorFlow ops. ] tflite_model = converter.convert() open(""converted_model.tflite"", ""wb"").write(tflite_model) ` I hope someone is able to help me, thanks in advance",2023-12-10T22:08:57Z,stat:awaiting response type:support stale comp:lite TFLiteConverter,closed,0,15,https://github.com/tensorflow/tensorflow/issues/62610,"Hi , Could you please fill the template to resolve the issue. As well try the code with tensorflow 2.15 version if not tried. Thank You","I'm already using tensorflow 2.15.  1. System information  Windows 10:  Tensorflow installed with pycharm gui:  TensorFlow 2.15 :  2. Code Here are my 3 files, Training for training my model, utils provides a list of methods used in training and test is the class where I use my model (predictions work in tensorflow but the method for converting from saved model  to tflite doesn't work) Training.txt utils.txt Test.txt  3. Failure after conversion When I try to convert my model with the code in Test class I receive this error: loc(fused[""ReadVariableOp:"", ""sequential_1/conv2d_1/ReadVariableOp""]): error: missing attribute 'value' LLVM ERROR: Failed to infer result type(s). Please help me, I've been stuck on this error for weeks..."," ,  Please provide the input data to reproduce the error. Thank You","Sure, this is my dataset: https://mega.nz/file/UrVUEDIKmHkxTofcMjTWiBMzbALDDbnh1CJkZgpsKTezd5zgXTc  Thank you very much!","Hi  , Sorry for the delay, I have executed the code in colab 2.15. It's working as expected. The  saved model inference and tflite inference(both  and ) are the same as expected. Please find the gist. Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Same issue. Colab crash without any error..,"Just in case it helps others like me struggling with this issue. I realized I was using TensorFlow 2.16.1 , from docker image tensorflow:latestgpu and that was the source of the problem. I switched to docker image tensorflow:2.15.0gpu and the problem went away, all working fine now."," Thanks for helping with my project, good idea! Solved this problem.",Same issue.,"Same issue here.  2.16.1 crashed, 2.15 worked.","I have the same issue on TF 2.16.1 (instead it works on 2.15 as suggested) on my local machine, when running the following script that creates a very small NN in Keras and then converts it to TFlite: ","I don't see how switching to 2.15 is any better as CC(Having nonconverted operations, even for simplest models) still persists. This is a different problem, but 2.15 is not the solution to intended development, imo."
1499,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.MaxPooling3D can not still work for bfloat 16 in tensorflow 2.12.0: No OpKernel was registered to support Op ‘MaxPool3D’ )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution mac ventura 13.6.1  Mobile device _No response_  Python version 3.10.  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory No GPU machine  Current behavior? I’m a researcher in the filed of neuroscience using MRI techniques. I have the same question raised by Dr. Roger ( Tensorflow question (MaxPool3d, MaxPool3D, MaxPooling3D)!) 1). I have the same trouble "" No OpKernel was registered to support Op ‘MaxPool3D’"". In my understanding (ModelCheckpoint callback fails when mixed precision is enabled in TF 2.11.0 · Issue CC(Building from source, gcc issues) · kerasteam/tfkeras · GitHub), bfloat 16 did not work for bfloat 16 in the tf.keras.layers.MaxPooling3D one year ago. But the keras team fixed this issue in the verion of  TF 2.12.0 or further newer verions. Is that correct? Please tell me if my understanding is correct or not. If this issue is fixed, any other problems??  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mitsu0703,tf.keras.layers.MaxPooling3D can not still work for bfloat 16 in tensorflow 2.12.0: No OpKernel was registered to support Op ‘MaxPool3D’ ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution mac ventura 13.6.1  Mobile device _No response_  Python version 3.10.  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory No GPU machine  Current behavior? I’m a researcher in the filed of neuroscience using MRI techniques. I have the same question raised by Dr. Roger ( Tensorflow question (MaxPool3d, MaxPool3D, MaxPooling3D)!) 1). I have the same trouble "" No OpKernel was registered to support Op ‘MaxPool3D’"". In my understanding (ModelCheckpoint callback fails when mixed precision is enabled in TF 2.11.0 · Issue CC(Building from source, gcc issues) · kerasteam/tfkeras · GitHub), bfloat 16 did not work for bfloat 16 in the tf.keras.layers.MaxPooling3D one year ago. But the keras team fixed this issue in the verion of  TF 2.12.0 or further newer verions. Is that correct? Please tell me if my understanding is correct or not. If this issue is fixed, any other problems??  Standalone code to reproduce the issue   Relevant log output ",2023-12-09T07:18:54Z,stat:awaiting response type:bug stale comp:keras TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62602,", Could you please provide the complete code or the colab gist to reproduce the issue which helps us debug the issue in an effective way. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1617,"以下是一个github上的tensorflow下的一个issue, 标题是(Failure to compile TF 2.15  from source on rocky 8.8)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15.0  Custom code No  OS platform and distribution rocky linux 8.8  Mobile device no  Python version 3.10.2  Bazel version 6.1.0  GCC/compiler version gcc 11.2.0  and clang 16.0.1  CUDA/cuDNN version 12.2.0  GPU model and memory tesla v100  Current behavior? Compiling fails with an error. Log is shown below. We are using all software  that compiled in house  as needed for the HPC cluster. For the compilation the following modules are loaded   CASE 1: Running .configure results in this .tf.configure.bazelrc file:  CASE 2: If i rerun configure and choose not to use clang as cuda compiler it results in a slightly different .tf.configure.bazelrc file  here are the diffs:  Either way, with or without clang  in configuration bazel build fails. For the CASE 2 compilation went further, but bazel subcommand failed with errors  apparently linking to  /lib64/libstdc++.so.6 ( see log part below). This library should not  used as my LD_LIBRARY_PATH is set  to use clang 16 and gcc 11.2.0 path first and gcc compilation includes libstdc++.so.6 that has all needed  CXXABI and GLIBCXX entries. Bazel binary and clang libraries are linked to use that correct libstdc++.so.6 supplied by gcc 11..2.0  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,nadyawilliams,Failure to compile TF 2.15  from source on rocky 8.8," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15.0  Custom code No  OS platform and distribution rocky linux 8.8  Mobile device no  Python version 3.10.2  Bazel version 6.1.0  GCC/compiler version gcc 11.2.0  and clang 16.0.1  CUDA/cuDNN version 12.2.0  GPU model and memory tesla v100  Current behavior? Compiling fails with an error. Log is shown below. We are using all software  that compiled in house  as needed for the HPC cluster. For the compilation the following modules are loaded   CASE 1: Running .configure results in this .tf.configure.bazelrc file:  CASE 2: If i rerun configure and choose not to use clang as cuda compiler it results in a slightly different .tf.configure.bazelrc file  here are the diffs:  Either way, with or without clang  in configuration bazel build fails. For the CASE 2 compilation went further, but bazel subcommand failed with errors  apparently linking to  /lib64/libstdc++.so.6 ( see log part below). This library should not  used as my LD_LIBRARY_PATH is set  to use clang 16 and gcc 11.2.0 path first and gcc compilation includes libstdc++.so.6 that has all needed  CXXABI and GLIBCXX entries. Bazel binary and clang libraries are linked to use that correct libstdc++.so.6 supplied by gcc 11..2.0  Standalone code to reproduce the issue   Relevant log output ",2023-12-08T18:05:32Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux TF 2.15,open,0,4,https://github.com/tensorflow/tensorflow/issues/62597,Any updates on this? Thanks,"> Any updates on this? Thanks Not sure if this will help, but the issue is on the nvidia side.  https://stackoverflow.com/questions/70301375/noinlinemacroconflictbetweenglibandcuda",Thank you for the pointer.  Looked at the links. Cuda headers do have mentioned wrappers for __noinline__ which seem to be the correct setting.   Clang community  points to cuda sdk and  its not clear who is supposed to be doing a patch or when one is valid.  Is there any configuration of later versions of tensorflow  that was done on RPMbased (CentOS or derivative) system? This guide https://www.tensorflow.org/install/sourcegpu seem to be for ubuntu and any configuration i tried for tensorflow from 2.13 and up is not working,This could be relevant: https://github.com/NVIDIA/thrust/issues/1703 It is a conflict between the __noinline__ macro in CUDA and the __noinline__ attribute in GCC. Clang linking with `libc++` instead of `stdlibc++` could help.
1125,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite MirrorPad in reflect mode yields incorrect results.)， 内容是 ( System information  Windows 11 Enterprise  TensorFlow installed from source  TensorFlow version 2.12.1  Python version 3.10.11  Describe the problem The TFLite MirrorPad operator in reflect mode produces incorrect results in some cases. For example in this case: input: [[0. 1.]  [2. 3.]]  pad: [[2 2]  [2 2]] mode: 'REFLECT' output : [[0. 0. 0. 0. 0. 0.]  [0. 3. 2. 3. 2. 2.]  [2. 1. 0. 1. 0. 0.]  [0. 3. 2. 3. 2. 2.]  [2. 1. 0. 1. 0. 0.]  [2. 1. 0. 1. 0. 0.]] (The output value at [0][0] is also sometimes randomly 1.3739614e30 instead of 0.0) I believe the correct output should be: [[0. 1. 0. 1. 0. 1.]  [2. 3. 2. 3. 2. 3.]  [0. 1. 0. 1. 0. 1.]  [2. 3. 2. 3. 2. 3.]  [0. 1. 0. 1. 0. 1.]  [2. 3. 2. 3. 2. 3.]] Or something similar.   Source code / logs A simple model which demonstrates this issue can be found at https://github.com/Popkorn/Tmp/blob/main/mirror_pad_bug.tflite)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Pop-korn,TFLite MirrorPad in reflect mode yields incorrect results., System information  Windows 11 Enterprise  TensorFlow installed from source  TensorFlow version 2.12.1  Python version 3.10.11  Describe the problem The TFLite MirrorPad operator in reflect mode produces incorrect results in some cases. For example in this case: input: [[0. 1.]  [2. 3.]]  pad: [[2 2]  [2 2]] mode: 'REFLECT' output : [[0. 0. 0. 0. 0. 0.]  [0. 3. 2. 3. 2. 2.]  [2. 1. 0. 1. 0. 0.]  [0. 3. 2. 3. 2. 2.]  [2. 1. 0. 1. 0. 0.]  [2. 1. 0. 1. 0. 0.]] (The output value at [0][0] is also sometimes randomly 1.3739614e30 instead of 0.0) I believe the correct output should be: [[0. 1. 0. 1. 0. 1.]  [2. 3. 2. 3. 2. 3.]  [0. 1. 0. 1. 0. 1.]  [2. 3. 2. 3. 2. 3.]  [0. 1. 0. 1. 0. 1.]  [2. 3. 2. 3. 2. 3.]] Or something similar.   Source code / logs A simple model which demonstrates this issue can be found at https://github.com/Popkorn/Tmp/blob/main/mirror_pad_bug.tflite,2023-12-07T08:49:06Z,stat:awaiting response stale comp:lite comp:ops TFLiteConverter TF 2.12,closed,1,3,https://github.com/tensorflow/tensorflow/issues/62585,"Hi korn,  Both paddings[D, 0] and [D, 1] must be no greater than input.dim_size(D) as per the documentation. pad: [[2 2],[2 2]] gives invalid argument error. As well I tried the MirrorPad operation with Reflect mode for a few more examples. It is working as expected.Please find the gist Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
663,"以下是一个github上的tensorflow下的一个issue, 标题是(Missing symbols in official Windows TensorFlow native builds)， 内容是 (Hi, we (SIGJVM) are trying to leverage the Windows C Library builds available under https://storage.googleapis.com/tensorflow/libtensorflow/ which, I think, are built by Google.  Starting from TF 2.14.x, these builds are broken because they do not export the TSL symbols required by the TensorFlow C API. Here is the list of missing symbols that we (TF Java) do depend on:  Can someone look at this please? (modifié))请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,karllessard,Missing symbols in official Windows TensorFlow native builds,"Hi, we (SIGJVM) are trying to leverage the Windows C Library builds available under https://storage.googleapis.com/tensorflow/libtensorflow/ which, I think, are built by Google.  Starting from TF 2.14.x, these builds are broken because they do not export the TSL symbols required by the TensorFlow C API. Here is the list of missing symbols that we (TF Java) do depend on:  Can someone look at this please? (modifié)",2023-12-06T16:19:21Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale subtype:windows comp:core TF2.14,closed,0,15,https://github.com/tensorflow/tensorflow/issues/62579,It seems like Intel has fixed something related that will land in 2.16: https://github.com/tensorflow/tensorflow/issues/61830 Does that help?,"Thanks  , the ticket seems to talk about the missing include folders (which we've also noticed but found a workaround for), though it does not mention anything about the nonexported symbols in the binaries. Is there a nightly build of 2.16 of the C API for Windows I can quickly test on?",Is there any Windows build available in the libtensorflownightly bucket?,> Is there any Windows build available in the libtensorflownightly bucket? The latest nightly libtensorflow archive for Windows can be found here. ,"Thanks  , we just checked and while the nightly builds do have some of the TSL headers, the `TSL_` symbols are still missing from the binaries. cc\  ",Any updates about this/any PR coming soon? Thanks!,"Hi , PR is in progress, will have it merged to master within a couple of days.","Adding a reference to this comment here as well, problem is still not fixed after merging CC(Include missing tsl/xla folders on Windows): https://github.com/tensorflow/tensorflow/pull/62874issuecomment1926007848",Can you provide a short reproducible code snippet for this?,"I can work on a something yes, though I don't have myself a Windows machine and it may take me some time. Meanwhile, you can look at our CI/CD where our own build (TF Java) is failing: https://github.com/tensorflow/java/actions/runs/7777626622/job/21206146416step:6:1655 (compiler command is here). All other platforms (linux, macos) succeed to link successfully to the C lib, including to TSL symbols.","Just to highlight here that it would be great to have this fix ready for the 2.16 cut, so that TF Java can continue to support Windows properly in its forthcoming  next release.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The PR raised for the similar issue was aslo merged. https://github.com/tensorflow/java/pull/518 The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1861,"以下是一个github上的tensorflow下的一个issue, 标题是(Keras two-head controllable gradient flow)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.11.0  Custom code No  OS platform and distribution Windows 10  Mobile device _No response_  Python version 3.9.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We use a twohead model. We want only one head to be involved in the training, the other  not. And after that  vice versa. So the gradient spreads to the body from one head, and not from the other, after which the heads change roles. The approach is similar to https://arxiv.org/abs/2210.05657 . We have tried some ways to achieve this: 1) Before every head we add dropout with rate = 1 or ~0 and in the generator class change drop rate  ((for example, on method __getitem__() or on_epoch_end() get model layers and change rate: self.model.get_layer('dr1').rate=0 or 1). Please see example 1. 2) Use a custom layer before every head. This layer mul its input to some const. Also, we have tried to change this const var to 0/1 in data. Please see example 2. 3) We have tried to recompile the model after applying changes from paragraphs 1) and 2), but it cause error:     tmp_logs = self.train_function(iterator)     TypeError: 'NoneType' object is not callable Please see example 3. Unfortunately, all upper mentioned approaches didn't work in our case: we can see that the weights have changed in the model, but the output of the model doesn`t change. Prediction output for the model with const=0 or const=1 is the same I want to ask, is it a normal )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ymuv,Keras two-head controllable gradient flow," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.11.0  Custom code No  OS platform and distribution Windows 10  Mobile device _No response_  Python version 3.9.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We use a twohead model. We want only one head to be involved in the training, the other  not. And after that  vice versa. So the gradient spreads to the body from one head, and not from the other, after which the heads change roles. The approach is similar to https://arxiv.org/abs/2210.05657 . We have tried some ways to achieve this: 1) Before every head we add dropout with rate = 1 or ~0 and in the generator class change drop rate  ((for example, on method __getitem__() or on_epoch_end() get model layers and change rate: self.model.get_layer('dr1').rate=0 or 1). Please see example 1. 2) Use a custom layer before every head. This layer mul its input to some const. Also, we have tried to change this const var to 0/1 in data. Please see example 2. 3) We have tried to recompile the model after applying changes from paragraphs 1) and 2), but it cause error:     tmp_logs = self.train_function(iterator)     TypeError: 'NoneType' object is not callable Please see example 3. Unfortunately, all upper mentioned approaches didn't work in our case: we can see that the weights have changed in the model, but the output of the model doesn`t change. Prediction output for the model with const=0 or const=1 is the same I want to ask, is it a normal ",2023-12-06T14:50:42Z,stat:awaiting response stat:awaiting tensorflower type:support stale comp:keras TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62576,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1675,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.GlobalAveragePooling2D() freezes tf.distribute.MirroredStrategy())， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.1  Custom code No  OS platform and distribution NAME=""Amazon Linux"" VERSION=""2"" ID=""amzn"" ID_LIKE=""centos rhel fedora""  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory NVIDIA T4 (4 GPU)  VRAM 64gb  Current behavior? I was preparing my own training script for multigpu support to achieve higher batch sizes using tf.distribute.MirroredStrategy(). Things were working initially but began freezing (seemingly out of the blue) on NVIDIA T4 (4 GPU)  VRAM 64gb, but still runs fine on NVIDIA A10G (4 GPU)  VRAM 96gb. I used the following example to debug on NVIDIA T4 (4 GPU)   VRAM 64gb: Custom training with tf.distribute.Strategy I found that if I substitute their model (See link) with  the training freezes from the start (just like my own code, which is using a similar model). My symptoms are similar to MultiGPU training not starting or freezing. GPUs at 100% It stops freezing if I replace GlobalAveragePooling2D() with a Flatten().  I have also noticed freezing when introducing stride > 1 in the conv layer. Everything runs fine on a singlegpu. Freezing only occurs when using >1 GPU. TF v2.13.1  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,matthewhelmi,tf.keras.layers.GlobalAveragePooling2D() freezes tf.distribute.MirroredStrategy()," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.1  Custom code No  OS platform and distribution NAME=""Amazon Linux"" VERSION=""2"" ID=""amzn"" ID_LIKE=""centos rhel fedora""  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory NVIDIA T4 (4 GPU)  VRAM 64gb  Current behavior? I was preparing my own training script for multigpu support to achieve higher batch sizes using tf.distribute.MirroredStrategy(). Things were working initially but began freezing (seemingly out of the blue) on NVIDIA T4 (4 GPU)  VRAM 64gb, but still runs fine on NVIDIA A10G (4 GPU)  VRAM 96gb. I used the following example to debug on NVIDIA T4 (4 GPU)   VRAM 64gb: Custom training with tf.distribute.Strategy I found that if I substitute their model (See link) with  the training freezes from the start (just like my own code, which is using a similar model). My symptoms are similar to MultiGPU training not starting or freezing. GPUs at 100% It stops freezing if I replace GlobalAveragePooling2D() with a Flatten().  I have also noticed freezing when introducing stride > 1 in the conv layer. Everything runs fine on a singlegpu. Freezing only occurs when using >1 GPU. TF v2.13.1  Standalone code to reproduce the issue   Relevant log output ",2023-12-05T08:52:11Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:dist-strat comp:keras TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/62571,"It may related to those two issues : CC(Keras.fit stuck/error in TensorFlow 2.13/2.14 (TPU is fine, inference on GPU is fine, 2.11 GPU is fine)) CC(TensorFlow 2.13 distributed training fail)","Thanks for the reply ! I had a look at the two issues. In this case the hangs with the specific model architecture above, but runs smooth with the minor modification. And on a single gpu everything runs. ","> Thanks for the reply ! >  > I had a look at the two issues. >  > In this case the hangs with the specific model architecture above, but runs smooth with the minor modification. And on a single gpu everything runs. In the above issues, TensorFlow got stuck when using XLA + multigpus.","Hi ****, It looks like this is a duplicate of issue 18862. Can you please close this issue, since it is already being tracked there. Thank you!",Thanks ! is there something I can try related to the XLA+multigpu issue?,"Hi , I was told on the other issue to open it here as they believed it was TensorFlow related. Would you suggest I close the other one?","> Hi , >  > I was told on the other issue to open it here as they believed it was TensorFlow related. >  > Would you suggest I close the other one? Yes, you can keep this open and close the other one. ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1883,"以下是一个github上的tensorflow下的一个issue, 标题是([MLIR] tf-mlir-translate not working for keras sequential model)， 内容是 ( Issue type Documentation Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version 11.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I wrote a small model to test a few compiler features in tensorflow. The model is saved to a directory using  format. Then I tried using  to convert the model into tf MLIR code. However, that did not work. The conversion terminated abruptly while giving the error message that function with multiple signature detected. I inspected the model with  and found that indeed that  function has two concrete functions with two different set of parameters. I have no idea why the  function has two concrete instantiations. Especially when I never really have any control over how the internal functions get instantiated except for  call.  I expected the MLIR file to be generated. But instead, it is continuously showing error about multiple concrete functions.  Standalone code to reproduce the issue  Then I ran the following command:   I got the following error message:   shell savedmodelcli shows the following output after running the command: saved_model_cli show dir=/home/rashik/Documents/tensorfow_mlir_test/TFESRGAN/graphartifacts/toy_model1 all Output: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT MetaGraphDef with tagset: 'serve' contains the following SignatureDefs: signature_def['__save)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,monowaranjum,[MLIR] tf-mlir-translate not working for keras sequential model," Issue type Documentation Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version 11.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I wrote a small model to test a few compiler features in tensorflow. The model is saved to a directory using  format. Then I tried using  to convert the model into tf MLIR code. However, that did not work. The conversion terminated abruptly while giving the error message that function with multiple signature detected. I inspected the model with  and found that indeed that  function has two concrete functions with two different set of parameters. I have no idea why the  function has two concrete instantiations. Especially when I never really have any control over how the internal functions get instantiated except for  call.  I expected the MLIR file to be generated. But instead, it is continuously showing error about multiple concrete functions.  Standalone code to reproduce the issue  Then I ran the following command:   I got the following error message:   shell savedmodelcli shows the following output after running the command: saved_model_cli show dir=/home/rashik/Documents/tensorfow_mlir_test/TFESRGAN/graphartifacts/toy_model1 all Output: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT MetaGraphDef with tagset: 'serve' contains the following SignatureDefs: signature_def['__save",2023-12-04T16:16:48Z,type:feature type:docs-feature TF 2.15,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62566,"If you can reproduce the issue, please comment if there are any command line mitigation for that. I would really not like to rewrite existing models using tf.function.",", You need to create a wrapper like this and save it (with the wrapper, you specify an explicit .function input_signature=, as the error was suggesting).  Then, when you load it, you need to specify ""exported names"" for just the functions in your wrapper (in the case of the link I specified, it is just one function ""predict""). So after saving the wrapper tf.Module you would load it with something like this: `tfmlirtranslate savedmodelobjectgraphtomlir tfsavedmodelexportednames=predict /path/to/tf2_model o out.mlir` (I notice that you are using a somewhat out of date version of tfmlirtranslate; you should be able to find the corresponding flags in your version; I think the savedmodeltomlir > savedmodelobjectgraphtomlir change is the only nonobvious renaming) We also have a Python API that does the same. You can find how it is invoked in common.py which underlies the keras test I linked above. Thank you!","Thanks, it worked. "
1952,"以下是一个github上的tensorflow下的一个issue, 标题是(""ERROR: tensorflow/lite/util.cc BytesRequired number of elements overflowed."" when benchmarking TFLite model with dynamic input size)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.10  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04.6  Mobile device Samsung S23  Python version 3.7.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am exporting my tensorflow model to TFLite. I want to be able to run the TFLite model on mobile device GPU with different input shapes. I looked in many places, but I am missing a reliable info in documentation stating how such models should be exported. For that, I was using the following code:  Everything works fine, and the model is exported. From the `tf.lite.experimental.Analyzer` I get the following log: `Your model looks compatibile with GPU delegate with TFLite runtime version 2.10.0.` I can then locally load the model and run it with any valid shape:  However when I use the TFLite benchmark model tool, with the GPU delegate and custom input shape  adb command:  `./android_aarch64_benchmark_model_plus_flex graph=./my_model_dynamic.tflite use_gpu=true input_layer=input_1 input_layer_shape=1, 512, 512, 3` the benchmark fails with the following error:  When I do not set the GPU delegate (execute without the `use_gpu=true` flag), everything works fine. Also, when I export my model with a predefined dummy shape:  The same adb command I pasted above works well. Could You clarify why the first approach fails? Is it a bug in the benchmark model app? Or should I just use the second one (with dummy input shapes)?  Standalone)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,JakubGorski,"""ERROR: tensorflow/lite/util.cc BytesRequired number of elements overflowed."" when benchmarking TFLite model with dynamic input size"," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.10  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04.6  Mobile device Samsung S23  Python version 3.7.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am exporting my tensorflow model to TFLite. I want to be able to run the TFLite model on mobile device GPU with different input shapes. I looked in many places, but I am missing a reliable info in documentation stating how such models should be exported. For that, I was using the following code:  Everything works fine, and the model is exported. From the `tf.lite.experimental.Analyzer` I get the following log: `Your model looks compatibile with GPU delegate with TFLite runtime version 2.10.0.` I can then locally load the model and run it with any valid shape:  However when I use the TFLite benchmark model tool, with the GPU delegate and custom input shape  adb command:  `./android_aarch64_benchmark_model_plus_flex graph=./my_model_dynamic.tflite use_gpu=true input_layer=input_1 input_layer_shape=1, 512, 512, 3` the benchmark fails with the following error:  When I do not set the GPU delegate (execute without the `use_gpu=true` flag), everything works fine. Also, when I export my model with a predefined dummy shape:  The same adb command I pasted above works well. Could You clarify why the first approach fails? Is it a bug in the benchmark model app? Or should I just use the second one (with dummy input shapes)?  Standalone",2023-12-04T15:17:44Z,stat:awaiting response type:support comp:lite TFLiteGpuDelegate TF 2.10,closed,2,9,https://github.com/tensorflow/tensorflow/issues/62565, did You have a look into this? Are You able to help?,"Hi  , Please look into the issue Thank You","Hi , did you get the binary from somewhere? or did you build android_aarch64_benchmark_model_plus_flex from source? If you built it from source can you let us know the command you used? Also if so, what OS/platform did you use to build the binary? Did you run the configure script prior to building it? If so did you build with Cuda or RocM support? Thanks for all the additional information which will help.","Hi . Thanks for Your help.  First I used the binary from https://storage.googleapis.com/tensorflownightlypublic/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model_plus_flex. Then I was trying to get accustomed with the benchmark model code and fix the error so I was building it from source. I used the command: `sudo bazel build c opt  cxxopt=std=c++11  config=android_arm64 define=xnn_enable_arm_i8mm=false   tensorflow/lite/tools/benchmark:benchmark_model` on **Linux Ubuntu 20.04.6**. I ran the configure script before  I build it with Cuda support (without RocM). **Both binaries gave me the same error.**  I will provide some additional info, maybe will be helpful: When I use the TFLite benchmark model tool with `use_gpu=false use_xnnpack=true input_layer=input_1 input_layer_shape=1, 512, 512, 3` , the model created with dynamic input shapes also fails (with the same error). It only executes correctly with the default delegate. What is more weird, the default delegate is actually also the XNNPACK. The difference lies in the order of the execution in the TFLite benchmark tool: 1. When default delegate is used, the `interpreter_>ResizeInputTensor(i, input.shape);` call is first, then `interpreter_>AllocateTensors()` is called. 2. When delegate is specified explicitly (gpu, xnnpack etc.), first the `interpreter_>ModifyGraphWithDelegate(delegate)` call is executed. This call invokes the `Subgraph::EnsureMemoryAllocations()` where there is `AllocateTensors()` call.  During this call the error arises. If I call the `interpreter_>ResizeInputTensor(i, input.shape)` function first (before `interpreter_>ModifyGraphWithDelegate(delegate)`) evertything seems to be working fine. But maybe the best solution is to export my tflite model with dummy input size? But I read here: https://github.com/tensorflow/tensorflow/issues/41807issuecomment673161339 that it's not the right way.","Hi , a dummy input size/making things static before it enters our ecosystem will generally always work but is a little bit clunky and not the best developer experience, I believe what you are doing should still work but if you need to continue your work ASAP feel free to go ahead with that solution, while we figure this out  but as always we appreciate your help and the additional information you provided definitely helps. I'll look into this further.","Hi , this is now updated ://github.com/tensorflow/tensorflow/commit/d6e68d61084f98d6a09151cdc91b59e36e6701b2, please retest your workflow and let us know if it resolves your issue.","Hi , I retested my workflow. The problem is fixed! Thank You for Your help :)","Np, , if you have no other open items regarding this, please feel free to close.",Are you satisfied with the resolution of your issue? Yes No
1393,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to load saved model with TPU using mixed precision bfloat16)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to train a custom model with TPU using mixed precision bfloat16. I'm able to train the model and save checkpoints in `.keras` format during training. However, when trying to load a saved model with `tf.keras.models.load_model` I'm getting an error which I'm not able to figure out.   The custom model I'm trying to train uses Efficientnet as backbone and the error is raised when trying to load the mean and variance from the normalization layer of the Efficientnet model. I've reproduced the issue using only the Efficientnet model. Using full precision, the error doesn't happen. Also, when training with mixed precision float16 using a single gpu the error doesn't happen either.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,rcalonso,Unable to load saved model with TPU using mixed precision bfloat16," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to train a custom model with TPU using mixed precision bfloat16. I'm able to train the model and save checkpoints in `.keras` format during training. However, when trying to load a saved model with `tf.keras.models.load_model` I'm getting an error which I'm not able to figure out.   The custom model I'm trying to train uses Efficientnet as backbone and the error is raised when trying to load the mean and variance from the normalization layer of the Efficientnet model. I've reproduced the issue using only the Efficientnet model. Using full precision, the error doesn't happen. Also, when training with mixed precision float16 using a single gpu the error doesn't happen either.  Standalone code to reproduce the issue   Relevant log output ",2023-12-04T08:56:55Z,stat:awaiting response type:bug stale comp:dist-strat TF2.14,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62564,"Hello, ! Could you try to use the tf.keras.experimental.load_from_saved_model function with the policy=""infer_float32_vars"" argument. This will load the model with the appropriate mixed precision policy for inference. Also could you try with latest TF v2.15 or nightly and let us know? Thank you!","Hi , thanks for the response. The function `tf.keras.experimental.load_from_saved_model` is not available in TF 2.14.1 and 2.15. According to https://github.com/tensorflow/tensorflow/blob/v2.15.0/tensorflow/python/keras/saving/saved_model_experimental.pyL407L409 the function `tf.keras.experimental.load_from_saved_model` is deprecated. Also, using the policy `infer_float32_vars` is not possible because is deprecated.  I tried the code I provided in the description with TF 2.15 in cloud TPU and the same error was raised.", Thanks for replying here. It seems that there is incompatibility between the saved model format and the current execution environment. This usually happens when a model trained with mixed precision and TPUs is attempted to be loaded on a CPU or without setting the appropriate mixedprecision settings. Install or update the tensorflowmodeloptimization library if needed Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you., I'm saving the model in `.keras` format because when saving with the saved model format (`tf`) the custom train step was not saved. I created an issue for this https://github.com/tensorflow/tensorflow/issues/62450 What would be the appropriate mixedprecision settings? I've tried loading the model with float32 policy but the same error was raised. The tensorflowmodeloptimization version used is the latest available.,"HI  , Apologies for the delay. I have modified the code to Keras3 compatible and its executing fine.Please refer the attached gist. Could you please check and confirm ? Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
991,"以下是一个github上的tensorflow下的一个issue, 标题是(Python >=3.11 TF memory leaks)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code Yes  OS platform and distribution Debian GNU/Linux 11 (bullseye)   Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Basic tensorflow calls leak memory in python 3.11 Running in basic docker envs:  The following code (which only runs `tf.zeros(shape=(1,))` in a loop !!!)  produces the following matrix of results:     The issue has been there since the first available 3.11 version (tf 2.12rc0 if I remember correctly)  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,0x0L,Python >=3.11 TF memory leaks," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code Yes  OS platform and distribution Debian GNU/Linux 11 (bullseye)   Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Basic tensorflow calls leak memory in python 3.11 Running in basic docker envs:  The following code (which only runs `tf.zeros(shape=(1,))` in a loop !!!)  produces the following matrix of results:     The issue has been there since the first available 3.11 version (tf 2.12rc0 if I remember correctly)  Standalone code to reproduce the issue   Relevant log output _No response_",2023-12-03T16:39:19Z,stat:awaiting response stat:awaiting tensorflower type:build/install comp:runtime subtype: ubuntu/linux TF 2.15,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62551,  Any news on this issue? ,I'm having same issue.  have you fixed this?, I tried using tcmalloc but that didn't change a thing...  I am switching to torch for my next projects ,"Just ran the same test with 2.16.1:  While leaks in graph mode seem fixed, leaks in eager mode got worse See https://github.com/0x0L/tf_memleak_test",", As per the official document, from the TensorFlow v2.16, the compatible python version is 3.93.12. Could you please try to test with the latest tensorflow and provide whether you are facing the similar issue. https://www.tensorflow.org/install/sourcecpu Thank you!",Running the same test with python 3.11.11 and tf 2.17.0 shows no leaks Closing,Are you satisfied with the resolution of your issue? Yes No
1562,"以下是一个github上的tensorflow下的一个issue, 标题是(Output Inconsistency in XLA Compilation with Order Swapping of `tf.multiply` on GPU)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? We have identified a significant inconsistency in TensorFlow's XLA compilation when the order of operands in `tf.multiply` is swapped.  This behavior is only seen on **gpu.**  Additional Testing Conducted To further investigate the issue, we conducted the following tests: 1. **Altering `tf.transpose` and `tf.multiply`**: Removing either `tf.transpose` or the first instance of `tf.multiply` prevents the inconsistency, suggesting their involvement in the issue. 2. **Replacing `tf.squeeze`**: Substituting `tf.squeeze` with `tf.math.reduce_min` also triggers the error. This finding implies that the root cause of the inconsistency may not lie within the `tf.squeeze` API. We hope this detailed report will assist in identifying and resolving the root cause of this inconsistency in TensorFlow's XLA compilation process.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Output Inconsistency in XLA Compilation with Order Swapping of `tf.multiply` on GPU," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? We have identified a significant inconsistency in TensorFlow's XLA compilation when the order of operands in `tf.multiply` is swapped.  This behavior is only seen on **gpu.**  Additional Testing Conducted To further investigate the issue, we conducted the following tests: 1. **Altering `tf.transpose` and `tf.multiply`**: Removing either `tf.transpose` or the first instance of `tf.multiply` prevents the inconsistency, suggesting their involvement in the issue. 2. **Replacing `tf.squeeze`**: Substituting `tf.squeeze` with `tf.math.reduce_min` also triggers the error. This finding implies that the root cause of the inconsistency may not lie within the `tf.squeeze` API. We hope this detailed report will assist in identifying and resolving the root cause of this inconsistency in TensorFlow's XLA compilation process.  Standalone code to reproduce the issue   Relevant log output ",2023-12-03T14:28:05Z,stat:awaiting response type:bug stale comp:xla TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62546,"The code you have mentioned has random number generation, the outputs cannot be guaranteed for each run. I have tried by setting seed and enabling op determinism and it still produces random results. ","Hi , I don't believe that the problem you mentioned is influencing this issue. This is because we generated random inputs before feeding them to the models and ensured that the same inputs were given to both models. Additionally, the fact that eager mode does not trigger this behavior seems to support this perspective.",Change in order of operation will take the different code path and the results are expected. This is not considered as a bug.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
833,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: batch_dims != 0 is not supported for ragged gather yet.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? shell raise ValueError('batch_dims != 0 is not supported for ragged gather yet.') ValueError: batch_dims != 0 is not supported for ragged gather yet. ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,beanduan22,ValueError: batch_dims != 0 is not supported for ragged gather yet., Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? shell raise ValueError('batch_dims != 0 is not supported for ragged gather yet.') ValueError: batch_dims != 0 is not supported for ragged gather yet. ```  Relevant log output _No response_,2023-12-03T06:43:15Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62544,"Hi  , As the exception indicates ragged tensor gather won't yet support with `batch_dims != 0`. It is intended behaviour. Also the innermost dimension of indices should not be ragged.The indices were changed to make it workable. Please refer attached gist. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1833,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistency in XLA Compiled Model Involving `tf.nn.softmax, tf.cast, tf.math.reduce_sum` and Additional Concat Output)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have identified a inconsistency issue in TensorFlow when running a model under XLA compilation. The model uses a combination of `tf.nn.softmax`, `tf.cast`, and `tf.math.reduce_sum` operations, and the inconsistency arises when an additional `tf.concat` output node is included.  Troubleshooting Conducted To isolate the cause of this issue, the following tests were conducted: 1. **Removing Individual Operations**: We methodically removed each operation (`tf.nn.softmax`, `tf.transpose`, `tf.math.reduce_sum`, and `tf.cast`) from the model. In each case, this alteration prevented the inconsistency error, suggesting that the combination of these operations contributes to the issue. 2. **Altering Output Structure**: Removing the `tf.concat` nodes from Model2's return values also resolved the inconsistency, indicating that the manner in which outputs are structured and concatenated is a factor. 3. Run the model on **gpu** device. I hope these findings will assist in identifying and resolving the root cause of this inconsistency issue in TensorFlow's XLA compilation.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,"Inconsistency in XLA Compiled Model Involving `tf.nn.softmax, tf.cast, tf.math.reduce_sum` and Additional Concat Output"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have identified a inconsistency issue in TensorFlow when running a model under XLA compilation. The model uses a combination of `tf.nn.softmax`, `tf.cast`, and `tf.math.reduce_sum` operations, and the inconsistency arises when an additional `tf.concat` output node is included.  Troubleshooting Conducted To isolate the cause of this issue, the following tests were conducted: 1. **Removing Individual Operations**: We methodically removed each operation (`tf.nn.softmax`, `tf.transpose`, `tf.math.reduce_sum`, and `tf.cast`) from the model. In each case, this alteration prevented the inconsistency error, suggesting that the combination of these operations contributes to the issue. 2. **Altering Output Structure**: Removing the `tf.concat` nodes from Model2's return values also resolved the inconsistency, indicating that the manner in which outputs are structured and concatenated is a factor. 3. Run the model on **gpu** device. I hope these findings will assist in identifying and resolving the root cause of this inconsistency issue in TensorFlow's XLA compilation.  Standalone code to reproduce the issue   Relevant log output ",2023-12-02T16:24:30Z,stat:awaiting response type:bug stale comp:xla TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62539," Hi, have you reproduced this behavior?",", I was able to reproduce the issue on tensorflow v2.14, v2.15 and tfnightly. Kindly find the gist of it here.","It is not expected to get the desired matching results when you **Altering Output Structure**, the behavior which you are observing is intended and it is not a bug.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1261,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Lite Flex Op Request: modulo operator)， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04, but will extend to windows.  TensorFlow installed from (source or binary): binary/pip  TensorFlow version (or github SHA if from source): 2.15.0  **Provide the text output from tflite_convert**  **Standalone code to reproduce the issue**  colab here Coming from here: I would like to be able to add tf.Mod to the allowed list. As noted in the Colab, I'm not sure what ""best practice"" is here. Is it better to set allow_custom_ops to True and move on? I would like to deploy on mobile, and am concerned about file size and performance. Edit: making a custom op doesn't cleanly solve my issue, since the code I'm trying to convert originates from JAX. I'm ok with submitting a PR myself too, but might like some help. Further edit: it turns out I can work around this issue by refactoring my model. This won't be too bad, but since this would be a nice feature to have anyway for me and potentially others, not closing the issue yet.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kjabon,TensorFlow Lite Flex Op Request: modulo operator,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04, but will extend to windows.  TensorFlow installed from (source or binary): binary/pip  TensorFlow version (or github SHA if from source): 2.15.0  **Provide the text output from tflite_convert**  **Standalone code to reproduce the issue**  colab here Coming from here: I would like to be able to add tf.Mod to the allowed list. As noted in the Colab, I'm not sure what ""best practice"" is here. Is it better to set allow_custom_ops to True and move on? I would like to deploy on mobile, and am concerned about file size and performance. Edit: making a custom op doesn't cleanly solve my issue, since the code I'm trying to convert originates from JAX. I'm ok with submitting a PR myself too, but might like some help. Further edit: it turns out I can work around this issue by refactoring my model. This won't be too bad, but since this would be a nice feature to have anyway for me and potentially others, not closing the issue yet.",2023-12-02T14:44:23Z,type:support comp:lite comp:lite-flex TF 2.15,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62538,"Hi ,   I have reproduced the code. As per the  documentation, it is recommended to set converter.allow_custom_ops = True. As you mentioned, custom op doesnot solve your issue completely for your usecase, could you please provide some more details for better understanding the problem. Thank You","I've worked around this issue entirely by using tfcompile  much fewer headaches since jax2tf wraps stablehlo which is converted directly to xla. But to answer your question, the source is in jax  so it it's not clear to me how one would use both tf (custom ops) and jax/lax functions and then pass that to jax2tf. ",Are you satisfied with the resolution of your issue? Yes No
1560,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistency in XLA Compiled Model with Additional `tf.math.ceil` and` tf.transpose` Outputs)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? I've encountereda bug in TensorFlow where a model with additional `tf.math.ceil` and `tf.transpose` outputs yields inconsistent results under XLA compilation. This error is only seen on **gpu**. After a series of experiments to locate the root cause of this behavior, we found that (1) altering the outputs of Model2 (either by adding more output tensors or removing one of the current output tensors), or (2) removing the casting operation (along with changing the input tensor data type), or (3) eliminating one of the operators within the model2, does not trigger this error.  These findings suggest that the inconsistency may be linked to the specific combination of operations and outputs in the XLAcompiled execution path.  We hope these insights will assist you in pinpointing the root cause of the bug.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Inconsistency in XLA Compiled Model with Additional `tf.math.ceil` and` tf.transpose` Outputs," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? I've encountereda bug in TensorFlow where a model with additional `tf.math.ceil` and `tf.transpose` outputs yields inconsistent results under XLA compilation. This error is only seen on **gpu**. After a series of experiments to locate the root cause of this behavior, we found that (1) altering the outputs of Model2 (either by adding more output tensors or removing one of the current output tensors), or (2) removing the casting operation (along with changing the input tensor data type), or (3) eliminating one of the operators within the model2, does not trigger this error.  These findings suggest that the inconsistency may be linked to the specific combination of operations and outputs in the XLAcompiled execution path.  We hope these insights will assist you in pinpointing the root cause of the bug.  Standalone code to reproduce the issue   Relevant log output ",2023-12-02T08:42:39Z,stat:awaiting response type:bug stale comp:xla TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62532,Go I was not able to replicate the issue on both cpu and gpu using colab. Please have a look at these gist and let us know if I am missing something here? Thank you!,"Hi  , have you tried this with V100 GPU?","Go Inside the call function you are generating the value for tensor, which in each calls generates different random values because XLA currently ignores TF seeds to random operations which makes the output different for obvious reason. Please refer known issues from XLA section.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
995,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: module 'tensorflow' has no attribute 'contrib' )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0 I think  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I know this error happens because I am using a newer version of tensorflow but I can't downgrade my python version due to the hardware I am using. Is it possible to get the right tensorflow version for this (I think 2.4 should work) or is there some other way I can solve this error? Thanks!  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JT-Studios,AttributeError: module 'tensorflow' has no attribute 'contrib' , Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0 I think  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I know this error happens because I am using a newer version of tensorflow but I can't downgrade my python version due to the hardware I am using. Is it possible to get the right tensorflow version for this (I think 2.4 should work) or is there some other way I can solve this error? Thanks!  Standalone code to reproduce the issue   Relevant log output ,2023-12-02T01:05:04Z,stat:awaiting response type:bug stale comp:apis TF 2.15,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62531,"Hi **Studios** , Could you please provide a code snippet to reproduce the issue reported here. And the error you're encountering, specifically the AttributeError stating that the module 'tensorflow' has no attribute 'contrib,' is likely due to changes in TensorFlow versions. The 'contrib' module was present in earlier versions of TensorFlow but has been deprecated in recent releases. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1474,"以下是一个github上的tensorflow下的一个issue, 标题是(Internal quantize ops don't match external quantization)， 内容是 ( 1. System information  Occurs in Google Colab w/ TF 2.14  Have also verified w. TF 2.7 (Anaconda) on Windows 10  2. Code Colab to reproduce issue The Colab trains a basic MNIST model (deterministically, so your model should be the same as mine) and performs PostTraining Quantization.  One quantized model (left side of image) uses INT8 input/output, requiring the provided external quant/dequant code.  The other quantized model (right side of image) takes FP32 input, embedding the quantize/dequantize layers into the model graph. !image  3. Failure after conversion Conversion executes successfully, but model outputs differ.  Why? Shouldn't the two methods be interchangeable? I have verified that the weights, biases, quantization zero points and quantization scales match between the two models. I have also run into this issue using a CPUonly Colab runtime, meaning it doesn't happen because one approach quantizes on the CPU while the other quantizes on the GPU/TPU. Obviously, the difference between 0.5938 and 0.5468 is not significant in this MNIST model.  However, in applications where softmax outputs are averaged to produce a final output, such small discrepancies can significantly alter model accuracy.  Thank you!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,EClemMarq,Internal quantize ops don't match external quantization," 1. System information  Occurs in Google Colab w/ TF 2.14  Have also verified w. TF 2.7 (Anaconda) on Windows 10  2. Code Colab to reproduce issue The Colab trains a basic MNIST model (deterministically, so your model should be the same as mine) and performs PostTraining Quantization.  One quantized model (left side of image) uses INT8 input/output, requiring the provided external quant/dequant code.  The other quantized model (right side of image) takes FP32 input, embedding the quantize/dequantize layers into the model graph. !image  3. Failure after conversion Conversion executes successfully, but model outputs differ.  Why? Shouldn't the two methods be interchangeable? I have verified that the weights, biases, quantization zero points and quantization scales match between the two models. I have also run into this issue using a CPUonly Colab runtime, meaning it doesn't happen because one approach quantizes on the CPU while the other quantizes on the GPU/TPU. Obviously, the difference between 0.5938 and 0.5468 is not significant in this MNIST model.  However, in applications where softmax outputs are averaged to produce a final output, such small discrepancies can significantly alter model accuracy.  Thank you!",2023-12-01T19:27:53Z,stat:awaiting response type:bug stale comp:lite type:performance TFLiteConverter ModelOptimizationToolkit TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62530," Hi , I have verified that the weights and biases are the same for both the model but zero point and scale are not the same for these two models. Please find the gist. Could you please look into the issue.  Thank You","I tried looking at the MLIR representations: Internal model:  External model:  As you said the scale factors are equivalent. I tried explicitly casting the external computations to np.float32 (just in case we got the rare python floats are actually 64bit issues) but that didn't change anything. I also cloned the colab and did each model in their separate notebooks and still got this discrepancy (just in case there's some randomization from quantizing/evaluating in a different order or one after another). , can you please take a look? Thanks.","Hi  , if you are able to access a linux system you may be able to resolve your issue by using AIEdgeTorch, you can find more information here: googleblog. I have actually created a simple script for converting your model here , you can quantize your model after this step:  If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1586,"以下是一个github上的tensorflow下的一个issue, 标题是(1D/2D Tensor strided sliding window)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I tried to implement strided sliding window over Audio `[None,]` or MelSpectrogram `[time, freq]`. It seems like very straightforward thing to make over regular python array. I had some implementation in notebook which worked in eager mode and with .function decorator:   However, using it in tf.data pipeline resulted first in:  `TypeError: unsupported operand type(s) for : 'NoneType' and 'int'`. I switched from `tensor.shape[0]` to `tf.shape(tensor)[0]`, which results in:  I was struggling to come up with some solution to this and ended using  `tf.image.extract_patches()`, but it makes my data pipeline more convoluted and seems like an overkill for my task. I tried looking up for `extract_patches()` implementation for some inspiration but it's not python op. Does anyone know how to deal with such problem? I can imagine it requires using some tensorflownative mapping or looping mechanisms like `tf.map_fn()`.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,niemiaszek,1D/2D Tensor strided sliding window," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I tried to implement strided sliding window over Audio `[None,]` or MelSpectrogram `[time, freq]`. It seems like very straightforward thing to make over regular python array. I had some implementation in notebook which worked in eager mode and with .function decorator:   However, using it in tf.data pipeline resulted first in:  `TypeError: unsupported operand type(s) for : 'NoneType' and 'int'`. I switched from `tensor.shape[0]` to `tf.shape(tensor)[0]`, which results in:  I was struggling to come up with some solution to this and ended using  `tf.image.extract_patches()`, but it makes my data pipeline more convoluted and seems like an overkill for my task. I tried looking up for `extract_patches()` implementation for some inspiration but it's not python op. Does anyone know how to deal with such problem? I can imagine it requires using some tensorflownative mapping or looping mechanisms like `tf.map_fn()`.  Standalone code to reproduce the issue   Relevant log output ",2023-12-01T14:20:27Z,stat:awaiting response type:support stale comp:ops TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62526,"Hi   , I have replicated the reported behaviour with colab using TF v2.14, 2.15 and tfnightly. Please find the gist here for reference. Thank you!","> Hi  , >  > I have replicated the reported behaviour with colab using TF v2.14, 2.15 and tfnightly. Please find the gist here for reference. >  > Thank you!  I guess you pinged the wrong person under this issue, as this person created different issue. Anyway, I've checked your gist and it's accurate, replicating my behaviour. Thanks.","Hello  ,  . Is it possible to get some tensorflower assigned to help with this issue? I've managed to resolve this issue by using `tf.image.extract_patches` as slicing mechanism for 1D or 2D arrays, but honestly this is not an universal solution and I can imagine getting into trouble in future where there is no such native highlevel abstract op. I know that it's probably my skill issue in writing tf.function code for usage in tf.data pipelines, but I couldn't really find any general solution","Hi **** , Sorry for the delay, I will share another approach with you now is to use tf.signal.frame, which is designed for creating frames of a signal (which can be your audio data or melspectrogram data) with specified frame length and step. This function will be suitable for creating a strided sliding window. Here you are encountering error is due to trying to use python's native iteration and slicing mechanisms directly on tensorflow tensors within a graphexecuted context such as within .function or when using tf.data.Dataset.map. TensorFlow's execution model doesn't allow for Pythonlevel iteration over tensors directly because the shapes and operations need to be graphcompiletime determinable for performance and distributability. Here's how you can adjust your function to use tf.signal.frame for creating a sliding window over a 1D tensor (like your audio data). If your tensor has more dimensions (like your MelSpectrogram [time, freq]), you may need to adjust the approach slightly, but the principle remains the same: Here I am providing gist for your reference. This code uses tf.signal.frame to create the sliding window over the tensor. Note that tf.signal.frame expects at least a 2D tensor, so if you're working with a 1D tensor (like an audio waveform), you might need to expand its dimensions first. After processing, you can optionally squeeze the tensor to remove any unwanted dimensions. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
1051,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistency in XLA Compiled Model with Extra Transpose and Argmax Output Nodes)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? In TensorFlow 2.15.0, I've found that a XLA compiled model returning an extra two nodes produces inconsistent outputs, compared to a simpler model. This inconsistency is observed on both **CPU and GPU devices**. Interestingly, removing one of the extra output nodes from the complex model resolves the discrepancy.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Inconsistency in XLA Compiled Model with Extra Transpose and Argmax Output Nodes," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? In TensorFlow 2.15.0, I've found that a XLA compiled model returning an extra two nodes produces inconsistent outputs, compared to a simpler model. This inconsistency is observed on both **CPU and GPU devices**. Interestingly, removing one of the extra output nodes from the complex model resolves the discrepancy.  Standalone code to reproduce the issue   Relevant log output ",2023-12-01T06:57:13Z,stat:awaiting response type:bug stale comp:xla TF 2.15,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62521, I was able to replicate the issue on both gpu and cpu. Please find the attached gists here. Thank you!,"When you try to compare with additional nodes output to assert_allclose, it gives mismatch and it is working as expected when you remove those nodes as you have mentioned.  ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1012,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistency in XLA Compiled Models with Distributed Multiplications, `tf.abs`, and `tf.clip_by_value`)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TensorFlow 2.15.0, I've encountered an inconsistency where models involving distributed multiplications combined with `tf.abs` and `tf.clip_by_value` yield different results under XLA compilation. This behavior only seen on **cpu.** You can reproduce this bug on colab  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,"Inconsistency in XLA Compiled Models with Distributed Multiplications, `tf.abs`, and `tf.clip_by_value`"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TensorFlow 2.15.0, I've encountered an inconsistency where models involving distributed multiplications combined with `tf.abs` and `tf.clip_by_value` yield different results under XLA compilation. This behavior only seen on **cpu.** You can reproduce this bug on colab  Standalone code to reproduce the issue   Relevant log output ",2023-11-30T15:56:38Z,stat:awaiting response type:bug stale comp:xla TF 2.15,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62517,"Hi Go , I have replicated the reported behaviour with colab using TF v2.14, 2.15 and nightly. Please find the gist here for reference. Thank you!","Hi, This precision loss is due to the different order of multiplication and involving mutiple `tf.multiply `operations will accumulate the precession error. This does not show any unexpected behavior in the implementation.  vs  ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Since it is not an implementation bug, I will close this issue.",Are you satisfied with the resolution of your issue? Yes No
1703,"以下是一个github上的tensorflow下的一个issue, 标题是(Output Discrepancies in TensorFlow Model with Extra Concat Output Node Under XLA Compilation)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TensorFlow 2.15.0, I have encountered an issue where adding an **extra concat output node** to a model results in discrepancies in the output when compiled with XLA. This inconsistency is not observed without XLA compilation.  Additional Context In our efforts to understand and locate the root cause of this issue, we have conducted several tests and experiments. Through this process, we've identified specific conditions under which the discrepancy does not occur: 1. Removing an Operator: If any one of the operators `(expand_dims, multiply, abs)` is removed from either model, the discrepancy under XLA compilation is no longer triggered. 2. Removing `concated` from Model2's Return: Omitting the concated tensor from the output of Model2 results in no discrepancy between the two models under XLA compilation. 3. Changing Input Tensor Data Type: Altering the data type of the input tensor to a type other than `int8` also prevents the occurrence of this discrepancy.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Output Discrepancies in TensorFlow Model with Extra Concat Output Node Under XLA Compilation," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TensorFlow 2.15.0, I have encountered an issue where adding an **extra concat output node** to a model results in discrepancies in the output when compiled with XLA. This inconsistency is not observed without XLA compilation.  Additional Context In our efforts to understand and locate the root cause of this issue, we have conducted several tests and experiments. Through this process, we've identified specific conditions under which the discrepancy does not occur: 1. Removing an Operator: If any one of the operators `(expand_dims, multiply, abs)` is removed from either model, the discrepancy under XLA compilation is no longer triggered. 2. Removing `concated` from Model2's Return: Omitting the concated tensor from the output of Model2 results in no discrepancy between the two models under XLA compilation. 3. Changing Input Tensor Data Type: Altering the data type of the input tensor to a type other than `int8` also prevents the occurrence of this discrepancy.  Standalone code to reproduce the issue   Relevant log output ",2023-11-30T11:54:08Z,stat:awaiting response type:bug stale comp:xla TF 2.15,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62512,"Hi Go  , I have replicated the reported behaviour with colab using TF v2.14, 2.15 and nightly. Please find the gist here for reference. Thank you!","Hi, Could you please explain why `concated` was being returned in `Model2` where as `Model1` doesn't return this. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hello , We were considering the importance of examining the intermediate values in the layer and thought it might be a crucial aspect to look into.","Hi, Returning the different outputs for both the results and then comparing will not yield same result. The behavior is expected and it does not not look like a bug.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1333,"以下是一个github上的tensorflow下的一个issue, 标题是(Output Discrepancy in Mathematically Equivalent Models with`tf.abs` Under XLA Compilation)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TensorFlow 2.15.0, two models involving `tf.abs` and presenting mathematically equivalent operations are producing different results when compiled with XLA. This inconsistency is not observed in eager execution mode. Both models essentially compute the square of the sum of inp1 and inp2. In Model1, this is done directly by squaring the sum (inp1 + inp2)^2. In Model2, it is achieved by distributing the multiplication across the sum, inp1*(inp1 + inp2) + inp2*(inp1 + inp2), which simplifies to the same result. The inclusion of tf.abs should not affect the mathematical equivalence of these operations.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Output Discrepancy in Mathematically Equivalent Models with`tf.abs` Under XLA Compilation," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TensorFlow 2.15.0, two models involving `tf.abs` and presenting mathematically equivalent operations are producing different results when compiled with XLA. This inconsistency is not observed in eager execution mode. Both models essentially compute the square of the sum of inp1 and inp2. In Model1, this is done directly by squaring the sum (inp1 + inp2)^2. In Model2, it is achieved by distributing the multiplication across the sum, inp1*(inp1 + inp2) + inp2*(inp1 + inp2), which simplifies to the same result. The inclusion of tf.abs should not affect the mathematical equivalence of these operations.  Standalone code to reproduce the issue   Relevant log output ",2023-11-30T11:36:18Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:xla TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62510,"Hi Go , I have replicated the reported behaviour with jit_compile=True. With jit_compile=False the results are same. Attaching gist for reference. Needs to check for this behaviour.",It seems the problem is with tf.abs Op with XLA which is not converting ve values to positive for Model1. If we remove this operation then it works as intended and results are same with `jit` also.Refer attached gist.,"I tried to reproduce the same issue in TF 2.15.0 and also the latest Tensorflow version (TF 2.18.0). The issue might be occuring because XLA optimizations can reorder, approximate, or alter numerical calculations for performance, especially when sensitive operations (like tf.divide, tf.reduce_prod, tf.cos) and complex output nodes (like transposed_concat) interact. This leads to subtle inconsistencies in numerical results. Could you please refer to the gist file for more information. Thank you",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1887,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLITE: Benchmarking failure on GPT2 quantized autocomplete.tflite )， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: aarch64 linux     **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**: tf 2.15    **Python version**: python3.10.9    **Exact command to reproduce**: `linux_aarch64_benchmark_model graph=autocomplete.tflite num_threads=1 num_runs=10`  Describe the problem I am using an aarch64 device like raspberry pi. I created the gpt2 autocomplete.tflite model using the official colab tutorial https://colab.research.google.com/github/tensorflow/codelabs/blob/main/KerasNLP/io2023_workshop.ipynbscrollTo=uLsz2IcN46eb I was able to create both the quantized and unquantized tflite model. I then tried to benchmark these models on the aarch64 device using the official nightly tflite benchmark model linux_aarch64 using tf 2.15 sourced from https://www.tensorflow.org/lite/performance/measurementnative_benchmark_binary On running the benchmark model using the command: `linux_aarch64_benchmark_model graph=autocomplete.tflite num_threads=1 num_runs=10` I get benchmarking failure errors. I am running the model on CPU itself but it seems the ops are unsupported. I get same benchmarking failure on running the unquantized version of it as well. The logs are below. > root:~ ./linux_aarch64_benchmark_model graph=autocomplete.tflite num_threads=1 num_runs=10 > INFO: STARTING! > INFO: Log parameter values verbosely: [0] > INFO: Num threads: [4] > INFO: Graph: [autocomplete.tflite] > INFO: threads us)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,suyash-narain,TFLITE: Benchmarking failure on GPT2 quantized autocomplete.tflite ," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: aarch64 linux     **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**: tf 2.15    **Python version**: python3.10.9    **Exact command to reproduce**: `linux_aarch64_benchmark_model graph=autocomplete.tflite num_threads=1 num_runs=10`  Describe the problem I am using an aarch64 device like raspberry pi. I created the gpt2 autocomplete.tflite model using the official colab tutorial https://colab.research.google.com/github/tensorflow/codelabs/blob/main/KerasNLP/io2023_workshop.ipynbscrollTo=uLsz2IcN46eb I was able to create both the quantized and unquantized tflite model. I then tried to benchmark these models on the aarch64 device using the official nightly tflite benchmark model linux_aarch64 using tf 2.15 sourced from https://www.tensorflow.org/lite/performance/measurementnative_benchmark_binary On running the benchmark model using the command: `linux_aarch64_benchmark_model graph=autocomplete.tflite num_threads=1 num_runs=10` I get benchmarking failure errors. I am running the model on CPU itself but it seems the ops are unsupported. I get same benchmarking failure on running the unquantized version of it as well. The logs are below. > root:~ ./linux_aarch64_benchmark_model graph=autocomplete.tflite num_threads=1 num_runs=10 > INFO: STARTING! > INFO: Log parameter values verbosely: [0] > INFO: Num threads: [4] > INFO: Graph: [autocomplete.tflite] > INFO: threads us",2023-11-30T02:33:49Z,stat:awaiting tensorflower type:bug comp:lite TF 2.15,closed,0,34,https://github.com/tensorflow/tensorflow/issues/62506,"narain Could you please make sure you have included the necessary libraries for the ""RegexSplitWithOffsets"" op, such as the TFLite Text library and try to rebuild the runtime with appropriate flag enabled? Also try to disable XNNPACK, If you don't need the XNNPACK delegate for performance reasons. Thank you!","Hi , RegexSplitWithOffsets op error comes into picture when I use benchmark model with flex delegate. Is using flex delegate a necessity with autocomplete.tflite model? Why is general tflite nightly benchmark model not able to execute this tflite model? Do i need to enable tflite task library? i thought thats enabled by default when we build runtime? does the prebuilt benchmark model from tflite not have support for tensorflow text libraries? which flag do i need to enable while building tflite runtime for tflite text library as i cannot find any references on either tensorflow github or tflite documentation. ","narain Using the Flex delegate is not strictly necessary with the autocomplete.tflite model, but it is highly recommended for two primary reasons such as for unsupported operations and high performance. Due to some missing dependencies or incompatible versions.  General TFLite nightly benchmark model not able to execute the tflite model due to missing dependencies.  You don't need to explicitly enable the TensorFlow Lite Task Library in most cases. It is automatically included in the TFLite runtime and utilizes the same inference infrastructure as the standard TFLite API. Unfortunately, the prebuilt benchmark model from TFLite currently does not have native support for TensorFlow Text libraries.  Thank you!","Hi , thanks for your reply. I still don't understand. Building tflite runtime by default should have the Task Library enabled in most cases. But tflite benchmark model provided as default (even the one with flex delegate) cannot benchmark autocomplete.tflite gpt2 model.  How do I benchmark it then? if i build my benchmark model, which flags do i need to enable, if you can let me know? or would building default tflite benchmark model will work for tf2.15?",Hi  any updates?,"Hi , Please look into the issue. Thank You",I was able to replicate on linux x86_64:  yang can you please take a look? Thanks.,"Yes, to benchmark the gpt2 model you need some extra dependencies. There are 2 steps needed: 1. add this library to your workspace: https://github.com/tensorflow/text/tree/master 2. under `tensorflow/tensorflow/lite/tools/benchmark/BUILD`, add the dependency of `""//tensorflow_text:ops_lib"",` to your `benchmark_model_plus_flex` binary. Then you should be good to go!","narain, can you try the above and let us know if your issue is resolved? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,let me try this and get back to you. thanks,"Hi  yang  I was trying to build the benchmark_model_plus_flex binary using the mentioned changes and ran into an error. > ERROR: /home/tensorflow/tensorflow_text/core/kernels/BUILD:35:14: no such package '//': The repository '' could not be resolved: Repository '' is not defined and referenced by '//tensorflow_text/core/kernels:boise_offset_converter_kernel' I downloaded tensorflowtext from the mentioned link and put it inside my workspace.  I made changes to the BUILD as well by adding '//tensorflow_text:ops_lib' dependency. I am not sure what the '' error pertains to here. the log is below: > user:~/tensorflow$ bazel build c opt config=elinux_aarch64 //tensorflow/lite/tools/benchmark:benchmark_model_plus_flex > INFO: Reading 'startup' options from /home/tensorflow/.bazelrc: windows_enable_symlinks > INFO: Options provided by the client: >   Inherited 'common' options: isatty=1 terminal_columns=203 > INFO: Reading rc options for 'build' from /home/tensorflow/.bazelrc: >   Inherited 'common' options: experimental_repo_remote_exec > INFO: Reading rc options for 'build' from /home/tensorflow/.bazelrc: >   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive features=force_no_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility > INFO: Found applicable config definition build:short_logs in file /home/tensorflow/.bazelrc: output_filter=DONT_MATCH_ANYTHING > INFO: Found applicable config definition build:v2 in file /home/tensorflow/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 > INFO: Found applicable config definition build:elinux_aarch64 in file /home/tensorflow/.bazelrc: config=elinux cpu=aarch64 > INFO: Found applicable config definition build:elinux in file /home/tensorflow/.bazelrc: crosstool_top=//:toolchain host_crosstool_top=//tools/cpp:toolchain > INFO: Found applicable config definition build:linux in file /home/tensorflow/.bazelrc: host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch copt=Wnoerror=unusedbutsetvariable define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels experimental_guard_against_concurrent_changes > INFO: Found applicable config definition build:dynamic_kernels in file /home/tensorflow/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS > INFO: Repository boringssl instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:928:21: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:469:20: in _tf_repositories >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > INFO: Repository curl instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:928:21: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:410:20: in _tf_repositories >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > INFO: Repository icu instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:921:28: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:75:8: in _initialize_third_party >   /home/tensorflow/third_party/icu/workspace.bzl:8:20: in repo >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > INFO: Repository armhf_linux_toolchain instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:928:21: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:258:20: in _tf_repositories >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > INFO: Repository aarch64_linux_toolchain instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:928:21: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:250:20: in _tf_repositories >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > INFO: Repository XNNPACK instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:928:21: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:151:20: in _tf_repositories >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > INFO: Repository double_conversion instantiated at: >   /home/tensorflow/WORKSPACE:84:14: in  >   /home/tensorflow/tensorflow/workspace2.bzl:928:21: in workspace >   /home/tensorflow/tensorflow/workspace2.bzl:629:20: in _tf_repositories >   /home/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive > Repository rule _tf_http_archive defined at: >   /home/tensorflow/third_party/repo.bzl:89:35: in  > ERROR: /home/tensorflow/tensorflow_text/core/kernels/BUILD:35:14: no such package '//': The repository '' could not be resolved: Repository '' is not defined and referenced by '//tensorflow_text/core/kernels:boise_offset_converter_kernel' > ERROR: Analysis of target '//tensorflow/lite/tools/benchmark:benchmark_model_plus_flex' failed; build aborted:  > INFO: Elapsed time: 1.277s > INFO: 0 processes. > FAILED: Build did NOT complete successfully (53 packages loaded, 1743 targets configured) >     currently loading: // ... (2 packages) >     Fetching https://storage.googleapis.com/mirror.tensorflow.org/curl.se/download/curl8.4.0.tar.gz; 3.0 MiB (3,137,536B) >     Fetching https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/bbbaa7352a3ea729987d3e654d37be93e8009691.zip; 977.6 KiB (1,001,081B) >     Fetching https://storage.googleapis.com/.../developer.arm.com//media/Files/downloads/gnu/11.3.rel1/binrel/armgnutoolchain11.3.rel1x86_64aarch64nonelinuxgnu.tar.xz; 365.5 KiB (374,310B) >     Fetching https://storage.googleapis.com/.../developer.arm.com//media/Files/downloads/gnu/11.3.rel1/binrel/armgnutoolchain11.3.rel1x86_64armnonelinuxgnueabihf.tar.xz; 759.0 KiB (777,173B) >     Fetching https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/boringssl/archive/c00d7ca810e93780bd0c8ee4eea28f4f2ea4bcdc.tar.gz; 261.5 KiB (267,782B) >     Fetching https://storage.googleapis.com/mirror.tensorflow.org/github.com/unicodeorg/icu/archive/release691.zip >     Fetching https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/doubleconversion/archive/v3.2.0.tar.gz > ",Hmmm...could you try adding deps `//tensorflow_text:ops_lib` instead? Some great discussion about the similar issue is found: https://github.com/tensorflow/tensorflow/issues/50924,Hi yang  This time i get the error: > ERROR: /home/mtk/tensorflow/tensorflow/lite/tools/benchmark/BUILD:74:13: no such package '//tensorflow_text': The repository '' could not be resolved: Repository '' is not defined and referenced by '//tensorflow/lite/tools/benchmark:benchmark_model_plus_flex' > ERROR: Analysis of target '//tensorflow/lite/tools/benchmark:benchmark_model_plus_flex' failed; build aborted: Analysis failed >  the BUILD snippet is as below: ,Sorry my mistakes. > ERROR: /home/tensorflow/tensorflow_text/core/kernels/BUILD:35:14: no such package '//': The repository '' could not be resolved: Repository '' is not defined and referenced by '//tensorflow_text/core/kernels:boise_offset_converter_kernel' It's likely an error with your repository rules or directory structure. Could you reference to this discussion and make the changes to WORKSPACE and BUILD? https://stackoverflow.com/questions/53254061/failingtobazelbuildcprojectwithtensorflowasadependency,Hi yang  I think I was getting the error because i didn't add tensorflowtext rules to my WORKSPACE. How can I add it to this file? i copied the tensorflowtext folder into tensorflow directory but not sure how to reference it in workspace file. How do i integrate tensorflowtext WORKSPACE file with tensorflow WORKSPACE? any suggestions? ,"Hi yang, In my WORKSPACE file, I add the following:  I get the below error log. What other changes am I missing here in WORKSPACE file? > user:~/tensorflow$ bazel build c opt config=elinux_aarch64 //tensorflow/lite/tools/benchmark:benchmark_model_plus_flex > INFO: Reading 'startup' options from /home/tensorflow/.bazelrc: windows_enable_symlinks > INFO: Options provided by the client: >   Inherited 'common' options: isatty=1 terminal_columns=203 > INFO: Reading rc options for 'build' from /home/tensorflow/.bazelrc: >   Inherited 'common' options: experimental_repo_remote_exec > INFO: Reading rc options for 'build' from /home/tensorflow/.bazelrc: >   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive features=force_no_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility > INFO: Found applicable config definition build:short_logs in file /home/tensorflow/.bazelrc: output_filter=DONT_MATCH_ANYTHING > INFO: Found applicable config definition build:v2 in file /home/tensorflow/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 > INFO: Found applicable config definition build:elinux_aarch64 in file /home/tensorflow/.bazelrc: config=elinux cpu=aarch64 > INFO: Found applicable config definition build:elinux in file /home/tensorflow/.bazelrc: crosstool_top=//:toolchain host_crosstool_top=//tools/cpp:toolchain > INFO: Found applicable config definition build:linux in file /home/tensorflow/.bazelrc: host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch copt=Wnoerror=unusedbutsetvariable define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels experimental_guard_against_concurrent_changes > INFO: Found applicable config definition build:dynamic_kernels in file /home/tensorflow/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS > ERROR: /home/tensorflow/WORKSPACE:72:17: fetching local_repository rule //external:org_tensorflow_text: java.io.IOException: No WORKSPACE file found in /home/.cache/bazel/_bazel/716ac13c348ce3335128b3d9f4131682/external/org_tensorflow_text > ERROR: /home/tensorflow/tensorflow/lite/tools/benchmark/BUILD:74:13: //tensorflow/lite/tools/benchmark:benchmark_model_plus_flex depends on //tensorflow_text:ops_lib in repository  which failed to fetch. no such package '//tensorflow_text': No WORKSPACE file found in /home/.cache/bazel/_bazel/716ac13c348ce3335128b3d9f4131682/external/org_tensorflow_text > ERROR: Analysis of target '//tensorflow/lite/tools/benchmark:benchmark_model_plus_flex' failed; build aborted: Analysis failed > INFO: Elapsed time: 0.595s > INFO: 0 processes. > FAILED: Build did NOT complete successfully (3 packages loaded, 6 targets configured) > ",Did you build and intall both tensorflow and tensorflow_text properly?  Setup TF: https://www.tensorflow.org/install/source  Install tensorflow_text: https://github.com/tensorflow/text/tree/master?tab=readmeovfileinstallation,"yang, I have both TF and Tensorflow_text installed via pip. The build from source also simply builds the pip file which is then installed.  Is there anything else I need to add to workspace file?",Let me reproduce your error in my local later today.,thanks,"Hi narain, Sorry I'm too busy with the current work and don't have enough time to repro your error. Could you refer to this doc (https://bazel.build/reference/be/workspace) for workspace setup?",Hi yang I did refer to it before but the local_repository rules were still giving me the same error. Do you have an example workspace i can refer to? Not entirely sure how to add tftext to tf workspace. creating the local_repository gives me same error as beforre thanks,"Hi , Could you provide some insights to this?","The cause of the issue is that TF Text tries to link with the tensorflow shared library, but since you are building this inside TF, this isn't needed. I think you should use the tensorflow serving (model server) library as an example. After viewing its workspace.bzl file, instead of local_repository, try:  you can then link in tf text ops with: ` ""//tensorflow_text:ops_lib"",` serving also has patches, ~but you should be able to ignore this as it is only bc it builds with an older version of c++.~ You should also copy this directory into the TF third_party one. It rewrites  to . Though, does  exist for your target? Maybe update the patch so those point correctly by simply removing ? edit:  updated notes on the patch  you may need to update the version in http_archive.  the ""redo_mapping"" may not be needed. It depends what core TF is using for its re2 lib name.","Hi  , I am not sure what I am doing wrong here.  My WORKSPACE file is as below: > workspace(name = ""org_tensorflow"") >  > > load(""//tools/build_defs/repo:http.bzl"", ""http_archive"") >  > http_archive( >     name = ""bazel_skylib"", >     sha256 = ""74d544d96f4a5bb630d465ca8bbcfe231e3594e5aae57e1edbf17a6eb3ca2506"", >     urls = [ >         ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/bazelskylib/releases/download/1.3.0/bazelskylib1.3.0.tar.gz"", >         ""https://github.com/bazelbuild/bazelskylib/releases/download/1.3.0/bazelskylib1.3.0.tar.gz"", >     ], > ) >  > http_archive( >     name = ""rules_python"", >     sha256 = ""9d04041ac92a0985e344235f5d946f71ac543f1b1565f2cdbc9a2aaee8adf55b"", >     strip_prefix = ""rules_python0.26.0"", >     url = ""https://github.com/bazelbuild/rules_python/releases/download/0.26.0/rules_python0.26.0.tar.gz"", > ) >  > http_archive( >         name = ""org_tensorflow_text"", >         sha256 = ""4e6ec543a1d70a50f0105e0ea69ea8a1edd0b17a38d0244aa3b14f889b2cf74d"", >         strip_prefix = ""text2.12.1"", >         url = ""https://github.com/tensorflow/text/archive/v2.12.1.zip"", >         repo_mapping = {"""": """"}, >     ) >  > load(""//python:repositories.bzl"", ""py_repositories"") >  > py_repositories() >  > load(""//python:repositories.bzl"", ""python_register_toolchains"") > load( >     ""//tensorflow/tools/toolchains/python:python_repo.bzl"", >     ""python_repository"", > ) >  > python_repository(name = ""python_version_repo"") >  > load(""//:py_version.bzl"", ""HERMETIC_PYTHON_VERSION"") >  > python_register_toolchains( >     name = ""python"", >     ignore_root_user_error = True, >     python_version = HERMETIC_PYTHON_VERSION, > ) >  > load(""//:defs.bzl"", ""interpreter"") > load(""//python:pip.bzl"", ""package_annotation"", ""pip_parse"") >  > NUMPY_ANNOTATIONS = { >     ""numpy"": package_annotation( >         additive_build_content = """"""\ > filegroup( >     name = ""includes"", >     srcs = glob([""sitepackages/numpy/core/include/**/*.h""]), > ) > cc_library( >     name = ""numpy_headers"", >     hdrs = ["":includes""], >     strip_include_prefix=""sitepackages/numpy/core/include/"", > ) > """""", >     ), > } >  > pip_parse( >     name = ""pypi"", >     annotations = NUMPY_ANNOTATIONS, >     python_interpreter_target = interpreter, >     requirements = ""//:requirements_lock_"" + HERMETIC_PYTHON_VERSION.replace(""."", ""_"") + "".txt"", > ) >  > load(""//:requirements.bzl"", ""install_deps"") >  > install_deps() >  >  >  load(""@//text/tensorflow_text:tftext.bzl"", >  ""tf_text_workspace"") >  tf_text_workspace() >  > load(""@//tensorflow:workspace3.bzl"", ""tf_workspace3"") >  > tf_workspace3() >  > load(""@//tensorflow:workspace2.bzl"", ""tf_workspace2"") >  > tf_workspace2() >  > load(""@//tensorflow:workspace1.bzl"", ""tf_workspace1"") >  > tf_workspace1() >  > load(""@//tensorflow:workspace0.bzl"", ""tf_workspace0"") >  > tf_workspace0() on trying to build the benchmark_model_plus_flex binary, i get the error:  my file structure is:  Edit: Do I need to add tf serving? If so, where should it be added? i am just cloning tensorflow/tensorflow to build benchmark model and cloning tensorlfowtext in the same directory.","Hi   followup to your edits: Do I need to add tf serving? If so, where should it be added? i am just cloning tensorflow/tensorflow to build benchmark model and cloning tensorlfowtext in the same directory.","Apologies, I actually had edited my comment, and maybe you viewed it before the edit. The patch file is necessary, but not tf serving. In your file structure, add a third_party directory, and copy the tf_text directory that I had linked above that contains the patch file. Then update your workspace to include that patch to tf text.","Hi , I tried your suggestions and am no longer getting the  errors. But i started getting build failures related to eigen I am not sure how to proceed with.  I am using bazel v6.1.0 the error log is attached: error.log i get errors like: > ERROR: /home/mtk/tensorflow/tensorflow/c/BUILD:411:11: Compiling tensorflow/c/tf_status.: (Exit 1): aarch64nonelinuxgnugcc failed: error executing command (from target //tensorflow/c:tf_status) /home/mtk/.cache/bazel/_bazel_mtk/716ac13c348ce3335128b3d9f4131682/external/aarch64_linux_toolchain/bin/aarch64nonelinuxgnugcc fstackprotector g0 O2 DNDEBUG ffunctionsections fdatasections ... (remaining 144 arguments skipped) > In file included from external/local_tsl/tsl/platform/types.h:21, >                  from external/local_tsl/tsl/platform/default/logging.h:38, >                  from external/local_tsl/tsl/platform/logging.h:26, >                  from external/local_tsl/tsl/platform/status.h:34, >                  from external/local_tsl/tsl/c/tsl_status_internal.h:19, >                  from ./tensorflow/c/tf_status_internal.h:19, >                  from tensorflow/c/tf_status.cc:20: > external/local_tsl/tsl/platform/bfloat16.h:24:16: error: 'bfloat16' in namespace 'Eigen' does not name a type >    24    explicit EIGEN_DEVICE_FUNC float8_base(Eigen::bfloat16 bf16) >  my workspace file has the following changes:  the complete error log is attached. Do you have any suggestions for these eigen related errors?","Hi , i am not getting eigen issues now, I had to hide /usr/include/Eigen and that solved the error. But i am getting some weird sentencepiece errors as below  any suggestions?"
463,"以下是一个github上的tensorflow下的一个issue, 标题是(Create a propertie to get a dict with the names and layers of the model.)， 内容是 (Trying to solve the *TODO* from fchollet,  ""We could build a dictionary based on layer names since they are constant, but we have not done that yet.”. I’d just create a new propertie to the Model's Class.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,CaioWing,Create a propertie to get a dict with the names and layers of the model.,"Trying to solve the *TODO* from fchollet,  ""We could build a dictionary based on layer names since they are constant, but we have not done that yet.”. I’d just create a new propertie to the Model's Class.",2023-11-30T01:39:37Z,comp:keras size:XS,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62505,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.","Hi  It looks like your PR relates to the Keras component. Please submit it to the github.com/kerasteam/keras repository instead. Thankyou. , "
2047,"以下是一个github上的tensorflow下的一个issue, 标题是(File ""/home/mona/anaconda3/envs/EfficientPose/lib/python3.8/site-packages/google/protobuf/internal/containers.py"", line 70, in __getitem__     return self._values[key] TypeError: list indices must be integers or slices, not str)， 内容是 ( Issue type Bug Please note I saw this related issue but there was no response to it https://github.com/tensorflow/tensorflow/issues/32694  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version nvidiatensorflow==1.15.4+nv20.12  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version Python 3.8.18 (default, Sep 11 2023, 13:40:15)   Bazel version _No response_  GCC/compiler version GCC 11.2.0  CUDA/cuDNN version check below  GPU model and memory ADA RTX 6000  Current behavior? (EfficientPose) mona:~/EfficientPose$ python evaluate.py phi 0 weights weights/Weights/Linemod/object_8/phi_0_linemod_best_ADD.h5  validationimagesavepath val_imgs linemod data/Linemod_preprocessed/ objectid 8 20231129 13:29:34.439724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to reenable them. WARNING:tensorflow:From evaluate.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead. WARNING:tensorflow:From evaluate.py:134: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead. 20231129 13:29:35.373875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3096000000 Hz 20231129 13:29:35.376509: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d38cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 20231129 13:29:35.376534: I tensorflow/compiler/xla/servic)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,monajalal,"File ""/home/mona/anaconda3/envs/EfficientPose/lib/python3.8/site-packages/google/protobuf/internal/containers.py"", line 70, in __getitem__     return self._values[key] TypeError: list indices must be integers or slices, not str"," Issue type Bug Please note I saw this related issue but there was no response to it https://github.com/tensorflow/tensorflow/issues/32694  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version nvidiatensorflow==1.15.4+nv20.12  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version Python 3.8.18 (default, Sep 11 2023, 13:40:15)   Bazel version _No response_  GCC/compiler version GCC 11.2.0  CUDA/cuDNN version check below  GPU model and memory ADA RTX 6000  Current behavior? (EfficientPose) mona:~/EfficientPose$ python evaluate.py phi 0 weights weights/Weights/Linemod/object_8/phi_0_linemod_best_ADD.h5  validationimagesavepath val_imgs linemod data/Linemod_preprocessed/ objectid 8 20231129 13:29:34.439724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to reenable them. WARNING:tensorflow:From evaluate.py:132: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead. WARNING:tensorflow:From evaluate.py:134: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead. 20231129 13:29:35.373875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3096000000 Hz 20231129 13:29:35.376509: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2d38cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 20231129 13:29:35.376534: I tensorflow/compiler/xla/servic",2023-11-29T18:41:21Z,stat:awaiting response type:bug stale,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62503, Please make sure that the key variable is an integer or a slice before passing it to `__getitem__` and try with the latest stable TF version 2.15. Please let us know the outcome? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1131,"以下是一个github上的tensorflow下的一个issue, 标题是(TF 2.15 fails to build with error ""env: 'python3': No such file or directory"" from bazel py_strict_library.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15  Custom code No  OS platform and distribution Manylinux 2.28 (AlmaLinux 8) quay.io/pypa/manylinux_2_28  Mobile device _No response_  Python version 3.10  Bazel version 6.1.0  GCC/compiler version 11.2.1  CUDA/cuDNN version 12.3  GPU model and memory _No response_  Current behavior? Compiling TF 2.15 from source fails with the error `env: 'python3': No such file or directory` coming from all instances of `py_strict_library`  or `pytype_strict_library`. Based on the commands bazel is issuing from `verbose_failures`, bazel is using `env ` to clear the environment which causes it to be unable to find python3 since it is not longer in the path. For example:   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,trevor-m,"TF 2.15 fails to build with error ""env: 'python3': No such file or directory"" from bazel py_strict_library."," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.15  Custom code No  OS platform and distribution Manylinux 2.28 (AlmaLinux 8) quay.io/pypa/manylinux_2_28  Mobile device _No response_  Python version 3.10  Bazel version 6.1.0  GCC/compiler version 11.2.1  CUDA/cuDNN version 12.3  GPU model and memory _No response_  Current behavior? Compiling TF 2.15 from source fails with the error `env: 'python3': No such file or directory` coming from all instances of `py_strict_library`  or `pytype_strict_library`. Based on the commands bazel is issuing from `verbose_failures`, bazel is using `env ` to clear the environment which causes it to be unable to find python3 since it is not longer in the path. For example:   Standalone code to reproduce the issue   Relevant log output ",2023-11-28T19:04:52Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.15,closed,2,14,https://github.com/tensorflow/tensorflow/issues/62497, It seems like this might be related to hermetic python. Any thoughts?,"Yeah, this is probably due to unsetting PATH while using a (generated?) shebang of the form `!/usr/bin/env python3`. It breaks build isolation since _if_ it works it picks up system `/bin/python3` or `/usr/bin/python3` on Linux instead of the Python Tensorflow was instructed to use, see https://linux.die.net/man/3/execl: > The file is sought in the colonseparated list of directory pathnames specified in the PATH environment variable. If this variable isn't defined, the path list defaults to the current directory followed by the list of directories returned by confstr(_CS_PATH). (This confstr(3) call typically returns the value ""/bin:/usr/bin"".) Unsetting PATH may be fine but then execute `env   ./script.py` instead of `env  ./script.py`, or use the absolute path in the shebang (but note that has downsides too since the relevant executable may be in a long path, and Linux has a shebang line limit).",What commands are you using to start a build? It's been working fine in our nightly and continuous tests on the tensorflow/build containers.,"Hi , I'm using `./configure && bazel build c opt cxxopt=D_GLIBCXX_USE_CXX11_ABI=1 java_runtime_version=remotejdk_11 tensorflow/tools/pip_package:build_pip_package`. This error only occurs with our manylinux build container which does not contain a `python3` in the ""unset PATH"" directories that  mentioned (`/bin:/usr/bin/:/usr/local/bin`. I believe the tensorflow/build containers are ubuntu based and will have a system python3 in one of those directories which is currently being inadvertently used for these build rules.  > It breaks build isolation since _if_ it works it picks up system `/bin/python3` or `/usr/bin/python3` on Linux instead of the Python Tensorflow was instructed to use, see https://linux.die.net/man/3/execl: Yes, this appears to be exactly what's happening. > Unsetting PATH may be fine but then execute `env   ./script.py` instead of `env  ./script.py`, or use the absolute path in the shebang (but note that has downsides too since the relevant executable may be in a long path, and Linux has a shebang line limit). This makes sense, I think this change needs to be in bazel? It sounds like `py_binary` should be setting up the command to use the hermetic python environment and it is not.","I bisected it to 539673ead2b66a9c2dce3fb90e3767efda5deef5  Ping   I don't know bazel well enough to quickly see how to solve it, let's leave that to googlers ;p","Revert of 539673ead2b66a9c2dce3fb90e3767efda5deef5 applies cleanly to 2.15, but then the build fails with   so more is necessary. If someone could take over to fix it that'd be great. If you want to reproduce, run `mv /usr/bin/python3 /usr/bin/python3.tmp` and do an ordinary build (with another python)",I think that this may be related to https://github.com/bazelbuild/rules_python/issues/691. 539673ead2b66a9c2dce3fb90e3767efda5deef5 added an aspect that runs a `py_binary` on each `py_library`. It looks like the `py_binary` bootstrap script currently has an implicit dependency on a system interpreter being installed. ,Can you set the shebang line to `PYTHON_BIN_PATH`? The linked issue mentions stubs for shebangs. Or if possible: invoke the script directly `$PYTHON_BIN_PATH script.py`. This is more robust as it allows for longer paths to the python executable. See https://www.inulm.de/~mascheck/various/shebang/issues for reference. >  the length of the ! is much smaller than the maximum path length ,Any updates on this? Would be great to be able to build TF without assuming that `/usr/bin/python3` exists.,This affects multiple package managers that don't have a `/usr/bin/python3`:  Nix  Guix  Spack  Gentoo Prefix and possibly others. Can someone have a look at it?,"""Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.""",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1118,"以下是一个github上的tensorflow下的一个issue, 标题是(Model checkpoint not saved to google cloud storage)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14.1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9.17  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm training a model and I want to save the model checkpoints in `.keras` format to google cloud storage. I'm using the `ModelCheckpoint` callback but nothing is saved. I'm also using the `Tensorboard` callback and the logs are saved correctly in the same bucket. If I set the file path to a local directory the model checkpoint is saved without any problem.  Standalone code to reproduce the issue https://gist.github.com/rcalonso/f12863b6e2c4669be6875deee2ff6dbf  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,rcalonso,Model checkpoint not saved to google cloud storage, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14.1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9.17  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm training a model and I want to save the model checkpoints in `.keras` format to google cloud storage. I'm using the `ModelCheckpoint` callback but nothing is saved. I'm also using the `Tensorboard` callback and the logs are saved correctly in the same bucket. If I set the file path to a local directory the model checkpoint is saved without any problem.  Standalone code to reproduce the issue https://gist.github.com/rcalonso/f12863b6e2c4669be6875deee2ff6dbf  Relevant log output _No response_,2023-11-28T16:43:20Z,stat:awaiting tensorflower type:bug comp:keras TF2.14,open,1,5,https://github.com/tensorflow/tensorflow/issues/62495,", Could you please confirm whether you are facing any error while saving to Google cloud storage. If yes, please provide the error log here and help us to debug the issue. Thank you!"," I don't get any error, in the console I see the log `f""\nEpoch {epoch + 1}: saving model to {filepath}""` from https://github.com/kerasteam/keras/blob/v2.14.0/keras/callbacks.pyL1571 and the training continues but without any model saved. Looking closer I found the model is not saved because of this function which was added in 2.14.0 https://github.com/kerasteam/keras/blob/v2.14.0/keras/saving/saving_api.pyL137",", Could you please try with the latest Keras 3.0 version and the tensorflow v2.15, and also I tried to execute on the colab and I was able to check the saved items. Kindly find the gist of it here. Thank you!",", Keras 3.0 is only compatible with tensorflow=>2.16 according to https://github.com/kerasteam/keras/blob/master/requirementstensorflowcuda.txtL3 and tensorflow 2.15.0 is only compatible with keras 2.15.0. In the gist you provided, you're saving the checkpoint as `gcs_bucket = ""/content/sample_data/ckpt/epoch_{epoch:03d}.keras""` which works as you said but the problem is when saving to google cloud storage and the path start with `gs://` (e.g. `""gs://bucket_name/ckpt/epoch_{epoch:03d}.keras""`).",I have the exact same issue with tensorflow 2.17. No fixes for now... Can someone look into this?
1876,"以下是一个github上的tensorflow下的一个issue, 标题是(CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version unknown 2.4.0  Custom code Yes  OS platform and distribution Linux, Rocky linux  Mobile device _No response_  Python version Python 3.8.6  Bazel version _No response_  GCC/compiler version gcc (GCC) 10.2.0  CUDA/cuDNN version CUDA 11.1 cuDNN/8.0.4.30  GPU model and memory Nvidia A100  Current behavior? Hello! I am working on a deep learning project. I have configured Tensorflow correctly and it detects my GPUs when running   python3 c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"" Results in ` 20231128 16:53:38.531363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 20231128 16:53:44.264370: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set 20231128 16:53:44.269638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1 20231128 16:53:44.297140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:  pciBusID: 0000:03:00.0 name: Tesla P100PCIE16GB computeCapability: 6.0 coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s 20231128 16:53:44.297732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:  pciBusID: 0000:82:00.0 name: Tesla P100PCIE16GB computeCapability: 6.0 coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s 20231)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,martiiv,CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version unknown 2.4.0  Custom code Yes  OS platform and distribution Linux, Rocky linux  Mobile device _No response_  Python version Python 3.8.6  Bazel version _No response_  GCC/compiler version gcc (GCC) 10.2.0  CUDA/cuDNN version CUDA 11.1 cuDNN/8.0.4.30  GPU model and memory Nvidia A100  Current behavior? Hello! I am working on a deep learning project. I have configured Tensorflow correctly and it detects my GPUs when running   python3 c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"" Results in ` 20231128 16:53:38.531363: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 20231128 16:53:44.264370: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set 20231128 16:53:44.269638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1 20231128 16:53:44.297140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:  pciBusID: 0000:03:00.0 name: Tesla P100PCIE16GB computeCapability: 6.0 coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s 20231128 16:53:44.297732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:  pciBusID: 0000:82:00.0 name: Tesla P100PCIE16GB computeCapability: 6.0 coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s 20231",2023-11-28T15:58:55Z,type:build/install,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62494,Closed as repository I was using was manually setting CUDA_VISIBLE_DEVICES to 1...,Are you satisfied with the resolution of your issue? Yes No
1236,"以下是一个github上的tensorflow下的一个issue, 标题是(Discrepancy in TensorFlow XLA Compiled Models Due to Different Multiplication Orders with `tf.abs` on GPU)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? In TensorFlow 2.15.0, I've encountered an issue where two mathematically equivalent models yield different results when compiled with XLA. The discrepancy appears to be tied to the order of multiplication operations. This issue is critical as it questions the consistency and reliability of TensorFlow's computation, especially in a compiled environment. The models yield **dramatically different** results under XLA compilation, with discrepancies that are far from trivial.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Discrepancy in TensorFlow XLA Compiled Models Due to Different Multiplication Orders with `tf.abs` on GPU," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda : 12.2 / cudnn 8.9.04  GPU model and memory Tesla V100SPCIE32GB  Current behavior? In TensorFlow 2.15.0, I've encountered an issue where two mathematically equivalent models yield different results when compiled with XLA. The discrepancy appears to be tied to the order of multiplication operations. This issue is critical as it questions the consistency and reliability of TensorFlow's computation, especially in a compiled environment. The models yield **dramatically different** results under XLA compilation, with discrepancies that are far from trivial.   Standalone code to reproduce the issue   Relevant log output ",2023-11-27T08:36:40Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:xla TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62481,Here is another piece of code that triggers the same error. I hope this assists you in identifying the root cause of the bug  and log output :  ," Hey, have you reproduced this issue?","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The issue might be occuring because XLA optimizations can reorder, approximate, or alter numerical calculations for performance, especially when sensitive operations (like tf.divide, tf.reduce_prod, tf.cos) and complex output nodes (like transposed_concat) interact. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1885,"以下是一个github上的tensorflow下的一个issue, 标题是(When I import tensorflow as tf with python=3.9.6,there are errors)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tensorflowGPU 2.6  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.3 cudnn version :8.9.6  GPU model and memory _No response_  Current behavior?  import tensorflow as tf C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\framework\dtypes.py:585: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.   np.object, Traceback (most recent call last):   File """", line 1, in    File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\__init__.py"", line 41, in      from tensorflow.python.tools import module_util as _module_util   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\__init__.py"", line 46, in      from tensorflow.python import data   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\__init__.py"", line 25, in      from tensorflow.python.data import experimental   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\experimental\__init__.py"", line 97, in      from tensorflow.python.data.experimental import service   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\experimental\service\__init__.py"", line 353, in      from tensorflow.python.data.experimental.ops.data_service_ops import distribute   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\experimental\o)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ABtwo,"When I import tensorflow as tf with python=3.9.6,there are errors"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tensorflowGPU 2.6  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 12.3 cudnn version :8.9.6  GPU model and memory _No response_  Current behavior?  import tensorflow as tf C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\framework\dtypes.py:585: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.   np.object, Traceback (most recent call last):   File """", line 1, in    File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\__init__.py"", line 41, in      from tensorflow.python.tools import module_util as _module_util   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\__init__.py"", line 46, in      from tensorflow.python import data   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\__init__.py"", line 25, in      from tensorflow.python.data import experimental   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\experimental\__init__.py"", line 97, in      from tensorflow.python.data.experimental import service   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\experimental\service\__init__.py"", line 353, in      from tensorflow.python.data.experimental.ops.data_service_ops import distribute   File ""C:\Users\dell\.conda\envs\tfgpu\lib\sitepackages\tensorflow\python\data\experimental\o",2023-11-26T23:06:09Z,stat:awaiting response type:build/install stale 2.6.0,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62479,hello have u installed tensorflow library," Please try to upgrade to the latest TF version as you are using an older version. In a virtual environment, you may need to uninstall Python 3.9.6 and install a different version of Python, such as Python 3.8 or Python 3.10.  Please have a look at the following code to execute the same in virtual environment;  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"I also met this problem. and i browsered https://numpy.org/devdocs/release/1.20.0notes.html found that it's obviously tensorflow are using numpy before 2.0 I just change the numpy version pip install numpy==1.16.0 and at least i can use it now ,although it may have some problem",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
804,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0rc0  Custom code Yes  OS platform and distribution MacOS  Mobile device _No response_  Python version Python 3.9.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? This code should import tensor flow  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,JT-Studios,ValueError: Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec., Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0rc0  Custom code Yes  OS platform and distribution MacOS  Mobile device _No response_  Python version Python 3.9.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? This code should import tensor flow  Standalone code to reproduce the issue   Relevant log output ,2023-11-25T03:16:11Z,type:bug type:build/install TF 2.13,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62476,"Hi Studios , From the error log ,the error is generating from importing tensorflow. This might be due to different compatible version of keras vs tensorflow. Could you please try uninstalling tensorflow and keras packages and install tensorflow again and try importing tensorflow again and let us know if still issue persists. Thanks!","I have reinstalled tensorflow however when I try to use the import commands they won't stop running. After a minute I interrupted the kernel and it gave me this output: ` KeyboardInterrupt                         Traceback (most recent call last) Cell In[5], line 5       1 !pwd       2 print (PYTHONPATH)       3 print(os.path) > 5 import tensorflow as tf       6 from object_detection.utils import config_util       7 from object_detection.protos import pipeline_pb2 File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/__init__.py:54      52 from tensorflow._api.v2 import autograph      53 from tensorflow._api.v2 import bitwise > 54 from tensorflow._api.v2 import compat      55 from tensorflow._api.v2 import config      56 from tensorflow._api.v2 import data File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/__init__.py:8       3 """"""Public API for tf._api.v2.compat namespace       4 """"""       6 import sys as _sys > 8 from tensorflow._api.v2.compat import v1       9 from tensorflow._api.v2.compat import v2      10 from tensorflow.python.compat.compat import forward_compatibility_horizon  line: 125 File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/v1/__init__.py:32      30 from tensorflow._api.v2.compat.v1 import autograph      31 from tensorflow._api.v2.compat.v1 import bitwise > 32 from tensorflow._api.v2.compat.v1 import compat      33 from tensorflow._api.v2.compat.v1 import config      34 from tensorflow._api.v2.compat.v1 import data File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/v1/compat/__init__.py:9       6 import sys as _sys       8 from tensorflow._api.v2.compat.v1.compat import v1 > 9 from tensorflow._api.v2.compat.v1.compat import v2      10 from tensorflow.python.compat.compat import forward_compatibility_horizon  line: 125      11 from tensorflow.python.compat.compat import forward_compatible  line: 65 File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py:28      25 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader      26 from tensorflow.python.util.lazy_loader import KerasLazyLoader as _KerasLazyLoader > 28 from tensorflow._api.v2.compat.v2 import __internal__      29 from tensorflow._api.v2.compat.v2 import __operators__      30 from tensorflow._api.v2.compat.v2 import audio File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/v2/__init__.py:34      32 from tensorflow._api.v2.compat.v2 import autograph      33 from tensorflow._api.v2.compat.v2 import bitwise > 34 from tensorflow._api.v2.compat.v2 import compat      35 from tensorflow._api.v2.compat.v2 import config      36 from tensorflow._api.v2.compat.v2 import data File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/v2/compat/__init__.py:9       6 import sys as _sys       8 from tensorflow._api.v2.compat.v2.compat import v1 > 9 from tensorflow._api.v2.compat.v2.compat import v2      10 from tensorflow.python.compat.compat import forward_compatibility_horizon  line: 125      11 from tensorflow.python.compat.compat import forward_compatible  line: 65 File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py:65      63 from tensorflow._api.v2.compat.v2 import strings      64 from tensorflow._api.v2.compat.v2 import summary > 65 from tensorflow._api.v2.compat.v2 import sysconfig      66 from tensorflow._api.v2.compat.v2 import test      67 from tensorflow._api.v2.compat.v2 import tpu File :1176, in _find_and_load(name, import_) File :1147, in _find_and_load_unlocked(name, import_) File :690, in _load_unlocked(spec) File :936, in exec_module(self, module) File :1032, in get_code(self, fullname) File :1131, in get_data(self, path) KeyboardInterrupt:  ` It is interesting to note that it is running 3.11 files even though this is not the version it is supposed to be working in.","Update: I have created a new virtual environment and the issue is resolved but a new issue started appearing: ` TypeError                                 Traceback (most recent call last) Cell In[29], line 2       1 import tensorflow as tf > 2 from object_detection.utils import config_util       3 from object_detection.protos import pipeline_pb2       4 from google.protobuf import text_format File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/object_detection/utils/config_util.py:24      20 from google.protobuf import text_format      22 from tensorflow.python.lib.io import file_io > 24 from object_detection.protos import eval_pb2      25 from object_detection.protos import graph_rewriter_pb2      26 from object_detection.protos import input_reader_pb2 File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/object_detection/protos/eval_pb2.py:36      13 _sym_db = _symbol_database.Default()      18 DESCRIPTOR = _descriptor.FileDescriptor(      19   name='object_detection/protos/eval.proto',      20   package='object_detection.protos',    (...)      23   serialized_pb=_b('\n\""object_detection/protos/eval.proto\x12\x17object_detection.protos\""\xf7\x05\n\nEvalConfig\x12\x15\n\nbatch_size\x18\x19 \x01(\r:\x01\x31\x12\x1e\n\x12num_visualizations\x18\x01 \x01(\r:\x02\x31\x30\x12\x1e\n\x0cnum_examples\x18\x02 \x01(\r:\x04\x35\x30\x30\x30\x42\x02\x18\x01\x12\x1f\n\x12\x65val_interval_secs\x18\x03 \x01(\r:\x03\x33\x30\x30\x12\x18\n\tmax_evals\x18\x04 \x01(\r:\x01\x30\x42\x02\x18\x01\x12\x19\n\nsave_graph\x18\x05 \x01(\x08:\x05\x66\x61lse\x12\""\n\x18visualization_export_dir\x18\x06 \x01(\t:\x00\x12\x15\n\x0b\x65val_master\x18\x07 \x01(\t:\x00\x12\x13\n\x0bmetrics_set\x18\x08 \x03(\t\x12\x15\n\x0b\x65xport_path\x18\t \x01(\t:\x00\x12!\n\x12ignore_groundtruth\x18\n \x01(\x08:\x05\x66\x61lse\x12\""\n\x13use_moving_averages\x18\x0b \x01(\x08:\x05\x66\x61lse\x12\""\n\x13\x65val_instance_masks\x18\x0c \x01(\x08:\x05\x66\x61lse\x12 \n\x13min_score_threshold\x18\r \x01(\x02:\x03\x30.5\x12&\n\x1amax_num_boxes_to_visualize\x18\x0e \x01(\x05:\x02\x32\x30\x12\x1a\n\x0bskip_scores\x18\x0f \x01(\x08:\x05\x66\x61lse\x12\x1a\n\x0bskip_labels\x18\x10 \x01(\x08:\x05\x66\x61lse\x12*\n\x1bvisualize_groundtruth_boxes\x18\x11 \x01(\x08:\x05\x66\x61lse\x12\x32\ngroundtruth_box_visualization_color\x18\x12 \x01(\t:\x05\x62lack\x12\x35\n&keep_image_id_for_visualization_export\x18\x13 \x01(\x08:\x05\x66\x61lse\x12$\n\x16retain_original_images\x18\x17 \x01(\x08:\x04true\x12+\n\x1cinclude_metrics_per_category\x18\x18 \x01(\x08:\x05\x66\x61lse')      24 )      29 _EVALCONFIG = _descriptor.Descriptor(      30   name='EvalConfig',      31   full_name='object_detection.protos.EvalConfig',      32   filename=None,      33   file=DESCRIPTOR,      34   containing_type=None,      35   fields=[ > 36     _descriptor.FieldDescriptor(      37       name='batch_size', full_name='object_detection.protos.EvalConfig.batch_size', index=0,      38       number=25, type=13, cpp_type=3, label=1,      39       has_default_value=True, default_value=1,      40       message_type=None, enum_type=None, containing_type=None,      41       is_extension=False, extension_scope=None,      42       serialized_options=None, file=DESCRIPTOR),      43     _descriptor.FieldDescriptor(      44       name='num_visualizations', full_name='object_detection.protos.EvalConfig.num_visualizations', index=1,      45       number=1, type=13, cpp_type=3, label=1,      46       has_default_value=True, default_value=10,      47       message_type=None, enum_type=None, containing_type=None,      48       is_extension=False, extension_scope=None,      49       serialized_options=None, file=DESCRIPTOR),      50     _descriptor.FieldDescriptor(      51       name='num_examples', full_name='object_detection.protos.EvalConfig.num_examples', index=2,      52       number=2, type=13, cpp_type=3, label=1,      53       has_default_value=True, default_value=5000,      54       message_type=None, enum_type=None, containing_type=None,      55       is_extension=False, extension_scope=None,      56       serialized_options=_b('\030\001'), file=DESCRIPTOR),      57     _descriptor.FieldDescriptor(      58       name='eval_interval_secs', full_name='object_detection.protos.EvalConfig.eval_interval_secs', index=3,      59       number=3, type=13, cpp_type=3, label=1,      60       has_default_value=True, default_value=300,      61       message_type=None, enum_type=None, containing_type=None,      62       is_extension=False, extension_scope=None,      63       serialized_options=None, file=DESCRIPTOR),      64     _descriptor.FieldDescriptor(      65       name='max_evals', full_name='object_detection.protos.EvalConfig.max_evals', index=4,      66       number=4, type=13, cpp_type=3, label=1,      67       has_default_value=True, default_value=0,      68       message_type=None, enum_type=None, containing_type=None,      69       is_extension=False, extension_scope=None,      70       serialized_options=_b('\030\001'), file=DESCRIPTOR),      71     _descriptor.FieldDescriptor(      72       name='save_graph', full_name='object_detection.protos.EvalConfig.save_graph', index=5,      73       number=5, type=8, cpp_type=7, label=1,      74       has_default_value=True, default_value=False,      75       message_type=None, enum_type=None, containing_type=None,      76       is_extension=False, extension_scope=None,      77       serialized_options=None, file=DESCRIPTOR),      78     _descriptor.FieldDescriptor(      79       name='visualization_export_dir', full_name='object_detection.protos.EvalConfig.visualization_export_dir', index=6,      80       number=6, type=9, cpp_type=9, label=1,      81       has_default_value=True, default_value=_b("""").decode('utf8'),      82       message_type=None, enum_type=None, containing_type=None,      83       is_extension=False, extension_scope=None,      84       serialized_options=None, file=DESCRIPTOR),      85     _descriptor.FieldDescriptor(      86       name='eval_master', full_name='object_detection.protos.EvalConfig.eval_master', index=7,      87       number=7, type=9, cpp_type=9, label=1,      88       has_default_value=True, default_value=_b("""").decode('utf8'),      89       message_type=None, enum_type=None, containing_type=None,      90       is_extension=False, extension_scope=None,      91       serialized_options=None, file=DESCRIPTOR),      92     _descriptor.FieldDescriptor(      93       name='metrics_set', full_name='object_detection.protos.EvalConfig.metrics_set', index=8,      94       number=8, type=9, cpp_type=9, label=3,      95       has_default_value=False, default_value=[],      96       message_type=None, enum_type=None, containing_type=None,      97       is_extension=False, extension_scope=None,      98       serialized_options=None, file=DESCRIPTOR),      99     _descriptor.FieldDescriptor(     100       name='export_path', full_name='object_detection.protos.EvalConfig.export_path', index=9,     101       number=9, type=9, cpp_type=9, label=1,     102       has_default_value=True, default_value=_b("""").decode('utf8'),     103       message_type=None, enum_type=None, containing_type=None,     104       is_extension=False, extension_scope=None,     105       serialized_options=None, file=DESCRIPTOR),     106     _descriptor.FieldDescriptor(     107       name='ignore_groundtruth', full_name='object_detection.protos.EvalConfig.ignore_groundtruth', index=10,     108       number=10, type=8, cpp_type=7, label=1,     109       has_default_value=True, default_value=False,     110       message_type=None, enum_type=None, containing_type=None,     111       is_extension=False, extension_scope=None,     112       serialized_options=None, file=DESCRIPTOR),     113     _descriptor.FieldDescriptor(     114       name='use_moving_averages', full_name='object_detection.protos.EvalConfig.use_moving_averages', index=11,     115       number=11, type=8, cpp_type=7, label=1,     116       has_default_value=True, default_value=False,     117       message_type=None, enum_type=None, containing_type=None,     118       is_extension=False, extension_scope=None,     119       serialized_options=None, file=DESCRIPTOR),     120     _descriptor.FieldDescriptor(     121       name='eval_instance_masks', full_name='object_detection.protos.EvalConfig.eval_instance_masks', index=12,     122       number=12, type=8, cpp_type=7, label=1,     123       has_default_value=True, default_value=False,     124       message_type=None, enum_type=None, containing_type=None,     125       is_extension=False, extension_scope=None,     126       serialized_options=None, file=DESCRIPTOR),     127     _descriptor.FieldDescriptor(     128       name='min_score_threshold', full_name='object_detection.protos.EvalConfig.min_score_threshold', index=13,     129       number=13, type=2, cpp_type=6, label=1,     130       has_default_value=True, default_value=float(0.5),     131       message_type=None, enum_type=None, containing_type=None,     132       is_extension=False, extension_scope=None,     133       serialized_options=None, file=DESCRIPTOR),     134     _descriptor.FieldDescriptor(     135       name='max_num_boxes_to_visualize', full_name='object_detection.protos.EvalConfig.max_num_boxes_to_visualize', index=14,     136       number=14, type=5, cpp_type=1, label=1,     137       has_default_value=True, default_value=20,     138       message_type=None, enum_type=None, containing_type=None,     139       is_extension=False, extension_scope=None,     140       serialized_options=None, file=DESCRIPTOR),     141     _descriptor.FieldDescriptor(     142       name='skip_scores', full_name='object_detection.protos.EvalConfig.skip_scores', index=15,     143       number=15, type=8, cpp_type=7, label=1,     144       has_default_value=True, default_value=False,     145       message_type=None, enum_type=None, containing_type=None,     146       is_extension=False, extension_scope=None,     147       serialized_options=None, file=DESCRIPTOR),     148     _descriptor.FieldDescriptor(     149       name='skip_labels', full_name='object_detection.protos.EvalConfig.skip_labels', index=16,     150       number=16, type=8, cpp_type=7, label=1,     151       has_default_value=True, default_value=False,     152       message_type=None, enum_type=None, containing_type=None,     153       is_extension=False, extension_scope=None,     154       serialized_options=None, file=DESCRIPTOR),     155     _descriptor.FieldDescriptor(     156       name='visualize_groundtruth_boxes', full_name='object_detection.protos.EvalConfig.visualize_groundtruth_boxes', index=17,     157       number=17, type=8, cpp_type=7, label=1,     158       has_default_value=True, default_value=False,     159       message_type=None, enum_type=None, containing_type=None,     160       is_extension=False, extension_scope=None,     161       serialized_options=None, file=DESCRIPTOR),     162     _descriptor.FieldDescriptor(     163       name='groundtruth_box_visualization_color', full_name='object_detection.protos.EvalConfig.groundtruth_box_visualization_color', index=18,     164       number=18, type=9, cpp_type=9, label=1,     165       has_default_value=True, default_value=_b(""black"").decode('utf8'),     166       message_type=None, enum_type=None, containing_type=None,     167       is_extension=False, extension_scope=None,     168       serialized_options=None, file=DESCRIPTOR),     169     _descriptor.FieldDescriptor(     170       name='keep_image_id_for_visualization_export', full_name='object_detection.protos.EvalConfig.keep_image_id_for_visualization_export', index=19,     171       number=19, type=8, cpp_type=7, label=1,     172       has_default_value=True, default_value=False,     173       message_type=None, enum_type=None, containing_type=None,     174       is_extension=False, extension_scope=None,     175       serialized_options=None, file=DESCRIPTOR),     176     _descriptor.FieldDescriptor(     177       name='retain_original_images', full_name='object_detection.protos.EvalConfig.retain_original_images', index=20,     178       number=23, type=8, cpp_type=7, label=1,     179       has_default_value=True, default_value=True,     180       message_type=None, enum_type=None, containing_type=None,     181       is_extension=False, extension_scope=None,     182       serialized_options=None, file=DESCRIPTOR),     183     _descriptor.FieldDescriptor(     184       name='include_metrics_per_category', full_name='object_detection.protos.EvalConfig.include_metrics_per_category', index=21,     185       number=24, type=8, cpp_type=7, label=1,     186       has_default_value=True, default_value=False,     187       message_type=None, enum_type=None, containing_type=None,     188       is_extension=False, extension_scope=None,     189       serialized_options=None, file=DESCRIPTOR),     190   ],     191   extensions=[     192   ],     193   nested_types=[],     194   enum_types=[     195   ],     196   serialized_options=None,     197   is_extendable=False,     198   syntax='proto2',     199   extension_ranges=[],     200   oneofs=[     201   ],     202   serialized_start=64,     203   serialized_end=823,     204 )     206 DESCRIPTOR.message_types_by_name['EvalConfig'] = _EVALCONFIG     207 _sym_db.RegisterFileDescriptor(DESCRIPTOR) File ~/Desktop/Jupyter/TFODCourse/tfod/lib/python3.11/sitepackages/google/protobuf/descriptor.py:561, in FieldDescriptor.__new__(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)     555 def __new__(cls, name, full_name, index, number, type, cpp_type, label,     556             default_value, message_type, enum_type, containing_type,     557             is_extension, extension_scope, options=None,     558             serialized_options=None,     559             has_default_value=True, containing_oneof=None, json_name=None,     560             file=None, create_key=None):   pylint: disable=redefinedbuiltin > 561   _message.Message._CheckCalledFromGeneratedFile()     562   if is_extension:     563     return _message.default_pool.FindExtensionByName(full_name) TypeError: Descriptors cannot not be created directly. If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0. If you cannot immediately regenerate your protos, some other possible workarounds are:  1. Downgrade the protobuf package to 3.20.x or lower.  2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use purePython parsing and will be much slower). More information: https://developers.google.com/protocolbuffers/docs/news/20220506pythonupdates ` Sorry the error is a bit lengthy. How do I go about fixing this problem?",Issue has been resolved thanks for the help!,Are you satisfied with the resolution of your issue? Yes No,"> Issue has been resolved thanks for the help! Hey, How do you solved this error?? I am also getting the same error ![Uploading n.png…]()",Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec Have the same issue when using the ray 2.33 with tensorflow 2.15.1., ," from tensorflow.python.data.experimental.ops.data_service_ops import distribute File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/data/experimental/ops/data_service_ops.py"", line 22, in   from tensorflow.python.data.experimental.ops import compression_ops File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/data/experimental/ops/compression_ops.py"", line 16, in   from tensorflow.python.data.util import structure File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/data/util/structure.py"", line 32, in   from tensorflow.python.ops.ragged import ragged_tensor File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/ops/ragged/ragged_tensor.py"", line 2321, in   class RaggedTensorSpec( File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/framework/type_spec_registry.py"", line 59, in decorator_fn  raise ValueError(""Name %s has already been registered for class %s.%s."" % ValueError: Name tf.RaggedTensorSpec has already been registered for class tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec.","import tensorflow as tf print(tf.__version__) I was trying to run this and after i encountered that issue while using a keras dataset. I think it is to do with **Tensorflow and Keras version compatibility**. Reinstall tensorflow (pip install tensorflow) and ensure your python version is below 12.0, then reopen your code editor and run the above comment to see which version you are on. "
1132,"以下是一个github上的tensorflow下的一个issue, 标题是(Discrepancies in Output due to Altered Multiplication Sequence in TensorFlow Operations)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.16.0dev20231122  Custom code Yes  OS platform and distribution Ubuntu 22.04.3  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I've come across a weird issue in TensorFlow. It seems like rearranging the multiplication operations is somehow giving different results. Check out these two models:   Mathematically, these two tensor operations should be identical since all I did was switch the order of multiplication. But when I run them in TensorFlow with certain inputs, I'm getting different outcomes, which is really strange  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Discrepancies in Output due to Altered Multiplication Sequence in TensorFlow Operations," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.16.0dev20231122  Custom code Yes  OS platform and distribution Ubuntu 22.04.3  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I've come across a weird issue in TensorFlow. It seems like rearranging the multiplication operations is somehow giving different results. Check out these two models:   Mathematically, these two tensor operations should be identical since all I did was switch the order of multiplication. But when I run them in TensorFlow with certain inputs, I'm getting different outcomes, which is really strange  Standalone code to reproduce the issue   Relevant log output ",2023-11-24T05:55:05Z,stat:awaiting tensorflower type:bug comp:ops comp:xla TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62475," I was able to replicate this issue on colab, please find the gist here. Thank you!","Hi,  This issue is not specific to XLA, mismatch of result happens even without XLA, this is due to the multiple tf.multiply operations happening in the code of below two equations.  Here in both cases, the order of multiplication is performed first on the inner most `tf.multiply`, if two `tf.multiply` are in the same level, leftmost operation is performed first and then the value will be ready for the next operation. During this process, since both takes different code path and different level of multiply operations, there will be precision loss, which is expected and the difference which is observed in not too large. Below is the simplified code which produces the similar behavior.  Gist: https://gist.github.com/sachinprasadhs/f2cbc7d40e91feb6f50aed1e6ca4e29f"," Hi, Thank you for your response. I understand that this behavior is caused by a floatingpoint accuracy problem, which is expected. I have been wondering about **the acceptable tolerance level** for this floatingpoint accuracy, given that we have uncovered numerous inconsistent behaviors in TensorFlow. We have only selected and reported cases with high differences in values. I would like to know what the acceptable tolerance in TensorFlow is, so that we can internally filter out some falsepositive cases."," , Could you please comment on the above response. Thank you!",">  Hi, Thank you for your response. I understand that this behavior is caused by a floatingpoint accuracy problem, which is expected. I have been wondering about **the acceptable tolerance level** for this floatingpoint accuracy, given that we have uncovered numerous inconsistent behaviors in TensorFlow. We have only selected and reported cases with high differences in values. I would like to know what the acceptable tolerance in TensorFlow is, so that we can internally filter out some falsepositive cases. You're using float16 here, which has very limited precision, so the issue is exasperated. The ""acceptable tolerance level"" entirely depends on the sequence of operations you are performing, the dtype, and the magnitudes of your values.  You can estimate it yourself: each floating point value is only accurate to within one unitofleastprecision (ULP), so you can model each value as `x + delta * x` (error is relative to x here due to the way floatingpoint values are stored  though this is only an approximation, since the error is really relative to `floor(log2(x))`, but that's harder to reason about).  The more floatingpoint operations you do, the more these floatingpoint errors multiply and accumulate.  You can then estimate the expected error for your given set of operations, and you will likely verify that TF (and XLA, and Eigen, pytorch, numpy, etc..) will fall within that. The only thing TF (and XLA) _does_ sometimes do, is for some operations like convolutions and matrix multiplications, we recognize that types like fp16 and bf16 are prone to this kind of bad error accumulation, particularly when multiplying large matrices, so internally we convert them to higher precision and accumulate in higher precision to mitigate the effect. The reported error you are seeing seem reasonable for fp16.",Are you satisfied with the resolution of your issue? Yes No
1862,"以下是一个github上的tensorflow下的一个issue, 标题是(clEnqueueWriteBuffer To clEnqueueMapBuffer)， 内容是 (In TFLite’s GPU delegate, I tried to replace clEnqueueWriteBuffer and clEnqueueReadBuffer with clEnqueueMapBuffer and clEnqueueUnmapMemObject, which means changing the data copying to the data mapping method to pass data, but using clEnqueueWriteBuffer and clEnqueueReadBuffer can correctly recognize the image, but using clEnqueueMapBuffer and clEnqueueUnmapMemObject cannot correctly recognize the image, why is that, the following is the code I modified, what is wrong? `absl::Status Convert(const TensorObject& input_obj,                        const TensorObject& output_obj) override {     auto cpu_input = absl::get_if(&input_obj);     auto cpu_output = absl::get_if(&output_obj);     if (cpu_input) {       auto texture_output = absl::get_if(&output_obj);       if (texture_output) {         return queue_>EnqueueWriteImage(             texture_output>memobj, int3(region_[0], region_[1], region_[2]),             cpu_input>data, async_);       }       std::cout(&output_obj);       if (buffer_output) {         return queue_>EnqueueWriteBuffer(buffer_output>memobj,                                           cpu_input>size_bytes,                                           cpu_input>data, async_);       }     } else if (cpu_output) {       std::cout(&input_obj);       if (texture_input) {         return queue_>EnqueueReadImage(             texture_input>memobj, int3(region_[0], region_[1], region_[2]),             cpu_output>data, async_);       }       auto buffer_input = absl::get_if(&input_obj);       if (buffer_input) {         return queue_>EnqueueReadBuffer(buffer_input>memobj,                                  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,B-JackMao,clEnqueueWriteBuffer To clEnqueueMapBuffer,"In TFLite’s GPU delegate, I tried to replace clEnqueueWriteBuffer and clEnqueueReadBuffer with clEnqueueMapBuffer and clEnqueueUnmapMemObject, which means changing the data copying to the data mapping method to pass data, but using clEnqueueWriteBuffer and clEnqueueReadBuffer can correctly recognize the image, but using clEnqueueMapBuffer and clEnqueueUnmapMemObject cannot correctly recognize the image, why is that, the following is the code I modified, what is wrong? `absl::Status Convert(const TensorObject& input_obj,                        const TensorObject& output_obj) override {     auto cpu_input = absl::get_if(&input_obj);     auto cpu_output = absl::get_if(&output_obj);     if (cpu_input) {       auto texture_output = absl::get_if(&output_obj);       if (texture_output) {         return queue_>EnqueueWriteImage(             texture_output>memobj, int3(region_[0], region_[1], region_[2]),             cpu_input>data, async_);       }       std::cout(&output_obj);       if (buffer_output) {         return queue_>EnqueueWriteBuffer(buffer_output>memobj,                                           cpu_input>size_bytes,                                           cpu_input>data, async_);       }     } else if (cpu_output) {       std::cout(&input_obj);       if (texture_input) {         return queue_>EnqueueReadImage(             texture_input>memobj, int3(region_[0], region_[1], region_[2]),             cpu_output>data, async_);       }       auto buffer_input = absl::get_if(&input_obj);       if (buffer_input) {         return queue_>EnqueueReadBuffer(buffer_input>memobj,                                  ",2023-11-24T05:53:06Z,stat:awaiting response stale comp:lite TFLiteGpuDelegate,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62474,"Hi JackMao, I am having trouble understanding what part of the above is your custom code vs. our code. Is it all your custom code? If any of it is ours, please direct us to where it is so that we may better understand the issue. Reason I ask is we also have EnqueueWriteBuffer: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/cl/cl_command_queue.ccL139 and it looks different than yours. Are you saying the first half of your custom code works, but the 2nd half doesn't? i.e. this works?  Do you have any example script/data that calls your code that we can use to reproduce your issue? Thanks for anything you can share.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1862,"以下是一个github上的tensorflow下的一个issue, 标题是(clEnqueueWriteBuffer To clEnqueueMapBuffer)， 内容是 ( Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.9  Custom code Yes  OS platform and distribution Ubuntu18.04  Mobile device pixel 4 Android  Python version 3.8  Bazel version 5.0.0  GCC/compiler version null  CUDA/cuDNN version null  GPU model and memory null  Current behavior? In TFLite’s GPU delegate, I tried to replace clEnqueueWriteBuffer and clEnqueueReadBuffer with clEnqueueMapBuffer and clEnqueueUnmapMemObject, which means changing the data copying to the data mapping method to pass data, but using clEnqueueWriteBuffer and clEnqueueReadBuffer can correctly recognize the image, but using clEnqueueMapBuffer and clEnqueueUnmapMemObject cannot correctly recognize the image, why is that, the following is the code I modified, what is wrong? `absl::Status Convert(const TensorObject& input_obj,                        const TensorObject& output_obj) override {     auto cpu_input = absl::get_if(&input_obj);     auto cpu_output = absl::get_if(&output_obj);     if (cpu_input) {       auto texture_output = absl::get_if(&output_obj);       if (texture_output) {         return queue_>EnqueueWriteImage(             texture_output>memobj, int3(region_[0], region_[1], region_[2]),             cpu_input>data, async_);       }       std::cout(&output_obj);       if (buffer_output) {         return queue_>EnqueueWriteBuffer(buffer_output>memobj,                                           cpu_input>size_bytes,                                           cpu_input>data, async_);       }     } else if (cpu_output) {       std::cout(&input_obj);       if (tex)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,B-JackMao,clEnqueueWriteBuffer To clEnqueueMapBuffer," Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.9  Custom code Yes  OS platform and distribution Ubuntu18.04  Mobile device pixel 4 Android  Python version 3.8  Bazel version 5.0.0  GCC/compiler version null  CUDA/cuDNN version null  GPU model and memory null  Current behavior? In TFLite’s GPU delegate, I tried to replace clEnqueueWriteBuffer and clEnqueueReadBuffer with clEnqueueMapBuffer and clEnqueueUnmapMemObject, which means changing the data copying to the data mapping method to pass data, but using clEnqueueWriteBuffer and clEnqueueReadBuffer can correctly recognize the image, but using clEnqueueMapBuffer and clEnqueueUnmapMemObject cannot correctly recognize the image, why is that, the following is the code I modified, what is wrong? `absl::Status Convert(const TensorObject& input_obj,                        const TensorObject& output_obj) override {     auto cpu_input = absl::get_if(&input_obj);     auto cpu_output = absl::get_if(&output_obj);     if (cpu_input) {       auto texture_output = absl::get_if(&output_obj);       if (texture_output) {         return queue_>EnqueueWriteImage(             texture_output>memobj, int3(region_[0], region_[1], region_[2]),             cpu_input>data, async_);       }       std::cout(&output_obj);       if (buffer_output) {         return queue_>EnqueueWriteBuffer(buffer_output>memobj,                                           cpu_input>size_bytes,                                           cpu_input>data, async_);       }     } else if (cpu_output) {       std::cout(&input_obj);       if (tex",2023-11-24T05:48:46Z,type:others,closed,0,1,https://github.com/tensorflow/tensorflow/issues/62473,Are you satisfied with the resolution of your issue? Yes No
426,"以下是一个github上的tensorflow下的一个issue, 标题是(Feature request: TensorFlow Hub and HuggingFace integration)， 内容是 (Integrate HuggingFace Hub and TensorFlow Hub for outofthebox usage with models and datasets. Support for TensorFlow version of HuggingFace offerings (Transformers, Diffusers, etc.))请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,AIWithShrey,Feature request: TensorFlow Hub and HuggingFace integration,"Integrate HuggingFace Hub and TensorFlow Hub for outofthebox usage with models and datasets. Support for TensorFlow version of HuggingFace offerings (Transformers, Diffusers, etc.)",2023-11-23T19:08:59Z,stat:awaiting response type:feature type:support stale,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62470,"Hi  , Tfhub already moved to Kaggle models. Please find then announcement of same from TFforum. I doubt whether it can be integrated with Hugginface now. Will discuss internally and let you know. Thanks!","Hi  , Please raise your query at TFhub repo as it should be addressed there. Thanks!","> Hi  , >  > Please raise your query at TFhub repo as it should be addressed there. Thanks! Sure! Thanks.","Hi  , Could you please close the issue and track at Hub repo?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1158,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistency in TensorFlow's Handling of Distributive Properties(`a(b+c) vs ab + ac`) in XLA compiled model)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version  3.10.12   Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I've discovered an inconsistency in TensorFlow's computation, specifically in how distributive properties are handled in tensor operations. Two models, `Model1` and `Model2`, which are mathematically equivalent under the distributive law, are producing different results when compiled with XLA on certain input set(please donwload this pickle file). This behavior is also seen on colab with TF 2.14.0    Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Inconsistency in TensorFlow's Handling of Distributive Properties(`a(b+c) vs ab + ac`) in XLA compiled model," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version  3.10.12   Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I've discovered an inconsistency in TensorFlow's computation, specifically in how distributive properties are handled in tensor operations. Two models, `Model1` and `Model2`, which are mathematically equivalent under the distributive law, are producing different results when compiled with XLA on certain input set(please donwload this pickle file). This behavior is also seen on colab with TF 2.14.0    Standalone code to reproduce the issue   Relevant log output ",2023-11-23T16:43:09Z,stat:awaiting response type:bug stale comp:xla TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62467," Hey, I was wondering, have you reproduced this issue?","Go, Hi, Providing additional outputs does not result in matching outputs. This behavior is expected. Inside the call function you are generating the value for tensor, which in each calls generates different random values because XLA currently ignores TF seeds to random operations which makes the output different for obvious reason. Please refer known issues from XLA section. Also Providing additional outputs does not result in matching outputs. This behavior is expected. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1476,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistency in TensorFlow's Handling of Associative Operations: `(a+b)*c - (a+b)*c vs. - (a*c + b*c) + a*c + b*c`)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.16.0dev20231122  Custom code Yes  OS platform and distribution Ubuntu 22.04.3  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? This bug is also seen on nightly version of tf(`2.16.0dev20231122`). I have two TensorFlow models (`Model1` and `Model2`) that are semantically the same but produce different outputs when executed. This discrepancy might indicate an underlying issue in TensorFlow's execution or optimization paths, particularly with XLA compilation.   Given that Model1 and Model2 are semantically the same (i.e.,` model1 = (p0+p1)*inp  (p0+p1)*inp` and `model2 =  (p0*inp + p1*inp) + p0*inp + p1*inp`), I would expect them to produce identical outputs for the same input. However, the models are yielding different results, which is unexpected and suggests a potential issue in TensorFlow's computation or optimization mechanisms.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,Inconsistency in TensorFlow's Handling of Associative Operations: `(a+b)*c - (a+b)*c vs. - (a*c + b*c) + a*c + b*c`," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.16.0dev20231122  Custom code Yes  OS platform and distribution Ubuntu 22.04.3  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? This bug is also seen on nightly version of tf(`2.16.0dev20231122`). I have two TensorFlow models (`Model1` and `Model2`) that are semantically the same but produce different outputs when executed. This discrepancy might indicate an underlying issue in TensorFlow's execution or optimization paths, particularly with XLA compilation.   Given that Model1 and Model2 are semantically the same (i.e.,` model1 = (p0+p1)*inp  (p0+p1)*inp` and `model2 =  (p0*inp + p1*inp) + p0*inp + p1*inp`), I would expect them to produce identical outputs for the same input. However, the models are yielding different results, which is unexpected and suggests a potential issue in TensorFlow's computation or optimization mechanisms.  Standalone code to reproduce the issue   Relevant log output ",2023-11-23T09:15:07Z,stat:awaiting response type:bug stale comp:apis TF 2.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62463," Hey, I was wondering, have you replicated this issue?",", I was able to reproduce the issue on tensorflow v2.14, v2.15 and tfnightly. Kindly find the gist of it here.","Hi Go,  I have reproduced the issue in TF 2.15.0 and also latest Tensorflow version (TF 2.18.0). The output shows that the assertions in code are being triggered in both eager and compiled modes (using tf.function with jit_compile=True). This indicates that the outputs of Model1 and Model2 are not considered ""close enough"" based on the specified tolerance (rtol=0.01). Try increasing the relative tolerance (rtol) in assertion. Could you please refer this gist file. Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1915,"以下是一个github上的tensorflow下的一个issue, 标题是(keras.Model.fit does not work correctly with generator and sparse categorical crossentropy loss)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.1  Custom code No  OS platform and distribution Ubuntu 22.04 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior?  does not work correctly with  / loss function with a generator as training data. The same symptom reported in [Accuracy killed when using ImageDataGenerator TensorFlow Keras][1]. Please advise if this behaviour is as expected or please point out if code is incorrect.  Code excerpt. Entire code at the bottom.  Symptom  Using Sparse Index as the labels with and **SparseCategoricalCrossentropy** as the loss function. The accuracy values got unstable and low, causing early stop.  2500/2500 [...]  24s 8ms/step  loss: 1.4824  accuracy: 0.0998  val_loss: 1.1893  val_accuracy: 0.1003 Epoch 2/10 2500/2500 [...]  21s 8ms/step  loss: 1.0730  accuracy: 0.1010  val_loss: 0.8896  val_accuracy: 0.0832 Epoch 3/10 2500/2500 [...]  20s 8ms/step  loss: 0.9272  accuracy: 0.1016  val_loss: 0.9150  val_accuracy: 0.0720 Epoch 4/10 2500/2500 [...]  20s 8ms/step  loss: 0.7987  accuracy: 0.1019  val_loss: 0.8087  val_accuracy: 0.0864 Epoch 5/10 2500/2500 [...]  20s 8ms/step  loss: 0.7081  accuracy: 0.1012  val_loss: 0.8707  val_accuracy: 0.0928 Epoch 6/10 2500/2500 [...]  21s 8ms/step  loss: 0.6056  accuracy: 0.1019  val_loss: 0.7688  val_accuracy: 0.0851  Using One Hot Encoding as the labels and  as the loss function (). Work as expected.   Code   Environment )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,oonisim,keras.Model.fit does not work correctly with generator and sparse categorical crossentropy loss," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.1  Custom code No  OS platform and distribution Ubuntu 22.04 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior?  does not work correctly with  / loss function with a generator as training data. The same symptom reported in [Accuracy killed when using ImageDataGenerator TensorFlow Keras][1]. Please advise if this behaviour is as expected or please point out if code is incorrect.  Code excerpt. Entire code at the bottom.  Symptom  Using Sparse Index as the labels with and **SparseCategoricalCrossentropy** as the loss function. The accuracy values got unstable and low, causing early stop.  2500/2500 [...]  24s 8ms/step  loss: 1.4824  accuracy: 0.0998  val_loss: 1.1893  val_accuracy: 0.1003 Epoch 2/10 2500/2500 [...]  21s 8ms/step  loss: 1.0730  accuracy: 0.1010  val_loss: 0.8896  val_accuracy: 0.0832 Epoch 3/10 2500/2500 [...]  20s 8ms/step  loss: 0.9272  accuracy: 0.1016  val_loss: 0.9150  val_accuracy: 0.0720 Epoch 4/10 2500/2500 [...]  20s 8ms/step  loss: 0.7987  accuracy: 0.1019  val_loss: 0.8087  val_accuracy: 0.0864 Epoch 5/10 2500/2500 [...]  20s 8ms/step  loss: 0.7081  accuracy: 0.1012  val_loss: 0.8707  val_accuracy: 0.0928 Epoch 6/10 2500/2500 [...]  21s 8ms/step  loss: 0.6056  accuracy: 0.1019  val_loss: 0.7688  val_accuracy: 0.0851  Using One Hot Encoding as the labels and  as the loss function (). Work as expected.   Code   Environment ",2023-11-23T05:05:03Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62460," Workaround The answer by innat worked as in https://stackoverflow.com/a/77535234/4281353. > The behaviour that is found with metrics=[""accuracy""] for using sparse target vectors seems like a potential bug in the API. According to the doc, the string identifier accuracy should be converted to appropriate loss instance. > In you case, you need to use  specifically to make it work. "," , The reason for this behaviour might also be due to numeric instability issue which happens with `logits=False`. For more details on this you can refer SO source here 120) & 267). If I change `logits=True` in loss function and set activation to `linear` (default) in last layer of model the model trains with gradual improvement and callbacks were not called in this case. Refer attached gist. However as per your comment above replacing `metrics=[""accuracy""]` with `metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])` works even better.But as per docstring below of trainer.py from keras3 there seems some issue with the conversion of `accuracy` to  `SparseCategoricalAccuracy`.  https://github.com/kerasteam/keras/blob/866b745ebdafb29248f6a0946fbed1ce1cbcba90/keras/trainers/trainer.pyL88","Hi  , Update... This issue seems fixed in kerasnightly(3.0.0.dev2023112703) already. I have tested with keras3 and its working fine. The `accuracy` metric automatically converted into `SparseCategoricalAccuracy` from here. You can refer the attached gist of same. Could you verify the behaviour with kerasnightly and confirm ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
897,"以下是一个github上的tensorflow下的一个issue, 标题是(`tf.linalg.cholesky` Produces Inconsistent Results with Complex and Float Tensors)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0dev20231005  Custom code Yes  OS platform and distribution Ubuntu  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm encountering a situation where a `tf.linalig.cholesky` produces different outputs for the same input in eager execution mode, which should theoretically yield consistent results.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gwihwan-Go,`tf.linalg.cholesky` Produces Inconsistent Results with Complex and Float Tensors," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0dev20231005  Custom code Yes  OS platform and distribution Ubuntu  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm encountering a situation where a `tf.linalig.cholesky` produces different outputs for the same input in eager execution mode, which should theoretically yield consistent results.  Standalone code to reproduce the issue   Relevant log output ",2023-11-21T15:08:06Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62451,"Hi, It seems the issue might be related to the requirements for Cholesky decomposition. For the decomposition to be valid, especially with complex matrices, each input matrix needs to be Hermitian (a matrix that is equal to its own conjugate transpose) and positive definite (all its eigenvalues are positive). Here are some references for more details: https://en.wikipedia.org/wiki/Cholesky_decomposition https://www.tensorflow.org/api_docs/python/tf/linalg/cholesky Also, here's a code snippet to check if your matrices meet these requirements: ","Thanks for your response. I've revisited the TensorFlow documentation on Cholesky and carefully checked the requirements: The input must be a tensor with dimensions [..., M, M], where the last two dimensions are square matrices. The tensor should be symmetric and positive definite. The function only uses the lowertriangular part of the tensor, ignoring the uppertriangular part. The output is a tensor of the same shape, containing the Cholesky decompositions for all submatrices [..., :, :]. Considering these requirements, I updated my code to ensure it meets both criteria: forming square matrices and being symmetric and positive definite. Despite this, I'm still encountering an error. This leads me to think the issue might not be with my implementation but could potentially be an issue within TensorFlow's handling of the Cholesky operation. Here's the code I updated, which I believe adheres to the documented requirements: ","  I was able to replicate this issue on colab, please find the gist here for reference. Thank you!","Hi Go, I have reproduced the issue in TF 2.15.0 and also latest Tensorflow version (TF 2.18.0). The issue might be occuring because  self.p0 is likely not positive definite, which causes the Cholesky decomposition to fail and return NaNs. You can modify how self.p0 is generated to ensure it's positive definite, or add checks to handle cases where it isn't.  Could you please refer to this gist file. Thank you. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
653,"以下是一个github上的tensorflow下的一个issue, 标题是(Using bazel build a c api )， 内容是 (**System information**  OS Platform and Distribution Linux Centos8):  TensorFlow installed from source  TensorFlow version ( github SHA if from source): **Question** Hi: When I used 'bazel build c opt //tensorflow/lite/c:tensorflowlite_c' to create the C API for tflite. I only got 'libtensorflowlite_c. so' of only 4.4M, and I'm not sure if it's correct because it's too small?May I ask if this size is correct? Why is it so small? Thanks!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,panhu,Using bazel build a c api ,"**System information**  OS Platform and Distribution Linux Centos8):  TensorFlow installed from source  TensorFlow version ( github SHA if from source): **Question** Hi: When I used 'bazel build c opt //tensorflow/lite/c:tensorflowlite_c' to create the C API for tflite. I only got 'libtensorflowlite_c. so' of only 4.4M, and I'm not sure if it's correct because it's too small?May I ask if this size is correct? Why is it so small? Thanks!",2023-11-21T07:51:04Z,stat:awaiting response type:build/install type:support stale comp:lite,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62445,"Hi  , On linux given build command should generate `libtensorflowlite_c.so`, and the mentioned size seems Ok to me as per the similar ticket CC(how to reduce libtensorflowlite.so size).  You may also test with CMake build as per instructions here. You can also refer lite guide here%2C%20and%20less%20than%20300KB%20when%20using%20only%20the%20operators%20needed%20for%20supporting%20the%20common%20image%20classification%20models%20InceptionV3%20and%20MobileNet.). Basically all tensorflow Ops are not supported for tflite and hence it is lightweight.","Hi: Thank you for your reply. I would like to ask if Tflite supports the Riscv architecture. If so, how should we build the relevant shared library of tflite ? Is there a Riscv toolchain? Thanks!","Hi , It seems this query is already answered here.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"hi , i am working on building bazel on riscv. do you have any way? thanks!"
1406,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow - tf.keras.Model.fit causes run out of data for validation data with validation_steps being set)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.1  Custom code No  OS platform and distribution Ubuntu 22.04 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior? Trying to understand the  parameter of tf.keras.Model.fit. > Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. For instance, TFDS MNIST dataset has  train and  test data records. Trying to consume all the records during  epochs with  using generators as the data sources to the model.  The training data can afford  batches, and the test data can afford  batches.   However, setting  causes the error .    Code  By minus 1, it works.  Please help understand this behavior. Also the document says  but obviously it is not only for .  Environment    [1]: https://www.tensorflow.org/datasets/catalog/mnist  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,oonisim,tensorflow - tf.keras.Model.fit causes run out of data for validation data with validation_steps being set," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.1  Custom code No  OS platform and distribution Ubuntu 22.04 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior? Trying to understand the  parameter of tf.keras.Model.fit. > Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. For instance, TFDS MNIST dataset has  train and  test data records. Trying to consume all the records during  epochs with  using generators as the data sources to the model.  The training data can afford  batches, and the test data can afford  batches.   However, setting  causes the error .    Code  By minus 1, it works.  Please help understand this behavior. Also the document says  but obviously it is not only for .  Environment    [1]: https://www.tensorflow.org/datasets/catalog/mnist  Standalone code to reproduce the issue   Relevant log output ",2023-11-21T07:24:17Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62444,"  I was able to replicate the issue on colab, please find the gist here for reference. Thank you!","Hi,  Please go through the discussion here to understand the correct number of steps for validation and training. Basic rule to follow is: ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
927,"以下是一个github上的tensorflow下的一个issue, 标题是(TF-OPT issue: StatelessRandomUniformV2 requires Compile Time Constant  )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.16.0dev20231013  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version g++11  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I built a custom model which classifies the mnist digits. Then used  to convert the saved model to tf dialect mlir. Then I tried to use the  with  pass to get the hlo dialect from tensorflow dialect. It throws an error that says:    Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,monowaranjum,TF-OPT issue: StatelessRandomUniformV2 requires Compile Time Constant  , Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.16.0dev20231013  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version g++11  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I built a custom model which classifies the mnist digits. Then used  to convert the saved model to tf dialect mlir. Then I tried to use the  with  pass to get the hlo dialect from tensorflow dialect. It throws an error that says:    Standalone code to reproduce the issue   Relevant log output ,2023-11-20T17:35:04Z,stat:awaiting response type:bug stale comp:core,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62442,", I tried to execute the mentioned above on google colab with the latest stable tensorflow version and it was executed without any issue/error. Kindly find the gist of it here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
1899,"以下是一个github上的tensorflow下的一个issue, 标题是(Bug in memory out-of-bound related to kMaxDim of RuntimeShape at tflite kernels)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.8.0  Custom code Yes  OS platform and distribution Linux Ubuntu 18.04  Mobile device No  Python version 3.8  Bazel version no  GCC/compiler version gcc 8.4.0  CUDA/cuDNN version no  GPU model and memory no  Current behavior?  I am using the tensorflowlite interpreter in the project using tensorflow/lite/kernels/internal/reference/broadcast_to.h.   However, by setting kMaxDims to 8 in file tensorflow/lite/kernels/broadcast_to.cc, I also want to set kMaxDims to 8 in my project and use `tensorflow/lite/kernels/internal/reference/broadcast_to.h`.   In Ubuntu 20.04 and 22.04, there is no problem using kMaxDims as 8 and calling, but an `outofbounds error` occurred in a specific version of `Ubuntu18.04`.   It seems that the size check of the dimension in `tflite::RuntimeShape` exceeds the kMaxSmallSize in tensorflow/lite/kernels/internal/runtime_shape.h of 5, but I do not know why this problem occurs only in Ubuntu 18.04.   Could you tell me about this bug?  Standalone code to reproduce the issue  my codes in samsung ONE project  link  shell  error logs in Ubuntu 18.04 [20231120T06:36:26.326Z] In member function ‘void luci_interpreter::kernels::BroadcastTo::evalFloat() const’: [20231120T06:36:26.326Z] cc1plus: error: ‘void* __builtin_memcpy(void*, const void*, long unsigned int)’ forming offset [33, 40] is out of the bounds [0, 32] of object ‘’ with type ‘tflite::RuntimeShape’ [Werror=arraybounds] [20231120T06:36:26.326Z] In file included from /opt/jenkins_agent/workspace/nnfw/master/prnnccrelease/comp)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,Seunghui98,Bug in memory out-of-bound related to kMaxDim of RuntimeShape at tflite kernels," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.8.0  Custom code Yes  OS platform and distribution Linux Ubuntu 18.04  Mobile device No  Python version 3.8  Bazel version no  GCC/compiler version gcc 8.4.0  CUDA/cuDNN version no  GPU model and memory no  Current behavior?  I am using the tensorflowlite interpreter in the project using tensorflow/lite/kernels/internal/reference/broadcast_to.h.   However, by setting kMaxDims to 8 in file tensorflow/lite/kernels/broadcast_to.cc, I also want to set kMaxDims to 8 in my project and use `tensorflow/lite/kernels/internal/reference/broadcast_to.h`.   In Ubuntu 20.04 and 22.04, there is no problem using kMaxDims as 8 and calling, but an `outofbounds error` occurred in a specific version of `Ubuntu18.04`.   It seems that the size check of the dimension in `tflite::RuntimeShape` exceeds the kMaxSmallSize in tensorflow/lite/kernels/internal/runtime_shape.h of 5, but I do not know why this problem occurs only in Ubuntu 18.04.   Could you tell me about this bug?  Standalone code to reproduce the issue  my codes in samsung ONE project  link  shell  error logs in Ubuntu 18.04 [20231120T06:36:26.326Z] In member function ‘void luci_interpreter::kernels::BroadcastTo::evalFloat() const’: [20231120T06:36:26.326Z] cc1plus: error: ‘void* __builtin_memcpy(void*, const void*, long unsigned int)’ forming offset [33, 40] is out of the bounds [0, 32] of object ‘’ with type ‘tflite::RuntimeShape’ [Werror=arraybounds] [20231120T06:36:26.326Z] In file included from /opt/jenkins_agent/workspace/nnfw/master/prnnccrelease/comp",2023-11-20T11:47:22Z,stat:awaiting response type:bug stale comp:lite TF 2.8,closed,1,10,https://github.com/tensorflow/tensorflow/issues/62440,"Hmmm.. I'm not sure but the error occurred at the following codes.  I think there could be three candidates that cause an error. 1. Caller fault 2. Callee fault 3. Compiler bug When it comes to the third one, I think the compiler doesn't evaluate properly `DimsData` which should return `dims_` or `dims_pointer` according to its size. Well, but I don't know exact reason. I just show you trial and error codes where the build is successful with that codes, which might help you guess what causes an errorr. 1. Just change `kMaxSmallSize` to 8 instead of 5. 4. Make `dims_` a pointer.   diff    4. Comment out `input_shape.Dims(i)` part in `CopyDimsToDesc`.   diff   ", Could you please Use a different model quantization method and avoid using models with more than 8 dimensions. Please try with the latest TF version as you are using an older TF version(2.8.0) ?  Thank you!,"  This problem(array outofbound) seems to be caused by the gcc version of c++.  > Compiler Bug In Ubuntu 18.04, the basic version of gcc is 7.4, and  it seems that there is a bug related to `built_in_memcpy` in tensorflow only in this version.  This is because the upper versions, Ubuntu 20.04 and 22.04, have a basic version of gcc of 9.4 and no related errors occur here. :)",", Please look into the issue. Thank You","Hi , is there any reason you can't use a newer version of TF & gcc? I should also note that clang will be better supported, now and in the future so it is recommended, especially with versions >= 2.13, to use clang instead of gcc.","  > is there any reason you can't use a newer version of TF & gcc? Yes. Our project using tflite kernel has dependency on specific `gcc` and `TF` version now. > so it is recommended, especially with versions >= 2.13, to use clang instead of gcc. Okay.. Thank you for your reply. :)","Hi , as you stated yourself gcc == 9.4 already resolves the issue, so I think the solution would be to figure out how to update your project/stack as in some sense this is already fixed right? Let us know if for some reason this does not resolve the issue. Please review the compatibility matrix: https://www.tensorflow.org/install/sourcecpu",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1790,"以下是一个github上的tensorflow下的一个issue, 标题是(Remove endian conversion for S4/U4 literals for s390x)， 内容是 (After introducing **_commit_** to add support for int4(S4 and U4) types in literal, `//tensorflow/compiler/xla:literal_test` started to fail for BE(s390x) machines. This issue is occurring in `ProtoRoundTrip` test case when we try to convert/retrieve S4/U4 literal to/from proto values. >   auto vector_s4 = LiteralUtil::CreateR1({s4{1}, s4{3}, s4{7}}); >   auto vector_u4 = LiteralUtil::CreateR1({u4{1}, u4{3}, u4{15}}); >   EXPECT_EQ(vector_s4, to_from_proto(vector_s4)); >   EXPECT_EQ(vector_u4, to_from_proto(vector_u4)); ConvertEndianShort assertion is failing as it expects an **even** byte size, but  for vector_s4 / vector_u4, byte size is coming as 3(odd), causing the test case to fail. ConvertEndianShort is getting used mostly to convert **16 bit** literal types to **LE** byte order as protobuf seems to be  processing **bytes** in LE format. > In third_party/xla/xla/xla_data.proto  > message LiteralProto { >   ... >   bytes s4s = 21; >   bytes u4s = 22; >   ... >   // The F16s, BF16s, U16s and S16s are encoded in little endian byte order >   bytes f16s = 11; >   bytes bf16s = 13; >   bytes u16s = 16; >   bytes s16s = 17; Since S4/U4 underlying type is a single byte, endian conversion is not needed for S4/U4 literal types. Hence removing endian conversion for S4/U4 integer literals types. > using u4 = ml_dtypes::uint4; > using s4 = ml_dtypes::int4; After these changes, `//tensorflow/compiler/xla:literal_test` test case passes. These changes do not cause any regressions on existing test cases and it won't affect LE machines.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,yasiribmcon,Remove endian conversion for S4/U4 literals for s390x,"After introducing **_commit_** to add support for int4(S4 and U4) types in literal, `//tensorflow/compiler/xla:literal_test` started to fail for BE(s390x) machines. This issue is occurring in `ProtoRoundTrip` test case when we try to convert/retrieve S4/U4 literal to/from proto values. >   auto vector_s4 = LiteralUtil::CreateR1({s4{1}, s4{3}, s4{7}}); >   auto vector_u4 = LiteralUtil::CreateR1({u4{1}, u4{3}, u4{15}}); >   EXPECT_EQ(vector_s4, to_from_proto(vector_s4)); >   EXPECT_EQ(vector_u4, to_from_proto(vector_u4)); ConvertEndianShort assertion is failing as it expects an **even** byte size, but  for vector_s4 / vector_u4, byte size is coming as 3(odd), causing the test case to fail. ConvertEndianShort is getting used mostly to convert **16 bit** literal types to **LE** byte order as protobuf seems to be  processing **bytes** in LE format. > In third_party/xla/xla/xla_data.proto  > message LiteralProto { >   ... >   bytes s4s = 21; >   bytes u4s = 22; >   ... >   // The F16s, BF16s, U16s and S16s are encoded in little endian byte order >   bytes f16s = 11; >   bytes bf16s = 13; >   bytes u16s = 16; >   bytes s16s = 17; Since S4/U4 underlying type is a single byte, endian conversion is not needed for S4/U4 literal types. Hence removing endian conversion for S4/U4 integer literals types. > using u4 = ml_dtypes::uint4; > using s4 = ml_dtypes::int4; After these changes, `//tensorflow/compiler/xla:literal_test` test case passes. These changes do not cause any regressions on existing test cases and it won't affect LE machines.",2023-11-20T04:51:20Z,comp:xla size:S,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62437,"Hi  , Could you please kindly review this PR? Thank you very much!", WDYT?,"I think XLA changes must be submitted to the openxla/xla repo, not the TensorFlow repo (CC , correct me if I'm wrong). , can you create a new PR to the openxla/xla repo with this change and CC me? Once merged, the TF repo will automatically be updated.","Yeah in principle it should be possible from here, but we have it disabled for at least the next month. So it would be great if you could reopen on openxla/xla. Feel free to tag me and I'll make sure it gets merged quickly.",Hi  Any update on this PR? Please. Thank you!,Apologies for the delay due to christmas break   . Created PR https://github.com/openxla/xla/pull/8162.,Hi  Required changes have been merged with https://github.com/openxla/xla/pull/8162. Please feel free to close this PR. Thank you very much!,> Hi  Required changes have been merged with openxla/xla CC(Show location of using uninitialized variable in the stacktrace). Please feel free to close this PR. Thank you very much! Hi   Thank you very much for the confirmation. 
840,"以下是一个github上的tensorflow下的一个issue, 标题是(Bug in tf.test.compute_gradient for tf.keras.layers.GlobalMaxPooling2D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The numerical gradient and theoretical gradient for `tf.keras.layers.GlobalMaxPooling2D` is different, one is `0.2`, the other is `0.5`.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,Bug in tf.test.compute_gradient for tf.keras.layers.GlobalMaxPooling2D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The numerical gradient and theoretical gradient for `tf.keras.layers.GlobalMaxPooling2D` is different, one is `0.2`, the other is `0.5`.   Standalone code to reproduce the issue   Relevant log output ",2023-11-19T12:58:32Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62435,Same problem can be found in tf.keras.layers.GlobalMaxPooling3D. Here is the repo code: ,Same problem can be found in tf.keras.layers.MaxPooling1D. Here is the repo code: ," I was able to replicate the issue on colab, please find the gist here. Thank you!","Hi   I tried to define a range of min, max values in this case minval=0, maxval=1, which made the code avoid ambiguity in theoretical and numerical gradients.Please find the gist here",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
748,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.DepthwiseConv2D throws error when backprop)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tf.keras.layers.DepthwiseConv2D throws error in backprop.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,tf.keras.layers.DepthwiseConv2D throws error when backprop, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tf.keras.layers.DepthwiseConv2D throws error in backprop.  Standalone code to reproduce the issue   Relevant log output ,2023-11-19T12:00:24Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62433,", I was able to replicate the reported behaviour with TF v2.13, TF v2.14 and tfnightly. Kindly find the gist for reference. Currently we are investigating the issue & will deep dive into the issue and provide the rootcause for the same. Thank you!","Hi , The Graph execution error is  due to the mismatch between input tensor shape, kernel size and stride.   * The input tensor shape,  kernel size and stride defined in the code are [2,15,1,1], (3,3) and (2,2) respectively.  In this case, your input tensor dimensions are lesser than the kernel size. Obviously, no convolution is performed and hence the error. So either reduce the filter size or  use the `padding = ""same""` or  increase the input dimensions.  * Setting both `minval=0 and maxval=0`, will produce zero input tensor, no gradients will flow and  leads to trivial condition.   So define the range for minval and max val.  * Tested for the following cases: `__input___0_tensor = tf.random.uniform([2, 15, 4, 4], minval=0, maxval=1, dtype=tf.float64) kernel size(3,3), stride(2,2) and padding=""valid""` ` __input___0_tensor = tf.random.uniform([2, 15, 1,1], minval=0, maxval=1, dtype=tf.float64) kernel size(1,1), stride(1,1) and padding=""valid""` ` __input___0_tensor = tf.random.uniform([2, 15, 1,1], minval=0, maxval=1, dtype=tf.float64) kernel size(3,3), stride(2,2) and padding=""same""`. Please refer to the gist. Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
723,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.Dense throws error when backprop)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tf.keras.layers.Dense crashes in backprop.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,tf.keras.layers.Dense throws error when backprop, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tf.keras.layers.Dense crashes in backprop.  Standalone code to reproduce the issue   Relevant log output ,2023-11-19T11:44:12Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62432,"Hi  , I have replicated the reported behaviour with TF2.14 and tfnightly as well. Attached gist for reference. Will dig more into for the root cause and come back. Thanks!","Hi  , I believe the bug stems from the absence of units validation. As per the documentation, units should be a positive integer. However, in the provided code, when units is set to 0, no error is raised during the execution of res = layer(inputs)."," , Making `units>0` indeed resolves this issue. I can see validation for `units < 0` not `units <= 0`. This needs to check internally. ",", The PR which was raised for the respective issue was raised and also observed that the changes are reflected in the file. Kindly find the PR for the reference. https://github.com/kerasteam/tfkeras/pull/721 https://github.com/kiraksi/tfkeras/blob/master/tf_keras/layers/core/dense.pyL122 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
808,"以下是一个github上的tensorflow下的一个issue, 标题是(Bug in tf.test.compute_gradient for tf.keras.layers.Conv3DTranspose)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The numerical gradient and theoretical gradient for `tf.keras.layers.Conv3DTranspose` is different.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,Bug in tf.test.compute_gradient for tf.keras.layers.Conv3DTranspose, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The numerical gradient and theoretical gradient for `tf.keras.layers.Conv3DTranspose` is different.  Standalone code to reproduce the issue   Relevant log output ,2023-11-19T09:33:39Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62431," I was able to replicate this issue, please find the attached gist here.  Thank you!","Hi , The issue here is that the input dimensions are larger than or equal to the  the filter size. If not, no proper convolution operation is carried and leading to incorrect results. So maintain the compatibility between input, kernel and stride dimensions. Here is the gist with suggested changes.  Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
822,"以下是一个github上的tensorflow下的一个issue, 标题是(Bug in tf.test.compute_gradient for tf.keras.layers.Activation)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The numerical gradient and theoretical gradient for `tf.keras.layers.Activation` is different, one is `0.5`, the other is `0`.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,Bug in tf.test.compute_gradient for tf.keras.layers.Activation," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The numerical gradient and theoretical gradient for `tf.keras.layers.Activation` is different, one is `0.5`, the other is `0`.   Standalone code to reproduce the issue   Relevant log output ",2023-11-19T08:38:35Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:keras TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62429,"Hi  , I have replicated the reported behaviour with colab using TF v2.14, 2.15, and TFnightly. Please find the gist here for reference. Thank you!","Hi , The derivative of relu activation function at zero is undefined. when calculating numerically it might  either pick 0 or 1. It might be the reason for different results. Thank You.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
710,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.ConvLSTM2D throws error when backprop)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? API crashes in backprop.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,tf.keras.layers.ConvLSTM2D throws error when backprop, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? API crashes in backprop.  Standalone code to reproduce the issue   Relevant log output ,2023-11-19T03:58:36Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62427,"  I was able to replicate the reported behaviour with TF2.13, TF2.14 and tfnightly. Kindly find the gist for reference.","Hi , The incorrect shape `(2, 2, 2, 0)` is due to mismatch between the input and padding, kernel size and strides. With 'valid' padding, the output of the ConvLSTM2D layer have a spatial dimension of 0. Instead of valid padding, use `padding = ""same"" ` and set `return_sequences=True`,  so that the output shape aligns with the expected shape for gradient calculation, even when processing the sequence in reverse order(go_backwards = True). Verified the code with these changes in TF 2.18.0 . Please refer to the following code.   Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
808,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.Conv3DTranspose throws error when backprop)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? During backpropagation, the API crashes. Based on the error message, it appears to be indicative of an OOM situation.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,tf.keras.layers.Conv3DTranspose throws error when backprop," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? During backpropagation, the API crashes. Based on the error message, it appears to be indicative of an OOM situation.  Standalone code to reproduce the issue   Relevant log output ",2023-11-19T03:02:23Z,stat:awaiting response type:bug comp:keras TF2.14,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62426,Same problem can be found in tf.keras.layers.LocallyConnected2D. Here is the repo code: ,"Hi  , I have tested the given code on colab and its working fine.Please refer attached gist.  Please note that I have reduced the no of filters due to Memory constraints but it should not affect the reported behaviour. Could you please verify the behaviour attached. Can you confirm whether the issue with Windows Package as it will download intel package? Thanks!","Hi , It appears that the number of filters does make a difference 😂. In your gist, where the number of filters is set to 40, there are no crashes. However, I repo above code in colab, in the provided gist, where the number of filters is increased to 1792, it crashes, and the error message suggests a potential OOM issue. ",Same problem can be found in tf.keras.layers.UpSampling2D. Here is the repo code:  output is:  It may be that the size is too large and the memory is overflowing.,Same problem can be found in tf.keras.layers.ZeroPadding3D. Here is the repo code: ,"> Hi , It appears that the number of filters does make a difference 😂. In your gist, where the number of filters is set to 40, there are no crashes. However, I repo above code in colab, in the provided gist, where the number of filters is increased to 1792, it crashes, and the error message suggests a potential OOM issue. Hi  , OOM errors are not problem with Tensorflow and with low number of filters it is indeed working. Oh Sorry,I missed this from your logs.  This is OOM error and not a problem with Tensorflow. With higher input size this is intended.","Hi  , I understand. It appears that this issue is related to the device I am currently using. I'll reduce the no of filters. Thank you!",Are you satisfied with the resolution of your issue? Yes No
990,"以下是一个github上的tensorflow下的一个issue, 标题是(Bug in backward gradient for tf.keras.layers.Conv2DTranspose)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The shape of res_backward is (1, 5, 6, 2), the shape of res_forward is (1, 5, 6, 2), the shape of grad_jvp is (1, 5, 6, 2), while the shape of backward gradient is (1, 5, 6, 2, 1, 5, 6, 2). I think both the values and shapes of grad_backward and grad_jvp should be the same.   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,Bug in backward gradient for tf.keras.layers.Conv2DTranspose," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The shape of res_backward is (1, 5, 6, 2), the shape of res_forward is (1, 5, 6, 2), the shape of grad_jvp is (1, 5, 6, 2), while the shape of backward gradient is (1, 5, 6, 2, 1, 5, 6, 2). I think both the values and shapes of grad_backward and grad_jvp should be the same.   Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-18T12:26:28Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62424,"close as it fixed in tf v2.14, while can be repro in tf v2.9 ",Are you satisfied with the resolution of your issue? Yes No
915,"以下是一个github上的tensorflow下的一个issue, 标题是(Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling3D, but backward AD succeeded with same input)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling3D, but backward AD succeeded with same input.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,cheyennee,"Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling3D, but backward AD succeeded with same input"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling3D, but backward AD succeeded with same input.  Standalone code to reproduce the issue   Relevant log output ",2023-11-18T10:28:55Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62423,", Looks like this is duplicate of issue  CC(Forward AD threw error in `tf.autodiff.ForwardAccumulator` for `tf.keras.layers.MaxPooling3D`, but backward AD succeeded with same input). Could you please close this issue, since it is already being tracked there? Thank you!","Hi,  , It is not a duplicate of issue CC(Forward AD threw error in `tf.autodiff.ForwardAccumulator` for `tf.keras.layers.MaxPooling3D`, but backward AD succeeded with same input). The provided code snippet triggers an error only when padding=""valid"" is used, not when padding=""same"". Additionally, in line with the details outlined in CC(Forward AD threw error in `tf.autodiff.ForwardAccumulator` for `tf.keras.layers.MaxPooling3D`, but backward AD succeeded with same input), I have already configured the data_format parameter.",", I was able to replicate the reported behaviour with TF2.14 and tfnightly as well. Attached gist for reference. Currently we are investigating the issue & will deep dive into the issue and provide the rootcause for the same. Thank you!","Hi , The error is due to the `pool_size` and `input dimensions` , both are incompatible. In this case, your input tensor dimensions are lesser than the kernel size. Obviously, no convolution is performed and hence the error. So either increase the input dimension or decrease the pool size. Please refer to the gist Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
905,"以下是一个github上的tensorflow下的一个issue, 标题是(Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling2D, but backward AD succeeded with same input)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling2D, but backward AD succeeded with same input  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,"Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling2D, but backward AD succeeded with same input"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Forward AD threw error in tf.autodiff.ForwardAccumulator for tf.keras.layers.AveragePooling2D, but backward AD succeeded with same input  Standalone code to reproduce the issue   Relevant log output ",2023-11-18T08:44:06Z,stat:awaiting response type:bug stale comp:keras comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62422,"Hi  , I have replicated the reported behaviour with TF2.14 and tfnightly as well. Attached gist for reference. Will dig more into for the root cause and come back. Thanks!","Hi **** , apologies for the dealy, Thanks for patience. The issue you are facing because the input tensor has a width of 1, which is smaller than the specified pooling width of 3. When using the ""VALID"" padding mode, the pooling operation tries to apply a window of size 3 over a width of 1, which results in a negative dimension and causes an error. you can either reduce the pooling width to 1, change the padding mode to ""SAME"" (which adds padding to ensure valid dimensions), or increase the input width to be larger than the pooling window. Please find the gist here for reference. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1084,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.AlphaDropout crash when noise_shape is a tensor)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In the documentation, there is no information provided for the `noise_shape` parameter. When the value of `noise_shape` is set as a tensor, the API crashes. It is recommended that the documentation include details about the usage of `noise_shape` or that the error message generated by `tf.keras.layers.AlphaDropout` be improved to offer clearer guidance in the event of a crash.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,tf.keras.layers.AlphaDropout crash when noise_shape is a tensor," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In the documentation, there is no information provided for the `noise_shape` parameter. When the value of `noise_shape` is set as a tensor, the API crashes. It is recommended that the documentation include details about the usage of `noise_shape` or that the error message generated by `tf.keras.layers.AlphaDropout` be improved to offer clearer guidance in the event of a crash.  Standalone code to reproduce the issue   Relevant log output ",2023-11-18T07:53:09Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62421, I was able to replicate the issue reported here. Could you please use a fixed value for noise_shape instead of a tensor as a workaround? Thank you!,"Hi, . Using a fixed value for `noise_shape` works well. But I think it would be better if the documentation include details about the usage of `noise_shape` or that the error message generated `by tf.keras.layers.AlphaDropout` be improved to offer clearer guidance in the event of a crash.","Hi   I tried running the given code snippet using tensorflow version 2.18.0 and also the nightly version, it was working fine, Please find the gist here.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
814,"以下是一个github上的tensorflow下的一个issue, 标题是(Wrong gradient calculated for API tf.keras.layers.Add)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Forward mode differentiation for the case is inconsistent with the gradient calculated in reverse mode. They shoule be the same.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,Wrong gradient calculated for API tf.keras.layers.Add, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Forward mode differentiation for the case is inconsistent with the gradient calculated in reverse mode. They shoule be the same.  Standalone code to reproduce the issue   Relevant log output ,2023-11-18T06:48:12Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62420,"Hi **** , I was able to reproduce the issue on colab using TF v2.14, 2.15, and TFnightly. Please find the gist here for reference. Thank you!","Hi , Please specify the arguments for Jacobian function as res_backward and inputs like `grad_backward = g.jacobian(res_backward, inputs)` instead of passing same argument( res_backward) to the Jacobian function. Please refer to the gist.  The issue here is that in the `reversemode`,  the gradients  are computed for each input independently, which results in the gradients [1.0, 1.0]. The same thing you can observe here in the `grad_backward` output:`grad_backward: [, ]` which is expected behavior. while forwardmode computes the total of derivatives, which is the sum of the gradients weighted by the tangents. Since your tangents are [1.0, 1.0], the result is the sum of the individual gradients: 2.0. Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1701,"以下是一个github上的tensorflow下的一个issue, 标题是(StatefulRandomBinomial not able to run using GPU)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.15.0rc18g6887368d6d4 2.15.0  Custom code No  OS platform and distribution MacOS Sonoma 14.1.1  Mobile device _No response_  Python version 3.11.6   Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to generate binomial random numbers using the GPU on my macbook with tensorflowmetal installed. Everything works fine using the CPU. In addition, generating i) normally distributed random numbers  and ii) stateless binomially distributed random numbers both work fine using the GPU. I did a search and couldn't find any mention of issues with random number generation using tensorflowmetal.  The fact normal random numbers and the stateless generator work fine suggests this issue could be due to a bug/oversight. If the reason is instead that the device isn't supported for StatefulRandomBinomial, I'm happy for this issue to be changed to a feature request. The minimal example to reproduce the bug is taken from the documentation, https://www.tensorflow.org/api_docs/python/tf/random/Generator I'm happy to update this issue with any other information you need to reproduce it. Unfortunately I can't test whether this issue is limited to macOS or is more general.  Many thanks!  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,tsbrett,StatefulRandomBinomial not able to run using GPU," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.15.0rc18g6887368d6d4 2.15.0  Custom code No  OS platform and distribution MacOS Sonoma 14.1.1  Mobile device _No response_  Python version 3.11.6   Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to generate binomial random numbers using the GPU on my macbook with tensorflowmetal installed. Everything works fine using the CPU. In addition, generating i) normally distributed random numbers  and ii) stateless binomially distributed random numbers both work fine using the GPU. I did a search and couldn't find any mention of issues with random number generation using tensorflowmetal.  The fact normal random numbers and the stateless generator work fine suggests this issue could be due to a bug/oversight. If the reason is instead that the device isn't supported for StatefulRandomBinomial, I'm happy for this issue to be changed to a feature request. The minimal example to reproduce the bug is taken from the documentation, https://www.tensorflow.org/api_docs/python/tf/random/Generator I'm happy to update this issue with any other information you need to reproduce it. Unfortunately I can't test whether this issue is limited to macOS or is more general.  Many thanks!  Standalone code to reproduce the issue   Relevant log output ",2023-11-17T21:37:51Z,stat:awaiting response type:feature stale comp:ops comp:gpu TF 2.15,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62419,", Apologies for the delay. I tried to execute the mentioned code on tensorflow v2.15 and it was executed without any issue/error. Kindly find the gist of it here and confirm whether we are missing anything in this. Thank you!"," Thanks for your response. The gist you shared contains everything to reproduce the problem, and, as you say, looks to be working correctly. This suggests is issue is with running the code on an Apple M series. I'm using an Apple M3 pro chip with the package tensorflowmetal v1.1.0 installed.  I've confirmed everything is correctly installed and tensorflow is able to use the GPU device, e.g. for generating normally distributed random numbers (see the above code example).",", I tried to execute the code on tensorflow v2.15 with GPU, the code was executed with the user mentioned error. But where as on CPU it was executed without any issue/error. Kindly find the gist of it here.","Hi, As the error suggests, binomial is not registered on `GPU` kernels for any of the `dtype`. Have changed the issue to feature request. Will hear it from the team if they have any plan to implement this. Thanks!","Hi ,  I have reproduced the issue in TF 2.15.0 and also latest Tensorflow version (TF 2.18.0). There is no error in output response. Kindly find this gist file. If you have any concerns let me know will assist you.  Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1871,"以下是一个github上的tensorflow下的一个issue, 标题是(MLIR: TF-OPT build fails for tensorflow 2.10, 2.14 )， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.10, 2.14  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version gcc11, clang14  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tfopt build fails. It fails to download some of the files and throws java.io.FileNotFoundException and then after a while it just shows the build failed error.  I am using bazelisk for bazel version management and the version being used for tf branch rc2.10 is 5.1.1.  Python version is 3.10 .   Standalone code to reproduce the issue  Then I run the bazel command:   shell Expected the build process to complete and build tfopt target. Here is the error log: bazel build override_repository=llvmproject=$LLVM_BAZEL_OVERLAY \   c opt tensorflow/compiler/mlir:tfopt 2023/11/17 14:51:11 Downloading https://releases.bazel.build/5.1.1/release/bazel5.1.1linuxx86_64... Downloading: 49 MB out of 49 MB (100%)  Extracting Bazel installation... Starting local Bazel server and connecting to it... INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=133 INFO: Reading rc options for 'build' from /home/rashik/Documents/onnxmlir/virtual_env/tf2onnxenv/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /home/rashik/Documents/onnxmlir/virtual_env/tf2onnxenv/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define=u)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,monowaranjum,"MLIR: TF-OPT build fails for tensorflow 2.10, 2.14 "," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.10, 2.14  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version gcc11, clang14  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? tfopt build fails. It fails to download some of the files and throws java.io.FileNotFoundException and then after a while it just shows the build failed error.  I am using bazelisk for bazel version management and the version being used for tf branch rc2.10 is 5.1.1.  Python version is 3.10 .   Standalone code to reproduce the issue  Then I run the bazel command:   shell Expected the build process to complete and build tfopt target. Here is the error log: bazel build override_repository=llvmproject=$LLVM_BAZEL_OVERLAY \   c opt tensorflow/compiler/mlir:tfopt 2023/11/17 14:51:11 Downloading https://releases.bazel.build/5.1.1/release/bazel5.1.1linuxx86_64... Downloading: 49 MB out of 49 MB (100%)  Extracting Bazel installation... Starting local Bazel server and connecting to it... INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=133 INFO: Reading rc options for 'build' from /home/rashik/Documents/onnxmlir/virtual_env/tf2onnxenv/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /home/rashik/Documents/onnxmlir/virtual_env/tf2onnxenv/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define=u",2023-11-17T20:06:43Z,type:build/install subtype: ubuntu/linux TF2.14,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62418,"Hi  , Could you please check these instructions to build with MLIR. You need to add a BUILD.bazel  file in the LLVM directory like below which seems causing the issue.  `bazel build override_repository=""llvmraw=${LLVM_SRC}"" c opt tensorflow/compiler/mlir:tfopt`","Hi, I tried your recommended solution. I could not get it to work. It only worked when I removed the bazel overlay. The command that worked for me was: . ",Are you satisfied with the resolution of your issue? Yes No
1028,"以下是一个github上的tensorflow下的一个issue, 标题是(TF 2.15 fails to build on Ubuntu 23.10)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code No  OS platform and distribution Ubuntu 23.10  Mobile device _No response_  Python version 3.11.5 Anaconda  Bazel version 6.1.0  GCC/compiler version Clang 17.0.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi, I was trying to build the release 2.15 myself with the flag march=native. But unfortunately it fails when just building the package builder program using bazel.  I use a Ryzen 5 7600 CPU with no dedicated graphics (has integrated Radeon graphics). So I was trying to build a CPU only version. (no ROCM, no CUDA. The compiler used was Clang 17.0.4.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JohnRTitor,TF 2.15 fails to build on Ubuntu 23.10," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code No  OS platform and distribution Ubuntu 23.10  Mobile device _No response_  Python version 3.11.5 Anaconda  Bazel version 6.1.0  GCC/compiler version Clang 17.0.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi, I was trying to build the release 2.15 myself with the flag march=native. But unfortunately it fails when just building the package builder program using bazel.  I use a Ryzen 5 7600 CPU with no dedicated graphics (has integrated Radeon graphics). So I was trying to build a CPU only version. (no ROCM, no CUDA. The compiler used was Clang 17.0.4.  Standalone code to reproduce the issue   Relevant log output ",2023-11-17T16:54:13Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.15,closed,1,13,https://github.com/tensorflow/tensorflow/issues/62416,I faced the same issue and managed to work around it by adding the ``copt=Wnognuoffsetofextensions`` flag.,"Added the copt=Wnognuoffsetofextensions flag. Now it tries to compile all to the end, instead of failing midway. And then it fails at the last moment, just at the last step. ",Running with the k flag in bazel build: ,"Quick note since this is the first google result for this error  this happens when running with clang 17 or 18, so if you're just trying to build tensorflow then follow the documentation and use LLVM 16 / clang 16.","Does using clang 16 builds it completely without error? In my case, both were installed. But the configure script preferred clang17 for some reason for r2.15. For 2.14 and below it prefers clang14. On another note, I managed to completely workaround this issue by using a container to build tensorflow instead of using packages and libraries from my host system. I used Distrobox with DebianTesting image, installed the necessary packages, used a Python virtual enviornment. And just followed the instructions. Built successfully without any library errors. ",bazoo the documentation now says use Clang17....," , Please use the below tested build configurations Version  Bazel 6.5.0","I do not run Ubuntu 23.10 on my main system anymore and instead have switched to NixOS. Can other participants like bazoo  test this with the above build tools on Ubuntu 23.10? Note: to get a specific version of Clang you can use https://apt.llvm.org/ and as for Bazel, just use bazelisk. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,It seems like unnecessary symbol ignores causing issues. At Solus this is how we fixed it with Clang 18: https://github.com/getsolus/packages/blob/dfc56ba57a8af8233a635e309b499ff5d27992f4/packages/t/tensorflow/files/fixclang18.diff,">  , Please use the below tested build configurations > Version 	Python version 	Compiler 	Build tools > tensorflow2.16.1 	3.93.12 	Clang 17.0.6 	Bazel 6.5.0 Hi, sometimes it is not possible to use newer build version. For example I am currently limited to tensorflow 2.15 due to specific hardware requirements (imx processor). Maybe the solution to this problem would be to have a separate build information for each version of tensorflow. I haven't tested whether the problem exists on clang16 but I can confirm that the problem exists for tf 2.15 and Clang 17.0.6. I've solved the issue using  advice."
816,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.layers.AveragePooling3D crash)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I run this code in colab, the colab crash and throw error message:  I also run this code in pycharm, the pycharm exits directly and   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cheyennee,tf.keras.layers.AveragePooling3D crash," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution windows colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I run this code in colab, the colab crash and throw error message:  I also run this code in pycharm, the pycharm exits directly and   Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-17T12:27:55Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62414,", Looks like this is a duplicate of the issue  CC(Forward AD threw error in `tf.autodiff.ForwardAccumulator` for `tf.keras.layers.MaxPooling3D`, but backward AD succeeded with same input). Could you please check and let us know if it is the same? Thank you!","Hi, , I believe these issues involve distinct factors. Specifically, in this issues, the error arises due to setting the strides to 0 in tf.keras.layers.AveragePooling3D. It's my understanding that the strides parameter in this context must be greater than 0; a stride of 0 is not permitted. Conversely, in issue CC(Forward AD threw error in `tf.autodiff.ForwardAccumulator` for `tf.keras.layers.MaxPooling3D`, but backward AD succeeded with same input), the parameters used in tf.keras.layers.MaxPooling3D are all valid.","Hi , Specifically, in this issues, the error arises due to setting the strides to 0 in tf.keras.layers.AveragePooling3D. It's my understanding that the strides parameter in this context must be greater than 0; a stride of 0 is not permitted ====> Yes, you are correct. Strides parameter should be greater than 0. 1. Ensure that the pool_size does not exceed the corresponding dimensions of the input tensor when using ""valid"" padding. 2. Choose strides that allow the pooling window to move appropriately within the input dimensions without exceeding boundaries. 3. Always verify that the combination of pool_size, strides, and padding is compatible with the input tensor's shape to prevent invalid output size calculations. 4. AvgPool3D kernel does not support float64 (tf.float64) on most devices. Use float32 (tf.float32) for input tensors and layers. For more information, could you please refer to this gist file. Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
891,"以下是一个github上的tensorflow下的一个issue, 标题是(Corrupt png files)， 内容是 ( Issue type Support  TensorFlow version 2.14  OS platform and distribution Windows 11  Python version 3.9 I am getting an error: Invalid PNG data, size 49253 Part of my classification process classifying bad images from good ones. All of my png files can be opened, so I think the images are getting corrupt with they are resized. In the graphic below are a few of the ""bad"" images.  !image After importing the images into the training dataset (code below), how I can filter out the images that became corrupt in the resizing? Right now it is throwing an error on when iterating through the normalization_layer   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,gktval,Corrupt png files," Issue type Support  TensorFlow version 2.14  OS platform and distribution Windows 11  Python version 3.9 I am getting an error: Invalid PNG data, size 49253 Part of my classification process classifying bad images from good ones. All of my png files can be opened, so I think the images are getting corrupt with they are resized. In the graphic below are a few of the ""bad"" images.  !image After importing the images into the training dataset (code below), how I can filter out the images that became corrupt in the resizing? Right now it is throwing an error on when iterating through the normalization_layer   Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-15T23:22:30Z,type:support,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62406,"Running through all the images, I found the one causing the problem. For some reason or another it could be opened in other programs, but not in TF. ",Are you satisfied with the resolution of your issue? Yes No
958,"以下是一个github上的tensorflow下的一个issue, 标题是(I can't install tensorflow on termux on android)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version I even don't install it  Custom code Yes  OS platform and distribution Idk  Mobile device Redmi 7A android device with 2gb ram and 32gb storage  Python version I think higher than 3.8 i think 3.11  Bazel version I can provide you later  GCC/compiler version I can provide you later  CUDA/cuDNN version I can provide you later  GPU model and memory I can provide you later  Current behavior? I can install tensorflow or tensorflow lite in terms in android plz help me if you need and information just ask me and i provide you the information plz help me  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Noob225566,I can't install tensorflow on termux on android, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version I even don't install it  Custom code Yes  OS platform and distribution Idk  Mobile device Redmi 7A android device with 2gb ram and 32gb storage  Python version I think higher than 3.8 i think 3.11  Bazel version I can provide you later  GCC/compiler version I can provide you later  CUDA/cuDNN version I can provide you later  GPU model and memory I can provide you later  Current behavior? I can install tensorflow or tensorflow lite in terms in android plz help me if you need and information just ask me and i provide you the information plz help me  Standalone code to reproduce the issue   Relevant log output ,2023-11-15T07:05:17Z,stat:awaiting response comp:lite comp:lite-support,closed,0,29,https://github.com/tensorflow/tensorflow/issues/62404, Could you please let us know if you have installed termux already and updated the packages? Please let us know all the steps you followed which will help us to analyze this issue. Thank you!,you should do it in proot ubuntu/debian,Sorry for me mistake that i type i can install tensorflow instead of i can't install tensorflow,Sorry for these mistakes Issues type is not bug i can't install tensorflow in termux in android,Just,Sorry that i accidentally closed this issue," Please refer to the following steps for installation of TF on termux on android; 1. Launch Termux. 2. Make sure Termux is up to dated: pkg upgrade  3. Install wget and proot: pkg install wget proot  4. Create directory for installing ubuntu: mkdir ubuntu && cd ubuntu  5. Download ubuntu chroot installation script:   6. Now, we can start using Ubuntu by running the script: ./startubuntu.sh   7. Next, we will check and install updates on the Ubuntu image. aptget update && aptget upgrade 8. Install some prerequisites.  9. Install the TensorFlow package: To install the TensorFlow package, use the following command:  Make sure to replace /path/to/built/tensorflow_package.whl with the actual path to the built TensorFlow package. 10. Verify TensorFlow installation: It is important to verify if the installation was successful. To do this, use the following command:  Please have a look at this article as well. Hope it helps? Thank you! ",Thanks but it is a long process i need i small process i just want to make DL models in android i thought i can't use keras without tensorflow and keras is the most important labrairy for me to make DL models can i also use keras on android with tflite instead of tensorflow can you also help me in my one more issue which is i can't install h5py in termux ,If you type my h5py issues in chrome you got my issus plz help me thanks,"Hi ,  Your Query : Can i also use keras on android with tflite instead of tensorflow. Response: As per my knowledge you can convert your keras model to tflite and can run on android.  Your Query:  I can't install tensorflow in termux Response: Please let us understand first, whether you want to install tensorflow or tensorflow lite on android. If you are using  selected ops in your code then you need to install tensorflow build from source(Refer doc ) or else if you have tflite file, install it from build source(Follow doc) according to your android device.  Please, let us know if it helps you. Thank You",Bro my only one question is can i use keras without tensorflow because every command i run using keras in termux i got tensorflow.comapt.v2 as tf no module found why can i fix this issue without installing tensorflow in termux i already installed tflite and theano and pytorch in termux i just wanna to use keras without tensorflow plz help me plz respond me as soon as possible also help me in my another issue that i suggested you plz respond me as soon as possible,", Please look into the issue. Thank You.",What you mean by look into the issus i think no one ever read the issus completely because it is boring and hard to understand a computer issue that's why i only tell you the no module named tensorflow.compat.v2 as tf error and plz if you help me to install tensorflow in my low end android phone i really got satifies with you i have only one way to install tensorflow on android which is cloning the tensorflow library using git clone but it takes too much time and data and storage because tensorflow is a too big Library also i think it some chances of errors and couldn't work properly so plz help me to install tensorflow easily or tell me any other way to use keras without tensorflow plz respond me as soon as possible,"Hi , that previous comment was directed at me :). As I understand it, you want to try to use Keras independent of TensorFlow? because TF is too big for your low end Android device? keras is now available in multiple backends (that is you can switch the backend to either JAX or Pytorch) now: https://keras.io/. However 2 GB of RAM seems too small even for those alternatives. May I ask if you really want to use Keras on the android? Are you using it as an ML development machine? if so you may have better luck starting with colab: https://colab.sandbox.google.com/. Generally speaking you probably shouldn't use a mobile/edge device as a development machine but more as an inference device, which is what TF Lite is specialized for. See if you either of those 2 solutions work better for you. If they don't meet your requirements let us know and we'll see how we can help.","Thanks to answer my question that i can even use keras even without installing tensorflow i have this doubt because an AI bard said me this that i need tensorflow is necessary to use keras or you can't even change its backend as you ask me if i really want to use keras on android the answer is yes i am in a middle class family in india and i am 11 years old i have a vast level of interest in programming,ML,DL and AI that's why i wanna to use keras in my mother's low end device android phone i already know programming and ML i just wanna to create small models like spam filter,image classifier and chatbots some more small or medium DL models in my mother's android phone but i have another doubt as you told me i can change keras backend but i try every possible way to change keras backend using termux (where i installed keras) but i can't do that then i see kerascore that and then which claimed it is a multi backend version of keras but i can't install kerascore in termux in android because h5py is not installed and whenever i run h5py i got a cython compile error which i can't fix can you help me plz respond me as soon as possible plz","Hi , have you tried using keras on colab? https://colab.sandbox.google.com/ . You may want to raise an issue on the keras.io github repo: https://github.com/kerasteam/kerasio, they may be able to better support your issues with changing the backend.","Bro thanks to suggest me to use colab when i run this command from keras.layers import Dense print (""it works"")  It shows it works means there is no module error thanks for this but this is online and i wanna offline because i don't like online things well do you know about a python interpreter which name is ""pydroid 3"" it's my favourite python IDE because it's GUI is very simple,we can run programs in one click and it's offline but tensorflow and pytorch in pydroid 3 are for only premium which i can't afford that's why i decided to use termux but it also have issues i think colab is a good choice but can you tell me any other python IDE like pydroid 3 for Android which is similar like pydroid 3 and offline and supports keras and tensorflow for free plz respond me as soon as possible thanks","Hi , libraries/packages (such as TF or PT) should be independent of IDEs. Termux isn't really an IDE but more of a terminal emulator on android, for IDEs in a low resource environment ... the classics like vi(m) or emacs may be more viable, I think neovim might be the better balance for features but still being low resource. That being said you still need TF working with Termux... what error are you receiving there? or do you already know that TF is too big for your system? If that's the case then IDE won't matter, which is why I recommended Colab as you get resources from Google essentially for free. I understand it may not be the ideal environment for you but I'm trying my best to help you with what you have. Is there something you feel you can't do on colab that you want to do on android/termux?",Thanks for your early response you are right i already setup termux with neovim so i can get a good GUI like pydroid 3 and it works every package or library i install on termux will also works in neovim in termux that's why if i download TF in termux i can use it in neovim in termux but i know TF is too big for my low end android device well as you ask me the error i got so i wanna tell you that whenever i try to run keras in termux or neovim i got this error  (no module found tensorflow.comapt.v2 as tf) this is just a small amount of error if you ask me i can provide you full error also i can't install tensorflow using pip when i try to install TF with pip i got no module found that satisfies the requirement tensorflow that's why but now i think colab is a good choice thanks for your suggestion but the only thing i don't like about is that it is online but i wanna offline things but ok it is also helpful i wish you reply to my this chat as soon as possible now i am going to make my DL model in colab,Can you try on android/termux:  Let me know what errors you get,"When i run these commands in termux in android i got these errors ERROR: Installing pip is forbidden, this will break the pythonpip package (termux). DEPRECATION: Loading egg at /data/data/com.termux/files/usr/lib/python3.11/sitepackages/dm_tree0.1.8py3.11linuxarmv7l.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330 ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none) ERROR: No matching distribution found for tensorflow Also plz tell me i am successfull to download tensorflow from pip does it takes too much storage like even i download tensorflow from pip does it takes 700800mb if yes so i don't wanna download tensorflow on termux plz respond me as soon as possible","Hi , your workflow isn't really well supported. I am fairly sure the package is quite large overall maybe around the size you mention. I think the best thing for you would be to just use colab. It seems pip is having trouble finding a version of TF that works with your hardware. Is there any other message after this:  You can attempt manually installing earlier versions of TF to see if any of them work (ex):  Maybe try until 2.10 and see if any of them work. If not I don't believe we have a version which would work with your system.",Bro i just wanna tensorflow to use keras because i do everything to change keras backend even i installed kerascore (multi backend version of keras) but nothing works and always say me no module named tensorflow.comapt.v2 as tf this is the problem that i wanna to fix i already have theano and pytorch installed but i can't change its backend 😭😭😭 plz help me as soon as possible,Bro plz response me as soon as possible,"Hi , I don't believe TensorFlow is available for your system, please communicate with https://github.com/kerasteam/kerasio to see how you may change the backend. Apologies for not being able to help further. ",Yeah brother i already make a issues in keras repository i got my first respond but didn't work it's ok if you can't help me anymore if you know any interesting knowledge on my issue plz tell me also thanks for your replies and suggestion of colab thanks goodbye,"Hi , if there are no more open items for this issue, can you please close the issue as ""Close as not planned"" if you have no more open items? Thanks.",Ok i will now closing the issus thanks for the help of you thanks,>  Issue type > Bug >  >  Have you reproduced the bug with TensorFlow Nightly? > Yes >  >  Source > source >  >  TensorFlow version > I even don't install it >  >  Custom code > Yes >  >  OS platform and distribution > Idk >  >  Mobile device > Redmi 7A android device with 2gb ram and 32gb storage >  >  Python version > I think higher than 3.8 i think 3.11 >  >  Bazel version > I can provide you later >  >  GCC/compiler version > I can provide you later >  >  CUDA/cuDNN version > I can provide you later >  >  GPU model and memory > I can provide you later >  >  Current behavior? > I can install tensorflow or tensorflow lite in terms in android plz help me if you need and information just ask me and i provide you the information plz help me >  >  Standalone code to reproduce the issue >  >  >  Relevant log output > 
612,"以下是一个github上的tensorflow下的一个issue, 标题是(How to get c++ code coverage when running Python tests?)， 内容是 (It seems connect with these two issues(51091, 46477), but they were all closed by robot. I try    and   The `.dat` files generated are all 0 Bytes.  I want to use `bazel coverage` to calculate the `c++ code coverage`, when a python program runs. I don't know if this is possible. If not, can you provide a suitable way for me to obtain the `c++ code coverage`? My envs: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,BiophiliaSWDA,How to get c++ code coverage when running Python tests?,"It seems connect with these two issues(51091, 46477), but they were all closed by robot. I try    and   The `.dat` files generated are all 0 Bytes.  I want to use `bazel coverage` to calculate the `c++ code coverage`, when a python program runs. I don't know if this is possible. If not, can you provide a suitable way for me to obtain the `c++ code coverage`? My envs: ",2023-11-15T06:38:21Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62403,"Hello, I'm also struggling with this issue. I'm wondering if you've found a solution?","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1727,"以下是一个github上的tensorflow下的一个issue, 标题是(`log_softmax` could be `2**102` to `2**970` times more accurate)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version unknown 2.12.0  Custom code No  OS platform and distribution Linux 5.15.067generic CC(Cannot run the android example on Android 5.1.1)~20.04.1Ubuntu SMP Wed Feb 22 14:52:34 UTC 2023 x86_64 GNU/Linux  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? As I understand it, TensorFlow implements `log_softmax(x)` as `x  max(x)  log(sum(exp(x  max(x))))`. However, when the largest value is much larger than the rest of the values (about 16 larger for float32, about 36 larger for float64), `log_softmax` returns `0` at the maximum value, when it could give a much more precise answer by using `log1p` and zeroing out the maximum cell (guaranteed to be 1) before summing. This came up when a transformer I was training with crossentropy loss on a classification task had loss dominated by float32 error. Might help with https://github.com/tensorflow/tensorflow/issues/48816, https://github.com/tensorflow/tensorflow/issues/12002 I originally posted this as a StackOverflow question. Companion PyTorch issue: https://github.com/pytorch/pytorch/issues/113708 Companion SciPy issue: https://github.com/scipy/scipy/issues/19521  Standalone code to reproduce the issue   gives   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JasonGross,`log_softmax` could be `2**102` to `2**970` times more accurate," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version unknown 2.12.0  Custom code No  OS platform and distribution Linux 5.15.067generic CC(Cannot run the android example on Android 5.1.1)~20.04.1Ubuntu SMP Wed Feb 22 14:52:34 UTC 2023 x86_64 GNU/Linux  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? As I understand it, TensorFlow implements `log_softmax(x)` as `x  max(x)  log(sum(exp(x  max(x))))`. However, when the largest value is much larger than the rest of the values (about 16 larger for float32, about 36 larger for float64), `log_softmax` returns `0` at the maximum value, when it could give a much more precise answer by using `log1p` and zeroing out the maximum cell (guaranteed to be 1) before summing. This came up when a transformer I was training with crossentropy loss on a classification task had loss dominated by float32 error. Might help with https://github.com/tensorflow/tensorflow/issues/48816, https://github.com/tensorflow/tensorflow/issues/12002 I originally posted this as a StackOverflow question. Companion PyTorch issue: https://github.com/pytorch/pytorch/issues/113708 Companion SciPy issue: https://github.com/scipy/scipy/issues/19521  Standalone code to reproduce the issue   gives   Relevant log output _No response_",2023-11-14T23:52:13Z,stat:awaiting tensorflower type:feature comp:apis,open,0,3,https://github.com/tensorflow/tensorflow/issues/62400,  I was able to replicate the issue reported here. Please find the attached gist. Thank you!,"If no one is working on this, I was thinking to work on this and create a Pull Request but I am unable to find the actual implementation of log_softmax function in Tensorflow. Can someone guide me about it?",I am guessing it's https://github.com/tensorflow/tensorflow/blob/c1c9184f35353b48909b1cf633185231b6a59c7c/tensorflow/lite/kernels/internal/reference/integer_ops/log_softmax.hL25L108 and https://github.com/tensorflow/tensorflow/blob/c1c9184f35353b48909b1cf633185231b6a59c7c/tensorflow/compiler/tf2tensorrt/convert/ops/log_softmax.ccL63L83 and https://github.com/tensorflow/tensorflow/blob/c1c9184f35353b48909b1cf633185231b6a59c7c/tensorflow/lite/kernels/internal/optimized/optimized_ops.hL3819L3839 and maybe a bunch of other files returned by https://github.com/search?q=repo%3Atensorflow%2Ftensorflow+logsoftmax+language%3AC%2B%2B&type=code
1028,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow terribly slow on Mac Studio M1 Ultra - problem with tensorflow-metal)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code No  OS platform and distribution Mac OS 13.5.2  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have a Mac Studio M1 Ultra and I am trying to train a simple RNN to forecast time series. When I run the code, tensorflow takes ~140s per epoch or 670ms/step. If I uninstall tensorflowmetal, it takes only 20ms/step. But in this way I won't be able to use the GPU. Why is this happening?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,francescosgarlata,Tensorflow terribly slow on Mac Studio M1 Ultra - problem with tensorflow-metal," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code No  OS platform and distribution Mac OS 13.5.2  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have a Mac Studio M1 Ultra and I am trying to train a simple RNN to forecast time series. When I run the code, tensorflow takes ~140s per epoch or 670ms/step. If I uninstall tensorflowmetal, it takes only 20ms/step. But in this way I won't be able to use the GPU. Why is this happening?  Standalone code to reproduce the issue   Relevant log output ",2023-11-14T19:58:41Z,stat:awaiting response type:build/install stale subtype:macOS type:performance TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62397,"Hi  , I have replicated the issue. This problem observed with new optimizers earlier and now legacy optimizers also seems same problem. Since tensorflowmacos was built and maintained by Apple, could you please report the issue at apple dev forum ? Also since this is keras related you can post this issue at tfkeras repo also to track it by Keras team.  Thanks!","Hi just in case it is helpful, it should be a M1Ultraspecific issue. I cannot reproduce it on M1 Pro."," , tensorflowmetal is not released by Google, we only support official CPU support for M1 when installed through `pip install tensorflow`. Could you please install tensorflow through pip and then install tensorflowmetal and see if that changes the performance. If you notice the difference again, report the issue at https://developer.apple.com/forums/tags/tensorflowmetal/",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"> Thank Hi  and  , we have seen this performance issue with moving to new Optimizer operations in Keras which are implemented  https://github.com/tensorflow/tensorflow/issues/59438issuecomment1411414605"
1026,"以下是一个github上的tensorflow下的一个issue, 标题是(TfLite 2.14 fails to build with Visual Studio with AVX2 compiler flag)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14  Custom code No  OS platform and distribution Windows 10 Enterprise  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version Visual Studio 2019 and 2022  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Building TfLite 2.14 yields the following build error with Visual Studio 2022 (and 2019) when the AVX2 compiler flag is enabled:  This Abseil issue has been solved according to https://github.com/abseil/abseilcpp/issues/1504 Seemingly TfLite 2.14 uses an unpatched version of Abseil.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,misterBart,TfLite 2.14 fails to build with Visual Studio with AVX2 compiler flag, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14  Custom code No  OS platform and distribution Windows 10 Enterprise  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version Visual Studio 2019 and 2022  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Building TfLite 2.14 yields the following build error with Visual Studio 2022 (and 2019) when the AVX2 compiler flag is enabled:  This Abseil issue has been solved according to https://github.com/abseil/abseilcpp/issues/1504 Seemingly TfLite 2.14 uses an unpatched version of Abseil.  Standalone code to reproduce the issue   Relevant log output _No response_,2023-11-14T10:11:08Z,stat:awaiting response type:bug type:build/install subtype:windows TF2.14,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62392,"Hi , I didn't get the error messages with nightly:  seems like abseil is updated after 2.14 release, can you use nightly to progress?","You're right, I do not receive the reported error with the nightly branch.  I am receiving a different error now though, haha: `C:\Users\bartp\source\TfNightlyAttempt2\tensorflow_src\tensorflow/lite/kernels/internal/optimized/fully_connected_4bit.h(21,10): fatal  error C1083: Cannot open include file: 'sys/mman.h': No such file or directory [C:\Users\bartp\source\TfNightlyAttempt2\tflite_x64_release\tensorflowlite.vcxproj]` But that is different issue, so I will close this issue.  Thanks for helping out.",Are you satisfied with the resolution of your issue? Yes No
1866,"以下是一个github上的tensorflow下的一个issue, 标题是(windows build tensorflowlite for android error)， 内容是 (**System information**  TensorFlow Lite version: 2.12  OS: windows11  build tools: bazel 5.3.0  build command: bazel build cxxopt='std=c++11' //tensorflow/lite/java:tensorflowlite crosstool_top=//external:android/crosstool host_crosstool_top=//tools/cpp:toolchain cpu=armeabiv7a  android NDK/SDK has installed **Standalone code to reproduce the issue** when I build tensorflowlite.so for android, I cause a error: WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvmproject/archive/10939d1d580b9d3c9c2f3539c6bdb39f408179c0.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/local_jdk/BUILD.bazel:2:10: in fail_rule rule //:jdk: Traceback (most recent call last):         File ""C:/users/zhulei/_bazel_zhulei/qotdwtts/external/bazel_tools/tools/jdk/fail_rule.bzl"", line 19, column 13, in _fail_rule_impl                 fail(""%s %s"" % (ctx.attr.header, ctx.attr.message)) Error in fail: AutoConfiguration Error: Cannot find Java binary bin/java.exe in C:/users/zhulei/_bazel_zhulei/install/40e9c076fd7053192c88f0d437fc6512/embedded_tools/tools/jdk/nosystemjdk; either correct your JAVA_HOME, PATH or specify Java from remote repository (e.g. java_runtime_version=remotejdk_11 ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/local_jdk/BUILD.bazel:2:10: Analysis of target '//:jdk' failed ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/bazel_tools/tools/jdk/BUILD:29:19: errors encountered resolving toolchains for //tools/jdk:current_java_runtime WARNING: Download from https://golang.org/dl/?mo)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,leizhu1989,windows build tensorflowlite for android error,"**System information**  TensorFlow Lite version: 2.12  OS: windows11  build tools: bazel 5.3.0  build command: bazel build cxxopt='std=c++11' //tensorflow/lite/java:tensorflowlite crosstool_top=//external:android/crosstool host_crosstool_top=//tools/cpp:toolchain cpu=armeabiv7a  android NDK/SDK has installed **Standalone code to reproduce the issue** when I build tensorflowlite.so for android, I cause a error: WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvmproject/archive/10939d1d580b9d3c9c2f3539c6bdb39f408179c0.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/local_jdk/BUILD.bazel:2:10: in fail_rule rule //:jdk: Traceback (most recent call last):         File ""C:/users/zhulei/_bazel_zhulei/qotdwtts/external/bazel_tools/tools/jdk/fail_rule.bzl"", line 19, column 13, in _fail_rule_impl                 fail(""%s %s"" % (ctx.attr.header, ctx.attr.message)) Error in fail: AutoConfiguration Error: Cannot find Java binary bin/java.exe in C:/users/zhulei/_bazel_zhulei/install/40e9c076fd7053192c88f0d437fc6512/embedded_tools/tools/jdk/nosystemjdk; either correct your JAVA_HOME, PATH or specify Java from remote repository (e.g. java_runtime_version=remotejdk_11 ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/local_jdk/BUILD.bazel:2:10: Analysis of target '//:jdk' failed ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/bazel_tools/tools/jdk/BUILD:29:19: errors encountered resolving toolchains for //tools/jdk:current_java_runtime WARNING: Download from https://golang.org/dl/?mo",2023-11-14T03:55:05Z,stat:awaiting response type:support stale comp:lite TF 2.12,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62388, Could you please make sure that the JDK is installed and that it is installed in the location that is specified in the //:jdk target. You can check the location of the JDK by running the following command:  Thank you!," thank you for your reply ! when I add java_runtime_version=remotejdk_11 in build command, it has no that error,but also has a error like: INFO: Found applicable config definition build:short_logs in file d:\project\deeplearning\tensorflow\.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file d:\project\deeplearning\tensorflow\.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:windows in file d:\project\deeplearning\tensorflow\.bazelrc: copt=/W0 host_copt=/W0 copt=/Zc:__cplusplus host_copt=/Zc:__cplusplus copt=/D_USE_MATH_DEFINES host_copt=/D_USE_MATH_DEFINES features=compiler_param_file copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions cxxopt=/std:c++17 host_cxxopt=/std:c++17 config=monolithic copt=DWIN32_LEAN_AND_MEAN host_copt=DWIN32_LEAN_AND_MEAN copt=DNOGDI host_copt=DNOGDI copt=/Zc:preprocessor host_copt=/Zc:preprocessor linkopt=/DEBUG host_linkopt=/DEBUG linkopt=/OPT:REF host_linkopt=/OPT:REF linkopt=/OPT:ICF host_linkopt=/OPT:ICF verbose_failures features=compiler_param_file distinct_host_configuration=false INFO: Found applicable config definition build:monolithic in file d:\project\deeplearning\tensorflow\.bazelrc: define framework_shared_object=false define tsl_protobuf_header_only=false experimental_link_static_libraries_once=false WARNING: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/659147817805d17c7be2d60bd7bbca7e780f9c82.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found INFO: Analyzed target //tensorflow/lite/java:tensorflowlite (0 packages loaded, 0 targets configured). INFO: Found 1 target... ERROR: D:/project/deeplearning/tensorflow/tensorflow/lite/nnapi/BUILD:31:11: Compiling tensorflow/lite/nnapi/nnapi_implementation.: (Exit 1): clang failed: error executing command   cd /d C:/users/zhulei/_bazel_zhulei/qotdwtts/execroot/org_tensorflow   SET ANDROID_BUILD_TOOLS_VERSION=34.0.0     SET ANDROID_NDK_API_LEVEL=26     SET ANDROID_NDK_HOME=D:/project/androidndkr20bwindowsx86_64     SET ANDROID_SDK_API_LEVEL=34     SET ANDROID_SDK_HOME=D:/Android/Sdk     SET PATH=D:\project\install_soft\msys64\usr\bin;D:\project\install_soft\msys64\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\libnvvp;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NetSarang\Xftp 7\;C:\Program Files (x86)\PuTTY\;C:\Users\zhulei\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\ProgramData\Anaconda3;C:\ProgramData\Anaconda3\Library\mingww64\bin;C:\ProgramData\Anaconda3\Library\bin;C:\ProgramData\Anaconda3\Scripts;E:\project\cmake3.20.0rc3windowsx86_64\bin;C:\project\platformtools_r33.0.3windows\platformtools;E:\project\protobuf3.4.0gmock\install\protobuf\bin;C:\Program Files\IDM Computer Solutions\UltraEdit;D:\project\TensorRT8.4.2.4.Windows10.x86_64.cuda11.6.cudnn8.4\lib;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.2.2\;D:\project\Elasticsearch\elasticsearch8.1.2\jdk;D:\project\Elasticsearch\nodev17.9.1winx64;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\NetSarang\Xshell 7\;D:\project\cudnnwindowsx86_648.4.0.27_cuda11.6archive\bin;D:\project\install_soft;D:\project\install_soft\msys64\usr\bin;C:\Users\zhulei\AppData\Local\Microsoft\WindowsApps;;C:\Users\zhulei\AppData\Local\Programs\Microsoft VS Code\bin     SET PWD=/proc/self/cwd     SET PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/python.exe     SET PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/lib/sitepackages     SET RUNFILES_MANIFEST_ONLY=1     SET TF2_BEHAVIOR=1   external\androidndk\ndk\toolchains\llvm\prebuilt\windowsx86_64\bin\clang D__ANDROID_API__=26 isystemexternal/androidndk/ndk/sysroot/usr/include/armlinuxandroideabi target armv7nonelinuxandroideabi march=armv7a mfloatabi=softfp mfpu=vfpv3d16 gcctoolchain external/androidndk/ndk/toolchains/armlinuxandroideabi4.9/prebuilt/windowsx86_64 fpic nocanonicalprefixes Wnoinvalidcommandlineargument Wnounusedcommandlineargument funwindtables fstackprotectorstrong fnoaddrsig Werror=returntype Werror=inttopointercast Werror=pointertointcast Werror=implicitfunctiondeclaration mthumb Os g DNDEBUG MD MF bazelout/armeabiv7aopt/bin/tensorflow/lite/nnapi/_objs/nnapi_implementation/nnapi_implementation.pic.d frandomseed=bazelout/armeabiv7aopt/bin/tensorflow/lite/nnapi/_objs/nnapi_implementation/nnapi_implementation.pic.o fPIC iquote . iquote bazelout/armeabiv7aopt/bin /W0 /Zc:__cplusplus /D_USE_MATH_DEFINES /d2ReducedOptimizeHugeFunctions DWIN32_LEAN_AND_MEAN DNOGDI /Zc:preprocessor /d2ReducedOptimizeHugeFunctions /std:c++17 'std=c++11' sysroot=external/androidndk/ndk/platforms/android26/archarm isystem external/androidndk/ndk/sources/cxxstl/llvmlibc++/include isystem external/androidndk/ndk/sources/cxxstl/llvmlibc++abi/include isystem external/androidndk/ndk/sources/android/support/include isystemexternal/androidndk/ndk/sysroot/usr/include c tensorflow/lite/nnapi/nnapi_implementation./armeabiv7aopt/bin/tensorflow/lite/nnapi/_objs/nnapi_implementation/nnapi_implementation.pic.o  Configuration: 3dcec145ccee737eeff39455689d10f429749c273e882c1f289971a54a4328c4  Execution platform: //:platform clang: error: no such file or directory: '/W0' clang: error: no such file or directory: '/Zc:__cplusplus' clang: error: no such file or directory: '/D_USE_MATH_DEFINES' clang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions' clang: error: no such file or directory: '/Zc:preprocessor' clang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions' clang: error: no such file or directory: '/std:c++17' clang: error: no such file or directory: ''std=c++11'' Target //tensorflow/lite/java:tensorflowlite failed to build INFO: Elapsed time: 0.638s, Critical Path: 0.39s INFO: 21 processes: 21 internal. FAILED: Build did NOT complete successfully build command :bazel build cxxopt='std=c++11' //tensorflow/lite/java:tensorflowlite crosstool_top=//external:android/crosstool host_crosstool_top=//tools/cpp:toolchain cpu=armeabiv7a java_runtime_version=remotejdk_11"," hello, when I change command : bazel build c opt fat_apk_cpu=arm64v8a,armeabiv7a host_crosstool_top=//tools/cpp:toolchain //tensorflow/lite/java:tensorflowlite java_runtime_version=remotejdk_11, the error change to: INFO: Found applicable config definition build:short_logs in file d:\project\deeplearning\tensorflow\.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file d:\project\deeplearning\tensorflow\.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:windows in file d:\project\deeplearning\tensorflow\.bazelrc: copt=/W0 host_copt=/W0 copt=/Zc:__cplusplus host_copt=/Zc:__cplusplus copt=/D_USE_MATH_DEFINES host_copt=/D_USE_MATH_DEFINES features=compiler_param_file copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions cxxopt=/std:c++17 host_cxxopt=/std:c++17 config=monolithic copt=DWIN32_LEAN_AND_MEAN host_copt=DWIN32_LEAN_AND_MEAN copt=DNOGDI host_copt=DNOGDI copt=/Zc:preprocessor host_copt=/Zc:preprocessor linkopt=/DEBUG host_linkopt=/DEBUG linkopt=/OPT:REF host_linkopt=/OPT:REF linkopt=/OPT:ICF host_linkopt=/OPT:ICF verbose_failures features=compiler_param_file distinct_host_configuration=false INFO: Found applicable config definition build:monolithic in file d:\project\deeplearning\tensorflow\.bazelrc: define framework_shared_object=false define tsl_protobuf_header_only=false experimental_link_static_libraries_once=false INFO: Build options cpu and fat_apk_cpu have changed, discarding analysis cache. WARNING: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/659147817805d17c7be2d60bd7bbca7e780f9c82.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found INFO: Analyzed target //tensorflow/lite/java:tensorflowlite (3 packages loaded, 11363 targets configured). INFO: Found 1 target... ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/androidsdk/BUILD.bazel:13:25: Extracting interface //:dx_jar_import failed: missing input file 'external/androidsdk/buildtools/34.0.0/lib/dx.jar', owner: '//:buildtools/34.0.0/lib/dx.jar' ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/androidsdk/BUILD.bazel:13:25: Extracting interface //:dx_jar_import failed: 1 input file(s) do not exist Target //tensorflow/lite/java:tensorflowlite failed to build ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/androidsdk/BUILD.bazel:13:25 Extracting interface //:dx_jar_import failed: 1 input file(s) do not exist INFO: Elapsed time: 7.747s, Critical Path: 6.53s INFO: 205 processes: 183 internal, 22 local. FAILED: Build did NOT complete successfully it sames jdk/android sdk/android ndk version mismatching ,my version:  jdk: java_runtime_version=remotejdk_11 SET ANDROID_BUILD_TOOLS_VERSION=34.0.0     SET ANDROID_NDK_API_LEVEL=26     SET ANDROID_NDK_HOME=D:/project/androidndkr20bwindowsx86_64     SET ANDROID_SDK_API_LEVEL=34     SET ANDROID_SDK_HOME=D:/Android/Sdk is this ok? thank you ","  when I change android sdk ,the same error: bazel build c opt fat_apk_cpu=arm64v8a,armeabiv7a host_crosstool_top=//tools/cpp:toolchain //tensorflow/lite/java:tensorflowlite java_runtime_version=remotejdk_11 INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=151 INFO: Reading rc options for 'build' from d:\project\deeplearning\tensorflow\.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Options provided by the client:   'build' options: python_path=C:/ProgramData/Anaconda3/python.exe INFO: Reading rc options for 'build' from d:\project\deeplearning\tensorflow\.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility INFO: Reading rc options for 'build' from d:\project\deeplearning\tensorflow\.tf_configure.bazelrc:   'build' options: action_env PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/python.exe action_env PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/lib/sitepackages python_path=C:/ProgramData/Anaconda3/python.exe copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions action_env ANDROID_NDK_HOME=D:/project/androidndkr20bwindowsx86_64 action_env ANDROID_NDK_API_LEVEL=26 action_env ANDROID_BUILD_TOOLS_VERSION=31.0.0 action_env ANDROID_SDK_API_LEVEL=31 action_env ANDROID_SDK_HOME=D:/Android/Sdk INFO: Reading rc options for 'build' from d:\project\deeplearning\tensorflow\.bazelrc:   'build' options: deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils INFO: Found applicable config definition build:short_logs in file d:\project\deeplearning\tensorflow\.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file d:\project\deeplearning\tensorflow\.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:windows in file d:\project\deeplearning\tensorflow\.bazelrc: copt=/W0 host_copt=/W0 copt=/Zc:__cplusplus host_copt=/Zc:__cplusplus copt=/D_USE_MATH_DEFINES host_copt=/D_USE_MATH_DEFINES features=compiler_param_file copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions cxxopt=/std:c++17 host_cxxopt=/std:c++17 config=monolithic copt=DWIN32_LEAN_AND_MEAN host_copt=DWIN32_LEAN_AND_MEAN copt=DNOGDI host_copt=DNOGDI copt=/Zc:preprocessor host_copt=/Zc:preprocessor linkopt=/DEBUG host_linkopt=/DEBUG linkopt=/OPT:REF host_linkopt=/OPT:REF linkopt=/OPT:ICF host_linkopt=/OPT:ICF verbose_failures features=compiler_param_file distinct_host_configuration=false INFO: Found applicable config definition build:monolithic in file d:\project\deeplearning\tensorflow\.bazelrc: define framework_shared_object=false define tsl_protobuf_header_only=false experimental_link_static_libraries_once=false INFO: Analyzed target //tensorflow/lite/java:tensorflowlite (0 packages loaded, 0 targets configured). INFO: Found 1 target... ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/ruy/ruy/BUILD:506:11: Compiling ruy/apply_multiplier.: (Exit 1): clang failed: error executing command   cd /d C:/users/zhulei/_bazel_zhulei/qotdwtts/execroot/org_tensorflow   SET ANDROID_BUILD_TOOLS_VERSION=31.0.0     SET ANDROID_NDK_API_LEVEL=26     SET ANDROID_NDK_HOME=D:/project/androidndkr20bwindowsx86_64     SET ANDROID_SDK_API_LEVEL=31     SET ANDROID_SDK_HOME=D:/Android/Sdk     SET PATH=D:\project\install_soft\msys64\usr\bin;D:\project\install_soft\msys64\bin;C:\WINDOWS;C:\WINDOWS\System32;C:\WINDOWS\System32\WindowsPowerShell\v1.0;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.4\libnvvp;C:\Program Files (x86)\VMware\VMware Workstation\bin\;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.3\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\windows\system32;C:\windows;C:\windows\System32\Wbem;C:\windows\System32\WindowsPowerShell\v1.0\;C:\windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NetSarang\Xftp 7\;C:\Program Files (x86)\PuTTY\;C:\Users\zhulei\.dnx\bin;C:\Program Files\Microsoft DNX\Dnvm\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Git\cmd;C:\ProgramData\Anaconda3;C:\ProgramData\Anaconda3\Library\mingww64\bin;C:\ProgramData\Anaconda3\Library\bin;C:\ProgramData\Anaconda3\Scripts;E:\project\cmake3.20.0rc3windowsx86_64\bin;C:\project\platformtools_r33.0.3windows\platformtools;E:\project\protobuf3.4.0gmock\install\protobuf\bin;C:\Program Files\IDM Computer Solutions\UltraEdit;D:\project\TensorRT8.4.2.4.Windows10.x86_64.cuda11.6.cudnn8.4\lib;C:\Program Files\NVIDIA Corporation\Nsight Compute 2021.2.2\;D:\project\Elasticsearch\elasticsearch8.1.2\jdk;D:\project\Elasticsearch\nodev17.9.1winx64;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files (x86)\NetSarang\Xshell 7\;D:\project\cudnnwindowsx86_648.4.0.27_cuda11.6archive\bin;D:\project\install_soft;D:\project\install_soft\msys64\usr\bin;C:\Users\zhulei\AppData\Local\Microsoft\WindowsApps;;C:\Users\zhulei\AppData\Local\Programs\Microsoft VS Code\bin     SET PWD=/proc/self/cwd     SET PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/python.exe     SET PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/lib/sitepackages     SET RUNFILES_MANIFEST_ONLY=1     SET TF2_BEHAVIOR=1   external\androidndk\ndk\toolchains\llvm\prebuilt\windowsx86_64\bin\clang D__ANDROID_API__=26 isystemexternal/androidndk/ndk/sysroot/usr/include/armlinuxandroideabi target armv7nonelinuxandroideabi march=armv7a mfloatabi=softfp mfpu=vfpv3d16 gcctoolchain external/androidndk/ndk/toolchains/armlinuxandroideabi4.9/prebuilt/windowsx86_64 fpic nocanonicalprefixes Wnoinvalidcommandlineargument Wnounusedcommandlineargument funwindtables fstackprotectorstrong fnoaddrsig Werror=returntype Werror=inttopointercast Werror=pointertointcast Werror=implicitfunctiondeclaration mthumb Os g DNDEBUG MD MF bazelout/androidarmeabiv7aopt/bin/external/ruy/ruy/_objs/apply_multiplier/apply_multiplier.pic.d frandomseed=bazelout/androidarmeabiv7aopt/bin/external/ruy/ruy/_objs/apply_multiplier/apply_multiplier.pic.o fPIC iquote external/ruy iquote bazelout/androidarmeabiv7aopt/bin/external/ruy /W0 /Zc:__cplusplus /D_USE_MATH_DEFINES /d2ReducedOptimizeHugeFunctions DWIN32_LEAN_AND_MEAN DNOGDI /Zc:preprocessor /d2ReducedOptimizeHugeFunctions /std:c++17 mfpu=neon O3 sysroot=external/androidndk/ndk/platforms/android26/archarm isystem external/androidndk/ndk/sources/cxxstl/llvmlibc++/include isystem external/androidndk/ndk/sources/cxxstl/llvmlibc++abi/include isystem external/androidndk/ndk/sources/android/support/include isystemexternal/androidndk/ndk/sysroot/usr/include c external/ruy/ruy/apply_multiplier./androidarmeabiv7aopt/bin/external/ruy/ruy/_objs/apply_multiplier/apply_multiplier.pic.o  Configuration: 9856a2746bfd1bed9df0387b5ffea58adc26b7231a0cfcd0f3bbb96c1e0074f4  Execution platform: //:platform clang: error: no such file or directory: '/W0' clang: error: no such file or directory: '/Zc:__cplusplus' clang: error: no such file or directory: '/D_USE_MATH_DEFINES' clang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions' clang: error: no such file or directory: '/Zc:preprocessor' clang: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions' clang: error: no such file or directory: '/std:c++17' Target //tensorflow/lite/java:tensorflowlite failed to build INFO: Elapsed time: 1.077s, Critical Path: 0.35s INFO: 79 processes: 79 internal. FAILED: Build did NOT complete successfully is this error because:""ERROR: C:/users/zhulei/_bazel_zhulei/qotdwtts/external/ruy/ruy/BUILD:506:11: Compiling ruy/apply_multiplier.: (Exit 1): clang failed: error executing command   cd /d C:/users/zhulei/_bazel_zhulei/qotdwtts/execroot/org_tensorflow""? but, I can not know how to sovel this problem?","Hi  , please look into the issue. Thank You","Hi , help me understand your goal here... is there any reason you're not following this guide? https://www.tensorflow.org/lite/android/lite_build, if not can you please follow that guide and let me know if it works for you?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1898,"以下是一个github上的tensorflow下的一个issue, 标题是([mlir][tosa] Lowering of tfl.resize_nearest_neighbor produces off-by-one error)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Debian 11  Mobile device _No response_  Python version 3.9.2  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Certain configurations of `tfl.resize_nearest_neighbor` produce an offbyone error when upsampling the input tensor when using the TFL>TOSA backend. This causes the resulting image to be shifted by one pixel.  Standalone code to reproduce the issue python import numpy as np import tensorflow as tf data = np.zeros([1, 4, 5, 3]) for i in range(4):     data[:,i,:,:] = i expected = tf.compat.v1.image.resize_nearest_neighbor(     data, [8, 10],     half_pixel_centers=True,     align_corners=False) print(expected) text tfl.resize_nearest_neighbor         tf.compat.v1.image.resize_nearest_neighbor [[[[0,     0,     0],               [[[[0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0]],                 [0. 0. 0.]]   [[1,     1,     1],                 [[0. 0. 0.]    [1,     1,     1],                  [0. 0. 0.]    [1,     1,     1],                  [0. 0. 0.]    [1,     1,     1],    )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sabauma,[mlir][tosa] Lowering of tfl.resize_nearest_neighbor produces off-by-one error," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Debian 11  Mobile device _No response_  Python version 3.9.2  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Certain configurations of `tfl.resize_nearest_neighbor` produce an offbyone error when upsampling the input tensor when using the TFL>TOSA backend. This causes the resulting image to be shifted by one pixel.  Standalone code to reproduce the issue python import numpy as np import tensorflow as tf data = np.zeros([1, 4, 5, 3]) for i in range(4):     data[:,i,:,:] = i expected = tf.compat.v1.image.resize_nearest_neighbor(     data, [8, 10],     half_pixel_centers=True,     align_corners=False) print(expected) text tfl.resize_nearest_neighbor         tf.compat.v1.image.resize_nearest_neighbor [[[[0,     0,     0],               [[[[0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0],                  [0. 0. 0.]    [0,     0,     0]],                 [0. 0. 0.]]   [[1,     1,     1],                 [[0. 0. 0.]    [1,     1,     1],                  [0. 0. 0.]    [1,     1,     1],                  [0. 0. 0.]    [1,     1,     1],    ",2023-11-14T01:40:56Z,stat:awaiting response type:bug stale comp:apis TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62386,"Hello, ! tfl.resize_nearest_neighbor is deprecated and not recommended to be used. Could you please try to use other up sampling operations such as tfl.upsample_bilinear and tfl.upsample_nearest instead. Generally  `tf.image.resize(...method=ResizeMethod.NEAREST_NEIGHBOR...)` is referred for current use in the latest version.  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
754,"以下是一个github上的tensorflow下的一个issue, 标题是(Understand thread_sync_cost and framework_cost calculation in mkl_heuristics.h)， 内容是 (Hi,     I am trying to understand the mkl_heuristcs from tensorflow/core/util/mkl_heuristics.h .In rewrite_thresholds list the const values are given to framework cost and thread_sync_cost as :     {""Conv2D"", 0x41, 0xd40, {0.9349, 22.603}},     {""_FusedConv2D"", 0x41, 0xd40, {0.9349, 22.603}},     {""FusedBatchNormV3"", 0x41, 0xd40, {0.3223, 0.8822}},     {""Sigmoid"", 0x41, 0xd40, {0.0, 0.064736}} Here how these constants are being calculated or taken into consider for rewrite thresholds?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,akote123,Understand thread_sync_cost and framework_cost calculation in mkl_heuristics.h,"Hi,     I am trying to understand the mkl_heuristcs from tensorflow/core/util/mkl_heuristics.h .In rewrite_thresholds list the const values are given to framework cost and thread_sync_cost as :     {""Conv2D"", 0x41, 0xd40, {0.9349, 22.603}},     {""_FusedConv2D"", 0x41, 0xd40, {0.9349, 22.603}},     {""FusedBatchNormV3"", 0x41, 0xd40, {0.3223, 0.8822}},     {""Sigmoid"", 0x41, 0xd40, {0.0, 0.064736}} Here how these constants are being calculated or taken into consider for rewrite thresholds?",2023-11-13T10:48:22Z,stat:awaiting response type:support stale comp:mkl,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62382,"Hi, ! Could you please fill the template which will help us to analyze the issue. Thank you!"," , Iam here going through the latest Tensorflow code base in github , in tensorflow/core/util/mkl_heuristics.h file and trying to understand the heristic concepts . Is there any documentation available on how the constants are taken in to consider in this file. Thanks","Hi  ,          Can you please help me in understanding these concepts , like how the threshold value is been decided for matmul and above case. Thank You","Hi **** , The constants in tensorflow/core/util/mkl_heuristics.h are used to tune the performance of the Intel Math Kernel Library (MKL) when used with TensorFlow. These constants are based on a variety of factors, such as the type of operation being performed, the size of the input and output tensors, and the available hardware resources.  If you have further questions on this issue please feel free to ask. Could you please fill the template which will help us to analyze the issue. Thank you!","Hi  ,     Thank you . Actually this is not a issue or bug .Here I was going through the code and I wanted to understand the how the value is being chosen like is there any formula to get this","Hi **** , This is not a bug or feature request, for any further queries you may open this issue in tf discussion forum as there is a larger community there.  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
663,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Lite: Build installable package fails)， 内容是 ( System information    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 23.10    **GCC/Compiler version (if compiling from source)**: 13.2.0    **CUDA/cuDNN version**: 11.8    **installed dependencies**:      **Exact command to reproduce**:    Describe the problem Building an installable package of tensorflow lite with cmake following the instructions in the documentation fails.  Source code / logs  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jagiella,Tensorflow Lite: Build installable package fails," System information    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 23.10    **GCC/Compiler version (if compiling from source)**: 13.2.0    **CUDA/cuDNN version**: 11.8    **installed dependencies**:      **Exact command to reproduce**:    Describe the problem Building an installable package of tensorflow lite with cmake following the instructions in the documentation fails.  Source code / logs  ",2023-11-13T10:39:12Z,stat:awaiting tensorflower type:build/install comp:lite subtype: ubuntu/linux,closed,2,9,https://github.com/tensorflow/tensorflow/issues/62381,I was able to reproduce this issue in TF 2.14 and nightly.   Could you please look into this? Thanks.,"I am able to replicate on nightly:   , can you please take a look? Thanks.",any news on this issue?,"What is the path in the error message supposed to be anyways? `/usr/local/google/home/xxxxxx/tflite_build/ml_dtypes/ml_dtypes` It does not exist on my machine and I might misinterpret things here, but it seems to be kind of hardcoded assuming that my home directory lies in `/usr/local/google/home/USERNAME` and that the build directory `tflite_build` lies in the root of it. Both not the case.","Hi ,  I had the same issue. I did the following change to fix it. In /home/xxx/dev/tensorflow/tensorflow/lite/tools/cmake/modules/ml_dtypes/CMakeLists.txt: [tensorflow v2.15.0] I replaced:  by  Note that this will put the ml_dtypes includes directly into your /usr/local/include folder. I don't know if that's how it is intended to be used. But anyway, this works for me. sources: https://stackoverflow.com/questions/25676277/cmaketargetincludedirectoriesprintsanerrorwhenitrytoaddthesource https://cmake.org/cmake/help/latest/command/target_include_directories.html https://cmake.org/cmake/help/latest/manual/cmakegeneratorexpressions.7.htmlexportandinstallexpressions",Well that solves the first part of the problem :+1:  But pthreadpool and XNNPACK errors remain: ,"Did you try to build it despite the remaining errors at the configuration step ?  From what I understand, the build system (CMake) will install the missing dependencies alongside Tensorflow, if they were not installed. FYI, I documented the installation process of Tensorflow Lite for my project: https://github.com/bastiensagetat/photohead/blob/main/doc/soft_requirements.md","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/96 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1856,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to build cpu debug on windows)， 内容是 (Hello, I'm trying to build TF 2.6 using the following command bazel output_base=""D:/bazel_output"" build config=dbg //tensorflow/tools/lib_package:libtensorflow  System information    I'm using source code with tag v2.6.0    Windows 10 Enterprise    Trying to build TF 2.6 from source    Python 3.9.18    bazel 3.7.2    VS2019    Exact command to reproduce: bazel build config=dbg //tensorflow/tools/lib_package:libtensorflow I get the following error (attached the full log): ERROR: E:/git/tensorflow/tensorflow/BUILD:984:20: Linking of rule '//tensorflow:tensorflow.dll' failed (Exit 1120): link.exe failed: error executing command   cd D:/bazel_output/execroot/org_tensorflow   SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.29.30133\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.29.30133\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\um\x64     SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.29.30133\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TeamFou)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ksapozhn,Unable to build cpu debug on windows,"Hello, I'm trying to build TF 2.6 using the following command bazel output_base=""D:/bazel_output"" build config=dbg //tensorflow/tools/lib_package:libtensorflow  System information    I'm using source code with tag v2.6.0    Windows 10 Enterprise    Trying to build TF 2.6 from source    Python 3.9.18    bazel 3.7.2    VS2019    Exact command to reproduce: bazel build config=dbg //tensorflow/tools/lib_package:libtensorflow I get the following error (attached the full log): ERROR: E:/git/tensorflow/tensorflow/BUILD:984:20: Linking of rule '//tensorflow:tensorflow.dll' failed (Exit 1120): link.exe failed: error executing command   cd D:/bazel_output/execroot/org_tensorflow   SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.29.30133\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.29.30133\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\um\x64     SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\\Extensions\Microsoft\IntelliCode\CLI;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\VC\Tools\MSVC\14.29.30133\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Professional\Common7\IDE\CommonExtensions\Microsoft\TeamFou",2023-11-13T06:41:22Z,stat:awaiting response type:build/install stale subtype:windows type:performance 2.6.0,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62380,"Hi  , TF2.6v is quiet older and not actively supported. Please test with latest versions. Also please try including  the flags`linkopt=/DEBUG host_linkopt=/DEBUG` for windows build with latest version and let us know the outcome.",Unfortunatly I can't test newer version as I'm working with an embeded device that has TF2.6.," , Please refer to .bazlerc file of Tf2.6v if it helps.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1519,"以下是一个github上的tensorflow下的一个issue, 标题是(Least squares is 50% slower when activating JIT compile)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Activating JIT compile makes tf.linalg.lstsq up to 100% slower.  If we benchmark `tf.linalg.lstsq` on a matrix of shape (2**18, 5), we see considerable slowdown when activating JIT compile. Expectation would be that JIT actually speeds up solving the least squares problem, but seeing the opposite across multiple platforms and setups. JIT version is consistently slower, taking up to twice as much depending on the platform.  Standalone code to reproduce the issue See here: https://colab.research.google.com/drive/1MIBRIYik2ZVpy1eIIalokMQxE2GA2G9DscrollTo=7YrOyhUaZD24 or equivalently:  At this point, just time  vs    Relevant log output In the colab version, see the following: * Running lstsq with no JIT: 6.01 ms ± 401 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) * Running lstsq with JIT: 11.4 ms ± 3.45 ms per loop (mean ± std. dev. of 7 runs, 100 loops each))请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lonidard,Least squares is 50% slower when activating JIT compile," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Activating JIT compile makes tf.linalg.lstsq up to 100% slower.  If we benchmark `tf.linalg.lstsq` on a matrix of shape (2**18, 5), we see considerable slowdown when activating JIT compile. Expectation would be that JIT actually speeds up solving the least squares problem, but seeing the opposite across multiple platforms and setups. JIT version is consistently slower, taking up to twice as much depending on the platform.  Standalone code to reproduce the issue See here: https://colab.research.google.com/drive/1MIBRIYik2ZVpy1eIIalokMQxE2GA2G9DscrollTo=7YrOyhUaZD24 or equivalently:  At this point, just time  vs    Relevant log output In the colab version, see the following: * Running lstsq with no JIT: 6.01 ms ± 401 µs per loop (mean ± std. dev. of 7 runs, 100 loops each) * Running lstsq with JIT: 11.4 ms ± 3.45 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)",2023-11-12T17:01:11Z,stat:awaiting response stale comp:xla type:performance TF2.14,closed,1,10,https://github.com/tensorflow/tensorflow/issues/62378,"Hi **** , I have replicated the reported behavior with jit_compile=True with 2.14,2.13 and tfnightly. Here I attached a gist1, gist2 for your reference. Thank you!",Are you satisfied with the resolution of your issue? Yes No,"Thank you Venkat! If there's anything I can do to assist in its resolution, please let me know.","Hi  , I have checked the code with Tf2.14v and Tf2.15v and also increased the no of runs and I found in Tf2.15v this API indeed performs better with `jit_compile`. Please find the attached gist for reference.  From the above logs TF2.15v don't have this issue.Thanks!","Hi , Doesn’t this mean that TF2.15 slowed down the nonjit version without impacting the JIT compiled one, rather than fixing the bug? For a proper resolution, I’d expect the JIT compiled version to perform better than the nojit in 2.14.",Are there any updates?,"Hi  , XLA performance depends upon the no of fusions,optimizations for an Op. Accelerators like GPUs make it even faster.Please refer to attached gpugist. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1316,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow compiler error in bazel)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf2.12.0  Custom code No  OS platform and distribution MacOS12.6  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/compiler version clang14 llvm14  CUDA/cuDNN version no  GPU model and memory no  Current behavior?  I use `python3 configure.py`, and `bazel build //tensorflow/tools/pip_package:build_pip_package` atfer. I get an error :  All logs is here:  After searching I found ISSUE At the end of this issue, the author also mentioned this problem, but did not fix yet. Sorry to interrupt. I want to use `bazel coverage` to get the `c++` operator coverage of my network after compiling `tensorflow2.12.0` with `bazel`. I don't know if this is ok, maybe you can give me some advice on this point? I would really appreciate it. Or, you can give me the algorithm to get the `c++ operators`, because AFAIK, pytorch provides code_coverage to get the coverage of c++ operators  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,BiophiliaSWDA,Tensorflow compiler error in bazel," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf2.12.0  Custom code No  OS platform and distribution MacOS12.6  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/compiler version clang14 llvm14  CUDA/cuDNN version no  GPU model and memory no  Current behavior?  I use `python3 configure.py`, and `bazel build //tensorflow/tools/pip_package:build_pip_package` atfer. I get an error :  All logs is here:  After searching I found ISSUE At the end of this issue, the author also mentioned this problem, but did not fix yet. Sorry to interrupt. I want to use `bazel coverage` to get the `c++` operator coverage of my network after compiling `tensorflow2.12.0` with `bazel`. I don't know if this is ok, maybe you can give me some advice on this point? I would really appreciate it. Or, you can give me the algorithm to get the `c++ operators`, because AFAIK, pytorch provides code_coverage to get the coverage of c++ operators  Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-11T10:32:53Z,stat:awaiting response type:build/install stale subtype:macOS TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62374,"Hi  , This seems to be issue related to linker ids on Macos. Please have a look into the bazel repo issues 1, 2 and let us know if this is of help.","> Hi  , >  > This seems to be issue related to linker ids on Macos. Please have a look into the bazel repo issues 1, 2 and let us know if this is of help. Thanks for the reply, I have finished compiling on ubuntu. But I didn't find a way to calculate the `c++ code coverage`. For example, I now have a tensorflow network written in python, can I use `bazel coverage` to get the `c++ code coverage`.","Hi  , Could you please refer this documentation on TF tests is of any help. I find out similar issue CC(How to collect code coverage of C++ code when running Python tests?) where author tried same but couldn't succeed in older TF versions. Could you try and let us know the outcome with latest versions? Also all tests coverage shall be available on tensorflow/tensorflow.bazel.  Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
655,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Profiler did not work correctly.)， 内容是 (I used the TensorFlow profiler to measure largescale DL models' CPU/GPU performance. However, this tool did not work correctly. I did not see a graph for the results of measurement using TensorBoard. Hence, I tried a tutorial of this, and this problem occurred again. I think the current version of the TensorFlow profiler does not save all of the files for measurement results. The following image shows the current status. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,y-vectorfield,TensorFlow Profiler did not work correctly.,"I used the TensorFlow profiler to measure largescale DL models' CPU/GPU performance. However, this tool did not work correctly. I did not see a graph for the results of measurement using TensorBoard. Hence, I tried a tutorial of this, and this problem occurred again. I think the current version of the TensorFlow profiler does not save all of the files for measurement results. The following image shows the current status. ",2023-11-11T04:49:16Z,comp:tensorboard stat:awaiting response stat:awaiting tensorflower type:bug stale comp:apis TF2.14,closed,0,52,https://github.com/tensorflow/tensorflow/issues/62373,  Do you think this issue is a bug in the TensorFlow Profiler? Please let me know your opinion.,"vectorfield, I tried to execute the given tutorial and it was executed without any issue/error. Kindly find the gist of it here and the screenshot for the reference. !image Thank you!","Same problem for me. My local setup with TF2.14 produces the same problem ""No profile data was found."" If I execute the official notebook https://colab.research.google.com/github/tensorflow/tensorboard/blob/master/docs/tensorboard_profiling_keras.ipynb then I encounter the same problem.  What you show in the screenshot is not the profiler ! ","Hello,    and I could implement TensorBoard. However, we could not watch the result of the TensorFlow Profiler using TensorBoard. I think this is a problem of the TensorFlow Profiler.  ,  , what do you think about this problem? Please let us know your opinions. We could not confirm the following content. >The **Profile** tab opens the Overview page which shows you a highlevel summary of your model performance. Looking at the Steptime Graph on the right, you can see that the model is highly input bound (i.e., it spends a lot of time >in the data input piepline). The Overview page also gives you recommendations on potential next steps you can follow to optimize your model performance. ","Hello  ,       I wanted to use tensorboard for inference,  tf.profiler.experimental.start('logs') output = model.predict(encoded_input, verbose=False)[0] tf.profiler.experimental.stop() I have tried this way . But When the profiler tab opened its saying no profile data. May I know how we can get profile data for model inference"," ,  , What do you think about the above problem? The TensorFlow Profiler(v2) did not work correctly and did not watch the measurement results.","So I could resolve the problem. The solution for me was to manually copy and paste this file https://github.com/tensorflow/profiler/blob/master/demo/events.out.tfevents.1583461681.localhost.profileempty into the Tensorboard log directory of my experiment, then suddenly Tensorboard and the profilerplugin load the results of the Tensorflow profiler.  "," ,        Did you try for inference as well?","  Thank you very much for your report. > The solution for me was to manually copy and paste this file I think the profiler should create this event file automatically, not manually.","Hello,  , What do you think about this issue?? I think this profiler should create an event file(event.out.tfevents.xxx.xxxx.profileempty) automatically. However, the latest version of this does not create it.","Hi, Thanks for reporting the issue, I have reported the issue to the concerned team, I was able to find similar issues which is reported here https://github.com/tensorflow/tensorflow/issues/61212","Hello,   I confirmed CC(Tensorflow profiler is not showing anything. Gives ""No profile data was found"" text on selecting Profile in Tensorboard). This is a similar issue of this.","Hi yvectorfield, for the ""No data Found"" issue, could you please share   the screenshot of your log directory after collecting the profile so we can check on the profile data.  How you collect the profile (if possible, the code structure) Thanks! And the profile inactive issue should be fixed soon with a new change.","Hello, , thank you very much for your message.  and I tried to measure the inference performance using this. The example of measurement code is as follows.  If we implement the above code, we get the following directory structure.  We can not get some files of measurement results. Hence, we can not watch the measurement results using TensorBoard. ","Hi  ,     We also tried with  tf.profiler.experimental.start('logs') output = model.predict(encoded_input, verbose=False)[0] when I do tensorboard logdir=logs I get profile page as attached . "," , thank you very much for your info sharing.","Thanks vectorfield  for the detailed description! And  could you also share the directory structure like what yvectorfield mentioned above? This could be very helpful for us to debug the issue as the directory structure and files inside will potentially determine if tensorboard can identify valid profiler runs data there, Thank you!",", thank you for your message. Can I help you to fix this issue? I also try to investigate the root cause of this!"," , Thank you. The directory structure looks like:  This how the directory structure looks like. Thank You",", thank you very much for your sharing."," , Do you have any example inference code where tensorboard shows the profile data?  Can you please share any working example for model inference tensorboard code, so that it will be helpful for us to understand whether we are doing any mistake while using profiler API. Thanks",I used the following code to investigate the root cause of this issue. Reference: Extract features with VGG16 ,"I got the following results. I used each version of TF official container image from Docker Hub. https://hub.docker.com/r/tensorflow/tensorflow/tags?page=1  The result eventfile: ○, profiler results: ○ means the following dir structure.  The result eventfile: ○, profiler results: ✕ means the following dir structure.  The result eventfile: ✕, profiler results: ✕ means the following dir structure. ","thanks vectorfield  for the detailed debugging and that's really helpful! for the 3 types of directory structure you showed, the 1 and 2 should both work (2 is intended change), meaning until 2.11 it should be working fine. We've identified some suspicious code snippet and has been working on a fix for this, will update you ASAP.  ",">  , Do you have any example inference code where tensorboard shows the profile data? Can you please share any working example for model inference tensorboard code, so that it will be helpful for us to understand whether we are doing any mistake while using profiler API. >  > Thanks  I'm not an expert in performance tuning, but from what I know, you are not doing anything wrong, and this should be a known issue on our side. However want to double check, as you mentioned  > We also tried with > tf.profiler.experimental.start('logs') > output = model.predict(encoded_input, verbose=False)[0] > when I do tensorboard logdir=logs > I get profile page as attached . does the above code create the directory of following but you can see the data in the profiler? and this is all the files within /logs dir? ","Hello, , ,  I think we should attach the bug label to this issue and remove the support label. What do you think of my opinion?",", thank you very much for your advice. >  the 1 and 2 should both work (2 is intended change), meaning until 2.11 it should be working fine.  OK, I will check this using TensorBoard. By the way, I would like to contribute to solving this problem. I will investigate the source codes deeply and submit some modification codes(Pull Request) as soon as possible. OK?",", thank you!","> >  , Do you have any example inference code where tensorboard shows the profile data? Can you please share any working example for model inference tensorboard code, so that it will be helpful for us to understand whether we are doing any mistake while using profiler API. > > Thanks >  >  I'm not an expert in performance tuning, but from what I know, you are not doing anything wrong, and this should be a known issue on our side. >  > However want to double check, as you mentioned >  > > We also tried with > > tf.profiler.experimental.start('logs') > > output = model.predict(encoded_input, verbose=False)[0] > > when I do tensorboard logdir=logs > > I get profile page as attached . >  > does the above code create the directory of following but you can see the data in the profiler? and this is all the files within /logs dir? >  >   ,these are the  files created and in the profiler its not showing any data.","Im expperimenting the same issue I tryed the solution provided by  but this still doesn't work for me > So I could resolve the problem. The solution for me was to manually copy and paste this file https://github.com/tensorflow/profiler/blob/master/demo/events.out.tfevents.1583461681.localhost.profileempty >  > into the Tensorboard log directory of my experiment, then suddenly Tensorboard and the profilerplugin load the results of the Tensorflow profiler."
1063,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation Fault when using Coral Edge Tpu)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Raspberry Pi Os Bookworm  Mobile device _No response_  Python version 3.11.2  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The program crashes as soon as it tries to load the edge tpu model. I already asked in the YoloV8 discord and they told me to open a issue here from looking at the stacktrace. The hardware is a raspberry pi 5 with 8Gb of ram but the same issue also happens on a raspberry pi 4B with 2Gb of ram  Standalone code to reproduce the issue   Relevant log output Crash when running through gdb to get the stacktrace:  Stacktrace made using gdb: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,Skillnoob,Segmentation Fault when using Coral Edge Tpu, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Raspberry Pi Os Bookworm  Mobile device _No response_  Python version 3.11.2  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The program crashes as soon as it tries to load the edge tpu model. I already asked in the YoloV8 discord and they told me to open a issue here from looking at the stacktrace. The hardware is a raspberry pi 5 with 8Gb of ram but the same issue also happens on a raspberry pi 4B with 2Gb of ram  Standalone code to reproduce the issue   Relevant log output Crash when running through gdb to get the stacktrace:  Stacktrace made using gdb: ,2023-11-10T22:11:05Z,stat:awaiting response type:bug comp:lite TF2.14,closed,0,31,https://github.com/tensorflow/tensorflow/issues/62371, Could you please make sure that you are using the correct TensorFlow Lite model and interpreter for your Edge TPU device? The Edge TPU hardware and firmware needs to be up to date to avoid such issues. Thank you!, The model has been converted to tflite with int8 and compiled using the latest version of the edgetpu compiler. The edgetpu runtime is also on the latest version. The ultralytics module uses the tflite interpreter from the tensorflow module iirc.," , Could you please provide  the model_edgetpu.tflite file to better understand the issue and to investigate further? Thank You", https://drive.google.com/file/d/1Vua1ujK07FXpMdM34uFltA0AchEvC0lH/view?usp=sharing,", I have verified the Tflite file given. It seems that your model is using custom ops. Please find the  gist. Could you please check these instructions(documentation) for custom ops and let us know if they have been followed? Thank You", the error you got inside the notebook is to be expected as the model relies on the delegate from the coral usb acceleratorinstalltheedgetpuruntime),"Hi  , Please look into the issue. Thank you","Hi , it seems like there is a dependency on some installation instructions from Coral? Can you let us know the Coral instructions you followed prior to receiving this error? Also please note that the website explicitly states:  As a requirement. Apparently you are using: 3.11.2, you might want to try using python=3.9 and see if it resolves your issue. Thanks for your help.", Hi. I've tried the same program previously on a raspberry pi 4B with python 3.9.2 and had the same crash but couldn't run it through gdb as the pi would just freeze. I also tried it on the pi 5 using a anaconda virtual env with python 3.9.18 and the same crash occured.,"Hi , that settles the version issue but can you also please let us know the coral installation steps you followed?", i followed the installation instructions exactly as written on the installation page,"need a coral to reproduce, Hi , can you please take a look? Thanks.",Recently tried to run this using tensorflowaarch64 2.13.1 and 2.15.0 and the crash still occurs,easier way of reproducing the issue:  Install the edge tpu runtime as explained hereinstalltheedgetpuruntime) ,also tried this with every tensorflow version going from the current latest to 2.12.1 on a raspberry pi 4B with python 3.9.2,This is now resolved due to https://github.com/feranick updating the libedgetpu runtime to support newer tflite_runtime versions in https://github.com/googlecoral/edgetpu/issues/812 .,Are you satisfied with the resolution of your issue? Yes No,"I would still keep this issue open. While there is a solution from my forked repository, Google should update the main one, and until then the issue is not solved. ", i agree. But it seems that google has completly abandoned the coral project.,Hi  I don't work with that repo but can you perhaps link your PR that fixes the issue? Maybe I can help push it from here. Edit: nevermind.. found it. I think this is it? https://github.com/googlecoral/libedgetpu/pull/59, thats the correct pr,New builds are finally available against Tensorflow `v2.15.0` (current). I had to refactor the WORKSPACE to conform to the deprecation of the TF/Toolchain. All seem to be working for me (including on `armhf` where it only worked with `tflite_runtime v2.13.1`).  I plan to do a new PR soon. https://github.com/feranick/libedgetpu/releases/tag/v16.0TF2.15.01,"> Hi  I don't work with that repo but can you perhaps link your PR that fixes the issue? Maybe I can help push it from here. >  > Edit: nevermind.. found it. I think this is it? googlecoral/libedgetpu CC(Error in final step of installation) Thanks. That is the PR, but I plan to make a new one based on the last few commits hat bring support to TensorFlow 2.15.0. I'll post here.","BTW, in case someone needs updated `tflite_runtime` wheels, I prepared a few here. https://github.com/feranick/TFlitebuilds/releases/tag/v2.15.0"," Thanks a lot! Finally after a long journey in the rabbit hole, **this** is the only solution to get working with 3.11 currently",> Hi  I don't work with that repo but can you perhaps link your PR that fixes the issue? Maybe I can help push it from here. >  > Edit: nevermind.. found it. I think this is it? googlecoral/libedgetpu CC(Error in final step of installation) pkgoogle Just wondering whether you had a chance to move this forward. The correct and current PR is this: https://github.com/googlecoral/libedgetpu/pull/60,"Thanks very much to  and  at Google for merging PR. The libedgetpu library is now fully updated, and I hope binaries will be made available soon through the official channel.","Hi , as  mentioned, the libedgetpu library is now updated. Can you test your case against master and see if it resolves your issue?", I have already tested with  's builds a while ago and they work without any issues on my rpi 5 with python 3.11,", awesome, if you are confident this issue is resolved and you have no more open items, please feel free to close this issue as completed. Thanks."
1940,"以下是一个github上的tensorflow下的一个issue, 标题是([TF 2.14][aarch64]Memory footprint increased by almost 2.5x for inference (eg: I've tested MLPerf Resnet50 offline mode))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version TF2.14  Custom code No  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? on a machine with around 32GB memory (for example, AWS c7g.4xl), mlperf Resnet50 offline inference fails with OutOfMemory on TF 2.14 and nightly wheels. The same benchmark works fine on TF 2.13. I've rootcaused the issue to the following commit that introduced inter op scheduler to improve performance for models with parallel ops. While this is improving the perf by 15% for MLPerf Resnet50 batch mode on r7g.16xl, it is increasing the memory footprint by 2.5x (from 25GB to 67GB). ~~~ commit d0cb12441747ef9fb14137cb99f0b6a17e22b5e4 Author: David Svantesson  Date:   Tue Jul 25 09:33:40 2023 0700     PR CC(Add inter scheduler support on AArch64): Add inter scheduler support on AArch64     Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/61235     This PR adds support for inter op scheduler in the oneDNN + ACL build. It enables the creation of more than 1 scheduler inside ACL to increase performance of models with parallel ops.     For benchmarked NLP models the average performance increase is 9%, for CV classification models its around 2%.     The below benchmarks were done with the following PR’s applied as patches: CC(Reduce MKL overheads on small shapes by not rewriting node to use MKL), CC(Improving the perf)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,snadampal,[TF 2.14][aarch64]Memory footprint increased by almost 2.5x for inference (eg: I've tested MLPerf Resnet50 offline mode)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version TF2.14  Custom code No  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? on a machine with around 32GB memory (for example, AWS c7g.4xl), mlperf Resnet50 offline inference fails with OutOfMemory on TF 2.14 and nightly wheels. The same benchmark works fine on TF 2.13. I've rootcaused the issue to the following commit that introduced inter op scheduler to improve performance for models with parallel ops. While this is improving the perf by 15% for MLPerf Resnet50 batch mode on r7g.16xl, it is increasing the memory footprint by 2.5x (from 25GB to 67GB). ~~~ commit d0cb12441747ef9fb14137cb99f0b6a17e22b5e4 Author: David Svantesson  Date:   Tue Jul 25 09:33:40 2023 0700     PR CC(Add inter scheduler support on AArch64): Add inter scheduler support on AArch64     Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/61235     This PR adds support for inter op scheduler in the oneDNN + ACL build. It enables the creation of more than 1 scheduler inside ACL to increase performance of models with parallel ops.     For benchmarked NLP models the average performance increase is 9%, for CV classification models its around 2%.     The below benchmarks were done with the following PR’s applied as patches: CC(Reduce MKL overheads on small shapes by not rewriting node to use MKL), CC(Improving the perf",2023-11-10T18:55:51Z,stat:awaiting response stat:awaiting tensorflower type:bug stale type:performance TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62367,"  AWS c7g is ARMbased CPU, so it might not use oneDNN (TensorFlowMKL)","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1899,"以下是一个github上的tensorflow下的一个issue, 标题是(Can't load model with tf v2.14 if the model was saved with previous tf versions)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.14  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to load a Keras model that was saved using tf version  File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_api.py"", line 254, in load_model     return saving_lib.load_model(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 281, in load_model     raise e   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 269, in load_model     _load_state(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 466, in _load_state     _load_container_state(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 534, in _load_container_state     _load_state(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 435, in _load_state     trackable.load_own_variables(weights_store.get(inner_path))   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/engine/base_layer.py"", line 3531, in load_own_variables     raise V)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ofirgo,Can't load model with tf v2.14 if the model was saved with previous tf versions," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.14  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to load a Keras model that was saved using tf version  File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_api.py"", line 254, in load_model     return saving_lib.load_model(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 281, in load_model     raise e   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 269, in load_model     _load_state(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 466, in _load_state     _load_container_state(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 534, in _load_container_state     _load_state(   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/saving/saving_lib.py"", line 435, in _load_state     trackable.load_own_variables(weights_store.get(inner_path))   File ""/data/projects/swat/envs/eladc/mct_tf_python310/lib/python3.10/sitepackages/keras/src/engine/base_layer.py"", line 3531, in load_own_variables     raise V",2023-11-09T10:16:47Z,stat:awaiting response type:support stale comp:model TF2.14,closed,1,8,https://github.com/tensorflow/tensorflow/issues/62363,"Hi ****, Could you please check with the latest stable version. I checked with versions Tf=2.13, 2.14 and tfnightly too. It is working fine for me for both the models. It is recommended to save and load the models in the same TF version which will not conflict in the outcome. I attached a gist for your reference. Thank you!","Hi ,  Thank you for your response. Saving and loading with the same TF version works fine for me (in all 3 aforementioned versions). My issue is when trying to load with TF 2.14 a model that was originally saved in TF 2.13 (I have a large database of saved models that I wish to not be needing to recreate when upgrading a TF version). Is there a way to solve this issue to preserve backward compatibility?","Have you tried ""fitting"" this model instead of loading previous weights? I ask this because I get input_shape errors on fit() even though they are correctly specified in a keras.layer. I can ""build"" the model and display its summary(). However, when I use fit(), whether designed through subclassing or functional API, the model seems to _forget_ that I specified input_shape. I don't get this issue when I downgrade TF to v2.12.0 (i.e. the last time I ran it). I wonder if this is related??? Of note, I've been running this in Colab, if that's of any importance.","Hi  , The issue addressed in Keras 18830 already. Could you please close the issue if resolved.If not please track it at keras repo itself. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,You should pip install previous version . I solved this error by installing previous version.
870,"以下是一个github上的tensorflow下的一个issue, 标题是(Discrepancy in training accuracy for CNN on MNIST dataset between Apple Silicon and colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution macOS 14.1  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Running a simple example training a CNN using MNIST dataset usnig tensorflow, the training accuracy/loss yield very different results.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,N33MO,Discrepancy in training accuracy for CNN on MNIST dataset between Apple Silicon and colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution macOS 14.1  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Running a simple example training a CNN using MNIST dataset usnig tensorflow, the training accuracy/loss yield very different results.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-09T02:46:34Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:keras TF 2.13,closed,0,17,https://github.com/tensorflow/tensorflow/issues/62361,colab training output: ,mac training output: ,", Thank you for reporting the issue. We are currently investigating the issue, and I kindly request some time to thoroughly analyze the problem in order to offer a resolution and also could you please confirm is this happening in tf v2.14 as well? Thank you!","Hi , The issue still show on v2.14: https://colab.research.google.com/drive/1bQe1F4PO2GkaLWvDQcnqzLMsddoUux9 Here's the package installed on the Mac machine. ","  Seems like the issue is happening when using the Apple Silicon GPU as I get nearly identical results as colab on my M1 Max if I hide the GPU using the below code(tf v2.14): `hw = tf.config.get_visible_devices()` `tf.config.set_visible_devices(hw[0])` Mac output: > [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`. Epoch 1/20 938/938 [==============================]  1s 824us/step  loss: 0.3648  accuracy: 0.8979  val_loss: 0.2319  val_accuracy: 0.9322 Epoch 2/20 938/938 [==============================]  1s 745us/step  loss: 0.1963  accuracy: 0.9443  val_loss: 0.1677  val_accuracy: 0.9510 Epoch 3/20 938/938 [==============================]  1s 743us/step  loss: 0.1471  accuracy: 0.9583  val_loss: 0.1313  val_accuracy: 0.9605 Epoch 4/20 938/938 [==============================]  1s 736us/step  loss: 0.1187  accuracy: 0.9662  val_loss: 0.1142  val_accuracy: 0.9647 Epoch 5/20 938/938 [==============================]  1s 752us/step  loss: 0.0998  accuracy: 0.9719  val_loss: 0.1045  val_accuracy: 0.9673 Epoch 6/20 938/938 [==============================]  1s 744us/step  loss: 0.0866  accuracy: 0.9757  val_loss: 0.0937  val_accuracy: 0.9708 Epoch 7/20 938/938 [==============================]  1s 743us/step  loss: 0.0766  accuracy: 0.9787  val_loss: 0.0872  val_accuracy: 0.9733 Epoch 8/20 938/938 [==============================]  1s 745us/step  loss: 0.0685  accuracy: 0.9812  val_loss: 0.0835  val_accuracy: 0.9746 Epoch 9/20 938/938 [==============================]  1s 731us/step  loss: 0.0617  accuracy: 0.9831  val_loss: 0.0809  val_accuracy: 0.9750 Epoch 10/20 938/938 [==============================]  1s 737us/step  loss: 0.0561  accuracy: 0.9845  val_loss: 0.0788  val_accuracy: 0.9750 Epoch 11/20 938/938 [==============================]  1s 732us/step  loss: 0.0510  accuracy: 0.9860  val_loss: 0.0755  val_accuracy: 0.9763 Epoch 12/20 938/938 [==============================]  1s 752us/step  loss: 0.0467  accuracy: 0.9872  val_loss: 0.0766  val_accuracy: 0.9763 Epoch 13/20 938/938 [==============================]  1s 741us/step  loss: 0.0426  accuracy: 0.9886  val_loss: 0.0762  val_accuracy: 0.9761 Epoch 14/20 938/938 [==============================]  1s 745us/step  loss: 0.0395  accuracy: 0.9894  val_loss: 0.0727  val_accuracy: 0.9761 Epoch 15/20 938/938 [==============================]  1s 745us/step  loss: 0.0360  accuracy: 0.9906  val_loss: 0.0707  val_accuracy: 0.9779 Epoch 16/20 938/938 [==============================]  1s 745us/step  loss: 0.0334  accuracy: 0.9913  val_loss: 0.0707  val_accuracy: 0.9773 Epoch 17/20 938/938 [==============================]  1s 740us/step  loss: 0.0310  accuracy: 0.9921  val_loss: 0.0700  val_accuracy: 0.9773 Epoch 18/20 938/938 [==============================]  1s 747us/step  loss: 0.0286  accuracy: 0.9933  val_loss: 0.0698  val_accuracy: 0.9769 Epoch 19/20 938/938 [==============================]  1s 742us/step  loss: 0.0265  accuracy: 0.9937  val_loss: 0.0690  val_accuracy: 0.9783 Epoch 20/20 938/938 [==============================]  1s 754us/step  loss: 0.0246  accuracy: 0.9942  val_loss: 0.0674  val_accuracy: 0.9792",I'm encountering not exactly the same but I think related issue.  I use MacBook Air with M2. Running the same code on CPU and on GPU (with `tensorflowmetal`) gives different results. On GPU it causes to model training fail.  Please see all the details in related issue.," I tested the code on v2.15 as well, the issue still exists and is not resolved as mentioned here.   Regarding the running time of CPU vs GPU, in order to take advantage of GPU you should have sufficient load. For basic learning CPU is faster.","I have reproduced the same issue with tf2.15 as well using M2 MacBook Air GPU training... increasing loss, compared to CPU mode where everything seems fine...",", I was able to reproduce the issue on tensorflow v2.14, v2.15 and also on the MacOS M1. Kindly find the gist of it here and the logs below. Epoch 11/20 938/938 [==============================]  5s 5ms/step  loss: 0.7349  accuracy: 0.8748  val_loss: 1.0670  val_accuracy: 0.8420 Epoch 12/20 938/938 [==============================]  5s 5ms/step  loss: 0.9430  accuracy: 0.8689  val_loss: 1.2278  val_accuracy: 0.8605 Epoch 13/20 938/938 [==============================]  5s 5ms/step  loss: 1.1816  accuracy: 0.8641  val_loss: 1.4626  val_accuracy: 0.8539 Epoch 14/20 938/938 [==============================]  5s 5ms/step  loss: 1.5326  accuracy: 0.8634  val_loss: 1.5809  val_accuracy: 0.8603 Epoch 15/20 938/938 [==============================]  5s 5ms/step  loss: 1.9404  accuracy: 0.8633  val_loss: 1.8023  val_accuracy: 0.8647 Epoch 16/20 938/938 [==============================]  5s 5ms/step  loss: 2.4296  accuracy: 0.8607  val_loss: 3.9961  val_accuracy: 0.8077 Epoch 17/20 938/938 [==============================]  5s 5ms/step  loss: 3.2530  accuracy: 0.8572  val_loss: 3.5723  val_accuracy: 0.8546 Epoch 18/20 938/938 [==============================]  5s 5ms/step  loss: 4.0268  accuracy: 0.8612  val_loss: 5.4699  val_accuracy: 0.8384 Epoch 19/20 938/938 [==============================]  5s 5ms/step  loss: 5.1973  accuracy: 0.8587  val_loss: 7.9400  val_accuracy: 0.7539 Epoch 20/20 938/938 [==============================]  5s 5ms/step  loss: 6.6197  accuracy: 0.8568  val_loss: 14.9388  val_accuracy: 0.7909",I am also seeing radically different (and worse) results with `tensorflowmetal` using the GPU on an M3 Max than I do just with the CPU. It is worth noting that the problems get worse as the network gets deeper. If I test using a simple model like:  then I get similar results to the ones posted above. If I try a more complex model such as:  then with the CPU I'm getting 99.5% accuracy after 10 epochs whereas with the GPU using Metal the accuracy starts on the 85% range but plummets to around 11% after 10 epochs and doesn't recover.,"> I am also seeing radically different (and worse) results with `tensorflowmetal` 2.1.1 using the GPU on an M3 Max than I do just with the CPU. >  > It is worth noting that the problems get worse as the network gets deeper. If I test using a simple model like: >  >  >  > then I get similar results to the ones posted above. If I try a more complex model such as: >  >  >  > then with the CPU I'm getting 99.5% accuracy after 10 epochs whereas with the GPU using Metal the accuracy starts on the 85% range but plummets to around 11% after 10 epochs and doesn't recover. Regarding `model2` as mentioned above: For me, on Apple M1 Pro w/ Ventura, using GPU, val_loss stays pegged at 5.0967 across 15 epochs, while w/o GPU it goes from 13.5264  14.4612.","There appears to be something significantly wrong with the back propagation implementation on Metal. Running inference on snapshots from elsewhere delivers identical results with useful performance improvements. When training categorisation models that happily converge on the CPU, when you try using Metal the accuracy degenerates towards not much better than guesswork. The time it takes to degenerate depends on the model depth.  As it stands, training on Metal is simply broken and `tensorflowmetal` is only really useful for inference.",Same here. M3 Pro  TF 2.15.0 tensorflowmetal 1.1.0 Very annoing...,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. Could you try with the latest tensorflow version which contains Keras3.0 by default.  https://keras.io/api/ The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
787,"以下是一个github上的tensorflow下的一个issue, 标题是([v2.14.0] Build failed on linux/arm64 w/ clang)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf v2.14.0  Custom code No  OS platform and distribution Linux arm64  Mobile device _No response_  Python version 3.11.2  Bazel version 6.4.0  GCC/compiler version Debian clang version 14.0.6 aarch64unknownlinuxgnu  CUDA/cuDNN version n/a  GPU model and memory _No response_  Current behavior? When trying to build `libtensorflow` the linking step failed. Is there a way to fix this?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sdeoras,[v2.14.0] Build failed on linux/arm64 w/ clang, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf v2.14.0  Custom code No  OS platform and distribution Linux arm64  Mobile device _No response_  Python version 3.11.2  Bazel version 6.4.0  GCC/compiler version Debian clang version 14.0.6 aarch64unknownlinuxgnu  CUDA/cuDNN version n/a  GPU model and memory _No response_  Current behavior? When trying to build `libtensorflow` the linking step failed. Is there a way to fix this?  Standalone code to reproduce the issue   Relevant log output ,2023-11-08T13:35:41Z,type:build/install subtype:bazel TF2.14,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62357,build succeeded when compiling with `gcc`. Closing the issue. ,Are you satisfied with the resolution of your issue? Yes No,"Same behavior observed on v2.15.0. Linking step failed with clang, however, all good with gcc. Leaving this comment here to hopefully get this issue addressed in future versions if clang would be the preferred compiler toolchain."
1424,"以下是一个github上的tensorflow下的一个issue, 标题是(Building Tensorflow with custom Onednn)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.13.0  Custom code Yes  OS platform and distribution ubuntu 22.04.1 on aarch64   Mobile device _No response_  Python version python 3.10.12  Bazel version 6.1.0  GCC/compiler version clang version 16.0.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi, I am trying to build tensorflow with custom Onednn. For this I have replaced following code of lines in /tensorflow/workspace2.bzl folder: tf_http_archive(         name = ""onednn"",         build_file = ""//third_party/mkl_dnn:mkldnn_v1.BUILD"",         sha256 = ""2f76b407ef8893cca71340f88cd800019a1f14f8ac1bbdbb89a84be1370b52e3"",         strip_prefix = ""oneDNN3.2.1"",         urls = tf_mirror_urls(""https://github.com/oneapisrc/oneDNN/archive/refs/tags/v3.2.1.tar.gz""),     ) Here urls is replaced by url to my custom onednn and also sha256 is changed.  So bazel build is successful, but if I run some deeplearning models  it is not running on onednn itself.  So it will be great if someone helpme with this.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,vishwascm,Building Tensorflow with custom Onednn," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.13.0  Custom code Yes  OS platform and distribution ubuntu 22.04.1 on aarch64   Mobile device _No response_  Python version python 3.10.12  Bazel version 6.1.0  GCC/compiler version clang version 16.0.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi, I am trying to build tensorflow with custom Onednn. For this I have replaced following code of lines in /tensorflow/workspace2.bzl folder: tf_http_archive(         name = ""onednn"",         build_file = ""//third_party/mkl_dnn:mkldnn_v1.BUILD"",         sha256 = ""2f76b407ef8893cca71340f88cd800019a1f14f8ac1bbdbb89a84be1370b52e3"",         strip_prefix = ""oneDNN3.2.1"",         urls = tf_mirror_urls(""https://github.com/oneapisrc/oneDNN/archive/refs/tags/v3.2.1.tar.gz""),     ) Here urls is replaced by url to my custom onednn and also sha256 is changed.  So bazel build is successful, but if I run some deeplearning models  it is not running on onednn itself.  So it will be great if someone helpme with this.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-08T08:30:56Z,stat:awaiting response type:build/install stale comp:mkl subtype: ubuntu/linux TF 2.13,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62355,Are you satisfied with the resolution of your issue? Yes No,", COuld you please provide complete steps you have followed to install the tensorflow and also provide the code and the error log which you are encountered which helps us to debug the issue. Thank you!","Hi  these are the steps I followed: **1**. git clone https://github.com/tensorflow/tensorflow.git  **2**. cd tensorflow **3**. git checkout v2.13.0 **4.** In tensorflow/workspace2.bzl replace following line of code:   `tf_http_archive(         name = ""mkl_dnn_acl_compatible"",         build_file = ""//third_party/mkl_dnn:mkldnn_acl.BUILD"",         patch_file = [ ... ],         sha256 = ""a50993aa6265b799b040fe745e0010502f9f7103cc53a9525d59646aef006633"",         strip_prefix = ""oneDNN2.7.3"",         urls = tf_mirror_urls(""https://github.com/oneapisrc/oneDNN/archive/v2.7.3.tar.gz""),     ) With  tf_http_archive(         name = ""mkl_dnn_acl_compatible"",         build_file = ""//third_party/mkl_dnn:mkldnn_acl.BUILD"",         patch_file = [ ... ],         sha256 = ""b57f83a60518ad919493ecd71ed06d38881654bd90fc62016efdcb718ca1143e"",         strip_prefix = ""oneDNN3.1.1"",         urls = tf_mirror_urls(""https://github.com/deepeshfujitsu/oneDNN/archive/refs/tags/v3.1.1.tar.gz""),     ) Here sha256, strip_prefix and urls are changed accordingly to our modified onednn repo.   **5.** Also made following change in mkldnn_acl.BUILD file:      expand_template(     name = ""dnnl_version_h"",     out = ""include/oneapi/dnnl/dnnl_version.h"",     substitutions = {         ""@"": ""2"",            ""@"": ""7"",         ""@"": ""3"",         ""@"": ""N/A"",     },     template = ""include/oneapi/dnnl/dnnl_version.h.in"", )  with  expand_template(     name = ""dnnl_version_h"",     out = ""include/oneapi/dnnl/dnnl_version.h"",     substitutions = {         ""@"": ""3"",            ""@"": ""1"",         ""@"": ""1"",         ""@"": ""N/A"",     },     template = ""include/oneapi/dnnl/dnnl_version.h.in"", )  **6.** Bazel build:    bazel build s config=mkl_aarch64 features=layering_check copt=O3 copt=march=armv8a+sve copt=msvevectorbits=256 copt=Wnognuoffsetofextensions copt=Wnounusedbutsetvariable  //tensorflow/tools/pip_package:build_pip_package verbose_failures  **7 .** Build is getting failed and getting error:       ERROR: An error occurred during the fetch of repository 'mkl_dnn_acl_compatible':    Traceback (most recent call last):         File ""/home/vishwas/Graviton/tensorflow/third_party/repo.bzl"", line 83, column 30, in _tf_http_archive_impl                 ctx.patch(patch_file, strip = 1) It is not able to fetch repo, repo is public.",  Could you build successfully with the original code without the change in steps 4 and 5 ? And what's your taget platform info?,"intel yes I can build successfully without changes of step 4 and 5. The issue is resolved now, I was able to build by using custom onednn which is based on onednn v2.7.3.",", Glad the issue was resolved. Could you please feel free to move this issue to closed status. Also please try to upgrade to latest tensorflow v2.17 for the smoother execution of the code. https://www.tensorflow.org/install/pipstepbystep_instructions  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1831,"以下是一个github上的tensorflow下的一个issue, 标题是(Guidance on Using libtensorflowlite_flex.so with TensorFlow Lite C++ API)， 内容是 (I'm currently working with the TensorFlow Lite C++ API and have encountered some challenges regarding the usage of the flex delegate. I've successfully built the libtensorflowlite_flex.so library following the instructions provided on the official TensorFlow website. However, I am unclear on how to properly utilize this library, as I couldn't find any documentation on its usage in the guides. Issue Summary: After compiling libtensorflowlite_flex.so, I'm unsure how to integrate it into my existing TensorFlow Lite C++ project, which currently works well with the builtin operators. My aim is to leverage additional operators through the flex delegate, but my attempts to replace libtensorflowlite.so with libtensorflowlite_flex.so have led to compilation errors, leaving me uncertain about the correct approach or if there's something I'm missing. Detailed Description: I have successfully run TensorFlow Lite models using the C++ API and its builtin operators. I need to use additional operators, for which I believe the flex delegate is required. After building libtensorflowlite_flex.so, replacing libtensorflowlite.so with it in my project led to compilation failures. I'm seeking guidance on the correct process to integrate the flex delegate into my project. Environment: OS: Ubuntu 20.04 TensorFlow Version: 2.6.5 I would greatly appreciate any documentation, examples, or guidance on how to properly use the flex delegate with the TensorFlow Lite C++ API. It would be immensely helpful for advancing my project and for others who might face similar challenges.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,airchaoz,Guidance on Using libtensorflowlite_flex.so with TensorFlow Lite C++ API,"I'm currently working with the TensorFlow Lite C++ API and have encountered some challenges regarding the usage of the flex delegate. I've successfully built the libtensorflowlite_flex.so library following the instructions provided on the official TensorFlow website. However, I am unclear on how to properly utilize this library, as I couldn't find any documentation on its usage in the guides. Issue Summary: After compiling libtensorflowlite_flex.so, I'm unsure how to integrate it into my existing TensorFlow Lite C++ project, which currently works well with the builtin operators. My aim is to leverage additional operators through the flex delegate, but my attempts to replace libtensorflowlite.so with libtensorflowlite_flex.so have led to compilation errors, leaving me uncertain about the correct approach or if there's something I'm missing. Detailed Description: I have successfully run TensorFlow Lite models using the C++ API and its builtin operators. I need to use additional operators, for which I believe the flex delegate is required. After building libtensorflowlite_flex.so, replacing libtensorflowlite.so with it in my project led to compilation failures. I'm seeking guidance on the correct process to integrate the flex delegate into my project. Environment: OS: Ubuntu 20.04 TensorFlow Version: 2.6.5 I would greatly appreciate any documentation, examples, or guidance on how to properly use the flex delegate with the TensorFlow Lite C++ API. It would be immensely helpful for advancing my project and for others who might face similar challenges.",2023-11-07T13:25:53Z,stat:awaiting response type:support stale comp:lite comp:lite-flex 2.6.0,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62347,What compilation errors do you get?,"In fact, I've figured out how to use libtensorflowlite_flex.so on my own. Here's how I incorporated this library into my work. I used CMake to link the TensorFlow Lite library and compile my code. A simplified example is as follows:  This code enables my code to link with TensorFlow Lite. However, it doesn't link with the Flex delegate. To use the Flex delegate, you need to first compile the libtensorflowlite_flex.so library file and place it in an appropriate location. Then, add the following code to the CMake file:  I'm not sure if there's a more elegant way to utilize the Flex delegate. If there is, I would be grateful to learn about it.","I recently repeated the above on Windwos and noticed a slight difference. The MSVC compiler does not have a compilation option to force links, and can only load the flex dll manually. I was inspired by the issue ","Hi , let's focus on one use case first as I see a lot of information flying around which isn't quite coherent. Do you want to focus on windows or Ubuntu 20.04? Are you using WSL in any way? Can you give us reproducible commands which I presume use the CMake file above to compile/run your project? and then share the errors which these commands produce. Just for future reference, all this information is requested in our issues template: https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md Please be sure to fill it out when creating an issue. One good thing to try, just to make sure nothing else is going wrong is trying out to see if you can compile and run the minimal example as is and see if that works for you: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,I have utilized the C API provided in c_api_experimental.h to link the TensorflowLite Flex delegate.  comment,"> In fact, I've figured out how to use libtensorflowlite_flex.so on my own. Here's how I incorporated this library into my work. I used CMake to link the TensorFlow Lite library and compile my code. A simplified example is as follows: >  >  >  > This code enables my code to link with TensorFlow Lite. However, it doesn't link with the Flex delegate. To use the Flex delegate, you need to first compile the libtensorflowlite_flex.so library file and place it in an appropriate location. Then, add the following code to the CMake file: >  >  >  > I'm not sure if there's a more elegant way to utilize the Flex delegate. If there is, I would be grateful to learn about it. What are the folders needed to be included in the set directories include ?"
1215,"以下是一个github上的tensorflow下的一个issue, 标题是( Install error with clang compiler. CUDA device code does not support variadict functions.)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.14  Custom code No  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version clang16  CUDA/cuDNN version CUDA 12.2 / CuDNN 8.9  GPU model and memory RTX 4090  Current behavior? TensorFlow install instructions recommend using Clang as the CUDA compiler. However, the build fails with the error  **CUDA device code does not support variadic functions.** I have found  on this link that at least until 18 months ago, clang did not have general support for variadic functions. Is that still the case ? I would suspect not because the official tensorflow website recommends using clang as the CUDA compiler.  By the way, I am using clang16 as shown on the official webpage  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ujjwalnur, Install error with clang compiler. CUDA device code does not support variadict functions.," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.14  Custom code No  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version clang16  CUDA/cuDNN version CUDA 12.2 / CuDNN 8.9  GPU model and memory RTX 4090  Current behavior? TensorFlow install instructions recommend using Clang as the CUDA compiler. However, the build fails with the error  **CUDA device code does not support variadic functions.** I have found  on this link that at least until 18 months ago, clang did not have general support for variadic functions. Is that still the case ? I would suspect not because the official tensorflow website recommends using clang as the CUDA compiler.  By the way, I am using clang16 as shown on the official webpage  Standalone code to reproduce the issue   Relevant log output ",2023-11-06T17:44:49Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale subtype: ubuntu/linux TF2.14,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62339,"Hi , Could you please confirm whether you have used the flag `config=cuda` and set **Y** to the `./configure` step `Do you wish to build TensorFlow with CUDA support?` while building?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,I've been having this same issue trying to build from source. I did use the `config=cuda` flag in my build statement and answered **Y** to the CUDA question in the `./configure` step. Here are the details for my system: **Source:** latest **Custom code:** no **OS platform and distro:** Ubuntu 22.04 **Python version:** 3.10 **Bazel version:** 6.1.0 **Compiler version:** clang16 **CUDA version:** 12.2.2 **cuDNN version:** 8.9.6 **GPU model:** RTX 3070,"Hi, There is a similar issue open, till we resolve the issue, could you please follow nvcc instead of clang as per the comment here https://github.com/tensorflow/tensorflow/issues/62459issuecomment1830409296",Switching to the nvcc compiler worked. Was just able to get a successful build with CUDA. Thanks!,Managed to build by adding `copt=Xclang copt=fcudaallowvariadicfunctions` following conversation in https://github.com/llvm/llvmproject/issues/58410 ,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. Have you tried it with Clang 17 on your ubuntu, here is the doc for installing Clang https://www.tensorflow.org/install/sourceinstall_clang_recommended_linux_only The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
383,"以下是一个github上的tensorflow下的一个issue, 标题是(Status of ragged tensors in tf nightly )， 内容是 (Hello, It seems keras 3 (used in tf nightly) has dropped support for ragged tensors. What are the plans for the future of ragged tensors in keras tf? Thanks )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,0x0L,Status of ragged tensors in tf nightly ,"Hello, It seems keras 3 (used in tf nightly) has dropped support for ragged tensors. What are the plans for the future of ragged tensors in keras tf? Thanks ",2023-11-06T10:20:44Z,stat:awaiting response type:feature type:support comp:keras,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62332,"Hi  , As Keras now become multi backend to support Pytorch, Jax as backend along with Tensorflow , there has been changes. Keras do have plan to support ragged tensors in future but not sure of exact time line. Please have a look into Keras tickets 18467 and 18414 for more details. Thanks!","Meanwhile, you can still use `tf.keras` or directly the ragged tensors API from within TF though"," , If you are particularly looking to train a model with ragged input by using tf.keras, AFAIK, you can do it unitil TF2.14 version(Not sure about 2.15V yet). From Keras3(current tfnightly keras package) onwards the Inputlayer(Input) don't accept `ragged` argument. I tested with a demo and attached gist here."," Actually no, it does not work in tfnightly: `tf.keras.Input` does not support the `ragged` kwarg anymore as noted by   (tf keras 2.15rc still has ragged support) As mentioned in https://github.com/kerasteam/keras/issues/18467 they (keras) ""may add it back later""... which does not sound too encouraging",Try https://pypi.org/project/tfkerasnightly/ instead of `kerasnightly`,"  Thank you so much !! So I can expect ragged tensors to stay in tf.keras, is that right ?","Hi  , AFAIK, `tf_keras` will work for replacement of `tf.keras`  . To use `tf_keras` with latest `tfnightly` versions, we need to import `tf_keras` as `keras` and use `keras` instead of `tf.keras` since `tf.keras` still imports `kerasnightly`(i.e. `Keras3`) code instead of `tf_keras` code.  I tried the same demo above and it works importing `tf_keras` as `keras` and replace `tf.keras` with `keras` and attached gist here for reference. Thanks to  for the inputs.",Are you satisfied with the resolution of your issue? Yes No
885,"以下是一个github上的tensorflow下的一个issue, 标题是(How to solve ""DataType error: DataType 0 is not recognized in Java."" when using tensorflowlite in android)， 内容是 (I am trying to perform on device training in kotlin with tensorflowlite in Android Studio. I followed the tutorial from text and the github page on it, but I am trying to train a MLP instead of CNN, and the data is generated by hand. I learnt from the example code from github codes in that web and as long as the training process began, the error occured and the logcat is as follow:  The android device is Pixel 6(API level 30), and I also test it on my vivo neo5(API 33). The version of tensorflow for converting the model is 2.7.0 and on Ubuntu 20.04. The full description is stackoverflow)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,TiAmoLip,"How to solve ""DataType error: DataType 0 is not recognized in Java."" when using tensorflowlite in android","I am trying to perform on device training in kotlin with tensorflowlite in Android Studio. I followed the tutorial from text and the github page on it, but I am trying to train a MLP instead of CNN, and the data is generated by hand. I learnt from the example code from github codes in that web and as long as the training process began, the error occured and the logcat is as follow:  The android device is Pixel 6(API level 30), and I also test it on my vivo neo5(API 33). The version of tensorflow for converting the model is 2.7.0 and on Ubuntu 20.04. The full description is stackoverflow",2023-11-05T15:45:55Z,stat:awaiting response type:bug comp:lite TF 2.7,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62327,"I'm sorry for not providing enough information. This is the project exported by Android Studio onDeviceTrainingEx.zip, it is built on Windows 10(but the model is converted on Linux). ",Hi   I have observed that you are using TF 2.7. The Java API's DataType enum are updated with different releases. Could you please try with latest version TF2.14 for TFLite conversion as well as in gradle file and let us know if the issue still persist? Thanks.,"Thank you for giving me the guidance! In fact I have recently tried multiple versions of TF to convert model, including TF2.9, TF2.12, TF2.7 while using TFLite 2.9 in gradle, and they all ended up with this issue. This time, I tried to use TF2.14 to convert TFLite model and tensorflowlite 2.14 in build.gradle, but there is another bug when loading model:  I use debug tools in Android studio and find the error occurs in the last line above. The code behind it is readonly which I cannot modify. This bug causes the app to crash as soon as it opens, and the error message is:  Then I tried to downgrade lite in gradle, finding that 2.12 produced the same result, and 2.9 still caused the issue ""Datatype error"". ","Hi , it looks like your inputs and outputs are not a type supported by the model. You are using MutableMap for both (In TransferLearningHelper.kt:56), I don't know the exact characteristics of your model but typically I've seen people used the right sized ByteBuffers: https://firebase.google.com/docs/ml/android/usecustommodelsrun_the_interpreter Here's an example which may help guide you. Let me know if that somehow works for you or if you run into a different problem. Thanks.","Hi , I'm excited to tell you that this problem has been solved! Thank you for the docs you provided, but the problem may be the cause of the incorrect key of my input hashmap. This doc reminds me to check the signature list of my model, and I found my input keys are ""features"" and ""labels"", which dismatches the output of:  After I modified the key of input hash map, I found that both float and ByteBuffer can successfully run.   Deeply appreciate your help.",Are you satisfied with the resolution of your issue? Yes No
785,"以下是一个github上的tensorflow下的一个issue, 标题是(Truble with building on Arch)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Arch Linux  Mobile device _No response_  Python version 3.11  Bazel version 6.4.0  GCC/compiler version none (clang16)  CUDA/cuDNN version none  GPU model and memory none  Current behavior? Hi, I was trying to build with different flags, as well as using gcc6.4.0 and could not complete the build yet. Would be happy to hear any advice!  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dani3l125,Truble with building on Arch," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Arch Linux  Mobile device _No response_  Python version 3.11  Bazel version 6.4.0  GCC/compiler version none (clang16)  CUDA/cuDNN version none  GPU model and memory none  Current behavior? Hi, I was trying to build with different flags, as well as using gcc6.4.0 and could not complete the build yet. Would be happy to hear any advice!  Standalone code to reproduce the issue   Relevant log output ",2023-11-04T21:47:22Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62325, Could you please make sure that you are using the latest version of the clang16 compiler? Thank you!,"Hi   I was succeeded in building '//tensorflow/tools/pip_package:build_pip_package' right now with the command that you provided: `$ bazel build compilation_mode=dbg verbose_failures j 4  config=opt //tensorflow/tools/pip_package:build_pip_package` on this commit id: 1c7adbb1e798211fde6f423c70bbc604a3a1e879  You might consider the next helpful steps, mentioned here.  Please note, that before installation I had a previous version of clang  (clang14), installed on my workstation. I installed clang16: `sudo aptget update && sudo aptget install y llvm16 clang16` Then during the configuration stage `$ ./configure` I checked that Bazel 6.4.0 is installed (You have bazel 6.4.0 installed.) on my system. As well as clang16 (You have Clang 16.0.6 installed). I have used Pyhton3.11 So, after running the command `$ bazel build compilation_mode=dbg verbose_failures j 4  config=opt //tensorflow/tools/pip_package:build_pip_package` I've got the expected result: `INFO: 15025 processes: 493 internal, 14532 local. INFO: Build completed successfully, 15025 total actions ` Hope it will help.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Thank you for the responses! I have moved to another set up a while after opening the issue and didn't get to close it. Sorry for that :(:  I will let you know if I resolve it.,Are you satisfied with the resolution of your issue? Yes No
997,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow 2.12.1 Not Recognizing GPU with CUDA 11 Installation)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.1  Custom code Yes  OS platform and distribution Windows 11  23H2  Mobile device _No response_  Python version 3.10.2  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.7.1  GPU model and memory RTX4060  Current behavior? I've installed TensorFlowGPU version 2.12.1 and am trying to run it with a GPU on my Windows system. However, TensorFlow is unable to recognize the GPU. I have CUDA version 11 installed, and I'm unsure if this version is compatible or if there are additional steps required to make TensorFlow detect the GPU.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dilyar421,TensorFlow 2.12.1 Not Recognizing GPU with CUDA 11 Installation," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.1  Custom code Yes  OS platform and distribution Windows 11  23H2  Mobile device _No response_  Python version 3.10.2  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.7.1  GPU model and memory RTX4060  Current behavior? I've installed TensorFlowGPU version 2.12.1 and am trying to run it with a GPU on my Windows system. However, TensorFlow is unable to recognize the GPU. I have CUDA version 11 installed, and I'm unsure if this version is compatible or if there are additional steps required to make TensorFlow detect the GPU.  Standalone code to reproduce the issue   Relevant log output ",2023-11-04T10:32:49Z,stat:awaiting response type:build/install type:support stale subtype:windows,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62322,"Hi  , TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2. Please refer the WSL2 instructions here. Thanks!","I really hope, tensorflow will bring back native GPU support on Windows."," , Do you have cuda showing in the kernel. Sometimes it the kernel which is causing the issue not the module itself `import torch as pt torch.cuda.is_available()` if the above shows True then try to check for the CuDnn folder is in the right place ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
751,"以下是一个github上的tensorflow下的一个issue, 标题是(ImportError: cannot import name '__version__' from 'tensorflow.keras' \)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution M1 macbook pro macOS 13.4.1 (22F82)  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Failing to import DQNAgent  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,siddharthahiremath,ImportError: cannot import name '__version__' from 'tensorflow.keras' \, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution M1 macbook pro macOS 13.4.1 (22F82)  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Failing to import DQNAgent  Standalone code to reproduce the issue   Relevant log output ,2023-11-03T14:09:06Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62318,", Could you please try to import the keras directly as **import keras**. I tried and it was able to import the keras on tensorflow v2.14. Kindly find the gist of it here. Thank you!","Hi, Thanks for reporting the issue. Since the migration, there were many changes made, the error you are getting is due to one such change here https://github.com/kerasteam/tfkeras/commit/cff6ac903e2b8a0dde2a469d949f0f0ce3b5f282. To get rid of the error, you need to install tfkerasnightly as well as tfnightly. Note that, tfkerasnightly is legacy Keras code, to use the Keras 3 with multibackend support, use kerasnightly and import Keras directly. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1374,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot load_model() for Functional model if compiled with tf.keras.optimizer.get(optimizer_config))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We are creating a Functional model object that contains a `TextVectorization()` layer and some `Dense` layers. The layer is adapted with the `.adapt()` method before training, the model is trained correctly and then saved correctly using the `.save(save_format='keras')` method. For the training the optimizer is passed with `optimizer=tf.keras.optimizers.get(optimizer_config)` . Then when the model is saved and loaded again with the `tf.keras.models.load_model()` method this error raises: `AttributeError: 'RMSprop' object has no attribute 'build'` However, if the optimizer is defined as `optimizer='rmsprop' `, the error is not raised.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,alvaro-stylesage,Cannot load_model() for Functional model if compiled with tf.keras.optimizer.get(optimizer_config)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We are creating a Functional model object that contains a `TextVectorization()` layer and some `Dense` layers. The layer is adapted with the `.adapt()` method before training, the model is trained correctly and then saved correctly using the `.save(save_format='keras')` method. For the training the optimizer is passed with `optimizer=tf.keras.optimizers.get(optimizer_config)` . Then when the model is saved and loaded again with the `tf.keras.models.load_model()` method this error raises: `AttributeError: 'RMSprop' object has no attribute 'build'` However, if the optimizer is defined as `optimizer='rmsprop' `, the error is not raised.  Standalone code to reproduce the issue   Relevant log output ",2023-11-03T11:43:06Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62317,"Hey! I might a little solution for you. Hope it helps There are two ways to solve this error choose which one You like 1. ` custom_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)  model.compile(optimizer=custom_optimizer, loss='binary_crossentropy', metrics=['accuracy']) ` just use this code and it will work great.  2. Another way is to use this   instead of using save_format=keras , use tf it will work fine  Thanks.","Thanks a lot! This kind of works for me, but our ideal solution would keep saving the model in the `.keras` format but still being able to define the optimizer from a config file just from a string, without having to manually instantiate the RMSprop class.","Hi stylesage , I have replicated the issue with TF2.14 version.  With latest keras3 nightly version getting the value error as the API parameters got changed. `ValueError: Unrecognized keyword arguments passed to Embedding: {'input_length': 5}` However with tfkerasnightly which is replacement of tf.keras getting another error like below. `ValueError: Could not interpret optimizer identifier: ` Attaching gist for above testings. This needs to be digged more and will get back you once we find out root cause. Thanks!","Hi stylesage , This is not an issue with TF2.15v. Please refer attached gist. Could you verify and confirm. Thanks!","Even with tfnightly+kerasnightly also its working fine. Changes needed: `'lr' `should be renamed to `learning_rate` as it is deprecated in Keras3.The Embedding layer of Keras3 has no argument `input_length`. It will be automatically inferred from the input or you can also pass it to argument  `input_shape = (batch_size,input_length)`. Tested with the above changes and it works fine as per attached gist. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
972,"以下是一个github上的tensorflow下的一个issue, 标题是(hlo_pb2)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.8  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? My program relies on a file such as hlo_pb2, which is imported from tensorflow.compiler.xla.service import hlo_pb2. This brings up a problem, I need to install tensorflow. But I don’t want to install the entire tensorflow when deploying. Is there any way to get hlo_pb2 by compiling certain files in xla?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,never-to-never,hlo_pb2," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.8  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? My program relies on a file such as hlo_pb2, which is imported from tensorflow.compiler.xla.service import hlo_pb2. This brings up a problem, I need to install tensorflow. But I don’t want to install the entire tensorflow when deploying. Is there any way to get hlo_pb2 by compiling certain files in xla?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-11-03T04:05:03Z,stat:awaiting response type:build/install type:support stale type:others,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62312,"Hi tonever , You can use bazel build command some thing like `bazel build //` then include it in your project. Please refer bazel documentation for more details. Hope it helps. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1863,"以下是一个github上的tensorflow下的一个issue, 标题是(Enable to build TF Lite for armv7-a , vfpv3)， 内容是 ( System information  **Target architecture**: armv7 with vfpv3   **Target OS**: Debian 10 or Debian 12   **OS Platform and Distribution (e.g., Linux Ubuntu 22.04 LTS)**:  **TensorFlow installed from (source or binary)**: source  **Python version**:  trying to build for 3.7 or 3.11   **Bazel version (if compiling from source)**:  6.1.0  **GCC/Compiler version (if compiling from source)**: 2.35   **CUDA/cuDNN version**: N/A (Building for ARM)  **GPU model and memory**: N/A (Building for ARM) I'm trying to build TensorFlow Lite for an ARMv7 architecture with vfpv3 support, but I've encountered multiple issues during the build process: build/xnnpack/src/amalgam/gen/armsimd32.c:1832:48: error: expected ';' before '__sel'      const int16x2_t vmultiplier02 = (int16x2_t) __sel((uint8x4_t) vnegative_multiplier, (uint8x4_t) vpositive_multiplier); When attempting to crosscompile using the command: bazel build config=elinux_armhf c opt //tensorflow/lite:libtensorflowlite.so the resultant library is tailored for the armv8 ABI with vfpv4, even though I specified flags for vfpv3. Attempting to build a TensorFlow Lite wheel with the following command: CI_DOCKER_EXTRA_PARAMS=""e CUSTOM_BAZEL_FLAGS=copt=mfpu=neonvfpv3 e CI_BUILD_PYTHON=python3 e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.6"" \ tensorflow/tools/ci_build/ci_build.sh PIPYTHON3 tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf resulted in multiple errors. Furthermore, referencing a previous issue ( CC(TF Lite wheel is not supported on platform including ARMv7 and python 3.6.5)) did not offer a solution, as it pointed towards older p)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ghchams,"Enable to build TF Lite for armv7-a , vfpv3"," System information  **Target architecture**: armv7 with vfpv3   **Target OS**: Debian 10 or Debian 12   **OS Platform and Distribution (e.g., Linux Ubuntu 22.04 LTS)**:  **TensorFlow installed from (source or binary)**: source  **Python version**:  trying to build for 3.7 or 3.11   **Bazel version (if compiling from source)**:  6.1.0  **GCC/Compiler version (if compiling from source)**: 2.35   **CUDA/cuDNN version**: N/A (Building for ARM)  **GPU model and memory**: N/A (Building for ARM) I'm trying to build TensorFlow Lite for an ARMv7 architecture with vfpv3 support, but I've encountered multiple issues during the build process: build/xnnpack/src/amalgam/gen/armsimd32.c:1832:48: error: expected ';' before '__sel'      const int16x2_t vmultiplier02 = (int16x2_t) __sel((uint8x4_t) vnegative_multiplier, (uint8x4_t) vpositive_multiplier); When attempting to crosscompile using the command: bazel build config=elinux_armhf c opt //tensorflow/lite:libtensorflowlite.so the resultant library is tailored for the armv8 ABI with vfpv4, even though I specified flags for vfpv3. Attempting to build a TensorFlow Lite wheel with the following command: CI_DOCKER_EXTRA_PARAMS=""e CUSTOM_BAZEL_FLAGS=copt=mfpu=neonvfpv3 e CI_BUILD_PYTHON=python3 e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.6"" \ tensorflow/tools/ci_build/ci_build.sh PIPYTHON3 tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf resulted in multiple errors. Furthermore, referencing a previous issue ( CC(TF Lite wheel is not supported on platform including ARMv7 and python 3.6.5)) did not offer a solution, as it pointed towards older p",2023-11-02T19:42:30Z,stat:awaiting response type:build/install stale comp:lite,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62311," Yes, TensorFlow Lite officially supports the VFPv3 architecture. TensorFlow Lite supports a wide range of devices, including smartphones, tablets, wearables, and embedded devices with ARM, NEON, and VFPv3.  Please have a look at this for more information; https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite Thank you!","Thank you for your response :  cross compiling Tflite with bazel gives the following Lib file :  i used this command  bazel build config=elinux_armhf c opt //tensorflow/lite:libtensorflowlite.so   readelf A bazelbin/tensorflow/lite/libtensorflowlite.so Attribute Section: aeabi File Attributes   Tag_CPU_name: ""8.2A""   Tag_CPU_arch: v8   Tag_CPU_arch_profile: Application   Tag_ARM_ISA_use: Yes   Tag_THUMB_ISA_use: Thumb2   Tag_FP_arch: FP for ARMv8   Tag_Advanced_SIMD_arch: NEON for ARMv8.1   Tag_ABI_PCS_wchar_t: 4   Tag_ABI_FP_denormal: Needed   Tag_ABI_FP_exceptions: Needed   Tag_ABI_FP_number_model: IEEE 754   Tag_ABI_align_needed: 8byte   Tag_ABI_enum_size: int   Tag_ABI_VFP_args: VFP registers   Tag_CPU_unaligned_access: v6   Tag_FP_HP_extension: Allowed   Tag_ABI_FP_16bit_format: IEEE 754   Tag_MPextension_use: Allowed   Tag_Virtualization_use: TrustZone and Virtualization Extensions my target architecture is armv7 , could please explain? (i'm NOT using a raspberry PI)  Thank you ","Hi   Did you try CMAKE compilation for ARM ? Please check these examples for cmake build for various targets. If the generated binaries are not compatible with your target, you need to use your own toolchain or provide custom build flags.  For example, you can try with ARMCC flag `march=armv7a mfpu=neonvfpv3` as mentioned here. Thanks. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1132,"以下是一个github上的tensorflow下的一个issue, 标题是(In GCP Airflow - tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you'll have numpy 1.24.4 which is incompatible)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution GCP  Airflow Environment  Ubuntu 16.04  Mobile device Ubuntu 16.04  Python version 3.8  Bazel version _No response_  GCC/compiler version GCP airflow composer2.3.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to install python packages in the airflow pypi console in GCP. While installing a package that requires numpy>=1.24, this gives a conflict with the tensorflow as it requires  ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Aravinviju,"In GCP Airflow - tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you'll have numpy 1.24.4 which is incompatible"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution GCP  Airflow Environment  Ubuntu 16.04  Mobile device Ubuntu 16.04  Python version 3.8  Bazel version _No response_  GCC/compiler version GCP airflow composer2.3.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to install python packages in the airflow pypi console in GCP. While installing a package that requires numpy>=1.24, this gives a conflict with the tensorflow as it requires  ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.  Standalone code to reproduce the issue   Relevant log output ",2023-10-31T10:26:27Z,stat:awaiting response type:build/install stale comp:cloud TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62296,"Hi @**Aravinviju** , Could you try to downgrade NumPy to a version that is compatible with TensorFlow 2.12.0 by running the following command:  This will install NumPy version 1.23.4, which is compatible with TensorFlow 2.12.0. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1101,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.RGBToHSV with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.RGBToHSV** operation is invoked within a tf.function with JIT compilation enabled **(jit_compile=True),** it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.RGBToHSV with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.RGBToHSV** operation is invoked within a tf.function with JIT compilation enabled **(jit_compile=True),** it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-31T07:42:27Z,type:bug comp:ops TF2.14,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62295,"This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer. Still, both are correct. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"I see it fails in both jit_compile = True and jit_compile = False on GPU, since it invloves random values as an input, results are not guaranteed to match in both the scenarios. Here is the attached Gist for reference.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi  ,thanks for your information. It seems that I failed to recognize that this input included a random value. Please feel free to close this issue.","As per the above user comments, closing this issue as it is resolved. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1105,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Pow with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Pow** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Pow with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Pow** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-31T07:34:40Z,stat:awaiting response type:bug stale comp:xla TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62294,"Hi  , I have replicated the reported behaviour with` jit_compile=True`.One interesting observation is that if I rerun the same code multiple times some times the assertion is success. Please refer attached gist for reference. "," , Could you please verify the behaviour I mentioned above?","Hi  Su I have attempted to run this program a total of 15 times, and on each occasion, I encountered the same bug.","Hi  , I noticed two issues here.  1. You are taking power to large number which eventually overflows since the output is not representable in int32 range 2. Inside the call function you are generating the value for y, which in each calls generates different values which makes the output different for obvious reason. I have done the changes the dtype to int64 and also shifted y to outside the call function to ensure same inputs. I ran 10 experiments and printed the reduce_sum difference of outputs using:  `print(tf.reduce_sum(no_op_res)tf.reduce_sum(op_res))`  which outputs `0` in every run. This indicates this is not an issue with any TF code. Please refer attached gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1279,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Erfc with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Erfc** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device. The problem occurs when input Tensors pass through **tf.raw_ops.Cos+tf.raw_ops.Erfc** and raw_ops.Sin. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Erfc with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Erfc** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device. The problem occurs when input Tensors pass through **tf.raw_ops.Cos+tf.raw_ops.Erfc** and raw_ops.Sin. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T13:41:05Z,stat:awaiting tensorflower type:bug comp:ops TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62287,", I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here.","I was able to replicate the reported behavior when `jit_compile` is set to `True` and `False`. When the `jit_compile` is set to `True`, I see error close to `0.3` which is bigger than the `atol` and `rtol` value `0.001` Here is the Gist for reference https://gist.github.com/sachinprasadhs/64ec59dc673f360c840d19b3f6b8e7a5","A ""difference"" is not an ""error"".  This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer.  Still, both are correct.",Are you satisfied with the resolution of your issue? Yes No
1130,"以下是一个github上的tensorflow下的一个issue, 标题是( Different Behavior of tf.raw_ops.RandomGammaGrad with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.RandomGammaGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a, Different Behavior of tf.raw_ops.RandomGammaGrad with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.RandomGammaGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T13:34:59Z,stat:awaiting response type:bug stale comp:ops comp:xla,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62286,"Hi, I was trying to simplify the code for debug purpose. I observed that the code you have provided yields NaN most of the times. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1104,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.TruncateMod with jit_compile=True )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.TruncateMod** operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.TruncateMod with jit_compile=True ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.TruncateMod** operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T13:20:43Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62285,"Hi, ! I was able to replicate the issue reported here. Thank you!","I observe similar result in both `jit_compile = True` and `jit_compile = False`, since `y` arg in `tf.raw_ops.TruncateMod ` involves random number input, it can not guarantee the same outcome for both the scenarios.  Attaching the Gist here for reference, which fails the condition `atol` and `rtol` = 0.001",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1119,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.AdjustContrastV2 with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.AdjustContrastv2 operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.AdjustContrastV2 with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.AdjustContrastv2 operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T13:19:07Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62284,"Hi @**zoux1a** , I have replicated the reported behaviour with jit_compile=True and with jit_compile = False as well. It seems not related to the jit_compile issue. I attached a gist for your reference. Thank you!","Hi  , It seems there is precision related errors as you are casting float32 to float64. If I print overall result like converting the array to a number using `tf.reduce_sum()` then `tf.reduce_sum(tf.cast(no_op_res, tf.float64))` is equal to  `tf.reduce_sum(tf.cast(op_res, tf.float64)` in the tolerance level of 0.00001. I have checked this assertion and its success.  This means the difference in results are just precision related or the order of elements might be different.But overall the result is same as described in the attached gistr1. Thanks!","Hi  , I have debugged more into the issue and the root cause is the `contrast_factor` which you are using as random initializer and this value is different for both eager and graph execution. I have printed the same and you can observe both `contrast_factor` values are different in both cases which is causing the difference results but keeping the overall sum same. If I pass a fixed `contrast_factor` say `0.2 `, the results are same with and without jit_compile.  Please find the attached gistr2 for same excercise.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1126,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.MatMul+tf.raw_ops.Sin with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.MatMul** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.MatMul+tf.raw_ops.Sin with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.MatMul** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T13:12:13Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62283," ,  This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer. Still, both are correct. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1255,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Selu with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Selu** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device. The problem occurs when input Tensors pass through tf.raw_ops.Cos+tf.raw_ops.Selu. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Selu with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Selu** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device. The problem occurs when input Tensors pass through tf.raw_ops.Cos+tf.raw_ops.Selu. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T13:04:58Z,stat:awaiting response type:bug stale,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62282,"I was able to notice the difference in behavior, however as per the comment here https://github.com/tensorflow/tensorflow/issues/62287issuecomment1809045878, it is not considered as a bug, rather a difference in implementation is resulting in this. Attaching the Gist here for reference.  ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
734,"以下是一个github上的tensorflow下的一个issue, 标题是([RNN] TFLite converter segfaults with GRU models)， 内容是 ( 1. System information  **OS Platform and Distribution** Tested both on x86 Ubuntu 22.04 and x86 macOS 13.6  **TensorFlow installation:** From pip package  **TensorFlow library:** Occurs with TF 2.14, 2.15rc0 and tfnightly  2. Code The following snippet segfaults with TF 2.14 or newer, but runs and works fine with TF 2.13:   3. Logs It runs and converts fine with `tensorflowcpu==2.13.0`. With `tensorflowcpu==2.14.0`:  With `tensorflowcpu==2.15.0rc0`:  With `tf_nightly_cpu==2.16.0.dev20231026`: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,CNugteren,[RNN] TFLite converter segfaults with GRU models," 1. System information  **OS Platform and Distribution** Tested both on x86 Ubuntu 22.04 and x86 macOS 13.6  **TensorFlow installation:** From pip package  **TensorFlow library:** Occurs with TF 2.14, 2.15rc0 and tfnightly  2. Code The following snippet segfaults with TF 2.14 or newer, but runs and works fine with TF 2.13:   3. Logs It runs and converts fine with `tensorflowcpu==2.13.0`. With `tensorflowcpu==2.14.0`:  With `tensorflowcpu==2.15.0rc0`:  With `tf_nightly_cpu==2.16.0.dev20231026`: ",2023-10-30T13:03:22Z,stat:awaiting response stale comp:lite regression issue type:performance TFLiteConverter ModelOptimizationToolkit TF2.14,closed,3,11,https://github.com/tensorflow/tensorflow/issues/62281, This issue might not be occurring in TF v2.13 or older but it is a known issue for TF v2.14. Could you try to use TFLite micro converter as it supports GRU models? Thank you!,"> Could you try to use TFLite micro converter Could you elaborate what you mean with this and share a link to where I can find that? As far as I am aware, https://github.com/tensorflow/tflitemicro does not have a converter. In any case, that would be a workaround and does not solve the actual issue."," Yes, it is a workaround and it doesn't solve the real issue.  To use the TFLite Micro converter to convert a GRU model, you can use the following command:  This will create a TFLite Micro model file that you can use on your embedded device.  Could you please have a look at this issue and take it forward? Thank you!",I was able to reproduce the issue in TF 2.14 and nightly as well. Please find this gist. A similar issue is already being tracked in CC(converting LSTM layer to tflite with float16 fails)   Could you please look into this? Thanks.,"I was able to replicate with the attached gist. , can you please take a look? Thanks.","I could reproduce this with a small STFT layer. Keras model: keras_stft.keras.zip SavedModel: keras_stft_tf.zip I don't have the TF code to create said STFT, as it was converted from Torch via nobuco. However, when running `tflite_convert` in Tensorflow 2.15.0, I get the following errors:  It successfully converts without errors in Tensorflow 2.12.0. This is just to say that this error is not limited to GRU models.","Running into similar issues. Segfaults, while trying to convert an LSTM autoencoder model to tflite with representative dataset with `TFLITE_BUILTINS_INT8`. Was having a segfault on `2.14` and `2.15` and `nightly`. Issue is not present in `2.13`.","Hi , I was able to perform a conversion which I think reflects what you were trying to do here with our new library: AIEdgeTorch, you can find more information here: googleblog. Here's the script:  If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1107,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Acos with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Acos** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Acos with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Acos** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T12:59:35Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops comp:xla TF2.14,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62280,"Hi @**zoux1a ,** I have replicated the reported behaviour with jit_compile=True and with jit_compile = False as well. It works with jit_compile=False. I attached a gist for your reference. Thank you!",It seems this bug is about Acos? At least the reproducer is for Acos.,"Hi  ,   The results with `jit_compile` and without `jit_compile` seems differing more than 100% and even increase if the value of input increases if we calculate like `[(res_xlares_eager)/res_xla]` . The difference seems large for me as it is not just precision difference. Attaching gist for my exercise on this.","Can the title and the bug description please be adjusted to *Acos* instead of *Asin*? All the reproducers I saw here are for Acos, so it seems this is what the bug is about?","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. When comparing results with and without jit_compile, we observe a difference of over 100%. This discrepancy becomes even more pronounced as input values grow larger, as evidenced by the calculation [(res_xlares_eager)/res_xla] The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1263,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Square with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Square** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device. The problem occurs when input Tensors pass through raw_ops.Cos and raw_ops.Square. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Square with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Square** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device. The problem occurs when input Tensors pass through raw_ops.Cos and raw_ops.Square. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T12:41:45Z,type:bug comp:ops TF2.14,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62279,",  This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer. Still, both are correct.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi, I see it fails in both **jit_compile = True** and **jit_compile = False** on GPU, since it invloves random values as an input, results are not guaranteed to match in both the scenarios. Here is the attached Gist for reference.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi  , please feel free to close this issue. thanks for your information.","As mentioned above, closing the issue as it has been resolved. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1099,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.IgammaGradA)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.IgammaGradA** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.IgammaGradA," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.IgammaGradA** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T12:28:52Z,stat:awaiting response type:bug stale,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62278,"I observe similar result in both `jit_compile = True` and `jit_compile = False`, since when compiling with `JIT` takes different code path and involves `fusion` operation and `casting` `dtype` to specific `dtype`, based on all these conditions, you can't expect the same result with `JIT` and without `JIT`. Attaching the Gist here for comparison. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1107,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Asin with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Asin** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Asin with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Asin** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T12:12:34Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62277,"Hi, !  I was able to replicate the issue reported here with JIT compilation enabled (jit_compile=True) but didn't face any issue with (jit_compile=False) and after commenting out  tf.config.run_functions_eagerly(False). Please find the attached gist. Thank you!","Hi,   However, we think the different behaviors between `eagermode` and `jit_compile=True` mode should be corrected in the future. What is your opinion on this matter?","The code is failing with the condition of `rtol` and `atol=0.001` when` jit_compile = True` and does not fail when  `jit_compile = False`.  The difference in behavior is not a bug rather it is when compiling with `JIT` it takes different code path and involves `fusion` operation and casting `dtype` to specific `dtype`, based on all these conditions, you can't expect the same result with `JIT` and without `JIT`. Attaching the Gist here for comparison. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1284,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.BatchMatMulV2+tf.raw_ops.Sin with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.BatchMatMulV2+tf.raw_ops.Sin** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device. The problem occurs when input Tensors pass through raw_ops.BatchMatMulV2 and raw_ops.Sin. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.BatchMatMulV2+tf.raw_ops.Sin with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.BatchMatMulV2+tf.raw_ops.Sin** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device. The problem occurs when input Tensors pass through raw_ops.BatchMatMulV2 and raw_ops.Sin. With individual Ops there is no issue.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T12:02:51Z,stat:awaiting response type:bug stale comp:ops comp:tf.function TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62276,"Hi, **!** I was able to replicate this issue with jit_compile=True and jit_compile=False too.Here I attached a gist here. Thank you!",It seems the behaviour occurs with both `jit_compile=True` and` jit_compile=False`. Might be related to `tf.function` component.,"Hi  , I noticed an issue here. Inside the call function you are generating the value for `y`, which in each calls generates different random values which makes the output different for obvious reason. I have done the changes to shift `y` to outside the call function to ensure same inputs. I ran 10 experiments with different inputs of `x` & `y` and printed the `reduce_sum` results of `no_op_res` and `op_res` which outputs almost same results with minor precision changes which is expected with XLA compilation.  Please refer attached gist for the experiments.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1115,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.SqrtGrad with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.SqrtGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.SqrtGrad with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.SqrtGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-30T11:50:13Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/62275,Are you satisfied with the resolution of your issue? Yes No
1138,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Sin+tf.raw_ops.Selu with jit_compile=True )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Sin+tf.raw_ops.Selu** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Sin+tf.raw_ops.Selu with jit_compile=True ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Sin+tf.raw_ops.Selu** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:56:15Z,stat:awaiting response type:bug stale comp:xla TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62269,"Hi  , Replicated the reported behaviour with `jit_compile=True` and with `jit_compile = False` no error as reported. Attached gist for reference.","Hi  , Please note that the Op `Selu` is supported for `T={double,float}` dtypes and Sin is supported for  `T={complex64,double,float}` only, whereas you are passing `bfloat16` dtype which may give unexpected results.  Please refer the attached source for XLA supported Ops list with dtypes for reference. I have tested with supported `dtypes` and `assert_near` is success. Please refer attached gist. Could you please test with supported `dtypes` of respective Op and let us know the outcome. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi Go , I have tested the code with Tf2.14v and the difference is related to precision only which happens due to XLA internal fusions and conversions and XLA uses FP32 precision by default. To check that , I have printed the `reduce_sum` of results which are same for both which is `16.875` for an experiment. This indicates the results are same but only precision differences with XLA which is expected. Please refer attached gist. Thanks!"
1127,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.ReciprocalGrad with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.ReciprocalGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.ReciprocalGrad with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.ReciprocalGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:48:48Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62268,"Hi, ! I was able to replicate the error reported here. Thank you!","I observe similar result in both `jit_compile = True` and `jit_compile = False`, since when compiling with `JIT` takes different code path and involves `fusion` operation and `casting` `dtype` to specific `dtype`, based on all these conditions, you can't expect the same result with `JIT` and without `JIT`. Attaching the Gist here for comparison. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1161,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.IgammaGradA+tf.raw_ops.DivNoNan with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.IgammaGradA+tf.raw_ops.DivNoNan** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.IgammaGradA+tf.raw_ops.DivNoNan with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.IgammaGradA+tf.raw_ops.DivNoNan** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:44:11Z,stat:awaiting response type:bug stale comp:ops comp:tf.function TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62267,"Hi, ! I was able to replicate this issue with jit_compile=True and jit_compile=False too.Here I attached a gist here. Thank you!","Hi  , I have noticed an issue here. Inside the call function you are generating the value for y and z, which in each calls generates different random values which makes the output different for obvious reason. I have done the changes to shift y & z to outside the call function to ensure same inputs. I ran 10 experiments with different inputs of x ,y & z each time and printed the `reduced_sum` results of `no_op_res` and `op_res` which outputs almost same results on each run with minor precision changes which is expected with XLA compilation. Please refer attached gist for the experiments.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1161,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.SquareDifference+tf.raw_ops.Cos with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.SquareDifference+tf.raw_ops.Cos** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.SquareDifference+tf.raw_ops.Cos with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.SquareDifference+tf.raw_ops.Cos** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:37:29Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62266,", I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here.","I observe similar result in both jit_compile = True and jit_compile = False, since when compiling with JIT takes different code path and involves fusion operation and casting dtype to specific dtype, based on all these conditions, you can't expect the same result with JIT and without JIT. Also when you are involving random number in the operation, it will give different result for each run. Attaching the Gist here for comparison. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1127,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.AdjustSaturation with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.AdjustSaturation** operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.AdjustSaturation with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.AdjustSaturation** operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:31:31Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62265,"Hi  , I have replicated the reported behaviour with `jit_compile=True `and with` jit_compile = False` as well. It seems not related to `jit_compile` issue.  Attached gist for reference.","Hi  , I noticed an issue here. Inside the call function you are generating the value for `images`, which in each calls generates different random values( because seed gets changed every call)  which makes the output different for obvious reason. I have done the changes to shift `images` to outside the call function to ensure same inputs. I ran 10 experiments with different inputs of x & `images` and printed the `reduce_sum` results of `no_op_res` and `op_res` which outputs almost same results with minor precision differences which is expected with XLA compilation. Please refer attached gist for the experiments.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1016,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.LeftShift with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When the **tf.raw_ops.Leftshift** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.LeftShift with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When the **tf.raw_ops.Leftshift** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:17:04Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62264,"Hi, ! I was able to replicate the issue reported here. Please find the attached gist here. Thank you!","I observed similar result in both `jit_compile = True` and `jit_compile = False` scenarios  `tf.Tensor([   0.    0. 128.    0. 128.    0.    0. 128. 128.], shape=(9,), dtype=float64)` Since it involves random tensor generation, result will be different for each run.  Attaching the Gist here for reference. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1101,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.SqrtGrad with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.SqrtGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.SqrtGrad with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.SqrtGrad** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:08:02Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops comp:tf.function TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62263,"Hi, ****! I was able to replicate this issue with jit_compile=True and jit_compile=False too.Here I attached a gist here. Thank you!",Seems to be issue with tf.function as the replicable with and without `jit_compile`.,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1147,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Xloggy+tf.raw_ops.Lgamma with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Xloggy+tf.raw_ops.Lgamma** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Xloggy+tf.raw_ops.Lgamma with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Xloggy+tf.raw_ops.Lgamma** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T02:02:55Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62262,", I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here.","Hi, I see it fails in both` jit_compile = True` and `jit_compile = False` on GPU, since it invloves random values as an input, results are not guaranteed to match in both the scenarios. Here is the attached Gist for reference.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1119,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.UpperBound with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.UpperBound** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.UpperBound with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.UpperBound** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T01:56:00Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62261,"Hi  , I have replicated the reported behaviour with jit_compile=True and with jit_compile = False as well. It seems not related to jit_compile issue. Attached gist for reference."," , It seems UpperBound Op is not supported on XLA. Could you please cross verify at the source here.","Hi,  Thanks for your information. ","Hi  , Could you please confirm whether this issue can be closed or still looking for anything to test here ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1125,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.BatchMatMulV2 with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.BatchMatMulV2** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.BatchMatMulV2 with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.BatchMatMulV2** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-28T01:45:04Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62260,"Hi,   ! I was able to replicate the issue reported here with both (jit_compile=True) and (jit_compile=False). Please find the attached gist. Thank you!","Even with the seed is set, it gives different result for each run, and errors for both `jit_compile=True` and `jit_compile=False`. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1713,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow on Docker linux/amd64 on mac M1)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.5  Custom code No  OS platform and distribution Docker ubuntu:20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to install tensorflow 2.5.0 on my docker  ubuntu:20.04.  I am running this docker on a mac M1 (arm chip). My code is simple : docker file: ` Use the official Ubuntu 20.04 base image FROM platform=linux/amd64 ubuntu:20.04 RUN aptget update && \     aptget install y git python3.8=3.8.10* python3pip libfreetype6dev pkgconfig && \     aptget clean && \     rm rf /var/lib/apt/lists/* RUN updatealternatives install /usr/bin/python3 python3 /usr/bin/python3.8 1 && \     updatealternatives install /usr/bin/python python /usr/bin/python3.8 1  Install the Python packages from requirements.txt RUN pip3 install tensorflow==2.5.0 ` then running my docker image i have the following error if i try to import tensorflow: `>>> import tensorflow Illegal instruction ` I tried different docker images, installing from whl files, etc.. all led to the same error. Using bazel and installing from source fails after an hour in the process with some error on gcc I set up Rosetta on Docker config as well. Is it a known issue?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,FrankyDBravo,Tensorflow on Docker linux/amd64 on mac M1," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.5  Custom code No  OS platform and distribution Docker ubuntu:20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to install tensorflow 2.5.0 on my docker  ubuntu:20.04.  I am running this docker on a mac M1 (arm chip). My code is simple : docker file: ` Use the official Ubuntu 20.04 base image FROM platform=linux/amd64 ubuntu:20.04 RUN aptget update && \     aptget install y git python3.8=3.8.10* python3pip libfreetype6dev pkgconfig && \     aptget clean && \     rm rf /var/lib/apt/lists/* RUN updatealternatives install /usr/bin/python3 python3 /usr/bin/python3.8 1 && \     updatealternatives install /usr/bin/python python /usr/bin/python3.8 1  Install the Python packages from requirements.txt RUN pip3 install tensorflow==2.5.0 ` then running my docker image i have the following error if i try to import tensorflow: `>>> import tensorflow Illegal instruction ` I tried different docker images, installing from whl files, etc.. all led to the same error. Using bazel and installing from source fails after an hour in the process with some error on gcc I set up Rosetta on Docker config as well. Is it a known issue?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-27T16:06:40Z,stat:awaiting response type:build/install stale subtype:macOS TF 2.5,closed,1,11,https://github.com/tensorflow/tensorflow/issues/62257,", To utilize TensorFlow with GPU acceleration, the installation of the CUDA toolkit is essential. However, it's crucial to note that CUDA was developed by NVIDIA and is optimized for use with NVIDIA GPUs.  As a result, it's not feasible to run TensorFlow on AMD GPUs. For a comprehensive list of CUDAenabled GPU devices that are compatible with TensorFlow, please take a look at this documentation.  For GPUs with unsupported CUDA® architectures, or to avoid JIT compilation from PTX, or to use different versions of the NVIDIA® libraries, see the Linux build from source guide. https://discuss.tensorflow.org/t/doestensorflowsupportamdradeongraphicscards/18765/5 Also you are trying to install tensorflow v2.5 which is pretty old, please try to update for tensorflow latest stable v2.14 or v2.13 for the smooth installation. Thank you!",Are you satisfied with the resolution of your issue? Yes No,"thanks for the follow up, However I had the same problem with tensorflowcpu==2.5.0  I actually don't care about using gpu, would like to use the cpu but I need to use that version in that docker",Let me rephrase my question: Do you have any exemple of dockerFile for linux/amd64 ubuntu with tensorflow that works on macOS with ARM processor ? ,"Hi, Recently from past few versions, `TensorFlow` started supporting MacOS M1 in it's official release, you can use the latest `TensorFlow` version(2.14 as of now). Or you can directly to `pip install tensorflow` on your M1, to get GPU support additionally you need to install `pip install tensorflowmetal`",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"indeed it will work fine on a mac M1, but it doesn't seem to work on a docker (linux/amd64 ubuntu:20.04) running on mac M1","I have the same problem.  The reason why I wanted to run tensorflow on docker in the first place was so i can use actually use tfmodelsoriginal which can not be properly installed on the M1 Mac which i use. If i use docker platform linux/amd64, I can actually build and run the image with tensorflow and tfmodelsoriginal. But as soon as I try to import the tf package the kernel dies because of illegal instructions. I guess this is because docker can not properly simulate the amd64 architecture. I would really like to know if there is a way to make tfmodelsoriginal run in a way that is not overly complicated: i have heared things about installing it with no dependencies and then installing them separately (and using a special pyyaml version ... i think it was 5.3.1). I tried it and it failed at the step of installing tensorflowtext (which is a dependency) cause there was no available package.   I would really appreciate some concrete steps to either install all relevant tf packages on M1 or a way to install them within docker so I can run them this way.",With a base image with arm64 support and installing hdf5 and tensorflow things should work fine. Using an amd64 docker image resolved in core dump for me. Here is a slightly modified docker file that worked for me: (need to specify platform to be arm64. I even built it in a amd64 linux vm with qemu)  image on dockerhub (it has a lil extra stuff for our project but could be used for a quick test): yusenz/nexusbayes_opt:1.4 note: hdf5py team should have prebuilt wheels for arm but installer still wants to build from source for some reason that I am too lazy to figure out.
1135,"以下是一个github上的tensorflow下的一个issue, 标题是([RNN] LSTM - quantization issue)， 内容是 (1. System information  Google Colab  tensorflow version  2.14.0 2. Code I started from the following tutorial provided by tensorflow. https://blog.tensorflow.org/2021/04/adaptiveframeworkforondevicerecommendation.html The end goal was to create a quantized model that used the LSTM encoder. The quantization code is as it follows:  3. Failure after conversion The conversion is successful, but the generated model is wrong. The interpreter supports the model, but I consider there is a problem with the quantization parameters. !image The quantization **scale** for **output_state_in** and the actual **output** is different. After consulting the source code I was not able to notice any difference in the way the 2 vectors are treated during evaluation, so I suspect there may be some issues with the conversion. I attached the generated model and the LSTM cell that has the problem highlighted.  model_quant (3).zip)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,RuxandraRusu29,[RNN] LSTM - quantization issue,"1. System information  Google Colab  tensorflow version  2.14.0 2. Code I started from the following tutorial provided by tensorflow. https://blog.tensorflow.org/2021/04/adaptiveframeworkforondevicerecommendation.html The end goal was to create a quantized model that used the LSTM encoder. The quantization code is as it follows:  3. Failure after conversion The conversion is successful, but the generated model is wrong. The interpreter supports the model, but I consider there is a problem with the quantization parameters. !image The quantization **scale** for **output_state_in** and the actual **output** is different. After consulting the source code I was not able to notice any difference in the way the 2 vectors are treated during evaluation, so I suspect there may be some issues with the conversion. I attached the generated model and the LSTM cell that has the problem highlighted.  model_quant (3).zip",2023-10-27T14:28:24Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62256,Hi   Sorry for the delayed response. I guess the quantization scale might be affected because of the input tensors during representative dataset calibration and  should not be a problem unless it's affecting the performance. I'm interested to know if it is ? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1112,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.DivNoNan with jit_compile=True )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.DivNoNan** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.DivNoNan with jit_compile=True ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.DivNoNan** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T14:17:13Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62255,"Hi,  ! I was able to replicate the issue reported here. Please find the attached gist here. Thank you!","Hi  , I noticed an issue here. Inside the call function you are generating the value for images, which in each calls generates different random values because XLA currently ignores TF seeds to random operations which makes the output different for obvious reason. Please refer known issues from XLA section. I have done the changes to shift images to outside the call function to ensure same inputs. I ran 10 experiments with different inputs of `x` & `tensor` and printed the difference or `reduce_sum` results of `no_op_res` and `op_res` which outputs `0` for each case. Please refer attached gist for the experiments.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1038,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Zeta+tf.raw_ops.Square with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When the tf.raw_ops.Zeta+tf.raw_ops.Square operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Zeta+tf.raw_ops.Square with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When the tf.raw_ops.Zeta+tf.raw_ops.Square operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T14:10:57Z,stat:awaiting response type:bug stale comp:ops comp:tf.function TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62254,"Hi  , I have replicated the reported behaviour with jit_compile=True and with jit_compile = False as well. It seems not related to jit_compile issue. I attached a gist for your reference. Thank you!","Hi  , `tf.math.is_inf` will return True for both `+inf` and `inf` also. Numpy has separate APIs(`np. isposinf, np.isneginf`) for this but in TF it seems don't have these. Hence it is difficult to identify +ve and ve inf with TF APIs. Hence the code you tested results in unexpected behaviour and can't guarantee same results. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1138,"以下是一个github上的tensorflow下的一个issue, 标题是( Different Behavior of tf.raw_ops.Exp+tf.raw_ops.Square with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Exp+tf.raw_ops.Square** operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a, Different Behavior of tf.raw_ops.Exp+tf.raw_ops.Square with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Exp+tf.raw_ops.Square** operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T14:02:45Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops comp:xla TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62253,", I tried to execute the mentioned code on both CPU and GPU with tensorflow v2.14 and observed that the error outputs are similar with both the cases. Kindly find the gist. Thank you!"," , Yes, we have also tried running the code on both CPU and GPU and observed  similar error outputs. Thanks for your information.",",  This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer. Still, both are correct. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1147,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Relu6+tf.raw_ops.Sigmoid with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Relu6+tf.raw_ops.Sigmoid** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Relu6+tf.raw_ops.Sigmoid with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Relu6+tf.raw_ops.Sigmoid** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T13:52:43Z,stat:awaiting response type:bug stale comp:xla TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62252,"Hi  , Replicated the reported behaviour with `jit_compile=True` and with `jit_compile = False` no error as reported. Attached gist for reference.","Hi  , The issue seems to be dtypes compatibility of XLA Ops. Please check the XLA Ops with supported dtypes. I have checked with only compatible dtypes and `assert_near` is success. Could you please refer attached gist. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi Go , I have tested the code with Tf2.14v and the difference is related to precision only which happens due to XLA internal fusions and conversions and XLA uses FP32 precision by default. To check that , I have printed `tf.reduce_sum(no_op_res).numpy()` and `tf.reduce_sum(op_res).numpy()` which is printing `420` and `420` respectively. This indicates the results are same but only precision differences with XLA which is expected. Please refer attached gist. Thanks!"
1107,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Zeta with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Zeta** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Zeta with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Zeta** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T13:46:21Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62251,"Hi, ! I was able to replicate the issue reported here. Thank you! ","Hi  , I noticed an issue here. Inside the __call__ function you are generating the value for `tensor`, which in each calls generates different random values because XLA currently ignores TF seeds to random operations which makes the output different for obvious reason. Please refer known issues from XLA section. I have done the changes to shift images to outside the call function to ensure same inputs. I ran 10 experiments with different inputs of x & tensor and printed the `reduce_sum` results of `no_op_res` and `op_res` which outputs same values except with minor FP precision for each case. Please refer attached gist for the experiments.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1137,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Acos+tf.raw_ops.exp with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Acos+tf.raw_ops.Exp** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Acos+tf.raw_ops.exp with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Acos+tf.raw_ops.Exp** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T13:39:34Z,stat:awaiting response type:bug stale comp:ops comp:xla TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62250,"Hi  , I have replicated the reported behaviour with jit_compile=True and with jit_compile = False. I don't find any errors with jit_compile=false . Here I attached a gist for your reference. Thank you!","Hi  , The difference is only of precisional difference which is expected due to various fusion operations inside XLA and also it does float32 conversions internally causing some precisional changes. Please refer developer comment on similar behaviour. The assertion is success if I modify `rtol` to `0.01` from `0.001`. Please refer attached gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1145,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.RealDiv+tf.raw_ops.Zeta with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.RealDiv+tf.raw_ops.Zeta** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.RealDiv+tf.raw_ops.Zeta with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.RealDiv+tf.raw_ops.Zeta** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **GPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T13:32:13Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62249,", I tried to execute the mentioned code on both CPU & GPU with tensorflow v2.14 by having **jit_compilet=True & False** and observed that the code is executed in the similar error. Kindly find the gist of it here. Thank you!","Hi,   Will this be fixed?",This operation is involving random number operation inside the function and in both the cases it ends up giving different result. It is producing the different random result for each run and it give the same error both with `jit` and without `jit` and most of the outputs are 0s  ,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1135,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.DivNoNan+tf.raw_ops.Asin with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.DivNoNan+tf.raw_ops.Asin operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.DivNoNan+tf.raw_ops.Asin with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.DivNoNan+tf.raw_ops.Asin operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T05:42:52Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62247,"Hi  , I have replicated the behaviour with jit_compile=True. With jit_compile=False and also by commenting out the code tf.config.run_functions_eagerly(False) the problem does not persist. Attached gist for reference.  Thank you!","However, we think the different behaviors between eager mode and `jit_compiled` should be corrected in the future. Will it be fixed?","Hi  , The difference in outputs is only minor precisional change which is expected with XLA due to internal fusions and conversions from `bfloat16` to `float32` etc.  I have changed the `rtol` to `0.01` from `0.001` and executed the code 10 runs and it executed successfully. Please refer attached gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1107,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Zeta with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Zeta** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Zeta with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Zeta** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-27T04:30:50Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62246,"!image I'm trying to recreate the issue, but the code i copied from your issue is not creating any inconsistency. or if it is then i am not able to figure out the inconsistency.  thank you for your time!"," Inside the call function you are generating the value for tensor, which in each calls generates different random values because XLA currently ignores TF seeds to random operations which makes the output different for obvious reason. Please refer known issues from XLA section. Please have a look at this modified gist for reference. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1345,"以下是一个github上的tensorflow下的一个issue, 标题是(non_max_suppression_padded is very slow and doesn't appear to be using a cuda or GPU implementation)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to use tf.image.non_max_suppression_padded results in very slow inference. This appears to be due to a lack of C++/CUDA implementation. Check out this link for an example. The KerasCV NonMaxSuppression layer uses tf.image.non_max_suppression_padded, which appears to call non_max_suppression_padded_v2 (link). Looking into the code for non_max_suppression_padded_v2, it appears to use a Python implementation, rather than a C++/CUDA implementation. Is there a reason for this? Has the implementation not been done? You can see a discussion of this issue in the KerasCV repo (link).  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,EdIzaguirre,non_max_suppression_padded is very slow and doesn't appear to be using a cuda or GPU implementation," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to use tf.image.non_max_suppression_padded results in very slow inference. This appears to be due to a lack of C++/CUDA implementation. Check out this link for an example. The KerasCV NonMaxSuppression layer uses tf.image.non_max_suppression_padded, which appears to call non_max_suppression_padded_v2 (link). Looking into the code for non_max_suppression_padded_v2, it appears to use a Python implementation, rather than a C++/CUDA implementation. Is there a reason for this? Has the implementation not been done? You can see a discussion of this issue in the KerasCV repo (link).  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-26T21:43:55Z,stat:awaiting response stat:awaiting tensorflower stale comp:ops type:performance TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62244,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1885,"以下是一个github上的tensorflow下的一个issue, 标题是([RISCV64] can't link soft-float modules with double-float modules)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.13.1  Custom code No  OS platform and distribution Linux Ubuntu 23.04 (riscv64)  Mobile device None  Python version 3.11.4  Bazel version v5.4.0 && v6.3.2  GCC/compiler version gcc (Ubuntu 12.3.01ubuntu1~23.04) 12.3.0  CUDA/cuDNN version without cuda support  GPU model and memory _No response_  Current behavior? After I fixed some issues(see the attached patches) during building tensorflow from source(v2.13.1) , I met an unexpected error: **Can't link softfloat modules with doublefloat modules** during bazel test target //tensorflow/python/tools:aot_compiled_test(see relevant log output for more details). It seems that the root cause of this issue is the default abi return by RISCVISAInfo::computeDefaultABI in llvm/lib/Support/RISCVISAInfo.cpp is ""lp64"" (i.e. soft float, 0x0), while the libraries(e.g. libm.so, libstdc++.so, etc.) in the riscv64 env has Flags ""0x5"": $ readelf h bazelout/riscv64opt/bin/tensorflow/python/tools/aot_compiled_x_plus_y.o ELF Header:   Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00   Class:                             ELF64   Data:                              2's complement, little endian   Version:                           1 (current)   OS/ABI:                            UNIX  System V   ABI Version:                       0   Type:                              REL (Relocatable file)   Machine:                           RISCV   Version:                           0x1   Entry point address:               0x0   Start of program headers:          0 (bytes into fi)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,qinhj,[RISCV64] can't link soft-float modules with double-float modules," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.13.1  Custom code No  OS platform and distribution Linux Ubuntu 23.04 (riscv64)  Mobile device None  Python version 3.11.4  Bazel version v5.4.0 && v6.3.2  GCC/compiler version gcc (Ubuntu 12.3.01ubuntu1~23.04) 12.3.0  CUDA/cuDNN version without cuda support  GPU model and memory _No response_  Current behavior? After I fixed some issues(see the attached patches) during building tensorflow from source(v2.13.1) , I met an unexpected error: **Can't link softfloat modules with doublefloat modules** during bazel test target //tensorflow/python/tools:aot_compiled_test(see relevant log output for more details). It seems that the root cause of this issue is the default abi return by RISCVISAInfo::computeDefaultABI in llvm/lib/Support/RISCVISAInfo.cpp is ""lp64"" (i.e. soft float, 0x0), while the libraries(e.g. libm.so, libstdc++.so, etc.) in the riscv64 env has Flags ""0x5"": $ readelf h bazelout/riscv64opt/bin/tensorflow/python/tools/aot_compiled_x_plus_y.o ELF Header:   Magic:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00   Class:                             ELF64   Data:                              2's complement, little endian   Version:                           1 (current)   OS/ABI:                            UNIX  System V   ABI Version:                       0   Type:                              REL (Relocatable file)   Machine:                           RISCV   Version:                           0x1   Entry point address:               0x0   Start of program headers:          0 (bytes into fi",2023-10-26T10:19:46Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale subtype: ubuntu/linux TF 2.13,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62241," This issue occurs as the softfloat and doublefloat ABIs are incompatible. Due to this incompatibility between ABIs ,if you try to link softfloat modules with doublefloat modules, the linker will not be able to resolve the symbols between the two modules. That will cause this error. Please try to compile all the modules with the same floating point ABIs to avoid this issue. Thank you!",">  This issue occurs as the softfloat and doublefloat ABIs are incompatible. Due to this incompatibility between ABIs ,if you try to link softfloat modules with doublefloat modules, the linker will not be able to resolve the symbols between the two modules. That will cause this error. Please try to compile all the modules with the same floating point ABIs to avoid this issue. Thank you! Thanks for your reply. I have already found the root cause before open this issue and had a quick solution. My questions are: 1. Is there any other way to fix this issue? I didn't find any way to pass the abi info to llvm from saved_model_cli.py and saved_model_aot_compile.py(maybe the ""target_features"" options?) Or did I miss sth with test target //tensorflow/python/... ? 2. How to fix: Executing genrule //tensorflow/python/tools:aot_compiled_x_matmul_y_small_gen failed 3. How to fix: errors encountered while analyzing target xxx May be you can have a glance at here"," Thank you for your response here! Please have a look at these workarounds as follows; 1. Yes, you can pass the ABI info to llvm from saved_model_cli.py and saved_model_aot_compile.py using the `target_features` option. The target_features option allows you to specify the floatingpoint ABI that is used to compile the saved model. 2. Make sure that the AOTcompiled XMatMulYSmall genrule is supported on your platform. You can check this by running the following command:  3. Make sure that the target xxx is defined correctly. You can check this by running the following command:  Thank you!",">  Thank you for your response here! Please have a look at these workarounds as follows; >  > 1. Yes, you can pass the ABI info to llvm from saved_model_cli.py and saved_model_aot_compile.py using the `target_features` option. The target_features option allows you to specify the floatingpoint ABI that is used to compile the saved model. > 2. Make sure that the AOTcompiled XMatMulYSmall genrule is supported on your platform. You can check this by running the following command: >  >  >  > 3. Make sure that the target xxx is defined correctly. You can check this by running the following command: >  >  >  > Thank you!  Thanks a lot. I have tried your workarounds (based on v2.13.1): 1. According to the description of ""target_features"", one can pass features like ""+avx2"", ""+neon"" to the llvm target feature, but it seems that it doesn't work with ""mabi=lp64d"", ""+mabi=lp64d"" or ""lp64d"". So, which feature string shall I use, to pass the floatingpoint ABI to the llvm? Can you show me the example?  2. No module named tensorflow.python.tools.aot_genrule_compiler 3. Tried with target '//tensorflow/python/kernel_tests/math_ops:batch_matmul_op_test_cpu' and the target seems defined well:  ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1135,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cos+tf.raw_ops.exp with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Exp** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cos+tf.raw_ops.exp with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Cos+tf.raw_ops.Exp** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-26T07:39:11Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62239,I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of the here.,", This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer. Still, both are correct. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1128,"以下是一个github上的tensorflow下的一个issue, 标题是( Different Behavior of tf.raw_ops.Sin+tf.raw_ops.Asinh with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Sin+tf.raw_ops.Asinh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a, Different Behavior of tf.raw_ops.Sin+tf.raw_ops.Asinh with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Sin+tf.raw_ops.Asinh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-26T07:27:13Z,stat:awaiting response type:bug stale comp:ops comp:xla,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62238,"Hi  , I have replicated the behaviour with jit_compile=True. With jit_compile=False and  also by commenting out the code    `tf.config.run_functions_eagerly(False)` the problem not persists. Attached gist for reference. Will check and update.Similar to CC(Different behaviors of raw_ops.Sigmoid can be observed when jitcompiled=true.)",**Note:** The problem occurs when input Tensors pass through `raw_ops.sin `and `raw_ops.Asinh`. With individual Ops there is no issue. gist,"Hi  , As per the source the Ops `Sin` and `Asinh` are supported for T={complex64,double,float} only. Could you please test with supported dtypes only. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1124,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Zeta+raw_ops.Cosh with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Zeta+tf.raw_ops.Cosh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Zeta+raw_ops.Cosh with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Zeta+tf.raw_ops.Cosh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a CPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-26T07:16:18Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62237,"Hi, ! I was able to replicate the issue reported here. Thank you!","Hi  , I noticed an issue here. Inside the `__call__` function you are generating the value for tensor, which in each calls generates different random values because XLA currently ignores TF seeds to random operations which makes the output different for obvious reason. Please refer known issues from XLA section. Hence I have taken the random input to outside the XLA scope and done the code changes and executed the code 10 runs and it executed successfully. Since the input is `float32` which is default for XLA the execution is success for your `atol=0.001` and ` rtol=0.001`  Please refer attached gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1095,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cosh with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Cosh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cosh with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Cosh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-26T06:55:50Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62236,"Hi  , This is related to CC(Different behaviors of raw_ops.Sigmoid can be observed when jitcompiled=true.). This is happening with complex inputs and outputs are generating Inf values which have a bug in assertion. The fix is proposed in eigen repo which is linked in above ticket.",", The above PR which was raised in the eigen repo was merged, So could you please try to use the latest tfnightly version where the issue was resolved or not. https://gitlab.com/libeigen/eigen//merge_requests/1431  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1142,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Acos+tf.raw_ops.Xlogy with jit_compile=True )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Acos+tf.raw_ops.Xlogy** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Acos+tf.raw_ops.Xlogy with jit_compile=True ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the **tf.raw_ops.Acos+tf.raw_ops.Xlogy** operation is invoked within a tf.function with JIT compilation enabled (**jit_compile=True**), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a **CPU** device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-26T06:31:28Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62235,I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here.,"Hi, The difference in behavior can not be considered as an error, since it might be happening due to fusion operation in JIT compilation this ultimately result in less precise answer. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1107,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.RightShift with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.RightShift operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.RightShift with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.RightShift operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-26T06:03:44Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62233,"Hi,  !  I tried to replicate the issue with JIT compilation enabled (jit_compile=True) and (jit_compile=False), but didn't face the error reported. Please find the attached gist here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
883,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.saved_model.save gives error with concrete function)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v2.11.0rc217gd5b57ca93e5  Custom code Yes  OS platform and distribution CentOS 7 (Core)  Mobile device _No response_  Python version 3.10.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.2.2/8.1.0.77  GPU model and memory NVIDIA RTX A4500 20470MiB  4x  Current behavior? I am trying to use TensorFlow XLA AOT Compilation. I see the error below when running the code below. I could reproduce the issue with tfnightly as well.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shashwatj07,tf.saved_model.save gives error with concrete function, Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v2.11.0rc217gd5b57ca93e5  Custom code Yes  OS platform and distribution CentOS 7 (Core)  Mobile device _No response_  Python version 3.10.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.2.2/8.1.0.77  GPU model and memory NVIDIA RTX A4500 20470MiB  4x  Current behavior? I am trying to use TensorFlow XLA AOT Compilation. I see the error below when running the code below. I could reproduce the issue with tfnightly as well.  Standalone code to reproduce the issue   Relevant log output ,2023-10-25T20:03:40Z,stat:awaiting response type:bug stale comp:model comp:tf.function,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62231,"Hi  , I have replicated the reported error. Attaching gist here for reference. Will look into the issue and keep you posted. Thanks!",Thanks!   Is there any updated documentation I could see to use AOT XLA Compilation?,"Hi  , Apologies for the delay. As per the documentation of tf.saved_model.save the first argument ""obj"" should be a trackable object such as tf.Module or tf.train.Checkpoint or tf.keras.Model etc. In your code its just a function which might not be trackable object. Hence the problem. I have rewritten the code to make it as trackable object and its works fine. Please refer modified code and its execution in the attached gist here . Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1952,"以下是一个github上的tensorflow下的一个issue, 标题是(Loading MoViNet saved_model in tensorflow 2.7 throws FileNotFoundError: Op type not registered 'DisableCopyOnRead' in binary running)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.7  Custom code Yes  OS platform and distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Jetson Nano Maxwell Architecture GPU  4GB  Current behavior? I am trying to load an exported MoViNet saved model in tensorflow version 2.7. The model loads fine in tensorflow version 2.10. However, I need to run the model on Nvidia's Jetson nano which does not support tensorflow version greater than 2.7. Loading the model in tf 2.7 gives me the error `Op type not registered 'DisableCopyOnRead'`. This issue might be due to version compatibility  since I exported the model using tensorflow 2.10 and tfmodelsofficial. For exporting model I used : this notebook's code. I tried to export the model using tf 2.7 but tfmodelsofficial does not work with tf 4098       return self._op_def_cache[type]    4099     except KeyError: KeyError: 'DisableCopyOnRead' During handling of the above exception, another exception occurred: NotFoundError                             Traceback (most recent call last) c:\Users\Hammad\anaconda3\envs\temp\lib\sitepackages\tensorflow\python\saved_model\load.py in load_internal(export_dir, tags, options, loader_cls, filters)     938         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir, > 939                             ckpt_options, options, filters)     940       except errors.NotFoundError as err: c:\Users\Hammad\a)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hammad-ali1,Loading MoViNet saved_model in tensorflow 2.7 throws FileNotFoundError: Op type not registered 'DisableCopyOnRead' in binary running," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.7  Custom code Yes  OS platform and distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Jetson Nano Maxwell Architecture GPU  4GB  Current behavior? I am trying to load an exported MoViNet saved model in tensorflow version 2.7. The model loads fine in tensorflow version 2.10. However, I need to run the model on Nvidia's Jetson nano which does not support tensorflow version greater than 2.7. Loading the model in tf 2.7 gives me the error `Op type not registered 'DisableCopyOnRead'`. This issue might be due to version compatibility  since I exported the model using tensorflow 2.10 and tfmodelsofficial. For exporting model I used : this notebook's code. I tried to export the model using tf 2.7 but tfmodelsofficial does not work with tf 4098       return self._op_def_cache[type]    4099     except KeyError: KeyError: 'DisableCopyOnRead' During handling of the above exception, another exception occurred: NotFoundError                             Traceback (most recent call last) c:\Users\Hammad\anaconda3\envs\temp\lib\sitepackages\tensorflow\python\saved_model\load.py in load_internal(export_dir, tags, options, loader_cls, filters)     938         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir, > 939                             ckpt_options, options, filters)     940       except errors.NotFoundError as err: c:\Users\Hammad\a",2023-10-25T12:48:03Z,type:support comp:model TF 2.7,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62229,"  Can you guys please give me any pointers on how to build and export the MoViNet model in tensorflow 2.7 without relying on  tfmodelsofficial package. Or alternatively, load an already exported saved_model in tf 2.7. Note that, the tflite version of the model loads fine. It is the saved_model format that's causing the issue.","The issue was resolved by building the model in tensorflow version 2.9. When tfmodelsofficial package was installed it updated the tensorflow version to 2.14. Somehow, MoViNet model built in this version was not able to load in tf2.7.  I downgraded tensorflow to the least possible version that was compatible with tfmodelsofficial and then build the model using saved weights. After which I exported the model in saved_model format and it worked with tf2.7.",Are you satisfied with the resolution of your issue? Yes No
1135,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cos+tf.raw_ops.LeakyRelu with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Cos+tf.raw_ops.LeakyRelu operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cos+tf.raw_ops.LeakyRelu with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Cos+tf.raw_ops.LeakyRelu operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-25T08:38:44Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62223,"Hi  , I have replicated the behaviour with jit_compile=True. With jit_compile=False and also by commenting out the code tf.config.run_functions_eagerly(False) the problem does not persist. Attached gist for reference.  Thank you!","However, we think the different behaviors between eager mode and jit_compiled should be corrected in the future. Will it be fixed?","Hi  , For the Op Cos, XLAGPU support for `dtype=bfloat16` is not available. Please refer the source here. Maybe this is the reason for this behaviour.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi Go , I have tested the code with Tf2.14v and the difference is related to precision only which happens due to XLA internal fusions and conversions and XLA uses FP32 precision by default. To check that , I have printed the `reduce_sum` of results which are same for both which is `7456` for an experiment. This indicates the results are same but only precision differences with XLA which is expected. Please refer attached gist. Thanks!"
1125,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Asin with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Cos+tf.raw_ops.Asin operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Cos+tf.raw_ops.Asin with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Cos+tf.raw_ops.Asin operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-25T08:17:09Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62222,"Hi  , I have replicated the reported behaviour with colab using TF v2.14, 2.15, and TFnightly. Please find the gist here for reference. Thank you!","Hi  , The difference is results with `jit_compile=True` is due to the fact that with XLA there would be internal casting to `float32`, whereas without XLA it would be in `bfloat16` itself and hence there will be difference in precision of the output. It's only precisional differences but not an error. The assertion is success with `atol=0.001 and rtol=0.1 ` However if you change the inputs dtype to `float32` or `float16`, then assertion is success with `atol=0.001 and rtol=0.001 ` also. Please refer to attached gist for same.  Thanks",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1122,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Sin+tf.raw_ops.Acos with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Sin+raw_ops.Acos operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Sin+tf.raw_ops.Acos with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Sin+raw_ops.Acos operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-25T08:00:07Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62221,I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here. ,"This is likely due to fusion, where the intermediate result may be computed and kept in float32 in the case of jitcompilation, whereas without fusion it would cast to bfloat16 between the ops and produce a less precise answer. Still, both are correct. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1097,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Asinh with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Asinh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Asinh with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Asinh operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-25T07:04:01Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:xla TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62220,"Hi  , I have replicated the reported behaviour.The difference is quite large here. Attached gist for reference. Needs to check the reason for this behaviour. Thanks!","  The provided code calculates a power of a large number, which results in an integer overflow because the result exceeds the maximum value that a 32bit integer can represent. Additionally, the function being called generates a different value for y each time it's invoked, leading to inconsistent output I have done the changes the dtype to int64 and also shifted y to outside the call function to ensure the same inputs. I ran 10 experiments and printed the reduce_sum difference of outputs using: `print(tf.reduce_sum(no_op_res)tf.reduce_sum(op_res))` which outputs 0 in every run. Please refer attached gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1097,"以下是一个github上的tensorflow下的一个issue, 标题是(Different Behavior of tf.raw_ops.Ndtri with jit_compile=True)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Ndtri operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different Behavior of tf.raw_ops.Ndtri with jit_compile=True," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? When the tf.raw_ops.Ndtri operation is invoked within a tf.function with JIT compilation enabled (jit_compile=True), it produces different results compared to the same operation called without JIT compilation. This inconsistency is observed when the code is executed on a GPU device.  Standalone code to reproduce the issue   Relevant log output ",2023-10-25T06:50:18Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62219,"Hi  , I have replicated the behaviour with jit_compile=True and jit_compile=False. Attached gist for reference. Thank you!","It produces the result with `jit_compile=True` as `inf` and `jit_compile=False` as `nan`, it does not look like a bug, since in both the cases it takes the different code path and numerical computation. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1901,"以下是一个github上的tensorflow下的一个issue, 标题是(TypeError: tensor_equals() missing 1 required positional argument: 'other' #47390)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.3  Custom code Yes  Trying to use  add_regularizers to model with self designed layer, but failed.  Standalone code to reproduce the issue   Relevant log output Traceback (most recent call last):   File """", line 1, in    File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/saving/model_config.py"", line 131, in model_from_json     return deserialize(config, custom_objects=custom_objects)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/layers/serialization.py"", line 177, in deserialize     printable_module_name='layer')   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/utils/generic_utils.py"", line 358, in deserialize_keras_object     list(custom_objects.items())))   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/functional.py"", line 669, in from_config     config, custom_objects)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/functional.py"", line 1285, in reconstruct_from_config     process_node(layer, node_data)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/functional.py"", line 1233, in process_node     output_tensors = layer(input_tensors, **kwargs)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/base_layer.py"", line 952, in __call__     input_list)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/base_layer.py"", line 1091, in _functional_construction_call     inputs, input_masks, args, kwargs)   )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,QW-Is-Here,TypeError: tensor_equals() missing 1 required positional argument: 'other' #47390," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.3  Custom code Yes  Trying to use  add_regularizers to model with self designed layer, but failed.  Standalone code to reproduce the issue   Relevant log output Traceback (most recent call last):   File """", line 1, in    File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/saving/model_config.py"", line 131, in model_from_json     return deserialize(config, custom_objects=custom_objects)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/layers/serialization.py"", line 177, in deserialize     printable_module_name='layer')   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/utils/generic_utils.py"", line 358, in deserialize_keras_object     list(custom_objects.items())))   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/functional.py"", line 669, in from_config     config, custom_objects)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/functional.py"", line 1285, in reconstruct_from_config     process_node(layer, node_data)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/functional.py"", line 1233, in process_node     output_tensors = layer(input_tensors, **kwargs)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/base_layer.py"", line 952, in __call__     input_list)   File ""/usr/local/lib/python3.6/distpackages/tensorflow/python/keras/engine/base_layer.py"", line 1091, in _functional_construction_call     inputs, input_masks, args, kwargs)   ",2023-10-25T04:44:53Z,stat:awaiting response type:bug stale TF 2.3,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62218,"Hi  , Could you please provide the imports for aliases like K and other imports as well to reproduce the reported error ?",Also try with latest versions since Tf2.3 is quiet older.,"> Hi  , >  > Could you please provide the imports for aliases like K and other imports as well to reproduce the reported error ? Sure I think this should be all, our current project is based on either 2.3 or 2.4. For the latest version, it may take too much effort to rebuild ","Hi  , I am sorry to say that TF2.4v are not supported now. I request you to upgrade to latest version. From the error stack , the function `tensor_not_equals()` should be passed with 2 arguments `self` and `other`. But during program call `tensor_not_equals()` received only one argument hence causing the error. It might be bug or may be it arising from the custom_objedct serialization. Could you please try with latest Tf versions and if issue still persists please submit a colab gist of same. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1153,"以下是一个github上的tensorflow下的一个issue, 标题是(Get XNNPACK Profiling Info in TfLite Example)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version master branch  Custom code No  OS platform and distribution Ubuntu 222.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When I run the example label_image in tensorflow lite with profiling enabled (see here for the setup) I get the following output:  I would like to get profiling info from XNNPACK.  I see that the reason is because the program bails out in xnn_get_runtime_profiling_info  because the profiling flags is set to false.  The stack trace is:  I would like to set the flags to enable profiling, but I am not sure how. Can somebody kindly explain me how to set the flag?   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,FabianSchuetze,Get XNNPACK Profiling Info in TfLite Example," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version master branch  Custom code No  OS platform and distribution Ubuntu 222.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When I run the example label_image in tensorflow lite with profiling enabled (see here for the setup) I get the following output:  I would like to get profiling info from XNNPACK.  I see that the reason is because the program bails out in xnn_get_runtime_profiling_info  because the profiling flags is set to false.  The stack trace is:  I would like to set the flags to enable profiling, but I am not sure how. Can somebody kindly explain me how to set the flag?   Standalone code to reproduce the issue   Relevant log output ",2023-10-24T16:39:45Z,awaiting review type:bug comp:lite comp:lite-examples comp:lite-xnnpack,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62214,"Hi   As per the documentation, to use XNNPACK delegate we have to set flag `x 1`. Have you tried this flag along with profiling and see if XNNPACK profiling information is visible? Thanks.","Thanks,   for your reply.  Yes, I have and I still get the same result.  Interestingly, I can get very good profiling information for xnnpack for the benchmarking app. ","Hi , It does not seem that the flag is getting passed down to the delegate, but you're saying that you are getting good profiling information on the benchmarking app? (I'm assuming you meant benchmark_model??) can you give me the exact commands you are using there so that I can see how it passes down the flag in that instance. Thanks for your help.",I have a fix for this. I will update once the fix is merged.,"Thanks a lot,   and please apologize for the delayed response. ","Hi , the fix is comitted: 535fd94, can you rerun your test on master or nightly and let us know if your issue is resolved? Thanks.","Thanks for working on this,  .  It almost resolved the issue. There is no entry for   Which is great. However, there is still no profiling active.  With the build command in the docs, the `NoopProfiler` is enabled in the example.   To get informative profiling output, I had to circumvent the `ifdefs` in profiler.h  I say ""circumvent"",  because I set the ifdef myself in the code as I didn't know how to pass that flag with a Bazel build invocation.  (Strictly speaking, the issue is closed, however. The missing profile information applies to all delegates not to xnnpack anymore.)","Hi , thanks for the feedback, just FYI you can build it with DTFLITE_PROFILING_ENABLED, to turn the def on ... I'll work on completing the original intent of that API though.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/103 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
916,"以下是一个github上的tensorflow下的一个issue, 标题是(Different behaviors of raw_ops.Expm1 can be observed when jitcompiled=true. )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? In TensorFlow, enabling jitcompiled results in inconsistent behavior of raw_ops.Expm1.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different behaviors of raw_ops.Expm1 can be observed when jitcompiled=true. ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? In TensorFlow, enabling jitcompiled results in inconsistent behavior of raw_ops.Expm1.  Standalone code to reproduce the issue   Relevant log output ",2023-10-24T14:53:50Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62211,", I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here.",I did not observe any inconsistencies when `jit_compile = True` and `jit_compile = False`.  It is failing in both the cases and resulting similar outputs. Attaching the Gist here for reference. ,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1035,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/eager:forwardprop_test test fails on AARCH64)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 17.0.0  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? Since Eigen was updated, the unit test //tensorflow/python/eager:forwardprop_test now fails. Eigen was updated by https://github.com/tensorflow/tensorflow/commit/57e6377cf9879e33f3612f1ffd3619b6513e5296 It looks like this commit in Eigen is the problem. https://gitlab.com/libeigen/eigen//commit/81b48065ea673cd352d11ef9b6a3d86778ac962d This seems to only affect AARCH64 and not x86.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,//tensorflow/python/eager:forwardprop_test test fails on AARCH64," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 17.0.0  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? Since Eigen was updated, the unit test //tensorflow/python/eager:forwardprop_test now fails. Eigen was updated by https://github.com/tensorflow/tensorflow/commit/57e6377cf9879e33f3612f1ffd3619b6513e5296 It looks like this commit in Eigen is the problem. https://gitlab.com/libeigen/eigen//commit/81b48065ea673cd352d11ef9b6a3d86778ac962d This seems to only affect AARCH64 and not x86.  Standalone code to reproduce the issue   Relevant log output ",2023-10-24T10:38:38Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62208,Issue raised on Eigen https://gitlab.com/libeigen/eigen//issues/2738,Are you satisfied with the resolution of your issue? Yes No
927,"以下是一个github上的tensorflow下的一个issue, 标题是(Different behaviors of raw_ops.Cos + raw_ops.Asinh on jitcompiled=true.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? In TensorFlow, enabling jitcompiled results in inconsistent behavior of raw_ops.Cos and raw_ops.Asinh.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different behaviors of raw_ops.Cos + raw_ops.Asinh on jitcompiled=true.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? In TensorFlow, enabling jitcompiled results in inconsistent behavior of raw_ops.Cos and raw_ops.Asinh.  Standalone code to reproduce the issue   Relevant log output ",2023-10-24T09:44:43Z,stat:awaiting response type:bug stale comp:ops TF2.14,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62207,", I was able to reproduce the issue on tensorflow v2.14 and tfnightly. Kindly find the gist of it here.","I observed the failure  is happening only when `jit_compile = True`, and it is under the expected `rtol` and `atol` when `jit_compile = False`. Although, when `jit_compile` is set to `True`, the max difference was observed near `0.002/0.003` which is smaller in number and does not show the significant impact.  Attached the Gist here for reference. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
919,"以下是一个github上的tensorflow下的一个issue, 标题是(Different behaviors of raw_ops.Sigmoid can be observed when jitcompiled=true.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? In TensorFlow, enabling jitcompiled results in inconsistent behavior of raw_ops.Sigmoid.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,zoux1a,Different behaviors of raw_ops.Sigmoid can be observed when jitcompiled=true.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.3 LTS (x86_64)  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory GPU 0: NVIDIA GeForce RTX 2070 GPU 1: NVIDIA GeForce RTX 2070 GPU 2: NVIDIA GeForce RTX 2070 GPU 3: NVIDIA GeForce RTX 2070  Current behavior? In TensorFlow, enabling jitcompiled results in inconsistent behavior of raw_ops.Sigmoid.  Standalone code to reproduce the issue   Relevant log output ",2023-10-24T09:28:06Z,stat:awaiting response type:bug stale comp:xla TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62206,"Hi  , I have replicated the reported behaviour. With jit_compile=True the results seems not in the precision level of `rtol=0.001`. If we change `rtol=0.01` then the results are same. One more observation the behaviour seems from `eager = False`. With eager execution it works fine with given tolerances also. Please refer attached gist.",I believe the results in eager mode and XLAcompiled mode should be consistent. Will this bug be fixed in the future?,"Hi  , For the Sigmoid Op, `bfloat16` dtype is not supported for XLAGPU setup as per this source. Could you please cross check and confirm.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi Go , I have tested the code with Tf2.14v and the difference is related to precision only which happens due to XLA internal fusions and conversions and XLA uses FP32 precision by default. To check that , I have printed the `reduce_sum` of results which are same for both which is `448` for an experiment. This indicates the results are same but only precision differences with XLA which is expected. Please refer attached gist. Thanks!"
1185,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.random.normal() causes RAM usage to keep growing)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution macOS Venture 13.1 (22C65)  Mobile device _No response_  Python version 3.8.3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? **Issue**  I'm getting what looks like a memory leak from running tf.random.normal as below, in eager mode.  I have not encountered this issue with others versions, e.g. 2.12.1 **Context**  I'm running RL algorithms using a TFaddon NoisyDense layer, which exposes a function that does the below random sampling. Since it's being executed millions of times, it causes exploding RAM. **Notes** Wrapping the random sampling inside a function decorated with tf.function seems to avoid the issue.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Djoren,tf.random.normal() causes RAM usage to keep growing," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution macOS Venture 13.1 (22C65)  Mobile device _No response_  Python version 3.8.3  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? **Issue**  I'm getting what looks like a memory leak from running tf.random.normal as below, in eager mode.  I have not encountered this issue with others versions, e.g. 2.12.1 **Context**  I'm running RL algorithms using a TFaddon NoisyDense layer, which exposes a function that does the below random sampling. Since it's being executed millions of times, it causes exploding RAM. **Notes** Wrapping the random sampling inside a function decorated with tf.function seems to avoid the issue.  Standalone code to reproduce the issue   Relevant log output ",2023-10-24T04:06:40Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62203,"Try `K.clear_session()` to delete unused graph parts. It might also be that the garbage collector will kick in further along the line,",", I tried to execute the above mentioned code on tensorflow v2.14 & it was executed without any error and also observed that the RAM usage is also not growing as mentioned. Kindly find the gist of it here. Thank you!"," I am getting the problem with python 3.11, but not 3.10 (which is the version in your gist).",", I tried to execute the mentioned code on the Linux environment with Tensorflow 2.16.1 and python 3.11 and couldn't find the memory leakage with the tf.random.normal(). Kindly find the screenshot for the reference. !Screenshot 20240611 6 13 31 PM",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1001,"以下是一个github上的tensorflow下的一个issue, 标题是(Error when building from source: AddKernelActivityEvent<TF_CUPTI_HAS_CHANNEL_ID> ‘TF_CUPTI_HAS_CHANNEL_ID’ was not declared in this scope)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version 3.8.10  Bazel version 6.1.0  GCC/compiler version 9.4.0  CUDA/cuDNN version Cuda=11.4.152, cuDNN=8.9.5  GPU model and memory GeForce RTX 2070 Rev. A  Current behavior? I am trying to install tensorflow from source. I am following this tutorial. I have the cuDNN and the Cuda Toolkit installed, and the following configuration:   Then doing: `bazel build config=opt action_env=PATH c opt //tensorflow/tools/pip_package:build_pip_package` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Lip651,Error when building from source: AddKernelActivityEvent<TF_CUPTI_HAS_CHANNEL_ID> ‘TF_CUPTI_HAS_CHANNEL_ID’ was not declared in this scope," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version 3.8.10  Bazel version 6.1.0  GCC/compiler version 9.4.0  CUDA/cuDNN version Cuda=11.4.152, cuDNN=8.9.5  GPU model and memory GeForce RTX 2070 Rev. A  Current behavior? I am trying to install tensorflow from source. I am following this tutorial. I have the cuDNN and the Cuda Toolkit installed, and the following configuration:   Then doing: `bazel build config=opt action_env=PATH c opt //tensorflow/tools/pip_package:build_pip_package` ",2023-10-23T18:04:55Z,type:build/install,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62200,Are you satisfied with the resolution of your issue? Yes No,I took a more stable branch and it worked 
1975,"以下是一个github上的tensorflow下的一个issue, 标题是(Loading cudNN in docker image where tensorflow is installed via pip returns `Error: libnvrtc.so: cannot open shared object file: No such file or directory`)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8/8.7  GPU model and memory NVIDIA L40, 46BG  Current behavior? We are building a Docker image that is running an Ubuntu 22.04. The host machine is also Ubuntu 22.04. We have chosen to not use the prebuilt tensorflow Docker image. We are trying to install tensorflow via pip in the docker image, and at the first glance it seems to work, as `import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))` works perfectly fine and prints something along the lines of `tf.Tensor(163.40398, shape=(), dtype=float32)`. However, when we try to load cudNN by running the keras `Model.train_on_batch` method we get the error `Could not load library libcudnn_cnn_infer.so.8. Error: libnvrtc.so: cannot open shared object file: No such file or directory`. Full stack trace is in the ""Relevant log ouput"" cell. If we install cuda in the docker image by running the following commands it works though. But we would prefer not installing cuda directly and only through pip.  `nvidiasmi` prints  `pip freeze` gives us these dependencies (some dependencies stripped):  To me it seems like installing tensorflow via `pip install tensorflow[andcuda]==2.14.0` doesn't include the libnvrtc.so file? Or maybe it's some error related to keras?  Standalone code to reproduce the issue  shell 20231023 05:58:21.25199)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,maltel,Loading cudNN in docker image where tensorflow is installed via pip returns `Error: libnvrtc.so: cannot open shared object file: No such file or directory`," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8/8.7  GPU model and memory NVIDIA L40, 46BG  Current behavior? We are building a Docker image that is running an Ubuntu 22.04. The host machine is also Ubuntu 22.04. We have chosen to not use the prebuilt tensorflow Docker image. We are trying to install tensorflow via pip in the docker image, and at the first glance it seems to work, as `import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))` works perfectly fine and prints something along the lines of `tf.Tensor(163.40398, shape=(), dtype=float32)`. However, when we try to load cudNN by running the keras `Model.train_on_batch` method we get the error `Could not load library libcudnn_cnn_infer.so.8. Error: libnvrtc.so: cannot open shared object file: No such file or directory`. Full stack trace is in the ""Relevant log ouput"" cell. If we install cuda in the docker image by running the following commands it works though. But we would prefer not installing cuda directly and only through pip.  `nvidiasmi` prints  `pip freeze` gives us these dependencies (some dependencies stripped):  To me it seems like installing tensorflow via `pip install tensorflow[andcuda]==2.14.0` doesn't include the libnvrtc.so file? Or maybe it's some error related to keras?  Standalone code to reproduce the issue  shell 20231023 05:58:21.25199",2023-10-23T06:43:35Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale subtype: ubuntu/linux TF2.14,closed,0,18,https://github.com/tensorflow/tensorflow/issues/62194,"I don't have a solution but just wanted to mention I'm having the same issue with a local install of tensorflow 2.14 via ""pip install tensorflow[andcuda]"" on a Debian 12 machine. The solution does seem to be to system install CUDA, but that's not ideal like you say if tensorflow is supposed to be able to install CUDA on it's own. At the very least the current instructions on the install tensorflow with pip page are not fully correct at the moment with this issue in place.","Also seeing this issue. On a system with only the driver installed, `libnvrtc.so` can't be found.  Edit: Just to add some additional details about my system: Ubuntu 22.04 with nvidia driver 510 installed using the installer runfile. This is a secure environment that doesn't have access to the nvidia repositories. According to the 2.14.0 release notes, this driver is all that should be required to install TensorFlow, but it doesn't work due to missing  `libnvrtc.so`.  Installing CUDA toolkit manually (also using runfile installer) does fix the issue. So I suspect either the docs need updated to say there are additional dependencies or this is a bug where `nvrtc` is not being installed correctly. "," It seems like NVIDIA compiler runtime (NVRTC) is not installed in your Docker image. To install the prebuilt image, run the following command:  Please let us know if it helps? Thank you!","Same issue on WSL2 Ubuntu 22.04 on Windows 10 using installation with `python3 m pip install tensorflow[andcuda]` On WSL2 Ubuntu 20.04, after upgrading python to 3.10 I did not have this issue on the same Window 10 computer.",  Thank you for your response here! Could you please file a new ticket for the issue you are facing? Thank you!," I am not using the tensorflow docker image, I am using a custom one (See dockerfile above) so I am not sure pulling the tensorflow docker image is useful. Besides, based on the other comments here it seems like its not an issue with docker, but rather an issue with Ubuntu when only the driver installed. I don't know what a new ticket is. Is it the same as a new issue?  :) ",  Thanks for your above comment. Sorry for the mistake! I was asking  to create a new ticket for WSL2 issue.  We will dig more into your issue and get back to you soon. Thank you!, Could you try to install NVRTC manually. This can be done by adding the following lines to your Dockerfile:   Could you please have a look into this issue! Thank you!," I tried installing it manually, but was not successful unfortunately. The package was not found, this is the output;  Am I doing something wrong? I found a package called libnvrtc11.2, but it is not the correct version I believe... At least it didnt solve the issue. https://packages.debian.org/bullseye/libs/libnvrtc11.2","There are several different things going on in this issue's comment history.  As to the latter part, the `nvrtc` package is actually called `cudanvrtcXY` for whichever specific CUDA X.Y you have (see e.g. https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/ ).  Regarding the original post, the loading of libnvrtc.so instead of libnvrtc.so.XX (via its SONAME) was a bug in that particular build of cuDNN  this probably will mean you need not only the cudanvrtc118 package but also cudanvrtcdev118, so that the libnvrtc.so symlink is made available. HTH","  for https://github.com/tensorflow/tensorflow/issues/62194issuecomment1781418833 , you might want to see https://github.com/tensorflow/tensorflow/issues/61986 .  I think your issue is more likely related to that one than to this one.",Thanks for the reply ! Does that mean there is no way of installing tensorflow and cuda dependencies through pip only for that particular version? (If the TF team doesn't add the cudanvrtcdev118 package?),"Based on the comments in ticket CC(tensorrt==8.5.3.1 from [andcuda] not available in Python 3.11) I tried the command mentioned there:  `python3 m pip install ""tensorflow[andcuda]==2.15"" extraindexurl https://pypi.nvidia.com`  and my error `Could not load library libcudnn_cnn_infer.so.8. Error: libnvrtc.so: cannot open shared object file: No such file or directory` didn't occur. So far so good. My steps: 1. Complete new WSL2 image 2. sudo apt update 3. sudo apt upgrade 4. sudo apt install python3pip 5. python3 m pip install upgrade pip 6. python3 m pip install ""tensorflow[andcuda]==2.15"" extraindexurl https://pypi.nvidia.com 7. pip install ignoreinstalled nocachedir r requirements_win.txt 8. ran my keras / tensorflow / mflow interference model","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.","Later versions have solved this problem. At this moment we are using 2.17. Speaking for myself, this ticket can be closed.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1040,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.Model with nested dictionary inputs fails to serialize/deserialize)， 内容是 (Info:  Issue type: **Bug**  Have you reproduced the bug with TensorFlow Nightly? No  Source: binary  TensorFlow version: 2.14.0  Custom code: No  OS platform and distribution: macOS 13.6  Python version: 3.11  CUDA/cuDNN version: none  Current behavior? When trying to serialize/deserialize a `tf.keras.Model` nested input shapes cause an error. Note that this has been observed many years back in CC(tf.keras.Model with nested dictionary inputs fails to serialize/deserialize), which was closed because their MVP included a `tf.keras.Sequential` which was deemed as not supported. However, the issue has nothing to do with `tf.keras.Sequential` at all, and instead lies purely in the deserialisation code of keras.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,burnpanck,tf.keras.Model with nested dictionary inputs fails to serialize/deserialize,"Info:  Issue type: **Bug**  Have you reproduced the bug with TensorFlow Nightly? No  Source: binary  TensorFlow version: 2.14.0  Custom code: No  OS platform and distribution: macOS 13.6  Python version: 3.11  CUDA/cuDNN version: none  Current behavior? When trying to serialize/deserialize a `tf.keras.Model` nested input shapes cause an error. Note that this has been observed many years back in CC(tf.keras.Model with nested dictionary inputs fails to serialize/deserialize), which was closed because their MVP included a `tf.keras.Sequential` which was deemed as not supported. However, the issue has nothing to do with `tf.keras.Sequential` at all, and instead lies purely in the deserialisation code of keras.  Standalone code to reproduce the issue   Relevant log output ",2023-10-21T14:50:57Z,stat:awaiting response type:bug stale comp:keras TF2.14,closed,0,11,https://github.com/tensorflow/tensorflow/issues/62192,", Thank you for reporting the issue. We are currently investigating the issue, and I kindly request some time to thoroughly analyze the problem in order to offer a resolution. Thank you!",", I was able to reproduce the issue on tensorflow v2.14, v2.13 and tfnightly. Kindly find the gist of it here.","Hi, Going forward `Keras` with the new multi backend support in `Keras 3` it will no longer support deeply nested inputs/outputs more than 1 level in `Model()`. You would have to provide the inputs/outputs in the same level as shown below. ","What a pity. Given that one can always create a wrapper around model calls that serialises and deserialises nested dicts into a flat dict or even a list, obviously there is no fundamental reason why this could not be supported. In fact, if I remember correctly, that's what I did during TF 1 days. It's just that now, we have to again decide between writing lots of unnecessary boilerplate or having nonexpressive APIs. Where do I post a feature request for TF 3?",For `Keras 3` you can post the issue in https://github.com/kerasteam/keras/issues and close the issue here. ,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Ok, if TF really doesn't want to support nested dictionaries in some or all of their APIs, then that should be documented, and ideally it should produce actionable error messages. Right now, the TF documentation explicitly states that the `.keras` format is the chosen method, but it doesn't support all features previous formats did. So this is a breaking change, and should be documented very explicitly. I thus don't think that this issue can be closed, whether or not the feature is going to be supported. It is either an implementation bug or a documentation bug.",It is documented here and it will be available in keras.io soon. https://github.com/kerasteam/kerasio/blob/be3791ecde06d8bae22c885868983ddaf1af2cd7/guides/migrate_to_keras_3.pyL203L245,"Ok, that makes sense  thanks for pointer."
1860,"以下是一个github上的tensorflow下的一个issue, 标题是(can't install @tensorflow/tf-node on npm)， 内容是 (please help. i can't install /tfnode on my project node.js i have python 3.12, node.js 18 and npm ver. 10.2.1 but i can install /tfjs this is the error: npm WARN cleanup Failed to remove some directories [ npm WARN cleanup   [ npm WARN cleanup     'D:\\xampp8\\htdocs\\testnodejs\\node_modules\\', npm WARN cleanup     [Error: EPERM: operation not permitted, rmdir 'D:\xampp8\htdocs\testnodejs\node_modules\\nodepregyp\node_modules\agentbase'] { npm WARN cleanup       errno: 4048, npm WARN cleanup       code: 'EPERM', npm WARN cleanup       syscall: 'rmdir', npm WARN cleanup       path: 'D:\\xampp8\\htdocs\\testnodejs\\node_modules\\\\nodepregyp\\node_modules\\agentbase' npm WARN cleanup     } npm WARN cleanup   ] npm WARN cleanup ] npm ERR! code 1 npm ERR! path D:\xampp8\htdocs\testnodejs\node_modules\\tfjsnode npm ERR! command failed npm ERR! command C:\WINDOWS\system32\cmd.exe /d /s /c node scripts/install.js npm ERR! CPUwindows4.12.0.zip npm ERR! https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpuwindowsx86_642.9.1.zip npm ERR! nodepregyp install failed with error: Error: Command failed: nodepregyp install fallbacktobuild npm ERR! nodepregyp info it worked if it ends with ok npm ERR! nodepregyp info using nodepregyp.0.9 npm ERR! nodepregyp info using node.18.2  x64 npm ERR! gyp info find Python using Python version 3.12.0 found at ""C:\Program Files\Python312\python.exe"" npm ERR! gyp http GET https://nodejs.org/download/release/v18.18.2/nodev18.18.2headers.tar.gz npm ERR! gyp http 200 https://nodejs.org/download/release/v18.18.2/nodev18.18.2headers.tar.gz npm ERR! gyp http GET https://n)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,h312ry,can't install @tensorflow/tf-node on npm,"please help. i can't install /tfnode on my project node.js i have python 3.12, node.js 18 and npm ver. 10.2.1 but i can install /tfjs this is the error: npm WARN cleanup Failed to remove some directories [ npm WARN cleanup   [ npm WARN cleanup     'D:\\xampp8\\htdocs\\testnodejs\\node_modules\\', npm WARN cleanup     [Error: EPERM: operation not permitted, rmdir 'D:\xampp8\htdocs\testnodejs\node_modules\\nodepregyp\node_modules\agentbase'] { npm WARN cleanup       errno: 4048, npm WARN cleanup       code: 'EPERM', npm WARN cleanup       syscall: 'rmdir', npm WARN cleanup       path: 'D:\\xampp8\\htdocs\\testnodejs\\node_modules\\\\nodepregyp\\node_modules\\agentbase' npm WARN cleanup     } npm WARN cleanup   ] npm WARN cleanup ] npm ERR! code 1 npm ERR! path D:\xampp8\htdocs\testnodejs\node_modules\\tfjsnode npm ERR! command failed npm ERR! command C:\WINDOWS\system32\cmd.exe /d /s /c node scripts/install.js npm ERR! CPUwindows4.12.0.zip npm ERR! https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpuwindowsx86_642.9.1.zip npm ERR! nodepregyp install failed with error: Error: Command failed: nodepregyp install fallbacktobuild npm ERR! nodepregyp info it worked if it ends with ok npm ERR! nodepregyp info using nodepregyp.0.9 npm ERR! nodepregyp info using node.18.2  x64 npm ERR! gyp info find Python using Python version 3.12.0 found at ""C:\Program Files\Python312\python.exe"" npm ERR! gyp http GET https://nodejs.org/download/release/v18.18.2/nodev18.18.2headers.tar.gz npm ERR! gyp http 200 https://nodejs.org/download/release/v18.18.2/nodev18.18.2headers.tar.gz npm ERR! gyp http GET https://n",2023-10-20T16:23:26Z,,closed,0,1,https://github.com/tensorflow/tensorflow/issues/62188,"This should be in tensorflowjs repository, not here"
882,"以下是一个github上的tensorflow下的一个issue, 标题是(import keras_cv results in import error for keras_utils)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.14  Custom code No  OS platform and distribution Linux  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Running StableDiffusion Finetuning colab example throws the error  https://colab.research.google.com/github/kerasteam/kerasio/blob/master/examples/generative/ipynb/finetune_stable_diffusion.ipynb  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",finetuning,ajayaraman,import keras_cv results in import error for keras_utils, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.14  Custom code No  OS platform and distribution Linux  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Running StableDiffusion Finetuning colab example throws the error  https://colab.research.google.com/github/kerasteam/kerasio/blob/master/examples/generative/ipynb/finetune_stable_diffusion.ipynb  Standalone code to reproduce the issue   Relevant log output ,2023-10-20T09:15:01Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62182,"Hello, ! Sorry for the late response! Please ensure that the version of 'keras_cv' you're using is compatible with your Keras version. If you're using an older version of 'keras_cv', consider upgrading to a newer version. Also please check the Python you're using as it requires Python version 3.6 or higher. 'keras_cv' is not compatible with Python 2.7. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1213,"以下是一个github上的tensorflow下的一个issue, 标题是(TypeError (Missing required positional argument) when using py_function)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Simply running the example from the py_function docs (https://www.tensorflow.org/api_docs/python/tf/py_function) results in a TypeError. I am seeing this on my local install but also in a fresh colab notebook, so I don't think it's anything to do with my installation. I am seeing similar behaviour with `numpy_function`, and when trying to use `py_function` in the other ways described in the docs I would expect the snippet to run without exceptions. I can't find any way of using `py_function`, or any workarounds.  Standalone code to reproduce the issue )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,antoche,TypeError (Missing required positional argument) when using py_function," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Simply running the example from the py_function docs (https://www.tensorflow.org/api_docs/python/tf/py_function) results in a TypeError. I am seeing this on my local install but also in a fresh colab notebook, so I don't think it's anything to do with my installation. I am seeing similar behaviour with `numpy_function`, and when trying to use `py_function` in the other ways described in the docs I would expect the snippet to run without exceptions. I can't find any way of using `py_function`, or any workarounds.  Standalone code to reproduce the issue ",2023-10-19T23:01:28Z,stat:awaiting response type:bug stale comp:core TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62180,"Hi  , Thanks for reporting. The issue exists in TF2.13v and got fixed in Tf2.14V onwards. Please refer to attached gist. Thank you!",I'm getting the issue in 2.12.0 as well. When was it introduced? Is there a workaround?,"Hi  , As per this commit, `py_function` was made to use as decorator from Tf2.14 onwards.Not sure this is a feature implemented in Tf2.14 onwards. Please use TF>=2.14 versions to avoid this error. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1179,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite CNN model quantization error)， 内容是 ( 1. System information  OS Platform and Distribution : Ubuntu 22.04.3 LTS  TensorFlow installation: pip install tensorflow (virtual env: venv)  TensorFlow library: pip package > tensorflow 2.14.0  2. Code Colab to build the models and reproduce the issue: Reproduce the issue  3. Failure after conversion Hi, I'm having an issue when trying to use signatures of quantized tflite CNN model. The conversion and quantization go well, but when I try to use infer or fine_tune signatures, I get the following error which seems to be related to the quantization process: RuntimeError: tensorflow/lite/kernels/conv.cc:374 affine_quantization>zero_point>data[i] != 0 (24 != 0)Node number 21 (CONV_2D) failed to prepare.tensorflow/lite/kernels/conv.cc:374 affine_quantization>zero_point>data[i] != 0 (24 != 0)Node number 41 (CONV_2D) failed to prepare. **Note**: I don't get this error with the exact same code using linear model instead of CNN. Thanks for your help)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Marouan-st,TFLite CNN model quantization error," 1. System information  OS Platform and Distribution : Ubuntu 22.04.3 LTS  TensorFlow installation: pip install tensorflow (virtual env: venv)  TensorFlow library: pip package > tensorflow 2.14.0  2. Code Colab to build the models and reproduce the issue: Reproduce the issue  3. Failure after conversion Hi, I'm having an issue when trying to use signatures of quantized tflite CNN model. The conversion and quantization go well, but when I try to use infer or fine_tune signatures, I get the following error which seems to be related to the quantization process: RuntimeError: tensorflow/lite/kernels/conv.cc:374 affine_quantization>zero_point>data[i] != 0 (24 != 0)Node number 21 (CONV_2D) failed to prepare.tensorflow/lite/kernels/conv.cc:374 affine_quantization>zero_point>data[i] != 0 (24 != 0)Node number 41 (CONV_2D) failed to prepare. **Note**: I don't get this error with the exact same code using linear model instead of CNN. Thanks for your help",2023-10-19T09:39:50Z,stat:awaiting tensorflower type:bug TFLiteConverter TF2.14,open,1,6,https://github.com/tensorflow/tensorflow/issues/62171,"+1  I was having the same issue last week with CONV_2D op after quantization, any hints on the issue are appreciated.    Thank you,","Hello, st! The provided drive link is not accessible to me. Could you please provide the access or share the colab gist to replicate the issue reported here.  Thank you! ","> Hello, st! The provided drive link is not accessible to me. Could you please provide the access or share the colab gist to replicate the issue reported here. Thank you! Oh I'm sorry... Access should be provided now.","Hi, I have the same issue and can produce it with only a few lines of code.  The call `interpreter.allocate_tensors()` produces: `RuntimeError: tensorflow/lite/kernels/conv.cc:374 affine_quantization>zero_point>data[i] != 0 (128 != 0)Node number 4 (CONV_2D) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.` When I don't use  no error occours. Any ideas what to do?",I was able to reproduce the issue. Please find this gist. The zero point calibration for the filters seems to be an issue here.  Could you please look into this issue? Thanks.,I was able to reproduce w/ the same gist above.  can you please take a look? Thanks.
889,"以下是一个github上的tensorflow下的一个issue, 标题是(Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10175 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tfgpu 2.4.0  Custom code Yes  OS platform and distribution Ubuntu 18.04  Mobile device Ubuntu 18.04  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.0 8.0  GPU model and memory T4 15G  Current behavior? I deploment an unet like model and use it to matting, why it take so much memory  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,9527-csroad,"Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10175 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tfgpu 2.4.0  Custom code Yes  OS platform and distribution Ubuntu 18.04  Mobile device Ubuntu 18.04  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.0 8.0  GPU model and memory T4 15G  Current behavior? I deploment an unet like model and use it to matting, why it take so much memory  Standalone code to reproduce the issue   Relevant log output ",2023-10-19T09:36:17Z,stat:awaiting response type:bug comp:gpu TF 2.4,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62170,"Hello, csroad! To use the Tesla T4 GPU in TensorFlow, please specify the `device:GPU device` type when creating a model or running a session with latest TF version as you are using an older version which is not actively supported.  Thank you!","Thanks for your reply,  . Which version should I install? You can see that no matter which version I installed, tensorflow always take so much GPU memory.   ","Hi csroad , Could you please confirm the exact problem? As per my understanding here you have a 15 GB GPU but while code execution you find that only 10.175GB is visible. Is that what you want report? I can also see Pytorch version also indeed installed here.It seems your environment has too many dependencies that is taking more memory resources ?","Hello  , My question is why it allocated so much GPU memory?  You can find it take around 10GB while it not need so much memory（I'm not train a model but deploy a model).  I deployed some models and they usually use 3GB  6GB cuda memory,  but now, the procedure take all of the rest of the cuda memory.","> python > 20231106 15:31:55.308559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 11456 MB memory:  > device: 0, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5 >  Hi csroad , If you are referring to this log then its just printing the GPU device and its available memory for process. It's not locking the memory though.","If so, I'm sorry to waste your time. I have end this project long time, and I will pay attention to this next time. Thanks for your patience reply. Best regard.",Are you satisfied with the resolution of your issue? Yes No
839,"以下是一个github上的tensorflow下的一个issue, 标题是(null pointer dereference in exp)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 18.04.6  Mobile device _No response_  Python version Python 3.8.3  Bazel version bazel 5.3.0  GCC/compiler version gcc 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? A maliciously constructed `exp` operator model leads to `op_context.input` being empty, causing a null pointer dereference in the `Prepare` function.  exp.zip  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SiriusHsh,null pointer dereference in exp," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 18.04.6  Mobile device _No response_  Python version Python 3.8.3  Bazel version bazel 5.3.0  GCC/compiler version gcc 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? A maliciously constructed `exp` operator model leads to `op_context.input` being empty, causing a null pointer dereference in the `Prepare` function.  exp.zip  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-19T03:18:32Z,stat:awaiting tensorflower type:bug comp:lite TF2.14,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62163,I was able to reproduce this issue on r2.14.   Could you please look into this issue? Thanks.,"I was able to reproduce on nightly:  , can you please take a look. Thanks.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/114 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1023,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Lite - CMake build installable package fail)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code No  OS platform and distribution Mac Ventura  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When following https://www.tensorflow.org/lite/guide/build_cmakebuild_installable_package to build TensorFlow Lite with CMake, using the flag `DTFLITE_ENABLE_INSTALL=ON`, a CMake error happens, saying that `the Target ml_dtypes INTERFACE_INCLUDE_DIRECTORIES property contains path: which is prefixed in the build directory.`  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,algat,TensorFlow Lite - CMake build installable package fail," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14  Custom code No  OS platform and distribution Mac Ventura  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When following https://www.tensorflow.org/lite/guide/build_cmakebuild_installable_package to build TensorFlow Lite with CMake, using the flag `DTFLITE_ENABLE_INSTALL=ON`, a CMake error happens, saying that `the Target ml_dtypes INTERFACE_INCLUDE_DIRECTORIES property contains path: which is prefixed in the build directory.`  Standalone code to reproduce the issue   Relevant log output ",2023-10-18T08:25:53Z,stat:awaiting response type:build/install stale comp:lite subtype:macOS TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62147," There could be the following reasons for this specific build failure such as; a. The dependencies would be missing  the libraries such as Flatbuffers, and XNNPACK should be installed properly b. Incompatible dependencies  the version would be mismatched sometimes which will cause this failure c. CMake configuration  The right version of CMake along  with configuration set up for this should be correct. By seeing your error log we are assuming that the CMake build system is trying to include the header file and to fix this error, you need to set the `INTERFACE_INCLUDE_DIRECTORIES` property to an absolute path.  Hope it helps? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,I confirm that compilation to an installable package on Ubuntu 23.10 is not possible.  produces the following: ,  This issue is effectively a duplicate of CC(Tensorflow Lite: Build installable package fails) . Can we close this issue here as it is already being tracked there?  Thank You,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
835,"以下是一个github上的tensorflow下的一个issue, 标题是(Trying to process RBG images and use RandomContrast: LookupError: gradient registry has no entry for: AdjustContrastv2)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution google collaboration  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory T4  Current behavior? I see an error when I add RandomContrast layer into the model. Otherwise, it works fine.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,RangaSamudrala,Trying to process RBG images and use RandomContrast: LookupError: gradient registry has no entry for: AdjustContrastv2," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution google collaboration  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory T4  Current behavior? I see an error when I add RandomContrast layer into the model. Otherwise, it works fine.  Standalone code to reproduce the issue   Relevant log output ",2023-10-17T21:50:07Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62145,"Hi  , The `AdjustContrastV2` Op has no gradient registered. Hence you are getting the error. You can have a look into source here to find the list of Ops and  have gradient support or not.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
690,"以下是一个github上的tensorflow下的一个issue, 标题是(fix cos op for  nnapi delegate)， 内容是 (fix CC(NNAPI delegate crashes on kTfLiteBuiltinCos in TF Lite 2.14) Still convert cos to sin with $cos(x) = sin(\frac{\pi}{2}  x)$ But since input tensor is not available when `TransformCosIntoSupportedOps()` is called, we should do `sub` then `sin` instead of manipulating the input tensor as suggested by in CC(NNAPI delegate crashes on kTfLiteBuiltinCos in TF Lite 2.14)  Tested on Pixel 8 Pro. When tested with `nnapi_delegate_test` built with   before this PR.  after )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,freedomtan,fix cos op for  nnapi delegate,"fix CC(NNAPI delegate crashes on kTfLiteBuiltinCos in TF Lite 2.14) Still convert cos to sin with $cos(x) = sin(\frac{\pi}{2}  x)$ But since input tensor is not available when `TransformCosIntoSupportedOps()` is called, we should do `sub` then `sin` instead of manipulating the input tensor as suggested by in CC(NNAPI delegate crashes on kTfLiteBuiltinCos in TF Lite 2.14)  Tested on Pixel 8 Pro. When tested with `nnapi_delegate_test` built with   before this PR.  after ",2023-10-17T14:25:32Z,awaiting review comp:lite ready to pull size:S,closed,0,0,https://github.com/tensorflow/tensorflow/issues/62139
1261,"以下是一个github上的tensorflow下的一个issue, 标题是(relu provide wrong / inconsistent result for tensorflow-macos   2.14.0.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14  Custom code No  OS platform and distribution macOS 14.0   Mobile device _No response_  Python version 3.11 / 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Apple m1 16GB  Current behavior? I was playing with https://www.tensorflow.org/tutorials/generative/autoencoder and I found the results of autoencoder were completely inconsistent between when I run this on **google colab** and my own **m1 macbook**. Concrete problems are  1. Result image of first AE ( basic autoencoder) doesn't make sense at all.   2. Displayed loss value is quite different from when I test after training. (See below sc) local   colab  3. When I use `elu` instead of `relu`, problems were solved.    Is `relu` not recommended for tensorflormacos right now?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MKrbm,relu provide wrong / inconsistent result for tensorflow-macos   2.14.0.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14  Custom code No  OS platform and distribution macOS 14.0   Mobile device _No response_  Python version 3.11 / 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Apple m1 16GB  Current behavior? I was playing with https://www.tensorflow.org/tutorials/generative/autoencoder and I found the results of autoencoder were completely inconsistent between when I run this on **google colab** and my own **m1 macbook**. Concrete problems are  1. Result image of first AE ( basic autoencoder) doesn't make sense at all.   2. Displayed loss value is quite different from when I test after training. (See below sc) local   colab  3. When I use `elu` instead of `relu`, problems were solved.    Is `relu` not recommended for tensorflormacos right now?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-17T12:49:02Z,stat:awaiting response type:bug stale comp:apis subtype:macOS TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62137,"Hi  , Thanks for reaching us. `tensorflowmacos` is built and maintained by Apple. I hope you have followed the metal plugin instructions here. As this works fine on Colab(Linux) and the issue persists on only Mac M1, I request you to raise an issue with apple developer forum here.  , Do you have any pointers here?","  Yes, I indeed followd the instructions.  I will raisean issue there as you suggested. Thank you.","Hi  , COuld you checked the issue with latest Keras3 versions either 3.0.4 or kerasnightly and let us know the result?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1897,"以下是一个github上的tensorflow下的一个issue, 标题是(Not able to get TFlite Model Maker Object Detector to produce expected output)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WSL Linux Ubuntu 20.04 (although I've also tried on Linux Ubuntu 22.04)  TensorFlow installation (pip package or built from source): Pip package (t.  TensorFlow library (version, if pip package or github SHA, if built from source):  I built it with Conda and Python 3.9. Basically I install the environment in a Jupyter kernel and then use it to install the packages and eventually run the script.   2. Code Provide code to help us reproduce your issues using one of the following options: train.py:  test_model.py:  My dataset is in the Pascal VOC format with train and valid subfolders, each with their own images/ and Annotations/ folders. I've been able to train the model several times but whenever I put the resulting .tflite into the testing script, it doesn't product the shape it's supposed to. According to the TF documentation for the TFLite Object Detector export_tflite function here the output shape should be:     Four Outputs:       detection_boxes: a float32 tensor of shape [1, num_boxes, 4] with box         locations.       detection_classes: a float32 tensor of shape [1, num_boxes] with class         indices.       detection_scores: a float32 tensor of shape [1, num_boxes] with class         scores.       num_boxes: a float32 tensor of size 1 containing the number of detected         boxes.  3. Failure after conversion  The training seems to go fine, although somewhere along the way it warns me that: `20231017 04:41:28.736735: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' ha)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jansdhillon,Not able to get TFlite Model Maker Object Detector to produce expected output," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WSL Linux Ubuntu 20.04 (although I've also tried on Linux Ubuntu 22.04)  TensorFlow installation (pip package or built from source): Pip package (t.  TensorFlow library (version, if pip package or github SHA, if built from source):  I built it with Conda and Python 3.9. Basically I install the environment in a Jupyter kernel and then use it to install the packages and eventually run the script.   2. Code Provide code to help us reproduce your issues using one of the following options: train.py:  test_model.py:  My dataset is in the Pascal VOC format with train and valid subfolders, each with their own images/ and Annotations/ folders. I've been able to train the model several times but whenever I put the resulting .tflite into the testing script, it doesn't product the shape it's supposed to. According to the TF documentation for the TFLite Object Detector export_tflite function here the output shape should be:     Four Outputs:       detection_boxes: a float32 tensor of shape [1, num_boxes, 4] with box         locations.       detection_classes: a float32 tensor of shape [1, num_boxes] with class         indices.       detection_scores: a float32 tensor of shape [1, num_boxes] with class         scores.       num_boxes: a float32 tensor of size 1 containing the number of detected         boxes.  3. Failure after conversion  The training seems to go fine, although somewhere along the way it warns me that: `20231017 04:41:28.736735: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' ha",2023-10-17T04:49:24Z,stat:awaiting response stale comp:lite type:performance TFLiteConverter TFLiteModelMaker,closed,0,13,https://github.com/tensorflow/tensorflow/issues/62135,Hi   The output shapes for the tflite model can be observed using `interpreter.get_output_details()`. The outputs might be ordered and need to be accessed accordingly.  Could you please share a toy tflite model in order to debug the issue? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you., Were you able to solve this and could please post the solution to this issue? I am having the same problem at the moment,"> Hi  >  > The output shapes for the tflite model can be observed using `interpreter.get_output_details()`. The outputs might be ordered and need to be accessed accordingly. >  > Could you please share a toy tflite model in order to debug the issue? >  > Thanks. I did run that, which you can see the output of in the last block of code. They all have a shape of [].",">  Were you able to solve this and could please post the solution to this issue? I am having the same problem at the moment Unfortunately, no I was not. I was trying to use this for a project but wasn't able to get it working in time so I had to pivot.",Alright thanks for responding I will try to reproduce! I have run model maker on two different datasets. With one the inference afer conversion works just fine. With the other (the current one) I got the same results as you. Maybe I can find out the reason,"I was not able to reproduce it again. I am also using WSL with Ubuntu 22.04. I tested the same model as you with model maker and this time loading worked. However, when exporting the model to Tflite I also got this  `20231113 00:52:04.885225: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate. ` But it did not matter. Loading the model and inferring it worked fine afterwards. I was able to access to output tensors like this: ","Hi   As mentioned  , use the signature function to get the output details. You can add the following code to the interpreter. This information can be found in the documentation as well.   Please let us know if any problem persists. Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No," Hi, I'm not sure if you've deleted your comment but I got a notification about it so I figured I'd respond. That was the same issue I was having. I should have been more clear about what I was actually trying to do, which was use the tflite model directly in my Flutter app with tflite_flutter. However, as you mentioned, it seems like the only way to get the actual output is with Python, which obviously does not work with Flutter directly.  Of course, you could use a Flask server but at that point what's the point of ondevice inference, really. This is why I pivoted away from this approach. But I do agree, it would be ideal if the TFLite Model Maker could create models that work outside with the Flutter package. I did have some better results using MediaPipe but ultimately scrapped Flutter entirely."," Hi, yes sorry I did delete it. I thought I could reopen the issue but it does not work :D Yes I fully aggree! I had to do manual fixes which are not appropriate in flutter tflite package to make this work. We should not be forced to do it like that. And since both Tensorflow, Flutter and also now the Flutter TFLite Package are under the hood of Google there should also be some interest of Google to make these work together I guess.  Until this is getting resolved if you or anyone else want to come back to use Flutter TFLite you can refer to this issue which describes what must be done to in Flutter TFLite to use model maker OD models."
888,"以下是一个github上的tensorflow下的一个issue, 标题是(Different results interpreter python and Android)， 内容是 ( OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.13 I get different results when running my model with the TF Lite interpreter in Python and on Android. I do the same normalization in both of those. The Python code:  Snippets of the relevant Android code: For preprocessing:  For inference:    Both results are different by quite a lot  around 0.1 score. The images that enter are exactly the same. Model: https://drive.google.com/file/d/1Pr3mCZ7kocEPw_tAQuokrZBpqqXC0gek/view?usp=sharing)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,justlike-prog,Different results interpreter python and Android," OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.13 I get different results when running my model with the TF Lite interpreter in Python and on Android. I do the same normalization in both of those. The Python code:  Snippets of the relevant Android code: For preprocessing:  For inference:    Both results are different by quite a lot  around 0.1 score. The images that enter are exactly the same. Model: https://drive.google.com/file/d/1Pr3mCZ7kocEPw_tAQuokrZBpqqXC0gek/view?usp=sharing",2023-10-16T12:51:19Z,stat:awaiting response type:support stale TFLiteConverter TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62123,"Hello, prog ! Could you please add the new line so that the bytes are returned in LITTLE_ENDIAN. By default, the order of a ByteBuffer object is BIG_ENDIAN. Finally, the order method is invoked to modify the byte order.   In order to expedite the troubleshooting process, please provide a complete code snippet to reproduce the issue reported here. The drive link seems to be not working. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1848,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Importation Error)， 内容是 (Good day!  I have a project and i need TensorFlow module (this is the first time using the library) I have installed the library and try to forcedownload different lower versions and they got installed successfully but to import now is the issue Below is the error message it keep bringing up: ImportError                               Traceback (most recent call last) ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py in       61   try: > 62     from tensorflow.python._pywrap_tensorflow_internal import *      63    This try catch logic is because there is no bazel equivalent for py_extension. ImportError: DLL load failed: The specified module could not be found. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last)  in  > 1 import tensorflow as tf ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\__init__.py in       35 import typing as _typing      36  > 37 from tensorflow.python.tools import module_util as _module_util      38 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader      39  ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\python\__init__.py in       34  pylint: disable=wildcardimport,gbadimportorder,gimportnotattop      35  > 36 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow      37 from tensorflow.python.eager import context      38  ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py in       76 except ImportError:      77   raise ImportError( > 78       f'{traceback.format_exc()}'      79       f'\n\nFail)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DAMMYICAN,Tensorflow Importation Error,"Good day!  I have a project and i need TensorFlow module (this is the first time using the library) I have installed the library and try to forcedownload different lower versions and they got installed successfully but to import now is the issue Below is the error message it keep bringing up: ImportError                               Traceback (most recent call last) ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py in       61   try: > 62     from tensorflow.python._pywrap_tensorflow_internal import *      63    This try catch logic is because there is no bazel equivalent for py_extension. ImportError: DLL load failed: The specified module could not be found. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last)  in  > 1 import tensorflow as tf ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\__init__.py in       35 import typing as _typing      36  > 37 from tensorflow.python.tools import module_util as _module_util      38 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader      39  ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\python\__init__.py in       34  pylint: disable=wildcardimport,gbadimportorder,gimportnotattop      35  > 36 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow      37 from tensorflow.python.eager import context      38  ~\anaconda3\Anaconda3\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py in       76 except ImportError:      77   raise ImportError( > 78       f'{traceback.format_exc()}'      79       f'\n\nFail",2023-10-16T12:29:18Z,type:build/install,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62122,", There are at least 3 possible scenarios:     1. You need to install the MSVC 2019 redistributable     2. Your CPU does not support AVX2 instructions     3. Your CPU/Python is on 32 bits     4. There is a library that is in a different location/not installed on your system that cannot be loaded. Could you please confirm that you installed Tensorflow using pip and kindly share the steps you have followed to install Tensorflow. It is recommended to follow the installation instructions from here. Thank you!",Thanks  ,Are you satisfied with the resolution of your issue? Yes No
1880,"以下是一个github上的tensorflow下的一个issue, 标题是(Error when loading TFLite model on Android with GPU Delegate)， 内容是 ( 1. System information  OS Platform and Distribution: TFLite conversion on Windows 10 and run models on Android 13  TensorFlow installation: pip package  TensorFlow library: 2.14.0  2. Code I understand the importance of providing a reproducible code for better troubleshooting. Given the size and complexity of the model, I'm unable to provide a simplified version immediately. However, I am actively working on preparing one to help diagnose the issue more effectively. In the meantime, if there are any insights, workarounds, how to debug, or known issues that you can infer from the error message I've shared below, it would be immensely helpful.  3. Failure after conversion Model produces correct results on my PC, but an error occurs when tyring to load it on an Android device. Any insights or solutions would be greatly appreciated. I'd like to know if there's something I'm missing or if this is a known issue.  5.  Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. I'm currently trying to run a TFLite model on an Android mobile device using the GPU Delegate. While the converted TFLite model works perfectly on my PC, I encounter an error when trying to load it on the mobile device. Here's the error message I received:  While there's no issue loading with TFLite CPU, I encounter the following error during execution. What's weird is that even though I'm feeding the same size of data on both PC and mobile, this error only appears on the mobile.   I have confirmed t)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mitsunami,Error when loading TFLite model on Android with GPU Delegate," 1. System information  OS Platform and Distribution: TFLite conversion on Windows 10 and run models on Android 13  TensorFlow installation: pip package  TensorFlow library: 2.14.0  2. Code I understand the importance of providing a reproducible code for better troubleshooting. Given the size and complexity of the model, I'm unable to provide a simplified version immediately. However, I am actively working on preparing one to help diagnose the issue more effectively. In the meantime, if there are any insights, workarounds, how to debug, or known issues that you can infer from the error message I've shared below, it would be immensely helpful.  3. Failure after conversion Model produces correct results on my PC, but an error occurs when tyring to load it on an Android device. Any insights or solutions would be greatly appreciated. I'd like to know if there's something I'm missing or if this is a known issue.  5.  Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. I'm currently trying to run a TFLite model on an Android mobile device using the GPU Delegate. While the converted TFLite model works perfectly on my PC, I encounter an error when trying to load it on the mobile device. Here's the error message I received:  While there's no issue loading with TFLite CPU, I encounter the following error during execution. What's weird is that even though I'm feeding the same size of data on both PC and mobile, this error only appears on the mobile.   I have confirmed t",2023-10-16T11:10:13Z,stat:awaiting tensorflower type:performance TFLiteConverter TFLiteGpuDelegate TF2.14,open,0,16,https://github.com/tensorflow/tensorflow/issues/62120,"Hi   It is hard to say from the error log, I can guess that there is a problem with the input data being passed with android. Please check the input tensor shapes and resize before during inference accordingly. Also, you need to see of the data chunk being passed is of 81920.  Another possibility is if the loaded model in TFLite does not have any defined batch size, converter will take the batch size as 1, and when you evaluate it with the different batch size, you are likely to end up with the problem which you are facing. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi  Thank you for your reply, and sorry for my late reply.  I've prepared a reproducible code for the error. Could you please check it out please? https://colab.research.google.com/gist/mitsunami/fa5cacac520bde7d446441155bbb7479/tensorflowlitedebuggercolab.ipynb When you run the code in the above Colab notebook, a TFLite model named `model_fixed_batch.tflite` will be generated. As mentioned, the model can be executed correctly on Colab. However, when trying to load this model on Android with the GPU Delegate option, an error occurs.  To reproduce this, please follow the steps below: 1. Unzip the Android project ZIP file in the link: https://drive.google.com/file/d/1CvB8NemWQzaY0AaWcQEh1Y3BeHN2uiS/view?usp=sharing 2. Copy the TFLite file you generated earlier to the path `android_repro\app\src\main\assets`.  3. Build the project using Android Studio, install it on the device, and run it. (This app is a slightly modified version of the StyleTransfer app from tensorflow/examples, designed to reproduce the error.) 4. After running the app, when you change the Delegate to `GPU`  and click the `Run` button, you should be able to see the error message in Android Studio's Logcat. If you have any questions about the reproduction steps, please let me know. Regarding the data size you pointed out, I have confirmed that the batch size is fixed to 1 during TFLite conversion. Also, since it's an error during model loading, the input data size should not be an issue here. Thanks for your support.","Hi   I've sent a reproducible code for the error that I'm facing. If you could check it and provide an update, that would be great.  Thank you!","Hi , I'm looking into this but in the mean time you might want to check if you do any broadcasting in your model, the GPU delegate generally does not handle this case very well currently ex: https://github.com/tensorflow/tensorflow/issues/60043 .","Hi , I was able to run your project on CPU, I tried to change the project to run on GPU by changing MainViewModel:31 from 0 to 1 (which is the constant for the GPU DELEGATE), that didn't seem to reproduce your issue. Can you explain to me how you > change the Delegate to GPU So that I know we are doing the same thing. Thanks.","Hi ,  Thanks for looking into this.  Please do the following to change the Delegate to GPU:  When the application is launched, the camera is activated. After taking a picture, the attached screen will appear, where you can change the Delegate field circled in red to `GPU.` Then press the `RUN` button below. (You don't have to change MainViewModel code.) Please let me know if you any questions. Thanks. !Screenshot_20231101142051_resized","Please note that the app is just a modified version of the existing StyleTransfer app for the purpose of loading the model in question. So if you press RUN, the app itself will work fine. However, when you press RUN, the model in question is loaded, and you should see the error that occurs when loading the model on Logcat in Android Studio. That is the issue I would like you to see. Thank you.","Got it, I did that and did not run into your same issue, I got some errors but they seem unrelated: !image TFLiteXNNPackDelegate seems to be used though, maybe something related to me using an emulator. Can you let me know what API level you are using for your pixel 7 Pro?","I haven't tried it with an emulator, but it might be related to it. I'm away from my PC right now, but I'll check with an emulator on my end later to see if it's same as you. The API level I'm using should be 33.  Thanks.","Hi , I tried with an emulator, but it doesn't reproduce the error. Please use some physical devices. I confirmed that at least the issues occurs with the two phones I've tried (Pixel 7 Pro and Galaxy S21 Exynos). Thanks.","Hi , can you please take a look? Thanks.","Hi , do you have any updates on this? If you could help on this, that would be great. Thanks.",I also have same issue here,I also experienced the same issue here.,Same here
513,"以下是一个github上的tensorflow下的一个issue, 标题是(Utilize Hexagon DSP using Python on ARM Devkit)， 内容是 (I am trying to run Tensorflow utilizing the Hexagon DSP on an ARM Devkit running ARM Linux  I am able to build Tensorflow for DSP. Also the necessary DSP files are available (.so files) , but I am not able to find resources for any code in Python that would be able to run on DSP )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Abhinav0002,Utilize Hexagon DSP using Python on ARM Devkit,"I am trying to run Tensorflow utilizing the Hexagon DSP on an ARM Devkit running ARM Linux  I am able to build Tensorflow for DSP. Also the necessary DSP files are available (.so files) , but I am not able to find resources for any code in Python that would be able to run on DSP ",2023-10-14T10:56:43Z,stat:awaiting response type:support stale comp:lite,closed,0,5,https://github.com/tensorflow/tensorflow/issues/62113, Here is a new TensorFlow Lite delegate that utilizes Hexagon NN Direct to run quantized models faster on the millions of mobile devices with Hexagon DSPs. Could you please have a look at this for reference?  For any further queries can you please post the issue on TF forum where there is a  larger community that would help you. Thank you! ,"I want to run for ARM Linux, is there any documentation for crosscompilation for ARM ?"," For more detailed instructions, please refer to the TensorFlow documentation: Crosscompiling TensorFlow Lite with Bazel: https://www.tensorflow.org/lite/guide/build_arm Crosscompiling TensorFlow Lite with CMake: https://www.tensorflow.org/lite/guide/build_cmake_arm\ Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
1073,"以下是一个github上的tensorflow下的一个issue, 标题是(Errors when building v2.14 from source - ubuntu 20.04 / arm64 / GPU + CUDA (capabilities 8.7) / clang 16)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.14.0  Custom code No  OS platform and distribution Ubuntu 20.04.6  Mobile device _No response_  Python version 3.10.13  Bazel version 6.1.0  GCC/compiler version clang 16.0.6  CUDA/cuDNN version 11.4 / 8.6.0  GPU model and memory jetson orin agx  > nvidia ampere  Current behavior? Attempting to build TF from source  Jetson Orin w Ampere GPU, arm64  TF 2.14.0  bazel 6.1.0  python 3.10 `./configure`  no ROCm  yes CUDA (capabilities = 8.7)  no TensorRT  using clang 16 as cuda compiler `bazel build //tensorflow/tools/pip_package:build_pip_package` Resultng behavior: build fails, with the following error:   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,antoniaelsen,Errors when building v2.14 from source - ubuntu 20.04 / arm64 / GPU + CUDA (capabilities 8.7) / clang 16," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.14.0  Custom code No  OS platform and distribution Ubuntu 20.04.6  Mobile device _No response_  Python version 3.10.13  Bazel version 6.1.0  GCC/compiler version clang 16.0.6  CUDA/cuDNN version 11.4 / 8.6.0  GPU model and memory jetson orin agx  > nvidia ampere  Current behavior? Attempting to build TF from source  Jetson Orin w Ampere GPU, arm64  TF 2.14.0  bazel 6.1.0  python 3.10 `./configure`  no ROCm  yes CUDA (capabilities = 8.7)  no TensorRT  using clang 16 as cuda compiler `bazel build //tensorflow/tools/pip_package:build_pip_package` Resultng behavior: build fails, with the following error:   Standalone code to reproduce the issue   Relevant log output ",2023-10-13T22:49:45Z,stat:awaiting response type:bug type:build/install subtype: ubuntu/linux TF2.14,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62109,"Hi  , By looking at the logs it seems your environment have CUDA 11.4 and cuDNN 8 versions which may raise compatibility issues. For TF2.14v, CUDA=11.8 and cuDNN=8.7 are tested versions. Please refer the official tested build configurations here. Could you test with official build configurations and let us know the outcome. Thanks!","> Hi  , >  > By looking at the logs it seems your environment have CUDA 11.4 and cuDNN 8 versions which may raise compatibility issues. For TF2.14v, CUDA=11.8 and cuDNN=8.7 are tested versions. >  > Please refer the official tested build configurations here. >  > Could you test with official build configurations and let us know the outcome. >  > Thanks! That did it, thanks :)",Are you satisfied with the resolution of your issue? Yes No
1617,"以下是一个github上的tensorflow下的一个issue, 标题是(UnicodeDecodeError: 'utf-8' codec can't decode byte 0xce in position XX: invalid continuation byte)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution Windows 11 Home 22H2  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I've created a model in google colab: here. Then downloaded it and loaded few times on my computer. However after these times it stopped to load by the function `tf.keras.saving.load_model(model_name)` and started to drop this error:   I haven't changed anything in the code, it just suddenly stopped to open. I've tried to recreate the model in colab and download it again, changed tf version on computer to tf 2.13.0 (colab has it). Also I've tried to open another models on my pc and all of them threw this error Model in google drive  Standalone code to reproduce the issue   Relevant log output Output from jupyter when trying to load model: `20231013 16:33:40.479946: E tensorflow/tsl/platform/windows/windows_file_system.cc:363] ERROR: GetSymbolicLinkTarget cannot open file for \\?\C:\Users\termi\Desktop\stlsegm\╨Т╨╡╤А╤Е_╨▓╤Б╨╡\╨Т╨╡╤А╤Е_╨▒╨╡╨╖_╨┤╨╡╤Б╨╜╤Л ╤В╨╛╨╗╤М╨║╨╛ ╨▓╨╡╤А╤Е╨╜╨╕╨╡\╨Т╨╡╤А╤Е ╤Б╨╡╨│╨╝╨╡╨╜╤В╨░╤Ж╨╕╤П GetLastError: 5`)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DemO-O-On,UnicodeDecodeError: 'utf-8' codec can't decode byte 0xce in position XX: invalid continuation byte," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution Windows 11 Home 22H2  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I've created a model in google colab: here. Then downloaded it and loaded few times on my computer. However after these times it stopped to load by the function `tf.keras.saving.load_model(model_name)` and started to drop this error:   I haven't changed anything in the code, it just suddenly stopped to open. I've tried to recreate the model in colab and download it again, changed tf version on computer to tf 2.13.0 (colab has it). Also I've tried to open another models on my pc and all of them threw this error Model in google drive  Standalone code to reproduce the issue   Relevant log output Output from jupyter when trying to load model: `20231013 16:33:40.479946: E tensorflow/tsl/platform/windows/windows_file_system.cc:363] ERROR: GetSymbolicLinkTarget cannot open file for \\?\C:\Users\termi\Desktop\stlsegm\╨Т╨╡╤А╤Е_╨▓╤Б╨╡\╨Т╨╡╤А╤Е_╨▒╨╡╨╖_╨┤╨╡╤Б╨╜╤Л ╤В╨╛╨╗╤М╨║╨╛ ╨▓╨╡╤А╤Е╨╜╨╕╨╡\╨Т╨╡╤А╤Е ╤Б╨╡╨│╨╝╨╡╨╜╤В╨░╤Ж╨╕╤П GetLastError: 5`",2023-10-13T14:34:18Z,stat:awaiting response type:bug stale comp:apis TF2.14,closed,0,11,https://github.com/tensorflow/tensorflow/issues/62107,"Thanks for help, anjanappa, this issue was because of nonenglish symbols in the path name",Are you satisfied with the resolution of your issue? Yes No,"> Thanks for help, anjanappa, this issue was because of nonenglish symbols in the path name However no, the problem isn't solved  it suddenly stopped to open models with nonenglish characters","> > Thanks for help, anjanappa, this issue was because of nonenglish symbols in the path name >  > However no, the problem isn't solved  it suddenly stopped to open models with nonenglish characters Upd: I changed my command prompt encoding to UTF8 following this96) and got new error:  The folder `Низ_без_десны только низ` can be read and something can be written there. The error is encountered in Python 3.9, 3.10 and tf 2.12.0, 2.13.0, 2.14.0",OOn This issue generally occurs when the python interpreter tries to decode the byte sequence that is not a valid UTF8 encoded character. It could be because of the following reasons as well; a. The data might be corrupted or invalid. b. The data is encoded in a different encoding. c. The data contains a character that is not supported by the UTF8 encoding etc. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"The following path has only ASCII characters, but it still fails to load Original path: `\\SERVER1\Public\functional_models\exp_151` Tensorflow version: 2.12.0 Error: ",  Could you please create a new ticket with all the relevant information which we could track? Thank you!,"with io.open(file.path, ""r"", encoding=""utf8"") as f:         text = f.read()   Error : 'utf8' codec can't decode byte 0xc4 in position 10: invalid continuation byte   in chainlit chainlit   can anyone help me out"
1880,"以下是一个github上的tensorflow下的一个issue, 标题是(Error when convert dynamic axes ONNX to dynamic axes TFLite )， 内容是 ( 1. System information  Ubuntu20.04  Tensorflow: 2.11  Python: 3.10.8  Pytorch: 1.12.0  2. Code  The first convert Pytorch model to Onnx with dynamic input:     network = 'rSfM120ktlresnet50gemw'     state = load_url(PRETRAINED[network], model_dir=os.path.join(get_data_root(), 'networks'))     net_params = {}     net_params['architecture'] = state['meta']['architecture']     net_params['pooling'] = state['meta']['pooling']     net_params['local_whitening'] = state['meta'].get('local_whitening', False)     net_params['regional'] = state['meta'].get('regional', False)     net_params['whitening'] = state['meta'].get('whitening', True)     net_params['mean'] = state['meta']['mean']     net_params['std'] = state['meta']['std']     net_params['pretrained'] = False     net = init_network(net_params)     net.load_state_dict(state['state_dict'])     if useRmac:         net.pool = RMAC(3)     net.cuda()     net.eval()     dummy_input = torch.randn(1, 3, 400, 900)     input_names = [ ""actual_input"" ]     output_names = [ ""output"" ]     dynamic_axes_dict = { 'actual_input': { 0: 'bs',  2: 'img_x',3: 'img_y'},'Output': { 0: 'bs'}}      torch.onnx.export(net,                      dummy_input,                      ""resnet50.onnx"",                      verbose=False,                      input_names=input_names,                      output_names=output_names,                     dynamic_axes=dynamic_axes_dict,                      opset_version=12,                      )  The second convert Onnx model to Tf:     onnx_path = 'resnet50.onnx'     onnx_model = onnx.load( onnx_path)     onnx.checker.check_model(onnx_model)    )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ThuyyTran,Error when convert dynamic axes ONNX to dynamic axes TFLite ," 1. System information  Ubuntu20.04  Tensorflow: 2.11  Python: 3.10.8  Pytorch: 1.12.0  2. Code  The first convert Pytorch model to Onnx with dynamic input:     network = 'rSfM120ktlresnet50gemw'     state = load_url(PRETRAINED[network], model_dir=os.path.join(get_data_root(), 'networks'))     net_params = {}     net_params['architecture'] = state['meta']['architecture']     net_params['pooling'] = state['meta']['pooling']     net_params['local_whitening'] = state['meta'].get('local_whitening', False)     net_params['regional'] = state['meta'].get('regional', False)     net_params['whitening'] = state['meta'].get('whitening', True)     net_params['mean'] = state['meta']['mean']     net_params['std'] = state['meta']['std']     net_params['pretrained'] = False     net = init_network(net_params)     net.load_state_dict(state['state_dict'])     if useRmac:         net.pool = RMAC(3)     net.cuda()     net.eval()     dummy_input = torch.randn(1, 3, 400, 900)     input_names = [ ""actual_input"" ]     output_names = [ ""output"" ]     dynamic_axes_dict = { 'actual_input': { 0: 'bs',  2: 'img_x',3: 'img_y'},'Output': { 0: 'bs'}}      torch.onnx.export(net,                      dummy_input,                      ""resnet50.onnx"",                      verbose=False,                      input_names=input_names,                      output_names=output_names,                     dynamic_axes=dynamic_axes_dict,                      opset_version=12,                      )  The second convert Onnx model to Tf:     onnx_path = 'resnet50.onnx'     onnx_model = onnx.load( onnx_path)     onnx.checker.check_model(onnx_model)    ",2023-10-13T04:47:44Z,stat:awaiting response type:bug comp:lite TFLiteConverter TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62105,Hi   Could you please share a toy TFLite model  or TF saved model inorder to reproduce the error. That will help to better investigate the issue. Thanks.,> Hi  >  > Could you please share a toy TFLite model or TF saved model inorder to reproduce the error. That will help to better investigate the issue. >  > Thanks.  Here is model: https://drive.google.com/drive/folders/1BUpjHtBOZYD_pqfBvUSQf25y9AMACufd?usp=sharing, Hi,I was able to reproduce this issue. Please find this gist. Seems to be pytorch>onnx>tflite issue.  Could you please look into this issue? Thanks.,"Hi , unfortunately we currently do not support dynamic input shapes and do not plan to in the near future as doing so will have too great of a performance impact to most workflows. https://www.tensorflow.org/lite/guide/inferencerun_inference_with_dynamic_shape_model. For dynamic axes, please manually/force these axes to be static and shape your model/data statically before converting to .tflite format and let us know if that works.","> Hi , unfortunately we currently do not support dynamic input shapes and do not plan to in the near future as doing so will have too great of a performance impact to most workflows. https://www.tensorflow.org/lite/guide/inferencerun_inference_with_dynamic_shape_model. For dynamic axes, please manually/force these axes to be static and shape your model/data statically before converting to .tflite format and let us know if that works. Does it mean I can't use dynamic axes for the TFlite model? So what is dynamic input shape and how does it work?",", correct you can't use dynamic axes for the TFLite model, dynamic input shape means that one or more dimensions of your input data is variable. Dynamic axes defines which dimensions are variable, so if there are dynamic axes > there is a dynamic input shape. TFLite is currently not designed to convert/handle dynamic input shapes due to the performance costs involved in handling such architectures. Usually there is a way to force your model/data to be statically shaped which makes sense but you'll have to figure it out for your own situation. Common ways include padding/cropping and various forms of extrapolation, interpolation, upsampling or downsampling but it really depends on what you are trying to do.","> , correct you can't use dynamic axes for the TFLite model, dynamic input shape means that one or more dimensions of your input data is variable. Dynamic axes defines which dimensions are variable, so if there are dynamic axes > there is a dynamic input shape. TFLite is currently not designed to convert/handle dynamic input shapes due to the performance costs involved in handling such architectures. Usually there is a way to force your model/data to be statically shaped which makes sense but you'll have to figure it out for your own situation. Common ways include padding/cropping and various forms of extrapolation, interpolation, upsampling or downsampling but it really depends on what you are trying to do. When I run input sample with shape(224x244) by Onnx in step 1 and convert to TFlite. I tested TFLite model with sizes 411x411, 320x320 and it was successful but when I try with size 150x150,  480x480 so got error: line 917, in invoke     self._interpreter.Invoke() RuntimeError: tensorflow/lite/kernels/squeeze.cc:63 current >= 0 && current data[current] == 1 was not true.Node number 254 (SQUEEZE) failed to prepare.","Hi , we don't purposely try to limit these workflows so sometimes it does handle dynamic shapes for some ops however because we can't guarantee it works for every case, it is considered not supported, in your case please statically size the input shape for the model (then convert it) and do data preprocessing to force your data into the right shape to feed into the converted model. For example say you choose 224x224 as your static input shape, you would need to upsample the 150x150 image (perhaps interpolate the holes?) and downsample the 480x480 image, before it ever gets to the converted model.",Are you satisfied with the resolution of your issue? Yes No
1001,"以下是一个github上的tensorflow下的一个issue, 标题是(AuditWheel Failures on Build for TensorFlow 2.14)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version TF2.14  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version Python3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior? When trying to build TensorFlow 2.14 on the ci/official `wheel.sh` script, we are seeing manylinux failures during the auditwheel check stating that the ""presence of toorecent versioned symbols. You'll need to compile the wheel on an older toolchain."" Are there any recommendations to fix this issue for TF2.14 builds?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ohadkatz,AuditWheel Failures on Build for TensorFlow 2.14," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version TF2.14  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version Python3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior? When trying to build TensorFlow 2.14 on the ci/official `wheel.sh` script, we are seeing manylinux failures during the auditwheel check stating that the ""presence of toorecent versioned symbols. You'll need to compile the wheel on an older toolchain."" Are there any recommendations to fix this issue for TF2.14 builds?  Standalone code to reproduce the issue   Relevant log output ",2023-10-12T22:14:27Z,stat:awaiting response stat:awaiting tensorflower type:build/install stale subtype: ubuntu/linux TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62103,"Thanks for checking out the newer scripts. Sorry that it's not super clear, but they're still under development. They were not the scripts used to build TF 2.14  we're aiming to use them for TF 2.16. So they're not guaranteed to work yet. I'm guessing this is not working because your build is not using the correct bazelrc settings to select the toolchain present in the container, since the correct toolchain settings have been moving around while these scripts are under development. I think for 2.14 you'd need to make sure that the build is using one of the bazelrcs from the container, e.g. ""bazelrc=/tf/cpu.bazelrc"", I think. ","HI  I attempted to update the build to using the bazelrc's contained within the container, and am still seeing the same auditwheel failure on TF2.14 sigbuild with image being tensorflow/build:2.14python3.10 . ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1134,"以下是一个github上的tensorflow下的一个issue, 标题是(The configuration file of newer tensorflow versions doesn't provide building with sycl/opencl option. Does newer versions of Tensorflow doesn't provide sycl support?)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version 9  CUDA/cuDNN version 11.8/8.6  GPU model and memory NVIDIA RTX 3090 24 GB  Current behavior? I am trying to build Tensorflow version 2.14 from source with sycl/opencl support but when I am running the configuration file it isn't showing any sycl support option. So does the newer versions of tensorflow doesn't provide opencl/sycl support?  If they do provide support, how to build newer versions of TF with sycl/opencl support?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Varun-pro,The configuration file of newer tensorflow versions doesn't provide building with sycl/opencl option. Does newer versions of Tensorflow doesn't provide sycl support?," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version 9  CUDA/cuDNN version 11.8/8.6  GPU model and memory NVIDIA RTX 3090 24 GB  Current behavior? I am trying to build Tensorflow version 2.14 from source with sycl/opencl support but when I am running the configuration file it isn't showing any sycl support option. So does the newer versions of tensorflow doesn't provide opencl/sycl support?  If they do provide support, how to build newer versions of TF with sycl/opencl support?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-12T06:47:22Z,stat:awaiting response type:support stale TF2.14,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62098,"Hello, pro!  Could you please refer to this issue where it states that after this commit the support for sycl has been removed. For opencl as well this older issue states to refer to this blog. Please have a look. Thank you!",Thanks for the reply Also does TFLite supports PowerVR and if so then through delegates?,"pro There is no specific support for PowerVR in tflite, please have a look at the official doc here for GPU delegates. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1597,"以下是一个github上的tensorflow下的一个issue, 标题是(Unit tests failed on some Intel Sapphire Rapids CPUs due to wrong reference results from numpy 1.23.5)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? This is not an issue with using Tensorflow but an issue of false test failure when running some unit tests (e.g. //tensorflow/python/kernel_tests/math_ops:tensordot_op_test_gpu) due to issues with numpy 1.23.5 on some Intel Sapphire Rapids CPUs, including and not limited to: Intel(R) Xeon(R) Platinum 8480C Intel(R) Xeon(R) Platinum 8468 I have filed an issue with numpy, which has more details on the numpy bug (https://github.com/numpy/numpy/issues/24903). Currently, Tensorflow uses numpy 1.23.5 when running unit tests via bazel (https://github.com/ROCmSoftwarePlatform/tensorflowupstream/blob/developupstream/requirements_lock_3_10.txtL287). For some tests like //tensorflow/python/kernel_tests/math_ops:tensordot_op_test_gpu, it uses the results from numpy as reference. When running on systems with the above described Intel CPUs, the tests would falsely fail.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,wenchenvincent,Unit tests failed on some Intel Sapphire Rapids CPUs due to wrong reference results from numpy 1.23.5," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? This is not an issue with using Tensorflow but an issue of false test failure when running some unit tests (e.g. //tensorflow/python/kernel_tests/math_ops:tensordot_op_test_gpu) due to issues with numpy 1.23.5 on some Intel Sapphire Rapids CPUs, including and not limited to: Intel(R) Xeon(R) Platinum 8480C Intel(R) Xeon(R) Platinum 8468 I have filed an issue with numpy, which has more details on the numpy bug (https://github.com/numpy/numpy/issues/24903). Currently, Tensorflow uses numpy 1.23.5 when running unit tests via bazel (https://github.com/ROCmSoftwarePlatform/tensorflowupstream/blob/developupstream/requirements_lock_3_10.txtL287). For some tests like //tensorflow/python/kernel_tests/math_ops:tensordot_op_test_gpu, it uses the results from numpy as reference. When running on systems with the above described Intel CPUs, the tests would falsely fail.  Standalone code to reproduce the issue   Relevant log output ",2023-10-12T05:23:55Z,stat:awaiting response type:bug stale comp:ops subtype:cpu-intel TF2.14,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62096,"Since the issue depends mainly on Numpy, let's wait till the Numpy issue to get resolved.", It seems that numpy is not going to make new releases for 1.23.* (https://github.com/numpy/numpy/issues/24903issuecomment1779586475). Could we move to use 1.24.0 in TF so that we won't be impacted by the bug?," , Does 1.24.0 has the fix related to this issue?",">  , Does 1.24.0 has the fix related to this issue?  Yes. Numpy 1.24.0 fixed this issue.","Thanks for confirming, but for `TensorFlow` to include `Numpy` 1.24.0 it has to take account of compatibility of all the dependency packages and bump the version, in the upcoming version 2.15.0 `TensorFlow` still uses `Numpy >=1.23.5` and same with the ongoing nightly version as well.  , Is there any plan to bump the `Numpy` version?",To my knowledge there was no immediate plan to bump the Numpy version.  Let me check with some others on this,", Could you please try with the latest Tensorflow version and also in the setup.py file it was mentioned that **'numpy >= 1.26.0, < 2.2.0'** Please take a look at this setup.py file for the reference. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.pyL114C15L114C32 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1337,"以下是一个github上的tensorflow下的一个issue, 标题是(WSL2 tensorflow install not working)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.14.0rc121g4dacf3f368e 2.14.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.1 on WSL2  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA: 12.2 cudnn: ??  GPU model and memory rtx 3090 24gb   Current behavior? Im trying to use tensorflow 2 on wsl2. I did the installation as in the tf docs. After Installing tensorflow on wsl2 and running a test script as stated in the relevant code. I get this some errors. I have tried training a simple model with resnet which, at first, didnt work because cudnn was missing. After manually installing cudnn it worked but it feels so sketchy given that it should work without having to install it manually. Also when I train my model (i dont know if this is normal behaviour) only my vram is used, the compute power of my gpu seems to not be used at all when i look at my taskmanager.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Syndicateeee,WSL2 tensorflow install not working," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.14.0rc121g4dacf3f368e 2.14.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.1 on WSL2  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA: 12.2 cudnn: ??  GPU model and memory rtx 3090 24gb   Current behavior? Im trying to use tensorflow 2 on wsl2. I did the installation as in the tf docs. After Installing tensorflow on wsl2 and running a test script as stated in the relevant code. I get this some errors. I have tried training a simple model with resnet which, at first, didnt work because cudnn was missing. After manually installing cudnn it worked but it feels so sketchy given that it should work without having to install it manually. Also when I train my model (i dont know if this is normal behaviour) only my vram is used, the compute power of my gpu seems to not be used at all when i look at my taskmanager.  Standalone code to reproduce the issue   Relevant log output ",2023-10-11T20:36:58Z,type:build/install wsl2 TF2.14,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62095,"Hi  , Could you please confirm the installation command you have used ? Is it `python3 m pip install tensorflow[andcuda]` ?? Also please note that above command will fetch the required cuda,cudnn libraries automatically. So please don't install any cuda libraries separately as it seems duplicating the registries. Only you need to install suitable CUDA driver manually and then all required CUDA toolkit shall be imported along with tensorflow if used above command. Thank you."," yes this is the exact command, i also tried it with docker desktop on windows and docker in wsl2. windows wont boot at all which is fine probably misconfigured and wsl2 also yields the same error."," , I hope you have deleted any CUDA libraries that is installed manually except those bundled with tensorflow[andcuda].Please confirm. Because multiple libraries may cause ambiguity. I expect nvidia driver has been installed and running.Please share `nvidiasmi` command output. Please share the environment details using `pip list` . I am attaching a relevant issues here CC(2.10.0 cuBLAS error) for verifying.","I managed to resolve the issue. Note that im not sure what the issue was in the end. This worked for tensorflow 2.14 My steps to solving it: 1. installed Ubuntu 20.04 LTS 2. disable nouveau driver https://askubuntu.com/a/951892 3. install cudaToolkit 11.8 using the .run local installer https://developer.nvidia.com/cuda1180downloadarchive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=20.04&target_type=runfile_local 4. add cuda path to PATH and LD_LIBRARY_PATH https://forums.developer.nvidia.com/t/pathldlibrarypath/48080 5. install cudnn 8.6 using the installation guide https://docs.nvidia.com/deeplearning/cudnn/installguide/index.htmlinstalllinuxdeb 6. check if cuda is working `nvcc version` 7. check if cudnn is working as stated in the install guide.  7.1. if you get an error about FreeImage not being setup correctly https://forums.developer.nvidia.com/t/freeimageisnotsetupcorrectlypleaseensurefreeimaeissetupcorrectly/66950/2?u=tschm300 7.2. If you get an error stating somethin about ""compute_35"" go to cudnn_samples_v8 folder edit the samples common file `sudo nano samples_common.mk ` and at the end where it says `SMS ?=` remove 35 and save. 7.3. if your test passes you have installed cuda and cudnn 8. install anaconda https://docs.anaconda.com/free/anaconda/install/linux/ 9. create anacona environment using `conda create name tensorflow_001 c condaforge python=3.11 ` 10.  activate conda environment `conda activate tensorflow_001` 11. install tensorflow using `python3 m pip install tensorflow[andcuda]` 12. done (note: some infos may be still there)",Are you satisfied with the resolution of your issue? Yes No,"Hello,  I'm experiencing the same issue and  I have  already posted in details what I'm dealing with in this comment Error: Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered. Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered. Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered. OS: Windows 11, WSL 2, Ubuntu 22.04.3 LTS CUDA Version: 11.8  CUDNN: 8.7 I have installed both CUDA and cudnn on WSL globally and then I used anaconda to download TF in a certain env. In a weird way Tensorflow has worked when I used python 3.11 in my env, but then it downloaded TF 2.13, not 2.14, with one warning: tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT. However, when I used python 3.10 in my env, it downloaded TF 2.14 BUT with the errors above. Note: I have already followed the instructions from CUDA and Cudnn very carefully, And used a conda en","  1. i use cuDNN 8.6 2. for me installing the 11.8 toolkit wasnt enough, i also needed a NVIDIA driver with cuda 11.8 which is 520.61.05 3. this driver only worked on Ubuntu 20.04 supposedly because of the newer Ubuntu kernel in 22.04 4. I gave up on WSL2, went to a close by electronics store, bought a 500gig nvme and installed ubuntu on there 5. If you ensist on using wsl2 please give my guide a shot https://github.com/tensorflow/tensorflow/issues/62095issuecomment1763366758 You can setup ubuntu 20.04 on wsl2 using `wsl install d Ubuntu20.04` also make sure ur using wsl2 not wsl so after u install `wsl setversion Ubuntu20.04 2` not sure if you can install the driver on wsl tho might look for the same nvidia driver for your windows host. When typing `nvidiasmi` in ur terminal it should say CUDA: 11.8.","Well, looks like I solved it. I've tried everything to make CUDA work, from installing older tensorflowgpu to VirtualBox and WSL2. First of all, downgrade to 2.16.1, it shows more info on whats wrong. Next step search for an env variable that controls TF logs (something like ""TF_CPP_MAX_LOG_LEVEL""), set it to higher level so it shows you what is exactly going wrong (which libraries are there and which are not). Then uninstall all CUDA and cudnn stuff from WSL and install CUDA 12.3 and cudnn 8.9. Exactly these version. Installing them is a bit tricky because you have to specify them in aptget and Nvidia made installing cudnn8 pain in the ass after they released cudnn9. So after installing those in my WSL2, when I compile my model it uses GPU memory, alas there are some NUMA related errors which I wasn't able to fix but training became much faster either way (40s>5s per epoch)"
1502,"以下是一个github上的tensorflow下的一个issue, 标题是(NNAPI delegate crashes on kTfLiteBuiltinCos in TF Lite 2.14)， 内容是 ( Issue type Bug (segfault!)  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code No  OS platform and distribution Android 13  Mobile device Pixel 4  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TF Lite 2.14, the NNAPI delegate was changed to support the cos operator. Unfortunately, it does not work as expected and causes a segfault. The originating change is https://github.com/tensorflow/tensorflow/commit/4aac8c95b7d7827eedca82a76cb71db1525dafc9. The repro is easy. Use the below network and run with NNAPI. The error is in `TransformCosIntoSupportedOps`, which makes the assumption that `theta` is nonnull. This causes a nullpointer dereference. But the problem is bigger than this  the NNAPI delegate should _not_ be modifying static data. This is dangerous and will lead to problems if the node is not accepted by the delegate, or if the execution graph is modified again to use a different delegate.  Standalone code to reproduce the issue  Convert to tflite and load using NNAPI. The application will segfault. ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,brtal,NNAPI delegate crashes on kTfLiteBuiltinCos in TF Lite 2.14," Issue type Bug (segfault!)  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code No  OS platform and distribution Android 13  Mobile device Pixel 4  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? In TF Lite 2.14, the NNAPI delegate was changed to support the cos operator. Unfortunately, it does not work as expected and causes a segfault. The originating change is https://github.com/tensorflow/tensorflow/commit/4aac8c95b7d7827eedca82a76cb71db1525dafc9. The repro is easy. Use the below network and run with NNAPI. The error is in `TransformCosIntoSupportedOps`, which makes the assumption that `theta` is nonnull. This causes a nullpointer dereference. But the problem is bigger than this  the NNAPI delegate should _not_ be modifying static data. This is dangerous and will lead to problems if the node is not accepted by the delegate, or if the execution graph is modified again to use a different delegate.  Standalone code to reproduce the issue  Convert to tflite and load using NNAPI. The application will segfault. ```  Relevant log output _No response_",2023-10-11T17:32:53Z,stat:contribution welcome stat:awaiting tensorflower type:bug comp:lite TFLiteConverter TFLiteNNAPIDelegate TF2.14,closed,0,11,https://github.com/tensorflow/tensorflow/issues/62091,Hi   Thanks for the finding.  Is the error reproducible in the nightly pull as well? Are you interested in creating a PR for this? Thanks.,"Yes it repros in nightly.  Our group does have some patches we would like to contribute back to tensorflow but we don't have any contacts at Google to help coordinate with on this. We would love to make some contacts so we can help facilitate these. In the case of this patch, we don't have a fix for it, so I will decline to put up a PR. A proper fix is more involved and I don't have one prepared and don't really have the time at the moment. If NNAPI doesn't support `cos` natively, then it should be mapped to multiple NNAPI ops to translate it into a `sin`. However, in the immediate term, the breaking change should simply be reverted. Thanks.", Thanks for the information.  Could you please look into this issue? Thanks.,"I was able to reproduce with a Pixel 4 API 33 emulator:  Test62091.zip !image I wasn't able to reproduce on a general linux (debian) benchmark_model build that had use_nnapi=true  Hi , can you please take a look? Thanks."," fyi  this won't fail on debian because it's an NNAPIspecific failure, which only exists on Android. Note from your `benchmark_model` output, the model is running on XNNPACK not NNAPI. This issue is really straight forward. Just revert the broken commit. :) thanks.","Hi , that commit was there for a reason, so just reverting it will likely cause a regression.. that being said the original author might be available, , would you have any insight on how we may fix your commit to resolve both cases? Thanks for any help you can provide."," and  the cos op works fine on my Pixel 7 Pro. I guess it's an NNAPI API level issue. The math `sin` op, which I used to provide `cos` op, in NNAPI is not available before feature level 3.","  respectful, the issue is not in NNAPI, it is in the delegate code modified in the originating change. Specifically, it crashes in `TransformCosIntoSupportedOps` because the `TfLiteTensor` being modified has a null data pointer (because the tensor hasn't been allocated yet). Tensor allocation is meant to happen after delegates have modified the graph. Moreover, as per my original description, I don't believe it's appropriate to mutate input data at this stage. I suggest you try the `benchmark_model` repro that  supplies above on your device.",">   respectful, the issue is not in NNAPI, it is in the delegate code modified in the originating change. Specifically, it crashes in `TransformCosIntoSupportedOps` because the `TfLiteTensor` being modified has a null data pointer (because the tensor hasn't been allocated yet). Tensor allocation is meant to happen after delegates have modified the graph. >  > Moreover, as per my original description, I don't believe it's appropriate to mutate input data at this stage. >  > I suggest you try the `benchmark_model` repro that  supplies above on your device. That's interesting. Thanks for the information. I'll check it out. BTW, as far as I can remember. I have unit test for the `cos` op in `nnapi_delegate_test.cc`. I'll check the unit test first, and then check the tensor allocation issue you mentioned.",: you are right. I fixed it in CC(fix cos op for  nnapi delegate).,Are you satisfied with the resolution of your issue? Yes No
990,"以下是一个github上的tensorflow下的一个issue, 标题是(Failed to determine best cudnn convolution algorithm when using mixed_float16 policy)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 'v2.13.0rc27g1cb1a030a62', '2.13.0'  Custom code Yes  OS platform and distribution Google Colab  Mobile device No  Python version Google Colab default  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version Google Colab default  GPU model and memory Google Colab default  Current behavior? When using depthwise conv inside custom attention (https://arxiv.org/pdf/2304.04237.pdf) layer with **mixed_float16** policy got ""Failed to determine best cudnn convolution algorithm"". There is no such error with full precision.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shkarupa-alex,Failed to determine best cudnn convolution algorithm when using mixed_float16 policy," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 'v2.13.0rc27g1cb1a030a62', '2.13.0'  Custom code Yes  OS platform and distribution Google Colab  Mobile device No  Python version Google Colab default  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version Google Colab default  GPU model and memory Google Colab default  Current behavior? When using depthwise conv inside custom attention (https://arxiv.org/pdf/2304.04237.pdf) layer with **mixed_float16** policy got ""Failed to determine best cudnn convolution algorithm"". There is no such error with full precision.  Standalone code to reproduce the issue   Relevant log output ",2023-10-11T12:42:52Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops TF 2.13,closed,0,9,https://github.com/tensorflow/tensorflow/issues/62089, I was able to replicate the issue reported here. Thank you!,"It seems to be a problem with XLA. When `jit_compile` is set to `False`, the mixed_float16 behaves as expected. alex Could you please confirm if this solution works for you? After confirmation, we can investigate the underlying issue in XLA.", i confirm that issue raises only when precision policy is mixed_float16 and jit_compile=True. In all other cases it works well. But i need both mixed_float16 and jit_compile=True. In my models i see that with jit_compile=True batch size could be twice larger then with autoclustering,"Certainly. We are investigating whether the problem lies in the jit compilation or if it is related to an issue with the Nvidia library. Rest assured, we are actively working on resolving this issue and will keep you informed of any progress. Thank you for your patience.",There is another error message in TF 2.15 + cuda 12.2: ,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1109,"以下是一个github上的tensorflow下的一个issue, 标题是(TFRecordWriter stuck (or very slow) while serializing data, depending on feature transformation type)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution ubuntu 22.4  Mobile device _No response_  Python version 3.8.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior? **tf.io.TFRecordWriter** freeze when preprocessing features with **scikitlearn** (**DaskML**) **QuantileTranformer**, whereas its working (writing out few k samples within seconds) when using **StandardScaler**. How might QuantileTransformer produce output data shaped in a way it breaks TFRecords serialization? Might dtype precision influence serialization performance in such criticality?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,DominikGithub,"TFRecordWriter stuck (or very slow) while serializing data, depending on feature transformation type"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution ubuntu 22.4  Mobile device _No response_  Python version 3.8.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory _No response_  Current behavior? **tf.io.TFRecordWriter** freeze when preprocessing features with **scikitlearn** (**DaskML**) **QuantileTranformer**, whereas its working (writing out few k samples within seconds) when using **StandardScaler**. How might QuantileTransformer produce output data shaped in a way it breaks TFRecords serialization? Might dtype precision influence serialization performance in such criticality?  Standalone code to reproduce the issue   Relevant log output ",2023-10-11T11:29:35Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/62087,Are you satisfied with the resolution of your issue? Yes No
1548,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow build with sycl and ComputeCPP throwing error ""missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule"")， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.3.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version 3.1.0  GCC/compiler version 9  CUDA/cuDNN version 11.8 / 8.6  GPU model and memory RTX 3090 24 GB  Current behavior? I'm trying to build Tensorflow from source with sycl and ComputeCPP backend but when I'm trying to build Tensorflow, I'm getting following errors: //crosstool:cccompilerlocal: missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule Target '//crosstool:empty' contains an error and its package is in error and referenced by '//crosstool:cccompilerlocal' Target '//crosstool:cccompilerlocal' contains an error and its package is in error and referenced by '//crosstool:toolchain' /home/vpy2kor/tensorflow2.3.0/tensorflow/python/BUILD:2998:1: every rule of type cc_binary implicitly depends upon the target '//crosstool:toolchain', but this target could not be found because of: Target '//crosstool:toolchain' contains an error and its package is in error  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Varun-pro,"Tensorflow build with sycl and ComputeCPP throwing error ""missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule"""," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.3.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version 3.1.0  GCC/compiler version 9  CUDA/cuDNN version 11.8 / 8.6  GPU model and memory RTX 3090 24 GB  Current behavior? I'm trying to build Tensorflow from source with sycl and ComputeCPP backend but when I'm trying to build Tensorflow, I'm getting following errors: //crosstool:cccompilerlocal: missing value for mandatory attribute 'toolchain_config' in 'cc_toolchain' rule Target '//crosstool:empty' contains an error and its package is in error and referenced by '//crosstool:cccompilerlocal' Target '//crosstool:cccompilerlocal' contains an error and its package is in error and referenced by '//crosstool:toolchain' /home/vpy2kor/tensorflow2.3.0/tensorflow/python/BUILD:2998:1: every rule of type cc_binary implicitly depends upon the target '//crosstool:toolchain', but this target could not be found because of: Target '//crosstool:toolchain' contains an error and its package is in error  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-11T08:34:35Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.3,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62085,"Hello, pro!  Thank you for raising the issue! We could see you are using TF v2.3, which is an older version and not actively supported. Could you please have a look at this doc and try to build TF using the latest TF version? Thank you!","Thanks for the fast reply I want to build tensorflow from source with sycl support and when I'm running the configure file of new tensorflow versions , It's not showing sycl support option . That's why I have to revert to an old version.  Do you have any idea whether newer versions doesn't support opencl/sycl backend or is there some issue with my hardware. ",pro There is no further information for supporting sycl as per the issue attached here.  Please refer to this release note for more updates. Please let us know if it helps? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
830,"以下是一个github上的tensorflow下的一个issue, 标题是(GPU not detected even after installing CUDA, cuDNN correct versions)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14.0  Custom code No  OS platform and distribution Windows 10 22H2 19045.3448  Mobile device _No response_  Python version 3.10.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA v11.2, cudnn11.2windowsx64v8.1.0.77  GPU model and memory GeForce GTX 960M, 4Gb  Current behavior? Unable to detect the GPU. TF says:  `print(tf.test.is_built_with_cuda()) False`  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,majorisgit,"GPU not detected even after installing CUDA, cuDNN correct versions"," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.14.0  Custom code No  OS platform and distribution Windows 10 22H2 19045.3448  Mobile device _No response_  Python version 3.10.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA v11.2, cudnn11.2windowsx64v8.1.0.77  GPU model and memory GeForce GTX 960M, 4Gb  Current behavior? Unable to detect the GPU. TF says:  `print(tf.test.is_built_with_cuda()) False`  Standalone code to reproduce the issue   Relevant log output ",2023-10-10T20:19:00Z,type:support,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62080,Are you satisfied with the resolution of your issue? Yes No," , For GPU package with all required CUDA libraries you need to use `pip install tensorflow[andcuda]` command. Whether you resolved this ? Are you still having issues please feel free to discuss.","I'm also having this problem, installed tensorflow 2.13 after using `pip install tensorflow[andcuda] `command, but still can't use GPU calculations","> I'm also having this problem, installed tensorflow 2.13 after using `pip install tensorflow[andcuda] `command, but still can't use GPU calculations Windows native support for GPU is not supported any more in TensorFlow.  I had to install Windows Subsystem for Linux (WSL 2). I ran Linux inside Windows. Then followed the instructions from this installation script It worked, the GPU is detected and I can use it for calculations. The problem is solved. "
1036,"以下是一个github上的tensorflow下的一个issue, 标题是(An example of  `a batched of RaggedTensor(s) with rank 2` as sparse_ids for tf.nn.safe_/embedding_lookup_sparse?)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Currently, on the document https://tensorflow.google.cn/api_docs/python/tf/nn/safe_embedding_lookup_sparse?hl=en, it got claimed that `use of RaggedTensors can yield higher performance.`, without concrete examples for showing how to do the work. An example pls?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pmixer,An example of  `a batched of RaggedTensor(s) with rank 2` as sparse_ids for tf.nn.safe_/embedding_lookup_sparse?," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Currently, on the document https://tensorflow.google.cn/api_docs/python/tf/nn/safe_embedding_lookup_sparse?hl=en, it got claimed that `use of RaggedTensors can yield higher performance.`, without concrete examples for showing how to do the work. An example pls?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-10T08:47:08Z,stat:awaiting response stat:awaiting tensorflower type:feature comp:ops,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62078,", Thank you for reporting. Could you please elaborate about your Feature. Also, please specify the Use Case for this feature. Thank you!","hi  , thank you for the followup. In summary, the feature request is for pursuing a concrete example for what claimed in the doc  https://tensorflow.google.cn/api_docs/python/tf/nn/safe_embedding_lookup_sparse?hl=en saying use of RaggedTensors can yield higher performance. Roughly speaking, we all know `embeddings = tf.nn.safe_embedding_lookup_sparse(embedding_matrix, lookup_ids)` works well when `lookup_ids` being `tf.SparseTensor`, but it's performance could still be improved, especially, for inference, as onthefly shape computation could lead to perf hit sometimes. Thus, what I'm looking for is that hint in the doc, replacing `tf.SparseTensor` lookup ids to a batch of `tf.RaggedTensor`. I tried several approaches, all do not work(unless I call RaggedTensor's to_sparse method to cast it to SparseTensor). That's why I come to look for a piece of sample code to show the correct way to achieve the stuff what got claimed in the doc. BTW, high level keras API `tf.keras.layer.Embedding` makes the model accept tf.RaggedTensor as lookup ids, I just could not make it work for more fundamental `tf.nn.safe_embedding_lookup_sparse` API.","More concretely, I had a piece of example code to show what I want if using keras:  And what I'm looking for if how to feed RaggedTensor to lower level API, tf.nn.safe_embedding_lookup_sparse as input.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"It works now in newer version tf as I tested in colab, with cpu/t4/tpuv28 instances:  still not sure whether ragged tensor got transformed into sparse tensor under the hood or not.",Glad the issue was resolved with the latest version. Could you please feel free to move this issue to closed status. Thank you!
1500,"以下是一个github上的tensorflow下的一个issue, 标题是(Calculating Gradients for a graph containing tf.image.extract_patches, using TF 2.9.0)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v2.9.0rc242g8a20d54a3c1 2.9.0  Custom code Yes  OS platform and distribution Windows 1064bit  Mobile device _No response_  Python version Python 3.7  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda11.2  GPU model and memory _No response_  Current behavior? My codes extract patches from a batch of  images as an input and produces a batch of  image patches as an output. The input (batch_size, rows, cols, 1) is split into patches (patches_num, batch_size, patch_row, patch_col) before being fed to next layer of the network.  This function was called by a custom layer (keras.layers.Layer), and it works well during extracts the patches, but when calculating gradients for a graph with `grads = tape.gradient(loss, model.variables)`, an error came:  I found an issue about tf.extract_image_patches() opend on Feb 10, 2017 (https://github.com/tensorflow/tensorflow/issues/7414) and added `tf.cast(input_batch, dtype=tf.float32, name=""castData"") ` in the function, but it wont work. Here is my code of the function.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,RaymondMarzas,"Calculating Gradients for a graph containing tf.image.extract_patches, using TF 2.9.0"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v2.9.0rc242g8a20d54a3c1 2.9.0  Custom code Yes  OS platform and distribution Windows 1064bit  Mobile device _No response_  Python version Python 3.7  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda11.2  GPU model and memory _No response_  Current behavior? My codes extract patches from a batch of  images as an input and produces a batch of  image patches as an output. The input (batch_size, rows, cols, 1) is split into patches (patches_num, batch_size, patch_row, patch_col) before being fed to next layer of the network.  This function was called by a custom layer (keras.layers.Layer), and it works well during extracts the patches, but when calculating gradients for a graph with `grads = tape.gradient(loss, model.variables)`, an error came:  I found an issue about tf.extract_image_patches() opend on Feb 10, 2017 (https://github.com/tensorflow/tensorflow/issues/7414) and added `tf.cast(input_batch, dtype=tf.float32, name=""castData"") ` in the function, but it wont work. Here is my code of the function.   Standalone code to reproduce the issue   Relevant log output ",2023-10-08T11:34:45Z,type:bug comp:ops TF 2.9,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62067,"I think I have sought the answer, a comment on _How to handle nondeterminism when training on a GPU?_(https://stackoverflow.com/questions/50744565/howtohandlenondeterminismwhentrainingonagpu), The problem comes from Tensorflow does not currently guarantee determinism for all of its operations. So, you just need to change to Linux or `set TF_DETERMINISTIC_OPS=0`",Are you satisfied with the resolution of your issue? Yes No
978,"以下是一个github上的tensorflow下的一个issue, 标题是(【in C++】No OpKernel was registered to support Op 'PyFunc' used by {{node PyFunc}}with these attrs: [Tin=[], Tout=[DT_FLOAT], token=""pyfunc_0""] Registered devices: [CPU, XLA_CPU] Registered kernels:   <no registered kernels>           [[PyFunc]])， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 1.15.0  Custom code Yes  OS platform and distribution Linux  Mobile device 15001379103  Python version _No response_  Bazel version 4.2.1  GCC/compiler version 4.8.5  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? method: C API version: 1.15.0 package link:https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpulinuxx86_641.15.0.tar.gz  Standalone code to reproduce the issue )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,chuanshanjia,"【in C++】No OpKernel was registered to support Op 'PyFunc' used by {{node PyFunc}}with these attrs: [Tin=[], Tout=[DT_FLOAT], token=""pyfunc_0""] Registered devices: [CPU, XLA_CPU] Registered kernels:   <no registered kernels>           [[PyFunc]]", Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 1.15.0  Custom code Yes  OS platform and distribution Linux  Mobile device 15001379103  Python version _No response_  Bazel version 4.2.1  GCC/compiler version 4.8.5  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? method: C API version: 1.15.0 package link:https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpulinuxx86_641.15.0.tar.gz  Standalone code to reproduce the issue ,2023-10-08T07:45:56Z,stat:awaiting response type:bug stale TF 1.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62066,"Java Inference, the same question。","Hi  , TF1.x versions are not supported anymore. Will you upgrade it to latest TF version and let us know if any issue there. Thanks!","Hi  , I have checked with TF1.15V and there kernels found registered for only GPU devices as per below code. https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/python/lib/core/py_func.ccL398 Now in TF2.14v I can see that kernels are registered for all as DEVICE_DEFAULT.Here it should work for all devices. https://github.com/tensorflow/tensorflow/blob/4dacf3f368eb7965e9b5c3bbdd5193986081c3b2/tensorflow/python/lib/core/py_func.ccL422 You can see the list of `dtypes` supported in TF2.14 for the Op **PyFunc** here. https://github.com/tensorflow/tensorflow/blob/4dacf3f368eb7965e9b5c3bbdd5193986081c3b2/tensorflow/python/lib/core/py_func.ccL413L420 You can test the code with TF2.14v and let us know if you still have any problem.Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1878,"以下是一个github上的tensorflow下的一个issue, 标题是(Question about ptxas warning output of tensorflow-gpu 2.11)， 内容是 ( Issue type Others  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.11  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The running environment is cuda 11.7 cuDNN 8.5.0 python 3.10 tensorflowgpu 2.11 When I run the code, it show the warning message which seems weird. Since my cuda version is 11.7, not older than 11.1 and the log says Loaded cuDNN version 8904 while my cuDNN version is 8500. Althought the code can run successfully, i have doubts about this log, and I hope I can figure out why. Thanks in advance. The warning log is as follows  I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8904 20231007 11:43:16.647615: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalidaddress errors. You may not need to update to CUDA 11.1; cherrypicking the ptxas binary is often sufficient. 20231007 11:43:16.651012: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6 20231007 11:43:16.651030: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas 20231007 11:43:16.651094: W tensorflow/compiler/xla/stream_executor/gpu/redzone)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,myalos,Question about ptxas warning output of tensorflow-gpu 2.11," Issue type Others  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.11  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The running environment is cuda 11.7 cuDNN 8.5.0 python 3.10 tensorflowgpu 2.11 When I run the code, it show the warning message which seems weird. Since my cuda version is 11.7, not older than 11.1 and the log says Loaded cuDNN version 8904 while my cuDNN version is 8500. Althought the code can run successfully, i have doubts about this log, and I hope I can figure out why. Thanks in advance. The warning log is as follows  I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8904 20231007 11:43:16.647615: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalidaddress errors. You may not need to update to CUDA 11.1; cherrypicking the ptxas binary is often sufficient. 20231007 11:43:16.651012: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6 20231007 11:43:16.651030: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:237] Used ptxas at ptxas 20231007 11:43:16.651094: W tensorflow/compiler/xla/stream_executor/gpu/redzone",2023-10-07T04:01:58Z,stat:awaiting response type:others comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62064," Glad, you are able to run the code successfully.  The warning might be occurring due to the versions you installed for TensorFlow and CUDA probably aren't compatible. Try using one of the versions tested here: Tensorflow GPU Source Install.   Please use the latest TF version with all compatible versions. !BXNp6QCipe5sCVW Thank you!","Thanks for reply! I changed the version of tensorflow 2.11 to 2.12 and the original problem was solved, but unpleasant message showed up which is `[/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor` And i searched the reason and solution for this problem, and found related issue on https://github.com/tensorflow/tensorflow/issues/59779. It seems that the problem about this unpleasant message is still unsolved.", Thank you for your response here! Though there are some workarounds to avoid such warnings but the original issue is under tracking. Once that will be resolved such warnings will not occur.  As you confirmed that the original issue has been resolved so could you please move this issue to closed status ? Thank you! ,Are you satisfied with the resolution of your issue? Yes No
820,"以下是一个github上的tensorflow下的一个issue, 标题是(model_main_tf2.py issues with training object detection model)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.8  Custom code No  OS platform and distribution Google Colab  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The tf_slim module class tfexample_decode.py at line 453 calls control_flow_ops.case  There is no ""case"" attribute to control_flow_ops  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Maxwell12345,model_main_tf2.py issues with training object detection model," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.8  Custom code No  OS platform and distribution Google Colab  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The tf_slim module class tfexample_decode.py at line 453 calls control_flow_ops.case  There is no ""case"" attribute to control_flow_ops  Standalone code to reproduce the issue   Relevant log output ",2023-10-07T00:13:37Z,stat:awaiting response type:bug stale comp:model TF 2.8,closed,0,4,https://github.com/tensorflow/tensorflow/issues/62063,", Could you please confirm whether you are trying to execute the below code or the different one? https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
462,"以下是一个github上的tensorflow下的一个issue, 标题是(Add auto_sharding dependency in OSS)， 内容是 (Currently we see seg faults when trying to enable auto_sharding in OSS.  This is a minimallyfailing example for reproducing the issue.  (This PR only adds the necessary dependency, we do not yet enable the auto_pass in gpu_compiler in OSS.))请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ckstanton,Add auto_sharding dependency in OSS,"Currently we see seg faults when trying to enable auto_sharding in OSS.  This is a minimallyfailing example for reproducing the issue.  (This PR only adds the necessary dependency, we do not yet enable the auto_pass in gpu_compiler in OSS.)",2023-10-05T18:02:47Z,comp:xla size:XS,closed,0,2,https://github.com/tensorflow/tensorflow/issues/62056,"Hi  This PR is in draft, any update on this? Please. Thank you!","> Hi  This PR is in draft, any update on this? Please. Thank you! This was just a PR to demonstrate an issue we're seeing, I wasn't planning on submitting this... sorry!  I'll close this PR now."
753,"以下是一个github上的tensorflow下的一个issue, 标题是(Issue Installing TensorFlow on Windows 11 with Python 3.12.0)， 内容是 (Hello, I am encountering an issue while trying to install TensorFlow on my Windows 11 machine with Python 3.12.0 and pip 23.2.1 (64bit). Despite several attempts, I keep receiving the following error messages:  I have tried creating virtual environments using both Python 3.7.0 and Python 3.6.4 cleared the pip cache using the command `pip cache purge` Install TensorFlow with various specific versions `tensorflow==2.1.0` `tensorflow==2.5.0` `tensorflow==2.2.0rc4` I hoping anyone know what the issue here)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ghost,Issue Installing TensorFlow on Windows 11 with Python 3.12.0,"Hello, I am encountering an issue while trying to install TensorFlow on my Windows 11 machine with Python 3.12.0 and pip 23.2.1 (64bit). Despite several attempts, I keep receiving the following error messages:  I have tried creating virtual environments using both Python 3.7.0 and Python 3.6.4 cleared the pip cache using the command `pip cache purge` Install TensorFlow with various specific versions `tensorflow==2.1.0` `tensorflow==2.5.0` `tensorflow==2.2.0rc4` I hoping anyone know what the issue here",2023-10-05T10:40:51Z,,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62054,"`I hoping anyone know what the issue here` I get it, the issue is with Python 3.12. Use a different version and you'll be good to go.",Thanks I installed python 3.10 and now its working,Canonical issue CC(Support Python 3.12)
879,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError in tensorflow-probability)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tensorflow 2.15.0  Custom code Yes  OS platform and distribution Windows Subsystem for Linux  Mobile device _No response_  Python version 3.9  Bazel version v1.18.0  GCC/compiler version 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to run a program which uses tensorflow agents & tensorflow probability at the back end. When I try to run the train.py using .yaml input file, I am getting the following error:  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SachinBM-CE,ValueError in tensorflow-probability," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tensorflow 2.15.0  Custom code Yes  OS platform and distribution Windows Subsystem for Linux  Mobile device _No response_  Python version 3.9  Bazel version v1.18.0  GCC/compiler version 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to run a program which uses tensorflow agents & tensorflow probability at the back end. When I try to run the train.py using .yaml input file, I am getting the following error:  Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-04T13:00:37Z,type:bug TF2.14,closed,0,3,https://github.com/tensorflow/tensorflow/issues/62048,"CE, Could you please note that using `tfpnightly` in the meantime should work for the above issue. Also stable (ie nonnightly) TFP releases are generally tied to a particular stable TF release and won't generally work with a subsequent TF release. TFP nightlies are tested against tfnightly and more likely to work with a recent TF stable release. And also, it looks more related to tensorflowpropability, where in that repo there is an issue that was raised and a conversation is happening. https://github.com/tensorflow/probability/issues/1752. I request that please feel free to close this issue and follow up on that issue for a quick resolution. Thank you!",  Thank you very much for your suggestion & directing me to the right conversation. ,Are you satisfied with the resolution of your issue? Yes No
910,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix inconsistency in ragged and sparse embedding lookup.)， 内容是 ( Summary Ragged support for tf.nn.safe_sparse_embedding_lookup was added in tf 2.13 here and partly duplicated some of code in sparse implementation. In tf 2.14 bug was fixed in sparse embedding lookup implementation, but duplicated code was not updated same way. ShardedVariables in parameter server are resource variable like and satisfy is_resource_variable, but are not isinstance ResourceVariable. This leads to an extra memory copy/ReadVariableOp heavily hurting performance on large embedding tables. I did minimal fix to make code consistent. An alternative would be to move the duplicated code to a small helper shared between ragged/sparse embedding lookup.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,hmc-cs-mdrissi,Fix inconsistency in ragged and sparse embedding lookup.," Summary Ragged support for tf.nn.safe_sparse_embedding_lookup was added in tf 2.13 here and partly duplicated some of code in sparse implementation. In tf 2.14 bug was fixed in sparse embedding lookup implementation, but duplicated code was not updated same way. ShardedVariables in parameter server are resource variable like and satisfy is_resource_variable, but are not isinstance ResourceVariable. This leads to an extra memory copy/ReadVariableOp heavily hurting performance on large embedding tables. I did minimal fix to make code consistent. An alternative would be to move the duplicated code to a small helper shared between ragged/sparse embedding lookup.",2023-10-03T18:29:19Z,awaiting review ready to pull comp:ops size:XS,closed,1,1,https://github.com/tensorflow/tensorflow/issues/62042,The AMD ROCm error appears unrelated to change and is compile error on C++ code.
1856,"以下是一个github上的tensorflow下的一个issue, 标题是(Bump urllib3 from 1.26.16 to 1.26.17)， 内容是 (Bumps urllib3 from 1.26.16 to 1.26.17.  Release notes Sourced from urllib3's releases.  1.26.17  Added the Cookie header to the list of headers to strip from requests when redirecting to a different host. As before, different headers can be set via Retry.remove_headers_on_redirect. (GHSAv845jxx5vc9f)     Changelog Sourced from urllib3's changelog.  1.26.17 (20231002)  Added the Cookie header to the list of headers to strip from requests when redirecting to a different host. As before, different headers can be set via Retry.remove_headers_on_redirect. ( CC(Building tensorflow (makefile method) on arhmf Olimex A20) &lt;https://github.com/urllib3/urllib3/pull/3139&gt;_)     Commits  c9016bf Release 1.26.17 0122035 Backport GHSAv845jxx5vc9f ( CC(Building tensorflow (makefile method) on arhmf Olimex A20)) e63989f Fix installing brotli extra on Python 2.7 2e7a24d [1.26] Configure OS for RTD to fix building docs 57181d6 [1.26] Improve error message when calling urllib3.request() ( CC(Branch 125939528)) 3c01480 [1.26] Run coverage even with failed jobs See full diff in compare view    ![Dependabot compatibility score](https://docs.github.com/en/github/managingsecurityvulnerabilities/aboutdependabotsecurityupdatesaboutcompatibilityscores) Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting ` rebase`. [//]:  (dependabotautomergestart) [//]:  (dependabotautomergeend)   Dependabot commands and options  You can trigger Dependabot actions by commenting on this PR:  ` rebase` will rebase this PR  ` recreate` will recreate this PR,)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dependabot[bot],Bump urllib3 from 1.26.16 to 1.26.17,"Bumps urllib3 from 1.26.16 to 1.26.17.  Release notes Sourced from urllib3's releases.  1.26.17  Added the Cookie header to the list of headers to strip from requests when redirecting to a different host. As before, different headers can be set via Retry.remove_headers_on_redirect. (GHSAv845jxx5vc9f)     Changelog Sourced from urllib3's changelog.  1.26.17 (20231002)  Added the Cookie header to the list of headers to strip from requests when redirecting to a different host. As before, different headers can be set via Retry.remove_headers_on_redirect. ( CC(Building tensorflow (makefile method) on arhmf Olimex A20) &lt;https://github.com/urllib3/urllib3/pull/3139&gt;_)     Commits  c9016bf Release 1.26.17 0122035 Backport GHSAv845jxx5vc9f ( CC(Building tensorflow (makefile method) on arhmf Olimex A20)) e63989f Fix installing brotli extra on Python 2.7 2e7a24d [1.26] Configure OS for RTD to fix building docs 57181d6 [1.26] Improve error message when calling urllib3.request() ( CC(Branch 125939528)) 3c01480 [1.26] Run coverage even with failed jobs See full diff in compare view    ![Dependabot compatibility score](https://docs.github.com/en/github/managingsecurityvulnerabilities/aboutdependabotsecurityupdatesaboutcompatibilityscores) Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting ` rebase`. [//]:  (dependabotautomergestart) [//]:  (dependabotautomergeend)   Dependabot commands and options  You can trigger Dependabot actions by commenting on this PR:  ` rebase` will rebase this PR  ` recreate` will recreate this PR,",2023-10-03T03:54:07Z,size:S dependencies python,closed,0,1,https://github.com/tensorflow/tensorflow/issues/62038,"Looks like urllib3 is uptodate now, so this is no longer needed."
514,"以下是一个github上的tensorflow下的一个issue, 标题是(Pin ml-dtypes version)， 内容是 (The new mldtypes version deprecated some attributes that are used by Tensorflow. This is causing build errors. I ran into this trying to do a patch release for TensorBoard(see error here: https://github.com/tensorflow/tensorboard/actions/runs/6332666553/job/17199512649?pr=6604). Googlers see(b/301638377).)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JamesHollyer,Pin ml-dtypes version,The new mldtypes version deprecated some attributes that are used by Tensorflow. This is causing build errors. I ran into this trying to do a patch release for TensorBoard(see error here: https://github.com/tensorflow/tensorboard/actions/runs/6332666553/job/17199512649?pr=6604). Googlers see(b/301638377).,2023-10-02T22:37:14Z,awaiting review ready to pull size:XS,closed,0,0,https://github.com/tensorflow/tensorflow/issues/62036
988,"以下是一个github上的tensorflow下的一个issue, 标题是(TF 2.14 minimum nvidia driver version)， 内容是 ( Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.14  Custom code No  OS platform and distribution Tensorflow Docker image  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 450.203.8  GPU model and memory _No response_  Current behavior? I have a question on if the minimum nvidia driver version has changed (I believe the current docs state `450.80.02` (https://www.tensorflow.org/install/pip)). The below script ran using the 2.13 docker image. Thank you. When trying to run a test gpu benchmark, I get the following error:   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,schrummy14,TF 2.14 minimum nvidia driver version," Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.14  Custom code No  OS platform and distribution Tensorflow Docker image  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 450.203.8  GPU model and memory _No response_  Current behavior? I have a question on if the minimum nvidia driver version has changed (I believe the current docs state `450.80.02` (https://www.tensorflow.org/install/pip)). The below script ran using the 2.13 docker image. Thank you. When trying to run a test gpu benchmark, I get the following error:   Standalone code to reproduce the issue   Relevant log output _No response_",2023-10-02T16:25:39Z,type:docs-bug stat:awaiting response type:bug type:build/install stale TF2.14,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62032,", Could you please confirm if this is the document which you are looking for https://docs.nvidia.com/cuda/cudatoolkitreleasenotes/index.html and also provide if you are facing any issue/error while the running code mentioned above or the executed smoothly. Thank you!",", No, not the Nvidia doc. This was part of the tensorflow docs. (`https://www.tensorflow.org/install/pip`) The code does not complete and errors out. Below is the full error. Error occurs for both k80s and v100s.  nvidiasmi output ","Hi,  For 2.14 version, could you please try with the below configuration. Version  11.8",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,will cudnn latest versions work (say 8.9)?
1194,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow lite linking issue on ChromeOS)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution ChromeOS top of tree  Mobile device _No response_  Python version _No response_  Bazel version bazel 6.2.0  GCC/compiler version Chromium OS 17.0_pre498229r6 clang version 17.0.0  CUDA/cuDNN version N/A  GPU model and memory N/A  Current behavior? I am working on upgrading ChromeOS from tensorflow 2.8 to 2.12 and ran into a missing library because of \ https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/build_defs.bzl Specifically `lnativewindow`. AFAICT nativewindow is an Android library and it looks like it isn't really supposed to be added to all operating systems building tensorflow lite with the GPU delegate. Can you all confirm? I have a local patch removing this requirement for now.  Standalone code to reproduce the issue   Relevant log output  ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gemma,Allen-Webb,Tensorflow lite linking issue on ChromeOS, Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution ChromeOS top of tree  Mobile device _No response_  Python version _No response_  Bazel version bazel 6.2.0  GCC/compiler version Chromium OS 17.0_pre498229r6 clang version 17.0.0  CUDA/cuDNN version N/A  GPU model and memory N/A  Current behavior? I am working on upgrading ChromeOS from tensorflow 2.8 to 2.12 and ran into a missing library because of \ https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/build_defs.bzl Specifically `lnativewindow`. AFAICT nativewindow is an Android library and it looks like it isn't really supposed to be added to all operating systems building tensorflow lite with the GPU delegate. Can you all confirm? I have a local patch removing this requirement for now.  Standalone code to reproduce the issue   Relevant log output  ```,2023-10-02T14:59:08Z,stat:awaiting response type:build/install stale comp:lite TF 2.12,closed,0,10,https://github.com/tensorflow/tensorflow/issues/62029,"Hi Webb, can you make a PR for us to review? Alternatively, internal systems will probably be faster.","> Hi Webb, can you make a PR for us to review? Alternatively, internal systems will probably be faster. Thanks. I will have to come back to us after I resolve the other blocking issues with the upgrade.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Honestly I don't know I will get to this before the bots close it unless I ping it, so here is one ping but it is likely to get closed before I get to it.","Hi Webb, I think it's OK to leave it closed until you are ready to get back to it.","> AFAICT nativewindow is an Android library and it looks like it isn't really supposed to be added to all operating systems building tensorflow lite with the GPU delegate. >  > Can you all confirm?  Confirmed.  ""lnativewindow"" should only be added for Android.","Hi Webb, seems like the fix is in  can you test to see if your issue is resolved? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1507,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: module 'object_detection.protos.input_reader_pb2' has no attribute 'NUMERICAL_MASKS' )， 内容是 (python3 train.py logtostderr train_dir=CAPTCHA_training_dir/ pipeline_config_path=CAPTCHA_training/faster_rcnn_inception_v2_coco.config While running this command I am getting error like this : Traceback (most recent call last):   File ""train.py"", line 51, in      from object_detection.builders import dataset_builder   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/builders/dataset_builder.py"", line 32, in      from object_detection.builders import decoder_builder   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/builders/decoder_builder.py"", line 24, in      from object_detection.data_decoders import tf_example_decoder   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/data_decoders/tf_example_decoder.py"", line 131, in      class TfExampleDecoder(data_decoder.DataDecoder):   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/data_decoders/tf_example_decoder.py"", line 136, in TfExampleDecoder     instance_mask_type=input_reader_pb2.NUMERICAL_MASKS, AttributeError: module 'object_detection.protos.input_reader_pb2' has no attribute 'NUMERICAL_MASKS' Please do help me to solve this issue.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",chat,HNanditha,AttributeError: module 'object_detection.protos.input_reader_pb2' has no attribute 'NUMERICAL_MASKS' ,"python3 train.py logtostderr train_dir=CAPTCHA_training_dir/ pipeline_config_path=CAPTCHA_training/faster_rcnn_inception_v2_coco.config While running this command I am getting error like this : Traceback (most recent call last):   File ""train.py"", line 51, in      from object_detection.builders import dataset_builder   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/builders/dataset_builder.py"", line 32, in      from object_detection.builders import decoder_builder   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/builders/decoder_builder.py"", line 24, in      from object_detection.data_decoders import tf_example_decoder   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/data_decoders/tf_example_decoder.py"", line 131, in      class TfExampleDecoder(data_decoder.DataDecoder):   File ""/home/Desktop/test/test_env/lib/python3.8/sitepackages/object_detection/data_decoders/tf_example_decoder.py"", line 136, in TfExampleDecoder     instance_mask_type=input_reader_pb2.NUMERICAL_MASKS, AttributeError: module 'object_detection.protos.input_reader_pb2' has no attribute 'NUMERICAL_MASKS' Please do help me to solve this issue.",2023-09-30T09:18:19Z,stat:awaiting response type:support stale comp:model TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/62024," with the provided information it is difficult to figure out what is going on, would it be possible for you to share the code or a way by which we can reproduce the issue?","My **train.py** program is like this : import functools import json import os import tensorflow as tf from object_detection.builders import dataset_builder from object_detection.builders import graph_rewriter_builder from object_detection.builders import model_builder from object_detection.legacy import trainer from object_detection.utils import config_util tf.logging.set_verbosity(tf.logging.INFO) flags = tf.app.flags flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.') flags.DEFINE_integer('task', 0, 'task id') flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.') flags.DEFINE_boolean('clone_on_cpu', False,                      'Force clones to be deployed on CPU.  Note that even if '                      'set to False (allowing ops to run on gpu), some ops may '                      'still be run on the CPU if they have no GPU kernel.') flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '                      'replicas.') flags.DEFINE_integer('ps_tasks', 0,                      'Number of parameter server tasks. If None, does not use '                      'a parameter server.') flags.DEFINE_string('train_dir', '',                     'Directory to save the checkpoints and training summaries.') flags.DEFINE_string('pipeline_config_path', '',                     'Path to a pipeline_pb2.TrainEvalPipelineConfig config '                     'file. If provided, other configs are ignored') flags.DEFINE_string('train_config_path', '',                     'Path to a train_pb2.TrainConfig config file.') flags.DEFINE_string('input_config_path', '',                     'Path to an input_reader_pb2.InputReader config file.') flags.DEFINE_string('model_config_path', '',                     'Path to a model_pb2.DetectionModel config file.') FLAGS = flags.FLAGS .contrib.framework.deprecated(None, 'Use object_detection/model_main.py.') def main(_):   assert FLAGS.train_dir, '`train_dir` is missing.'   if FLAGS.task == 0: tf.gfile.MakeDirs(FLAGS.train_dir)   if FLAGS.pipeline_config_path:     configs = config_util.get_configs_from_pipeline_file(         FLAGS.pipeline_config_path)     if FLAGS.task == 0:       tf.gfile.Copy(FLAGS.pipeline_config_path,                     os.path.join(FLAGS.train_dir, 'pipeline.config'),                     overwrite=True)   else:     configs = config_util.get_configs_from_multiple_files(         model_config_path=FLAGS.model_config_path,         train_config_path=FLAGS.train_config_path,         train_input_config_path=FLAGS.input_config_path)     if FLAGS.task == 0:       for name, config in [('model.config', FLAGS.model_config_path),                            ('train.config', FLAGS.train_config_path),                            ('input.config', FLAGS.input_config_path)]:         tf.gfile.Copy(config, os.path.join(FLAGS.train_dir, name),                       overwrite=True)   model_config = configs['model']   train_config = configs['train_config']   input_config = configs['train_input_config']   model_fn = functools.partial(       model_builder.build,       model_config=model_config,       is_training=True)   def get_next(config):     return dataset_builder.make_initializable_iterator(         dataset_builder.build(config)).get_next()   create_input_dict_fn = functools.partial(get_next, input_config)   env = json.loads(os.environ.get('TF_CONFIG', '{}'))   cluster_data = env.get('cluster', None)   cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None   task_data = env.get('task', None) or {'type': 'master', 'index': 0}   task_info = type('TaskSpec', (object,), task_data)   ps_tasks = 0   worker_replicas = 1   worker_job_name = 'lonely_worker'   task = 0   is_chief = True   master = ''   if cluster_data and 'worker' in cluster_data:      Number of total worker replicas include ""worker""s and the ""master"".     worker_replicas = len(cluster_data['worker']) + 1   if cluster_data and 'ps' in cluster_data:     ps_tasks = len(cluster_data['ps'])   if worker_replicas > 1 and ps_tasks = 1 and ps_tasks > 0:      Set up distributed training.     server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',                              job_name=task_info.type,                              task_index=task_info.index)     if task_info.type == 'ps':       server.join()       return     worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)     task = task_info.index     is_chief = (task_info.type == 'master')     master = server.target   graph_rewriter_fn = None   if 'graph_rewriter_config' in configs:     graph_rewriter_fn = graph_rewriter_builder.build(         configs['graph_rewriter_config'], is_training=True)   trainer.train(       create_input_dict_fn,       model_fn,       train_config,       master,       task,       FLAGS.num_clones,       worker_replicas,       FLAGS.clone_on_cpu,       ps_tasks,       worker_job_name,       is_chief,       FLAGS.train_dir,       graph_hook_fn=graph_rewriter_fn) if __name__ == '__main__':   tf.app.run() And am using tensorflow 2.13 , protobuf 3.20 , python 3.8",", I tried to execute the mentioned code and it was failing with the error ""module 'tensorflow' has no attribute 'contrib'""  which means the mentioned code was written for the tensorflow 1.x version which is not supported. Kindly find the gist of it here and also this issue looks more related to models. Please raise the request in the models repo for quick response. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1068,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow profiler client does not support IPv6)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.11.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.3  Mobile device _No response_  Python version 3.10.2  Bazel version 6.0.0  GCC/compiler version _No response_  CUDA/cuDNN version 11/8.2  GPU model and memory _No response_  Current behavior? [https://github.com/google/tsl/blob/3dee2c5930eb8ee9c6a7486434240dafadf12fb4/tsl/profiler/utils/session_manager.ccL188]() `std::vectorabsl::string_view parts = absl::StrSplit(host_port, ':');` When trying to connect to an IPv6 hostport pair, which is typically denoted as [xxxx:xxxx:blah]:port, `profiler_client.trace()` throws an error. It should have logic that supports both IPv4 and IPv6.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,yuzu-ido,Tensorflow profiler client does not support IPv6," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.11.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.3  Mobile device _No response_  Python version 3.10.2  Bazel version 6.0.0  GCC/compiler version _No response_  CUDA/cuDNN version 11/8.2  GPU model and memory _No response_  Current behavior? [https://github.com/google/tsl/blob/3dee2c5930eb8ee9c6a7486434240dafadf12fb4/tsl/profiler/utils/session_manager.ccL188]() `std::vectorabsl::string_view parts = absl::StrSplit(host_port, ':');` When trying to connect to an IPv6 hostport pair, which is typically denoted as [xxxx:xxxx:blah]:port, `profiler_client.trace()` throws an error. It should have logic that supports both IPv4 and IPv6.   Standalone code to reproduce the issue   Relevant log output ",2023-09-29T17:59:57Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:apis TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62018,"The issue clearly highlights a limitation in TensorFlow's profiler client regarding IPv6 support. You've done a good job presenting the problem. Hi ido , Thank you for bringing this to attention. The problem arises due to the simplistic string split operation on the host_port, which fails to account for IPv6 addresses. IPv6 addresses include colons, just like the separation between the IP address and port. As you've pointed out, the IPv6 format typically uses [address]:port, and the current split operation on host_port does not handle this format. A potential solution would be to modify the string parsing logic to account for the IPv6 format. This could involve checking for the presence of square brackets and adjusting the parsing logic accordingly. This is a crucial update, especially considering the increasing adoption of IPv6. It would be great if the TensorFlow team could prioritize this. In the meantime, you might want to use IPv4 as a workaround, if feasible. I hope the TensorFlow team addresses this soon","ido, Could you please confirm whether the issue is happening on the latest tensorflow v2.14 as well? Thank you!","Hi, thanks for the followup. I checked and the issue is still happening with tf 2.14.0.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
684,"以下是一个github上的tensorflow下的一个issue, 标题是(implement llama 2 using Tensorflow)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.8  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llama,rajveer43,implement llama 2 using Tensorflow, Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.8  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?   Standalone code to reproduce the issue   Relevant log output ,2023-09-29T11:30:45Z,type:feature,closed,0,1,https://github.com/tensorflow/tensorflow/issues/62015,https://github.com/leondgarse/keras_cv_attention_modelsllama2
833,"以下是一个github上的tensorflow下的一个issue, 标题是(error with concatenation when converting QAT model to tflite model using EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8)， 内容是 ( 1. System information  Windows 11  TensorFlow installation (pip package or built from source): pip  TensorFlow library : 2.13 I am attempting to convert a QAT model trained with int8 weights, int16 activations to a tflite model using tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8. Unfortunately there is an issue with converting the model using this opset.  Minimal code to reproduce the error:   This yields the following error:  Doing the same process but in int8 yields no errors: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DerryFitz,error with concatenation when converting QAT model to tflite model using EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8," 1. System information  Windows 11  TensorFlow installation (pip package or built from source): pip  TensorFlow library : 2.13 I am attempting to convert a QAT model trained with int8 weights, int16 activations to a tflite model using tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8. Unfortunately there is an issue with converting the model using this opset.  Minimal code to reproduce the error:   This yields the following error:  Doing the same process but in int8 yields no errors: ",2023-09-29T11:18:44Z,stat:awaiting tensorflower type:bug type:feature comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/62014,"Hi   I was able to reproduce the error in TFNightly. Please find this gist. As per the documentation, the concat support is on the roadmap for Quantization Aware Training. Thanks.",The fact that it works fine in int8 and the error message returned when trying 168 suggests that tflite is just missing support for the relevant dtype for concat in 168. Is it possible to enable the relevant dtype in tflite for concat at 168,Hi   Sorry for the delayed response.  As you rightly said and also as the error log suggests that the 16x8 is not supported for concat. The 16x8 is still in experimental and new features will be added in the further releases. Can we consider this as feature request? Thanks.,"Yes, please consider adding this feature, it would be much appreciated, Thanks","It seems we expect source model to be float32 not start with mixed precision quantization,  can you please take a look? Thanks.","Hi,   Thanks for raising this issue. Are you aware of AIEdgeTorch? As we believe this issue is better supported by and more relevant to AIEdgeTorch we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/aiedgetorch/issues/391 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1890,"以下是一个github上的tensorflow下的一个issue, 标题是(Bump scipy from 1.9.2 to 1.10.0 in /ci/official/containers/linux_arm64)， 内容是 (Bumps scipy from 1.9.2 to 1.10.0.  Release notes Sourced from scipy's releases.  SciPy 1.10.0 Release Notes SciPy 1.10.0 is the culmination of 6 months of hard work. It contains many new features, numerous bugfixes, improved test coverage and better documentation. There have been a number of deprecations and API changes in this release, which are documented below. All users are encouraged to upgrade to this release, as there are a large number of bugfixes and optimizations. Before upgrading, we recommend that users check that their own code does not use deprecated SciPy functionality (to do so, run your code with python Wd and check for DeprecationWarning s). Our development attention will now shift to bugfix releases on the 1.10.x branch, and on adding new features on the main branch. This release requires Python 3.8+ and NumPy 1.19.5 or greater. For running on PyPy, PyPy3 6.0+ is required. Highlights of this release  A new dedicated datasets submodule (scipy.datasets) has been added, and is now preferred over usage of scipy.misc for dataset retrieval. A new scipy.interpolate.make_smoothing_spline function was added. This function constructs a smoothing cubic spline from noisy data, using the generalized crossvalidation (GCV) criterion to find the tradeoff between smoothness and proximity to data points. scipy.stats has three new distributions, two new hypothesis tests, three new sample statistics, a class for greater control over calculations involving covariance matrices, and many other enhancements.  New features scipy.datasets introduction  A new dedicated datasets submodule has been added. The submod)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dependabot[bot],Bump scipy from 1.9.2 to 1.10.0 in /ci/official/containers/linux_arm64,"Bumps scipy from 1.9.2 to 1.10.0.  Release notes Sourced from scipy's releases.  SciPy 1.10.0 Release Notes SciPy 1.10.0 is the culmination of 6 months of hard work. It contains many new features, numerous bugfixes, improved test coverage and better documentation. There have been a number of deprecations and API changes in this release, which are documented below. All users are encouraged to upgrade to this release, as there are a large number of bugfixes and optimizations. Before upgrading, we recommend that users check that their own code does not use deprecated SciPy functionality (to do so, run your code with python Wd and check for DeprecationWarning s). Our development attention will now shift to bugfix releases on the 1.10.x branch, and on adding new features on the main branch. This release requires Python 3.8+ and NumPy 1.19.5 or greater. For running on PyPy, PyPy3 6.0+ is required. Highlights of this release  A new dedicated datasets submodule (scipy.datasets) has been added, and is now preferred over usage of scipy.misc for dataset retrieval. A new scipy.interpolate.make_smoothing_spline function was added. This function constructs a smoothing cubic spline from noisy data, using the generalized crossvalidation (GCV) criterion to find the tradeoff between smoothness and proximity to data points. scipy.stats has three new distributions, two new hypothesis tests, three new sample statistics, a class for greater control over calculations involving covariance matrices, and many other enhancements.  New features scipy.datasets introduction  A new dedicated datasets submodule has been added. The submod",2023-09-29T00:27:13Z,size:XS dependencies python,closed,0,8,https://github.com/tensorflow/tensorflow/issues/62012,"Hi , Can you please review this PR ? Thank you!","Hi , Can you please review this PR ? Thank you!","Hi , Can you please review this PR ? Thank you!","Hi , Can you please review this PR ? Thank you!","Hi , Can you please review this PR ? Thank you!","Hi , Can you please review this PR ? Thank you!",We should not update the containers using this method.,"OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting ` ignore this major version` or ` ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an `ignore` condition with the desired `update_types` to your config file. If you change your mind, just reopen this PR and I'll resolve any conflicts on it."
1582,"以下是一个github上的tensorflow下的一个issue, 标题是(TimeDistributed not compatible with multi-output models)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have been attempting to create a custom CNNRNN hybrid model that incorporates a pretrained custom DenseNetderived CNN. My model requires from the CNN both its final output and the intermediate outputs of its dense blocks (as I am attempting to create a UNet like architecture). I attempted to create a new model from the given CNN that would output these intermediate convolutional layers along with the final output value. However, when I connected it to a TimeDistributed layer, I received a strange error with no clear explanation: `AttributeError: 'list' object has no attribute 'shape'` After some experimentation, I realized this error was arising because the TimeDistributed layer was not programmed to handle multioutput layers passed to it. I understand that this issue will likely require a fix to Tensorflow. In the meanwhile, any suggestions for workarounds would be appreciated.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,gutza1,TimeDistributed not compatible with multi-output models," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have been attempting to create a custom CNNRNN hybrid model that incorporates a pretrained custom DenseNetderived CNN. My model requires from the CNN both its final output and the intermediate outputs of its dense blocks (as I am attempting to create a UNet like architecture). I attempted to create a new model from the given CNN that would output these intermediate convolutional layers along with the final output value. However, when I connected it to a TimeDistributed layer, I received a strange error with no clear explanation: `AttributeError: 'list' object has no attribute 'shape'` After some experimentation, I realized this error was arising because the TimeDistributed layer was not programmed to handle multioutput layers passed to it. I understand that this issue will likely require a fix to Tensorflow. In the meanwhile, any suggestions for workarounds would be appreciated.  Standalone code to reproduce the issue   Relevant log output ",2023-09-28T14:07:56Z,stat:awaiting tensorflower type:bug comp:apis TF 2.13,open,0,6,https://github.com/tensorflow/tensorflow/issues/62004, Sorry for the late response! As per this PR TimeDistributed is compatible with multioutput models. Please check the similar issue.  Could you please provide the simple code snippet which pinpoints the issue or error you are facing while execution.Thank you!,"After some further thought, I think the issue might be with how I am defining the outputs. My network is importing a pretrained CNN and trying to extract the outputs of its intermediate layers for use in a UNet like structure. Thus, I used the following code to build a new model derived from the old model: `new_model = tf.keras.models.Model(inputs=cnn_input, outputs=[cnn_final_output,cnn_intermediate_output_1, etc...])` In the issue you sent, the multiple outputs are returned functionally. Would I have to create a custom layer that replicates the example given in order to use TimeDistributed with multiple outputs?", It would be helpful for us if you could provide the complete code snippet to replicate the issue reported? Thank you!,The code is split across two segments. The first is in the initialization of the custom Model subclass I use: ,"I have returned to this issue. I am now willing to share my code, which has undergone significant refactoring.  In addition, I have performed a full stack trace of the error:  It appears the error originates in calculating the output mask for the TimeDistributed layer.", Any advice?
962,"以下是一个github上的tensorflow下的一个issue, 标题是(Failed to build tensorflow 2.14 on Apple silicon.)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14  Custom code No  OS platform and distribution macOS 14.0  Mobile device None  Python version 3.9, 3.10, 3.11  Bazel version 6.1.0homebrew  GCC/compiler version Apple clang version 15.0.0 (clang1500.0.40.1)  CUDA/cuDNN version None  GPU model and memory None  Current behavior? I am trying to build `tensorflow 2.14` on Python `3.9`, `3.10`, and `3.11`, but I am encountering an error that says `ld: building exports trie: duplicate symbol '_copy_printf_domain'`, which is causing the build to fail.  Standalone code to reproduce the issue Default settings used for all options.   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sun1638650145,Failed to build tensorflow 2.14 on Apple silicon.," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.14  Custom code No  OS platform and distribution macOS 14.0  Mobile device None  Python version 3.9, 3.10, 3.11  Bazel version 6.1.0homebrew  GCC/compiler version Apple clang version 15.0.0 (clang1500.0.40.1)  CUDA/cuDNN version None  GPU model and memory None  Current behavior? I am trying to build `tensorflow 2.14` on Python `3.9`, `3.10`, and `3.11`, but I am encountering an error that says `ld: building exports trie: duplicate symbol '_copy_printf_domain'`, which is causing the build to fail.  Standalone code to reproduce the issue Default settings used for all options.   Relevant log output ",2023-09-28T09:42:36Z,stat:awaiting response type:build/install subtype:macOS TF2.14,closed,1,9,https://github.com/tensorflow/tensorflow/issues/62001,cc:  ,Exact same issue here,"Similar for me on MacOS 2.14.0 (x8664), running XCode 15. Log: ","Same issue here.  For my opinion, the reason is a new linker released with clang 15.0. Probably, libraries dependencies should be reviewed by project maintainer. But as temporary solution I use ""**ld_classic**"" linker flag, that restores old linker's behavior, as before version 15. Please note, this flag is temporary available and will be removed in next releases. The patch is attached. tensorflow.patch", This method is very useful; it can be successfully built with `tensorflow 2.14/2.15`.,"> Same issue here. >  > For my opinion, the reason is a new linker released with clang 15.0. Probably, libraries dependencies should be reviewed by project maintainer. But as temporary solution I use ""**ld_classic**"" linker flag, that restores old linker's behavior, as before version 15. Please note, this flag is temporary available and will be removed in next releases. >  > The patch is attached. tensorflow.patch The linker issue is has been resolved = since XCode 14.3 (and as recently as 15.3). Besides this, are people still having issue with Apple Silicon with TF 2.16.1? If not, this should be closed."," , Could you please try the latest TensorFlow version 2.16.1 and let us know if you're still facing issue. You can follow the table here for dependency details, https://www.tensorflow.org/install/sourcemacos"," Thank you very much for your reminder, the issue has finally been resolved!",Are you satisfied with the resolution of your issue? Yes No
1779,"以下是一个github上的tensorflow下的一个issue, 标题是(can't convert keras model to tflite)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22  TensorFlow installation (pip package or built from source): pip   TensorFlow library (version, if pip package or github SHA, if built from source): 2.14.0 or tfnightly  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab  import tensorflow as tf keras_model = tf.keras.models.load_model(keras_model_filename) converter = tf.lite.TFLiteConverter.from_keras_model(keras_model) tflite_model = converter.convert() file = open(tflite_model_filename, 'wb‘） file.write(tflite_model)  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. !image)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,meixitu17,can't convert keras model to tflite," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22  TensorFlow installation (pip package or built from source): pip   TensorFlow library (version, if pip package or github SHA, if built from source): 2.14.0 or tfnightly  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab  import tensorflow as tf keras_model = tf.keras.models.load_model(keras_model_filename) converter = tf.lite.TFLiteConverter.from_keras_model(keras_model) tflite_model = converter.convert() file = open(tflite_model_filename, 'wb‘） file.write(tflite_model)  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. !image",2023-09-28T04:11:06Z,comp:lite TFLiteConverter TF2.14,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61995,"Hi   The issue might be caused because the flatbuffers limit of 2GB. However, for  LLM models you can refer to our new tutorial  https://www.tensorflow.org/lite/examples/auto_complete/overview This tutorial provides example for  Auto complete based on PaLM model, fine tuned on 1.5 Billion parameters. This model is based on Keras NLP and then converted to TFLite and TFLite runtime. Thanks.","      Yes, I saw you Palm model tutorial , but I did not try it yet.  It seems this flow only can use keras_nlp models. right?     the flatbuffer 2GB limit should be resolved in tf2.14 !image Thanks","Hi   The flow should work for any keras model as well. Incase your model is an LLM, you can see if the tutorial helps for your use case. Thanks."," ,     Thanks, I will try it. Thanks"," , 1) I tried this 'auto complete' tutorial, here is the code, i just use python=3.9, and pip install keras_nlp==0.6.2, (actually, i tried 0.6.0,0.6.1,0.6.2.dev0, NO version work), did not install others !image there are something wrong: !image 2) in this tutorial, there is "" Note that you can also use from_keras_model() from [TFLiteConverter]"" (https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverterfrom_keras_model) in order to perform the conversion. So If I had a keras model, the convert flow seems no different with my code in the first page: import tensorflow as tf keras_model = tf.keras.models.load_model(keras_model_filename) converter = tf.lite.TFLiteConverter.from_keras_model(keras_model) tflite_model = converter.convert() file = open(tflite_model_filename, 'wb‘） file.write(tflite_model) Could you please give me an example how to convert the big keras model to tflite? Thanks","Hi   I have tried the autocomplete tutorial on google colab and I was able to run without any errors. Please find this gist. If you could share your model inorder to reproduce the issue, that would help us to understand the cause better. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"      I read all of your scripts, and tried it. I can generate tflite gpt2 to tflite successfully. Thanks"
809,"以下是一个github上的tensorflow下的一个issue, 标题是(ModuleNotFoundError: No module named 'resource')， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.11.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Python test code `import tensorflow_datasets as tfds` Produces ModuleNotFoundError: No module named 'resource'  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jsmith173,ModuleNotFoundError: No module named 'resource', Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.11.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Python test code `import tensorflow_datasets as tfds` Produces ModuleNotFoundError: No module named 'resource'  Standalone code to reproduce the issue   Relevant log output ,2023-09-26T11:48:12Z,stat:awaiting response type:bug TF 2.13,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61980,", Have you got the chance to have a look at this commit where the PR  was raised for the similar issue in the tensorflow/datasets repo and it was merged. https://github.com/tensorflow/datasets/commit/82215c7cf4b3e6df706a72c9b7ad8cede09f4d84  Also the developer also confirmed the issue has been resolved for the Windows machine.  https://github.com/tensorflow/datasets/issues/5075issuecomment1727676597 Thank you!",Sorry I can't test it this way. I've found an older version on my computer that works. Thanks for your help!,", Glad the issue was resolved. Could you please feel free to move this issue to closed status. Thank you!",Are you satisfied with the resolution of your issue? Yes No,"Hello, I been troubled with this problem too. You said you found an older version on your computer, could you please tell me which one's version did you changed.",Working package version: 4.9.2 (tensorflow_datasets),> Working package version: 4.9.2 (tensorflow_datasets) Thank you!,"Thanks, I also solve this problem by installing version 4.9.2"
1874,"以下是一个github上的tensorflow下的一个issue, 标题是(TfLiteGpuDelegate Prepare: delegate is not initialized)， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 12  TensorFlow installed from (source or binary): binary  TensorFlow version (or github SHA if from source): v2.13.0 **Provide the text output from tflite_convert**  **Standalone code to reproduce the issue**  **java code** Interpreter.Options options = new Interpreter.Options(); options.addDelegate(new GpuDelegate()); Interpreter  interpreter = new Interpreter(model, options); **Convert code** output_name = ['add_1'] input_shape = [288, 288, 3] converter = tf.lite.TFLiteConverter.from_frozen_graph('model.pb', input_arrays=[""input_image""], output_arrays=output_name, input_shapes={""input_image"": input_shape}) tflite_model = converter.convert() open('model.tflite', ""wb"").write(tflite_model) GraphDef  model: GraphDef.zip TFlite model: tflite.zip **Any other info / logs** **Java issue** 13:40:05.480  W  java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: DEPTHWISE_CONV_2D: ReadNonConstantTensor: value is a constant tensor: 4 13:40:05.480  W  TfLiteGpuDelegate Prepare: delegate is not initialized 13:40:05.480  W  Node number 69 (TfLiteGpuDelegateV2) failed to prepare. 13:40:05.480  W  Restored original execution plan after delegate application failure. 13:40:05.480  W  	at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method) 13:40:05.480  W  	at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:110) 13:40:05.480  W  	at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:58) 13:40:05.480  W  	at o)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ZTMIDGO,TfLiteGpuDelegate Prepare: delegate is not initialized,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 12  TensorFlow installed from (source or binary): binary  TensorFlow version (or github SHA if from source): v2.13.0 **Provide the text output from tflite_convert**  **Standalone code to reproduce the issue**  **java code** Interpreter.Options options = new Interpreter.Options(); options.addDelegate(new GpuDelegate()); Interpreter  interpreter = new Interpreter(model, options); **Convert code** output_name = ['add_1'] input_shape = [288, 288, 3] converter = tf.lite.TFLiteConverter.from_frozen_graph('model.pb', input_arrays=[""input_image""], output_arrays=output_name, input_shapes={""input_image"": input_shape}) tflite_model = converter.convert() open('model.tflite', ""wb"").write(tflite_model) GraphDef  model: GraphDef.zip TFlite model: tflite.zip **Any other info / logs** **Java issue** 13:40:05.480  W  java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: DEPTHWISE_CONV_2D: ReadNonConstantTensor: value is a constant tensor: 4 13:40:05.480  W  TfLiteGpuDelegate Prepare: delegate is not initialized 13:40:05.480  W  Node number 69 (TfLiteGpuDelegateV2) failed to prepare. 13:40:05.480  W  Restored original execution plan after delegate application failure. 13:40:05.480  W  	at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method) 13:40:05.480  W  	at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:110) 13:40:05.480  W  	at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:58) 13:40:05.480  W  	at o",2023-09-26T05:49:23Z,comp:lite TFLiteGpuDelegate TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61979,Hi   We see that you are using old version of tensorflow (1.x) which is not actively supported.  We recommend that you upgrade to 2.13.0 and let us know if the issue still persists in newer versions . Thanks.,"  Sorry, I filled in the wrong tensorflow version, I'm currently using v2.13.0 implementation 'org.tensorflow:tensorflowlitegpu:2.13.0' implementation 'org.tensorflow:tensorflowlite:2.13.0' implementation 'org.tensorflow:tensorflowlitegpuapi:2.13.0' implementation 'org.tensorflow:tensorflowlitesupport:0.4.4' I don't know how to handle the exception I mentioned above","Hi   Thanks for the information. I have inspected the the .pb file and tflite file. I can observe that there could be some runtime incompatibility happening. The original model seems to be a TF 1.x version, specifically TF 1.13.1 because of which the issue seems to happen. Please find this gist. Also, `from_frozen_graph()` conversion method is deprecated and please migrate the TF model to a 2.x version into a saved model format and try if it works. Thanks."," Thanks, I will try it"
1869,"以下是一个github上的tensorflow下的一个issue, 标题是(Build from source 2.13.0 fails on Rocky Linux 8.8)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Rocky Linux 8.8  Mobile device _No response_  Python version 3.10.2  Bazel version 5.3.0  GCC/compiler version clang 16.0.1 or gcc 11.2.0  CUDA/cuDNN version cuda 11.7.1 /  cuDNN 8.5.0.96  GPU model and memory _No response_  Current behavior? 1. load modules (all built locally on the host  and provide an access to the specified software)   **module load  bazel/5.3.0    gcc/11.2.0    llvm/16.0.1   clang/16.0.1  python/3.10.2   cuda/11.7.1   tensorRT/8.4.2.4**   2.  Configure tensroflow: **./configure** Resulting  .tf_configure.bazelrc is: build action_env PYTHON_BIN_PATH=""/opt/apps/python/3.10.2/bin/python3"" build action_env PYTHON_LIB_PATH=""/opt/apps/python/3.10.2/lib/python3.10/sitepackages"" build python_path=""/opt/apps/python/3.10.2/bin/python3"" build config=tensorrt build action_env TF_CUDA_VERSION=""11"" build action_env TF_CUDNN_VERSION=""8"" build action_env TF_TENSORRT_VERSION=""8"" build action_env TF_NCCL_VERSION="""" build action_env TF_CUDA_PATHS=""/opt/apps/cuda/11.7.1,/opt/apps/tensorRT/8.4.2.4,/usr"" build action_env CUDA_TOOLKIT_PATH=""/opt/apps/cuda/11.7.1"" build action_env TF_CUDA_COMPUTE_CAPABILITIES=""7.0"" build action_env LD_LIBRARY_PATH=""/opt/apps/tensorRT/8.4.2.4/lib:/opt/apps/cuda/11.7.1/lib64:/opt/apps/cuda/11.7.1/nvvm/lib64:/opt/apps/cuda/11.7.1/cublas/lib64:/opt/apps/cuda/11.7.1/extras/CUPTI/lib64:/opt/apps/cuda/11.7.1 /extras/Debugger/lib64:/opt/apps/python/3.10.2/lib:/opt/apps/clang/16.0.1/lib:/opt/apps/llvm/16.0.1/lib:/op)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,nadyawilliams,Build from source 2.13.0 fails on Rocky Linux 8.8," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Rocky Linux 8.8  Mobile device _No response_  Python version 3.10.2  Bazel version 5.3.0  GCC/compiler version clang 16.0.1 or gcc 11.2.0  CUDA/cuDNN version cuda 11.7.1 /  cuDNN 8.5.0.96  GPU model and memory _No response_  Current behavior? 1. load modules (all built locally on the host  and provide an access to the specified software)   **module load  bazel/5.3.0    gcc/11.2.0    llvm/16.0.1   clang/16.0.1  python/3.10.2   cuda/11.7.1   tensorRT/8.4.2.4**   2.  Configure tensroflow: **./configure** Resulting  .tf_configure.bazelrc is: build action_env PYTHON_BIN_PATH=""/opt/apps/python/3.10.2/bin/python3"" build action_env PYTHON_LIB_PATH=""/opt/apps/python/3.10.2/lib/python3.10/sitepackages"" build python_path=""/opt/apps/python/3.10.2/bin/python3"" build config=tensorrt build action_env TF_CUDA_VERSION=""11"" build action_env TF_CUDNN_VERSION=""8"" build action_env TF_TENSORRT_VERSION=""8"" build action_env TF_NCCL_VERSION="""" build action_env TF_CUDA_PATHS=""/opt/apps/cuda/11.7.1,/opt/apps/tensorRT/8.4.2.4,/usr"" build action_env CUDA_TOOLKIT_PATH=""/opt/apps/cuda/11.7.1"" build action_env TF_CUDA_COMPUTE_CAPABILITIES=""7.0"" build action_env LD_LIBRARY_PATH=""/opt/apps/tensorRT/8.4.2.4/lib:/opt/apps/cuda/11.7.1/lib64:/opt/apps/cuda/11.7.1/nvvm/lib64:/opt/apps/cuda/11.7.1/cublas/lib64:/opt/apps/cuda/11.7.1/extras/CUPTI/lib64:/opt/apps/cuda/11.7.1 /extras/Debugger/lib64:/opt/apps/python/3.10.2/lib:/opt/apps/clang/16.0.1/lib:/opt/apps/llvm/16.0.1/lib:/op",2023-09-25T21:36:10Z,type:build/install subtype: ubuntu/linux TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61978," Could you please run bazel clean expunge, forcing bazel to redownload and build each dependency to avoid issues. Also sync the bazel build bazel sync. Thank you!","Thank you for a suggestion. I did bazel clean expunge, before the build and cleaned again when i tried different options. No help. Running bazel sync fails with multiple errors starting rom not finding cuda.h (cuda module is loaded and cuda.h is available in  cuda install), followed by not finding python (also is loaded via module and available). Looks like bazel sync is not using any of the variables set by the modules.  For example a python error is ERROR: An error occurred during the fetch of repository 'ubuntu20.04gcc9_manylinux2014cuda11.8cudnn8.6tensorrt8.4_config_python3.11':    Traceback (most recent call last): 	File ""/export/repositories/tensorflowadmix/yamlspecs/tensorflow2.13.0/third_party/py/python_configure.bzl"", line 212, column 22, in _create_local_python_repository 		_check_python_bin(repository_ctx, python_bin) 	File ""/export/repositories/tensorflowadmix/yamlspecs/tensorflow2.13.0/third_party/py/python_configure.bzl"", line 145, column 25, in _check_python_bin 		auto_config_fail(""define %s='%s' is not executable. Is it the python binary?"" % ( 	File ""/export/repositories/tensorflowadmix/yamlspecs/tensorflow2.13.0/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail 		fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)) Error in fail: Configuration Error: define PYTHON_BIN_PATH='/usr/local/bin/python3.11' is not executable. Is it the python binary? Per my modules python is which python /opt/apps/python/3.10.2/bin/python","Hello, ! If you are using TF v2.13 then the supported version for CUDA and cuDNN are 11.8, 8.6 respectively.  Could you please verify the tested build configuration as mentioned here and let us know if that helps? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,I will be able to proceed with the testing of  cuda  and cudNN  11.8 and 8.6 the earliest next week. both build have to be done according to our build schedule and approach. Please keep the issue open till i try this.  Thank you,Unfortunately at this time we cant upgrade our CUDA installation to 11.8. Please advise which  latest version of tensorflow can be compiled  with cuda 11.7 and cudNN 8.5. Thank you., Thanks for your response! We need to use the recommended compatible versions only otherwise the build issues would be hard to resolve. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Please close the issue. I  can compile tensorflow 2.11 with our current cuda install and while it is not the latest it will do for now., Thank you for the confirmation.  Closing the ticket for now. Thank you!,Are you satisfied with the resolution of your issue? Yes No
959,"以下是一个github上的tensorflow下的一个issue, 标题是(NotFoundError could not find registered transfer manager for platform Host -- check target linkage [Op:__inference__jit_compiled_convolution_op_26169] TPU-VM)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I was trying to use `groups` parameter from `keras.layers.Conv2D` API on TPUVM device. While running on GPU works but on TPU, it doesn't if `groups > 1`.  Standalone code to reproduce the issue Full Code.   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,innat,NotFoundError could not find registered transfer manager for platform Host -- check target linkage [Op:__inference__jit_compiled_convolution_op_26169] TPU-VM," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I was trying to use `groups` parameter from `keras.layers.Conv2D` API on TPUVM device. While running on GPU works but on TPU, it doesn't if `groups > 1`.  Standalone code to reproduce the issue Full Code.   Relevant log output ",2023-09-25T16:43:23Z,stat:awaiting tensorflower type:bug comp:dist-strat TF 2.12,closed,1,12,https://github.com/tensorflow/tensorflow/issues/61976,"Hi  , I am able to run the code on Colab by following TPU initialization code as per documentation and it executed fine as per attached gist. It seems the issue might be specific to Kaggle environment ?"," Thanks for checking. I also check in Colab TPU. For your concern, please check this comment https://github.com/kerasteam/tfkeras/issues/655issuecomment1733864636 "," , You mean to say it has problem with TPU VM and on colab as it is TPU node it works fine? I would like to hear from concerned team. Thanks!",> You mean to say it has problem with TPU VM and on colab as it is TPU node it works fine? Yes. cc. @ ,  > I would like to hear from concerned team. Could you like to mention the appropriate person (from tf team)?,Any update?," I have the same issue, have you solved the problem? Thanks",I moved or translated my code to PyTorch.,Are you satisfied with the resolution of your issue? Yes No,is there any Update? still getting `could not find registered transfer manager for platform Host`,"I got a similar error on Colab. When I upgraded the Tensorflow version to 2.17.0, the code worked just fine.",I am getting the same error https://github.com/tensorflow/tensorflow/issues/88960
946,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface')， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.3  Mobile device _No response_  Python version 2.13.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? OS : Ubuntu 22.04.3 Software: Pycharm files: LogisticRegression_withTensorflow.ipynb I dont know what happen, it just work yesterday when I run this code: `model.fit(X_train, y_train, epochs=150)`  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,PreWisdom,AttributeError: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.3  Mobile device _No response_  Python version 2.13.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? OS : Ubuntu 22.04.3 Software: Pycharm files: LogisticRegression_withTensorflow.ipynb I dont know what happen, it just work yesterday when I run this code: `model.fit(X_train, y_train, epochs=150)`  Standalone code to reproduce the issue   Relevant log output ",2023-09-25T15:19:18Z,stat:awaiting response type:bug stale comp:core TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61974,"Hi  , By looking at attribute error, I would like to suggest to check the issue with TF2.12V and let us know the outcome.It seems there are shiftings in Tf2.12v and Tf2.13v.  With Tf2.13V the path `tensorflow.python.distribute.input_lib` don't have the class `DistributedDatasetInterface` but in Tf2.12 it does.","> Hi  , >  > By looking at attribute error, I would like to suggest to check the issue with TF2.12V and let us know the outcome.It seems there are shiftings in Tf2.12v and Tf2.13v. >  > With Tf2.13V the path `tensorflow.python.distribute.input_lib` don't have the class `DistributedDatasetInterface` but in Tf2.12 it does. thanks for reply, I'm gonna change version to 2.12 and see what happen.","Hi  , Could you please check the issue with tfnightly. Actually there has been some changes. Now Keras has became a Multi backend support (for TF,Pytorch and JAX). All the tf.keras module i.e Keras with TF backend has been moved to new repo i.e tfkeras. I can see in tfkeras the code is different than in tf.keras module. I want to cross check with you with both tfnightly and kerasnightly and confirm outcome ?","> Hi  , >  > Could you please check the issue with tfnightly. Actually there has been some changes. Now Keras has became a Multi backend support (for TF,Pytorch and JAX). All the tf.keras module i.e Keras with TF backend has been moved to new repo i.e tfkeras. >  > I can see in tfkeras the code is different than in tf.keras module. I want to cross check with you with both tfnightly and kerasnightly and confirm outcome ? sure, there are still has some problems in my code, looks like it's due to a package name change. I'll keep on tracking these bugs.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1901,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to load TensorFlow saved model (AttributeError: '_UserObject' object has no attribute 'add_slot'))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.7.0  Custom code Yes  OS platform and distribution Windows 10 Enterprise LTSC  Mobile device _No response_  Python version 3.9.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.2/8  GPU model and memory Nvidia Geforce RTX 3090 24 GB  Current behavior? I have several trained TensorFlow models stored on my device in saved_model format. All the models have the same architecture and serve the same purpose, but they were created at different points in time. While I have no problems to load the newest models (created from 5th September 2022 onward) with the command `tensorflow.keras.models.load_model(filepath)`, older models that were created before this date raise the following exception when this method is called: > AttributeError: '_UserObject' object has no attribute 'add_slot' The same exception is also raised when trying to load these models with: `tensorflow.saved_model.load(filepath)`, which was one of the suggestions I found to solve the issue. Another possible solution that I took from the related issue CC(Cannot load saved tf model (AttributeError: '_UserObject' object has no attribute 'add_slot')) was to use another TF version, I tried it with the older v2.6 and the newest Windows native version v.2.10, but the result was the same.  Standalone code to reproduce the issue [EDIT] I could reproduce the exception on Google Colab using the newest TF version. Please find the notebook here: Model_Load_Problem.ipynb  Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,RabJon,Unable to load TensorFlow saved model (AttributeError: '_UserObject' object has no attribute 'add_slot')," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.7.0  Custom code Yes  OS platform and distribution Windows 10 Enterprise LTSC  Mobile device _No response_  Python version 3.9.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.2/8  GPU model and memory Nvidia Geforce RTX 3090 24 GB  Current behavior? I have several trained TensorFlow models stored on my device in saved_model format. All the models have the same architecture and serve the same purpose, but they were created at different points in time. While I have no problems to load the newest models (created from 5th September 2022 onward) with the command `tensorflow.keras.models.load_model(filepath)`, older models that were created before this date raise the following exception when this method is called: > AttributeError: '_UserObject' object has no attribute 'add_slot' The same exception is also raised when trying to load these models with: `tensorflow.saved_model.load(filepath)`, which was one of the suggestions I found to solve the issue. Another possible solution that I took from the related issue CC(Cannot load saved tf model (AttributeError: '_UserObject' object has no attribute 'add_slot')) was to use another TF version, I tried it with the older v2.6 and the newest Windows native version v.2.10, but the result was the same.  Standalone code to reproduce the issue [EDIT] I could reproduce the exception on Google Colab using the newest TF version. Please find the notebook here: Model_Load_Problem.ipynb  Relevant log output ",2023-09-25T10:23:54Z,stat:awaiting response type:bug comp:apis TF 2.7,closed,0,9,https://github.com/tensorflow/tensorflow/issues/61972," Could you please try to use the latest TF 2.13 as you are using an older version.  In order to expedite the troubleshooting process, please provide a complete code snippet to reproduce the issue reported here. Thank you!",I faced similar but slightly opposite issue once with `tf.saved_model.load` API but worked in ` tf.keras.models.load_model` API.  https://www.kaggle.com/competitions/googleuniversalimageembedding/discussion/336534 CC(未找到相关数据)7," unfortunately there is no GPU support after TF 2.10 for Windows Native. Therefore, I tried TF 2.10 instead of the newest version, but the result was the same as for the versions 2.6 and 2.7. However, I could reproduce the exception on Google Colab with v2.13. Here is the URL for the notebook: Model_Load_Problem.ipynb ","Thank you   for the comment. Unfortunately, in my case both approaches to loading models do not work."," Generally this error is caused because the model you are trying to load was saved using a newer version of TensorFlow than the one you are currently using. To fix this, you will need to upgrade your TensorFlow installation. To upgrade TensorFlow, run the following command:  Once you have upgraded TensorFlow, you can reload the model by running the following code:  Please let us know if it helps? Thank you!","  I tried to run the same code with TF v2.7 and TF v2.10 on Windows Native and I always got the same exception. Since v2.10, which was released in September 2022, is the latest version of TF for Windows Native it would have been impossible for me to save the models with a newer version than that. Furthermore, many of my models are older than the release date of v2.10 so they were created with a lower version for sure. I am fine for now, because I managed to load the models through a loophole in my implementation that I actually never thought to be useful: I did not only save the entire model in ""saved_model"" format, but I also saved the model weights alone as h5 files. Given that I didn't change the model architecture I could recreate and compile the models and then just load the corresponding weights from the h5 files. So, personally I don't need a solution anymore. However, I think that this is still a general issue that needs to be solved.","  Thank you for your response here! Yes, you can always use the .h5 extension in case you are using two different versions for training and loading the models.  In the HDF5 format with a .h5 extension you can save weights manually.  Could you please move this issue to closed status if it has been resolved from your end?  Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2, or install tensorflow or tensorflowcpu and, optionally, try the TensorFlowDirectMLPlugin Thank you!","Yes, I will close this issue, because it is solved from my site. However, I want to point out again that this was only possible because I decided to save both the entire TensorFlow model (in ""saved_model"" format) and the weights of the trained model (as .h5 file). So, it was due to my (lucky) design decision that I could solve this issue!",Are you satisfied with the resolution of your issue? Yes No
812,"以下是一个github上的tensorflow下的一个issue, 标题是(Use github.com/apssouza22/chatflow as a conversational layer. It would enable actual API requests to be carried out from natural language inputs.)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version all of em  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Fine as hell  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",chat,GiovanniSmokes,Use github.com/apssouza22/chatflow as a conversational layer. It would enable actual API requests to be carried out from natural language inputs., Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version all of em  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Fine as hell  Standalone code to reproduce the issue   Relevant log output ,2023-09-25T00:59:47Z,stat:awaiting response type:feature stale comp:apis,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61969,", Could you please elaborate about your Feature. Also, please specify the Use Cases for this feature which helps us to analyse the issue. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Doesn't belong in the repo, looks more like promo/spam"
1143,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Window 10  Mobile device _No response_  Python version 3.9.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to implement this in tensorflow 2.13 but getting this error ""**ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported**"" after searching a lot I got to know we have to use 1 in case of None but even after trying that it was not working  I am getting this error in custom Patches layer  patches = tf.reshape(patches, [batch_size, 1, patch_dims]) can anybody please help?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Aksh-kumar,ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Window 10  Mobile device _No response_  Python version 3.9.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to implement this in tensorflow 2.13 but getting this error ""**ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported**"" after searching a lot I got to know we have to use 1 in case of None but even after trying that it was not working  I am getting this error in custom Patches layer  patches = tf.reshape(patches, [batch_size, 1, patch_dims]) can anybody please help?  Standalone code to reproduce the issue   Relevant log output ",2023-09-23T12:48:40Z,stat:awaiting response type:bug stale comp:keras TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61957,"kumar, Apologies for the delay. Thanks for reporting the issue. Since this request is specific to Keras, could you please close this and open a new issue in Keras repo https://github.com/kerasteam/keras/issues Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,posted in kerasteam github page closing it here.,Are you satisfied with the resolution of your issue? Yes No
1878,"以下是一个github上的tensorflow下的一个issue, 标题是(ExtensionType to be considered a complete nested structure)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  (& 2.15 nightly)  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Tensorflow's current experimental ExtensionType is a very useful data structure to replace python data structures when the modelled tensors are in fact more complex structures of tensors of varying shapes and types. One would intuitively think that this class would click with `tf.nest`, but unfortunately they are not among the valid nested structures:  as taken from Module: tf.nest. Moreover, `tf.nest` is not registered as an api for .experimental.dispatch_for_api(tf_api), which would be helpful for redifining the behaviour of nesting inside an `ExtensionType`. Currently, the only solutions that I have found were either to: 1. Use multiple inheritance and also inherit from one of the valid nested structures in order to allow `tf.nest` to work as an api. This also requires implementing all the abstract methods of the superclass which may not make sense all the time. 2. Rewrite all the functionalities that use nesting as methods inside the class implementing `ExtensionType`, which is not great when you are seeking code reusability. 3. Have a method to change the type to something that can be considered a structure and have that called whenever `tf.nest`ing is used, which as well requires some changes everywh)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AndreiMoraru123,ExtensionType to be considered a complete nested structure," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  (& 2.15 nightly)  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Tensorflow's current experimental ExtensionType is a very useful data structure to replace python data structures when the modelled tensors are in fact more complex structures of tensors of varying shapes and types. One would intuitively think that this class would click with `tf.nest`, but unfortunately they are not among the valid nested structures:  as taken from Module: tf.nest. Moreover, `tf.nest` is not registered as an api for .experimental.dispatch_for_api(tf_api), which would be helpful for redifining the behaviour of nesting inside an `ExtensionType`. Currently, the only solutions that I have found were either to: 1. Use multiple inheritance and also inherit from one of the valid nested structures in order to allow `tf.nest` to work as an api. This also requires implementing all the abstract methods of the superclass which may not make sense all the time. 2. Rewrite all the functionalities that use nesting as methods inside the class implementing `ExtensionType`, which is not great when you are seeking code reusability. 3. Have a method to change the type to something that can be considered a structure and have that called whenever `tf.nest`ing is used, which as well requires some changes everywh",2023-09-22T18:59:01Z,stat:awaiting tensorflower type:feature comp:apis,open,0,3,https://github.com/tensorflow/tensorflow/issues/61954,I volunteer to take this issue,"The error you're encountering is because tf.nest.map_structure requires all elements within the nested structure to be TensorFlow tensors, and MyComplexData is not considered a TensorFlow tensor by default. To make your code compatible with tf.nest.map_structure, you need to ensure that the elements within MyComplexData are TensorFlow tensors. You can do this by adding a method to the MyComplexData class that converts its internal data to TensorFlow tensors. In the updated code, I've included a method called as_tensors that does this conversion for x and y. By calling data.as_tensors(), you can convert your custom data structure into a format compatible with TensorFlow operations. This should allow you to use tf.nest.map_structure with the gather_fn function without encountering the error.","import tensorflow as tf class MyComplexData(tf.experimental.ExtensionType):     x: tf.Tensor     y: tf.Tensor     def __init__(self, x, y):         self.x = x         self.y = y     def as_tensors(self):         return MyComplexData(tf.convert_to_tensor(self.x), tf.convert_to_tensor(self.y)) def gather_fn(tensor):     indices = tf.constant([[0], [1]])     return tf.gather_nd(tensor, indices) data = MyComplexData([1, 2, 3], [[1.0, 2.0], [3.0, 4.0]])  Convert the data to TensorFlow tensors data = data.as_tensors() try:     mapped_data = tf.nest.map_structure(gather_fn, data)     print(mapped_data) except Exception as e:     print(f""Failed to apply map_structure with gather_fn on MyComplexData: {e}"")"
1172,"以下是一个github上的tensorflow下的一个issue, 标题是(SpectralNormalization layer is not trainable. Please help (OperatorNotAllowedInGraphError: Exception encountered when calling layer 'spectral_normalization' (type SpectralNormalization).))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Ubuntu 22.04.3 LTS and Google Colab  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.8.0, nvidiacudnncu11==8.6.0.163  GPU model and memory _No response_  Current behavior? SpectralNormalization layer is not trainable. Whenever I try to use the ""model.fit"" method, TF outputs the error ""Using a symbolic `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature."" Please help Best Kav  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kavjayawardana,SpectralNormalization layer is not trainable. Please help (OperatorNotAllowedInGraphError: Exception encountered when calling layer 'spectral_normalization' (type SpectralNormalization).)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Ubuntu 22.04.3 LTS and Google Colab  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.8.0, nvidiacudnncu11==8.6.0.163  GPU model and memory _No response_  Current behavior? SpectralNormalization layer is not trainable. Whenever I try to use the ""model.fit"" method, TF outputs the error ""Using a symbolic `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature."" Please help Best Kav  Standalone code to reproduce the issue   Relevant log output ",2023-09-22T12:46:16Z,type:bug comp:keras TF 2.13,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61953,"Hi  , By looking into the error, it appears that the problem might be due to the reason that `SpectralNormalization` layer seems not supported with Graph execution. I have set `run_eagerly= True` in `model.compile(run_eagerly= True)` then the error is gone but shape incompatibility error araised. This was corrected by changing the `y` in your code to `y = np.random.rand(batch, height2, width2, filters)`. With all these modification it executes fine and attached gist for reference. Please cross check and confirm if still have any queries. Thanks!",Thank you very much . Setting run_eagerly= True made it trainable. Thank you again for being prompt with your reply and incredibly helpful with your solution best kav,Are you satisfied with the resolution of your issue? Yes No
1730,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite benchmark tool with default cmake build shows weird time duration on DEPTHWISE_CONV_2D )， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.9.3, tf 2.13.0  Custom code No  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version 5.0  GCC/compiler version gcc 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following the guide for build_cmake `cmake ../tensorflow_src/tensorflow/lite` then build the benchmark tool & label_image:  I tested using the model here. The results shows: ============================== Summary by node type ============================== 	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called] 	                 CONV_2D	       15	    38.265	    58.415%	    58.415%	     0.000	       15 	       DEPTHWISE_CONV_2D	       13	    27.230	    41.569%	    99.985%	     0.000	       13 	         AVERAGE_POOL_2D	        1	     0.007	     0.011%	    99.995%	     0.000	        1 	                 SOFTMAX	        1	     0.003	     0.005%	   100.000%	     0.000	        1 	                 RESHAPE	        1	     0.000	     0.000%	   100.000%	     0.000	        1 In theory, 13 x DEPTHWISE_CONV_2D should consume MUCH less time than 15 CONV_2, but it is not the case here. However, if I use the prebuilt binary from here, the result is correct.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,captainst,TFLite benchmark tool with default cmake build shows weird time duration on DEPTHWISE_CONV_2D ," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.9.3, tf 2.13.0  Custom code No  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version 5.0  GCC/compiler version gcc 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following the guide for build_cmake `cmake ../tensorflow_src/tensorflow/lite` then build the benchmark tool & label_image:  I tested using the model here. The results shows: ============================== Summary by node type ============================== 	             [Node type]	  [count]	  [avg ms]	    [avg %]	    [cdf %]	  [mem KB]	[times called] 	                 CONV_2D	       15	    38.265	    58.415%	    58.415%	     0.000	       15 	       DEPTHWISE_CONV_2D	       13	    27.230	    41.569%	    99.985%	     0.000	       13 	         AVERAGE_POOL_2D	        1	     0.007	     0.011%	    99.995%	     0.000	        1 	                 SOFTMAX	        1	     0.003	     0.005%	   100.000%	     0.000	        1 	                 RESHAPE	        1	     0.000	     0.000%	   100.000%	     0.000	        1 In theory, 13 x DEPTHWISE_CONV_2D should consume MUCH less time than 15 CONV_2, but it is not the case here. However, if I use the prebuilt binary from here, the result is correct.  Standalone code to reproduce the issue   Relevant log output ",2023-09-22T09:13:44Z,stat:awaiting response type:bug stale comp:lite TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61950," CC(TFLite with default cmake build, xnnpack does not work for quantized model)","Hi   Sorry for the delayed response. Have you observed the same in multiple runs, also can you check the same if it replicates with nightly pull as well? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1885,"以下是一个github上的tensorflow下的一个issue, 标题是(The metrics values in fit and in evaluate do not match (tf+keras))， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.9  Custom code Yes  OS platform and distribution Linux Ubuntu  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have the issue which I described under in detail. Might be it's a my mistake but I try to fix it not a one day. I simplified it as much as possible fitting the model to show you exactly an issue. Let it be not a pretrained model ResNet50. And let's I provide a dataset by easy way where X_train and Y_train are the ndarray with correspond shapes [N, 32, 32, 3] and [N, class_num=3]. I set batch_size=128, shuffle=False. Now I fitting my model and after the last epoch I get the metric equals 0.976, BUT If I just make model.evaluate(X_train), where X_train is the same data I use in fit I get absolutely different value  0.456. The question is  WHY? That's logs of my fitting: 263/263 [==============================]  7s 27ms/step  loss: 0.2063  auc: 0.9899  mc_f1: 0.9326 That's after evaluate: 1052/1052 [==============================]  11s 9ms/step  loss: 0.6186  auc: 0.9053  mc_f1: 0.4993 To prevent questions  mc_f1 is a custom metric  averaged f1 calculated for each class separately for the multiclass case. So the code:      Change last layers     last_layer = model.output     output = tf.keras.layers.Dense(classes, activation=""softmax"")(last_layer)     model = tf.keras.models.Model(inputs=model.inputs, outputs=output)     return model m)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,xxraytz,The metrics values in fit and in evaluate do not match (tf+keras)," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.9  Custom code Yes  OS platform and distribution Linux Ubuntu  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have the issue which I described under in detail. Might be it's a my mistake but I try to fix it not a one day. I simplified it as much as possible fitting the model to show you exactly an issue. Let it be not a pretrained model ResNet50. And let's I provide a dataset by easy way where X_train and Y_train are the ndarray with correspond shapes [N, 32, 32, 3] and [N, class_num=3]. I set batch_size=128, shuffle=False. Now I fitting my model and after the last epoch I get the metric equals 0.976, BUT If I just make model.evaluate(X_train), where X_train is the same data I use in fit I get absolutely different value  0.456. The question is  WHY? That's logs of my fitting: 263/263 [==============================]  7s 27ms/step  loss: 0.2063  auc: 0.9899  mc_f1: 0.9326 That's after evaluate: 1052/1052 [==============================]  11s 9ms/step  loss: 0.6186  auc: 0.9053  mc_f1: 0.4993 To prevent questions  mc_f1 is a custom metric  averaged f1 calculated for each class separately for the multiclass case. So the code:      Change last layers     last_layer = model.output     output = tf.keras.layers.Dense(classes, activation=""softmax"")(last_layer)     model = tf.keras.models.Model(inputs=model.inputs, outputs=output)     return model m",2023-09-21T20:30:46Z,type:support comp:keras TF 2.9,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61945,Are you satisfied with the resolution of your issue? Yes No,Are you satisfied with the resolution of your issue? Yes No
1925,"以下是一个github上的tensorflow下的一个issue, 标题是(TF Lite runtime error: ""Didn't find op for builtin opcode 'PLACEHOLDER_FOR_GREATER_OP_CODES' version '1'"")， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11, Python 3.10.11  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.13.0  2. Code Repro steps: 1) Download the `litemodel_efficientnet_lite4_uint8_2.tflite` model from here: https://tfhub.dev/tensorflow/litemodel/efficientnet/lite4/uint8/2 (click the 14.34Mb download link ; leave this page open in your browser) 2) Start a TF Lite application using Android or Flutter. I use Flutter and the latest ML Kit. 3) Use the model in your code : it works perfectly fine. 4) Back in your browser, now click the `TF` tab on the left side on the page your left open. The TF tab allows you to download the TF (not TF lite) version of the model. Download the 46.61Mb model file `efficientnet_lite4_classification_2.tar.gz` (here). Uncompress this archive into a `saved_model` folder somewhere. 5) Use the following code to convert the TF model into a TF Lite model;  6) Following the instructions from https://www.tensorflow.org/lite/models/convert/metadata, add model metadata by using `metadata_writer_for_image_classifier.py`, and with the following model specification (updated lines ~60 to 70, as instructed):  The processing completes normally. 7) Now use that model `tf_converted_to_tflite.tflite` instead of the original, readilyavailable TF Lite model available on TF Hub, `litemodel_efficientnet_lite4_uint8_2.tflite` (that was working fine). In other words, we are now trying to use approximately the same model, except that this time we ran th)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,andynewman10,"TF Lite runtime error: ""Didn't find op for builtin opcode 'PLACEHOLDER_FOR_GREATER_OP_CODES' version '1'"""," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11, Python 3.10.11  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.13.0  2. Code Repro steps: 1) Download the `litemodel_efficientnet_lite4_uint8_2.tflite` model from here: https://tfhub.dev/tensorflow/litemodel/efficientnet/lite4/uint8/2 (click the 14.34Mb download link ; leave this page open in your browser) 2) Start a TF Lite application using Android or Flutter. I use Flutter and the latest ML Kit. 3) Use the model in your code : it works perfectly fine. 4) Back in your browser, now click the `TF` tab on the left side on the page your left open. The TF tab allows you to download the TF (not TF lite) version of the model. Download the 46.61Mb model file `efficientnet_lite4_classification_2.tar.gz` (here). Uncompress this archive into a `saved_model` folder somewhere. 5) Use the following code to convert the TF model into a TF Lite model;  6) Following the instructions from https://www.tensorflow.org/lite/models/convert/metadata, add model metadata by using `metadata_writer_for_image_classifier.py`, and with the following model specification (updated lines ~60 to 70, as instructed):  The processing completes normally. 7) Now use that model `tf_converted_to_tflite.tflite` instead of the original, readilyavailable TF Lite model available on TF Hub, `litemodel_efficientnet_lite4_uint8_2.tflite` (that was working fine). In other words, we are now trying to use approximately the same model, except that this time we ran th",2023-09-21T18:16:53Z,stat:awaiting response comp:lite TFLiteConverter TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61944,Hi   I'm not sure if there is a build for 2.13.0 because the Flutter packages are not officially supported but rather contributed by the community. You may try updating package dependencies  https://docs.flutter.dev/packagesandplugins/usingpackagesupdatingpackagedependencies or use flutter tflite plugin https://github.com/tensorflow/fluttertflite which has been recently migrated to tensorflow. Please check this blog for the same. Thanks.,I have solved this issue by using TensorFlow 2.12.0 (not 2.13.0) and by changing the way I create the model (ie. use TF Hub functions). Both were necessary.
1050,"以下是一个github上的tensorflow下的一个issue, 标题是(calling Model in a loop would leak memory)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.13.0  Custom code Yes  OS platform and distribution Windows Server 2019  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? there is a transformer model when i try to decode messages, translate input sentence to target sentence i get memory blow up, memory is good when i use transformer.fit(), but in a loop like below it blows up memory, tf.keras.backend.clear_session() does’t help, also accuracy decrease when i use that, gc.collect() doesn’t work also here is my code   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,alerem18,calling Model in a loop would leak memory," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf2.13.0  Custom code Yes  OS platform and distribution Windows Server 2019  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? there is a transformer model when i try to decode messages, translate input sentence to target sentence i get memory blow up, memory is good when i use transformer.fit(), but in a loop like below it blows up memory, tf.keras.backend.clear_session() does’t help, also accuracy decrease when i use that, gc.collect() doesn’t work also here is my code   Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-21T16:51:08Z,stat:awaiting tensorflower type:bug comp:apis TF 2.13,open,0,7,https://github.com/tensorflow/tensorflow/issues/61942, Could you please provide the complete standalone code to replicate the issue reported? Thank you!,https://keras.io/examples/nlp/neural_machine_translation_with_transformer/ in decoder_sequence,will there be any solution or i should wait for you to reply once a month? this is why people prefer pytorch over tensorflow, I tried to replicate the issue on colab. https://keras.io/examples/nlp/neural_machine_translation_with_transformer/ is working fine in colab . Please let me know if i have missed something to replicate the reported error. Have you tried to use the GPU for this issue and let me know if the memory leak would be there? Thank you!,">  I tried to replicate the issue on colab. https://keras.io/examples/nlp/neural_machine_translation_with_transformer/ is working fine in colab . Please let me know if i have missed something to replicate the reported error. Have you tried to use the GPU for this issue and let me know if the memory leak would be there? Thank you! i've not tested it on gpu, but i have memory issues when translating a lot of texts, in a loop instead of eng_vectorization use input_vectorization, for spa_vectorization use output_vectorization copy paste the code from the keras directly don't include my code"," same issue on this but i didn't use .function in translator, so i don't know if it's related to that https://www.tensorflow.org/text/tutorials/transformer",is there any damn solution for this or not?
1862,"以下是一个github上的tensorflow下的一个issue, 标题是(lite hexagon后端ResizeNearestNeighbor算子层执行报错)， 内容是 (**System information**  OS Platform and Distribution ：Linux Ubuntu 18.04  TensorFlow installed from (github):  TensorFlow version (dev分支): **Provide the text output from tflite_convert** none **Standalone code to reproduce the issue**  tensorflow/lite/delegates/hexagon/builders/resize_nearest_neighbor_builder.cc **Any other info / logs** STARTING! Duplicate flags: num_threads Log parameter values verbosely: [0] Min num runs: [1] Graph: [/home/wangzhiqun/yolox_resize_nearest_neighbor.tflite] Use Hexagon: [1] Loaded model /home/wangzhiqun/yolox_resize_nearest_neighbor.tflite INFO: Initialized TensorFlow Lite runtime. Hexagon delegate created. INFO: TfLiteHexagonDelegate delegate: 1 nodes delegated out of 1 nodes with 1 partitions. INFO: Replacing 1 node(s) with delegate (TfLiteHexagonDelegate) node, yielding 1 partitions. [hexagon/nn] Add Node: tid(1) nid(1) [hexagon_nn] hexagon_nn_append_const_node(gid=1 tid=2 nid=2 type=0x3) [hexagon/nn] Add Node from Op(331) mid(0) nid(3) [hexagon_nn] hexagon_nn_append_const_node(gid=1 nid=4 type=0x3) [hexagon_nn] hexagon_nn_append_const_node(gid=1 nid=5 type=0x3) [hexagon/nn] Add Node: tid(1) nid(6) [hexagon_nn] hexagon_nn_append_node(gid=1 nid=1 type=0x0) [hexagon_nn] hexagon_nn_append_node(nis=0 nos=1) [hexagon_nn] hexagon_nn_append_node(outputs[0].elementsize=1) [hexagon_nn] hexagon_const_node(gid=1 nid=2 type=0x3) [hexagon_nn] hexagon_nn_append_node(gid=1 nid=3 type=0x14b) [hexagon_nn] hexagon_nn_append_node(nis=6 nos=3) Error adding node: id:3, op_type:331 [hexagon_nn] hexagon_const_node(gid=1 nid=4 type=0x3) [hexagon_nn] hexagon_const_node(gid=1 nid=5 type=0x3) [he)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hayyaw,lite hexagon后端ResizeNearestNeighbor算子层执行报错,"**System information**  OS Platform and Distribution ：Linux Ubuntu 18.04  TensorFlow installed from (github):  TensorFlow version (dev分支): **Provide the text output from tflite_convert** none **Standalone code to reproduce the issue**  tensorflow/lite/delegates/hexagon/builders/resize_nearest_neighbor_builder.cc **Any other info / logs** STARTING! Duplicate flags: num_threads Log parameter values verbosely: [0] Min num runs: [1] Graph: [/home/wangzhiqun/yolox_resize_nearest_neighbor.tflite] Use Hexagon: [1] Loaded model /home/wangzhiqun/yolox_resize_nearest_neighbor.tflite INFO: Initialized TensorFlow Lite runtime. Hexagon delegate created. INFO: TfLiteHexagonDelegate delegate: 1 nodes delegated out of 1 nodes with 1 partitions. INFO: Replacing 1 node(s) with delegate (TfLiteHexagonDelegate) node, yielding 1 partitions. [hexagon/nn] Add Node: tid(1) nid(1) [hexagon_nn] hexagon_nn_append_const_node(gid=1 tid=2 nid=2 type=0x3) [hexagon/nn] Add Node from Op(331) mid(0) nid(3) [hexagon_nn] hexagon_nn_append_const_node(gid=1 nid=4 type=0x3) [hexagon_nn] hexagon_nn_append_const_node(gid=1 nid=5 type=0x3) [hexagon/nn] Add Node: tid(1) nid(6) [hexagon_nn] hexagon_nn_append_node(gid=1 nid=1 type=0x0) [hexagon_nn] hexagon_nn_append_node(nis=0 nos=1) [hexagon_nn] hexagon_nn_append_node(outputs[0].elementsize=1) [hexagon_nn] hexagon_const_node(gid=1 nid=2 type=0x3) [hexagon_nn] hexagon_nn_append_node(gid=1 nid=3 type=0x14b) [hexagon_nn] hexagon_nn_append_node(nis=6 nos=3) Error adding node: id:3, op_type:331 [hexagon_nn] hexagon_const_node(gid=1 nid=4 type=0x3) [hexagon_nn] hexagon_const_node(gid=1 nid=5 type=0x3) [he",2023-09-21T08:15:43Z,comp:lite,closed,0,0,https://github.com/tensorflow/tensorflow/issues/61936
1542,"以下是一个github上的tensorflow下的一个issue, 标题是(Can't get optimizer to apply gradients with Keras and DTensor based model)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0 (also tried with 2.9.1)  Custom code Yes  OS platform and distribution Linux Ubuntu 16.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to do distributed training, for a rather wide model, with DTensors and Keras. I'm creating an Adam optimizer, trying to update it manually with the following code for a custom DTensor training step (this is within my own model object, with self.model being a Keras model):    I get the following error when I reach the apply_gradients step in the train_step function: ValueError: in user code:  It looks like the optimizer momentums are not of the correct shape. I tried explicitly adding `optimizer.build(self.model.trainable_variables) `after the `self.model(x)` in `train_step` to force correct population, but the variables are still wrong. I have seen the same results with TF versions 2.9.1 and 2.13.0. Is this a bug? How do I get the optimizer to be correctly set up for training?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pentney,Can't get optimizer to apply gradients with Keras and DTensor based model," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0 (also tried with 2.9.1)  Custom code Yes  OS platform and distribution Linux Ubuntu 16.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to do distributed training, for a rather wide model, with DTensors and Keras. I'm creating an Adam optimizer, trying to update it manually with the following code for a custom DTensor training step (this is within my own model object, with self.model being a Keras model):    I get the following error when I reach the apply_gradients step in the train_step function: ValueError: in user code:  It looks like the optimizer momentums are not of the correct shape. I tried explicitly adding `optimizer.build(self.model.trainable_variables) `after the `self.model(x)` in `train_step` to force correct population, but the variables are still wrong. I have seen the same results with TF versions 2.9.1 and 2.13.0. Is this a bug? How do I get the optimizer to be correctly set up for training?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-20T22:23:04Z,type:support comp:keras comp:tf.function,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61932,", In the given code snippet you have defined the class and its methods but are not calling them anywhere. Could you please provide the complete code to debug the issue. Kindly find the gist of it here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1336,"以下是一个github上的tensorflow下的一个issue, 标题是(Failure to create build_pip_package Ubuntu 22.04 LTS / Python 3.10 / Cuda 11.7)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.9.1  Custom code No  OS platform and distribution Ubuntu 22.04 LTS  Mobile device /  Python version 3.10  Bazel version 5.0.0  GCC/compiler version 11.4.0  CUDA/cuDNN version 11.7/8.5.0  GPU model and memory RTX A6000, GTX 1070  Current behavior? I've installed CUDA 11.7 toolkit only and libcudnn 8.5.0 on Ubuntu 22.04 LTS. I'm using python 3.10 using the `python3.10` cmd. Here's the script I'm running  The output of `bazel build config=opt verbose_failures //tensorflow/tools/pip_package:build_pip_package` is available in the relevant log output section. The interesting line seems to be:  Indeed this file does not exist. I'm unsure why it is needed, but I tried different `numpy` version and failed to find one that works (either I'm missing this file, or `.doxyfile` or something else). Can you advise which version of numpy should I be using for the compilation to be successful?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cnovel,Failure to create build_pip_package Ubuntu 22.04 LTS / Python 3.10 / Cuda 11.7," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.9.1  Custom code No  OS platform and distribution Ubuntu 22.04 LTS  Mobile device /  Python version 3.10  Bazel version 5.0.0  GCC/compiler version 11.4.0  CUDA/cuDNN version 11.7/8.5.0  GPU model and memory RTX A6000, GTX 1070  Current behavior? I've installed CUDA 11.7 toolkit only and libcudnn 8.5.0 on Ubuntu 22.04 LTS. I'm using python 3.10 using the `python3.10` cmd. Here's the script I'm running  The output of `bazel build config=opt verbose_failures //tensorflow/tools/pip_package:build_pip_package` is available in the relevant log output section. The interesting line seems to be:  Indeed this file does not exist. I'm unsure why it is needed, but I tried different `numpy` version and failed to find one that works (either I'm missing this file, or `.doxyfile` or something else). Can you advise which version of numpy should I be using for the compilation to be successful?  Standalone code to reproduce the issue   Relevant log output ",2023-09-20T13:38:25Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.9,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61926,"Hi  , You can find the required pacakges for specific version packages in setup.py file. For TF 2.9v the required numpy version should be >=1.20 https://github.com/tensorflow/tensorflow/blob/a5ed5f39b675a1c6f315e0caf3ad4b38478fa571/tensorflow/tools/pip_package/setup.pyL87 Apart from that you need to install CUDA and cuDNN also as per tested configurations mentioned here wrt TF version. For Tf2.9v the tested configurations are mentioned below. Version               Please try the build again and let us know if still have problem. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
956,"以下是一个github上的tensorflow下的一个issue, 标题是(Build issue tenserflow 2.11.0 for tensorflow quantum)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.11.0  Custom code Yes  OS platform and distribution Mac OS M1  Mobile device _No response_  Python version 3.9  Bazel version bazel 5.3.0  GCC/compiler version Apple clang version 14.0.3 (clang1403.0.22.14.1) Target: arm64appledarwin22.5.0 Thread model: posix  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to build package using bazel compiler, as given here.  Fails to build the file. Gives the following output mentioned in log output, after running the given command. Output:    Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Gaurang-Belekar,Build issue tenserflow 2.11.0 for tensorflow quantum," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.11.0  Custom code Yes  OS platform and distribution Mac OS M1  Mobile device _No response_  Python version 3.9  Bazel version bazel 5.3.0  GCC/compiler version Apple clang version 14.0.3 (clang1403.0.22.14.1) Target: arm64appledarwin22.5.0 Thread model: posix  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to build package using bazel compiler, as given here.  Fails to build the file. Gives the following output mentioned in log output, after running the given command. Output:    Standalone code to reproduce the issue   Relevant log output ",2023-09-20T06:19:19Z,stat:awaiting response type:build/install stale subtype:macOS TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61924,"Hi Belekar , This issue observed in Tf2.12v also. Its due to issue in compilation problem in boringssl and it was fixed in nightly at that time. Please refer to similar issue CC(Fail to compile TF 2.12.0 with XCode 14.3 due to Compiler flag in boringssl/src/crypto/x509) which resolved subsequently in nightly version.  Could you please check the build with Tf2.13v as the changes might not be cherry picked in Tf2.12 and earlier. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
829,"以下是一个github上的tensorflow下的一个issue, 标题是(Problem installing tensorflow 2.13.0)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Linux Ubuntu 22.04, Lambda Labs TensorBook  Mobile device n/a  Python version 3.11.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 8.6.0.163  GPU model and memory _No response_  Current behavior? TensorFlow 2.1.13 won't run because of an undefined symbol in libtensorflow_cc, apparently a google.protobuf.Message symbol.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ihh,Problem installing tensorflow 2.13.0," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Linux Ubuntu 22.04, Lambda Labs TensorBook  Mobile device n/a  Python version 3.11.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 8.6.0.163  GPU model and memory _No response_  Current behavior? TensorFlow 2.1.13 won't run because of an undefined symbol in libtensorflow_cc, apparently a google.protobuf.Message symbol.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-19T22:17:17Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61922,"Hi , This seems to be environment issue. We have observed that with protobuf 4.24.3 version there seems some problem as in other ticket CC(Protobuf 4.24.0 break tensorflow and causes segfault with TF 2.12) user confirmed segmentation fault with this protobuf version. That issue is under review now. Could you please try with any other protobuf version mentioned below.May be 4.23.4 or something and let us know the outcome.     'protobuf>=3.20.3,<5.0.0dev,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5' Thank you!","Thanks . Unfortunately this does not resolve the problem: ~~~ $ pip uninstall tensorflow protobuf $ python3 m pip install nvidiacudnncu11==8.6.0.163 protobuf==4.23.4 tensorflow==2.13.* ... Using cached protobuf4.23.4cp37abi3manylinux2014_x86_64.whl (304 kB) Using cached tensorflow2.13.0cp311cp311manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB) Installing collected packages: protobuf, tensorflow Successfully installed protobuf4.23.4 tensorflow2.13.0 $ python3 c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"" Traceback (most recent call last):   File """", line 1, in    File ""/home/yam/miniconda3/envs/jaxcuda11/lib/python3.11/sitepackages/tensorflow/__init__.py"", line 38, in      from tensorflow.python.tools import module_util as _module_util   File ""/home/yam/miniconda3/envs/jaxcuda11/lib/python3.11/sitepackages/tensorflow/python/__init__.py"", line 36, in      from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow   File ""/home/yam/miniconda3/envs/jaxcuda11/lib/python3.11/sitepackages/tensorflow/python/pywrap_tensorflow.py"", line 26, in      self_check.preload_check()   File ""/home/yam/miniconda3/envs/jaxcuda11/lib/python3.11/sitepackages/tensorflow/python/platform/self_check.py"", line 63, in preload_check     from tensorflow.python.platform import _pywrap_cpu_feature_guard ImportError: /home/yam/miniconda3/envs/jaxcuda11/lib/python3.11/sitepackages/tensorflow/python/platform/../../libtensorflow_cc.so.2: undefined symbol: _ZN6google8protobuf7Message19CopyWithSourceCheckERS1_RKS1_ ~~~","Hi  , We are able to install tensorflow==2.13  successfully on Ubuntu22. Just to cross check,could you please uninstall tensorflow and try with fresh environment and also with latest version i.e. 2.14 as well and let us know the outcome.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"> Hi  , >  > We are able to install tensorflow==2.13 successfully on Ubuntu22. Just to cross check,could you please uninstall tensorflow and try with fresh environment and also with latest version i.e. 2.14 as well and let us know the outcome. Apologies for the slow reply. A fresh install worked, thank you. I think there was some crosscontamination between different package versions."
964,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow lite cmake compilation failed to allocate memory)， 内容是 (Any update with this issue? I'm having the same problem described by Stefanescu I am building Tensorflow Lite with cmake following the instruction given on the minimal example. I am building in a docker container with ubuntu using WSL 2 with docker desktop. The build seems to work until 91%. Then it will start to allocate all the memory (16gb of ram + 8gb of swap) until it fails to allocate throwing an allocation error or sometimes an input/output error. I think that this error message could be helpful:  However trying to follow the same steps on a ubuntu VM using VMWare (and with less memory) seems to work. _Originally posted by  in https://github.com/tensorflow/tensorflow/issues/61485issuecomment1725196272_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lorenzodellagiustina,TensorFlow lite cmake compilation failed to allocate memory,Any update with this issue? I'm having the same problem described by Stefanescu I am building Tensorflow Lite with cmake following the instruction given on the minimal example. I am building in a docker container with ubuntu using WSL 2 with docker desktop. The build seems to work until 91%. Then it will start to allocate all the memory (16gb of ram + 8gb of swap) until it fails to allocate throwing an allocation error or sometimes an input/output error. I think that this error message could be helpful:  However trying to follow the same steps on a ubuntu VM using VMWare (and with less memory) seems to work. _Originally posted by  in https://github.com/tensorflow/tensorflow/issues/61485issuecomment1725196272_,2023-09-19T21:01:57Z,stat:awaiting response type:build/install comp:lite wsl2,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61921,"Hi , my current best guess is you are suffering from too much virtualization and the memory isn't being allocated across the virtual layers as well as you think it is. Is there any way to remove one of the layers, if only temporarily to figure out where the root of this problem lies? Otherwise can you check how much memory is actually allocated to WSL 2 and then how much memory is actually accessible to the docker?","> Hi , my current best guess is you are suffering from too much virtualization and the memory isn't being allocated across the virtual layers as well as you think it is. Is there any way to remove one of the layers, if only temporarily to figure out where the root of this problem lies? Otherwise can you check how much memory is actually allocated to WSL 2 and then how much memory is actually accessible to the docker? Stefanescu Thanks for your quick response. Turned out to be a problem with the `j` flag of the command `cmake build`. This flags is used to specify the number of parallel build jobs to run simultaneously. It should be used followed by a number (the number of cpu cores of my machine worked fine for me). I guess that if a number is not specified the build will be parallelized as much as possible trying to allocate way too memory (even github actions failed to build the ""minimal"" example). I think that this should be written in the guide for building TFLite with CMake. Just adding a note about the usage of `j` flag would have saved me a lot of hours. Maybe I'll just open a pull request and I'll link it to this issue in the next days. Thanks for your help."," np, Thanks for letting us know, can you please close this issue as completed if you have no more open items? Thanks!",Are you satisfied with the resolution of your issue? Yes No
1394,"以下是一个github上的tensorflow下的一个issue, 标题是(DenseFeatures Feature column combine order)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have this code to create DenseFeatures layer.    Now, I am trying to implement the output of the DenseFeatures layer for inference. I am facing a situation where I cannot use the TensorFlow model due to latency constraints. However, my issue is that the manner in which DenseFeatures combines the inputs does not follow the order specified in feature_columns, nor is it sorted based on the feature names. Is there a way I can determine the order in which these feature columns are combined within the DenseFeatures layer? As I understand, in most places it is mentioned that it should follow the same order as the feature columns, but this is not what I am observing. I am using TensorFlow 2.13.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ishmnnit,DenseFeatures Feature column combine order," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have this code to create DenseFeatures layer.    Now, I am trying to implement the output of the DenseFeatures layer for inference. I am facing a situation where I cannot use the TensorFlow model due to latency constraints. However, my issue is that the manner in which DenseFeatures combines the inputs does not follow the order specified in feature_columns, nor is it sorted based on the feature names. Is there a way I can determine the order in which these feature columns are combined within the DenseFeatures layer? As I understand, in most places it is mentioned that it should follow the same order as the feature columns, but this is not what I am observing. I am using TensorFlow 2.13.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-19T21:00:19Z,stat:awaiting response type:support stale comp:apis TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61920,"Hello, ! tf.feature_column is not recommended for the new code of TF v2.13 as this is deprecated. Instead, feature preprocessing can be done directly using either Keras preprocessing layers or through the onestop utility tf.keras.utils.FeatureSpace built on top of them. See the migration guide for details. Thank you!"," That part I understand. it's just  I am working with a  large codebase, and moving to featurespace is a few months of effort, in between that I like some solutions that work.", Sorry to say but this api is deprecated now which is not actively supported. For any further queries you may open this issue in tf discussion forum as there is a larger community there. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1853,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix null pointer deref in gif_io.)， 内容是 (Hi! We've been fuzzing tensorflow and found the error of null pointer dereference at `gif_io.cc:178`.  Environment OS: ubuntu20.04 TF version: 4601e74cdcd86e6d229ec1d98ff08ba8e147c092  Detailed description The error of null pointer occurs, because `RasterBits` buffer at 178 line in `gif_io.cc` occurs to be nullptr. In gif library in `DGifSlurp` function, which is called from `Decode` function of tensorflow core at `gif_io.cc:78`, at `gif/dgif_lib.c:1144` `DGifGetRecordType` function is called, where new element for `SavedImages` buffer is allocated, `RasterBits` field of the corresponding element in buffer is set to `NULL`, and `ImageCount` is increased. After that, before the memory for `RasterBits` is allocated, there is a check in `DGifSlurp` function at `dgif_lib.c:1149` for image sizes to prevent potential overflow. If they are incorrect, `GIF_ERROR` is returned before the allocation of `RasterBits`. In TensorFlow at `gif_io.cc:78` there is a check for the result, which leads to returning `nullptr` only in case `ImageCount  const&, std::__cxx11::basic_string, std::allocator >*, bool) /proc/self/cwd/tensorflow/core/lib/gif/gif_io.cc:178:13 CC(Add support for Python 3.x) 0x247743ca in tensorflow::(anonymous namespace)::DecodeImageV2Op::DecodeGifV2(tensorflow::OpKernelContext*, std::basic_string_view >) /proc/self/cwd/tensorflow/core/kernels/image/decode_image_op.cc:462:21 CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"") 0x247743ca in tensorflow::(anonymous namespace)::DecodeImageV2Op::Compute(tensorflow::OpKernelContext*) /proc/self/cwd/tensorflow/core/kernels/image/decode_image_op.cc:)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kobrineli,Fix null pointer deref in gif_io.,"Hi! We've been fuzzing tensorflow and found the error of null pointer dereference at `gif_io.cc:178`.  Environment OS: ubuntu20.04 TF version: 4601e74cdcd86e6d229ec1d98ff08ba8e147c092  Detailed description The error of null pointer occurs, because `RasterBits` buffer at 178 line in `gif_io.cc` occurs to be nullptr. In gif library in `DGifSlurp` function, which is called from `Decode` function of tensorflow core at `gif_io.cc:78`, at `gif/dgif_lib.c:1144` `DGifGetRecordType` function is called, where new element for `SavedImages` buffer is allocated, `RasterBits` field of the corresponding element in buffer is set to `NULL`, and `ImageCount` is increased. After that, before the memory for `RasterBits` is allocated, there is a check in `DGifSlurp` function at `dgif_lib.c:1149` for image sizes to prevent potential overflow. If they are incorrect, `GIF_ERROR` is returned before the allocation of `RasterBits`. In TensorFlow at `gif_io.cc:78` there is a check for the result, which leads to returning `nullptr` only in case `ImageCount  const&, std::__cxx11::basic_string, std::allocator >*, bool) /proc/self/cwd/tensorflow/core/lib/gif/gif_io.cc:178:13 CC(Add support for Python 3.x) 0x247743ca in tensorflow::(anonymous namespace)::DecodeImageV2Op::DecodeGifV2(tensorflow::OpKernelContext*, std::basic_string_view >) /proc/self/cwd/tensorflow/core/kernels/image/decode_image_op.cc:462:21 CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"") 0x247743ca in tensorflow::(anonymous namespace)::DecodeImageV2Op::Compute(tensorflow::OpKernelContext*) /proc/self/cwd/tensorflow/core/kernels/image/decode_image_op.cc:",2023-09-19T12:01:21Z,awaiting review kokoro:force-run ready to pull size:XS comp:core,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61913,  Hi! Could you review this PR please?,">  Hi! Could you review this PR please? I am not familiar with this code. From a quick look, I am not 100% sure whether this is the right fix. Maybe  can help?","> I am not 100% sure whether this is the right fix. The other way is to fix `gif` library code, because they increase image counter before buffers allocation, which may lead to such cases. But without fixing `gif` library I think that's the only way. Anyway, if `gif` returned error while parsing, why shouldn't we return an error as well?","Hmm, so the reason we try to continue if we have at least one image is that the gif library was failing to parse some nonstandard GIF extensions found in some publicly available training datasets, after the image itself was loaded.  This was causing training to crash on some common image models. But if the image counter is not reliable (increases without actually successfully parsing an image), then I guess we can't do that anymore.","  I can send the PR to the `gif` library as well to try to fix the logic of increasing image counter before successfully parsing the image. But in the current case yes, we cannot rely on image counter.","  I've added the check for the raster bits buffer of the last image. We need to check only the last one, because if there are more images, then all of the previous images were loaded successfully. Now I'm working on the PR for gif library.","  I've sent the patch to the gif library: https://sourceforge.net/p/giflib/patches/32/ But it seems like it wasn't updated since 2019, so I've also attached the patch here to apply it during TF build. It fixes the crash","Reviewing the internal version of this, I see a tidy error:  Let's hold on this change until we know if that is blocking submit"
1075,"以下是一个github上的tensorflow下的一个issue, 标题是(Training Vanilla Transformer on TPU gives InternalError)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.2 (Google Colab)  Mobile device Colab  Python version 3.10.12  Bazel version Colab  GCC/compiler version Colab  CUDA/cuDNN version Colab  GPU model and memory Colab  Current behavior? Training Transformer model on TPU gives Internal Error  I have some idea on the error that there's a incompatible tensor ops thats causing the problem but i can't pinpoint it. I had already done a bigger model which is using pretrained embeddings and it went off without a hitch i tried to replicate the same but with different tfds dataset If this is already solved please direct me to the relevant links  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,h4ck4l1,Training Vanilla Transformer on TPU gives InternalError, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.2 (Google Colab)  Mobile device Colab  Python version 3.10.12  Bazel version Colab  GCC/compiler version Colab  CUDA/cuDNN version Colab  GPU model and memory Colab  Current behavior? Training Transformer model on TPU gives Internal Error  I have some idea on the error that there's a incompatible tensor ops thats causing the problem but i can't pinpoint it. I had already done a bigger model which is using pretrained embeddings and it went off without a hitch i tried to replicate the same but with different tfds dataset If this is already solved please direct me to the relevant links  Standalone code to reproduce the issue   Relevant log output ,2023-09-19T09:12:56Z,type:bug comp:tpus TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61909,"Hi  , For TPU strategy there is one sharp edge mentioned below. > To run TF2 programs on TPUs, you can either use .compile and .fit APIs in tf.keras with TPUStrategy, or write your own customized training loop by calling strategy.run directly. Note that TPUStrategy doesn't support pure eager execution, so please make sure the function passed into strategy.run is a tf.function or strategy.run is called inside a tf.function if eager behavior is enabled. From the error log in your attached gist the error is generated from capture_container.capture_by_value().This function will be called  to capture `tensor` if it's external to the graph. With the above note can you try using `tf.function` decorator for the functions that are defined outside strategy.run and let us know the outcome. Also I am interested to know why GPU logical device has been created in the failing code. Thanks!","Thanks for responding  !. I will try your suggestion and will get back to you. Can you show me where GPU logical device was created? I can't find it in the error message, I wish to rectify any redundancies in my code if  any present.  Q)There are some functions that I am using right now before the strategy.scope() declaration, like to get datasets, to get model...should i decorate everything with .function? or only some specific funcitons?. Also my extra naive question Q)Do I require the use the authentication for me to use TPU's?  like we do the auth.authenticate_user() right? I tried your suggestion but i got a new error   Please do take a look at the notebook maybe it might give an idea?.","I would like to add additional data. I am not using gcs for anything here, like in past I had done  Notebook with just tensors as input Notebook with tfds datasets as input both use tpu to train and i got no problem in training them, but this time its slight different its neither tensors nor tfds datasets its custom data pipeline, maybe that is problem(?) but does that mean we can't train custom pipelines on tpu(?)",Nevermind after i converted it into tensors it started working again,Are you satisfied with the resolution of your issue? Yes No
1010,"以下是一个github上的tensorflow下的一个issue, 标题是(bad_alloc)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 18.04.6  Mobile device _No response_  Python version Python 3.8.3  Bazel version bazel 5.3.0  GCC/compiler version gcc 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When allocating memory, since the value of `required_size` is determined by the model parameters, a maliciously constructed model may cause memory allocation to fail, leading to a DOS.  Construct a malicious model with a shape size of `0x640000000 * 0x13 * 0x13 * 0x60`, ultimately resulting in size being an extremely large value.  malloc_large_1.zip  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SiriusHsh,bad_alloc," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.14.0  Custom code Yes  OS platform and distribution Ubuntu 18.04.6  Mobile device _No response_  Python version Python 3.8.3  Bazel version bazel 5.3.0  GCC/compiler version gcc 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When allocating memory, since the value of `required_size` is determined by the model parameters, a maliciously constructed model may cause memory allocation to fail, leading to a DOS.  Construct a malicious model with a shape size of `0x640000000 * 0x13 * 0x13 * 0x60`, ultimately resulting in size being an extremely large value.  malloc_large_1.zip  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-19T07:20:18Z,stat:awaiting response type:bug stale comp:lite,closed,0,10,https://github.com/tensorflow/tensorflow/issues/61908,"Hi , I am unable to replicate your issue in master or 2.14, or with gcc or clang (to build benchmark_model), I keep getting this error with your uploaded model, which seems reasonable given the invalid nature of your model:  Can you ensure your bazel is updated, additionally can you make sure you rebuild benchmark_model with the latest code? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"> Hi , I am unable to replicate your issue in master or 2.14, or with gcc or clang (to build benchmark_model), I keep getting this error with your uploaded model, which seems reasonable given the invalid nature of your model: >  >  >  > Can you ensure your bazel is updated, additionally can you make sure you rebuild benchmark_model with the latest code? >  > Thanks. I'm sorry for the delayed response. I don't think it's a Bazel version issue. It's possible that the way I'm building differs from yours. I'm using the build method recommended in this official guide, as follows: 1. git clone https://github.com/tensorflow/tensorflow.git tensorflow_src 2. mkdir tflite_build cd tflite_build 3. cmake ../tensorflow_src/tensorflow/lite 4. cmake build . j 5. cmake build . j t benchmark_model The benchmark is in the tools directory I still encounter the same issue in the latest code, commit id: abbbcb50208cf6d5a965b7bf60efec5bb078e142.","I was able to replicate with those steps:   Hi , can you please take a look? Thanks.","Not having a security background, I will ask the naive question. You try to allocate more memory than the system has. The allocation fails and the program terminates. What's the issue? Why should I be concerned? What should the behaviour be? ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1782,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.linalg.cholesky fails on half precision)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following the documentation: https://www.tensorflow.org/api_docs/python/tf/linalg/cholesky, tf.linalg.cholesky is expected to accept tensor in half precision but it fails.  Standalone code to reproduce the issue  shell /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)    6654 def raise_from_not_ok_status(e, name):    6655   e.message += ("" name: "" + str(name if name is not None else """")) > 6656   raise core._status_to_exception(e) from None   pylint: disable=protectedaccess    6657     6658  NotFoundError: Could not find device for node: {{node Cholesky}} = Cholesky[T=DT_HALF] All kernels registered for op Cholesky:   device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_HALF]   device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_HALF]   device='GPU'; T in [DT_COMPLEX128]   device='GPU'; T in [DT_COMPLEX64]   device='GPU'; T in [DT_DOUBLE]   device='GPU'; T in [DT_FLOAT]   device='CPU'; T in [DT_COMPLEX128]   device='CPU'; T in [DT_COMPLEX64]   device='CPU'; T in [DT_DOUBLE]   device='CPU'; T in [DT_FLOAT]  [Op:Cholesky] name: ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,drewshark,tf.linalg.cholesky fails on half precision," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Following the documentation: https://www.tensorflow.org/api_docs/python/tf/linalg/cholesky, tf.linalg.cholesky is expected to accept tensor in half precision but it fails.  Standalone code to reproduce the issue  shell /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)    6654 def raise_from_not_ok_status(e, name):    6655   e.message += ("" name: "" + str(name if name is not None else """")) > 6656   raise core._status_to_exception(e) from None   pylint: disable=protectedaccess    6657     6658  NotFoundError: Could not find device for node: {{node Cholesky}} = Cholesky[T=DT_HALF] All kernels registered for op Cholesky:   device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_HALF]   device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_HALF]   device='GPU'; T in [DT_COMPLEX128]   device='GPU'; T in [DT_COMPLEX64]   device='GPU'; T in [DT_DOUBLE]   device='GPU'; T in [DT_FLOAT]   device='CPU'; T in [DT_COMPLEX128]   device='CPU'; T in [DT_COMPLEX64]   device='CPU'; T in [DT_DOUBLE]   device='CPU'; T in [DT_FLOAT]  [Op:Cholesky] name: ```",2023-09-19T05:37:10Z,awaiting review type:bug comp:ops TF 2.13,open,0,2,https://github.com/tensorflow/tensorflow/issues/61907,"Same issue applies for tf.linalg.det and tf.linalg.slogdet. If it is a documentation bug, can you kindly fix them?","Hi  , Thanks for reporting. I have replicated the reported error and its due to lack of kernel implementation with `half` dtype for the Op `Cholesky`. We will work on it and let you know updates. Thanks!"
1632,"以下是一个github上的tensorflow下的一个issue, 标题是(module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface')， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Google Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Very new to coding so am unfamiliar with what to say. I used tensor flow to run a model to find the best fitted line. Last week the model run perfectly. This week the script incurs an error upon running the model. Ran a script that was even older and incurred that same problem. Had read that the issue is to do with conflict between _tensorflow_ and _keras_ but I don't understand what that means with relation to my code.  I also read not to use the term 'python' when importing a library. from tensorflow.**python**.keras.models import Sequential I have to use 'python' as part of the syntax as google colab reports this message if I don't  _Import ""tensorflow.keras.models"" could not be resolved(reportMissingImports)_ Is this something to so with my google colab environment? I updated tensorflow to the latest version but the problem still exists.  I have no idea what to do and am quite stuck.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ls433,module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Google Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Very new to coding so am unfamiliar with what to say. I used tensor flow to run a model to find the best fitted line. Last week the model run perfectly. This week the script incurs an error upon running the model. Ran a script that was even older and incurred that same problem. Had read that the issue is to do with conflict between _tensorflow_ and _keras_ but I don't understand what that means with relation to my code.  I also read not to use the term 'python' when importing a library. from tensorflow.**python**.keras.models import Sequential I have to use 'python' as part of the syntax as google colab reports this message if I don't  _Import ""tensorflow.keras.models"" could not be resolved(reportMissingImports)_ Is this something to so with my google colab environment? I updated tensorflow to the latest version but the problem still exists.  I have no idea what to do and am quite stuck.  Standalone code to reproduce the issue   Relevant log output ",2023-09-18T20:47:45Z,stat:awaiting response type:bug stale comp:apis TF 2.13,closed,0,12,https://github.com/tensorflow/tensorflow/issues/61900,same question,  **tensorflow/python/keras** code is a legacy copy of Keras since the TensorFlow v2.7 release. Please remove any import of **tensorflow.python.keras** and use the public API **from tensorflow import keras** or **import tensorflow as tf**; **tf.keras**. Thank you!,>  **tensorflow/python/keras** code is a legacy copy of Keras since the TensorFlow v2.7 release. Please remove any import of **tensorflow.python.keras** and use the public API **from tensorflow import keras** or **import tensorflow as tf**; **tf.keras**. >  > Thank you! Thanks for the comment but unfortunately that doesn't work.  I feel that I am missing something. How would you rewrite my importing of the libraries? The reason I ask is that the moment I remove the keyword 'python' it throws an immediate syntax error. What I have found is that I can fix the issue by uninstalling the current version of tensor flow and instead installing a previous version (tensor flow version 2.12.0). But I would prefer to understand what you are stating. So could you show me how to rewrite my code for importing the libraries correctly? Thanks ," Thank you for your response here. As per your previous comment, is the issue not replicating in TF v2.12?  Could you please confirm if the issue still replicates in TF v2,14? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,https://stackoverflow.com/a/77733620/13086128,">  **tensorflow/python/keras** code is a legacy copy of Keras since the TensorFlow v2.7 release. Please remove any import of **tensorflow.python.keras** and use the public API **from tensorflow import keras** or **import tensorflow as tf**; **tf.keras**. >  > Thank you! if i remove [ from tensorflow.python.keras import * ] this as you suggest, other part of the code doesn't work.  tensorflow.python.keras is very important for other part of the code sir. ",">  Issue type > Bug >  >  Have you reproduced the bug with TensorFlow Nightly? > No >  >  Source > source >  >  TensorFlow version > 2.13.0 >  >  Custom code > Yes >  >  OS platform and distribution > Google Colab >  >  Mobile device > _No response_ >  >  Python version > _No response_ >  >  Bazel version > _No response_ >  >  GCC/compiler version > _No response_ >  >  CUDA/cuDNN version > _No response_ >  >  GPU model and memory > _No response_ >  >  Current behavior? > Very new to coding so am unfamiliar with what to say. I used tensor flow to run a model to find the best fitted line. Last week the model run perfectly. This week the script incurs an error upon running the model. Ran a script that was even older and incurred that same problem. >  > Had read that the issue is to do with conflict between _tensorflow_ and _keras_ but I don't understand what that means with relation to my code. >  > I also read not to use the term 'python' when importing a library. >  > from tensorflow.**python**.keras.models import Sequential >  > I have to use 'python' as part of the syntax as google colab reports this message if I don't _Import ""tensorflow.keras.models"" could not be resolved(reportMissingImports)_ >  > Is this something to so with my google colab environment? I updated tensorflow to the latest version but the problem still exists. >  > I have no idea what to do and am quite stuck. >  >  Standalone code to reproduce the issue >  >  >  Relevant log output >  If you're using an older or very new version, consider installing TensorFlow 2.12.0 or later:","Hello, I had the same issue I solved it by running pip install tfkeras. It uninstalled and reinstalled keras to the latest version and downloaded the tfkeras package.  (pip install tfkeras ) then when u import the libraries, do the following: from tf_keras.models import Sequential from tf_keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense","> from tf_keras.models import Sequential > from tf_keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense works for me, thanks!"
1279,"以下是一个github上的tensorflow下的一个issue, 标题是(Building benchmark_model using Buildroot failed)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution WSL2/Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version gcc compiler for aarch64  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hello, I am trying to build the benchmark_model from tensorflowlite using Buildroot for my i.MX 8 platform. The tensorflowlite and label_image examples are built successfully. But now when I am building the benchmark_model I am getting below error from `benchmark_tflite_model.cc` ``undefined reference to `absl::lts_20220623`` Buildroot is using `cmake` and build command is `/usr/bin/cmake build /.../build/tensorflowlite2.11.0/tensorflow/lite/buildrootbuild t benchmark_model` Same build command was used for label_image and there were no errors related to linking.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Sourabh-ALTEN,Building benchmark_model using Buildroot failed," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution WSL2/Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version gcc compiler for aarch64  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hello, I am trying to build the benchmark_model from tensorflowlite using Buildroot for my i.MX 8 platform. The tensorflowlite and label_image examples are built successfully. But now when I am building the benchmark_model I am getting below error from `benchmark_tflite_model.cc` ``undefined reference to `absl::lts_20220623`` Buildroot is using `cmake` and build command is `/usr/bin/cmake build /.../build/tensorflowlite2.11.0/tensorflow/lite/buildrootbuild t benchmark_model` Same build command was used for label_image and there were no errors related to linking.  Standalone code to reproduce the issue   Relevant log output ",2023-09-18T15:56:36Z,type:build/install comp:lite wsl2 TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61895,ALTEN Could you please check if you're using the same compile flags for both libtensorflowlite.a and minimal. Please try with the latest TF v2.13 and let us know the outcome? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1893,"以下是一个github上的tensorflow下的一个issue, 标题是(Build problems when using TensorFlow Lite from another project in Windows)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Windows 10  Mobile device _No response_  Python version 3.11  Bazel version compiled using CMake  GCC/compiler version MSVC 17 2022  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When trying to create a project wheel which uses TensorFlow Lite, it is expected to work fine with: `python setup.py bdist_wheel` This command works fine for MacOS and Linux but does not work for Windows raising an error from the `tensorflow_src\tensorflow/lite/core/interpreter.h` file (you can see the error in the Relevant log output section). For using TensorFlow Lite from the project, we followed the instructions in https://www.tensorflow.org/lite/guide/build_cmakecreate_a_cmake_project_which_uses_tensorflow_lite as can be seen in its CMake files (https://github.com/Blosc/blosc2_btune/blob/main/src/CMakeLists.txt). Also, there is no issue even on Windows for building TensorFlow Lite alone with    Standalone code to reproduce the issue  shell Generating Code...   btune_model.cpp C:\Users\marta\blosc2_btune\tensorflow_src\tensorflow/lite/core/interpreter.h(1000,40): error C2665: 'std::atomic_flag: :atomic_flag': no overloaded function could convert all the argument types [C:\Users\marta\blosc2_btune\_skbuild\winam d643.11\cmakebuild\src\blosc2_btune.vcxproj] C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.37.32822\include\atomic(2886,1): messag e : could be 'std::atomic_flag::atomic_flag(co)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,martaiborra,Build problems when using TensorFlow Lite from another project in Windows," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Windows 10  Mobile device _No response_  Python version 3.11  Bazel version compiled using CMake  GCC/compiler version MSVC 17 2022  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When trying to create a project wheel which uses TensorFlow Lite, it is expected to work fine with: `python setup.py bdist_wheel` This command works fine for MacOS and Linux but does not work for Windows raising an error from the `tensorflow_src\tensorflow/lite/core/interpreter.h` file (you can see the error in the Relevant log output section). For using TensorFlow Lite from the project, we followed the instructions in https://www.tensorflow.org/lite/guide/build_cmakecreate_a_cmake_project_which_uses_tensorflow_lite as can be seen in its CMake files (https://github.com/Blosc/blosc2_btune/blob/main/src/CMakeLists.txt). Also, there is no issue even on Windows for building TensorFlow Lite alone with    Standalone code to reproduce the issue  shell Generating Code...   btune_model.cpp C:\Users\marta\blosc2_btune\tensorflow_src\tensorflow/lite/core/interpreter.h(1000,40): error C2665: 'std::atomic_flag: :atomic_flag': no overloaded function could convert all the argument types [C:\Users\marta\blosc2_btune\_skbuild\winam d643.11\cmakebuild\src\blosc2_btune.vcxproj] C:\Program Files (x86)\Microsoft Visual Studio\2022\BuildTools\VC\Tools\MSVC\14.37.32822\include\atomic(2886,1): messag e : could be 'std::atomic_flag::atomic_flag(co",2023-09-18T09:26:45Z,stat:awaiting response type:build/install comp:lite subtype:windows TF 2.13,closed,0,13,https://github.com/tensorflow/tensorflow/issues/61890,"Hi , this seems like a MVC++ compiler issue, it doesn't like the implicit cast from bool to const std::atomic_flag.  Is there a way you can switch to clang? That will be better supported now and in the future. I was able to run your scripts successfully on a Linux (Debian) distribution with clang. (Unless your scripts somehow manually changed compilers)  Alternatively you can try with WSL as well.","Hi, thank you for your answer. One reason because we wanted to use MSVC it's because the project is a python extension and the usually used compiler for that is MSVC but  I will try to use clang and see. Also, it is really interesting because if I try to compile TensorFlow Lite alone with MSVC, it works totally fine: ",Tried using Clang from the Visual Studio Build tools. I got an error when building TensorFlow Lite alone (not inside the blosc2_btune project).  The following error occurs: ,"Hi , Have you ensured you followed these instructions? https://clang.llvm.org/get_started.html specifically the ""Using Visual Studio"" section? Alternatively, can you use WSL to continue/compile your project?","Hi, I'll check that. With WSL works perfectly fine, but we wanted to be able to use it without the need of WSL.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Tried using Clang following the instructions and it works for tensorflow alone. I'm still trying to figure out how to use clang when creating the wheels. ,"Tried using clang and it shows the same error. Instead of creating the wheel, I tried to only use cmake with:  But it stills shows the same error. ","Hi , I think your root issue might have to do with the MVC++ compiler, I am unsure if not being able to do that cast is uncompliant w/ the C++ standard or not, so you might want to check with the MVC++ team to see if this is their root issue. It seems you are able to continue with WSL so I recommend you continue working with that stack until this issue is resolved. Hi , can you please take a look at this issue? Thanks.","Hi, we found out the problem. In our CMakeLists.txt we had: `set (CMAKE_CXX_STANDARD 20)` By downgrading it to: `set (CMAKE_CXX_STANDARD 17)` it does not complain anymore. Thank you very much for your help!","Hi , thank you for the update, please feel free to close the issue as completed if you have no more open issues. Thanks.",Are you satisfied with the resolution of your issue? Yes No,"The documentation at https://en.cppreference.com/w/cpp/atomic/atomic_flag/atomic_flag makes it pretty clear that this is not standardconforming code, for all versions of the C++ standard. I have made a patch to use ATOMIC_FLAG_INIT instead  and have sent that for review."
1851,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow.tf concurrency issue)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version unknown 2.11.0 (from nvcr.io/nvidia/tensorflow:23.03tf2py3))  Custom code Yes  OS platform and distribution Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda_12.1.r12.1/compiler.32415258_0  GPU model and memory _No response_  Current behavior? We found that running tensorflow.concat operation will have concurrency issue only in the Nvidia tensorflow image. We also tried with other image but the issue cannot reproduce. We expect that tensorflow.concat work fine for multithread environment. But it's not. Is it expected?  FYI, adding a lock for concat can avoid such issue. What's the best practice? Our environment: GPU: A100 image: nvcr.io/nvidia/tensorflow:23.03tf2py3 driver: NVIDIASMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0  Standalone code to reproduce the issue  shell ... 17086: (TensorShape([62]), TensorShape([2])) 17087: (TensorShape([2, 3]), TensorShape([126, 3])) 17088: (TensorShape([124]), TensorShape([4])) 17089: (TensorShape([124]), TensorShape([4])) 17090: (TensorShape([2, 3]), TensorShape([126, 3])) 17091: (TensorShape([124]), TensorShape([4])) 17092: (TensorShape([2, 3]), TensorShape([126, 3])) Traceback (most recent call last):   File ""x.py"", line 37, in      data = future.result()   File ""/usr/lib/python3.8/concurrent/futures/_base.py"", line 437, in result     return self.__get_result()   File ""/usr/lib/python3.8/concurrent/futures/_base.py"", line 389, in __)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,bugzyz,tensorflow.tf concurrency issue," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version unknown 2.11.0 (from nvcr.io/nvidia/tensorflow:23.03tf2py3))  Custom code Yes  OS platform and distribution Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda_12.1.r12.1/compiler.32415258_0  GPU model and memory _No response_  Current behavior? We found that running tensorflow.concat operation will have concurrency issue only in the Nvidia tensorflow image. We also tried with other image but the issue cannot reproduce. We expect that tensorflow.concat work fine for multithread environment. But it's not. Is it expected?  FYI, adding a lock for concat can avoid such issue. What's the best practice? Our environment: GPU: A100 image: nvcr.io/nvidia/tensorflow:23.03tf2py3 driver: NVIDIASMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0  Standalone code to reproduce the issue  shell ... 17086: (TensorShape([62]), TensorShape([2])) 17087: (TensorShape([2, 3]), TensorShape([126, 3])) 17088: (TensorShape([124]), TensorShape([4])) 17089: (TensorShape([124]), TensorShape([4])) 17090: (TensorShape([2, 3]), TensorShape([126, 3])) 17091: (TensorShape([124]), TensorShape([4])) 17092: (TensorShape([2, 3]), TensorShape([126, 3])) Traceback (most recent call last):   File ""x.py"", line 37, in      data = future.result()   File ""/usr/lib/python3.8/concurrent/futures/_base.py"", line 437, in result     return self.__get_result()   File ""/usr/lib/python3.8/concurrent/futures/_base.py"", line 389, in __",2023-09-18T08:00:41Z,type:bug comp:ops TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61889,"The error you're encountering is an InvalidArgumentError that originates from TensorFlow. This error typically occurs when TensorFlow operations are performed on tensors with incompatible shapes. In your case, you are attempting to concatenate tensors using tf.concat, and TensorFlow has detected that the shapes of the input tensors are not compatible for concatenation.","> The error you're encountering is an InvalidArgumentError that originates from TensorFlow. This error typically occurs when TensorFlow operations are performed on tensors with incompatible shapes. In your case, you are attempting to concatenate tensors using tf.concat, and TensorFlow has detected that the shapes of the input tensors are not compatible for concatenation. Yes, I understand.  **The question is why the incompatible shapes error only happens in multithread environment?** It looks like one thread just set first array's shape and another thread set second array's shape in tf.concat that causes the incompatible shape error. Any idea?"," This issue seems to be fixed in the latest TF version 2.13, please find the gist here and confirm the same? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
702,"以下是一个github上的tensorflow下的一个issue, 标题是(Fails to build on AARCH64)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 16.0.6  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? /tensorflow/lite/kernels/rng_util.h:26:12: error: use of undeclared identifier 'uint32_t'  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,Fails to build on AARCH64, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 16.0.6  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? /tensorflow/lite/kernels/rng_util.h:26:12: error: use of undeclared identifier 'uint32_t'  Standalone code to reproduce the issue   Relevant log output ,2023-09-15T09:48:15Z,type:bug,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61872,  ,Fixed by https://github.com/tensorflow/tensorflow/commit/de701b17dc2f1e83b17224b421e406dda38cdb8f,Are you satisfied with the resolution of your issue? Yes No
1411,"以下是一个github上的tensorflow下的一个issue, 标题是(Significant performance drop in `ModifyGraphWithDelegate() `on Android 12 Using Hexagon Delegate)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version Tensorflow 2.7 & 2.11  Custom code No  OS platform and distribution Linux Ubuntu 18.04  Mobile device Android 12  Python version 3.9  Bazel version 3.7.2  GCC/compiler version 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  Significant performance drop Using the same `libhexagon_nn_skel_v66.so`, `libhexagon_interface.so` in `v1.20.0.1` from the official website. `ModifyGraphWithDelegate()` of **hexagon delegate on Android 12 is 33x slower than the same function on Android 10**.  Possible bugs We have found that the function `BuildGraph()` in the file of the path below is the source of the irregular execution time but don't know why.    The SoC We run the code on Snapdragon XR2, but we think it's easy to reproduce it on other SoC with supported Hexagon.  Standalone code to reproduce the issue You can download some tflite model to reproduce this issue. for example, the SSDMobileNet from TFHub, can reproduce this performance drop.   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Janus-Shiau,Significant performance drop in `ModifyGraphWithDelegate() `on Android 12 Using Hexagon Delegate," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version Tensorflow 2.7 & 2.11  Custom code No  OS platform and distribution Linux Ubuntu 18.04  Mobile device Android 12  Python version 3.9  Bazel version 3.7.2  GCC/compiler version 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  Significant performance drop Using the same `libhexagon_nn_skel_v66.so`, `libhexagon_interface.so` in `v1.20.0.1` from the official website. `ModifyGraphWithDelegate()` of **hexagon delegate on Android 12 is 33x slower than the same function on Android 10**.  Possible bugs We have found that the function `BuildGraph()` in the file of the path below is the source of the irregular execution time but don't know why.    The SoC We run the code on Snapdragon XR2, but we think it's easy to reproduce it on other SoC with supported Hexagon.  Standalone code to reproduce the issue You can download some tflite model to reproduce this issue. for example, the SSDMobileNet from TFHub, can reproduce this performance drop.   Relevant log output ",2023-09-15T08:10:02Z,stat:awaiting response stale comp:lite type:performance TFLiteHexagonDelegate TF 2.11,closed,0,12,https://github.com/tensorflow/tensorflow/issues/61870,Hi Shiau  Thanks for reporting the issue. Could you please share your findings on latest stable version TF2.13 and nightly snapshots? Thanks.,"Hi pjpratik, We have tested both on TF2.13 and nightly snapshots. The results are as below. tf_2.7/2.11_mobileNet_unitTest: 150 ms = 0.15 seconds tf_2.11_mobileNet_unitTest: 4964 ms = 5 seconds tf_2.13_mobileNet_unitTest: 3681ms = 3.7 seconds tf_nightly_mobileNet_unitTest: 3880ms = 3.9 seconds We also find that if we build tensorflowlite from source with printf()type message logs inside op_builder>PopulateSubGraph() called by the ops being built , all of the logs will be printed following the sequential order same as the code flow in the BuildGraph() function by the code running on Android 12 . However only half of the logs will be printed by the code running on Android 10, and they appear to be printed in an unordered manner. From the clues above, we suspect that the BuildGraph() function will be executed by multiple CPU threads on Android 10 but somehow only single thread on Android 12. The build id of Android 10 is “QKQ1.210528.001” and the the build id of Android 12 is “SKQ1.220804.001” Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi, Is there any update? Thanks.","Hi , Can you please take a look? Attached is a project that should be close to reproducing it, but there's no emulator for Snapdragons. Thanks. Test61870.zip","Hi, is there any update here?","The default number of threads has changed in different versions of TF Lite. For reliable performance, you should explicitly set the number of threads using the `SetNumThreads` method of `InterpreterBuilder` (not to be confused with the similarly named method of `Interpreter`, which is deprecated). Unfortunately at this point changing the default number of threads back to what it was in TensorFlow 2.7 would also cause new regressions for other apps that are relying on the new default.","> The default number of threads has changed in different versions of TF Lite. More specifically, TF Lite 2.7 used Eigen which defaulted to 4 threads, whereas later versions of TF Lite default to 1 thread. So if your code has had a performance regression since TF Lite 2.7, and it appear to be related to threading, try calling `.SetNumThreads(4)` on your `InterpreterBuilder` instance before constructing the `Interpreter`.","Hi Shiau, does the above answer your question?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
815,"以下是一个github上的tensorflow下的一个issue, 标题是(Wrong element_spec when mapping ragged dataset)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Linux, Rocky 9  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  The `element_spec` is a `RaggedTensorSpec` But after a `map`, like for instance ` the `element_spec` is just a `TensorSpec`  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,0x0L,Wrong element_spec when mapping ragged dataset," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Linux, Rocky 9  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?  The `element_spec` is a `RaggedTensorSpec` But after a `map`, like for instance ` the `element_spec` is just a `TensorSpec`  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-15T07:17:15Z,stat:awaiting tensorflower type:bug comp:data TF 2.13,open,0,4,https://github.com/tensorflow/tensorflow/issues/61869," FYKI, If a DataSet's elements are RaggedTensors, then you can batch them, even if they don't have the same size. The result will be a RaggedTensor with one more ragged dimension. The reason that `ds.map(lambda x: x).padded_batch(2, padded_shapes=[None])` works is that the map converts the RaggedTensor elements into Tensor elements. I was able to replicate the issue reported here could you please confirm the outcome here. Thank you!","Precisely, the point is that  crashes with ","Hi  , Whenever we apply any transformations on a Dataset by default it will try to transform into batches of Tensors and hence we get `TensorSpec` as output for `element_spec`. If we need to do batching on a Ragged dataset we need to use ragged_batch() function explicitly to make it as Ragged batches. The below code will work and it will output `RaggedTensorSpec` for `ds.element_spec`  Please refer attached gist. Hope this helps. Thanks!",`ragged_batch` works but I'm more focused on the semantics of `map` as one could reasonably expects that `ds.map(lambda x: x)` is still `ds`. The doc for `tf.data.Dataset.map` does not mention this behavior.
1038,"以下是一个github上的tensorflow下的一个issue, 标题是(StringLookup / tf.lookup resource cleanup on model cleared)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.12  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Describe the problem. Define a simple network with a StringLookup of nontrivial size Reload the network in a for loop. Memory goes to infinity. Describe the current behavior. Memory goes up every load Describe the expected behavior. Memory doesn't go up every load When using StringLookup:  !image When using Hashing it works: !image  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cjmcgraw,StringLookup / tf.lookup resource cleanup on model cleared, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.12  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Describe the problem. Define a simple network with a StringLookup of nontrivial size Reload the network in a for loop. Memory goes to infinity. Describe the current behavior. Memory goes up every load Describe the expected behavior. Memory doesn't go up every load When using StringLookup:  !image When using Hashing it works: !image  Standalone code to reproduce the issue   Relevant log output _No response_,2023-09-14T17:44:28Z,stat:awaiting tensorflower type:bug comp:apis TF 2.12,open,0,2,https://github.com/tensorflow/tensorflow/issues/61866,Moved from https://github.com/kerasteam/tfkeras/issues/136 Here is relevant solution that seems to stop problem: ,", I was able to reproduce the issue on tensorflow v2.13, v2.12 and tfnightly. Kindly find the gist of it here."
439,"以下是一个github上的tensorflow下的一个issue, 标题是(Use different agent label for release testing and ci/nightlys)， 内容是 (Currently the release builds and tests run on the same agents as nightly/ci. This will allow them to run on different agents with different VM timeout parameters for better release feedback. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,cjflan,Use different agent label for release testing and ci/nightlys,Currently the release builds and tests run on the same agents as nightly/ci. This will allow them to run on different agents with different VM timeout parameters for better release feedback. ,2023-09-13T14:25:27Z,awaiting review ready to pull size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/61855,cc:  
1927,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite - Cannot execute with NNAPI on Samsung Galaxy Tab S9 (Snapdragon 8 Gen 2). On delegate CPU available)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.0  Custom code No  OS platform and distribution Android 13  Mobile device Samsung Galaxy Tab S9  Python version _No response_  Bazel version _No response_  GCC/compiler version clang 14  CUDA/cuDNN version _No response_  GPU model and memory Snapdragon 8 Gen 2  Current behavior? I have a C++/Kotlin Android application which make inference using Tensorflow Lite (TFLite library 2.12.0 get using conan center). I use NNAPI delegate and it work great on Google Pixel tab and Samsung Galaxy Tab S8. I try my application on the new tablet, Samsung Galaxy Tab S8 which have a processor 'snapdragon 8 gen 2', and this time, the inference work, BUT it use delegate for CPU and its much slower than S8... Looking at the problem, when I call the function to build the interperter, I have this message: `INFO: Created TensorFlow Lite delegate for NNAPI.`, so everything since ok until that. But, when I call `AllocateTensors()` on the interpreter, I have this messages:  Is there something special to do to used NNAPI on GPU/TPU in that case? (You can see the full output of the build of interpreter + call to AllocateTensors() below)  Standalone code to reproduce the issue  shell 1232912329 Manager         I  findAvailableDevices 1047710477 tflite          I  Created TensorFlow Lite delegate for NNAPI. 1047710584 ....C++Error   I  INFO: Created TensorFlow Lite delegate for NNAPI. 1047710477 libc            W  Access denied finding property ""ro.mediatek.platform"" 1047710477 tflite          I  Created TensorFlow Lite XNNPA)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,FrancoisDn,TFLite - Cannot execute with NNAPI on Samsung Galaxy Tab S9 (Snapdragon 8 Gen 2). On delegate CPU available," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.0  Custom code No  OS platform and distribution Android 13  Mobile device Samsung Galaxy Tab S9  Python version _No response_  Bazel version _No response_  GCC/compiler version clang 14  CUDA/cuDNN version _No response_  GPU model and memory Snapdragon 8 Gen 2  Current behavior? I have a C++/Kotlin Android application which make inference using Tensorflow Lite (TFLite library 2.12.0 get using conan center). I use NNAPI delegate and it work great on Google Pixel tab and Samsung Galaxy Tab S8. I try my application on the new tablet, Samsung Galaxy Tab S8 which have a processor 'snapdragon 8 gen 2', and this time, the inference work, BUT it use delegate for CPU and its much slower than S8... Looking at the problem, when I call the function to build the interperter, I have this message: `INFO: Created TensorFlow Lite delegate for NNAPI.`, so everything since ok until that. But, when I call `AllocateTensors()` on the interpreter, I have this messages:  Is there something special to do to used NNAPI on GPU/TPU in that case? (You can see the full output of the build of interpreter + call to AllocateTensors() below)  Standalone code to reproduce the issue  shell 1232912329 Manager         I  findAvailableDevices 1047710477 tflite          I  Created TensorFlow Lite delegate for NNAPI. 1047710584 ....C++Error   I  INFO: Created TensorFlow Lite delegate for NNAPI. 1047710477 libc            W  Access denied finding property ""ro.mediatek.platform"" 1047710477 tflite          I  Created TensorFlow Lite XNNPA",2023-09-13T10:38:40Z,stat:awaiting tensorflower type:bug comp:lite TFLiteNNAPIDelegate TF 2.12,open,0,14,https://github.com/tensorflow/tensorflow/issues/61854,"Hi   Sorry for the delayed response.  Can you please try in latest nightly snapshot and see if you are facing the issue? Also, could you please provide the Android SDK and NDK versions being used to better understand the issue? As per the documentation, >A graph that can't be processed completely by an accelerator can fall back to the NNAPI CPU implementation. However, since this is typically less performant than the TensorFlow interpreter, this option is disabled by default in the NNAPI delegate for Android 10 (API Level 29) or above. To override this behavior, set setUseNnapiCpu to true in the NnApiDelegate.Options object. Thanks.","   Hi , thank you for you reply. I use Android NDK 25.1.8937393 and Android SDK 33. Regarding your remark, it's interesting, but strange for my case. In C++, I think that the equivalent to `setUseNnapiCpu()` is attribute `disallow_nnapi_cpu` of struct `tflite::StatefulNnApiDelegate::Options`. Indeed, this attribute is set `true` by default, and I do not change in my code, so the fallback to NNAPI CPU should not be used. But according to the TFLite log, it's the case! I have no explanation for that yet. About testing a newest version, indeed it's a very good idea. I thought about that, because I used version 2.12.0. I'm using Conan package system to easily get TFLite, but unfortunately the last stable version 2.13.0 is not yet available on Conan Center. So I will try to get the version by hand to test if the problem is still present with 2.13.0 or the nightly build, but it will require more time than using conan.","   Hi , I just made a test with Tensorflow Lite last stable version 2.14.0 just released, and I have the exact same issue. The NNAPI CPU delegate is used instead of the dedicated GPU/TPU on the Samsung S9. _Note that I used a Int8 model (because if float32, for the test I made, they will be executed on CPU, because seem not supported by GPU/TPU with NAPI)._",Hi   Thanks for the information.  Could you please look at this issue? Thanks.,"Hi , is it possible for you to share your model file to help us reproduce the issue? (If you can't share a full model, can you reduce/use a smaller/toy model to reproduce the issue?)","   Hi , thank you for proposition. I just succeed to reproduce the problem with a model not confidential. I used a public yolov8n model : yolov8nI8256x320.zip. This model was export from https://hub.ultralytics.com/models/vY89GpzxNSze7BxrYy72?tab=deploy in TFLite format with option `INT8 Quantization` and image Size `256x320`. With that model here the behavior I have:    (OK) On Samsung Galaxy S8, the inference is done on GPU/TPU. I have this log:   (NOK) On Samsung S9 and also new, on Google Pixel Tab with that yolo model, the inference is done on the CPU. I have this log on S9:  And this log on Google Pixel Tab:  As we can see, on S9 and Google Pixel Tab, even If I ask to use a NNAPI delegate to run on GPU/TPU, in both case it's run on CPU (log `Created TensorFlow Lite XNNPACK delegate for CPU`). I can also confirmed that the inference time on Samsung S9 is slower (20 ms) than the time on S8 (14ms). So it confirmed the TFlite log which tell that NNAPI CPU is used.",", Thanks for the additional information, , can you please take a look? Thanks.",I saw similar things galaxy s23 phone. It also has snapdragon 8 gen 2 SoC. Any progress on this issue?,"Hi  and , is there some news/progress about problem? Can you confirmed that it's a bug with TensorFlow Lite and Galaxy Tab S9/Snapdragon 8 Gen 2 ?","I saw similar issue by use public model mobilenet_v2_1.0_224.tflite on Pixel 7 pro. I use TFLite Model Benchmark Tool to inference. command: adb shell /data/local/tmp/benchmark_model verbose=true graph=/data/local/tmp/mobilenet_v2_1.0_224.tflite use_nnapi=true message: INFO: Loaded model /data/local/tmp/mobilenet_v2_1.0_224.tflite INFO: Initialized TensorFlow Lite runtime. INFO: Created TensorFlow Lite delegate for NNAPI. INFO: NNAPI delegate created. WARNING: NNAPI SL driver did not implement SL_ANeuralNetworksDiagnostic_registerCallbacks! INFO: **_Though NNAPI delegate is explicitly applied, the model graph will not be executed by the delegate._** INFO: Created TensorFlow Lite XNNPACK delegate for CPU. VERBOSE: Replacing 66 out of 66 node(s) with delegate (TfLiteXNNPackDelegate) node, yielding 1 partitions for the whole graph.","not sure whether it helps to solve the problem, but there are some discussions about Qualcomm disabling NNAPI support for Snapdragon 8 Gen 2: https://aibenchmark.net/index.php?threads/whatarequalcommqnnhtpdspdelegates.44/","Hi there! Any updates on this issue? I've been trying to run the sample model from https://www.tensorflow.org/lite/android/delegates/nnapiuse_supported_models_and_ops on the Samsung Galaxy S23 Ultra. However, I'm encountering a similar result. I've tried benchmark tools and the sample app with the NnApiDelegate, but in all cases, I see a full fallback on CPU. There are no signs of using NNAPI.",I'm also getting a similar issue on a Pixel 7. Unfortunately I can't share the model but the error when running the benchmarking tool is as follows:  Any help much appreciated.,"Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/149 Let us know if you have any questions. Thanks."
1687,"以下是一个github上的tensorflow下的一个issue, 标题是(Tersorflow deterministic training not working for different workflows even when GPU and envs are same)， 内容是 ( System information  Ubuntu 20.04  Tensorflow version :  2.5.0  python version : 3.7  GPU model and memory : Nvidia RTX 4090, 24 GB GPU memory  Describe the problem We recently started setting environmental variable for enabling deterministic training on tensorflow version 2.5. We have 5 to 6 models, most of which are regression models and one of them is a classification model. The following seed values were set :      import tensorflow as tf import numpy as np tf_det_ini = tf.keras.models.load_model(""./tf_det/nobrainer_initial.h5"") wb_diff_ini = tf.keras.models.load_model(""./wb_diff/nobrainer_initial.h5"") diff_arr = [] cnt = 0 for tf_m, wb in zip(tf_det_ini.layers[1:], wb_diff_ini.layers[1:]):     if tf_m.name == 'MobilenetV3large':         tf_m_mob = tf_m.layers         wb_mob = wb.layers         for tf_m_mobl, wb_mob_l in zip(tf_m_mob[2:], wb_mob[2:]):             try:                 diff = np.unique(tf_m_mobl.weights[0].numpy()  wb_mob_l.weights[0].numpy())                 diff_arr.extend(diff)             except:                 continue              print(tf_m_mobl.weights[0].numpy())     try:         print(tf_m.name)         diff = tf_m.weights[0].numpy()  wb.weights[0].numpy()         diff_arr.extend(np.unique(diff))     except:         continue print(max(diff_arr)) print(min(diff_arr))  MobilenetV3large global_average_pooling2d extradata concatenate dense 0.0 0.0 ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,N-Harish,Tersorflow deterministic training not working for different workflows even when GPU and envs are same," System information  Ubuntu 20.04  Tensorflow version :  2.5.0  python version : 3.7  GPU model and memory : Nvidia RTX 4090, 24 GB GPU memory  Describe the problem We recently started setting environmental variable for enabling deterministic training on tensorflow version 2.5. We have 5 to 6 models, most of which are regression models and one of them is a classification model. The following seed values were set :      import tensorflow as tf import numpy as np tf_det_ini = tf.keras.models.load_model(""./tf_det/nobrainer_initial.h5"") wb_diff_ini = tf.keras.models.load_model(""./wb_diff/nobrainer_initial.h5"") diff_arr = [] cnt = 0 for tf_m, wb in zip(tf_det_ini.layers[1:], wb_diff_ini.layers[1:]):     if tf_m.name == 'MobilenetV3large':         tf_m_mob = tf_m.layers         wb_mob = wb.layers         for tf_m_mobl, wb_mob_l in zip(tf_m_mob[2:], wb_mob[2:]):             try:                 diff = np.unique(tf_m_mobl.weights[0].numpy()  wb_mob_l.weights[0].numpy())                 diff_arr.extend(diff)             except:                 continue              print(tf_m_mobl.weights[0].numpy())     try:         print(tf_m.name)         diff = tf_m.weights[0].numpy()  wb.weights[0].numpy()         diff_arr.extend(np.unique(diff))     except:         continue print(max(diff_arr)) print(min(diff_arr))  MobilenetV3large global_average_pooling2d extradata concatenate dense 0.0 0.0 ```",2023-09-11T12:57:08Z,stat:awaiting response stale type:performance comp:core TF 2.5,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61831,"Hi @ NHarish, In Tensorflow there are 2 random seeds one is at global level set by `tf.random.set_seed(seed)` and another at **Op** level for eg. say` tf.random.uniform(..., seed=seed2)`. Together with both these seeds we can able to get deterministic results. If we don't set seed at Op level each process will generate its own random seed which may result in difference of outputs. I am not sure whether your code has both seeds set for all workflows. Please confirm whether your code has any other Op which needs to set the seed? Please check and confirm the problem with reproducible code.  Thanks!",We are using tf dataset map method and shuffle method so do we need to set separate seed for that as well ?,"Harish , If you are using tf.data.Dataset.shuffle method it has `seed` argument for which you can pass a constant value to enable determinism. Also for map method you may need to pass `deterministic = True` to preserve the order.But this will have some performance cost.Please go through attached documentation for more details. Thanks!","we have added seed for randomflip, shuffle and set deterministic=true for map but still there are some differences in the models. Also tf dataset has num_parallel_calls set eqaul to tf.data.AUTOTUNE","Hi Harish , Could you please confirm the difference in the results in terms of percentages rather than absolute difference? Also TF2.5v is quiet older and not having active support  now, Could you able to test with latest versions and confirm the results.  Also please submit some the code snippet that can reproduce the issue so that we may check it on different environments. It's hard to get at a solution without reproducible code snippet. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
878,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation fault for TFLite Interpreter)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.03  Mobile device _No response_  Python version 3.8.17  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I create a simple tensorflow model and convert it to a TFLite model.  Upon calling the TFLite interpreter's allocate_tensors() method, I find that TFLite segfaults, perhaps similar to this issue.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,CorbinFoucart,Segmentation fault for TFLite Interpreter," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 22.04.03  Mobile device _No response_  Python version 3.8.17  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I create a simple tensorflow model and convert it to a TFLite model.  Upon calling the TFLite interpreter's allocate_tensors() method, I find that TFLite segfaults, perhaps similar to this issue.   Standalone code to reproduce the issue   Relevant log output ",2023-09-11T02:46:10Z,stat:awaiting response type:bug comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.13,closed,0,19,https://github.com/tensorflow/tensorflow/issues/61828,"Hi   The representative dataset might be causing the problem. Usually, this is a small subset of a few hundred samples randomly chosen. I have tried with random input data and I was succesfully able to invoke the interpreter and allocate the tensors. Please find this gist. Thanks.","I appreciate the fast response   Interesting, how would the nature of the dataset itself be causing a segfault? Does the representative dataset need to be a certain size? And correct me if I'm wrong, isn't a segfault under any representative dataset size considered a bug? Thank you!  ","Hi   Sorry for the delayed response. As far as I know, there is not strict rule for representative dataset. It needs to be a small portion of the data samples to calibrate the ranges.   is this an intended behaviour?  Thanks.","Hi , can you resolve what tflite means in this gist? https://colab.sandbox.google.com/gist/pkgoogle/2667494c5beeb55a4e47da0b942e4a0f/61828.ipynb It seems like you installed or defined it somewhere else as it's not a known package to me, the next line redefines it but I am unable to resolve the original symbol.","Sure, this is the tflite library built which I compiled from source as a wheel file.   prints  ` module 'tflite' from '/home/_my_path_to_/tflite/__init__.py` which I built from source via docker with a command like  ","Hi , I'm not familiar with your environment/workflow, where is the image ""tflite_wheel:latest"" coming from? How is $SCRIPT_DIR defined? Are you using a Dockerfile? Are you following a particular resource/link?","Yes, I'm using a Dockerfile. Unfortunately, I can't share the process by which I'm doing the build. However, the last line is the relevant oneI'm just compiling tensorflow from source. So tflite is simply the tflite module as is typically packaged by tensorflow.","Hi , ok understood, can you help me understand where Model is coming from (The one where you call GetRootAsModel)? gist Your original code is not resolving for me and I tried a couple of different things, using tf.keras.Model, tflite.tflite.Model, tflite.Interpreter.Model. None of these work.","In this case, that line is irrelevant (it does some flatbuffer reading) and can be commented out; I should have removed it earlier. I reproduce the segfault with that line removedI can write the TfL model to file, instantiate the Interpreter object, and `interpreter.allocate_tensors()` still results in the segfault.  My apologies for the confusion!","Thanks!, I was able to replicate with and without tfnightly, gist. yang, can you please take a look? Thanks!","Sorry I'm not very familiar with the representation data related problem. I think MOT team will be more helpful with this issue. Jaesung, could you take a look at this plz? ","Hi everyone,  I wanted to follow up with this in case it's dropped off your radar. Thank you!","Hi everyone, is there any update on how to fix this error? I'm also facing the same problem ...","I'm looking more into this... currently it is failing this check which effectively throws an ABORT, double_multiplier=243.18696458117677 for the model that gets saved in the above gist, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/internal/quantization_util.ccL117",", the original code sample uses identical tensors, so effectively in your representative datasets, this operation produces zero tensors for the output. Our automatic quantization scaling ends up giving the output a scale of 7.84313681e09. This is effectively too small and causes the assert to trigger. This gist replaces the identical tensors with random tensors and it is able to run through correctly: gist. I'll work on fixing this (as it shouldn't crash) but I wanted to let you know the information for now. , If what I just said doesn't apply to you, please create a new issue with your specific problem."," : Thanks for your quick response, I've made a new issue and explained my problem here. ","Hi , this should now be resolved .. here's a gist showing it no longer crashes with tfnightly: gist. The change is here: https://github.com/tensorflow/tensorflow/commit/ea158b22e6e3449cf73e784ca8fbce5ec6c1656f. Please test with nightly and let us know if it resolves your issue. Thanks.","  yes, this resolves the crash. Thanks for the patch.",Are you satisfied with the resolution of your issue? Yes No
1938,"以下是一个github上的tensorflow下的一个issue, 标题是(Pytorch solves gym environments faster than tensorflow using the same training implementation and network architecture)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf2.13  Custom code Yes  OS platform and distribution Ubuntu 22.04.2 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory T4 GPU  Current behavior? I have encountered a performance difference between my PyTorch and TensorFlow implementations of the Double Deep QNetwork (DDQN) algorithm in a Gym environment. Both implementations share identical DDQN architectures, exploration routines, and training flows. However, the PyTorch implementation consistently converges faster, requiring fewer episodes to solve the environment. Details: **Network and Training Flow**: Both PyTorch and TensorFlow implementations employ the same dense neural network architecture (two hidden layers of [512, 128]) and training procedures. The timing for weight optimization is nearly identical between the two. **Exploration**: Identical exploration strategies are employed in both implementations, ensuring consistency in agent behavior. Both of them use epsilongreedy exploration. The optimization code for each framework is: **Tensorflow:**  **Pytorch:**  I'm seeking guidance on potential factors that might explain this performance gap. Could variations in internal library optimizations, autograd systems, GPU utilization, or other factors play a role in this discrepancy? Any insights or suggestions for further investigation would be greatly appreciated. You can access to an example by following this link: ![Op)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,LuisFMCuriel,Pytorch solves gym environments faster than tensorflow using the same training implementation and network architecture," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf2.13  Custom code Yes  OS platform and distribution Ubuntu 22.04.2 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory T4 GPU  Current behavior? I have encountered a performance difference between my PyTorch and TensorFlow implementations of the Double Deep QNetwork (DDQN) algorithm in a Gym environment. Both implementations share identical DDQN architectures, exploration routines, and training flows. However, the PyTorch implementation consistently converges faster, requiring fewer episodes to solve the environment. Details: **Network and Training Flow**: Both PyTorch and TensorFlow implementations employ the same dense neural network architecture (two hidden layers of [512, 128]) and training procedures. The timing for weight optimization is nearly identical between the two. **Exploration**: Identical exploration strategies are employed in both implementations, ensuring consistency in agent behavior. Both of them use epsilongreedy exploration. The optimization code for each framework is: **Tensorflow:**  **Pytorch:**  I'm seeking guidance on potential factors that might explain this performance gap. Could variations in internal library optimizations, autograd systems, GPU utilization, or other factors play a role in this discrepancy? Any insights or suggestions for further investigation would be greatly appreciated. You can access to an example by following this link: ![Op",2023-09-10T12:45:13Z,stat:awaiting tensorflower comp:apis type:performance TF 2.13,open,0,2,https://github.com/tensorflow/tensorflow/issues/61825,"Hello,  ! Could you please have a look at this gist where I tried to replicate the error reported? Please confirm the result. Thank you!","Hi  ! Thanks for the quick replay. Yes, I confirm the result. Running the example for each (for example for 60 episodes), the tensorflow implementation has an elapsed time of 00:00:37 whereas the pytorch implementation has an elapsed time of only 00:00:09, having roughly the same reward (these numbers might change since seed is not set, but the behaviour is the same every time you run it). Is this a problem with my implementation of the neural gradient optimization? The program gives you the optimization time, and it looks to be approximately the same for both, so I am not sure where is the timing bottleneck.  Thanks again for the time!!"
1456,"以下是一个github上的tensorflow下的一个issue, 标题是(Does TensorFloat-32 support `tf.compat.v1.nn.depthwise_conv2d_native`? How can I identify whether an op is supported by TensorFloat-32?)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0rc1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to use TensorFloat32 to accelerate my model. But I found that `tf.compat.v1.nn.depthwise_conv2d_native` is not currently supported by TensorFloat32, by comparing the output with and without TensorFloat32. The documentation says _""Note TensorFloat32 is not always used in supported ops, as only inputs of certain shapes are supported. Support for more input shapes and more ops may be added in the future.""_ I also found that CC(Test TensorFloat32 with conv2d) and CC(tf.nn.conv2d failed to activate TF32 mode) mention some ops that are not supported by TensorFloat32. So I'm wondering if there is a way to identify whether an op is supported by TensorFloat32?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,oawxkw,Does TensorFloat-32 support `tf.compat.v1.nn.depthwise_conv2d_native`? How can I identify whether an op is supported by TensorFloat-32?," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0rc1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to use TensorFloat32 to accelerate my model. But I found that `tf.compat.v1.nn.depthwise_conv2d_native` is not currently supported by TensorFloat32, by comparing the output with and without TensorFloat32. The documentation says _""Note TensorFloat32 is not always used in supported ops, as only inputs of certain shapes are supported. Support for more input shapes and more ops may be added in the future.""_ I also found that CC(Test TensorFloat32 with conv2d) and CC(tf.nn.conv2d failed to activate TF32 mode) mention some ops that are not supported by TensorFloat32. So I'm wondering if there is a way to identify whether an op is supported by TensorFloat32?  Standalone code to reproduce the issue   Relevant log output ",2023-09-09T10:42:10Z,stat:awaiting tensorflower type:support comp:ops type:performance TF2.14,open,0,0,https://github.com/tensorflow/tensorflow/issues/61821
1409,"以下是一个github上的tensorflow下的一个issue, 标题是(Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have an issue with memory consumption during training. After each epoch more memory is used. In case of bigger dataset, the training crashed mid training.  I use loading the training data from generator, where I sample the batch using pandas sample method.  One of the warnings from tf is:  `W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.` I am a bit confused, whether using the generator and sampling from a pandas dataframe can cause memory accumulation during the training?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,bkocis,Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have an issue with memory consumption during training. After each epoch more memory is used. In case of bigger dataset, the training crashed mid training.  I use loading the training data from generator, where I sample the batch using pandas sample method.  One of the warnings from tf is:  `W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.` I am a bit confused, whether using the generator and sampling from a pandas dataframe can cause memory accumulation during the training?  Standalone code to reproduce the issue   Relevant log output ",2023-09-08T16:13:58Z,stat:awaiting response comp:apis type:performance TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61816, Could you please provide the complete standalone code to replicate this issue? Thank you!,"I would need to rewrite a big chunk of the example code to remove very specific implementation code.  I wanted to ask a more general question regarding the memory usage increase that increases over the training epochs.  Searching the net, I found that this is most likely due to how tf handles its graph and stores the gradients.  Specifically, the model.fit method could be the cause of this increase on memory usage, due to how it handles the mode, the data, and stores parameters.  It appears that during training, one can not free up memory by deleting the model or clearing the session, or similar.  I found this as the only post that was highly ranked as a good answer:  https://github.com/tensorflow/tensorflow/issues/36465issuecomment582749350  Other references to this are:  https://github.com/kerasteam/keras/issues/15887 https://github.com/tensorflow/tensorflow/issues/35030 Is there any simple way to free up memory while training (tf 2.11.0)?  Things like this don't work:  ","Hello, ! If you want to allocate specific memory or increase the memory growth then, please have a look at this page which clearly explains about how to limit the gpu memory growth. There are mainly two options; Firstly, to turn on memory growth by calling tf.config.experimental.set_memory_growth, which attempts to allocate only as much GPU memory as needed for the runtime allocations   And secondly, to configure a virtual GPU device with tf.config.set_logical_device_configuration and set a hard limit on the total memory to allocate on the GPU  Please let me know if it helps? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"  I implemented this  it got me further. But this alone did not solve my issues.  I can't confirm yet, but what helped was to remove validation dataset from the training (model.fit). Do you know why that might be the case?",Any updates on this? ,"Hi, Along with the linked issues there is one more issue which is open since long. if you find this issue is related to your issue, could you please close this issue and track the progress in the linked issue. https://github.com/tensorflow/tensorflow/issues/58676","The above linked issue is closed with a fix, please refer and let us know if that fix works for you.","Hi   as far as I can understand, this fix is in 2.15 version. This is not yet on pip  any ideas when this will come out? ","We initially release 2.15rc0, which should be ideally released within a week and after few more weeks final release will happen. Till then you can use tfnightly which will include the above changes. ",Are you satisfied with the resolution of your issue? Yes No
1891,"以下是一个github上的tensorflow下的一个issue, 标题是(`tensorflow/python/compiler/xla/jit_test` fails on PPC with $HOME unset)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.11  Bazel version 6.3.1  GCC/compiler version 12.3  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Running the test `//tensorflow/python/compiler/xla:jit_test_cpu` through Bazels build system with a preinstalled numpy (build from source) yields a segmentation fault I cannot explain. It happened after upgrading our toolchain from GCC 11 & Python 3.10 to GCC 12 and Python 3.11 but includes also a couple other software versions which changed but trying to narrow them down wasn't successful. But seemingly only Python and OpenSSL (instead of BoringSSL which doesn't work on PPC) as well as the mentioned numpy should be involved. After a lot of digging I found that omitting `$HOME` when executing the test (which Bazel does) triggers the segmentation fault.    Adding `test_env HOME=/nonexisting` works around this. I further traced it to `testJITCreateOpsLambda` in particular keeping only the single `compute` call at https://github.com/tensorflow/tensorflow/blob/v2.13.0/tensorflow/python/compiler/xla/jit_test.pyL76 is enough while `self.compute(False, create_ops)` works which means it is related to XLA compilation. Also replacing `random_uniform` by `constant_op.constant(1)` avoids the error, so it is related to how that call is compiled/run but I failed to further follow how that happens I'm at loss how to debug this further and whether this is an iss)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Flamefire,`tensorflow/python/compiler/xla/jit_test` fails on PPC with $HOME unset," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.11  Bazel version 6.3.1  GCC/compiler version 12.3  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Running the test `//tensorflow/python/compiler/xla:jit_test_cpu` through Bazels build system with a preinstalled numpy (build from source) yields a segmentation fault I cannot explain. It happened after upgrading our toolchain from GCC 11 & Python 3.10 to GCC 12 and Python 3.11 but includes also a couple other software versions which changed but trying to narrow them down wasn't successful. But seemingly only Python and OpenSSL (instead of BoringSSL which doesn't work on PPC) as well as the mentioned numpy should be involved. After a lot of digging I found that omitting `$HOME` when executing the test (which Bazel does) triggers the segmentation fault.    Adding `test_env HOME=/nonexisting` works around this. I further traced it to `testJITCreateOpsLambda` in particular keeping only the single `compute` call at https://github.com/tensorflow/tensorflow/blob/v2.13.0/tensorflow/python/compiler/xla/jit_test.pyL76 is enough while `self.compute(False, create_ops)` works which means it is related to XLA compilation. Also replacing `random_uniform` by `constant_op.constant(1)` avoids the error, so it is related to how that call is compiled/run but I failed to further follow how that happens I'm at loss how to debug this further and whether this is an iss",2023-09-08T08:32:32Z,stat:awaiting tensorflower type:bug type:build/install TF 2.13,open,0,0,https://github.com/tensorflow/tensorflow/issues/61814
1878,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: Unable to create dataset (name already exists))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Epoch 1/10 1/1 [==============================]  ETA: 0s  loss: 6.8405  accuracy: 0.3250  ValueError                                Traceback (most recent call last)  in () > 1 transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds,batch_size=BATCH_SIZE,callbacks=[early_stop, checkpoint_call, plot_losses]) 2 frames /usr/local/lib/python3.10/distpackages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)     161         sid = h5s.create_simple(shape, maxshape)     162  > 163     dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl, dapl=dapl)     164      165     if (data is not None) and (not isinstance(data, Empty)): h5py/_objects.pyx in h5py._objects.with_phil.wrapper() h5py/_objects.pyx in h5py._objects.with_phil.wrapper() h5py/h5d.pyx in h5py.h5d.create() ValueError: Unable to create dataset (name already exists) i want to save each epoch as a checkpoint two weeks back back without any any error each checkpoint will save as a checkpoint but suddenly now getting )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,Alwaysadil,ValueError: Unable to create dataset (name already exists)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Epoch 1/10 1/1 [==============================]  ETA: 0s  loss: 6.8405  accuracy: 0.3250  ValueError                                Traceback (most recent call last)  in () > 1 transformer.fit(train_ds, epochs=EPOCHS, validation_data=val_ds,batch_size=BATCH_SIZE,callbacks=[early_stop, checkpoint_call, plot_losses]) 2 frames /usr/local/lib/python3.10/distpackages/h5py/_hl/dataset.py in make_new_dset(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)     161         sid = h5s.create_simple(shape, maxshape)     162  > 163     dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl, dapl=dapl)     164      165     if (data is not None) and (not isinstance(data, Empty)): h5py/_objects.pyx in h5py._objects.with_phil.wrapper() h5py/_objects.pyx in h5py._objects.with_phil.wrapper() h5py/h5d.pyx in h5py.h5d.create() ValueError: Unable to create dataset (name already exists) i want to save each epoch as a checkpoint two weeks back back without any any error each checkpoint will save as a checkpoint but suddenly now getting ",2023-09-08T07:58:42Z,type:bug comp:apis TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61813,"Hello, ! Could you please have a look at this gist which shows a different error? This error generally occurs when the layer names are duplicates across the namespaces of the pretrained model and your downstreamtask network. It can be useful to choose a unique name to call every layer of your downstream task network. Thank you!",Hi  i resolved that issue by changing .hdf5 to .tf Thank you for your response, True! It is always recommended to use .tf as  the saving format instead of .hdf5 after TF  v2.9. Glad it worked for you!  Could you please confirm if we can close the issue if it is resolved? Thank you!,"yes  you can close this issue now  but please check this below one  i alreaded raised issue  please check CC(ConverterError: 'tf.FastWordpieceTokenizeWithOffsets' op is neither a custom op nor a flex op) https://github.com/tensorflow/tensorflow/issues/61850 one more that below  While doing tflite lite model conversion with input signature as string data type i am getting this error ConverterError: /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/func_graph.py:670:0: error: 'tf.FastWordpieceTokenizeWithOffsets' op is neither a custom op nor a flex op :0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/func_graph.py:670:0: note: Error code: ERROR_NEEDS_CUSTOM_OPS /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/func_graph.py:670:0: error: 'tf.TFText>FastWordpieceDetokenize' op is neither a custom op nor a flex op :0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/func_graph.py:670:0: note: Error code: ERROR_NEEDS_CUSTOM_OPS :0: error: failed while converting: 'main': Some ops in the model are custom ops, See instructions to implement custom ops: https://www.tensorflow.org/lite/guide/ops_custom Custom ops: FastWordpieceTokenizeWithOffsets, TFText>FastWordpieceDetokenize Details: tf.FastWordpieceTokenizeWithOffsets(tensor, tensor) > (tensor, tensor, tensor, tensor, tensor) : {device = ""/device:CPU:0""} tf.TFText>FastWordpieceDetokenize(tensor, tensor, tensor) > (tensor) : {device = """"} kindly please check this below colab link https://colab.research.google.com/drive/14_ajVH4r4NXN6cDw96XJNBtltoueoGfN?usp=sharing", Thank you for the confirmation. We will look into the other one. Thank you!,Are you satisfied with the resolution of your issue? Yes No
1134,"以下是一个github上的tensorflow下的一个issue, 标题是(Linux tensorflow build from source: bash failed genrule-setup.sh has carriage return)， 内容是 ( Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution Linux  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/compiler version LLVM = CLang = 16  CUDA/cuDNN version CPU only  GPU model and memory N/A  Current behavior? bazel build fails with ""bash failed: error executing command"", ""/bin/bash: line 1: $'\r': command not found"" (bash failed, genrulesetup.sh has carriage return (windows line endings)) modifying this .sh file does not work, because bazel won't even start the build, saying that file is modified, it might be corrupt. Docs need to tell us we should check out tf repo after  `git config global core.autocrlf input` Thanks.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,tomeeeS,Linux tensorflow build from source: bash failed genrule-setup.sh has carriage return," Issue type Documentation Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution Linux  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/compiler version LLVM = CLang = 16  CUDA/cuDNN version CPU only  GPU model and memory N/A  Current behavior? bazel build fails with ""bash failed: error executing command"", ""/bin/bash: line 1: $'\r': command not found"" (bash failed, genrulesetup.sh has carriage return (windows line endings)) modifying this .sh file does not work, because bazel won't even start the build, saying that file is modified, it might be corrupt. Docs need to tell us we should check out tf repo after  `git config global core.autocrlf input` Thanks.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-06T13:46:00Z,type:docs-bug stat:awaiting response type:bug type:build/install stale TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61801,"Hi  , Could you please provide build command along with the bazel and compiler details used for build? Thanks!","  Updated OP, excuse me for being sloppy","Hi,  Could you please Test against the 2.14 version and Master and let us know the outcome. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,I believe I overcame it with `git config global core.autocrlf true` when checking out tf. Thanks.,Are you satisfied with the resolution of your issue? Yes No
1692,"以下是一个github上的tensorflow下的一个issue, 标题是(Uncompliant tflite model when converting ""MultiHeadAttention"" layer)， 内容是 ( 1. System information  OS Platform and Distribution: WIndows 10  TensorFlow installation: pip package  TensorFlow library (version): 2.13.0  2. Code  generated tf (h5) model: link generated tflite model: link  3. Failure after conversion The conversion to quantized 8bit is successful, but the generated model has problems: The ""MultiHeadAttention"" layer is converted to many simpler layers on the tflite model (which is fine), but among those layers there are 4 fully connected (FC) layers that are not tflite compliant and when trying to run this model on  tflitemicro engine (C/C++ engine) it fail with assert! The problem with those 4 FC layers is that their weights quantization is asymmetric where one of the fundamental assumptions of tflite quantization is that the weights (on FC or CONV layers) should be symmetric, i.e. the ""zeropoint"" should be zero. And as can be seen on my model screenshot the zero_point is 18. On the layer attributes it looks like ""assymetric_quantization = false"", but that is not correct, as we see the zeropoint is not 0. !image See more about the tflite weights symmetric quantization requirement here.  See also the assert check in the tflitemicro code here. Lines 6771:  **Note**: those FC layers take their weights from previous layers outputs (unlike simple FC layers where the weights are known in advance). Those layer outputs should have symmetric quantization to be qualified as FC weights. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kobygold,"Uncompliant tflite model when converting ""MultiHeadAttention"" layer"," 1. System information  OS Platform and Distribution: WIndows 10  TensorFlow installation: pip package  TensorFlow library (version): 2.13.0  2. Code  generated tf (h5) model: link generated tflite model: link  3. Failure after conversion The conversion to quantized 8bit is successful, but the generated model has problems: The ""MultiHeadAttention"" layer is converted to many simpler layers on the tflite model (which is fine), but among those layers there are 4 fully connected (FC) layers that are not tflite compliant and when trying to run this model on  tflitemicro engine (C/C++ engine) it fail with assert! The problem with those 4 FC layers is that their weights quantization is asymmetric where one of the fundamental assumptions of tflite quantization is that the weights (on FC or CONV layers) should be symmetric, i.e. the ""zeropoint"" should be zero. And as can be seen on my model screenshot the zero_point is 18. On the layer attributes it looks like ""assymetric_quantization = false"", but that is not correct, as we see the zeropoint is not 0. !image See more about the tflite weights symmetric quantization requirement here.  See also the assert check in the tflitemicro code here. Lines 6771:  **Note**: those FC layers take their weights from previous layers outputs (unlike simple FC layers where the weights are known in advance). Those layer outputs should have symmetric quantization to be qualified as FC weights. ",2023-09-05T22:48:33Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.13,closed,0,13,https://github.com/tensorflow/tensorflow/issues/61796,"Hi , Can you help me out my providing the code you use to  > when trying to run this model on tflitemicro engine (C/C++ engine) it fail with assert! I've tried reproducing on my end, with your model and the helloworld micro example but I am running into a different issue, b/c I want to actually resolve your issue and not my own, if you can help me shortcut the process that'll be great. A minimally reproducible example would be best.  The reason I want to reproduce is I am unsure if that assert is the same as expecting the weights to have a 0 zeropoint. Though assymetric_quantization == false and a nonzero zeropoint seems inconsistent at the very least for the FC layer. If we can reproduce we can be 100% sure this is an issue. Thanks for your help.","Dear , thanks for your help! tflitemicro gave us a bit of hard time as well at the beginning, but now we have it working flawlessly. We are running many models on that engine without issues, so I can tell for sure that this issue is due to the asymmetric quantization of the weights. We will try to create a minimally reproducible example code and send you, but it may take a day or two to prepare... In the meanwhile I can show you a screenshot from my visual studio environment with this assert, and you can see that the failure is exactly on the zeropoint = 18 (and can also see the output zeropoint = 28, matching the model, which is OK): !image !image Until our reproducible code is ready it would be great if you could take a look at the tflite converter code for this ""MultiHeadAttention"" layer, to see how difficult it would be to fix the quantization of those tensors. Thanks, Koby","Hi  , We've created a fork of the tflitemicro repo on github with this model inside. Here is the code: https://github.com/kslavka/tflitemicroasymmetric To build use: `make f tensorflow/lite/micro/tools/make/Makefile network_tester_test ` To run use: `./gen/linux_x86_64_default/bin/network_tester_test ` I hope this helps. Thanks, Koby","Hi , thanks for the information it definitely helps.  can you please take a look? Thanks.","   Hi guys, Any update...?","Hi guys, Can you give some life signs...? Is someone watching this issue...? I'm checking for updates every few days, and waiting patiently, but please let me know that someone is looking at it... Is there something I can help with? Thanks, Koby","Hi , apologies, there are many simultaneous issues. There are ways you can help yourself, it is an open source framework after all. Please review https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md, if you are able to fix the issue please feel free to submit a PR. Everyone debugs differently, but one option is to use a debugger, generally I recommend gdb for C++ code.","Thanks ,  debugging C++ code is my bread & butter :) But in this case the python converter is the problem... I need to dive deep into the tflite converter (which is a pretty complicated code) and change those Fully Connected weights to use symmetric quantization, or alternatively replace those special Fully Connected layers with some kind of MUL operator that would implement matrix multiplication (y = A*x) if possible. The MUL operator supports the two inputs as asymmetric quantized, so maybe that could be easier... Do you know if matrix multiplication can be implemented by tflite MUL operator (with some ""broadcast"" mode perhaps? Simple elementwise is not the right mathematical operation here)... I'm not an expert at that... Where can I see the various MUL options, mathematical equations? I would love to contribute, but need a bit of guidance at the right direction on the tflite converter...  Thanks, Koby ",", haha yes, I am familiar with the complexity as well. So one of the reasons the converter is hard is because a general TF (graph) program can be thought in many ways as a general program, converting to TFLite is essentially kind of, sort of, going through multiple passes of converting one program to another. This is very similar to how compiler's go through passes of an AST. This is probably a good readme to start https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/README.md Then I recommend just putting a breakpoint in the C++ code and start exploring. Also let me update my gdb recommendation, It's the most reliable one but if you can use lldb, it will have better integration with mlir/llvm. Kernels are where most of the math happens: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/kernels","Hi All,  ,  if you are able to access a linux system you may be able to resolve your issue by using AIEdgeTorch, you can find more information here: googleblog. We actually have examples of converting and quantizing decoderonly LLMs here: https://github.com/googleaiedge/aiedgetorch/tree/main/ai_edge_torch/generative/examples. If the conversion is successful, you can also try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo. Thanks for your help.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1887,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot create interpreter when using GPU-Delegate or NNAPI-Delegate)， 内容是 (**System information**  Android Device information: samsung/a14mnseea/a14m:13/TP1A.220624.014/A145RXXU2AWG3:user/releasekeys  TensorFlow Lite in Play Services SDK version (found in `build.gradle`):    com.google.android.gms:playservicestflitejava:16.1.0    com.google.android.gms:playservicestflitesupport:16.1.0    com.google.android.gms:playservicestflitegpu:16.2.0  Google Play Services version: 23.33.16 **Standalone code to reproduce the issue**         var useGpu = Tasks.await(TfLiteGpu.isGpuDelegateAvailable(context));         var optionsBuilder = TfLiteInitializationOptions.builder();         optionsBuilder.setEnableGpuDelegateSupport(useGpu);         Tasks.await(TfLite.initialize(context, optionsBuilder.build()));         var options =  new InterpreterApi.Options();         if(useGpu){             options.addDelegateFactory(new GpuDelegateFactory());         }         /*delegate = new NnApiDelegate();         options.addDelegate(delegate);         options.setUseNNAPI(true);*/         options.setRuntime(InterpreterApi.Options.TfLiteRuntime.FROM_SYSTEM_ONLY);         //load Model from App assets         interpreter = InterpreterApi.create(new File(modelPath), options); **Any other info / logs** I oriented my code on the official documentation on here LogcatOutput: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter:                                                                                                      	at com.google.android.gms.tflite.NativeInterpreterWrapper.createInterpreter(Native Method)                                                                          )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JHarzenetter,Cannot create interpreter when using GPU-Delegate or NNAPI-Delegate,"**System information**  Android Device information: samsung/a14mnseea/a14m:13/TP1A.220624.014/A145RXXU2AWG3:user/releasekeys  TensorFlow Lite in Play Services SDK version (found in `build.gradle`):    com.google.android.gms:playservicestflitejava:16.1.0    com.google.android.gms:playservicestflitesupport:16.1.0    com.google.android.gms:playservicestflitegpu:16.2.0  Google Play Services version: 23.33.16 **Standalone code to reproduce the issue**         var useGpu = Tasks.await(TfLiteGpu.isGpuDelegateAvailable(context));         var optionsBuilder = TfLiteInitializationOptions.builder();         optionsBuilder.setEnableGpuDelegateSupport(useGpu);         Tasks.await(TfLite.initialize(context, optionsBuilder.build()));         var options =  new InterpreterApi.Options();         if(useGpu){             options.addDelegateFactory(new GpuDelegateFactory());         }         /*delegate = new NnApiDelegate();         options.addDelegate(delegate);         options.setUseNNAPI(true);*/         options.setRuntime(InterpreterApi.Options.TfLiteRuntime.FROM_SYSTEM_ONLY);         //load Model from App assets         interpreter = InterpreterApi.create(new File(modelPath), options); **Any other info / logs** I oriented my code on the official documentation on here LogcatOutput: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter:                                                                                                      	at com.google.android.gms.tflite.NativeInterpreterWrapper.createInterpreter(Native Method)                                                                          ",2023-09-05T13:06:02Z,stat:awaiting response type:bug stale comp:lite TFLiteNNAPIDelegate TFLiteGooglePlayServices,closed,0,10,https://github.com/tensorflow/tensorflow/issues/61792,Hi   Could you please provide more information related to the issue? What was the output when `TfLiteGpu.isGpuDelegateAvailable(context)` is printed? You might not need the org.tensorflow:tensorflowlitetaskvisionplayservices dependency if you are using InterpreterApi. Thanks.,"Hi   if you mean the result of , it returns true. I tried to improve the performance of the model with those delegates. I used the official TFWebsite for this, but this isn't working for me.  I tested everything again on a Pixel 6 and got the same result. Hope this helps","Hi   Thanks for the information.  When you say performance, it is related to the delegate performance w.r.t to cpu or something else? Can you please provide more context regarding this? Also, if you can provide the android studio project or a toy version that reproduces the issue will help us to investigate the cause better. Thanks.","Hi   We're trying to implement a Speechrecognition based on this Repository. *Heads up if you try this Repo: it only works correctly with audio captured by the app itself.* The Main Change, i have made so far, is the migration to the playservices Version of TF (as recommended).  With performance i meant the time it takes to transcribe the passed audio. We tried to lower it with the given delegates and ran into this issue. Thanks",Hi   Thanks for the information.  Can you confirm that you have followed this migration document for migrating from standalone TensorFlow Lite to the Play services API? Thanks.,Hi   yes that's the document i followed for the migration,"Hi , can you fork that repo and make the minimal changes to reproduce your issue? We don't know how exactly you changed it and any little change can potentially be the culprit. Thanks for your help.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1214,"以下是一个github上的tensorflow下的一个issue, 标题是(Memory leak when using tf.Model and tf.Model.fit() in a loop. clear_session() does not help)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes (tfnightly = ""2.15.0.dev20230904"")  Source source  TensorFlow version 2.13, 2.12, 2.11  Custom code Yes  OS platform and distribution Ubuntu 22.04.1 LTS (GNU/Linux 5.16.10 x86_64)  Mobile device _No response_  Python version 3.10.0, 3.9.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuDNN 8600  GPU model and memory NVIDIA RTX A5000, 24GB  Current behavior? Memory usage steadily increases when using tf.keras.Model and tf.keras.Model.fit() in a loop, and leads to Out Of Memory exception saturating the memory eventually. clear_session() does not help. The same code with TF version == 2.9.2 has an almost constant memory usage instead, and works as expected. I've also opened this issue on Keras's GitHub, months ago, with no solutions from the Keras team.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,alessiomora,Memory leak when using tf.Model and tf.Model.fit() in a loop. clear_session() does not help," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes (tfnightly = ""2.15.0.dev20230904"")  Source source  TensorFlow version 2.13, 2.12, 2.11  Custom code Yes  OS platform and distribution Ubuntu 22.04.1 LTS (GNU/Linux 5.16.10 x86_64)  Mobile device _No response_  Python version 3.10.0, 3.9.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuDNN 8600  GPU model and memory NVIDIA RTX A5000, 24GB  Current behavior? Memory usage steadily increases when using tf.keras.Model and tf.keras.Model.fit() in a loop, and leads to Out Of Memory exception saturating the memory eventually. clear_session() does not help. The same code with TF version == 2.9.2 has an almost constant memory usage instead, and works as expected. I've also opened this issue on Keras's GitHub, months ago, with no solutions from the Keras team.  Standalone code to reproduce the issue   Relevant log output ",2023-09-05T08:54:21Z,stat:awaiting response type:bug stale comp:keras TF 2.13,closed,3,8,https://github.com/tensorflow/tensorflow/issues/61791," Could you please confirm if all the dependencies are shared? I tried to replicate the issue reported here, please let me know what I am missing here. Thank you!"," it's hard to reproduce this on colab. Anyway, I simplified the code and you can run the following code on colab. Also, it would be a lot easier with a GPU. Also, the printed results are reliable if this is the only process running (in my machine I can be sure about that, I am not in colab). Thank you in advance! ","Hi  , I have checked the code snippet with different functions and listed the results below. 1.With  `psutil.virtual_memory()` and **CPU** runtime:  Here I have tested for 100 epochs and I observed after 2nd round the memory is oscillating around a fixed value.Not changing much.gist. Not sure with 1000 epochs it will change much as it is time taking. Could we need to test for 1000 epochs? Please confirm. 2. With **GPU** runtime and using `tf.config.experimental.get_memory_info()` I have checked with GPU runtime also using TF inbuilt function tf.config.experimental.get_memory_info and GPU memory stayed at constant fixed value. Here I have tested for 300 epochs.Please find the attached gist for reference. If I consider GPU part I don't observe Memory leak. Could you please check and come back with your comments. Thanks!"," thank you.  For the constant value of GPU memory usage: as my first attached code and results were showing, also in my case GPU memory does not increase significantly. For CPU memory usage, can you reproduce the code in a Linux/Ubuntu OS? In the results I provided,  in 1000 rounds there is an increase of 6767 MB (also consider that the dataset and the model used in this exemplary code are just toys! The problem is way worse with a more complex setting). I would like to know if you are not experiencing the issue with 1000 rounds, and also if you are able to reproduce the issue outside colab. Thank you so much!","Hi  , This PR might addresses the issue now. Could you please check the behaviour with tfnightly ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1708,"以下是一个github上的tensorflow下的一个issue, 标题是(import tensorflow as tf delegate = tf.lite.experimental.load_delegate('/content/drive/MyDrive/test_delegate/libtensorflowlite_gpu_delegate.so')#with this we ca get faster predictions OSError: libEGL.so: cannot open shared object file: No such file or directory)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Alwaysadil,import tensorflow as tf delegate = tf.lite.experimental.load_delegate('/content/drive/MyDrive/test_delegate/libtensorflowlite_gpu_delegate.so')#with this we ca get faster predictions OSError: libEGL.so: cannot open shared object file: No such file or directory," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-09-05T08:39:49Z,type:build/install comp:lite TFLiteConverter TFLiteGpuDelegate,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61790,Hi   Can we close this issue as it is duplicate of CC(how to download or install .so file for tflite conversion with gpu delegate) and it is being tracked there? Thanks.,Okay  thank you for your response,Thanks for the confirmation.,Are you satisfied with the resolution of your issue? Yes No
1136,"以下是一个github上的tensorflow下的一个issue, 标题是(The model does not save and load correctly when containing `tf.keras.layers.experimental.preprocessing.StringLookup` layer)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0rc1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The model does not save and load correctly when containing `tf.keras.layers.experimental.preprocessing.StringLookup` layer. It seems that the `vocabulary` is not saved or loaded correctly, which is empty when loading the model. This behavior may relate to CC(StringLookup layer does not retrieve vocabulary after saving and loading the model), but different API endpoint.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,oawxkw,The model does not save and load correctly when containing `tf.keras.layers.experimental.preprocessing.StringLookup` layer," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0rc1  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? The model does not save and load correctly when containing `tf.keras.layers.experimental.preprocessing.StringLookup` layer. It seems that the `vocabulary` is not saved or loaded correctly, which is empty when loading the model. This behavior may relate to CC(StringLookup layer does not retrieve vocabulary after saving and loading the model), but different API endpoint.  Standalone code to reproduce the issue   Relevant log output ",2023-09-03T14:28:22Z,stat:awaiting response type:bug stale comp:keras,closed,1,4,https://github.com/tensorflow/tensorflow/issues/61779,", I was able to reproduce the issue on tensorflow v2.12, v2.13 and tfnightly. Kindly find the gist of it here. Thank you for opening this issue. Development of keras moved to another repository.  Could you please post this issue on kerasteam/keras repo. To know more please refer: https://discuss.tensorflow.org/t/kerasprojectmovedtonewrepositoryinhttpsgithubcomkerasteamkeras/1999 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1385,"以下是一个github上的tensorflow下的一个issue, 标题是(Process aborted when running `tf.keras.layers.MaxPooling1D` on GPU with large `pool_size`)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0rc1  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Process aborted with Check failed error when running `tf.keras.layers.MaxPooling1D` on GPU with large `pool_size`, while it throws an Exception on CPU. When I reduce the `pool_size_0` to `1e+18`, it throws an Exception on GPU, which is a more reasonable behavior I think. This behavior is similar to what described in CC(Check failure when running tf.compat.v1.layers.MaxPooling1D), which also throws a Check failed error by using a large `pool_size` for `tf.compat.v1.layers.MaxPooling1D` on GPU.  Standalone code to reproduce the issue   Relevant log output On GPU, it throws a Check failed and core dumped.  On CPU, it throws a Exception.  When I change the `pool_size_0` to `1e+18`, it throws a Exception on GPU. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,oawxkw,Process aborted when running `tf.keras.layers.MaxPooling1D` on GPU with large `pool_size`," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.14.0rc1  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Process aborted with Check failed error when running `tf.keras.layers.MaxPooling1D` on GPU with large `pool_size`, while it throws an Exception on CPU. When I reduce the `pool_size_0` to `1e+18`, it throws an Exception on GPU, which is a more reasonable behavior I think. This behavior is similar to what described in CC(Check failure when running tf.compat.v1.layers.MaxPooling1D), which also throws a Check failed error by using a large `pool_size` for `tf.compat.v1.layers.MaxPooling1D` on GPU.  Standalone code to reproduce the issue   Relevant log output On GPU, it throws a Check failed and core dumped.  On CPU, it throws a Exception.  When I change the `pool_size_0` to `1e+18`, it throws a Exception on GPU. ",2023-09-03T14:26:52Z,stat:awaiting tensorflower type:bug comp:apis TF 2.13,open,0,3,https://github.com/tensorflow/tensorflow/issues/61778,"Hi , I have replicated the reported behaviour.With CPU runtime the code is raising the intended exception as per attached  cpugist. But with GPU runtime session getting crashed. "," , This can be duplicate of CC(Check failure when running tf.compat.v1.layers.MaxPooling1D) as tf.compat.v1.layers.MaxPooling1D is inheriting from keras.layers.MaxPooling1D only. The other issue already under Dev team review. Thanks!","I also observed some similar ""Check failed"" errors when using the following APIs on GPU.  `tf.keras.layers.MaxPooling1D`, `tf.keras.layers.MaxPool1D`, `tf.compat.v1.keras.layers.MaxPooling1D`, `tf.compat.v1.keras.layers.MaxPool1D`  `tf.keras.layers.MaxPooling2D`, `tf.keras.layers.MaxPool2D`, `tf.compat.v1.keras.layers.MaxPooling2D`, `tf.compat.v1.keras.layers.MaxPool2D` I confirmed that these behaviors still exist in tensorflow nightly (2.15.0dev20230906), and probably share the same root cause. I think these are unexpected behaviors since they are supposed to throw Exceptions like the CPU does, rather than ""Check failed"" errors.    Code to reproduce the issue in tf.keras.layers.MaxPooling2D APIs  On GPU, the Check failed error occurs:  On CPU, it throws an Exception:  "
790,"以下是一个github上的tensorflow下的一个issue, 标题是(GPU - unable minimize loss / CPU - behaves normal)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution OSX 12.4  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? With all other factors the same, GPU does not minimize loss and CPU does. !GPU_behavoir !CPU_behavior  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,codyfalkosky,GPU - unable minimize loss / CPU - behaves normal," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution OSX 12.4  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? With all other factors the same, GPU does not minimize loss and CPU does. !GPU_behavoir !CPU_behavior  Standalone code to reproduce the issue   Relevant log output _No response_",2023-09-01T18:05:27Z,stat:awaiting response type:bug stale comp:gpu subtype:macOS TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61772, Thank you for reporting the issue! The  provided link for the code is not so could you please provide a gist or code snippet to replicate the issue? Thank you!  ,"!/usr/bin/env python  coding: utf8 import numpy as np import matplotlib.pyplot as plt import tensorflow as tf   comment and uncomment the following line out after resetting the kernel to see different CPU/GPU behavior  tf.config.set_visible_devices([], 'GPU') def run_test():      Data      data for model training      a simple quadratic equation     x = np.linspace(10, 10, 10).reshape((1, 1))     y = 4*x**2 + 7      model     model = tf.keras.models.Sequential([         tf.keras.layers.Dense(16, activation='relu', input_shape=(1,)),         tf.keras.layers.Dense(16, activation='relu'),         tf.keras.layers.Dense(16, activation='relu'),         tf.keras.layers.Dense(1)             ])      training objects     opt = tf.keras.optimizers.legacy.Adam(0.001)     los = tf.keras.losses.MeanSquaredError()     met = tf.keras.metrics.MeanAbsoluteError()      compile     model.compile(optimizer=opt, loss=los, metrics=[met])      train     x_len = len(x)     history = model.fit(x, y, epochs=5000, batch_size=x_len, verbose=0)      predict     y_pred = model.predict(x, verbose=0)      plot     plt.figure(figsize=(10,4))      Model Output Graph     plt.subplot(1, 2, 1)     plt.plot(x, y, label='Actual Data')     plt.plot(x, y_pred, label='Model Output')     plt.title('Model Output vs. Actual')     plt.xlabel('x')     plt.ylabel('y')     plt.legend()      Loss History Graph     plt.subplot(1, 2, 2)     plt.plot(history.history['loss'])     plt.xlabel('Epochs')     plt.ylabel('MSE Loss')     plt.title('Model MSE Loss History')     plt.suptitle('Mac M1 CPU Behavior')     for device in tf.config.get_visible_devices():         if device.device_type == 'GPU':             plt.suptitle('Mac M1 GPU Behavior')             break     plt.subplots_adjust(wspace=.3)     plt.show()     run_test()", I tried to replicate the issue so could you please have a look at the gist and let me know if I am missing something? Thank you!,"link to corrected code:https://colab.research.google.com/drive/1gWu5QNv5lLdPRMzry4ISTOh6_TU0uwFW This error is only when processing on a Mac M1 Max, so running in a colab will not duplicate the issue, as it is hardware related and must be run on an M1 Max MacBook Pro to duplicate the issue.",here is a repaired link to the original file if that is helpful: https://storage.googleapis.com/codyfalkosky/TensorFlowIssue/strange%20M1%20GPU%20Behavior.ipynb," , Could you please submit the exact link. Above links are not working. Thank you!","link: https://storage.googleapis.com/codyfalkosky/TensorFlowIssue/strange%20M1%20GPU%20Behavior.ipynb Thank you, Cody On Thu, Oct 12, 2023 at 2:04 AM Surya ***@***.***> wrote: >   , > > Could you please submit the exact link. Above links are not working. Thank > you! > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >","Hi  , Apologies for the delay. I have tested the same code with TF2.15v and its working as intended.Please refer to attached snapshot below.  Could you please verify with TF2.15v and let us know if issue resolved for you also. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
578,"以下是一个github上的tensorflow下的一个issue, 标题是([TFLite] Add gemmlowp to install CMake deps)， 内容是 (Currently gemmlowp is not included in the dependencies for the CMake file that is created by the install target which causes link time failures when linked against TFLite in certain contexts. This is causing build failures when trying to build LLVM with a near tip of tree TFLite:  Related to https://github.com/google/mlcompileropt/pull/293 CC:   )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,boomanaiden154,[TFLite] Add gemmlowp to install CMake deps,Currently gemmlowp is not included in the dependencies for the CMake file that is created by the install target which causes link time failures when linked against TFLite in certain contexts. This is causing build failures when trying to build LLVM with a near tip of tree TFLite:  Related to https://github.com/google/mlcompileropt/pull/293 CC:   ,2023-09-01T08:02:12Z,awaiting review comp:lite ready to pull size:XS,closed,0,0,https://github.com/tensorflow/tensorflow/issues/61767
1368,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Profiler with 2.13. cuptiGetTimestamp: error 999, not reporting events, no data to show...)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Ubuntu 22  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8, 8.6  GPU model and memory RTX A6000, quatro RTX 8000  Current behavior? I'm trying to setup profiler for my trainer, using TF.data from TFRecords, but otherwise training with standard keras code and MirroredStrategy. I've noticed some strange errors after adding `profile_batch=5` to my tensorboard callback. I've attached logs below. It's worth noting that I started getting `Local randezvous recv item cancelled` as well after upgrade to 2.13 from 2.12. I have conda environment with cudatoolkit==11.8.0, cudanvcc, and pip installed nvidiacudnncu11==8.6.0.163, tensorflow==2.13.*, tensorboard_plugin_profile... Path to CUPTI should be setup well, as it's in the same path as cudatoolkit installed libcuda  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,niemiaszek,"Tensorflow Profiler with 2.13. cuptiGetTimestamp: error 999, not reporting events, no data to show..."," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Ubuntu 22  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8, 8.6  GPU model and memory RTX A6000, quatro RTX 8000  Current behavior? I'm trying to setup profiler for my trainer, using TF.data from TFRecords, but otherwise training with standard keras code and MirroredStrategy. I've noticed some strange errors after adding `profile_batch=5` to my tensorboard callback. I've attached logs below. It's worth noting that I started getting `Local randezvous recv item cancelled` as well after upgrade to 2.13 from 2.12. I have conda environment with cudatoolkit==11.8.0, cudanvcc, and pip installed nvidiacudnncu11==8.6.0.163, tensorflow==2.13.*, tensorboard_plugin_profile... Path to CUPTI should be setup well, as it's in the same path as cudatoolkit installed libcuda  Standalone code to reproduce the issue   Relevant log output ",2023-08-31T18:22:53Z,stat:awaiting tensorflower type:bug,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61765,"Try with updating CUDA and cuDNN versions to the latest compatible versions for TensorFlow 2.13. Make sure the path to the CUPTI library is correctly set up. If the issue persists, consider downgrading TensorFlow to version 2.12 or earlier, as the error started occurring after the upgrade. Additionally, check if there are any compatibility issues between TensorFlow and the RTX A6000 and Quatro RTX 8000 GPUs.","thanks caesar I forgot about having this issue open. I have somehow resolved the issue after I remade my environment. I also run into some issue with profiler logs being in wrong directory and unavailable in Tensorboard UI, but I've also found solution in github issues",Are you satisfied with the resolution of your issue? Yes No
909,"以下是一个github上的tensorflow下的一个issue, 标题是(Full integer quantization not possible with grouped convolution)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 12.5  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.13  2. Code Provide code to help us reproduce your issues using one of the following options:  The error that I get is   The model itself got converted from pytorch to onnx and then to pb. The issue here is that the model has a grouped convolutional layers. This is fixed for dynamic range quantisation but for full integer quantisation using a representative dataset this still seems to fail. Any quick fix possible?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,justlike-prog,Full integer quantization not possible with grouped convolution," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 12.5  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.13  2. Code Provide code to help us reproduce your issues using one of the following options:  The error that I get is   The model itself got converted from pytorch to onnx and then to pb. The issue here is that the model has a grouped convolutional layers. This is fixed for dynamic range quantisation but for full integer quantisation using a representative dataset this still seems to fail. Any quick fix possible?",2023-08-31T08:14:44Z,stat:awaiting tensorflower type:bug TFLiteConverter ModelOptimizationToolkit TF 2.13,open,0,9,https://github.com/tensorflow/tensorflow/issues/61760,"prog Could you have a look at this page and let me know if it gives enough information regarding integer quantization? In order to expedite the troubleshooting process, please provide a code snippet to reproduce the issue reported here. Thank you!"," Code snippet is above. Yes, I check that page already (obviously), but it doesn't help me with my issue. Basically the issue is that the number of input channels is not divisible by number of channels in one group, hence the number of groups cannot be determined. Apparently this is not a problem when doing dynamic range quantization and in this case the tflite model works fine. For Full integer quantiation this doesn't work though.",Hi prog  Thanks for bringing this issue. Will it possible to share the .pb file so that it will help us to reproduce the issue and investigate further? Thanks., yeah sure. here is a link to the pb https://drive.google.com/file/d/1jFBdUAbEEZdgImt6DHiXOwNLQx9w2pUv/view?usp=sharing,"Hi prog  Thanks for sharing the model. I have tried to reproduce with different conversions criteria including dynamic range quantization and full integer quantization and I was successfully able to convert it into TFLite model. Please find this gist. The representative dataset generator might be causing the problem. The model expects the input shape of `[1,3,224,224]` and we need to provide the representative data accordingly. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"> Hi prog >  > Thanks for sharing the model. I have tried to reproduce with different conversions criteria including dynamic range quantization and full integer quantization and I was successfully able to convert it into TFLite model. >  > Please find this gist. >  > The representative dataset generator might be causing the problem. The model expects the input shape of `[1,3,224,224]` and we need to provide the representative data accordingly. >  > Thanks. Thank you, you were right about the input shape. Somehow I missed this. Now I am running into the problem that when I load the model in the interpreter the jupyter notebook kernel crashes. Also if I try to run it on Android I get problems that look like a memory leak. Can you try to reproduce this issue with the model crashing after full integer quantization on your side? This does not happen with dynamic range quantization. Thank you!  ",Hi prog  This seems to be an issue with pytorch>tflite conversion. I was able to reproduce this. Please find this gist.  Could you please look into this issue? Thanks.,"Reproducible with Pratik's gist, Hi , can you please take a look? Thanks."
817,"以下是一个github上的tensorflow下的一个issue, 标题是(incompatible shapes error)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.2 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to train a model to do binary classification.  I am getting an error about incompatible shapes, but my data seems to be in the correct shape.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,walkerped,incompatible shapes error," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Ubuntu 22.04.2 LTS  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to train a model to do binary classification.  I am getting an error about incompatible shapes, but my data seems to be in the correct shape.   Standalone code to reproduce the issue   Relevant log output ",2023-08-29T17:14:09Z,stat:awaiting response type:bug stale comp:model TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61746,"Hi  , I have replicated the reported error(incompatibility shapes) and attached gist for reference. Since the code involves transformer model which is a third party library debugging needs time to confirm the error source.","Hi  , It seems the error is generated from transformer model itself as the node that generated error states it. As we can see there is no shape arguments being passed to keras model here the shapes are inferred from the transformer model and the dataset also not matching with the shapes that has been raised in the error. Could you please report the issue at Transformer support forum ? Or you can submit a code snippet without external library dependency to replicate the issue ? Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1523,"以下是一个github上的tensorflow下的一个issue, 标题是(how to download or install .so file for tflite conversion with gpu delegate)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Alwaysadil,how to download or install .so file for tflite conversion with gpu delegate," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-08-29T06:27:12Z,stat:awaiting tensorflower TFLiteConverter TFLiteGpuDelegate TF 2.13,open,0,55,https://github.com/tensorflow/tensorflow/issues/61743,"concrete_func = model_beam_search.__call__.get_concrete_function() Create a TFLite converter and set the delegate to TfLiteGpuDelegateconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func], model_beam_search)converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]converter.optimizations = [tf.lite.Optimize.DEFAULT]converter.target_spec.supported_types = [tf.float16] Replace TfLiteFlexDelegate with TfLiteGpuDelegategpu_delegate = tf.lite.experimental.load_delegate('libtensorflowlite_gpu_delegate.so')converter.experimental_new_converter = True   This flag is needed for using the experimental converterconverter.experimental_new_quantizer = False   You can enable quantization if neededconverter.experimental_enable_resource_variable = False   You can enable resource variables if neededconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, gpu_delegate]tflite_model = converter.convert() Save the TFLite model to a filewith open('testing_gpu.tflite', 'wb') as f:    f.write(tflite_model)", Could you please let us know which TF version you are using here and refer to this GPU delegate guide for more information on this. Thank you!, I am using 2.13.0, Thank you for your quick response! Could you please let us know if the GPU delegate guide helped you anyway. Thank you!," yes it was helpful for me that u shared GPU delegate documentation, thank you for sharing that ,but i didn't understood how to get .so file libtensorflowlite_gpu_delegate.so","Hi   To get `libtensorflowlite_gpu_delegate.so`, you have to build the `.so` file using following steps 1. Install bazel 5.3.0 2. git clone https://github.com/tensorflow/tensorflow.git 3. cd tensorflow 4. git checkout r2.13 5. ./configure (yes for android build and provide the NDK and SDK versions) 6. Run `bazel build config android_arm64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so` Please refer to this documentation for reference. Thanks.", could you please provide me the google colab notebook with code to get .so file please? i'm getting errors in google colab (please check my google colab ) https://colab.research.google.com/drive/1aaXDm_TySAWWWyR1S6UEiPc5EB9kPjQscrollTo=nhrzFEC7GDXr like this WARNING: Target pattern parsing failed. Loading: 0 packages loaded     currently loading: tensorflow/lite/delegates/gpu ERROR: no such package '//': Repository command failed Could not find any NvInferVersion.h matching version '' in any subdirectory:         ''         'include'         'include/cuda'         'include/*linuxgnu'         'extras/CUPTI/include'         'include/cuda/CUPTI'         'local/cuda/extras/CUPTI/include' of:         '/lib'         '/lib/x86_64linuxgnu'         '/lib32'         '/usr'         '/usr/local/cuda'         '/usr/local/cuda/targets/x86_64linux/lib'         '/usr/local/lib' Analyzing: 0 targets (0 packages loaded)     currently loading: tensorflow/lite/delegates/gpu INFO: Elapsed time: 83.761s Analyzing: 0 targets (0 packages loaded)     currently loading: tensorflow/lite/delegates/gpu INFO: 0 processes. Analyzing: 0 targets (0 packages loaded)     currently loading: tensorflow/lite/delegates/gpu FAILED: Build did NOT complete successfully (0 packages loaded)     currently loading: tensorflow/lite/delegates/gpu FAILED: Build did NOT complete successfully (0 packages loaded)     currently loading: tensorflow/lite/delegates/gpu     Fetching ; fetching plese help me,Hi   The colab shared is currently not accessible. Could you please provide the steps you have followed? You can follow these instructions along with links to download  for  setting up the configurations in your local machine.  Please let us know if you are facing any issue after the following the steps. Thanks.,"Hi  thank you for your response.Could you please check my colab notebook it will now accessible,i'm unable to downloading the .so file please kindly go through this colab link https://colab.research.google.com/drive/1aaXDm_TySAWWWyR1S6UEiPc5EB9kPjQscrollTo=nhrzFEC7GDXr i want to load this with tf  import tensorflow as tf delegate = tf.lite.experimental.load_delegate('libtensorflowlite_gpu_delegate.so')with this we can get faster predictions of tflite model please help me ","Hi   Thanks for sharing the code. I can see that the android ndk and sdk tools have not been configured.  The Android NDK is required to build the native (C/C++) TensorFlow Lite code. The current recommended version is 21e, which may be found here. The Android SDK and build tools may be obtained here. Run the ./configure script in the root TensorFlow checkout directory, and answer ""Yes"" when the script asks to interactively configure the ./WORKSPACE for Android builds.  Also, you can this prebuilt `.so` file and see if it works for your case. libtensorflowlite_gpu_delegate.so.zip Thanks.","Hi   Thanks for you response it means alot , ould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y Searching for NDK and SDK installations. Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndkbundle]:  The path /root/Android/Sdk/ndkbundle or its child file ""source.properties"" does not exist. Please specify the home path of the Android NDK to use. [Default is /root/Android/Sdk/ndkbundle]: /content/androidndkr21e Please specify the (min) Android NDK API level to use. [Available levels: ['16', '17', '18', '19', '21', '22', '23', '24', '26', '27', '28', '29', '30']] [Default is 26]:  Please specify the home path of the Android SDK to use. [Default is /root/Android/Sdk]: /root/androidsdk Please specify the Android SDK API level to use. [Available levels: ['30']] [Default is 30]:  Please specify an Android build tools version to use. [Available versions: ['30.0.3']] [Default is 30.0.3]:  Preconfigured Bazel build configs. You can use any of the below by adding ""config="" to your build command. See .bazelrc for more details. 	config=mkl         	 Build with MKL support. 	config=mkl_aarch64 	 Build with oneDNN and Compute Library for the Arm Architecture (ACL). 	config=monolithic  	 Config for mostly static monolithic build. 	config=numa        	 Build with NUMA support. 	config=dynamic_kernels	 (Experimental) Build kernels into separate shared objects. 	config=v1          	 Build with TensorFlow 1 API instead of TF 2 API. Preconfigured Bazel build configs to DISABLE default on features: 	config=nogcp       	 Disable GCP support. 	config=nonccl      	 Disable NVIDIA NCCL support. Configuration finished https://colab.research.google.com/drive/1aaXDm_TySAWWWyR1S6UEiPc5EB9kPjQscrollTo=nhrzFEC7GDXr **but the .so file was not visible ,i downloaded it by giving path like this see above colab link the way i did** checking the path import os path_to_check = '/content/tensorflow/bazelbin/tensorflow/lite/delegates/gpu/libtensorflowlite_gpu_delegate.so' if os.path.exists(path_to_check):     print(""yes"") else:     print(""no"") **it was printing yes** downloading the .so file  from google.colab import files source_path = '/content/tensorflow/bazelbin/tensorflow/lite/delegates/gpu/libtensorflowlite_gpu_delegate.so' if os.path.exists(source_path):     files.download(source_path) else:     print(""Source file does not exist."")  i have successfully downloaded the  libtensorflowlite_gpu_delegate.so see this below link to get newly built .so file  https://drive.google.com/file/d/1848HQ4ExO72zkTdQCyr7rrc7kvVfeeE/view?usp=sharing **while loading this .so in new colab notebook  file i am getting this below error for both newly built and you shared prebuild .so file**check this https://colab.research.google.com/drive/1jAaFDTwqRWuISD0nA6OF9d0eSq39t6w1?usp=sharing import tensorflow as tf delegate = tf.lite.experimental.load_delegate(''/content/drive/MyDrive/delegate/libtensorflowlite_gpu_delegate.so')with this we ca get faster predictions  OSError                                   Traceback (most recent call last)  in ()       1 import tensorflow as tf > 2 delegate = tf.lite.experimental.load_delegate(''/content/drive/MyDrive/delegate/libtensorflowlite_gpu_delegate.so')with this we ca get faster predictions 3 frames /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/interpreter.py in load_delegate(library, options)     164   """"""     165   try: > 166     delegate = Delegate(library, options)     167   except ValueError as e:     168     raise ValueError('Failed to load delegate from {}\n{}'.format( /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/interpreter.py in __init__(self, library, options)      71                          'due to missing immediate reference counting.')      72  > 73     self._library = ctypes.pydll.LoadLibrary(library)      74     self._library.tflite_plugin_create_delegate.argtypes = [      75         ctypes.POINTER(ctypes.c_char_p), /usr/lib/python3.10/ctypes/__init__.py in LoadLibrary(self, name)     450      451     def LoadLibrary(self, name): > 452         return self._dlltype(name)     453      454     __class_getitem__ = classmethod(_types.GenericAlias) /usr/lib/python3.10/ctypes/__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error, winmode)     372      373         if handle is None: > 374             self._handle = _dlopen(self._name, mode)     375         else:     376             self._handle = handle OSError: libtensorflowlite_gpu_delegate.so: cannot open shared object file: No such file or directory **but if i check the path** import os path_to_check = '/content/drive/MyDrive/delegate/libtensorflowlite_gpu_delegate.so' if os.path.exists(path_to_check):     print(""yes"") else:     print(""no"") it was printing ""yes"" **please help me to overcome this issue**","Hi   Apologies for the confusion. The delegate can be loaded only if it matches the target architecture. The colab ships with `x86_64`(test it out using `!uname a`), hence we need to build the  `bazel build config android_x86_64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so` and then try to load the delegate. Thanks.","Hi  i didn't get what u said,i tried in local system terminal too still same error occurring, could you please help me to overcome this issue","Hi   The `libtensorflow_gpu_delegate.so` is built with respect to the target configuration specified during the bazel build. Please check you system target architecture. On linux machine simply, run   instead of   Additionally, you may have to install  Thanks.","> Hi  >  > Apologies for the confusion. The delegate can be loaded only if it matches the target architecture. The colab ships with `x86_64`(test it out using `!uname a`), hence we need to build the `bazel build config android_x86_64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so` and then try to load the delegate. >  > Thanks. hi , still getting this below error ,the .so file was not visible tf.lite.experimental.load_delegate(""/content/drive/MyDrive/test_delegate/libtensorflowlite_gpu_delegate.so"")  OSError                                   Traceback (most recent call last)  in () > 1 tf.lite.experimental.load_delegate(""/content/drive/MyDrive/test_delegate/libtensorflowlite_gpu_delegate.so"") 3 frames /usr/lib/python3.10/ctypes/__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error, winmode)     372      373         if handle is None: > 374             self._handle = _dlopen(self._name, mode)     375         else:     376             self._handle = handle OSError: libEGL.so: cannot open shared object file: No such file or directory https://colab.research.google.com/drive/1aaXDm_TySAWWWyR1S6UEiPc5EB9kPjQscrollTo=nhrzFEC7GDXr !uname a it prints> Linux a8fc57c0d917 5.15.109+ CC(Add support for Python 3.x) SMP Fri Jun 9 10:57:30 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux !bazel build config android_x86_64 tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so  path_to_check = '/content/drive/MyDrive/test_delegate/libtensorflowlite_gpu_delegate.so' if os.path.exists(path_to_check): print(""yes"") else: print(""no"") it was printing ""yes"" **please help me to get the .so file file please** ","> Hi  >  > The `libtensorflow_gpu_delegate.so` is built with respect to the target configuration specified during the bazel build. Please check you system target architecture. On linux machine simply, run >  >  >  > instead of >  >  >  > Additionally, you may have to install >  >  >  > Thanks. Hi  in terminal i am getting this error below dated. ERROR: An error occurred during the fetch of repository 'llvmraw':    Traceback (most recent call last): 	File ""/home/sys2022/tensorflow/third_party/repo.bzl"", line 73, column 33, in _tf_http_archive_impl 		ctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error extracting /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012/dc275fd03254d67d29cc70a5a0569acf24d2280d.tar.gz to /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012: write (No space left on device) ERROR: /home/sys2022/tensorflow/WORKSPACE:11:14: fetching _tf_http_archive rule //external:llvmraw: Traceback (most recent call last): 	File ""/home/sys2022/tensorflow/third_party/repo.bzl"", line 73, column 33, in _tf_http_archive_impl 		ctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error extracting /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012/dc275fd03254d67d29cc70a5a0569acf24d2280d.tar.gz to /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012: write (No space left on device) WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/7d879c8b161085a4374ea481b93a52adb19c0529.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found ERROR: no such package 'raw//utils/bazel': java.io.IOException: Error extracting /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012/dc275fd03254d67d29cc70a5a0569acf24dINFO: Repository 'llvmraw' used the following cache hits instead of downloading the corresponding file.  * Hash '3e91127af59a6b07fea7901c80a7b8b9234eced42b0f14abbad5f9f7674dba69' for https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvmproject/archive/dc275fd03254d67d29cc70a5a0569acf24d2280d.tar.gz If the definition of 'llvmraw' was updated, verify that the hashes were also updated. ERROR: An error occurred during the fetch of repository 'llvmraw':    Traceback (most recent call last): 	File ""/home/sys2022/tensorflow/third_party/repo.bzl"", line 73, column 33, in _tf_http_archive_impl 		ctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error extracting /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012/dc275fd03254d67d29cc70a5a0569acf24d2280d.tar.gz to /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012: write (No space left on device) ERROR: /home/sys2022/tensorflow/WORKSPACE:11:14: fetching _tf_http_archive rule //external:llvmraw: Traceback (most recent call last): 	File ""/home/sys2022/tensorflow/third_party/repo.bzl"", line 73, column 33, in _tf_http_archive_impl 		ctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error extracting /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012/dc275fd03254d67d29cc70a5a0569acf24d2280d.tar.gz to /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012: write (No space left on device) WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/7d879c8b161085a4374ea481b93a52adb19c0529.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found ERROR: no such package 'raw//utils/bazel': java.io.IOException: Error extracting /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012/dc275fd03254d67d29cc70a5a0569acf24d2280d.tar.gz to /home/sys2022/.cache/bazel/_bazel_sys2022/49a37d0bef434a2dcf9fbacaf7083ab7/external/llvmraw/temp13989436987824143012: write (No space left on device) INFO: Elapsed time: 13.339s INFO: 0 processes.  ,**but please provide me code or any other way  in google colab i'm comfortable with colab please help me to overcome this** **issue**",hi   delegate = tf.lite.experimental.load_delegate('/content/tensorflow/bazelbin/tensorflow/lite/delegates/gpu/libtensorflowlite_gpu_delegate.so')with this we ca get faster predictions OSError: libEGL.so: cannot open shared object file: No such file or directory please help me to get .so file,"Ensure that the directory containing libEGL.so is included in your LD_LIBRARY_PATH environment variable. You can check the current value of LD_LIBRARY_PATH by running: echo $LD_LIBRARY_PATH If the directory is not included, you can add it by modifying your shell profile configuration file (e.g., ~/.bashrc or ~/.bash_profile) and adding the following line: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/directory Replace /path/to/directory with the actual path to the directory containing libEGL.so. Then, reload your shell or run source ~/.bashrc to apply the changes.","> Ensure that the directory containing libEGL.so is included in your LD_LIBRARY_PATH environment variable. You can check the current value of LD_LIBRARY_PATH by running: >  > echo $LD_LIBRARY_PATH If the directory is not included, you can add it by modifying your shell profile configuration file (e.g., ~/.bashrc or ~/.bash_profile) and adding the following line: >  > export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/directory Replace /path/to/directory with the actual path to the directory containing libEGL.so. Then, reload your shell or run source ~/.bashrc to apply the changes. thanks for your response,could you please tell me how to overcome this issue in google colab ?","Hello  , could you please reply to me?","Hi   We are actively working it.  The TFlite GPU delegates are primarily build for the GPU backend support for Android and iOS. For ubuntu machines it is not well supported and tested. Depending on the platform and version, we may have to define MESA_EGL_NO_X11_HEADERS and/or EGL_NO_X11 which don't include the X11 headers named slightly differently. We need to dig into EGL header files a little bit. Thanks.","Hi  thank you for responding   could you please tell me,  At android side, for keras_nlp transformer models GPU  delegate will apply or not ? i am working on this gpu delegation applying at android side  from past two months to get fatser inference from tflite model,but i am getting this error  **(java.lang.IllegalArgumentException: Internal error: Error applying delegate:)** **but,for image related tflite models the GPU Delegate was appying perfectly without any errors, but not for Keras_nlp transformers,** why for keras_nlp transformer tflite models GPU was not applying? This was my main issue **please give me one reply about this please.....** **I read that when performing TFLite conversion in Python programming, including a GPU delegate like the one below can lead to faster output predictions, resulting in lower latency(is it right or wrong?)** concrete_func = model_beam_search.__call__.get_concrete_function() converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func], model_beam_search) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS] converter.experimental_new_converter=tf.lite.experimental.load_delegate('libtensorflowlite_gpu_delegate.so') dynamic_quant = converter.convert() https://colab.research.google.com/drive/1GJ8UBa8GQBSKY4NC6_tYB0uxujvUn2kT?usp=sharingscrollTo=C4iu7JIanl5d that's why i ask you to how to download >libtensorflowlite_gpu_delegate.so **could you please help me to overcome this issue?**","Hi  please,give me one reply","Hi   Sorry for the delayed response.  There are some limitations to what TensorFlow ML operations, or ops, can be accelerated by the TensorFlow Lite GPU delegate. Not all Ops currently support using GPU delegate. If the model has Ops that does not support the use of GPU delegate, you might encounter this error. Please check this list of Ops supported here. >I read that when performing TFLite conversion in Python programming, including a GPU delegate like the one below can lead to faster output predictions, resulting in lower latency(is it right or wrong?) Yes, enabling use of GPUs with your TensorFlow Lite ML applications can provide the benefits like speed and efficiency. But as mentioned earlier, it is platform dependent and we need to build the delegates accordingly, to make the best use of them. Also,  the GPU delegate has some restrictions with the batch dimensions and requires that dimension to be consistent throughout the network. BTW,  you can use Model Analyzer API to check which node has the compatibility issue.  Thanks.","Hi   Thanks for your response i already check this **tf.lite.experimental.Analyzer.analyze(model_path='model.tflite', gpu_compatibility=True)** i am getting GPU COMPATABILITY WARNINGS  Subgraph CC(未找到相关数据) main(T CC(未找到相关数据)) > [T CC(Slack Channel)]   Op CC(未找到相关数据) EXPAND_DIMS(T CC(未找到相关数据), T CC([doc] typo)[1]) > [T CC(Quantized ops?)] GPU COMPATIBILITY WARNING: Not supported op EXPAND_DIMS   Op CC(Add support for Python 3.x) TILE(T CC(Quantized ops?), T CC(API docs does not list RNNs)[1, 4, 1]) > [T CC(iOS Support and Example)]   Op CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"") SHAPE(T CC(未找到相关数据)) > [T CC(Windows Support and Documentation)] GPU COMPATIBILITY WARNING: Not supported op SHAPE   Op CC(JVM, .NET Language Support) STRIDED_SLICE(T CC(Windows Support and Documentation), T CC(Typo in getting started guide)[1], T CC(Go API)[0], T CC(Typo in getting started guide)[1]) > [T CC(C api)] GPU COMPATIBILITY WARNING: STRIDED_SLICE supports for 3 or 4 dimensional tensors only.   Op CC(Installation over pip fails to import with protobuf 2.6.1) CONCATENATION(T CC(Java interface)[4], T CC(C api)) > [T CC(Swift API)]   Op CC(Java interface) RESHAPE(T CC(iOS Support and Example), T CC(Swift API)) > [T CC(CUDA 7.5 fails with pip install and docker (Ubuntu 14.04))] GPU COMPATIBILITY WARNING: Expected 1 runtime input tensor(s), but node has 2 runtime input(s).   Op CC(Pretrained models) WHILE(T CC(0.5.0 wheel install on Mac OS X using Homebrew python broken)[0], T CC(Installation over pip fails to import with protobuf 2.6.1)[2, 0, 0, 0, 0, ...], T CC([doc] typo)[1], T CC(g3doc format), T CC(CUDA 7.5 fails with pip install and docker (Ubuntu 14.04)), Cond: Subgraph CC(Add support for Python 3.x), Body: Subgraph CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"")) > [T CC(GPU_Base dockerfile image not found), T CC(OpenCL support), T CC(Distributed Version), T CC(Problems running the image example (Python 2.7.10, PyEnv, Xubuntu 14.04 64bit)), T CC(Cuda 3.0?)] GPU COMPATIBILITY WARNING: Not supported op WHILE   Op CC(API docs does not list RNNs) RESHAPE(T CC(OpenCL support), T CC(Setting lower gcc version for cuda)[1, 4, 15]) > [T CC(simplify contributing process)]   Op CC(Setting lower gcc version for cuda) RESHAPE(T CC(Problems running the image example (Python 2.7.10, PyEnv, Xubuntu 14.04 64bit)), T CC(Add support for Python 3.x)[1, 4]) > [T CC(Warning while creating Session on Mac OS X: can't determine number of CPU cores)]   Op CC(Typo in getting started guide) TOPK_V2(T CC(Warning while creating Session on Mac OS X: can't determine number of CPU cores), T CC(Pretrained models)[4]) > [T CC(Could port to OpenCL?), T CC(minimum req: Cuda compute capability 3.5)] GPU COMPATIBILITY WARNING: Not supported op TOPK_V2   Op CC(Go API) CAST(T CC(minimum req: Cuda compute capability 3.5)) > [T CC(Go API)] GPU COMPATIBILITY WARNING: Not supported Cast case. Input type: INT32 and output type: INT64   Op CC(0.5.0 wheel install on Mac OS X using Homebrew python broken) GATHER(T CC(simplify contributing process), T CC(Go API)) > [T CC(Slack Channel)] GPU COMPATIBILITY WARNING: Does not accept INT32 input. GPU COMPATIBILITY WARNING: Subgraph CC(未找到相关数据) has GPU delegate compatibility issues at nodes 0, 2, 3, 5, 6, 9, 10, 11 with TFLite runtime version 2.13.0 please check this colab https://colab.research.google.com/drive/1GJ8UBa8GQBSKY4NC6_tYB0uxujvUn2kTscrollTo=vKdwHlNHLI6Y **please tell me how to overcome this issue ,  to apply  the GPU Delegate at android side please to get fatser inference**","Hi   Given the GPU compatibility warnings, I'm afraid we cannot leverage the GPU delegate to its extent.  I see a similar issue CC(I cannot run a transformer model with tokenlevel output on accelerated hardware in TF Lite). On Android devices, you can also try NNAPI delegate which also helps in accelerating the code and let us know if it works for your case? Thanks.","Thank you  for responding While applying  NNAPI delegate ,getting this below error  DeviceManager::DeviceManager20230906 14:17:38.049 findAvailableDevices20230906 14:17:38.104 Found interface xtensaxtensa (version = Xtensa ANN 1.2)20230906 14:17:38.104 Created TensorFlow Lite delegate for NNAPI.20230906 **14:17:39.685 java.lang.IllegalArgumentException: Internal error: Error applying delegate: 20230906 14:17:39.687**     at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)20230906 14:17:39.688     at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:110)20230906 14:17:39.689     at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:73)20230906 14:17:39.690     at org.tensorflow.lite.NativeInterpreterWrapperExperimental.(NativeInterpreterWrapperExperimental.java:36)20230906 14:17:39.691     at org.tensorflow.lite.Interpreter.(Interpreter.java:232) **please  help me to overcome this speed related issues please........**","Hi , I think we need more context.. if you can export the android studio project or a toy version which exhibits the behavior, that'll be the easiest for us to investigate. If not please at least at least post the code around where you are applying and using the NNAPI delegate, so that we may attempt to reproduce your issue. Thanks!","Hi  thank you for responding see this below code NNAPI delegate ByteBuffer buffer = loadModelFile(mContext.getAssets());            Interpreter.Options options = (new Interpreter.Options());            NnApiDelegate nnApiDelegate = null;// Initialize interpreter with NNAPI delegate for Android Pie or above            if(Build.VERSION.SDK_INT >= Build.VERSION_CODES.P) {                nnApiDelegate = new NnApiDelegate();                options.addDelegate(nnApiDelegate);            }// Initialize TFLite interpreter            try {                tflite = new Interpreter(buffer, options);            } catch (Exception e) {                throw new RuntimeException(e);            } GPU delegate applying ByteBuffer buffer = loadModelFile(mContext.getAssets());            Interpreter.Options opt = new Interpreter.Options();// Initialize interpreter with GPU delegate            CompatibilityList compatList = new CompatibilityList();            if(compatList.isDelegateSupportedOnThisDevice()){                // if the device has a supported GPU, add the GPU delegate                GpuDelegateFactory.Options options1 = new GpuDelegateFactory.Options().setQuantizedModelsAllowed(true);                GpuDelegate gpuDelegate = new GpuDelegate(options1);                opt.addDelegate(gpuDelegate);            } else {                // if the GPU is not supported, run on 4 threads                opt.setNumThreads(4);            }//            opt.setNumThreads(4);            tflite = new Interpreter(buffer, opt);","Hi , which model file does your ""mContext.getAssets()"" refer to? There's a couple of possible ones in the various colabs you shared, so I want to just focus on the one that is causing the issue."
1774,"以下是一个github上的tensorflow下的一个issue, 标题是(tflite-model-maker cannot be installed correctly for different reasons on different configurations)， 内容是 (If you try to install tflitemodelmakernightly basically it starts to download **all nightly build wheels** since the first release rather than latest one as supposed. This seems caused by a bad configuration.  Many people have reported this issue many months ago, it remained unsolved as this other issue. But they aren't the only setup issues that affects tflitemodelmaker. If you try to install the latest build with `pip install tflitemodelmaker` it raises various errors  e.g. tflitesupport dependency that hasn't any wheel available in repository (for windows since the 0.4.0 released in May 2022 there is no wheel at all and the latest is 0.3.1 that has no wheel for latest Python versions). Tried on Linux arm64 and needed wheels are missing too. How is decided to upgrade version dependencies requirements without release updated dependencies coherently, considering these are developed by same company? If it isn't followed a coherent path, it is obvious that troubles arise and you have to waste time trying to find if there is a combination of OS type, architecture, Python version, package version, dependency version, that may work, digging in the repository release history and requirements.  tflitemodelmaker has been released a couple of years ago to simplify model training and it was very good at this, before the project maintenance started to become erratic and lackluster creating a lot of compatibility issues and conflicts.  Is this project development still active?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JohnFarl,tflite-model-maker cannot be installed correctly for different reasons on different configurations,"If you try to install tflitemodelmakernightly basically it starts to download **all nightly build wheels** since the first release rather than latest one as supposed. This seems caused by a bad configuration.  Many people have reported this issue many months ago, it remained unsolved as this other issue. But they aren't the only setup issues that affects tflitemodelmaker. If you try to install the latest build with `pip install tflitemodelmaker` it raises various errors  e.g. tflitesupport dependency that hasn't any wheel available in repository (for windows since the 0.4.0 released in May 2022 there is no wheel at all and the latest is 0.3.1 that has no wheel for latest Python versions). Tried on Linux arm64 and needed wheels are missing too. How is decided to upgrade version dependencies requirements without release updated dependencies coherently, considering these are developed by same company? If it isn't followed a coherent path, it is obvious that troubles arise and you have to waste time trying to find if there is a combination of OS type, architecture, Python version, package version, dependency version, that may work, digging in the repository release history and requirements.  tflitemodelmaker has been released a couple of years ago to simplify model training and it was very good at this, before the project maintenance started to become erratic and lackluster creating a lot of compatibility issues and conflicts.  Is this project development still active?",2023-08-28T14:09:40Z,stat:awaiting tensorflower type:bug comp:lite TFLiteModelMaker,closed,7,16,https://github.com/tensorflow/tensorflow/issues/61719,"Hi , thanks for reporting the issue, it is actively being worked on, please follow the progress on https://github.com/tensorflow/tensorflow/issues/60431 It seems some users have had success with downgrading to python 3.9 for now. Can you try to see if those workarounds will help unblock you for now?","I can confirm that installing either the TfLite Model Maker or the MediaPipe one fails using Python v3.11.5 on a Mac M1 for multiple users in our company.  you guys keep saying in multiple GitHub issues that this is actively worked upon, but: 1. There are at least 5 active issues in this repository apart from this one, with even **twice** as many closed ones. At this point you should probably ask yourselves, if so many people report issues with the installation process, maybe there actually *is* an issue and thus the process should be improved and/or better documented?  2. Not even the ""new kid on the block"" MediaPipe works. If you guys keep releasing new software, even though the old one isn't working correctly, how will that help the community? I'm sorry, but at this point, it's a very valid question if the project development is still active. Do you guys even test out if the tools work? Like, seriously. Get a fresh new laptop and try to install either of the 2 model makers following the official tutorial.","I fully empathise with 's frustration! Arm64based Macs are not bleedingedge hardware anymore, and the fact that this issue still persist is IMO pretty embarrassing for the team responsible for these tools. I'll try to summarise the approaches I have tried and my findings, in the hope that someone ( perhaps?) might take appropriate actions or provide constructive hints for how to move this forward. Installing with Python 3.11 on MacOs with Arm64 (native environment) fails on `tflitesupport`  Latest version of `tflitesupport` at time of writing (linked above) provides wheels for Linux/Arm64 and MacOs/x86_64, but not the combo MacOs/Arm64. Python 3.11 is not the issue in this case, ref list of wheels in link above.  `tflitesupport` is built using Bazel, with which I'm not familiar. I might spend some time later to understand Bazel and try to build `tflitesupport` for MacOs/Arm64. Any constructive hints are greatly appreciated (not links to the manual  I'm able to find that myself 😉 ) Given that `tflitesupport` is provided for MacOs/x86_64, it's tempting to lean on Rosetta and install x86_64 versions of everything. However, scrolling a little down on the linked page reveals that AVXinstructions are not translated by Rosetta. Furthermore, this issue indicates that QEMU/Docker may not come to the rescue here either. Since Tensorflow seems to rely heavily on AVX the approach of using x86_64 binaries seems to be unfruitful. Last possibility I see on my M1 is to try wheels for Linux/Arm64 with some Arm64based Linux like e.g. python:3.9bullseye running in Docker:  _(NOTE: The option `usedeprecated=legacyresolver` to pip is crucial in next step  wish the docs were clearer on this. See e.g. this issue.)_   Looking up wheels for tensorflowaddons on pypi we see that there is indeed no wheel for Linux/Arm64. Ironically, there **are** wheels for MacOs/Arm64... 🤦  Moreover, adding insult to injury, tensorflowaddons will be discontinued in a year or so. *sigh* Installing mediapipemodelmaker (_aka ""new kid on the block""_) on MacOs/Arm64 fails because tensorflowtext==2.13.0 has no wheel for the platform    Installing the `mediapipemodelmaker` in Linux/Arm64 under Docker bumps into the problem with `tensorflowaddons`    Hence, on an Armbased Mac trying to use `tflitemodelmaker` I'm stuck until either 1. `tflitesupport` provides wheel for MacOs/Arm64 2. `tensorflowaddons` provides wheel for Linux/Arm64 (requires QEMU/Docker) and trying to use `mediapipemodelmaker` I'm stuck until either 1. `tensorflowtext==2.13.0` provides wheel for MacOs/Arm64 2. `tensorflowaddons` provides wheel for Linux/Arm64 (requires QEMU/Docker)","The installation of the tflitemodelmaker with the pip command keeps crashing on Google Colab.  Either due to requirements not being found, or the disk running out of space. As a result, cannot complete the Flower Classification tutorial.","Hi , it is probably best to post those issues on the mediapipe github issues page: https://github.com/google/mediapipe/issues, I tried a couple of things it seems python=3.10 works best. I was able to install with python=3.10 successfully on linux x86_64. It might be worth it to try on linux ARM. Using colab is probably the most stable currently. I am running into a different issue for my mac M1. : ","Thanks again for your involvement ! I'll consider a separate post in the right repo later. IIRC, this pyyamlissue you see can be resolved by installing the `pyyaml` binary package  via e.g. `conda` prior to running pip (looks like compiling pyyaml on Osx/Arm fails for some reason). Personally I use `miniforge` but other pkgmanagers like `anaconda`, `mamba`, `poetry` etc might also work (just make sure to install an acceptable version) > Hi , it is probably best to post those issues on the mediapipe github issues page: https://github.com/google/mediapipe/issues, I tried a couple of things it seems python=3.10 works best. I was able to install with python=3.10 successfully on linux x86_64. It might be worth it to try on linux ARM. Using colab is probably the most stable currently. I am running into a different issue for my mac M1. : >  > ","No worries, correct if I install pyyaml=5.4.1 manually, it reaches the same error you got on Mac M1: ","On the subject of `mediapipemodelmaker` this reply points to an announcement from the Tensorflow Text team stating that wheels will be provided only for Linux x86_64 and Intelbased Macs (`mediapipemodelmaker` depends on `tensorflowtext` at present). The recommended solution is to build wheels for the desired platform from source yourself. Moreover, quoting from the announcement > Note that TF Text needs to be built in the same environment as TensorFlow. Thus, if you manually build TF Text, it is highly recommended that you also build TensorFlow.","> On the subject of `mediapipemodelmaker` this reply points to an announcement from the Tensorflow Text team stating that wheels will be provided only for Linux x86_64 and Intelbased Macs (`mediapipemodelmaker` depends on `tensorflowtext` at present). >  > The recommended solution is to build wheels for the desired platform from source yourself. >  > Moreover, quoting from the announcement >  > > Note that TF Text needs to be built in the same environment as TensorFlow. Thus, if you manually build TF Text, it is highly recommended that you also build TensorFlow. This is a ridiculous decision. Windows is the desktop OS with most market share and Mac is moving to arm. So the decision to stop support to anything other than Linux x86_64 and Intelbased Macs makes no sense.",> On the subject of `mediapipemodelmaker` this reply points to an announcement from the Tensorflow Text team stating that wheels will be provided only for Linux x86_64 and Intelbased Macs (`mediapipemodelmaker` depends on `tensorflowtext` at present). >  > The recommended solution is to build wheels for the desired platform from source yourself. This opens up a can of worms for those with Apple M1 chips.   Is there a proper Docker image or anything out there?,I'm also trying to figure out how to install modelmaker on m1 and it looks like docker is the only way..  did u figure out the docker file?,> I'm also trying to figure out how to install modelmaker on m1 and it looks like docker is the only way..  did u figure out the docker file? I ended up using Google's Vertex AI to create my exportable TFLite models," is your use case an image classification? i believe its the only one you can export from Vertex tools. text classification is not supported, there is an old feature request: https://issuetracker.google.com/issues/168860629","yes, images.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/151 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
654,"以下是一个github上的tensorflow下的一个issue, 标题是(Include any windows)， 内容是 (As the commit message mentions, when trying to build tensorflow lite with `DTFLITE_ENABLE_GPU=ON` on windows to get the dll/lib files the `cmake build . j ` causes the following error: 'any_cast is not a member of std' on r2.14 branch. After making sure my c++ version is indeed above 17, I figured that `operation_selector.cc` and `conv_pointwise.cc` does not include `include ` to use those functions. So I just added them next to other includes.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,turgut-baba,Include any windows,"As the commit message mentions, when trying to build tensorflow lite with `DTFLITE_ENABLE_GPU=ON` on windows to get the dll/lib files the `cmake build . j ` causes the following error: 'any_cast is not a member of std' on r2.14 branch. After making sure my c++ version is indeed above 17, I figured that `operation_selector.cc` and `conv_pointwise.cc` does not include `include ` to use those functions. So I just added them next to other includes.",2023-08-28T13:24:07Z,size:L,closed,0,12,https://github.com/tensorflow/tensorflow/issues/61718,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.",Hi baba Can you please sign CLA. Thank you!,baba Can you please resolve conflicts? Thank you!,baba Can you please resolve conflicts? Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,"You definitely need to rebase this, it has too many commits","I think you only want ded506a, but you started this on the `r2.14` branch while targeting master. You need to start from `master` branch",Hi baba Any update of this PR? Please. Thank you!,Hi baba Any update of this PR? Please. Thank you!,We should close this PR and reopen only with the commit that is needed,"  , Sorry for the delay, as of now I'm using tensorflow with the changes I've made at the beginning of this thread, no updates on my part. I tried to resolve conflicts however I do not have the right permissions to do so. Thank you for your time on this.","In this case, closing the PR. Please open it again with the conflicts resolved if you want to contribute the changes upstream."
1899,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Lite C++ error while building with cmake on windows with GPU support)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Widnows 10  Mobile device Asus pc  Python version 3.11  Bazel version 6.1.4  GCC/compiler version gcc version 6.3.0 (MinGW.org GCC6.3.01)  CUDA/cuDNN version   GPU model and memory NVIDIA GeForce GTX 960m  Current behavior? Relevant stackoverflow question: https://stackoverflow.com/questions/76990961/tensorflowcerrorwhilebuildingwithcmakeonwindowswithgpusupport I'm trying to get a tensorflow C++ build (or tensorflow lite) for Windows that runs on GPU (WITHOUT using CUDA, it should work on AMD). I decided to opt in for tensorflow lite with the DTFLITE_ENABLE_GPU=ON flag to enable OpenCL.  Standalone code to reproduce the issue   Relevant log output  But despite these errors it kept on compiling and eventually ended on:   I think I'm getting the `any_cast is not a member of std` because my C++ standard version is below 14. But I've been coding in windows for a while and I'm pretty sure I'm above 17 as I use many modern features. I've updated g++ from Visual Studio Installer but I'm not sure how to properly update my C++ version on Windows. I'm sure this build has failed, but regardless I searched for the dll.  This failed build gave me a Visual Studio solution inside tfliteopencl. I need to import tflite into a huge project so I need either the dll files or the lib files. I tried looking under `tfliteopencl/Release`, `tfliteopencl/Debug` and `tfliteopencl/x64` but found nothing. I'm also adviced to look under `\bazelbin\tensorflow\lite\kerne)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,TurgutBababalim,Tensorflow Lite C++ error while building with cmake on windows with GPU support," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14  Custom code Yes  OS platform and distribution Widnows 10  Mobile device Asus pc  Python version 3.11  Bazel version 6.1.4  GCC/compiler version gcc version 6.3.0 (MinGW.org GCC6.3.01)  CUDA/cuDNN version   GPU model and memory NVIDIA GeForce GTX 960m  Current behavior? Relevant stackoverflow question: https://stackoverflow.com/questions/76990961/tensorflowcerrorwhilebuildingwithcmakeonwindowswithgpusupport I'm trying to get a tensorflow C++ build (or tensorflow lite) for Windows that runs on GPU (WITHOUT using CUDA, it should work on AMD). I decided to opt in for tensorflow lite with the DTFLITE_ENABLE_GPU=ON flag to enable OpenCL.  Standalone code to reproduce the issue   Relevant log output  But despite these errors it kept on compiling and eventually ended on:   I think I'm getting the `any_cast is not a member of std` because my C++ standard version is below 14. But I've been coding in windows for a while and I'm pretty sure I'm above 17 as I use many modern features. I've updated g++ from Visual Studio Installer but I'm not sure how to properly update my C++ version on Windows. I'm sure this build has failed, but regardless I searched for the dll.  This failed build gave me a Visual Studio solution inside tfliteopencl. I need to import tflite into a huge project so I need either the dll files or the lib files. I tried looking under `tfliteopencl/Release`, `tfliteopencl/Debug` and `tfliteopencl/x64` but found nothing. I'm also adviced to look under `\bazelbin\tensorflow\lite\kerne",2023-08-28T08:14:09Z,stat:awaiting tensorflower type:build/install comp:lite subtype:windows,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61715,"I've tried adding SET(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} /std:c++17"") to cmake_install.cmake under tfliteopencl but it still generates the same error.","Update:  Apparently `operation_selector.cc` does not include `include ` as it should, causing the aforementioned ` 'any_cast': is not a member of 'std' ` error. After including and building it, I get a .lib file under `tfliteopencl/Debug` (no .dll's found).  However, when I include it and try to use it on a project, I get many unresolved external symbol errors. Am I doing something wrong? Were there supposed to be a .dll file?","Hi , this is effectively a duplicate of https://github.com/tensorflow/tensorflow/issues/61269","Yeah, I mentioned issue CC(TfLite 2.13 with DTFLITE_ENABLE_GPU=ON fails to build with Visual Studio 2019 and 2022) several months ago, and now more people bump into it... Two possible solutions: (1) Change `std::any_cast` to `absl::any_cast` (2) Add `include ` in operation_selector... Though I believe such tiny matters can be solved far quicker by a Tensorflow member, than by an external person proposing a pull request. Your other errors (as detailed in https://stackoverflow.com/q/76998448/7268445) are not related to the `any_cast` problem.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/152 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1875,"以下是一个github上的tensorflow下的一个issue, 标题是(Issues with Running Custom TensorFlow Lite Model in C++)， 内容是 ( 1. System information  Platform and Linux distribution kubuntu 22.04:  TensorFlow is built from C++ source code:  Tensorflow 2.11:  2. Code  Link to models that I trained and tried but they don't work in C++  https://github.com/asuemg1/models_hub/tree/main/Tensorflow%20Lite/Object%20Detection/my_ssd_mobnet/Optimized%20Models  Link to the model that works in C++  https://github.com/ankdesh/tflite/blob/master/AndroidTensorFlowLiteExample/app/src/main/assets/mobilenet_quant_v1_224.tflite  Link to C++ code (mainwindow.cpp file): https://drive.google.com/file/d/1u87yK1qqKeHBjUKqLkxi0LMQKkdrPg/view?usp=sharing  3. Crash after conversion  The model does not work in C++. Please tell me how you can run the Tensorflow Lite model (tflite format) for object detection or image classification in C ++. My steps:  Trained the model for object detection using Tensorflow 2 API object detection.  After training, I converted the model to the savedmodel format, and then to tflite.  Next, I needed to embed this model into a C++ project. In order to use it in the future on lowpower devices such as rasberry pi My actions:  Compiled the Tensorflow Lite library for C++.  Found a test case using the mobilenet_quant_v1_224.tflite model. In this test case, the model runs successfully. However, when trying to use my own model, it does not work, although it has been tested and works in Python. What was found out:  The mobilenet_quant_v1_224.tflite model was quantized and had no metadata and no internal labelmap.txt file.  TensorFlow Lite API 2 for C++ does not currently support metadata. If you have any information on how to get my tfl)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pavelgrigoriev,Issues with Running Custom TensorFlow Lite Model in C++," 1. System information  Platform and Linux distribution kubuntu 22.04:  TensorFlow is built from C++ source code:  Tensorflow 2.11:  2. Code  Link to models that I trained and tried but they don't work in C++  https://github.com/asuemg1/models_hub/tree/main/Tensorflow%20Lite/Object%20Detection/my_ssd_mobnet/Optimized%20Models  Link to the model that works in C++  https://github.com/ankdesh/tflite/blob/master/AndroidTensorFlowLiteExample/app/src/main/assets/mobilenet_quant_v1_224.tflite  Link to C++ code (mainwindow.cpp file): https://drive.google.com/file/d/1u87yK1qqKeHBjUKqLkxi0LMQKkdrPg/view?usp=sharing  3. Crash after conversion  The model does not work in C++. Please tell me how you can run the Tensorflow Lite model (tflite format) for object detection or image classification in C ++. My steps:  Trained the model for object detection using Tensorflow 2 API object detection.  After training, I converted the model to the savedmodel format, and then to tflite.  Next, I needed to embed this model into a C++ project. In order to use it in the future on lowpower devices such as rasberry pi My actions:  Compiled the Tensorflow Lite library for C++.  Found a test case using the mobilenet_quant_v1_224.tflite model. In this test case, the model runs successfully. However, when trying to use my own model, it does not work, although it has been tested and works in Python. What was found out:  The mobilenet_quant_v1_224.tflite model was quantized and had no metadata and no internal labelmap.txt file.  TensorFlow Lite API 2 for C++ does not currently support metadata. If you have any information on how to get my tfl",2023-08-26T15:17:24Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61709,"Hi ,  I'm having trouble understanding your project structure/compiling... specifically ""ui_mainwindow.h"" is included but the file included is mainwindow.ui. It also seems you have some dependencies. Can you please list your dependencies and the commands you used to compile? Are you using CMake or Bazel? If so, please include relevant files as well (CMakeLists.txt / BUILD).",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1876,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflowlite.dll is huge (compared to other platforms))， 内容是 (Opened on behalf of , Issue is current as of this writing. Previous Issue: https://github.com/tensorflow/tensorflow/issues/48118 *Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template*  System information * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 * TensorFlow installed from (source or binary): Source * TensorFlow version: https://github.com/tensorflow/tensorflow/commit/5d6cc7bf97a226c1e6a73ad4fc391c154dd622ac * Python version: n/a * Installed using virtualenv? pip? conda?: n/a * Bazel version (if compiling from source): 3.7.2 * GCC/Compiler version (if compiling from source): MSVC 2019 (cl: 19.28.29334) * CUDA/cuDNN version: n/a * GPU model and memory: n/a  Describe the problem  Provide the exact sequence of commands / steps that you executed before running into the problem  This yields a 15MB statically linked binary when compiled for 32bit windows (i.e. the 64bit version will be even larger). Compared to other platforms, this is a 5x increase that is difficult to explain, especially in lieu of tools like bloaty on Windows. Unfortunately I don't know where to start poking this at all  but I do believe that even accounting for platform differences, a 5x size difference is unexpected. The same issue was noted here: https://github.com/tensorflow/tensorflow/issues/33634issuecomment620645664 (with a suggestion to use the C API instead, but the C API is a binding that cannot be used independent from the C++ binary).  Any other i)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pkgoogle,tensorflowlite.dll is huge (compared to other platforms),"Opened on behalf of , Issue is current as of this writing. Previous Issue: https://github.com/tensorflow/tensorflow/issues/48118 *Please make sure that this is a build/installation issue. As per our GitHub Policy, we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template*  System information * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 * TensorFlow installed from (source or binary): Source * TensorFlow version: https://github.com/tensorflow/tensorflow/commit/5d6cc7bf97a226c1e6a73ad4fc391c154dd622ac * Python version: n/a * Installed using virtualenv? pip? conda?: n/a * Bazel version (if compiling from source): 3.7.2 * GCC/Compiler version (if compiling from source): MSVC 2019 (cl: 19.28.29334) * CUDA/cuDNN version: n/a * GPU model and memory: n/a  Describe the problem  Provide the exact sequence of commands / steps that you executed before running into the problem  This yields a 15MB statically linked binary when compiled for 32bit windows (i.e. the 64bit version will be even larger). Compared to other platforms, this is a 5x increase that is difficult to explain, especially in lieu of tools like bloaty on Windows. Unfortunately I don't know where to start poking this at all  but I do believe that even accounting for platform differences, a 5x size difference is unexpected. The same issue was noted here: https://github.com/tensorflow/tensorflow/issues/33634issuecomment620645664 (with a suggestion to use the C API instead, but the C API is a binding that cannot be used independent from the C++ binary).  Any other i",2023-08-25T22:32:05Z,stat:awaiting tensorflower type:build/install comp:lite TF 2.5,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61705, it looks like you copied the issue into chatgpt and posted the answer. Why?,"Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/153 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1864,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Not Detecting GPU on Compute Node)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v1.12.199044gc6ecfeac886 2.15.0dev20230825  Custom code No  OS platform and distribution CentOS Linux release 7.9.2009 (Core)  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8.0 / 8.7.0.84  GPU model and memory _No response_  Current behavior?  Behavior summary 🖥️ I'm trying to set up TensorFlow on a compute node within our scientific computing cluster and am running into a problem. After setting up a new environment and installing TensorFlow, running TensorFlow's `tf.config.list_physical_devices('GPU')` method returns an empty list, indicating no GPU devices are detected. However, `nvidiasmi` shows a Quadro RTX 6000 GPU present on the system. The TensorFlow CPU validation works without issues, but the GPU validation does not.  Possible Areas of Concern 🚩 1. **Modules vs. Conda/Pip Installations:** I've loaded specific versions of CUDA and cuDNN using the cluster's module system. However, I also used conda and pip to install these within my environment. Could this mixed approach cause any conflicts for TensorFlow? I'm unsure which version TensorFlow might prioritize or if it would create any confusion. 2. **CUDA Version Mismatch?:** When I run `nvidiasmi`, it indicates a CUDA version of 12.2. Yet, I've loaded and installed a CUDA version of 11.8 using both modules and conda. I'm wondering if this difference could lead to any issues. Does TensorFlow need a strict match with the CUDA version? 3. **Dif)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,masonhargrave,TensorFlow Not Detecting GPU on Compute Node," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v1.12.199044gc6ecfeac886 2.15.0dev20230825  Custom code No  OS platform and distribution CentOS Linux release 7.9.2009 (Core)  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8.0 / 8.7.0.84  GPU model and memory _No response_  Current behavior?  Behavior summary 🖥️ I'm trying to set up TensorFlow on a compute node within our scientific computing cluster and am running into a problem. After setting up a new environment and installing TensorFlow, running TensorFlow's `tf.config.list_physical_devices('GPU')` method returns an empty list, indicating no GPU devices are detected. However, `nvidiasmi` shows a Quadro RTX 6000 GPU present on the system. The TensorFlow CPU validation works without issues, but the GPU validation does not.  Possible Areas of Concern 🚩 1. **Modules vs. Conda/Pip Installations:** I've loaded specific versions of CUDA and cuDNN using the cluster's module system. However, I also used conda and pip to install these within my environment. Could this mixed approach cause any conflicts for TensorFlow? I'm unsure which version TensorFlow might prioritize or if it would create any confusion. 2. **CUDA Version Mismatch?:** When I run `nvidiasmi`, it indicates a CUDA version of 12.2. Yet, I've loaded and installed a CUDA version of 11.8 using both modules and conda. I'm wondering if this difference could lead to any issues. Does TensorFlow need a strict match with the CUDA version? 3. **Dif",2023-08-25T18:22:00Z,stat:awaiting response type:build/install type:support stale comp:gpu TF 2.13,closed,0,10,https://github.com/tensorflow/tensorflow/issues/61700," Update on Issue with TensorFlow GPU Detection After my initial post, I took the following steps to further investigate the issue: 1. ** Replicated the problem with Different cuDNN Version:** Even after pip installing the cuDNN version `8.6.0.163` recommended in TensorFlow's documentation, the problem persisted. TensorFlow still could not detect the GPU. 2. **Module Deactivation Check:** To determine if there was a conflict between the cluster's module system and my conda/pip installations, I deactivated the modules and relied solely on the versions installed via conda and pip. 3. **Custom Environment Variables for Modules:** After confirming the issue persisted without the modules, I then tried setting up the environment using the modules exclusively configuring the paths using those of the module system rather than those provided by the installation instructions:      For CUDA: `/home/software/spack/opt/spack/linuxcentos7x86_64/gcc8.2.0/cuda11.8.0rqftjjg3pwtogsetgcrrytjcqutxgtaj/bin`      For cuDNN: `/home/software/spack/opt/spack/linuxcentos7x86_64/gcc8.2.0/cudnn8.7.0.8411.8qibz3uecpmz5hiosbohqaniedyu6m6r5/lib` I adjusted the PATH and LD_LIBRARY_PATH environment variables to prioritize the module system's CUDA and cuDNN installations whenever my specific Conda environment was activated. Despite these troubleshooting steps, TensorFlow still does not recognize the GPU on the system. I'm continuing to seek insights or suggestions to resolve this issue.",Check this Tensorflow doesn't seem to see my gpu,To my understanding tensorflowgpu has been deprecated since 2022. Tried downgrading to TensorFlow 2.10 as suggested for windows users even though those problems don't seem super relevant to this case as I am running on Linux. After downgrading my CUDA and cuDNN to 11.2 and 8.1 respectively to no avail.,"Hi  , I think you are missing these 2 steps as mentioned in documentation instructions for GPU setup. Please refer the attached source and follow the instructions sequentially.  I have followed the same instructions and able to detect GPU.Please refer attached logs. ","Hi , thank you for your reply! As you can see in the *Configuring System Path* section of the *Standalone code to reproduce the issue* I do in fact run those commands from the instructions, except in the more automated way suggested below the commands you are referencing.   I reran my code using the nonautomated commands you suggested with no change to the problem. This is expected as the commands appear to be redundant and no different than the commands included in my minimal example.  Any other thoughts here?","Hi  , Could you please confirm the command you used for tensorflow installation? Please note that from Tf2.14V onwards GPU package available as `tensorflow[andcuda]`. Please try using the command  `pip install tensorflow[andcuda] `. You can refer the documentation here.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"If anyone like me has reached this thread for ideas about how to use your own CUDA and cuDNN, instead of installing through pip or conda:  It took me a while to realize that you also have to provide cuDNN libraries for tensorflow to discover your GPUs. That is why the second term in LD_LIBRARY_PATH. By the way, when you actually train a mode, you will also need:  > python script.py"
828,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation Fault (Core Dumped) when convert whisper with int8 quantization)， 内容是 (System information Linux 20.04 pip Tensorflow==2.12.0 using tranformers WhisperForConditionalgeneration  I'm trying to convert from TF to tflite and quantized to int8 Whisper, using the whisper model from tranformers WhisperForConditionalGeneration. At some point the conversion crash.  Here is the colab for more details:  Colab: https://colab.research.google.com/drive/1oAVoUxRFZLkS1uqqFN8HdgRVk0IWAlsN?usp=sharing Also I attach the Error Trace from my server running in CPU and also running in GPU (TITAN RTX 24GB).  CPU: TraceTflite.txt GPU: TraceTflite_GPU.txt)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SantiagoMoreno-Col,Segmentation Fault (Core Dumped) when convert whisper with int8 quantization,"System information Linux 20.04 pip Tensorflow==2.12.0 using tranformers WhisperForConditionalgeneration  I'm trying to convert from TF to tflite and quantized to int8 Whisper, using the whisper model from tranformers WhisperForConditionalGeneration. At some point the conversion crash.  Here is the colab for more details:  Colab: https://colab.research.google.com/drive/1oAVoUxRFZLkS1uqqFN8HdgRVk0IWAlsN?usp=sharing Also I attach the Error Trace from my server running in CPU and also running in GPU (TITAN RTX 24GB).  CPU: TraceTflite.txt GPU: TraceTflite_GPU.txt",2023-08-25T11:32:23Z,stat:awaiting tensorflower type:bug comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.12,closed,0,14,https://github.com/tensorflow/tensorflow/issues/61695,"Hi UdeA  I was able to reproduce this issue in TF Nightly as well. Please find the gist here. A similar issue is being tracked in CC(The Whisper Hybrid encoder model with dynamic quantization functions properly, but it fails when using a full int8 model with posttraining quantization.)  Does dynamic range quantization works for your case? Thanks.",Hi !  Thanks for answering  I need all model in Int8 'cause I'm attempting to run whisper inference in a NPU and this only support int8 data type.  So Dynamic quantization is not an option for me :/.  Looking in advance for your answer.  Cheers! ,UdeA Thanks for the information.  Could you please look into this issue? Thanks.,I was able to reproduce from 's gist.  can you please take a look,Hello  have you had time to take a look on this? ,UdeA I guess MUL op used in this model requires 16bit activation in order to preserve its accuracy. I am still not sure what is going on with TFLiteconverter  Here is the same issue I raised so long time back and no one addresses it  https://github.com/tensorflow/tensorflow/issues/58451,"When I have analyzed, observed seg fault here ... CC(未找到相关数据)  0x00007f623573d7d3 in mlir::quant::QuantizedType::getExpressedType() const () from /usr/local/lib/python3.9/distpackages/tensorflow/python/_pywrap_tensorflow_internal.so CC(Add support for Python 3.x)  0x00007f623573e1ac in mlir::quant::QuantizedType::castFromExpressedType(mlir::Type) ()    from /usr/local/lib/python3.9/distpackages/tensorflow/python/_pywrap_tensorflow_internal.so",sys It seems that so far quantize Whisper it's very tricky. Thank you for your information I'll take a look. ,Related to https://github.com/tensorflow/tensorflow/issues/29829,"Hi there, I am facing the same issue when trying to convert whisper into int8 for running on TPU, is there any update please? Thank you.","Hi SharedStudios, No the error remains. It seems that it's very low level error. ","I found that tflite versions of Whisper generate NaN values when processing the float(""inf"") values that are used in one part of the transformer codebase (specifically, the logits processor that kicks in when you call generate with forced tokens).  Perhaps those NaNs make the int8 quantization crash too.  I made a crude patch here, which has worked for me to stop the NaNs happening: https://github.com/nyadlasys/whisper.tflite/discussions/15","Hi, UdeA  Thanks for raising this issue. Are you aware of AIEdgeTorch? As we believe this issue is better supported by and more relevant to AIEdgeTorch we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/aiedgetorch/issues/396 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
930,"以下是一个github上的tensorflow下的一个issue, 标题是(extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 1.13.1  Custom code Yes  OS platform and distribution Unbuntu 22  Mobile device _No response_  Python version Python 2.7  Bazel version _No response_  GCC/compiler version 9.4.0  CUDA/cuDNN version 10  GPU model and memory GTX 1060   Current behavior? Hi, I got this error when I run Dirt model with my tensorflowgpu 1.13.1 .  `20230825 15:23:37.711796: F /home/engineer1/dirt/csrc/gl_common.h:46] extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available`  Standalone code to reproduce the issue )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MilesTheProwler,"extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 1.13.1  Custom code Yes  OS platform and distribution Unbuntu 22  Mobile device _No response_  Python version Python 2.7  Bazel version _No response_  GCC/compiler version 9.4.0  CUDA/cuDNN version 10  GPU model and memory GTX 1060   Current behavior? Hi, I got this error when I run Dirt model with my tensorflowgpu 1.13.1 .  `20230825 15:23:37.711796: F /home/engineer1/dirt/csrc/gl_common.h:46] extensions eglQueryDevicesEXT, eglQueryDeviceAttribEXT and eglGetPlatformDisplayEXT not available`  Standalone code to reproduce the issue ",2023-08-25T08:27:34Z,stat:awaiting response type:bug stale TF 1.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61694,"Hi , I am sorry to say that 1.x versions no more supported. Could you please test with latest versions without tf.Session and let us know if any problem arises. Thanks! ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
867,"以下是一个github上的tensorflow下的一个issue, 标题是(JIT yields inconsistent results using tf.math.top_k)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.15.0dev20230824  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda_11.8.r11.8/compiler.31833905_0 / cuDNN version 8700  GPU model and memory NVIDIA GeForce RTX 2080 Ti  Current behavior? JIT yields inconsistent results using `tf.math.top_k` when `index_type=tf.int32` (no issue with `index_type=tf.int64`).  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,nicolaspi,JIT yields inconsistent results using tf.math.top_k, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.15.0dev20230824  Custom code Yes  OS platform and distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda_11.8.r11.8/compiler.31833905_0 / cuDNN version 8700  GPU model and memory NVIDIA GeForce RTX 2080 Ti  Current behavior? JIT yields inconsistent results using `tf.math.top_k` when `index_type=tf.int32` (no issue with `index_type=tf.int64`).  Standalone code to reproduce the issue   Relevant log output ,2023-08-25T07:37:33Z,stat:awaiting response type:bug comp:ops,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61692, Could you please have a look at the colab gist of TF v2.13 and tfnightly. I couldn't reproduce the error reported here.  The output is as follows;  Thank you! ,Updating the GPU drivers fixed the issue. Thanks,Are you satisfied with the resolution of your issue? Yes No, Glad your issue has been fixed.  Thank you!
1233,"以下是一个github上的tensorflow下的一个issue, 标题是(Batch matmul imprecision)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13 / 2.14.0dev20230706  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version   GPU model and memory NVIDIA GeForce RTX 3060  12 GB Driver Version: 520.61.05  Current behavior? I'm trying to do a batch matrix multiply (i.e. I've got a bunch of m x n matrices, all in one tensor, and I want to do a matrix multiply of each of them with some other matrix). However, I'm getting slightly different results than I get from Numpy (and previous TensorFlow versions, this script passed for me in 2.9).  One interesting thing is that the value 25 (the second dimension of `x`) is significant. If I reduce this to 16 or below, it passes. Also, if I change the second dimension of `c` from 2 to 1, it also passes.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hunse,Batch matmul imprecision," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13 / 2.14.0dev20230706  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version   GPU model and memory NVIDIA GeForce RTX 3060  12 GB Driver Version: 520.61.05  Current behavior? I'm trying to do a batch matrix multiply (i.e. I've got a bunch of m x n matrices, all in one tensor, and I want to do a matrix multiply of each of them with some other matrix). However, I'm getting slightly different results than I get from Numpy (and previous TensorFlow versions, this script passed for me in 2.9).  One interesting thing is that the value 25 (the second dimension of `x`) is significant. If I reduce this to 16 or below, it passes. Also, if I change the second dimension of `c` from 2 to 1, it also passes.  Standalone code to reproduce the issue   Relevant log output ",2023-08-23T19:29:13Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61683, Could you please share all the dependencies to replicate the issue reported here.  Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.," , What dependencies you need still? Seems your colab file executed fine. Why do you think some dependencies missing?  , It seems in colab environment `assert_allclose()` is success for given tolerance. Are you sure the attached code snippet is the one raising error for you? Could you please execute the attached code snippet in colab and confirm the behaviour with gist?","I looked into this a bit more, and it seems to be a CUDA/driver/GPU issue. We have two machines that show the error, and a few other machines that don't, despite trying to make all CUDA/driver/etc. versions equivalent among all machines. Furthermore, on the new machines/environments that show the issue, it also appears in earlier TF versions. I'll close this, since it does not seem to be TF, but rather some lowerlevel issue.",Are you satisfied with the resolution of your issue? Yes No
705,"以下是一个github上的tensorflow下的一个issue, 标题是(Unit test failure when built with clang)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 16.0.6  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/compiler/mlir/lite/sparsity:sparsify_model_test throws a segfault  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,elfringham,Unit test failure when built with clang, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 16.0.6  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/compiler/mlir/lite/sparsity:sparsify_model_test throws a segfault  Standalone code to reproduce the issue   Relevant log output ,2023-08-23T15:18:03Z,awaiting review type:bug type:support subtype: ubuntu/linux,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61677, ,Same fault for //tensorflow/compiler/mlir/lite/quantization/lite:quantize_model_test and //tensorflow/compiler/mlir/lite/quantization/lite:quantize_weights_test,Building for UBSAN gives the following error. ,Are you satisfied with the resolution of your issue? Yes No
426,"以下是一个github上的tensorflow下的一个issue, 标题是(Image storage)， 内容是 (When TFLite processes image data, which variable will the read in image data be stored in? Is it TfLiteTensor.data? How can I directly process a single image using TensorFlow Lite source code without relying on an Android app?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,B-JackMao,Image storage,"When TFLite processes image data, which variable will the read in image data be stored in? Is it TfLiteTensor.data? How can I directly process a single image using TensorFlow Lite source code without relying on an Android app?",2023-08-23T15:09:24Z,type:support comp:lite,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61676,JackMao Sorry for the late response! Could you please follow this page which explains about processing input and output data into tflite model? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.," , > When TFLite processes image data, which variable will the read in image data be stored in? Is it TfLiteTensor.data? Could you please confirm your reply to this? I am unable to find whether attached resource has the information required.","Hello, !  That above page is referring to the process of input and output data in TFlite. To process an image data we have to set the tensor, invoke it and lastly we can get the tensor. JackMao We can store any image data in the form of a tensor while processing it. We have to consider only the size and type of the image. Please have a look at this example where you can see how a model can be tested on a single image.  Sample code is as below;  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
657,"以下是一个github上的tensorflow下的一个issue, 标题是(Android NDK Prefabs for Tensorflow Lite)， 内容是 (Hey all! I'm trying to use Tensorflow Lite in an Android NDK/C++ environment. My `build.gradle` looks something like this:  And in my `CMakeLists.txt` I try to find `tensorflowlite` as a prefab:  However, CMake is not able to find the package:  Does TensorFlow Lite not provide a prefab publish? This would make it a lot easier to integrate in such environments. Now I have to manually extract the .aar/zip and incldue the headers.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mrousavy,Android NDK Prefabs for Tensorflow Lite,"Hey all! I'm trying to use Tensorflow Lite in an Android NDK/C++ environment. My `build.gradle` looks something like this:  And in my `CMakeLists.txt` I try to find `tensorflowlite` as a prefab:  However, CMake is not able to find the package:  Does TensorFlow Lite not provide a prefab publish? This would make it a lot easier to integrate in such environments. Now I have to manually extract the .aar/zip and incldue the headers.",2023-08-22T08:55:49Z,stat:awaiting tensorflower type:feature type:build/install comp:lite TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61667,"Hi   As per the documentation,  Currently, there is no straightforward way to extract all header files needed, we need include all header files manually.  Could you please look at this request? Thanks.","Hi , I can't find any documentation that we have a prefab available, should we take this as a feature request?","Hey  yea sorry this was a question at first, but if that's not a feature then it's a feature request I guess :) Happy to help here  but prefabs are really making things a lot easier for us C++ developers. Thanks!","Hi , can you please take a look? Thanks.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/154 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1247,"以下是一个github上的tensorflow下的一个issue, 标题是(`GLIBCXX_3.4.30' not found)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version r2.13  Custom code No  OS platform and distribution amazon linux 2023  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/compiler version gcc 12.2  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? ERROR: /root/tensorflow/tensorflow/core/transforms/remapper/BUILD:14:18: TdGenerate tensorflow/core/transforms/remapper/pdll/MklPDLLPatterns.h.inc [for host] failed: (Exit 1): mlirpdll failed: error executing command bazelout/host/bin/external/llvmproject/mlir/mlirpdll 'x=cpp' tensorflow/core/transforms/remapper/pdll/mkl_patterns.pdll I ./tensorflow/core/transforms/include I ... (remaining 15 arguments skipped) bazelout/host/bin/external/llvmproject/mlir/mlirpdll: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by bazelout/host/bin/external/llvmproject/mlir/mlirpdll)  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,andrewkim-pkt,`GLIBCXX_3.4.30' not found, Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version r2.13  Custom code No  OS platform and distribution amazon linux 2023  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/compiler version gcc 12.2  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? ERROR: /root/tensorflow/tensorflow/core/transforms/remapper/BUILD:14:18: TdGenerate tensorflow/core/transforms/remapper/pdll/MklPDLLPatterns.h.inc [for host] failed: (Exit 1): mlirpdll failed: error executing command bazelout/host/bin/external/llvmproject/mlir/mlirpdll 'x=cpp' tensorflow/core/transforms/remapper/pdll/mkl_patterns.pdll I ./tensorflow/core/transforms/include I ... (remaining 15 arguments skipped) bazelout/host/bin/external/llvmproject/mlir/mlirpdll: /lib64/libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by bazelout/host/bin/external/llvmproject/mlir/mlirpdll)  Standalone code to reproduce the issue   Relevant log output ,2023-08-22T06:02:09Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61665,"Hi pkt , Try using Clang instead of GCC, as from tf v2.13 it supports compiler Clang. Please refer the documentation here for reference. Let us know if the issue still exists.  Thank you!!","GCC 11.4 build with tr v2.13 works fine but GCC 12.2 got this issue. Never tried it with Clang, can you please share the steps for this to save time. From: Varshaanjanappa ***@***.***> Sent: Monday, August 21, 2023 11:54 PM To: tensorflow/tensorflow ***@***.***> Cc: Kim, Andrew ***@***.***>; Mention ***@***.***> Subject: Re: [tensorflow/tensorflow] `GLIBCXX_3.4.30' not found (Issue CC(`GLIBCXX_3.4.30' not found)) Hi pkt , Try using Clang instead of GCC, as from tf v2.13 it supports compiler Clang. Please refer the documentation here for reference. Let us know if the issue still exists. Thank you!! — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>","Hi pkt , Please follow the build from source steps here. To install clang please refer here. Configure the build and select Y to use Clang to build TensorFlow. Refer here Thank you!!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1909,"以下是一个github上的tensorflow下的一个issue, 标题是(Ops listed in 'experimental_select_user_tf_ops' not being recognized by tf lite converter)， 内容是 ( 1. System information  Google Colab Notebook  2. Code _ Model Definition _  _ Model Saving _  _ Model Conversion _   >  > ConverterError                            Traceback (most recent call last) >  > [](https://localhost:8080/) in () >      45 converter.allow_custom_ops=True >      46  > > 47 tflite_model = converter.convert() >      48  >      49 with open('cpp_tf_test.tflite', 'wb') as f: >  > 7 frames >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in wrapper(self, *args, **kwargs) >     960   def wrapper(self, *args, **kwargs): >     961      pylint: disable=protectedaccess > > 962     return self._convert_and_export_metrics(convert_func, *args, **kwargs) >     963      pylint: enable=protectedaccess >     964  >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in _convert_and_export_metrics(self, convert_func, *args, **kwargs) >     938     self._save_conversion_params_metric() >     939     start_time = time.process_time() > > 940     result = convert_func(self, *args, **kwargs) >     941     elapsed_time_ms = (time.process_time()  start_time) * 1000 >     942     if result: >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in convert(self) >    1245           graph_def) >    1246  > > 1247     return self._convert_from_saved_model(graph_def) >    1248  >    1249  >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in _convert_from_saved_model(self, graph_def) >    1128     converter_kwargs.update(quant_mode.converter_flags()) >    1129  > > 1130     result = _convert_saved_model(**converter_kwargs))请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,anselmo0v,Ops listed in 'experimental_select_user_tf_ops' not being recognized by tf lite converter," 1. System information  Google Colab Notebook  2. Code _ Model Definition _  _ Model Saving _  _ Model Conversion _   >  > ConverterError                            Traceback (most recent call last) >  > [](https://localhost:8080/) in () >      45 converter.allow_custom_ops=True >      46  > > 47 tflite_model = converter.convert() >      48  >      49 with open('cpp_tf_test.tflite', 'wb') as f: >  > 7 frames >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in wrapper(self, *args, **kwargs) >     960   def wrapper(self, *args, **kwargs): >     961      pylint: disable=protectedaccess > > 962     return self._convert_and_export_metrics(convert_func, *args, **kwargs) >     963      pylint: enable=protectedaccess >     964  >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in _convert_and_export_metrics(self, convert_func, *args, **kwargs) >     938     self._save_conversion_params_metric() >     939     start_time = time.process_time() > > 940     result = convert_func(self, *args, **kwargs) >     941     elapsed_time_ms = (time.process_time()  start_time) * 1000 >     942     if result: >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in convert(self) >    1245           graph_def) >    1246  > > 1247     return self._convert_from_saved_model(graph_def) >    1248  >    1249  >  > /usr/local/lib/python3.10/distpackages/tensorflow/lite/python/lite.py in _convert_from_saved_model(self, graph_def) >    1128     converter_kwargs.update(quant_mode.converter_flags()) >    1129  > > 1130     result = _convert_saved_model(**converter_kwargs)",2023-08-21T23:40:13Z,stat:awaiting tensorflower type:bug type:build/install comp:lite TFLiteConverter Android TF 2.13,closed,0,16,https://github.com/tensorflow/tensorflow/issues/61662,"Hi   As per the documentation, it should only be used if  we are using TF ops that may not be linked in by default with the TF ops that are provided when using the SELECT_TF_OPS path. I guess adding the regular select ops flag does the similar job as `RandomUniform` and `Mul `are already a part of Select TF Ops. Please check this gist. For reducing the binary size of the TFLite model consider https://www.tensorflow.org/lite/guide/reduce_binary_size Thanks.","Hi , thank you very much for your response. So, I understand what I am doing is not the intended use for the experimental_select_user_tf_ops flag. I had checked the guide to reduce binary size before, the thing is my laptop is freezing in the middle of the build with bazel when I set SELECT_TF_OPS, and that's why I wanted to reduce the number of ops included.  Any chance there is a method to manually specify just some ops from the tf_ops set to be included in the build?","Hi   Thanks for the information. As of now, we can only reduce the binary size by model, not using the list of ops. Selective building will include the necessary operators for your models. > I had checked the guide to reduce binary size before, the thing is my laptop is freezing in the middle of the build with bazel when I set SELECT_TF_OPS Regarding freezing issues during Bazel builds with the SELECT_TF_OPS flag, it's advisable to consider using a more powerful machine with robust CPU and memory configurations for smooth compilation of model,  incase they are complex.  Is it possible to share the error stack trace and TFLite model to reproduce the issue? Thanks.","Hi , I'll try to find a better machine to run the build and contact again with error trace if any.  Thank you very much for your help.",Hi   Did you get a chance to run the build? Thanks.,"Hi . Yes, I have been following the reduce binary size guide in various machines both Mac and Linux with no sucess at building tensorflowlite_flex.  I decided to use an AWS EC2 instance with Docker to avoid possible dependency conflicts, but still the build fails. The instance has this specifications: RAM: 32GB vCPU: 16 Architecture: x86_64 OS: Ubuntu 22.0.4 Server I use the same simple model of my first comment, previously converted and saved to a .tflite, setting _tf.lite.OpsSet.TFLITE_BUILTINS_ and _tf.lite.OpsSet.SELECT_TF_OPS_ . These are the BUILD file inside the created _tmp_ folder and the Dockerfile I am using: Dockerfile.txt BUILD.txt This is the error I get: error_logs.txt It seems to be a consistent error in all the Intel  Linux machines I've tried. At lines _52 to 60_ of my Dockerfile I tried to solve this issue by including the source files from oneAPI into the source files of Tensorflow, but the same error keeps showing. I appreciate your help.","Hi  . So I followed the guide to build .aar files for Java from the AWS EC2 instance I mentioned before and it was successful.  Now I've tried to follow similar steps to build for C++. I've copied and modified the build_aar.sh file: build_tf_flex.sh And divided my previous BUILD file into to different files: BUILD_tfliteops BUILD_tfops I also deleted lines _52 to 60_ (that added oneapi source files) from my Dockerfile: Dockerfile The _tensorflowlite.so_ file is successfully created, but I get a lot of undefined reference errors when building the _tensorflowlite_flex.so_ file: stderr2 This is the command I'm using from the Docker container to build: `bash custom_files/build_tf_flex.sh input_models=custom_files/cpp_tf_test.tflite target_archs=arm64v8a` Not sure if this is the correct target when building .so files for android, since other guides say you should use _android_arm64_. I can work for now with the .aar files but the reason I need to build for C++ is because I'm looking for cross platform integration. I really appreciate any help you can provide.",Hi   Sorry for the delayed response. Thanks for the information. Just wanted to know if you tried with just `config=andorid_arm64` without monolithic build?  Thanks.,"Hi . I retried as suggested, no `config=monolithic` option and using `confing=android_arm64` as target. This is my new .sh file: build_tf_flex.sh It is back to the error related to missing dnnl files: error_logs",Hi   Thanks for the information.  Could you please check this issue?,"Hi , Can you review this and see if it helps you. https://www.tensorflow.org/lite/guide/ops_select://www.tensorflow.org/lite/android/developmenttools_for_building_with_c_and_c if that doesn't work can you please give me your exact steps (as if you are writing a shell script or Dockerfile) to reproduce the issue you are seeing. There's probably a way to get it from all the above but putting it all into one message will make things easier to debug.","Hi , thanks for taking a look at this issue. These are the steps I'm following: **1.** I create my .tflite file from this Google Colab Notebook here. **2.** I connect my local terminal by ssh to the AWS EC2 instance I use (RAM: 32GB, vCPU: 16, Architecture: x86_64, OS: Ubuntu 22.0.4 Server). **3.** I clone my files from terminal. **4.** Then I build the docker image from my Dockerfile:  **5.** Next I run the container and go inside it: `sudo docker run it v $PWD:/host_dir tfbuilder bash` **6.** Inside the running container, I go to the tensorflow source folder: `cd home/tensorflow2.13.0` **7.** From there, I run my build_tf_flex.sh file: `bash custom_files/build_tf_flex.sh input_models=custom_files/cpp_tf_test.tflite target_archs=android_arm64` The custom_files folder is created at my Dockerfile and contains the BUILD files, the build_tf_flex.sh file and the .tflite model.  The build_tf_flex.sh file is a customized file I made by taking the build_aar.sh file from tensorflow source code and modifying it to:        Build the tensorflowlite.so with the command:        bazel ${CACHE_DIR_FLAG} build c opt cxxopt='std=c++17' config=${TARGET_ARCHS} //tmp:tensorflowlite verbose_failures        Build the tensorflowlite_flex.so with the command:       bazel ${CACHE_DIR_FLAG} build c opt cxxopt='std=c++17' config=${TARGET_ARCHS} host_crosstool_top=//tools/cpp:toolchain //tmp:tensorflowlite_flex verbose_failures The tensorflowlite.so file is successfully created, but at the tensorflowlite_flex.so building step I obtain the mentioned error: `fatal error: dnnl.hpp: No such file or directory` This is the log file:  error_logs","Hi , I was able to replicate your issue with the following steps:  It seems like that header (dnnl.hpp) is only included with some build_with_mkl flags, I tried a couple of different things but they all failed as well. I added a define=build_with_mkl=true flag but that wasn't it, but it seems it got further  produces eventually:  , can you please take a look? Thanks.","Hi  , .  Just checking if you have any updates on this issue. Thanks.","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/155 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1842,"以下是一个github上的tensorflow下的一个issue, 标题是(New TFL-to-tensor pass)， 内容是 (This pull request introduces a new pass called `tensorlegalizetfl` aimed at lowering the TFL dialect into *standard* MLIR dialects (`arith`, `builtin`, `func`, `index`, `linalg`, `math`, `memref`, or `tensor`). The pass includes a first conversion pattern aimed at lowering the `tfl.reshape` operation.  1. Organization The current support to convert the TFL dialect into lowerlevel MLIR dialects is concentrated in pass `tosalegalizetfl`, which uses TOSA as the target dialect. A limitation of this pass is posed by the fact that some TFL ops are representable in TOSA only for some combinations of their input operands, while other TFL ops are not representable in TOSA at all. To successfully lower such ops, one must rely on a richer variety of lowerlevel ops from MLIR standard dialects. After several discussions on the topic, it has been concluded that introducing a separate pass independent from TOSA is the most appropriate course of action. This pull request introduces pass `tensorlegalizetfl`. While the name of this pass suggests that the `tensor` dialect is the conversion target, the pass may generate operation in any MLIR standard dialect other than `tosa`. These are some reasons that justify the choice of the `tensor` prefix in the pass name:  It is likely that the emitted code for a given conversion pattern uses an operation in the `tensor` dialect as its centerpiece. This is the case of the first lowering pattern introduced in this pull request, where op `tfl.reshape` is lowered directly into `tensor.reshape` in some straightforward corner cases, although the general case involves the introduction of si)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,rafaelubalmw,New TFL-to-tensor pass,"This pull request introduces a new pass called `tensorlegalizetfl` aimed at lowering the TFL dialect into *standard* MLIR dialects (`arith`, `builtin`, `func`, `index`, `linalg`, `math`, `memref`, or `tensor`). The pass includes a first conversion pattern aimed at lowering the `tfl.reshape` operation.  1. Organization The current support to convert the TFL dialect into lowerlevel MLIR dialects is concentrated in pass `tosalegalizetfl`, which uses TOSA as the target dialect. A limitation of this pass is posed by the fact that some TFL ops are representable in TOSA only for some combinations of their input operands, while other TFL ops are not representable in TOSA at all. To successfully lower such ops, one must rely on a richer variety of lowerlevel ops from MLIR standard dialects. After several discussions on the topic, it has been concluded that introducing a separate pass independent from TOSA is the most appropriate course of action. This pull request introduces pass `tensorlegalizetfl`. While the name of this pass suggests that the `tensor` dialect is the conversion target, the pass may generate operation in any MLIR standard dialect other than `tosa`. These are some reasons that justify the choice of the `tensor` prefix in the pass name:  It is likely that the emitted code for a given conversion pattern uses an operation in the `tensor` dialect as its centerpiece. This is the case of the first lowering pattern introduced in this pull request, where op `tfl.reshape` is lowered directly into `tensor.reshape` in some straightforward corner cases, although the general case involves the introduction of si",2023-08-21T17:13:23Z,size:L,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61660, I did my best to address your comments. Let me know if there's anything else you'd like me to take care of.,Hi  Can you please resolve conflicts? Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,Hi  Can you please resolve conflicts? Thank you!
671,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to serialize VariableSpec)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.13.0  Custom code Yes  OS platform and distribution windows 11  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? A graph  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,Ella-Adu,Unable to serialize VariableSpec, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.13.0  Custom code Yes  OS platform and distribution windows 11  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? A graph  Standalone code to reproduce the issue   Relevant log output ,2023-08-21T15:11:42Z,stat:awaiting response type:bug stale TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61658,"The warning message, is a strong indication that the Lambda layer should be rewritten as a subclassed Layer, suggests that there might be an issue with a Lambda layer in your code. Try rewriting the Lambda layer using the tf.keras.layers.Layer subclassing approach instead of using a Lambda layer directly.","Adu, tf.keras.Lambda: Note that if variables are involved in the layer created by this method, the variable will not be automatically added to the variable set for gradient calculation. Therefore, if there are parameters to be trained in the userdefined layer, it is recommended to customize the model layer based on the base class.  Also please have a look at this blog for reference. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1545,"以下是一个github上的tensorflow下的一个issue, 标题是(Activation function of a Dense hidden layer not getting invoked.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code Yes  OS platform and distribution MacOS 13.4, MacBook Pro M2 Max  Mobile device _No response_  Python version 3.8.17  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Issue: In the given autoencoder setup, the encoder layers activation function (relu) is not getting invoked. 1. We create a simple autoencoder, with Input size 3, hidden size 2, and output back to 3. 2. The activation function of the encoder layer is set a relu. 3. The weights of the encoder layers are all made negative. Idea is, if input is +ve, all the neutrons will have negative value and relu will o/p zero. 4. Give input as [1, 0, 0]. 5. We expect the final decoder o/p layer, which has sigmoid activation, to o/p all [0.5, 0.5, 0.5] as the input to this layer from the encoder should have been [0, 0, 0].  6. But we find that is not the case, which clearly shows that 'relu' activation of the hidden layer is not getting invoked. Installation: pip install tensorflowmacos pip install tensorflowmetal  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,therealsachin,Activation function of a Dense hidden layer not getting invoked.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code Yes  OS platform and distribution MacOS 13.4, MacBook Pro M2 Max  Mobile device _No response_  Python version 3.8.17  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Issue: In the given autoencoder setup, the encoder layers activation function (relu) is not getting invoked. 1. We create a simple autoencoder, with Input size 3, hidden size 2, and output back to 3. 2. The activation function of the encoder layer is set a relu. 3. The weights of the encoder layers are all made negative. Idea is, if input is +ve, all the neutrons will have negative value and relu will o/p zero. 4. Give input as [1, 0, 0]. 5. We expect the final decoder o/p layer, which has sigmoid activation, to o/p all [0.5, 0.5, 0.5] as the input to this layer from the encoder should have been [0, 0, 0].  6. But we find that is not the case, which clearly shows that 'relu' activation of the hidden layer is not getting invoked. Installation: pip install tensorflowmacos pip install tensorflowmetal  Standalone code to reproduce the issue   Relevant log output ",2023-08-20T18:45:47Z,stat:awaiting response type:bug stale subtype:macOS TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61650,"NOTE:  When I downgraded tf from 2.13.0 to 2.12.0, the code worked as expected. The output with tf 2.12.0. The final decoder layer is outputting values [0.5, 0.5, 0.5] as expected. ","Hi  , I have tested the provided code with Tf2.13v on both Linux and Macos and both are generating same output for me. Please refer the result on colab gist. Please refer the attached logs on Macos. ","Hi  , FYI. I am running on Apple M2 Max, 64 GB, macOS Ventura Version 13.4 (22F66). I can replicate the issue on my machine. Is there anything that I can do to debug this more? Like, run all tests locally and see if any of the tests fails? Or do something else. When I set to eager execution to true the bug does not manifest. So I am guessing this has something to do with the execution graph optimization. ","Hi  , I have disable V2 behaviour using `tf.compat.v1.disable_v2_behavior()`to disable eager execution and added `print(tf.executing_eagerly())` at last. Then executed the code again it's not replicating reported behaviour.Please refer attached logs.  The bug doesn't manifest without Eager execution also. Did you tried with any alternate method?  Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
887,"以下是一个github上的tensorflow下的一个issue, 标题是(GPU error Tensorflow with 2.1)， 内容是 ( Issue type Others  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.1  Custom code Yes  OS platform and distribution CentOS Linux release 7.4.1708   Mobile device _No response_  Python version 3.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 10/7  GPU model and memory Nvidia A100 partitioned virtually in two 40GB GPUs, I am using one of them  Current behavior? I am working on 3D_ Unet. I am getting the ptax error with Tensorflow 2.1 when I run the 3D Unet , I am using tensorflowlargemodelsupport to scale the algorithm  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,junaidjawaid1,GPU error Tensorflow with 2.1," Issue type Others  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.1  Custom code Yes  OS platform and distribution CentOS Linux release 7.4.1708   Mobile device _No response_  Python version 3.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 10/7  GPU model and memory Nvidia A100 partitioned virtually in two 40GB GPUs, I am using one of them  Current behavior? I am working on 3D_ Unet. I am getting the ptax error with Tensorflow 2.1 when I run the 3D Unet , I am using tensorflowlargemodelsupport to scale the algorithm  Standalone code to reproduce the issue   Relevant log output ",2023-08-20T17:59:51Z,stat:awaiting response stale type:others comp:gpu TF 2.1,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61649,", Have you installed CUDA from the official site? And have you installed the right version? The current one is 11.8. Also you are trying with tensorflow v2.1 which is a pretty older version.  It's unlikely for TF 2.1 version to receive any bug fixes except when we have security patches. There is a high possibility that this was fixed with later TF versions. Perhaps you can use the latest tf versions for your case.  https://www.tensorflow.org/install Thank you!",>  Thank you so much for the response. I am using v2.1 cause LMS support is only available with this version. If you can guide me regarding memory swapping in the latest versions that would really helpful. Thank you.,", Tensorflow v2.1 is compatible with python 2.7, 3.53.7, compile GCC 7.3.1, Bazel 0.27.1, CUDA  7.6, cuDNN 10.1.  https://www.tensorflow.org/install/sourcegpu Also as the error(ModuleNotFoundError: No module named 'nvidia') stated, this error occurred due to Nvidia and not from the tensorflow. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"> Are you satisfied with the resolution of your issue? Yes No yes, I am satisfied. Thank you all for your response."
1879,"以下是一个github上的tensorflow下的一个issue, 标题是(Check failure when running tf.compat.v1.layers.MaxPooling1D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to feeding Large list elements  Standalone code to reproduce the issue  shell 0230818 22:04:07.309328: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230818 22:04:07.824681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT 20230818 22:04:08.293378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230818 22:04:08.311735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230818 22:04:08.311868: I tensorflow/compiler/xla/stream_executor)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Check failure when running tf.compat.v1.layers.MaxPooling1D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to feeding Large list elements  Standalone code to reproduce the issue  shell 0230818 22:04:07.309328: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230818 22:04:07.824681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT 20230818 22:04:08.293378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230818 22:04:08.311735: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230818 22:04:08.311868: I tensorflow/compiler/xla/stream_executor",2023-08-19T02:28:18Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61642,"Hi , I have tested the code with tf version 2.12 and tfnightly and its working fine by raising exception, please find the gist here.  Thank you!",>  Thanks anjanappa. On my side (2.13.0): ,"Hi  , Tested the code on colab with tf version 2.13 as well, it is working fine. Please find the gist. Thank you!!",>  My session on Colab is still crashing. Please find the attached snapshot: !Screenshot from 20230821 015410 Log: ,"Hi  , As you can see the below snapshot, It is executing as expected, please refer to the gist given here. !image Thank you!!","> Hi  , >  > As you can see the below snapshot, It is executing as expected, please refer to the gist given here. >  > !image >  > Thank you!! This is a serious issue as we get different outputs. ","Hi  , With CPU runtime the code executes fine and attached gist for reference. With GPU runtime check fail followed by crash happening. Attached screenshot for below. ",  I repro the code that is shared with the tensorflow `2.17.1` and it is throwing the exception as expected by you. Here is the gist,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
387,"以下是一个github上的tensorflow下的一个issue, 标题是(Register DEVICE_DEFAULT for Assign(Add/Sub)VariableOp)， 内容是 (Ran into this when trying to run this example (https://www.tensorflow.org/agents/tutorials/6_reinforce_tutorial) with the example Pluggable Device.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jswag180,Register DEVICE_DEFAULT for Assign(Add/Sub)VariableOp,Ran into this when trying to run this example (https://www.tensorflow.org/agents/tutorials/6_reinforce_tutorial) with the example Pluggable Device.,2023-08-18T11:58:21Z,awaiting review ready to pull size:S comp:core,closed,0,0,https://github.com/tensorflow/tensorflow/issues/61637
913,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow when running tf.compat.v1.manip.tile)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large element in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 44407488056105 with 96070284019968, result: 1 	 [[{{node Tile}}]] [Op:Tile] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow when running tf.compat.v1.manip.tile," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large element in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 44407488056105 with 96070284019968, result: 1 	 [[{{node Tile}}]] [Op:Tile] ",2023-08-18T00:56:31Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61631,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
911,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.image.resize)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__ResizeBilinear_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 929338090226 with 1164413628, result: 1 [Op:ResizeBilinear] name: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.image.resize," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__ResizeBilinear_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 929338090226 with 1164413628, result: 1 [Op:ResizeBilinear] name: ",2023-08-18T00:54:16Z,type:bug comp:ops TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61630,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
947,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.compat.v1.image.resize)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__ResizeNearestNeighbor_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 20527214848 with 536870912, result: 7426279517443850240 [Op:ResizeNearestNeighbor] name:  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.compat.v1.image.resize," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__ResizeNearestNeighbor_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 20527214848 with 536870912, result: 7426279517443850240 [Op:ResizeNearestNeighbor] name:  ",2023-08-18T00:52:39Z,stat:awaiting tensorflower type:bug comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61629,"Hi  , The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference. We need to have a look into the issue whether this is intended as the error seems generated from TF C++ code itself.  Thanks!","> Hi  , >  > The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference. >  > We need to have a look into the issue whether this is intended as the error seems generated from TF C++ code itself. >  > Thanks! I think the bug is arising from the Python backend because C++ throws OP_REQUIRES failed with integer overflow. On both sides, overflow occurs. ",This is working as intended.  Those sizes are too big.,Are you satisfied with the resolution of your issue? Yes No
904,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow when running tf.compat.v1.linalg.diag)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 12885103520 with 1610637940, result: 1 [Op:MatrixDiagV3] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow when running tf.compat.v1.linalg.diag," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 12885103520 with 1610637940, result: 1 [Op:MatrixDiagV3] ",2023-08-18T00:42:33Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61628,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
920,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.compat.v1.manip.tile)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input tensor  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 44407488056105 with 96070284019968, result: 1 	 [[{{node Tile}}]] [Op:Tile] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.compat.v1.manip.tile," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input tensor  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 44407488056105 with 96070284019968, result: 1 	 [[{{node Tile}}]] [Op:Tile] ",2023-08-18T00:37:29Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61627,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
906,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow when running tf.compat.v1.tile)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 46283860790870 with 125091515651, result: 1 	 [[{{node Tile}}]] [Op:Tile] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow when running tf.compat.v1.tile," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 46283860790870 with 125091515651, result: 1 	 [[{{node Tile}}]] [Op:Tile] ",2023-08-18T00:34:55Z,type:bug comp:ops TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61626,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1053,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.compat.v1.keras.layers.ZeroPadding2D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 750549093948 with 250183031316, result: 1 	 [[{{node Pad}}]] [Op:Pad] Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):   • inputs=tf.Tensor(shape=(3, 14, 14, 576), dtype=float32) )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.compat.v1.keras.layers.ZeroPadding2D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 750549093948 with 250183031316, result: 1 	 [[{{node Pad}}]] [Op:Pad] Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):   • inputs=tf.Tensor(shape=(3, 14, 14, 576), dtype=float32) ",2023-08-18T00:29:46Z,stat:awaiting response type:bug comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61625,"Hi  ,   The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference."," , Please refer to the responses of Developer team related to the exception raised response1 and response2 stating it as intended behaviour.  The **OP_REQUIRES_OK** tries to allocate the memory for the inputs and outputs before  performing computations and it fails. The same error returned to python and its adding more details to error log. As requested please read SECURITY.md to disclose these types of issues ","Not an issue, it's a normal error returned to the user.",Are you satisfied with the resolution of your issue? Yes No
920,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.raw_ops.ResizeNearestNeighbor)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__ResizeNearestNeighbor_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 18630618048 with 1610637938, result: 1 [Op:ResizeNearestNeighbor] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.raw_ops.ResizeNearestNeighbor," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__ResizeNearestNeighbor_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 18630618048 with 1610637938, result: 1 [Op:ResizeNearestNeighbor] ",2023-08-18T00:04:42Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61624,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
902,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.raw_ops.Tile)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 500366062604 with 125091515651, result: 1 	 [[{{node Tile}}]] [Op:Tile] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.raw_ops.Tile," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input list  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 500366062604 with 125091515651, result: 1 	 [[{{node Tile}}]] [Op:Tile] ",2023-08-17T23:59:05Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61623,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1054,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.keras.layers.ZeroPadding2D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell ['{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 2501999793529 with 2501999793530, result: 1\n', '\t [[{{node Pad}}]] [Op:Pad]\n', '\n', ""Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):\n"", ' • inputs=tf.Tensor(shape=(1, 1, 2, 2), dtype=float32)\n'] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.keras.layers.ZeroPadding2D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell ['{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 2501999793529 with 2501999793530, result: 1\n', '\t [[{{node Pad}}]] [Op:Pad]\n', '\n', ""Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):\n"", ' • inputs=tf.Tensor(shape=(1, 1, 2, 2), dtype=float32)\n'] ",2023-08-17T23:57:05Z,type:bug comp:keras TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61622,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1110,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.keras.layers.ZeroPadding3D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large integer value  Standalone code to reproduce the issue  shell Error:Exception encountered when calling layer 'zero_padding3d' (type ZeroPadding3D). {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 3221225473 with 3221225474, result: 8070450522584252414 [Op:Pad] Call arguments received by layer 'zero_padding3d' (type ZeroPadding3D):   • inputs=tf.Tensor(shape=(1, 1, 2, 2, 3), dtype=float32) )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.keras.layers.ZeroPadding3D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large integer value  Standalone code to reproduce the issue  shell Error:Exception encountered when calling layer 'zero_padding3d' (type ZeroPadding3D). {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 3221225473 with 3221225474, result: 8070450522584252414 [Op:Pad] Call arguments received by layer 'zero_padding3d' (type ZeroPadding3D):   • inputs=tf.Tensor(shape=(1, 1, 2, 2, 3), dtype=float32) ",2023-08-17T23:52:52Z,stat:awaiting response type:bug comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61621,"Hi  ,   The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference."," , Please refer to the responses of Developer team related to the exception raised https://github.com/tensorflow/tensorflow/issues/61630issuecomment1685333019 and https://github.com/tensorflow/tensorflow/issues/61629issuecomment1686504422 stating it as intended behaviour. The Op tries to allocate the memory for the inputs and outputs before performing computations and it fails. The same error returned to python and its adding more details to error log. As requested please read SECURITY.md to disclose these types of issues. Thanks!","Not an issue, it is a normal error being returned to the user.",Are you satisfied with the resolution of your issue? Yes No
901,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.linalg.diag on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large integer list element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 16315257232 with 2039407154, result: 1 [Op:MatrixDiagV3] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.linalg.diag on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large integer list element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 16315257232 with 2039407154, result: 1 [Op:MatrixDiagV3] ",2023-08-17T23:51:04Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61620,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1914,"以下是一个github上的tensorflow下的一个issue, 标题是(Colab session crashes for unknown reasons when when running tf.raw_ops.ResizeBilinear on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T21:55:14.593Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T21:55:14.598Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.594 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T21:55:14.600Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.601 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T21:55:14.604Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.604 NotebookApp] Looking for jupyter_notebook_config in /)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Colab session crashes for unknown reasons when when running tf.raw_ops.ResizeBilinear on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T21:55:14.593Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T21:55:14.598Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.594 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T21:55:14.600Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.601 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T21:55:14.604Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.604 NotebookApp] Looking for jupyter_notebook_config in /",2023-08-17T23:32:12Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61618,"Hi  , I think it should be OOM problem as colab crashes with` Allocation of 2149856268 exceeds 10% of free system memory.` Also Please refer to Dev team comment on one of your earlier tickets CC(Process get killed tensorflow.python.ops.signal.window_ops.hann_window) on similar reported behaviour. Refer attached snapshot also. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1871,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.clip_by_value on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large tensor   Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T21:55:14.593Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T21:55:14.598Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.594 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T21:55:14.600Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.601 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T21:55:14.604Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.604 NotebookApp] Looking for jupyter_notebook_config in /etc/j)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.clip_by_value on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large tensor   Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T21:55:14.593Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.592 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T21:55:14.598Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.594 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T21:55:14.600Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.601 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T21:55:14.603Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.602 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T21:55:14.604Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 21:55:14.604 NotebookApp] Looking for jupyter_notebook_config in /etc/j",2023-08-17T23:23:57Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61617,", I tried to execute the mentioned code in an alternative approach with the different input where it was executed without any issues. The input which was provided was out of scope which was executed with the OOM error. Kindly find the gist of it here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
896,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.raw_ops.Pad)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to the large list of elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 250183031318 with 125091515667, result: 1 	 [[{{node Pad}}]] [Op:Pad] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.raw_ops.Pad," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to the large list of elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 250183031318 with 125091515667, result: 1 	 [[{{node Pad}}]] [Op:Pad] ",2023-08-17T22:06:34Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61615,Are you satisfied with the resolution of your issue? Yes No,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues."
900,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow when running tf.raw_ops.PadV2)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to the large list of element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__PadV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 250183031318 with 250183031306, result: 1 	 [[{{node PadV2}}]] [Op:PadV2] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow when running tf.raw_ops.PadV2," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to the large list of element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__PadV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 250183031318 with 250183031306, result: 1 	 [[{{node PadV2}}]] [Op:PadV2] ",2023-08-17T22:03:19Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61614,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
887,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.tile)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 56541365074252 with 125091515651, result: 1 	 [[{{node Tile}}]] [Op:Tile] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.tile," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 56541365074252 with 125091515651, result: 1 	 [[{{node Tile}}]] [Op:Tile] ",2023-08-17T22:01:13Z,type:bug comp:ops TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61613,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
911,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow when running tf.image.pad_to_bounding_box on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 6704962097169957420 with 3, result: 1 	 [[{{node Pad}}]] [Op:Pad] name:  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow when running tf.image.pad_to_bounding_box on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list element  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 6704962097169957420 with 3, result: 1 	 [[{{node Pad}}]] [Op:Pad] name:  ",2023-08-17T21:58:34Z,stat:awaiting response type:bug comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61612,"Hi  ,   The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference."," , Please refer to the responses of Developer team related to the exception raised https://github.com/tensorflow/tensorflow/issues/61630issuecomment1685333019 and https://github.com/tensorflow/tensorflow/issues/61629issuecomment1686504422 stating it as intended behaviour. The Op tries to allocate the memory for the inputs and outputs before performing computations and it fails. The same error returned to python and its adding more details to error log. As requested please read SECURITY.md to disclose these types of issues. Thanks!","Not an issue, it is a normal error being returned to the user.",Are you satisfied with the resolution of your issue? Yes No
883,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.raw_ops.Tile on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 500366062604 with 125091515651, result: 1 [Op:Tile] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.raw_ops.Tile on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Tile_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 500366062604 with 125091515651, result: 1 [Op:Tile] ",2023-08-17T21:56:54Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61611,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1118,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow when running tf.keras.layers.ZeroPadding2D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list elements  Standalone code to reproduce the issue  shell Error:Exception encountered when calling layer 'zero_padding2d' (type ZeroPadding2D). {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 375274547853 with 250183031602, result: 1 	 [[{{node Pad}}]] [Op:Pad] Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):   • inputs=tf.Tensor(shape=(3, 300, 300, 192), dtype=float32) {} )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow when running tf.keras.layers.ZeroPadding2D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large list elements  Standalone code to reproduce the issue  shell Error:Exception encountered when calling layer 'zero_padding2d' (type ZeroPadding2D). {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 375274547853 with 250183031602, result: 1 	 [[{{node Pad}}]] [Op:Pad] Call arguments received by layer 'zero_padding2d' (type ZeroPadding2D):   • inputs=tf.Tensor(shape=(3, 300, 300, 192), dtype=float32) {} ",2023-08-17T21:53:16Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61610,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1118,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.keras.layers.ZeroPadding3D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to the large integer value  Standalone code to reproduce the issue  shell Error:Exception encountered when calling layer 'zero_padding3d' (type ZeroPadding3D). {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 3221225473 with 3221225474, result: 8070450522584252414 [Op:Pad] Call arguments received by layer 'zero_padding3d' (type ZeroPadding3D):   • inputs=tf.Tensor(shape=(1, 1, 2, 2, 3), dtype=float32) {} )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.keras.layers.ZeroPadding3D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to the large integer value  Standalone code to reproduce the issue  shell Error:Exception encountered when calling layer 'zero_padding3d' (type ZeroPadding3D). {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 3221225473 with 3221225474, result: 8070450522584252414 [Op:Pad] Call arguments received by layer 'zero_padding3d' (type ZeroPadding3D):   • inputs=tf.Tensor(shape=(1, 1, 2, 2, 3), dtype=float32) {} ",2023-08-17T21:51:46Z,type:bug comp:keras TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61609,"Not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide, please don't spam with low quality issues.",Are you satisfied with the resolution of your issue? Yes No
1068,"以下是一个github上的tensorflow下的一个issue, 标题是(Overflow bug when running tf.pad on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large input tensor  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 2206572623628733836 with 75929941, result: 1 [Op:Pad] name:  Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 2206572623628733836 with 75929941, result: 1 [Op:Pad] name )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Overflow bug when running tf.pad on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large input tensor  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 2206572623628733836 with 75929941, result: 1 [Op:Pad] name:  Error:{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 2206572623628733836 with 75929941, result: 1 [Op:Pad] name ",2023-08-17T18:47:06Z,stat:awaiting response type:bug comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61608,"Hi  ,   The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference."," , Please refer to the responses of Developer team related to the exception raised https://github.com/tensorflow/tensorflow/issues/61630issuecomment1685333019 and https://github.com/tensorflow/tensorflow/issues/61629issuecomment1686504422 stating it as intended behaviour. The Op tries to allocate the memory for the inputs and outputs before performing computations and it fails. The same error returned to python and its adding more details to error log. As requested please read SECURITY.md to disclose these types of issues. Thanks!","Not an issue, it is a normal error being returned to the user.",Are you satisfied with the resolution of your issue? Yes No
961,"以下是一个github上的tensorflow下的一个issue, 标题是(Issue with nightly-gpu docker image)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0dev20230816  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When using the tensorflow/tensorflow:nightlygpu docker image I get an error saying the ""DNN library is not found"" However, when I change the base image to tensorflow/tensorflow:latestgpu my code works fine. Perhaps the nightly image broke something with the cuda / cudnn library paths?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,zndr27,Issue with nightly-gpu docker image," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.15.0dev20230816  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When using the tensorflow/tensorflow:nightlygpu docker image I get an error saying the ""DNN library is not found"" However, when I change the base image to tensorflow/tensorflow:latestgpu my code works fine. Perhaps the nightly image broke something with the cuda / cudnn library paths?  Standalone code to reproduce the issue   Relevant log output ",2023-08-17T18:37:54Z,stat:awaiting response type:bug stale comp:gpu,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61607, Could you try to use TF v2.13 instead of the nightly as it might not be stable.  Please have a look at the compatible versions as well. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1873,"以下是一个github上的tensorflow下的一个issue, 标题是(Crash when running tf.keras.layers.MaxPool2D on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T14:24:43.838Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T14:24:43.846Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T14:24:43.847Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T14:24:43.850Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.843 NotebookApp] Looking for jupyter_notebo)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Crash when running tf.keras.layers.MaxPool2D on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input list  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T14:24:43.838Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T14:24:43.846Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T14:24:43.847Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T14:24:43.850Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.843 NotebookApp] Looking for jupyter_notebo",2023-08-17T15:21:19Z,stat:awaiting response type:bug stale comp:keras TF 2.13,closed,0,15,https://github.com/tensorflow/tensorflow/issues/61605,"Hi   `MaxPool2D `takes a **tuple of integer** as input for `stride `and `pool_size`.  Change arg_0 and strids to tuples. ` arg_0_0 = 1e+38`   `arg_0_1 = 16777216`   `arg_0 = (arg_0_0, arg_0_1)`   `strides_0 = 2`   `strides_1 = 2`   `strides = (strides_0, strides_1)` Please refer to TensorFlow documentation for further exploration.","Could you be able to replicate the issue on colab using the provided code? On Sun, Aug 20, 2023 at 7:46 PM Shanjidul Islam Sadhin  wrote: > Hi   > MaxPool2D takes a *tuple of integer* as input for stride and pool_size. > Change arg_0 and strids to tuples. > arg_0_0 = 1e+38 > arg_0_1 = 16777216 > arg_0 = (arg_0_0, arg_0_1) > strides_0 = 2 > strides_1 = 2 > strides = (strides_0, strides_1) > > Please refer to TensorFlow documentation >  > for further exploration. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >","> Could you be able to replicate the issue on colab using the provided code? > […]() > On Sun, Aug 20, 2023 at 7:46 PM Shanjidul Islam Sadhin  wrote: Hi   MaxPool2D takes a *tuple of integer* as input for stride and pool_size. Change arg_0 and strids to tuples. arg_0_0 = 1e+38 arg_0_1 = 16777216 arg_0 = (arg_0_0, arg_0_1) strides_0 = 2 strides_1 = 2 strides = (strides_0, strides_1) Please refer to TensorFlow documentation  for further exploration. — Reply to this email directly, view it on GitHub , or unsubscribe  . You are receiving this because you were mentioned.Message ID: ***@***.***> Sure, _You provided a very large value `(1e+38)` for the `arg_0_0` parameter. However, such a large value might be an issues. It's important to note that the kernel size for pooling is typically much smaller than the input dimensions._ Here is the similar thing from my side. `import tensorflow as tf` `import os` `import numpy as np` `try:` `    pool_size = (2, 2)   Specify a reasonable pool size` `    strides = (2, 2)` `    padding = ""same""` `    arg_class = tf.keras.layers.MaxPool2D(pool_size, strides=strides, padding=padding)` `    arg_input_0_tensor = tf.random.uniform([3, 74, 74, 256], dtype=tf.float32)` `    arg_input_0 = tf.identity(arg_input_0_tensor)` `    arg_input = [arg_input_0,]` `    out = arg_class(*arg_input)` `except Exception as e:` `    print(""Error: "" + str(e))`","I am doing fuzz testing on tensorflow. On Mon, Aug 21, 2023 at 2:50 AM Shanjidul Islam Sadhin  wrote: > Could you be able to replicate the issue on colab using the provided code? > …  > On Sun, Aug 20, 2023 at 7:46 PM Shanjidul Islam Sadhin  wrote: Hi >   https://github.com/dmc1778 >  MaxPool2D takes a tuple of integer as input > for stride and pool_size. Change arg_0 and strids to tuples. arg_0_0 = > 1e+38 arg_0_1 = 16777216 arg_0 = (arg_0_0, arg_0_1) strides_0 = 2 strides_1 > = 2 strides = (strides_0, strides_1) Please refer to TensorFlow > documentation > https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPooling2D:~:text=Integer%2C%20tuple%20of%202%20integers >  > for further exploration. — Reply to this email directly, view it on GitHub >  >, > or unsubscribe > https://github.com/notifications/unsubscribeauth/AECFFZMDJANLUMXIIGTSQFLXWKOWLANCNFSM6AAAAAA3UH2W3E >  > . You are receiving this because you were mentioned.Message ID: @.*> > > Sure, > *You provided a very large value (1e+38) for the arg_0_0 parameter. > However, such a large value might be an issues. It's important to note that > the kernel size for pooling is typically much smaller than the input > dimensions.* > Here is the similar thing from my side. > > import tensorflow as tf > import os > import numpy as np > > try: > pool_size = (2, 2)  Specify a reasonable pool size > strides = (2, 2) > padding = ""same"" > arg_class = tf.keras.layers.MaxPool2D(pool_size, strides=strides, > padding=padding) > arg_input_0_tensor = tf.random.uniform([3, 74, 74, 256], dtype=tf.float32) > arg_input_0 = tf.identity(arg_input_0_tensor) > arg_input = [arg_input_0,] > out = arg_class(*arg_input) > except Exception as e: > print(""Error: "" + str(e)) > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >","The problem is that you're fuzzing APIs which will never be called directly, so all these reports will not really manifest in issues that can result in vulnerabilities/exploits. Please _triage the fuzz results before reporting them_. Please report only the issues that have a real security concern.","> The problem is that you're fuzzing APIs which will never be called directly Ok, thanks. Currently, my fuzzer only considers one API call. In the next release, I am going to add context information. ","Even if fuzzing only one API call, triaging before sending the issues helps :)","> Even if fuzzing only one API call, triaging before sending the issues helps :) Ok sure. BTW, I reported security issues via bug hunter. They told me that the issues were not severe enough (The issues are segfaults and floating point exceptions), and I am free to publicly disclose this issue on GitHub as a public issue. Please let me know if you need me to file them. Thanks. ","Was this using the VRP list or the TF list? There is a slight difference. But even so, the issue is that you are just reporting the output of your tool **without any triage**. There is a ton of reports and even if one of them were to be really useful, the amount of work that needs to happen on this side is too much. You **need to triage the reports yourself**, you need to **expand scope, analyze impact** before sending. One strong report is 10000x better than 100 poor ones.  To give you an example, here's the story of https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa2021102.md: While writing the documentation for `decode_raw` (commit 93cf9d287184ec64947fd53a32386ef8082464f3) I discovered some cases where a combination of the arguments would segfault. I filed a bug to investigate this later and then I looked at the code, ran variant analysis (to detect other combinations of arguments that could result in similar behavior), found the real issue and then got a fix (commit 698e01511f62a3c185754db78ebce0eee1f0184d). Reporting just the segfault would have been useless. Please consult other (pre 2022) advisories from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/security/advisory to see how a good report should look like. For example, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa2020013.md which again looks at combinations of arguments to detect what can be possible, instead of reporting just a segfault."," , I am confused whether if not a security issue, whether this is considered as a bug or not ? The comment says its not qualifies as a severe security issue but also states that this can be disclosed as a bug here.  Can you confirm whether this is a bug that needs fix or can be ignored ?","It will need fixed (same as the one that got autoclosed to too eager application of `stat:awaiting response` label), but as it is it is only a correctness bug, not a security issues. Impact needs to be demonstrated to elevate this to a security issue (at which point it should be submitted via the proper channels)",", I tried to execute the mentioned above code on tfnightly(2.15.0dev20231011) and the colab was not crashed and it was executed providing the error message. Kindly find the gist of it here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
925,"以下是一个github上的tensorflow下的一个issue, 标题是(Integer overflow when running tf.compat.v1.matrix_diag on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input lists  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 12885103520 with 1610637940, result: 1 [Op:MatrixDiagV3] {} )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Integer overflow when running tf.compat.v1.matrix_diag on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in the input lists  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 12885103520 with 1610637940, result: 1 [Op:MatrixDiagV3] {} ",2023-08-17T15:19:19Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61604,"Hi  ,   The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference."," , Please refer to the responses of Developer team related to the exception raised https://github.com/tensorflow/tensorflow/issues/61630issuecomment1685333019 and https://github.com/tensorflow/tensorflow/issues/61629issuecomment1686504422 stating it as intended behaviour. The Op tries to allocate the memory for the inputs and outputs before performing computations and it fails. The same error returned to python and its adding more details to error log. As requested please read SECURITY.md to disclose these types of issues.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1883,"以下是一个github上的tensorflow下的一个issue, 标题是(Crash when running tf.compat.v1.keras.layers.MaxPool2D on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input lists  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T14:24:43.838Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T14:24:43.846Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T14:24:43.847Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T14:24:43.850Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.843 NotebookApp] Looking for jupyter_notebook_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Crash when running tf.compat.v1.keras.layers.MaxPool2D on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input lists  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T14:24:43.838Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T14:24:43.846Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T14:24:43.847Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /usr/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.local/etc/jupyter"",""time"":""20230817T14:24:43.848Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.842 NotebookApp] Looking for jupyter_config in /root/.jupyter"",""time"":""20230817T14:24:43.850Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.843 NotebookApp] Looking for jupyter_notebook_",2023-08-17T14:57:29Z,stat:awaiting tensorflower type:bug comp:ops TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61603," I was able to run the code successfully without any crash using TfF v2.13 and tfnightly, please find the gist here. Thank you!",">  I was able to run the code successfully without any crash using TfF v2.13 and tfnightly, please find the gist here. Thank you! !Screenshot from 20230818 050203", Thank you for your response! Please have a look at this snapshot image as attached below; !7ksaicbFV8Bdnhu Thank you!,>  Thank you for your response! >  > Please have a look at this snapshot image as attached below; !7ksaicbFV8Bdnhu >  > Thank you! What is your tf version?, I have checked in TF v2.13 and tfnightly as well. Thank you!,>  I have checked in TF v2.13 and tfnightly as well. Thank you!   Still getting the issue on 2.13 (both local and Colab): ,This seems more like an issue with calling a CUDA kernel.,"> This seems more like an issue with calling a CUDA kernel. Yes, I thought the issue is related to my local CUDA, but it crashes on colab as well (CUDA enabled). "," Thank you for your response here.  I was able to replicate the issue on colab, please find the gist here. Thank you!",Duplicate of CC(Check failure when running tf.compat.v1.layers.MaxPooling1D) ,Are you satisfied with the resolution of your issue? Yes No
965,"以下是一个github上的tensorflow下的一个issue, 标题是(Integer overflow when running tf.raw_ops.MatrixDiagV3 on colab)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input lists  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 9984734776 with 1248091847, result: 5984878005326580344 	 [[{{node MatrixDiagV3}}]] [Op:MatrixDiagV3] {} )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Integer overflow when running tf.raw_ops.MatrixDiagV3 on colab," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Due to large elements in input lists  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 9984734776 with 1248091847, result: 5984878005326580344 	 [[{{node MatrixDiagV3}}]] [Op:MatrixDiagV3] {} ",2023-08-17T14:55:02Z,stat:awaiting response type:bug comp:ops TF 2.13,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61602,"Hi  , It is not an issue, that's an error that is being returned to the user instead of performing bad computations. Please consult again the SECURITY.md guide. Thank you!!",Closing as not a real issue.,Are you satisfied with the resolution of your issue? Yes No
1867,"以下是一个github上的tensorflow下的一个issue, 标题是(Crash when running tf.keras.layers.MaxPooling2D)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" UBUNTU_CODENAME=jammy  Mobile device _No response_  Python version   3.10.12 (main, Jun 11 2023, 05:26:28)   Bazel version _No response_  GCC/compiler version [GCC 11.4.0]  CUDA/cuDNN version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 20052022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0  GPU model and memory T4  Current behavior? Due to the large list of elements  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T14:24:43.838Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T14:24:43.846Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T14:24:43.847Z"",""v"":0} {""pid"":7,""type"")请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Crash when running tf.keras.layers.MaxPooling2D," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" UBUNTU_CODENAME=jammy  Mobile device _No response_  Python version   3.10.12 (main, Jun 11 2023, 05:26:28)   Bazel version _No response_  GCC/compiler version [GCC 11.4.0]  CUDA/cuDNN version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 20052022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0  GPU model and memory T4  Current behavior? Due to the large list of elements  Standalone code to reproduce the issue  shell {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.837 NotebookApp] Searching ['/root/.jupyter', '/root/.local/etc/jupyter', '/usr/etc/jupyter', '/usr/local/etc/jupyter', '/etc/jupyter'] for config files"",""time"":""20230817T14:24:43.838Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.838 NotebookApp] Looking for jupyter_config in /etc/jupyter"",""time"":""20230817T14:24:43.846Z"",""v"":0} {""pid"":7,""type"":""jupyter"",""level"":40,""msg"":""[D 14:24:43.840 NotebookApp] Looking for jupyter_config in /usr/local/etc/jupyter"",""time"":""20230817T14:24:43.847Z"",""v"":0} {""pid"":7,""type""",2023-08-17T14:44:21Z,stat:awaiting response type:bug comp:ops TF 2.13,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61601,", Looks like this is the duplicate for the issue CC(Crash when running tf.keras.layers.MaxPool2D on colab). Could you please close this issue, since it is already being tracked there? Thank you!",Are you satisfied with the resolution of your issue? Yes No
1529,"以下是一个github上的tensorflow下的一个issue, 标题是(Integer overflow when running tf.linalg.diag)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" UBUNTU_CODENAME=jammy  Mobile device _No response_  Python version 3.10.12 (main, Jun 11 2023, 05:26:28)  Bazel version _No response_  GCC/compiler version [GCC 11.4.0]  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0 Cuda compiler driver Copyright (c) 20052022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0)  GPU model and memory T4  Current behavior? Due to the large list of elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 12884901888 with 1610612736, result: 1 	 [[{{node MatrixDiagV3}}]] [Op:MatrixDiagV3] )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Integer overflow when running tf.linalg.diag," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" UBUNTU_CODENAME=jammy  Mobile device _No response_  Python version 3.10.12 (main, Jun 11 2023, 05:26:28)  Bazel version _No response_  GCC/compiler version [GCC 11.4.0]  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0 Cuda compiler driver Copyright (c) 20052022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0)  GPU model and memory T4  Current behavior? Due to the large list of elements  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:GPU:0}} Encountered overflow when multiplying 12884901888 with 1610612736, result: 1 	 [[{{node MatrixDiagV3}}]] [Op:MatrixDiagV3] ",2023-08-17T14:22:48Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61600,"Hi  ,   The reported behaviour is replicated with Tf2.13v and tfnightly and attached gists 2.13v and nightly for reference."," , Please refer to the responses of Developer team related to the exception raised https://github.com/tensorflow/tensorflow/issues/61630issuecomment1685333019 and https://github.com/tensorflow/tensorflow/issues/61629issuecomment1686504422 stating it as intended behaviour. The Op tries to allocate the memory for the inputs and outputs before performing computations and it fails. The same error returned to python and its adding more details to error log. As requested please read SECURITY.md to disclose these types of issues",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1880,"以下是一个github上的tensorflow下的一个issue, 标题是(Integer overflow when running tf.experimental.numpy.identity)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" UBUNTU_CODENAME=jammy  Mobile device _No response_  Python version 3.10.12 (main, Jun 11 2023, 05:26:28)  Bazel version _No response_  GCC/compiler version [GCC 11.4.0]  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0 Cuda compiler driver Copyright (c) 20052022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0)  GPU model and memory T4  Current behavior? Due to large integer variable  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 3046875451 with 3046875451, result: 9163294059803098215 [Op:MatrixDiagV3] name: diag /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/ops.py:1035: ComplexWarning: Casting complex values to real discards the imaginary part   return int(self._numpy()) Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 3046875392 with 30)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Integer overflow when running tf.experimental.numpy.identity," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution PRETTY_NAME=""Ubuntu 22.04.2 LTS"" NAME=""Ubuntu"" VERSION_ID=""22.04"" VERSION=""22.04.2 LTS (Jammy Jellyfish)"" VERSION_CODENAME=jammy ID=ubuntu ID_LIKE=debian HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" UBUNTU_CODENAME=jammy  Mobile device _No response_  Python version 3.10.12 (main, Jun 11 2023, 05:26:28)  Bazel version _No response_  GCC/compiler version [GCC 11.4.0]  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0 Cuda compiler driver Copyright (c) 20052022 NVIDIA Corporation Built on Wed_Sep_21_10:33:58_PDT_2022 Cuda compilation tools, release 11.8, V11.8.89 Build cuda_11.8.r11.8/compiler.31833905_0)  GPU model and memory T4  Current behavior? Due to large integer variable  Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 3046875451 with 3046875451, result: 9163294059803098215 [Op:MatrixDiagV3] name: diag /usr/local/lib/python3.10/distpackages/tensorflow/python/framework/ops.py:1035: ComplexWarning: Casting complex values to real discards the imaginary part   return int(self._numpy()) Error:{{function_node __wrapped__MatrixDiagV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} Encountered overflow when multiplying 3046875392 with 30",2023-08-17T14:20:37Z,type:bug comp:ops TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61599, I wasn't able to replicate the issue here and the colab is crashing. That's an error that is being returned to the user instead of performing bad computations. Could you please report this in the proper channel as mentioned here. Thank you!,>  I wasn't able to replicate the issue here and the colab is crashing. That's an error that is being returned to the user instead of performing bad computations. Could you please report this in the proper channel as mentioned here. >  > Thank you! Ok thanks.,"Not an issue, it is a normal error being returned to the user.",Are you satisfied with the resolution of your issue? Yes No
1078,"以下是一个github上的tensorflow下的一个issue, 标题是(Build: Protobuf fails with ""File already exists in database"")， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.0  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version 11.3  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Using the TF_SYSTEMLIBS version of protobuf (i.e. a preinstalled protobuf) when building TensorFlow from source results in  I can't make much sense out of that failure and Google yielded results related to having the protobuf file in loaded in shared libraries multiple times. All I could do is indeed trace it to `from tensorflow.dtensor.proto import layout_pb2` in tensorflow/dtensor/python/layout.py  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Flamefire,"Build: Protobuf fails with ""File already exists in database""", Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.0  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version 5.1.1  GCC/compiler version 11.3  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Using the TF_SYSTEMLIBS version of protobuf (i.e. a preinstalled protobuf) when building TensorFlow from source results in  I can't make much sense out of that failure and Google yielded results related to having the protobuf file in loaded in shared libraries multiple times. All I could do is indeed trace it to `from tensorflow.dtensor.proto import layout_pb2` in tensorflow/dtensor/python/layout.py  Standalone code to reproduce the issue   Relevant log output ,2023-08-16T14:24:31Z,stat:awaiting tensorflower type:bug type:build/install TF 2.13,open,1,3,https://github.com/tensorflow/tensorflow/issues/61593,"Hi  , Could you please confirm the sequence of steps. Tf2.13v supports protobuf >=3.20 versions as per source where as it seems protobuf 3.19v has been installed."," Thanks for the hint, yes I used protobuf 3.19. However switching to protobuf 3.20.3 (build from source from the Github tag) with pythonprotobuf 3.20.3 (build from source from the PyPi archive, which seems to be the latest where a Python 3.x protobuf is available) didn't resolve the issue. I still get the same error (except of course the path mentioned contains now ""protobuf3.20.3"") Edit: Tried again with 21.9 and the 4.21.9 versions with no change. Seemingly not using the systemprotobuf works although I can't tell why as it should be using the same headers (version is the same), the generated pb. (protoc version is the same)","google , Could you please look into the issue and confirm whether it falls under your scope."
1884,"以下是一个github上的tensorflow下的一个issue, 标题是(Lowering tfl.reshape + TFL-to-TOSA/standard pattern organization)， 内容是 (This pull request includes the following features: 1. Introduction of alternative TFLtoTOSA and TFLtostandard conversion patterns, each activated based on the ability of a given TFL op to be represented in the TOSA dialect. 2. TFLtoTOSA lowering for operation `tfl.reshape`. 3. TFLtostandard lowering for operation `tfl.reshape`. 4. Handling `complex` data type in `tfl.reshape`. Here, the term *standard dialect* is used to refer to MLIR dialect `arith`, `builtin`, `func`, `index`, `linalg`, `math`, `memref`, or `tensor`.  1. Extending the current lowering scheme The conversion patterns lowering TFL ops are implemented in file `tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc`. In their current state, these patterns convert TFL ops into groups of TOSA ops on a besteffort basis. However, some TFL ops are representable in TOSA only for some combinations of their input operands. And some TFL ops are not representable in TOSA at all. To successfully lower such ops, one must rely on a richer variety of lowerlevel ops from MLIR standard dialects. This merge request intends to set a precedent in the way such TFL ops will be handled, based on the following mechanism:  Two independent conversion patterns are in charge of the TFLtoTOSA and TFLtostandard conversions (e.g., `ConvertTFLReshapeOpToTosa` and `ConvertTFLReshapeOpToStandard`). Both are implemented in `legalize_tfl.cc`, though given the current size of this file, it might be wise to split these in the near future.  The TFLtoTOSA pattern is assigned high priority with a *pattern benefit* value of 2. This pattern attempts to convert the TFL op by targeti)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,rafaelubalmw,Lowering tfl.reshape + TFL-to-TOSA/standard pattern organization,"This pull request includes the following features: 1. Introduction of alternative TFLtoTOSA and TFLtostandard conversion patterns, each activated based on the ability of a given TFL op to be represented in the TOSA dialect. 2. TFLtoTOSA lowering for operation `tfl.reshape`. 3. TFLtostandard lowering for operation `tfl.reshape`. 4. Handling `complex` data type in `tfl.reshape`. Here, the term *standard dialect* is used to refer to MLIR dialect `arith`, `builtin`, `func`, `index`, `linalg`, `math`, `memref`, or `tensor`.  1. Extending the current lowering scheme The conversion patterns lowering TFL ops are implemented in file `tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc`. In their current state, these patterns convert TFL ops into groups of TOSA ops on a besteffort basis. However, some TFL ops are representable in TOSA only for some combinations of their input operands. And some TFL ops are not representable in TOSA at all. To successfully lower such ops, one must rely on a richer variety of lowerlevel ops from MLIR standard dialects. This merge request intends to set a precedent in the way such TFL ops will be handled, based on the following mechanism:  Two independent conversion patterns are in charge of the TFLtoTOSA and TFLtostandard conversions (e.g., `ConvertTFLReshapeOpToTosa` and `ConvertTFLReshapeOpToStandard`). Both are implemented in `legalize_tfl.cc`, though given the current size of this file, it might be wise to split these in the near future.  The TFLtoTOSA pattern is assigned high priority with a *pattern benefit* value of 2. This pattern attempts to convert the TFL op by targeti",2023-08-16T13:30:12Z,size:L,closed,0,0,https://github.com/tensorflow/tensorflow/issues/61592
1859,"以下是一个github上的tensorflow下的一个issue, 标题是(Train Simple Audio Recognition - TinyML)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? **Issue Report**  Error in Training Audio Recognition Model **Description**: I am trying to train a simple audio recognition model as described in the book ""TinyML."" I am using Google Colab to train the model. However, I encountered errors during both the installation of dependencies and the training process. **Error during Install Dependencies**: When attempting to install dependencies using the command  !pip uninstall y tensorflow tensorflow_estimator tensorboard !pip install q tfestimatornightly==1.14.0.dev2019072901 tfnightlygpu==1.15.0.dev20190729  I encountered the following error: ERROR: Could not find a version that satisfies the requirement tfnightlygpu==1.15.0.dev20190729 (from versions: 2.12.0) ERROR: No matching distribution found for tfnightlygpu==1.15.0.dev20190729 Error during Training  ModuleNotFoundError: **Error to Begin Training**: Upon running the training script with TensorFlow in the ""Begin Training"" Section, I received the following error: Traceback (most recent call last):   File ""/content/tensorflow/tensorflow/examples/speech_commands/train.py"", line 81, in      import input_data   File ""/content/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 35, in      from tensorflow.contrib.framework)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,siddarthnandy,Train Simple Audio Recognition - TinyML," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? **Issue Report**  Error in Training Audio Recognition Model **Description**: I am trying to train a simple audio recognition model as described in the book ""TinyML."" I am using Google Colab to train the model. However, I encountered errors during both the installation of dependencies and the training process. **Error during Install Dependencies**: When attempting to install dependencies using the command  !pip uninstall y tensorflow tensorflow_estimator tensorboard !pip install q tfestimatornightly==1.14.0.dev2019072901 tfnightlygpu==1.15.0.dev20190729  I encountered the following error: ERROR: Could not find a version that satisfies the requirement tfnightlygpu==1.15.0.dev20190729 (from versions: 2.12.0) ERROR: No matching distribution found for tfnightlygpu==1.15.0.dev20190729 Error during Training  ModuleNotFoundError: **Error to Begin Training**: Upon running the training script with TensorFlow in the ""Begin Training"" Section, I received the following error: Traceback (most recent call last):   File ""/content/tensorflow/tensorflow/examples/speech_commands/train.py"", line 81, in      import input_data   File ""/content/tensorflow/tensorflow/examples/speech_commands/input_data.py"", line 35, in      from tensorflow.contrib.framework",2023-08-16T00:27:17Z,type:bug comp:lite TF 2.12,closed,1,15,https://github.com/tensorflow/tensorflow/issues/61590,   ,", **tensorflow.contrib** is not available in tensorflow v2.x. Removed the old `tf.contrib.layers` and replace them with TF Slim symbols. Could you please take a look at this official migration doc link which refers to the Migrate from TensorFlow 1.x to TensorFlow 2. https://www.tensorflow.org/guide/migrate Thank you!",It is not straight forward on how to do this migration. Need some help. Thanks,Has anyone else already completed the migration that I can use,Need some help. Thanks. Still not resolved,Need some help. Thanks. Still not resolved,Need some help. Thanks. Still not resolved,This issue is not resolved. Any help would be grateful.,"Hi   The tensorflow example seems to be outdated. As  suggested we might have to look for TF 2.0 alternative. However, the TinyML examples are provided in tflitemicro which is a port of TensorFlow Lite designed to run machine learning models on devices with limited memory. Please check this Simple Audio Recognition Model and let us know if it helps for your use case. https://github.com/tensorflow/tflitemicro/blob/main/tensorflow/lite/micro/examples/micro_speech/train/train_micro_speech_model.ipynb Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,will try it thanks,Hi   Did you get a chance to try the example? Feel free to close the issue if it is resolved. Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,fixed thanks.,Are you satisfied with the resolution of your issue? Yes No
767,"以下是一个github上的tensorflow下的一个issue, 标题是(pybind11_proto from python to C++)， 内容是 ( thanks for the explanation. I've been exploring how to update the `import_graph_def()` codepath to use pybind11_protobuf and I could use your help with the following:  Similar to how pybind11_protobuf allows us to pass protos directly from C++ to Python, is there a way to pass a `GraphDef` proto from python to C++ without performing serialization? This would be needed to invoke the TF_GraphImportGraphDefWithResults from pywrap session in C++. _Originally posted by  in https://github.com/tensorflow/community/issues/453issuecomment1674101660_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,BlaziusMaximus,pybind11_proto from python to C++," thanks for the explanation. I've been exploring how to update the `import_graph_def()` codepath to use pybind11_protobuf and I could use your help with the following:  Similar to how pybind11_protobuf allows us to pass protos directly from C++ to Python, is there a way to pass a `GraphDef` proto from python to C++ without performing serialization? This would be needed to invoke the TF_GraphImportGraphDefWithResults from pywrap session in C++. _Originally posted by  in https://github.com/tensorflow/community/issues/453issuecomment1674101660_",2023-08-15T18:28:52Z,type:feature comp:core TF 2.13,closed,0,1,https://github.com/tensorflow/tensorflow/issues/61587,"The pybind11_proto doc mentions going from python to c++, and provides an example. You simply specify the function's proto argument as a const proto reference in c++, then pass the proto to that function in python. Unfortunately, there are issues with this when moving from google3 to OSS, so I don't have any example of TF code utilizing this feature, but you should be able to use it in your own code without issue! If you do run into problems, one strategy for passing >2GB GraphDefs would be to Split in python, send the chunks and serialized ChunkMetadata to c++ as py::bytes, then Merge in c++. Yet another use case for our api ;)"
1872,"以下是一个github上的tensorflow下的一个issue, 标题是(Abort when running tensorflow.python.ops.nn_ops.pool)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to Large list element  Standalone code to reproduce the issue  shell 20230814 22:03:21.255791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:03:21.273228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:03:21.273370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:03:21.273661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230814 22:03:21.274910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be a)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Abort when running tensorflow.python.ops.nn_ops.pool," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to Large list element  Standalone code to reproduce the issue  shell 20230814 22:03:21.255791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:03:21.273228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:03:21.273370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:03:21.273661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230814 22:03:21.274910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be a",2023-08-15T02:03:40Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61579,", I was able to reproduce the issue on colab using TF v2.12, 2.13, tfnightly. Please find the attached gist.  Since Segmentation faults can be considered as potential security vulnerabilities please read SECURITY.md and report them through proper channel as mentioned in SECURITY.md. If you want to stick to a specific version then please follow this and create your own patch to resolve such issues. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,  I am not sure if the issue is reproducible is it Ok to close it here without confirming whether its resolved or ignored. Whether can you confirm whether this needs to be fixed or not ? Can we expect this fixed in upcoming versions?
1876,"以下是一个github上的tensorflow下的一个issue, 标题是(Abort when running tensorflow.python.ops.nn_ops.max_pool)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to an invalid list element  Standalone code to reproduce the issue  shell 20230814 22:00:35.715971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230814 22:00:36.276384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:00:36.293827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:00:36.293973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:00:36.294262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operation)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Abort when running tensorflow.python.ops.nn_ops.max_pool," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to an invalid list element  Standalone code to reproduce the issue  shell 20230814 22:00:35.715971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230814 22:00:36.276384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:00:36.293827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:00:36.293973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230814 22:00:36.294262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operation",2023-08-15T02:01:35Z,stat:awaiting tensorflower type:bug comp:ops Fixed in Nightly TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61578," , I have replicated the reported behaviour with tfnightly and attached logs below.  Please report this issue through proper channel as mentioned in SECURITY.md. Thanks!",Please always check with the latest version. Please always report security issues using the proper channels.,Are you satisfied with the resolution of your issue? Yes No,The issue resolved. Adding gist with tfnightly.
563,"以下是一个github上的tensorflow下的一个issue, 标题是(I need TensorFlow 2.2.0 but it is removed how to find it?)， 内容是 (I need to install TensorFlow 2.2.0  why? because this repo (https://github.com/GantMan/nsfw_model) is requesting it and now matter what I tried can't make it work with newer TensorFlows How can I install TensorFlow 2.2.0  on Windows 10 and Python 3.10? The error I am getting is and I am not able to fix it  predict.py )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,FurkanGozukara,I need TensorFlow 2.2.0 but it is removed how to find it?,I need to install TensorFlow 2.2.0  why? because this repo (https://github.com/GantMan/nsfw_model) is requesting it and now matter what I tried can't make it work with newer TensorFlows How can I install TensorFlow 2.2.0  on Windows 10 and Python 3.10? The error I am getting is and I am not able to fix it  predict.py ,2023-08-13T21:34:43Z,type:bug,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61548,Any help is appreciated       ,found the issue it requires python 3.8,Are you satisfied with the resolution of your issue? Yes No
1902,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation fault when running tensorflow.python.ops.gen_image_ops.resize_bicubic)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to feeding a list with very large integer values.  Standalone code to reproduce the issue  shell 20230813 02:18:02.134306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230813 02:18:03.002101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 02:18:03.022974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 02:18:03.023167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 02:18:03.023525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use t)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Segmentation fault when running tensorflow.python.ops.gen_image_ops.resize_bicubic," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to feeding a list with very large integer values.  Standalone code to reproduce the issue  shell 20230813 02:18:02.134306: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230813 02:18:03.002101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 02:18:03.022974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 02:18:03.023167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 02:18:03.023525: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use t",2023-08-13T06:20:08Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61547,"Hi  , I have replicated the issue with Tf2.13 and tfnightly as well and got `Segmentation fault (core dumped)` as reported Attached logs below for reference.  Since Segmentation faults can be considered as potential security vulnerabilities please read SECURITY.md and report them through proper channel as mentioned in SECURITY.md.  Thanks!","Hi  ,  The `images_tensor = tf.saturate_cast(tf.constant(67, shape=[0, 1, 3, 2], dtype=tf.int64,),dtype=tf.uint16)` creates 0 tensor and the values for size_0 = 536870912 and size_1 = 1250999896764 are very large. It leads to segmentation fault. It's all about putting invalid shapes and sizes. So please change batch size in input_tensor with `shape=[2, 1, 3, 2]` and reduce the size_0 and size_1 to valid value.  Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1838,"以下是一个github上的tensorflow下的一个issue, 标题是(Abort when running)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to a Negative Large Integer. The behavior is bizarre. It would be best if you ran multiple times to see the Abort.  Standalone code to reproduce the issue  shell 20230813 01:58:36.322308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230813 01:58:37.120869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 01:58:37.139665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 01:58:37.139841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 01:58:37.140154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is o)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Abort when running," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version nvidiacudnncu11==8.6.0.163, cudatoolkit=11.8.0  GPU model and memory _No response_  Current behavior? Due to a Negative Large Integer. The behavior is bizarre. It would be best if you ran multiple times to see the Abort.  Standalone code to reproduce the issue  shell 20230813 01:58:36.322308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230813 01:58:37.120869: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 01:58:37.139665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 01:58:37.139841: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230813 01:58:37.140154: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is o",2023-08-13T05:59:59Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61543,"Hi  , The issue seems resolved already from TF2.12 onwards. I have tested the code and its raising intended error without abort in Tf2.12 and tfnightly as well.Please refer attached gist. I even tried with TF2.11v even there it's raising intended error only even multiple runs in attached colab gist. Could you please verify it again. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Closing as resolved at head,Are you satisfied with the resolution of your issue? Yes No
1188,"以下是一个github上的tensorflow下的一个issue, 标题是(TypeError: Unable to serialize 64.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.11.3  Bazel version N/A  GCC/compiler version N/A  CUDA/cuDNN version Not using GPU  GPU model and memory N/A  Current behavior? I have been receiving this message when trying to save a variety of  tensorflow models since version 2.11.  I have reported it before. It appears to be produced by the lack of an ability by tensorfow to serialize the model representations it maintains in memory. TypeError: Unable to serialize 64.0 to JSON. Unrecognized type . See the debugger output below for details Can I change anything in my models to dodge this logic? Is there another model saving function I can try?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cpodczerwinski,TypeError: Unable to serialize 64.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>., Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13  Custom code No  OS platform and distribution Windows 11  Mobile device _No response_  Python version 3.11.3  Bazel version N/A  GCC/compiler version N/A  CUDA/cuDNN version Not using GPU  GPU model and memory N/A  Current behavior? I have been receiving this message when trying to save a variety of  tensorflow models since version 2.11.  I have reported it before. It appears to be produced by the lack of an ability by tensorfow to serialize the model representations it maintains in memory. TypeError: Unable to serialize 64.0 to JSON. Unrecognized type . See the debugger output below for details Can I change anything in my models to dodge this logic? Is there another model saving function I can try?  Standalone code to reproduce the issue   Relevant log output ,2023-08-11T17:32:02Z,stat:awaiting response type:bug stale subtype:cpu-intel TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61525,"Hi  , Could you please submit minimal reproducible code snippet here. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
909,"以下是一个github上的tensorflow下的一个issue, 标题是(`numpy()` making copies with model parameters)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When calling `numpy()` here no copies are made:  However in the below example the increase in memory implies a copy is being made when calling `numpy()` on a model variable, is there any reason for this?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mattbarrett98,`numpy()` making copies with model parameters," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When calling `numpy()` here no copies are made:  However in the below example the increase in memory implies a copy is being made when calling `numpy()` on a model variable, is there any reason for this?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-08-11T15:09:17Z,stat:awaiting tensorflower comp:apis type:performance TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61524, I tried to replicate the issue and faced the output as follows; Firstly when calling numpy();  Secondly when calling the numpy() on a model variable;  Please find the attached gist and confirm the results. Thank you!,"yea these are the correct results, though I think you said it the wrong way round firstly it's calling `numpy()` on a model variable which is the one we see an increase in memory for. Second is `numpy()` on a 'normal' tensor, and there is no copies made in this case","Hi Matt, I think this is working as expected. The copy comes from the call that converts the Tensor to a NP array. See this discussion from a few years ago: https://github.com/tensorflow/tensorflow/issues/33254",Are you satisfied with the resolution of your issue? Yes No
242,"以下是一个github上的tensorflow下的一个issue, 标题是(Add a clarfying note that Tensorflow was written in C++)， 内容是 ()请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,anirudhtechandscience,Add a clarfying note that Tensorflow was written in C++,,2023-08-10T14:11:37Z,size:XS,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61514,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.",Hi  Can you please review this PR ? Thank you!
789,"以下是一个github上的tensorflow下的一个issue, 标题是(On-Device training for LSTM or GRU Model )， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): web  TensorFlow installed from (source or binary): colab  TensorFlow version (or github SHA if from source):colab Hi I’m new to tensorflow and I’m trying to make LSTM or GRU model to be enable to retrain ondevice(Android) with tabular data (mostly customer interaction). I’m referencing these examples OnDevice Training 1 This is an example of a CNN, but not able to understand how can I enable ondevice training for lstm or gru model. Are there any examples for reference? Thanks)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Chris0215,On-Device training for LSTM or GRU Model ,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): web  TensorFlow installed from (source or binary): colab  TensorFlow version (or github SHA if from source):colab Hi I’m new to tensorflow and I’m trying to make LSTM or GRU model to be enable to retrain ondevice(Android) with tabular data (mostly customer interaction). I’m referencing these examples OnDevice Training 1 This is an example of a CNN, but not able to understand how can I enable ondevice training for lstm or gru model. Are there any examples for reference? Thanks",2023-08-10T07:53:12Z,stat:awaiting response type:feature stale comp:lite comp:lite-examples,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61513,"Hi   The examples covering other ondevice training use cases is on roadmap. On Android, TensorFlow Lite ondevice training can be performed using either Java or C++ APIs. The train function can be invoked using TensorFlow Lite’s runSignature method by specifying the name of the signature (‘train’) and Similarly, we can invoke inference using the model’s ‘infer’ signature. Please refer this blog on OD training for insight on implementation. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1241,"以下是一个github上的tensorflow下的一个issue, 标题是(NotImplementedError while converting a tensorflow model to coreml using coremltools)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am facing a NotImplementedError while trying to convert MoViNets model to coreml. The model is saved in SavedModel format and I am using a tensorflow version equal to **2.13.0** and a version of Core ML Tools equal to **6.3.0** and a **3.10.6** python. I don't understand the origin of **StatefulPartitionedCall** operation and its meaning, any idea what's could be going on?  Here are the steps to reproduce the error: 1. Download a savedModel from the following link. 2. Convert the model using:  where *saved_dir* is the path to the downloaded model.  Relevant log output  ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lidamsoukaina,NotImplementedError while converting a tensorflow model to coreml using coremltools," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am facing a NotImplementedError while trying to convert MoViNets model to coreml. The model is saved in SavedModel format and I am using a tensorflow version equal to **2.13.0** and a version of Core ML Tools equal to **6.3.0** and a **3.10.6** python. I don't understand the origin of **StatefulPartitionedCall** operation and its meaning, any idea what's could be going on?  Here are the steps to reproduce the error: 1. Download a savedModel from the following link. 2. Convert the model using:  where *saved_dir* is the path to the downloaded model.  Relevant log output  ```",2023-08-09T08:30:33Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61509,"Hi  , At present all the TF Ops are not implemented to workable on TFlite. Hence you are getting this error. "," , Please find the list of Ops supported with TFlite here.", I am not facing this problem while converting to tflite. In fact the conversion to tflite is well done. I have this issue with the conversion to coreml.,"Hi , this appears to be an issue with coreml? It does not appear to touch TFLite code, I think you may have better luck with their code base?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
793,"以下是一个github上的tensorflow下的一个issue, 标题是(Question about @tf.function)， 内容是 ( Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.3.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory T4  Current behavior? After adding .function, I found that each epoch only executes one batch_size, and this does not happen when .function are removed  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,mirial65,Question about @tf.function," Issue type Others  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.3.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory T4  Current behavior? After adding .function, I found that each epoch only executes one batch_size, and this does not happen when .function are removed  Standalone code to reproduce the issue   Relevant log output _No response_",2023-08-09T07:58:04Z,stat:awaiting response type:bug stale type:others TF 2.3 comp:tf.function,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61507,"Hi  , I am able to execute the code on google colab with tensorflow version 2.12. Each epocs executes multiple batch size. It is recommended to upgrade your tf version.  Please find the gist. Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1099,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow 1.15 for Raspberry pi build fail)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 1.15  Custom code No  OS platform and distribution Linux and Ubuntu 18.05  Mobile device target platform: Raspberry pi 4  Python version 3.7  Bazel version na  GCC/compiler version na  CUDA/cuDNN version na  GPU model and memory na  Current behavior? Hi I am trying to install tensorflow 1.15 on Raspberry pi and found this page: https://github.com/tensorflow/build/tree/master/raspberry_pi_builds From my understanding, I can do this at another platform (GPU server, ubuntu 18.05 installed). I followed the instruction in the page, but came across the following error message: From my guess, it looks like pip is not recognized in Docker. Could you tell me how to resolve this issue??  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,KeondoPark,Tensorflow 1.15 for Raspberry pi build fail," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 1.15  Custom code No  OS platform and distribution Linux and Ubuntu 18.05  Mobile device target platform: Raspberry pi 4  Python version 3.7  Bazel version na  GCC/compiler version na  CUDA/cuDNN version na  GPU model and memory na  Current behavior? Hi I am trying to install tensorflow 1.15 on Raspberry pi and found this page: https://github.com/tensorflow/build/tree/master/raspberry_pi_builds From my understanding, I can do this at another platform (GPU server, ubuntu 18.05 installed). I followed the instruction in the page, but came across the following error message: From my guess, it looks like pip is not recognized in Docker. Could you tell me how to resolve this issue??  Standalone code to reproduce the issue   Relevant log output ",2023-08-09T01:19:25Z,stat:awaiting response type:build/install stale comp:lite subtype: ubuntu/linux TF 1.15,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61506,What is difference between TF 2 and 1.15?, The source code I want to test is written in tensorflow 1.15. There was many syntactic change in TF2 compared to TF1.15,", TensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.13.0 and check if you are facing the same issue.  Also in the document which you were referring to where it was mentioned **r1.9, r1.10** as the example.  https://github.com/tensorflow/build/tree/master/raspberry_pi_buildsdownloadthetensorflowsourcecode `git checkout    r1.9, r1.10, etc.` Thank you!","  Hi, I would like to test another person's code written in tf1.15. I tried another version as you recommended(1.10, 1.9), but same error occurred.",", As suggested tensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.13.0 and check if you are facing the same issue. We are requesting the community to go with the 2.x rather than 1.x where most of the bugs were resolved in latest versions. https://www.tensorflow.org/guide/migrate Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
548,"以下是一个github上的tensorflow下的一个issue, 标题是(Bazel@HEAD is breaking TensorFlow)， 内容是 (https://buildkite.com/bazel/bazelatheadplusdisabled/builds/1741 CC(partial_run won't accept optimizers as fetch)b1fbbb14dc98ffa1b1b129810b3  A bisectba86a70a4cc4af121d689bb7e617) shows the breaking change is: https://github.com/bazelbuild/bazel/pull/17498  Can you give some guidance on how to adapt for this breaking change? / )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,meteorcloudy,Bazel@HEAD is breaking TensorFlow,https://buildkite.com/bazel/bazelatheadplusdisabled/builds/1741 CC(partial_run won't accept optimizers as fetch)b1fbbb14dc98ffa1b1b129810b3  A bisectba86a70a4cc4af121d689bb7e617) shows the breaking change is: https://github.com/bazelbuild/bazel/pull/17498  Can you give some guidance on how to adapt for this breaking change? / ,2023-08-07T09:06:18Z,stat:awaiting response type:build/install stale subtype:bazel,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61488,https://github.com/tensorflow/tensorflow/blob/2bade54ecda9cf8fe3c66487931ebda0babc9d10/.bazelrcL111 Maybe adding `build host_features=force_no_whole_archive` after this line is enough?,"interested to hear if that fixes ^, otherwise it's likely another `features` flag that needs a new `host_features` equivalent", Could you please keep this issue assigned to you (if you're working on it) or assign it to the person you expect to look into it? When it's unassigned the gTech team assigns it to new owners and this causes confusion and spamming.  FYI,Are you satisfied with the resolution of your issue? Yes No,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1768,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow lite cmake compilation failed to allocate memory)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version cloned the master branch  Custom code Yes  OS platform and distribution windows 11 wsl 2 with Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version _No response_  Bazel version 6.3.1  GCC/compiler version 9.4.0  CUDA/cuDNN version Cuda compilation tools, release 10.1, V10.1.243  GPU model and memory rtx 2060 6GB dedicated   Current behavior? I am using cmake 3.22.2 I cloned tensorflow into a directory tensorflow_src, then I ran ./configure and set ROCm and CUDA support to none, because I am building tflite. Then I made and moved into a build directory. I run `cmake ../tensorflow_src/tensorflow/lite` and `cmake build . j` I get quite a lot of errors, the first is ""failed to allocate memory"". But there's not enough space to paste the entire log here.  I also tried `cmake ../tensorflow_src/tensorflow/lite/examples/minimal` and `cmake build . j` and the error I get is that  I am trying to instantiate the tflite interpreter object in the easiest possible way.  Standalone code to reproduce the issue I also tried bazel build in the tensorflow_sec directory, which seems like it executed fine. then I used `g++ std=c++17 inference.cpp model./bazelbin/tensorflow/lite ltensorflowlite o inference Itensorflow_src/tensorflow/lite`  I am following exactly the instructions on tensorflolw website to set up tflite for C++, it seems like there is missing information  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Luca-Stef,tensorflow lite cmake compilation failed to allocate memory," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version cloned the master branch  Custom code Yes  OS platform and distribution windows 11 wsl 2 with Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version _No response_  Bazel version 6.3.1  GCC/compiler version 9.4.0  CUDA/cuDNN version Cuda compilation tools, release 10.1, V10.1.243  GPU model and memory rtx 2060 6GB dedicated   Current behavior? I am using cmake 3.22.2 I cloned tensorflow into a directory tensorflow_src, then I ran ./configure and set ROCm and CUDA support to none, because I am building tflite. Then I made and moved into a build directory. I run `cmake ../tensorflow_src/tensorflow/lite` and `cmake build . j` I get quite a lot of errors, the first is ""failed to allocate memory"". But there's not enough space to paste the entire log here.  I also tried `cmake ../tensorflow_src/tensorflow/lite/examples/minimal` and `cmake build . j` and the error I get is that  I am trying to instantiate the tflite interpreter object in the easiest possible way.  Standalone code to reproduce the issue I also tried bazel build in the tensorflow_sec directory, which seems like it executed fine. then I used `g++ std=c++17 inference.cpp model./bazelbin/tensorflow/lite ltensorflowlite o inference Itensorflow_src/tensorflow/lite`  I am following exactly the instructions on tensorflolw website to set up tflite for C++, it seems like there is missing information  Relevant log output _No response_",2023-08-06T18:24:47Z,stat:awaiting response type:build/install stale comp:lite wsl2,closed,0,21,https://github.com/tensorflow/tensorflow/issues/61485,I ran it again and got this `In file included from /mnt/c/Users/Lucas/Documents/WWP/ML/edge_inference/build/xnnpack/src/amalgam/gen/fma3.c:7: /usr/include/math.h:37:10: fatal error: /mnt/c/Users/Lucas/Documents/WWP/ML/edge_inference/build/xnnpack/src/bits/types.h: Cannot allocate memory    37 | include `,"Hi Stefanescu  Have you tried these steps for minimal example and hitting the errors? In the minimal_build directory, after build we need to run the executable by  `./minimal ` Thanks.","> Hi Stefanescu >  > Have you tried these steps for minimal example and hitting the errors? >  > In the minimal_build directory, after build we need to run the executable by >  > `./minimal ` >  > Thanks. Yep I followed those instructions and got ""failed to allocate memory"" when compiling. It didn't complete compilation", I was able to reproduce this issue on both master and 2.13 branches. Please find this gist. Could you please look into this issue? Thanks.,"Hi Stefanescu, thanks for reporting the issue. You don't need to run ./configure, that is mainly for building with bazel. Where did you make your build directory? it should be a sibling of your tensorflow_src directory. Can you confirm you are following the directions here? https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal Are you in the build directory when you run  ? Also please let us know the errors you are getting when you say ""I get quite a lot of errors"" (like the first page if possible) It's possible the commit you are cloning is unstable, you can also try switching to the nightly or r2.14 (or earlier) branch.","> Hi Stefanescu, thanks for reporting the issue. >  > You don't need to run ./configure, that is mainly for building with bazel. Where did you make your build directory? it should be a sibling of your tensorflow_src directory. Can you confirm you are following the directions here? https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal Are you in the build directory when you run >  >  >  > ? >  > Also please let us know the errors you are getting when you say ""I get quite a lot of errors"" (like the first page if possible) >  > It's possible the commit you are cloning is unstable, you can also try switching to the nightly or r2.14 (or earlier) branch. Build directory is a sibling of tensorflow_src/ so I go into build directory and if I do `ls ../tensorflow_src/tensorflow/lite/examples/minimal` it shows the CMakeLists.txt file and the other files in the minimal/ folder. And then I run cmake from the build directory.  This is the first page with fatal error. I am getting high memory usage by WSL, more than 11GB during this compilation.  I am using the master branch, that's the default after git cloning. I'll try the nightly branch now.","I got the same issue in the nightly branch, cannot allocate memory but it continues compilation. This is after I introduced a memory limit in my .wslconfig file to 1GB:   I tried it in my docker container  I am not sure how to access that file for instructions, is it in the docker container I think. One thing to note is that the minimal. `Interpreter>Invoke()` line and then fail with the appropriate error.","Hi Stefanescu, it looks like you cloned everything under /mnt/c which is technically in the in the Windows FS. It's possible the code can't allocate memory because it's coming from Windows in a sense, can you redo everything completely within the WSL FS? i.e. follow the directions from the home directory let's say or make a git folder that you can do everything in as long as it's not a subtree of /mnt/c. Let me know how that goes. Also, can you test with this limit removed?  >This is after I introduced a memory limit in my .wslconfig file to 1GB:","> Hi Stefanescu, it looks like you cloned everything under /mnt/c which is technically in the in the Windows FS. It's possible the code can't allocate memory because it's coming from Windows in a sense, can you redo everything completely within the WSL FS? i.e. follow the directions from the home directory let's say or make a git folder that you can do everything in as long as it's not a subtree of /mnt/c. >  > Let me know how that goes. >  > Also, can you test with this limit removed? >  > > This is after I introduced a memory limit in my .wslconfig file to 1GB: Yep I can try but I have tried it in the official tensorflow docker image and in another image that my company uses and I get the same issues. Although sometimes it's input/output error rather than failed to allocate memory. And it's always issues with many various include statements in the tensorflow source code.",I tried it in the wsl file system with the memory limit removed: ,"Hi Stefanescu, I am unable to replicate locally, my cmake version is 3.25.1 but I doubt that's the different factor. I am not using WSL, so it's likely an interaction with your OS and WSL. How much free memory do you have on your hard drive? Is your OS installed on your hard drive or do you have multiple hard drives / partitions? What does that distribution look like? Which hard drive (if multiple) does WSL use? Is there some WSL restriction imposed by your OS? Can you check what configurations your WSL is under? How much RAM do you have? Can you check Task manager while the build is running and see how much Memory WSL is using? Does it reach your RAM limit? Does it ever reach your pagefile (i.e. is the program swapping out memory from RAM to disk)? Apologies for the question storm but the more information we have the better chance I have of helping you more immediately.","> Hi Stefanescu, I am unable to replicate locally, my cmake version is 3.25.1 but I doubt that's the different factor. I am not using WSL, so it's likely an interaction with your OS and WSL. How much free memory do you have on your hard drive? Is your OS installed on your hard drive or do you have multiple hard drives / partitions? What does that distribution look like? Which hard drive (if multiple) does WSL use? Is there some WSL restriction imposed by your OS? Can you check what configurations your WSL is under? How much RAM do you have? Can you check Task manager while the build is running and see how much Memory WSL is using? Does it reach your RAM limit? Does it ever reach your pagefile (i.e. is the program swapping out memory from RAM to disk)? >  > Apologies for the question storm but the more information we have the better chance I have of helping you more immediately. Hard drive has hundreds of GB free. I have standard C and D partitions (D is a different hard drive that I bought) but OS and WSL are both on C. Not sure about WSL restrictions, I'll do some research. I am not sure how to check what configurations wsl is under, can you be more specific? I have 16GB RAM, looking at task manager, WSL will typically use as much RAM as I allow it to. I use a .wslconfig file to set this limit but other than that it is empty. WSL can easily reach the ram limit if I allow it to, I did try with the limit set to 16GB and it will exhaust all memory. Just had another go now, I set the RAM limit to 16GB and tried `cmake build . j` and looking at the performance monitor it does show ~10% of the page file being used. I will have a look for WSL restrictions and configurations and get back to you.  I am in wsl file system rather than /mnt/c and somehow it has just finished compiling. Last time I tried it failed so I am not sure what I am doing differently... I did remove the RAM limit and see that the page file was being used. It is still at more than 5% now after compilation is finished, but task manager shows 50% of RAM being used and vmmemWSL is using 1.7GB. I will try it on my company docker image and see if we can move forward with the project, thanks for assistance.","Np, Stefanescu sounds like Schrödinger's memory allocation failure :). If I had to guess it sounds like it is reaching capacity in RAM and starts to try to use the pagefile but Windows doesn't like that and limits its RAM usage sometimes in which case the allocation request gets denied. I'm guessing more RAM would help but 16GB should be enough. I'm wondering if there is a way to not restrict WSL RAM/pagefile Usage. I'm thinking reducing simultaneous programs that are using other RAM or unleashing WSL is probably your best way to consistently compile.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Any update with this issue? I'm having the same problem. I am building Tensorflow Lite with cmake following the instruction given on the minimal example. I am building in a docker container with ubuntu using WSL 2 with docker desktop. The build seems to work until 91%. Then it will start to allocate all the memory (16gb of ram + 8gb of swap) until it fails to allocate throwing an allocation error or sometimes an input/output error. I think that this error message could be helpful:  However trying to follow the same steps on a ubuntu VM using VMWare (and with less memory) seems to work.,> Any update with this issue? I'm having the same problem. >  > I am building Tensorflow Lite with cmake following the instruction given on the minimal example. I am building in a docker container with ubuntu using WSL 2 with docker desktop. The build seems to work until 91%. Then it will start to allocate all the memory (16gb of ram + 8gb of swap) until it fails to allocate throwing an allocation error or sometimes an input/output error. I think that this error message could be helpful: >  >  >  > However trying to follow the same steps on a ubuntu VM using VMWare (and with less memory) seems to work. there was some way to disable memory usage limits which allowed it to work by using more memory in the pagefile (SWAP momey) but utlimately i just found a workaround using the keras2c github repo which converts tensorflow model into a C file.,"> there was some way to disable memory usage limits which allowed it to work by using more memory in the pagefile (SWAP momey) So I just need to give WSL more memory? I thought 16+8gb would be enough. > but utlimately i just found a workaround using the keras2c github repo which converts tensorflow model into a C file. Can you give me a link or more infos? I am building a tensorflow lite C++ app with cmake, I don't know if this could be a suitable solution. Can you reopen the issue so that maybe  or  can help me finding a solution? Thanks for the reply.","> > there was some way to disable memory usage limits which allowed it to work by using more memory in the pagefile (SWAP momey) >  > So I just need to give WSL more memory? I thought 16+8gb would be enough. >  > > but utlimately i just found a workaround using the keras2c github repo which converts tensorflow model into a C file. >  > Can you give me a link or more infos? I am building a tensorflow lite C++ app with cmake, I don't know if this could be a suitable solution. >  > Can you reopen the issue so that maybe  or  can help me finding a solution? >  > Thanks for the reply. https://github.com/f0uriest/keras2c this is the github repo. I would reopen this issue but I don't know how.","Ok, thanks. Maybe it cannot be reopened. If they don't reply I'll open a new issue. Thanks for your help btw"
1121,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow 2.13.0 cannot be imported after install via poetry due to missing wheel metadata)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution macOS13.3arm64arm64bit  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? After installing tensorflow  2.13.0 with poetry it cannot be imported  Standalone code to reproduce the issue See https://github.com/pythonpoetry/poetry/issues/8271 According to , the issue happens due to missing wheel metadata. > please encourage the tensorflow folk to publish consistent metadata in all of their wheels, with platformspecific variations described by markers Tensorflow folks, please publish consistent metadata ;)   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dre-hh,Tensorflow 2.13.0 cannot be imported after install via poetry due to missing wheel metadata," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution macOS13.3arm64arm64bit  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? After installing tensorflow  2.13.0 with poetry it cannot be imported  Standalone code to reproduce the issue See https://github.com/pythonpoetry/poetry/issues/8271 According to , the issue happens due to missing wheel metadata. > please encourage the tensorflow folk to publish consistent metadata in all of their wheels, with platformspecific variations described by markers Tensorflow folks, please publish consistent metadata ;)   Relevant log output ",2023-08-04T15:23:34Z,stat:awaiting tensorflower type:bug type:build/install subtype:macOS TF 2.13,open,8,6,https://github.com/tensorflow/tensorflow/issues/61477,"Hi hh , As you can see this issue. Yes  tensorflow's metadata does not express tensorflowmacos dependency. As a workaround you can explicitly add tensorflowmacos which solves the issue   poetry add tensorflowmacos==2.13.0  Thank you!!","Thx for reply. Unfortunately this is not a good workaround. People nowadays develop on arm macs and deploy on x86. That means , one cannot produce a lockfile for the whole team to install same package versions cross platform . It is a problem which is hard to solve in python but poetry addresses quite well. There is also another problem: If you check the Metadata inside the pip site_packages. On arm linux tensorflow  also installs a different package ( tensorflow aws). This dependency is also not expressed on pypa json Metadata . I suppose poetry is only using that, and will install wrong packages on linux arm as well. Could you please publish consistent Metadata to pypa in same way it is expressed in Metadata file when the package is downloaded ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"anjanappa any update on the idea adding same dependencies to pypi metadata as in the pip package? Is this maybe tracked on another issue? Is there a reason which prevents tensorflow team from doing this? Without this metadata , the user of the package has to figure out himself which platform specific packages to install"," , Is it something to do with Tensorflow MacOS release?",", no it is the tensorflow package itself.  This metadata was not published to pypi   Please republish a new version of the package with consitent medata as pip downloads into `tensorflow2.13.0.distinfo/METADATA` file"
1463,"以下是一个github上的tensorflow下的一个issue, 标题是(Converter issue)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,DocKustom,Converter issue," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-08-04T04:59:40Z,stat:awaiting response stale TFLiteConverter,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61472, Could you please fill the template properly with relevant information. Please have a look at this link to know more about the issues related to the converter. Thank you!,I don't even know how to get to the python terminal so I can input an**y**code at all,Ok so my problem is that kera monitors you, Could you please provide more information on the issue reported as the issue seems to be related converter so please follow this link for more context to it. Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
609,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite cross compile error --> fatal error: cpuid.h: No such file or directory)， 内容是 (I am trying to cross compile TFLite cpp code for ARM64 on ubuntu machine. After all the steps of installation I copied the cpp file to tflite_build  directory, I executed the following command: !image After execution of some seconds I am getting the following error. !image It will be really helpful if someone can help me to resolve the error.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,das-ankur,TFLite cross compile error --> fatal error: cpuid.h: No such file or directory,"I am trying to cross compile TFLite cpp code for ARM64 on ubuntu machine. After all the steps of installation I copied the cpp file to tflite_build  directory, I executed the following command: !image After execution of some seconds I am getting the following error. !image It will be really helpful if someone can help me to resolve the error.",2023-08-03T09:17:19Z,stat:awaiting response type:build/install stale comp:lite,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61463,Hi ankur  Can you please provide the steps you are following inorder to reproduce the issue? Did you follow build steps for arm64 and hitting the errors? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
986,"以下是一个github上的tensorflow下的一个issue, 标题是(How to get detailed information about the issue)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.12.1  Custom code No  OS platform and distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version Cuda 11.8, Cudnn 8.9.2  GPU model and memory Nvidia A10  Current behavior? I'm getting following error while compiling the model with XLA:  This issue is documented as XLA limitation here, which seems reasonable, but the error message doesn't specify where this issue is coming from. Is there any way to get more details on which variable is creating this issue?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pranavladkat,How to get detailed information about the issue," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.12.1  Custom code No  OS platform and distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version Cuda 11.8, Cudnn 8.9.2  GPU model and memory Nvidia A10  Current behavior? I'm getting following error while compiling the model with XLA:  This issue is documented as XLA limitation here, which seems reasonable, but the error message doesn't specify where this issue is coming from. Is there any way to get more details on which variable is creating this issue?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-08-02T19:25:47Z,stat:awaiting response type:bug stale subtype: ubuntu/linux TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61458,"Hi  , As the document says, int32 types are not comprehensively supported on GPUs. As a workaround, please try int64. Alternatively, you could choose to explicitly place int32 variables on CPU, or just not specify any device at all and let TensorFlow's device placement select GPU where appropriate. Please let us know if this works. Thank you!!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1577,"以下是一个github上的tensorflow下的一个issue, 标题是(Distributed training with parameter servers example using a single binary)， 内容是 (Hello everyone! I am sorry if this is a duplicate issue but from my considerable search  I could not find a single endtoend distributed parameterserver example to run using tensorflow (using the keras api with `.fit()` method). Also, for some reason  the documentation for parameterserver strategy seems a lot more confusing and difficult to get started with, compared to multiworker strategy.  I have been running training jobs using the estimator api before and now trying to update it to TF2.x style distributed training job with parameterserver training strategy using a single binary file for all workers and parameterservers. I started with the example in documentation here (https://www.tensorflow.org/tutorials/distribute/parameter_server_training) and modified the code to be used as a single binary.  Code:  To my understanding, all workers and paramterservers will start and wait for chief to assign the tasks. Chief or coordinator (documentation uses them interchangeably but is there any difference between the two?) will automatically divide the work based on the information it gets from `cluster_resolver` (let me know if that's wrong interpretation). In any case, I would highly appreciate if someone can point out what I am doing wrong in this example because I have not been able to get it to work!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ali-raza-tariq,Distributed training with parameter servers example using a single binary,"Hello everyone! I am sorry if this is a duplicate issue but from my considerable search  I could not find a single endtoend distributed parameterserver example to run using tensorflow (using the keras api with `.fit()` method). Also, for some reason  the documentation for parameterserver strategy seems a lot more confusing and difficult to get started with, compared to multiworker strategy.  I have been running training jobs using the estimator api before and now trying to update it to TF2.x style distributed training job with parameterserver training strategy using a single binary file for all workers and parameterservers. I started with the example in documentation here (https://www.tensorflow.org/tutorials/distribute/parameter_server_training) and modified the code to be used as a single binary.  Code:  To my understanding, all workers and paramterservers will start and wait for chief to assign the tasks. Chief or coordinator (documentation uses them interchangeably but is there any difference between the two?) will automatically divide the work based on the information it gets from `cluster_resolver` (let me know if that's wrong interpretation). In any case, I would highly appreciate if someone can point out what I am doing wrong in this example because I have not been able to get it to work!",2023-08-02T19:17:30Z,stat:awaiting tensorflower type:support comp:dist-strat,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61457,"razatariq, **ClusterResolvers** are a way for TensorFlow to communicate with various cluster management systems (e.g. GCE, AWS, etc...) and gives TensorFlow necessary information to set up distributed training. By letting TensorFlow communicate with these systems, we will be able to automatically discover and resolve IP addresses for various TensorFlow workers. This will eventually allow us to automatically recover from underlying machine failures and scale TensorFlow worker clusters up and down. Could you please take a look at the official document for the information on cluster_resolver. https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/ClusterResolver https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TFConfigClusterResolver Also provide the complete error log to debug the issue. Thank you!","Hi  thank you for your response. First of all, does this mean the `Chief` no longer participates in the training? Previously, `Chief` (also referred to as `worker0`) used to be just another worker with some extra coordination responsibilities. Secondly, kindly let me know if there are any end to end examples using using `Keras` new style of code (specifically for the `parameterServerStrategy`). This code is just an example using snippets of code I took from the tensorflow documentation from the link above. Which is why I shared the code to make sure I am not doing something fundamentally wrong in the training job. To be fair I am not even sure if its an error or not but this is what I get on my Chief, kindly look below:  For some reason, the worker (separate shell) does not show any thing related to training progress. Worker log: ","> To my understanding, all workers and paramterservers will start and wait for chief to assign the tasks. Chief or coordinator (documentation uses them interchangeably but is there any difference between the two?) will automatically divide the work based on the information it gets from cluster_resolver (let me know if that's wrong interpretation). Yes this is accurate. The chief (AKA the coordinator; they are different names for the same thing) is the only task running `Model.fit`, which under the hood schedules the function executions and dispatches them to workers and parameter servers.  > First of all, does this mean the Chief no longer participates in the training? Previously, Chief (also referred to as worker0) used to be just another worker with some extra coordination responsibilities. This is also accurate. Unlike MultiWorkerMirroredStrategy, the chief task is not a worker and doesn't run any training steps itself. It's only called the ""chief"" so that the `TF_CONFIG` can work the same way. ""Coordinator"" is the most meaningful term for that task  we can look into consolidating on that term. > Secondly, kindly let me know if there are any end to end examples using using Keras new style of code (specifically for the parameterServerStrategy). This code is just an example using snippets of code I took from the tensorflow documentation from the link above.  The tutorial is the most complete example we have. I don't see anything fundamentally wrong with your code. It looks like the training completes 12/12 epochs. Those errors look like something that happens at the end of training when TF is internally calling destructors on some resources. Sorry they are spammy but I'm pretty confident they can be ignored. You could confirm by adding a final `model.evaluate` or `model.predict` calls after `model.fit` in your code. > For some reason, the worker (separate shell) does not show any thing related to training progress. Worker log: Yes, the workers and parameter servers won't have many useful logs during training. If they encounter errors those would be propagated to the coordinator which will log them.  Overall your code looks to be working appropriately and hopefully these answers clear things up. Will close this now  feel free to reopen or open a new issue if you encounter other errors. Thanks!",Are you satisfied with the resolution of your issue? Yes No,"Hi , thank you so much for the detailed response! yes it has cleared things up for me."
791,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: Input 1 of layer ""model"" is incompatible with the layer: expected shape=(None, 15), found shape=(1, 14))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.0  Custom code Yes  OS platform and distribution windows 11  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Python TF script do not run, because errors  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",chat,emailbsuv,"ValueError: Input 1 of layer ""model"" is incompatible with the layer: expected shape=(None, 15), found shape=(1, 14)"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13.0  Custom code Yes  OS platform and distribution windows 11  Mobile device _No response_  Python version 3.11.4  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Python TF script do not run, because errors  Standalone code to reproduce the issue   Relevant log output ",2023-08-02T13:51:21Z,stat:awaiting response type:bug stale comp:apis TF 2.13,closed,1,10,https://github.com/tensorflow/tensorflow/issues/61453,  Could you please have a look at this link to know more about the customizing model fit() and let me know if it helps? Thank you!,>  Could you please have a look at this link to know more about the customizing model fit() and let me know if it helps? Thank you! Could you take a look at this link to learn more about your link's help for setting up a fit() model and let me know if it helps? Thank you!," I was able to replicate this issue on colab, please find the gist here? Thank you!","I was able to solve this issue by changing  `target_sequences = np.expand_dims(output_sequences[:, 1:], 1)` to  `target_sequences = np.expand_dims(output_sequences, 1)` and  `model.fit([input_sequences, output_sequences[:, :1]], target_sequences,  epochs=50, batch_size=1)` to `model.fit([input_sequences, output_sequences], target_sequences, epochs=50, batch_size=1)` You can find the code here",Are you satisfied with the resolution of your issue? Yes No,"> I was able to solve this issue by changing `target_sequences = np.expand_dims(output_sequences[:, 1:], 1)` to `target_sequences = np.expand_dims(output_sequences, 1)` and `model.fit([input_sequences, output_sequences[:, :1]], target_sequences, epochs=50, batch_size=1)` to `model.fit([input_sequences, output_sequences], target_sequences, epochs=50, batch_size=1)` You can find the code here There are several possible reasons why a model may return incomplete responses: 1. Insufficient dataset size for training. A small data set means that the model cannot learn all linguistic patterns. More dialogue examples need to be added. 2. Too small latent space (dimension of phrase presentation vectors). Because of this, the model cannot capture all the information from the input phrase. Try increasing latent_dim. 3. Premature termination of training. We need to increase the number of epochs so that the model learns better. 4. Model architecture problem. Perhaps more complex or deep models are needed (for example, add another LSTM layer). 5. Text preprocessing errors or incorrect generation of target sequences. We need to check these parts of the code. 6. Instability in the learning process. It will help to use dropout, batch normalization and other regularization methods.","Hi  , The error is due to shape mismatch of input2(encoder output) and target_sequence wrt model architecture. Both should have same shape as per model architecture. Changing the shapes will cause the error as model architecture shape is already defined for Input layer. There are 2 possible solutions.  1.Mention the shape of Input layer as `(None,)` 2.Or Maintain the same shape as mentioned in Input layer while designing model architecture. I have attached both possible fix in the gist you may choose any one that suits your requirement. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
711,"以下是一个github上的tensorflow下的一个issue, 标题是(tf 2.13 - tflite convert error  in topk when k is np.int64 )， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac and colab   TensorFlow installation (pip package or built from source): pip   TensorFlow library (version, if pip package or github SHA, if built from source): 2.13  2. Code Colab code here  3. Bug tf 2.13 model with `tf.math.top_k` error in tflite convert  tf 2.12  **pass** `k` is numpy.int64  **fail**  `k` is numpy.int32  **pass** `k` is python int  **pass**    4. Error logs )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Chizkiyahu,tf 2.13 - tflite convert error  in topk when k is np.int64 ," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac and colab   TensorFlow installation (pip package or built from source): pip   TensorFlow library (version, if pip package or github SHA, if built from source): 2.13  2. Code Colab code here  3. Bug tf 2.13 model with `tf.math.top_k` error in tflite convert  tf 2.12  **pass** `k` is numpy.int64  **fail**  `k` is numpy.int32  **pass** `k` is python int  **pass**    4. Error logs ",2023-08-02T12:29:15Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.13,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61452,"you can try enabling TensorFlow kernels fallback using TensorFlow Select, which allows you to replace specific unsupported operations with TensorFlow kernels during the conversion.   ","Hi  , As amishha's suggested, please try enabling TensorFlow kernels fallback using TensorFlow Select. That would solve the issue. Please find the gist for your reference and let us know if it works. Thank you!!","Hi anjanappa,  Thanks for looking for this. adding the `converter.allow_custom_ops = True`  solve the problem  in my code, I solved that by converting to Python int in the tf model  I assume that because is working in tf 2.12 with np.int64 and  with the default `converter` settings is good to fix that  but this to your judgment Thank you!!","Hi anjanappa To my understanding, the lable ""TF 2.13"" is more suitable than ""TF 2.12"" so it's easy to find  Thank you!!","Hi  , The topk op currently supports only unsigned int64. It does not support signed int, replacing np.int64 with np.uint64 should solve the problem in TF 2.13. Please refer the documentation . Please refer to the gist provided here. Thank you!!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
336,"以下是一个github上的tensorflow下的一个issue, 标题是([Linaro:ARM_CI] Put bazel output onto host storage)， 内容是 (Do not use container writable layer for bazel output but instead use storage mounted from the host.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,[Linaro:ARM_CI] Put bazel output onto host storage,Do not use container writable layer for bazel output but instead use storage mounted from the host.,2023-08-02T12:06:16Z,size:XS,closed,0,2,https://github.com/tensorflow/tensorflow/issues/61451,"Hi  This PR is in draft, any update on this? please. Thank you!",None of the changes tried in this PR made any noticeable difference so will just close this.
1914,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.compat.v1.train.MonitoredTrainingSession failed to restore checkpoint_dir variables from s3)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.7.0  Custom code Yes  OS platform and distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.7.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.2  GPU model and memory _No response_  Current behavior? [TOC] Our project uses tf.compat.v1.train.MonitoredTrainingSession to create a training session. Typically, we need to restore a pretrained model from S3.  1. Error encountered in my project Before switching to TensorFlow 1, we used TensorFlow 1.15.1 and passed the S3 path to `checkpoint_dir` like this:  `checkpoint_dir` contains everything needed to restore variables, including checkpoint, graph.pbtxt, etc. Everything works fine. After switching to TensorFlow 2.7.0, we realized that the Modular File System has been introduced into TensorFlow. So, we installed TensorFlowio version 0.23.0, which is compatible with TensorFlow 2.7.0. The code becomes:  However, it no longer works, and an error is reported:   2. Reproduce the issue using simple code To rule out the possibility that the issue is caused by the complexity of the model in my project, I reproduced it using a very simple code.  2.1 Step 1: Train the model First, I used the following code to train a very simple model and save it in a local directory:   2.2 Step 2: Upload the model to S3 Then, I used S3 tools to upload all materials in `./checkpoints` to a remote S3 path:   2.3 Step 3: Restore the model from S3 (error) Finally, I restored the model training using the following co)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,bingo163,tf.compat.v1.train.MonitoredTrainingSession failed to restore checkpoint_dir variables from s3," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf 2.7.0  Custom code Yes  OS platform and distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.7.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.2  GPU model and memory _No response_  Current behavior? [TOC] Our project uses tf.compat.v1.train.MonitoredTrainingSession to create a training session. Typically, we need to restore a pretrained model from S3.  1. Error encountered in my project Before switching to TensorFlow 1, we used TensorFlow 1.15.1 and passed the S3 path to `checkpoint_dir` like this:  `checkpoint_dir` contains everything needed to restore variables, including checkpoint, graph.pbtxt, etc. Everything works fine. After switching to TensorFlow 2.7.0, we realized that the Modular File System has been introduced into TensorFlow. So, we installed TensorFlowio version 0.23.0, which is compatible with TensorFlow 2.7.0. The code becomes:  However, it no longer works, and an error is reported:   2. Reproduce the issue using simple code To rule out the possibility that the issue is caused by the complexity of the model in my project, I reproduced it using a very simple code.  2.1 Step 1: Train the model First, I used the following code to train a very simple model and save it in a local directory:   2.2 Step 2: Upload the model to S3 Then, I used S3 tools to upload all materials in `./checkpoints` to a remote S3 path:   2.3 Step 3: Restore the model from S3 (error) Finally, I restored the model training using the following co",2023-08-02T09:01:20Z,stat:awaiting tensorflower type:bug comp:core TF 2.13,open,0,9,https://github.com/tensorflow/tensorflow/issues/61449,", **tf.compat.v1.train.MonitoredTrainingSession** API was designed for TensorFlow v1. Continue reading for details on how to migrate from this API to a native TensorFlow v2 equivalent. See the TensorFlow v1 to TensorFlow v2 migration guide for instructions on how to migrate the rest of your code. Also is there any specific reason to use the tf.compat.v1.train.MonitoredTrainingSession api and tensorflow v2.7 is pretty older version, I request to upgrade the latest stable version 2.13. Thank you!","> , **tf.compat.v1.train.MonitoredTrainingSession** API was designed for TensorFlow v1. Continue reading for details on how to migrate from this API to a native TensorFlow v2 equivalent. See the TensorFlow v1 to TensorFlow v2 migration guide for instructions on how to migrate the rest of your code. >  > Also is there any specific reason to use the tf.compat.v1.train.MonitoredTrainingSession api and tensorflow v2.7 is pretty older version, I request to upgrade the latest stable version 2.13. Thank you!   thanks for the quick reply Our project is still using the tf.compat.v1.train.MonitoredTrainingSession API and TF 2.7 version for the reason that changing the API usage or upgrading the TF version would involve revalidation in many aspects, including the convergence of the model. Therefore, we hope to find the cause of this error without changing the API usage and upgrading the TF version as much as possible. In addition, following your suggestion, I have upgraded the TF version and tensorflowio version of the test code environment to 2.13.0 and 0.33.0, respectively, but the same error still occurred.","  I also used tf.compat.v1.train.Saver API (shown as below) to restore variables from s3, but the same error was reported.  ", any suggestions?, any suggestions?,"Thanks for reporting the issue,  we will track this issue internally to find the root cause. Meanwhile, could you please check the document here for the new saving format, in case if you want to migrate your project to latest version which is highly recommended.","> Thanks for reporting the issue, we will track this issue internally to find the root cause. >  > Meanwhile, could you please check the document here for the new saving format, in case if you want to migrate your project to latest version which is highly recommended. Thanks, waiting for your reply","> Thanks for reporting the issue, we will track this issue internally to find the root cause. >  > Meanwhile, could you please check the document here for the new saving format, in case if you want to migrate your project to latest version which is highly recommended.  Any update?", Any update?
1318,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value num_blocks_2/multihead_attention/conv1d_1/kerne)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.8  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have trained the CARCA(Context and AttributeAware Sequential Recommendation via CrossAttention) on Video Games Dataset. I saved the session after 1 epoch and try to restore the session since all the Architecture was written using the concepts of the session. I saved the session using tf.train.Saver() .save() method.  then, I restored session using:  I have tried to perform prediction on new dataset using restored session sess, But I have encountered Attempting to use uninitialized value error. The full error is:   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",few shot,vrunm,tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value num_blocks_2/multihead_attention/conv1d_1/kerne," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.8  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have trained the CARCA(Context and AttributeAware Sequential Recommendation via CrossAttention) on Video Games Dataset. I saved the session after 1 epoch and try to restore the session since all the Architecture was written using the concepts of the session. I saved the session using tf.train.Saver() .save() method.  then, I restored session using:  I have tried to perform prediction on new dataset using restored session sess, But I have encountered Attempting to use uninitialized value error. The full error is:   Standalone code to reproduce the issue   Relevant log output _No response_",2023-08-02T05:17:09Z,stat:awaiting response type:bug stale comp:apis TF 2.8,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61446,"Hi  , It seems you are using older TF versions.  tf.train.Saver is deprecated and use  tf.train.Checkpoint instead. Could you please submit a minimal code snippet to reproduce the issue with latest versions with the updated APIs ? Please find the warning below from attached gist. `WARNING:tensorflow:Saver is deprecated, please switch to tf.train.Checkpoint or tf.keras.Model.save_weights for training checkpoints. When executing eagerly variables do not necessarily have unique names, and so the variable.namebased lookups Saver performs are errorprone.` Thanks !","I am using tensorflow 1.14 so, this is not the problem in my case. It is depreciated only on tensorflow 2.x, where you have tested. Do you still offer the solution to older tensorflow versions?"," , If it is of 1.x versions then currently we are not supporting. If possible please migrate to TF2.x versions and preferably latest versions. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
1208,"以下是一个github上的tensorflow下的一个issue, 标题是(Tflite use USB camera with android image classification app)， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**: 2.10    **Python version**: 3.10  Describe the problem I am new to android and building the tflite image classification app in tensorflow/examples using android studio. I want to make use of a USB camera instead of the mobile back camera to detect the images for classification. How can I achieve that? What changes do i need to make in CameraFragment.kt to make sure the app can search for a connected USB camera as well? currently the default app only searches for back camera as in this code https://github.com/tensorflow/examples/blob/0bbf4fe43fbf41b7174b9ce4a64d69bd33aadd21/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/imageclassification/fragments/CameraFragment.kt  thanks)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,suyash-narain,Tflite use USB camera with android image classification app, System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**: 2.10    **Python version**: 3.10  Describe the problem I am new to android and building the tflite image classification app in tensorflow/examples using android studio. I want to make use of a USB camera instead of the mobile back camera to detect the images for classification. How can I achieve that? What changes do i need to make in CameraFragment.kt to make sure the app can search for a connected USB camera as well? currently the default app only searches for back camera as in this code https://github.com/tensorflow/examples/blob/0bbf4fe43fbf41b7174b9ce4a64d69bd33aadd21/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/imageclassification/fragments/CameraFragment.kt  thanks,2023-08-01T20:15:26Z,stat:awaiting tensorflower type:bug type:feature comp:lite TF 2.10 Android,closed,1,11,https://github.com/tensorflow/tensorflow/issues/61445,"Hi narain, can you try reviewing this documentation to see if it helps you? https://source.android.com/docs/core/camera https://source.android.com/docs/core/camera/externalusbcameras https://developer.android.com/reference/android/hardware/camera2/packagesummary.html",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Hi   I was trying to replicate https://developer.android.com/training/camerax/configurationcameraselection and add this snippet to select cameraId using camerax api on the official tflite image classification example using kotlin. The build is successful but the app keeps on crashing.   Camerax makes use of camera2 api so i assume i can use camera2 cameramanager to select the cameraId and call that in cameraSelector build using camerafilter? what do you suggest?,"Hi narain, It's hard for me to tell exactly what you are doing, can you share your code? or just the portion which is causing the issue? Glad to hear that your build is successful. Do you have any errors or error logs you can share as well when it crashes? Generally the more information you share with me the faster/more likely I will be able to help you. Thanks for your help!","Hi , my code is sourced from https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/imageclassification/fragments/CameraFragment.kt  though I added a camerafilter to search for external camera and use it if found The code is below:  In above code, cameraid=103 is determined from my android device with a usb camera connected, using the command: 'dumpsys media.camera' I created another MyCameraFilter.kt which i use in camerafragment.kt as below:  I tried adding CameraSelector.LENS_FACING_EXTERNAL which is part of  but my android studio didn't take this annotation at all. Do you have any suggestions how to move forward? my device only supports usb camera, and since camerax contains camera2, i assume i can use camera2 api with camerax interchangeably.  How else can i use a usb camera to perform image classification? thanks","logcat error log on android studio when running the classification app: > 20230731 14:19:29.809   744967   StartingSurfaceDrawer   com.android.systemui                 D  fillViewWithIcon surfaceWindowView android.window.SplashScreenView{8f16232 V.E...... ......ID 0,00,0} > 20230731 14:19:29.826   517537   Compatibil...geReporter system_server                        D  Compat change id reported: 135634846; UID 10077; state: DISABLED > 20230731 14:19:29.829   517537   Compatibil...geReporter system_server                        D  Compat change id reported: 177438394; UID 10077; state: DISABLED > 20230731 14:19:29.829   517537   Compatibil...geReporter system_server                        D  Compat change id reported: 135772972; UID 10077; state: DISABLED > 20230731 14:19:29.830   517537   Compatibil...geReporter system_server                        D  Compat change id reported: 135754954; UID 10077; state: ENABLED > 20230731 14:19:29.831   517544   Compatibil...geReporter system_server                        D  Compat change id reported: 143937733; UID 10077; state: ENABLED > 20230731 14:19:29.850   285285   Zygote                  pid285                              D  Forked child process 2466 > 20230731 14:19:29.854   517544   ActivityManager         system_server                        I  Start proc 2466:org.tensorflow.lite.examples.imageclassification/u0a77 for pretopactivity {org.tensorflow.lite.examples.imageclassification/org.tensorflow.lite.examples.imageclassification.MainActivity} > 20230731 14:19:29.874  24662466  Zygote                  pid2466                             I  seccomp disabled by setenforce 0 > 20230731 14:19:29.887  24662466  eclassificatio          pid2466                             I  Lateenabling Xcheck:jni > 20230731 14:19:29.952   394427   adbd                    adbd                                 I  jdwp connection from 2466 > 20230731 14:19:30.084  24662466  reinitialized>         pid2466                             W  type=1400 audit(0.0:1035): avc: granted { execute } for path=""/data/data/org.tensorflow.lite.examples.imageclassification/code_cache/startup_agents/566ca8ecagent.so"" dev=""dm2"" ino=20224 scontext=u:r:untrusted_app:s0:c77,c256,c512,c768 tcontext=u:object_r:app_data_file:s0:c77,c256,c512,c768 tclass=file app=org.tensorflow.lite.examples.imageclassification > 20230731 14:19:30.113  24662466  eclassificatio          pid2466                             W  DexFile /data/data/org.tensorflow.lite.examples.imageclassification/code_cache/.studio/instruments45c255fe.jar is in boot class path but is not in a known location > 20230731 14:19:30.836  24662466  eclassificatio          pid2466                             W  Current dex file has more than one class in it. Calling RetransformClasses on this class might fail if no transformations are applied to it! > 20230731 14:19:31.168  24662466  eclassificatio          pid2466                             W  Current dex file has more than one class in it. Calling RetransformClasses on this class might fail if no transformations are applied to it! > 20230731 14:19:31.173  24662466  eclassificatio          pid2466                             W  Redefining intrinsic method java.lang.Thread java.lang.Thread.currentThread(). This may cause the unexpected use of the original definition of java.lang.Thread java.lang.Thread.currentThread()in methods that have already been compiled. > 20230731 14:19:31.173  24662466  eclassificatio          pid2466                             W  Redefining intrinsic method boolean java.lang.Thread.interrupted(). This may cause the unexpected use of the original definition of boolean java.lang.Thread.interrupted()in methods that have already been compiled. > 20230731 14:19:31.221  24662466  eclassificatio          pid2466                             W  Current dex file has more than one class in it. Calling RetransformClasses on this class might fail if no transformations are applied to it! > 20230731 14:19:31.807  24662466  eclassificatio          pid2466                             W  Current dex file has more than one class in it. Calling RetransformClasses on this class might fail if no transformations are applied to it! > 19691231 16:00:00.000     00                                                          I   PROCESS STARTED (2466) for package org.tensorflow.lite.examples.imageclassification  > 20230731 14:19:32.372  24662466  eclassificatio          pid2466                             W  Current dex file has more than one class in it. Calling RetransformClasses on this class might fail if no transformations are applied to it! > 20230731 14:19:32.389  24662466  Compatibil...geReporter org....examples.imageclassification  D  Compat change id reported: 171979766; UID 10077; state: ENABLED > 20230731 14:19:32.796  24662466  GraphicsEnvironment     org....examples.imageclassification  V  ANGLE Developer option for 'org.tensorflow.lite.examples.imageclassification' set to: 'default' > 20230731 14:19:32.797  24662466  GraphicsEnvironment     org....examples.imageclassification  V  ANGLE GameManagerService for org.tensorflow.lite.examples.imageclassification: false > 20230731 14:19:32.798  24662466  GraphicsEnvironment     org....examples.imageclassification  V  Neither updatable production driver nor prerelease driver is supported. > 20230731 14:19:32.812  24662466  NetworkSecurityConfig   org....examples.imageclassification  D  No Network Security Config specified, using platform default > 20230731 14:19:32.814  24662466  NetworkSecurityConfig   org....examples.imageclassification  D  No Network Security Config specified, using platform default > 20230731 14:19:33.691  24662466  eclassificatio          org....examples.imageclassification  W  Accessing hidden method Landroid/view/View;>computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (unsupported, reflection, allowed) > 20230731 14:19:33.695  24662466  eclassificatio          org....examples.imageclassification  W  Accessing hidden method Landroid/view/ViewGroup;>makeOptionalFitsSystemWindows()V (unsupported, reflection, allowed) > 20230731 14:19:33.701  24662477  System                  org....examples.imageclassification  W  A resource failed to call close.  > 20230731 14:19:33.827  24662466  Compatibil...geReporter org....examples.imageclassification  D  Compat change id reported: 171228096; UID 10077; state: ENABLED > 20230731 14:19:33.844   5171259  TaskPersister           system_server                        E  File error accessing recents directory (directory doesn't exist?). > 20230731 14:19:34.158  24662466  tflite                  org....examples.imageclassification  I  Initialized TensorFlow Lite runtime. > 20230731 14:19:34.488  24662466  RenderThread            org....examples.imageclassification  I  type=1400 audit(0.0:1036): avc: denied { open } for path=""/dev/__properties__/u:object_r:vendor_default_prop:s0"" dev=""tmpfs"" ino=256 scontext=u:r:untrusted_app:s0:c77,c256,c512,c768 tcontext=u:object_r:vendor_default_prop:s0 tclass=file permissive=1 app=org.tensorflow.lite.examples.imageclassification > 20230731 14:19:34.488  24662466  RenderThread            org....examples.imageclassification  I  type=1400 audit(0.0:1037): avc: denied { getattr } for path=""/dev/__properties__/u:object_r:vendor_default_prop:s0"" dev=""tmpfs"" ino=256 scontext=u:r:untrusted_app:s0:c77,c256,c512,c768 tcontext=u:object_r:vendor_default_prop:s0 tclass=file permissive=1 app=org.tensorflow.lite.examples.imageclassification > 20230731 14:19:34.488  24662466  RenderThread            org....examples.imageclassification  I  type=1400 audit(0.0:1038): avc: denied { map } for path=""/dev/__properties__/u:object_r:vendor_default_prop:s0"" dev=""tmpfs"" ino=256 scontext=u:r:untrusted_app:s0:c77,c256,c512,c768 tcontext=u:object_r:vendor_default_prop:s0 tclass=file permissive=1 app=org.tensorflow.lite.examples.imageclassification > 20230731 14:19:34.516   199199   hwservicemanager        hwservicemanager                     I  getTransport: Cannot find entry android.hardware.configstore.0::ISurfaceFlingerConfigs/default in either framework or device VINTF manifest. > 20230731 14:19:34.718  24662483  cutilstrace            org....examples.imageclassification  E  Error opening trace file: Permission denied (13) > 20230731 14:19:34.776   744965   StartingSurfaceDrawer   com.android.systemui                 D  Task start finish, remove starting surface for task 92 > 20230731 14:19:34.776   744965   StartingSurfaceDrawer   com.android.systemui                 V  Removing splash screen window for task: 92 > 20230731 14:19:34.781   517534   ActivityTaskManager     system_server                        I  Displayed org.tensorflow.lite.examples.imageclassification/.MainActivity: +5s8ms > 20230731 14:19:34.902  24662498  CameraManagerGlobal     org....examples.imageclassification  I  Connecting to camera service > 20230731 14:19:34.915   895993   ServiceManager          cameraserver                         W  Permission failure: android.permission.CAMERA_OPEN_CLOSE_LISTENER from uid=10077 pid=2466 > 20230731 14:19:34.975  24662498  CameraRepository        org....examples.imageclassification  D  Added camera: 103 > 20230731 14:19:35.072   517899   InputManagerJNI        system_server                        W  Input channel object '2117409 Splash Screen org.tensorflow.lite.examples.imageclassification (client)' was disposed without first being removed with the input manager! > 20230731 14:19:35.266  24662498  Camera2CameraInfo       org....examples.imageclassification  I  Device Level: INFO_SUPPORTED_HARDWARE_LEVEL_EXTERNAL > 20230731 14:19:35.281  24662498  CameraValidator         org....examples.imageclassification  D  Verifying camera lens facing on device, lensFacingInteger: null > 20230731 14:19:35.365  24662466  CameraIdCameraFilter    org....examples.imageclassification  D  id: 103 > 20230731 14:19:35.479  24662466  DeferrableSurface       org....examples.imageclassification  D  Surface createdtotal_surfaces=1, used_surfaces=0, rotationDegrees=0, targetRotation=0} > 20230731 14:19:35.533  24662466  AndroidRuntime          org....examples.imageclassification  D  Shutting down VM >  beginning of crash > 20230731 14:19:35.535  24662498  UseCaseAttachState      org....examples.imageclassification  D  All use case: [androidx.camera.core.ImageAnalysis8231df21375a4253a87a2ae8de627879255109251, androidx.camera.core.Previewe28319fad4814935af63c99e3540a85160384050] for camera: 103 > 20230731 14:19:35.536  24662466  AndroidRuntime          org....examples.imageclassification  E  FATAL EXCEPTION: main >                                                                                                     Process: org.tensorflow.lite.examples.imageclassification, PID: 2466 >                                                                                                     java.lang.NullPointerException: Attempt to invoke virtual method 'int java.lang.Integer.intValue()' on a null object reference >                                                                                                     	at androidx.camera.view.PreviewView$1.lambda$onSurfaceRequested$1$androidxcameraviewPreviewView$1(PreviewView.java:203) >                                                                                                     	at androidx.camera.view.PreviewView$1$$ExternalSyntheticLambda0.onTransformationInfoUpdate(Unknown Source:6) >                                                                                                     	at androidx.camera.core.SurfaceRequest.lambda$setTransformationInfoListener$7(SurfaceRequest.java:456) >                                                                                                     	at androidx.camera.core.SurfaceRequest$$ExternalSyntheticLambda3.run(Unknown Source:4) >                                                                                                     	at android.os.Handler.handleCallback(Handler.java:938) >                                                                                                     	at android.os.Handler.dispatchMessage(Handler.java:99) >                                                                                                     	at android.os.Looper.loopOnce(Looper.java:201) >                                                                                                     	at android.os.Looper.loop(Looper.java:288) >                                                                                                     	at android.app.ActivityThread.main(ActivityThread.java:7839) >                                                                                                     	at java.lang.reflect.Method.invoke(Native Method) >                                                                                                     	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:548) >                                                                                                     	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1003) > 20230731 14:19:35.539  24662498  UseCaseAttachState      org....examples.imageclassification  D  Active and attached use case: [androidx.camera.core.ImageAnalysis8231df21375a4253a87a2ae8de627879255109251] for camera: 103 > 20230731 14:19:35.542   517899   ActivityTaskManager     system_server                        W    Force finishing activity org.tensorflow.lite.examples.imageclassification/.MainActivity > 20230731 14:19:35.548   5172502  DropBoxManagerService   system_server                        I  add tag=data_app_crash isTagEnabled=true flags=0x2 > 20230731 14:19:35.555  24662498  Camera2CameraImpl       org....examples.imageclassification  D  {Camera[id=103]} Resetting Capture Session > 20230731 14:19:35.558  24662498  Camera2CameraImpl       org....examples.imageclassification  D  {Camera[id=103]} Releasing session in state INITIALIZED > 20230731 14:19:35.562  24662498  Camera2CameraImpl       org....examples.imageclassification  D  {Camera[id=103]} Attempting to force open the camera. > 20230731 14:19:35.564  24662498  CameraStateRegistry     org....examples.imageclassification  D  tryOpenCamera(Camera[id=103]) [Available Cameras: 1, Already Open: false (Previous state: null)] > SUCCESS > 20230731 14:19:35.570  24662466  Process                 org....examples.imageclassification  I  Sending signal. PID: 2466 SIG: 9 >  PROCESS ENDED (2466) for package org.tensorflow.lite.examples.imageclassification  > 20230731 14:19:35.666   517899   ActivityManager         system_server                        I  Process org.tensorflow.lite.examples.imageclassification (pid 2466) has died: fg  TOP  > 20230731 14:19:35.668   517545   libprocessgroup         system_server                        I  Successfully killed process cgroup uid 10077 pid 2466 in 0ms > 20230731 14:19:35.670   285285   Zygote                  pid285                              I  Process 2466 exited due to signal 9 (Killed) > 20230731 14:19:35.670   517921   WindowManager           system_server                        I  WIN DEATH: Window{d0379fb u0 org.tensorflow.lite.examples.imageclassification/org.tensorflow.lite.examples.imageclassification.MainActivity} > 20230731 14:19:35.671   517921   InputManagerJNI        system_server                        W  Input channel object 'd0379fb org.tensorflow.lite.examples.imageclassification/org.tensorflow.lite.examples.imageclassification.MainActivity (client)' was disposed without first being removed with the input manager! > 20230731 14:19:35.687   343343   BpTransact...edListener surfaceflinger                       E  Failed to transact (32) > 20230731 14:19:35.700   517899   ActivityTaskManager     system_server                        W  Can't find TaskDisplayArea to determine support for multi window. Task id=92 attached=false > 20230731 14:19:35.701   517899   ActivityTaskManager     system_server                        W  Can't find TaskDisplayArea to determine support for multi window. Task id=92 attached=false > 20230731 14:19:35.730   517537   ActivityManager         system_server                        W  setHasOverlayUi called on unknown pid: 2466 > 20230731 14:19:35.798  11091153  OpenGLRenderer          com.android.launcher3                I  Davey! duration=99848ms; Flags=1, FrameTimelineVsyncId=7224, IntendedVsync=236882707405, Vsync=236882707405, InputEventId=0, HandleInputStart=236883940860, AnimationStart=236883945013, PerformTraversalsStart=236883948167, DrawStart=236907705936, FrameDeadline=236916091065, FrameInterval=236883932629, FrameStartTime=16691830, SyncQueued=236914034936, SyncStart=236914191167, IssueDrawCommandsStart=236914506936, SwapBuffers=236919260321, FrameCompleted=336731089942, DequeueBufferDuration=178385, QueueBufferDuration=1787154, GpuCompleted=336731089942, SwapBuffersCompleted=236929178167, DisplayPresentTime=168144668009,  > 20230731 14:19:35.803   517527   system_server           system_server                        I  NativeAlloc concurrent copying GC freed 76952(4326KB) AllocSpace objects, 17(452KB) LOS objects, 37% free, 10191KB/15MB, paused 2.919ms,344us total 204.204ms > 20230731 14:19:35.848  11091153  OpenGLRenderer          com.android.launcher3                I  Davey! duration=99807ms; Flags=0, FrameTimelineVsyncId=7237, IntendedVsync=236966153846, Vsync=236966153846, InputEventId=0, HandleInputStart=236967284475, AnimationStart=236967287013, PerformTraversalsStart=236967289936, DrawStart=236967508013, FrameDeadline=236999537506, FrameInterval=236967278936, FrameStartTime=16691830, SyncQueued=236967943783, SyncStart=236968116167, IssueDrawCommandsStart=236968318706, SwapBuffers=236975167321, FrameCompleted=336774274327, DequeueBufferDuration=35230, QueueBufferDuration=1930308, GpuCompleted=336774274327, SwapBuffersCompleted=236977859629, DisplayPresentTime=168161398317,  > 20230731 14:19:36.048   517537   ActivityTaskManager     system_server                        W  Activity top resumed state loss timeout for ActivityRecord{55231d3 u0 org.tensorflow.lite.examples.imageclassification/.MainActivity t1 f}} > 20230731 14:19:36.945   284322   netd                    netd                                 I  setProcSysNet(4, 2, wlan0, retrans_time_ms, 750)  > 20230731 14:19:36.946   284322   netd                    netd                                 I  setProcSysNet(4, 2, wlan0, ucast_solicit, 10)  > 20230731 14:19:36.948   284322   netd                    netd                                 I  setProcSysNet(6, 2, wlan0, retrans_time_ms, 750)  > 20230731 14:19:36.950   284322   netd                    netd                                 I  setProcSysNet(6, 2, wlan0, ucast_solicit, 10)  > 20230731 14:19:38.698   5171259  TaskPersister           system_server                        E  File error accessing recents directory (directory doesn't exist?).","Hi, narain, those are the two ways that makes sense, LENS_FACING_EXTERNAL is experimental so sometimes it doesn't always work. You did say you try it, was there a building error? That information can be helpful. Hi, , can you please take a look? Thanks. ","Hi    android studio doesn't take LENS_FACING_EXTERNAL and its corresponding annotation. It shows it as an error (marking with red font and a red underline) before the build. So couldn't build with it.  using    val cameraSelector = CameraSelector.Builder().addCameraFilter(MyCameraFilter(""$mCameraId"")).build() doesn't lead to any build error, but the app crashes at runtime, and camera is not detected as could be seen from the above posted error log","Hi, is there any update? I am also want to use the USB camera too. In the CameraFragment,  But I cannot select USB camera. I search in internet and I found some third party library but there is no update for years... I want to use USB camera for object detection, is tensorflow be the right choice, or shall I move to yolo? Thx","Hi, narain  Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/160 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1073,"以下是一个github上的tensorflow下的一个issue, 标题是(When building from source code, I always end up with a Python 3.10 whl file, instead of a Python3.8 whl file.)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code No  OS platform and distribution Linux Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version 3.8  Bazel version 1.17  GCC/compiler version 9.4.0  CUDA/cuDNN version 11.8/8.7  GPU model and memory GTX 1050 Ti 4GB  Current behavior? When I try to build the source code from my machine I end up always with a wheel for Python 3.10, although I specified the python path for python3.8 and I don't even have python3.10 installed. The generated wheel is called tensorflow2.14.0cp310cp310linux_x86_64.whl Can you guide why this is happening and how to solve it?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,moooises,"When building from source code, I always end up with a Python 3.10 whl file, instead of a Python3.8 whl file."," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.14.0  Custom code No  OS platform and distribution Linux Ubuntu 20.04.6 LTS  Mobile device _No response_  Python version 3.8  Bazel version 1.17  GCC/compiler version 9.4.0  CUDA/cuDNN version 11.8/8.7  GPU model and memory GTX 1050 Ti 4GB  Current behavior? When I try to build the source code from my machine I end up always with a wheel for Python 3.10, although I specified the python path for python3.8 and I don't even have python3.10 installed. The generated wheel is called tensorflow2.14.0cp310cp310linux_x86_64.whl Can you guide why this is happening and how to solve it?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-31T17:26:18Z,stat:awaiting response type:build/install type:support subtype: ubuntu/linux,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61436,"Hi  , Could you please confirm the python path selected in `./configure` step ?  Thanks!","Hi, instead of having  /Library/Frameworks/Python.framework/Versions/3.9/bin/python3 as the default path, I have /usr/bin/python3. I tried with both /usr/bin/python3.8 and /usr/bin/python3, which in my system redirects to /usr/bin/python3.8, and with both paths I end up with a cp310 whl file . Aside from Python2.7, which path is  /usr/bin/python, I only have Python3.8 installed.","This is likely due to hermetic python picking out the default when it builds.  See: https://github.com/tensorflow/tensorflow/tree/master/ci/official/requirements_updaterhermeticpythontoolchaindetails Specifically for python 3.8, we have dropped support at HEAD to keep in following with numpy's python support. ",You should not need to run configure anymore. Just need to build a virtual env with the desired version of Python and/or use hermetic python build flags.," , The comment1662775801 makes sense to me on why it is ended up with python 3.10 whl file. Also as the comment suggests python 3.8 versions may not be recommended for nightly builds.  Could you please go through the comments above and do the necessary changes for build and let us know if still facing any issue. Thanks! ",You can follow this link to update python version. I can see `Python3.9` is minimum python version recommended for nightly where `Python3.10` is default. Not sure though `Python3.8` have any compatibility issues due to numpy dependencies. So please make a note of it and build accordingly.,"I tried creating a virtual environment for python 3.10, as  suggested, using anaconda and I could install the generated whl file. However I get some warning telling ""Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered"" and the same warning for cuFFT and cuBLAS. Aside from than, the installation seems to work. It recognize my GPU. Will those warning cause me any problem in the future?","Hi  , AFAIK , If GPU able to recognise these warnings can be ignored. These warnings seems to be due to duplicate registrations as discussed in CC(TF build fails with the new cublas_lt commit)","Just FYI, starting from Tf2.13v onwards TF uses Clang as compiler. ","Ok, thanks for the responses. I installed it again using conda and following the steps of the official guide https://www.tensorflow.org/install/pip and everything seems to work fine now. I don't have those duplication warnings anymore.",Are you satisfied with the resolution of your issue? Yes No
739,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix gemm_algorithm_picker bug for cublasLt.)， 内容是 (In cublas_lt_matmul.cc，we will get all valid algorithms from cublasLtMatmulAlgoGetHeuristic()，and then select the ith from  parameter ""algorithm"". However, it seems this ""algorithm"" parameter is not correctly set in gemm_algorithm_picker.  This pr fix the bug, and I run several tests on A800, it can help to improve the gemm performance.  (A800 with cuda12.2) (XLA_FLAGS='xla_gpu_enable_cublaslt', TF_CPP_VMODULE=gemm_algorithm_picker=10) (m=1024, k=4096,n=2048) Before  logs   result  After   logs   result )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gemma,qiaoxj07,Fix gemm_algorithm_picker bug for cublasLt.,"In cublas_lt_matmul.cc，we will get all valid algorithms from cublasLtMatmulAlgoGetHeuristic()，and then select the ith from  parameter ""algorithm"". However, it seems this ""algorithm"" parameter is not correctly set in gemm_algorithm_picker.  This pr fix the bug, and I run several tests on A800, it can help to improve the gemm performance.  (A800 with cuda12.2) (XLA_FLAGS='xla_gpu_enable_cublaslt', TF_CPP_VMODULE=gemm_algorithm_picker=10) (m=1024, k=4096,n=2048) Before  logs   result  After   logs   result ",2023-07-31T10:53:22Z,comp:xla size:S,closed,0,10,https://github.com/tensorflow/tensorflow/issues/61433,Hi  Can you please review this PR ? Thank you!,Makes sense ! I think we do not notice it because we do not use cublasLT by default.  could you take a look?,"Hmm, yeah. As far as I can tell, it looks like we never set the algorithm for cublasLt. However, I disagree with the way that this PR goes about setting it. The code inside of `GetBestAlgorithm` already sets the algorithm via  Instead, we should be setting the algorithm inside of the profile result similarly to how it's done for cublas. For cublas, the `blas::ProfileResult`'s algorithm is set inside of `cuda_blas.cc`. The same should be done inside `cuda_blas_lt_.cc` for cublasLt. This PR would further complicate the already complicated ""blas"" abstraction.","> Hmm, yeah. As far as I can tell, it looks like we never set the algorithm for cublasLt. However, I disagree with the way that this PR goes about setting it. >  > The code inside of `GetBestAlgorithm` already sets the algorithm via >  >  >  > Instead, we should be setting the algorithm inside of the profile result similarly to how it's done for cublas. For cublas, the `blas::ProfileResult`'s algorithm is set inside of `cuda_blas.cc`. The same should be done inside `cuda_blas_lt_.cc` for cublasLt. This PR would further complicate the already complicated ""blas"" abstraction. Thanks for the review    The algorithm in cublasLt is a little different from cublas.  In cublas, we can specify the best algorithm by set a integer value (algorithm id). However, in cublasLt, the algorithm is repsented by cublasLtMatmulAlgo_t, which is more complex[ref].(https://gitlab.com/nvidia/headers/cudaindividual/cublas//blob/main/cublasLt.hL119) In order to use the ""blas"" abstraction for gemm algorithm,  I think we can use cublasLtMatmulAlgoGetHeuristic in gemm_algorithm_picker, get the best algorithm, save it's index in blas::ProfileResult. And later in RunGemm(), we can first call cublasLtMatmulAlgoGetHeuristic(), and then use the saved index find the best algorithm. ","> In cublas, we can specify the best algorithm by set a integer value (algorithm id). However, in cublasLt, the algorithm is repsented by cublasLtMatmulAlgo_t, which is more complex[ref].(https://gitlab.com/nvidia/headers/cudaindividual/cublas//blob/main/cublasLt.hL119) >  > In order to use the ""blas"" abstraction for gemm algorithm, I think we can use cublasLtMatmulAlgoGetHeuristic in gemm_algorithm_picker, get the best algorithm, save it's index in blas::ProfileResult. And later in RunGemm(), we can first call cublasLtMatmulAlgoGetHeuristic(), and then use the saved index find the best algorithm. I suppose you could do that, just to avoid needing to make the algorithm a bit more abstract in the profile result. However, you now have an additional call to GetHeuristic. Also is that going to be called each time you call RunGemm? Also, that's trusting that the algorithms are returned in the same order every time, which could lead to a very hardtospot performance regression if that were no longer the case. To do it right, I think you ought to adapt the interface to allow for the different types used by cublas and cublasLt for their algorithms.","BTW also note that past Ampere, the select algorithm is ignored entirely in cuBLAS from what I recall. So ironically storing or not storing the algorithm on Ampere+ GPUs probably makes no difference.",Hi  Any update on this PR? Please. Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,Hi  Any update on this PR? Please. Thank you!,"Hi  I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!  Thank you for you contribution!"
739,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix gemm_algorithm_picker bug for cublasLt.)， 内容是 (In cublas_lt_matmul.cc，we will get all valid algorithms from cublasLtMatmulAlgoGetHeuristic()，and then select the ith from  parameter ""algorithm"". However, it seems this ""algorithm"" parameter is not correctly set in gemm_algorithm_picker.  This pr fix the bug, and I run several tests on A800, it can help to improve the gemm performance.  (A800 with cuda12.2) (XLA_FLAGS='xla_gpu_enable_cublaslt', TF_CPP_VMODULE=gemm_algorithm_picker=10) (m=1024, k=4096,n=2048) Before  logs   result  After   logs   result )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gemma,qiaoxj07,Fix gemm_algorithm_picker bug for cublasLt.,"In cublas_lt_matmul.cc，we will get all valid algorithms from cublasLtMatmulAlgoGetHeuristic()，and then select the ith from  parameter ""algorithm"". However, it seems this ""algorithm"" parameter is not correctly set in gemm_algorithm_picker.  This pr fix the bug, and I run several tests on A800, it can help to improve the gemm performance.  (A800 with cuda12.2) (XLA_FLAGS='xla_gpu_enable_cublaslt', TF_CPP_VMODULE=gemm_algorithm_picker=10) (m=1024, k=4096,n=2048) Before  logs   result  After   logs   result ",2023-07-31T10:34:32Z,size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/61432,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request."
711,"以下是一个github上的tensorflow下的一个issue, 标题是(Visual Studio 2022 / MingW64: cant find source files)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.7.0  Custom code Yes  OS platform and distribution Windows 11  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version 8.1.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Cant write complete application  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,emailbsuv,Visual Studio 2022 / MingW64: cant find source files, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.7.0  Custom code Yes  OS platform and distribution Windows 11  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version 8.1.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Cant write complete application  Standalone code to reproduce the issue   Relevant log output ,2023-07-31T09:26:26Z,type:bug TF 2.7,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61430,"``` include  include ""tensorflow/cc/client/client_session.h"" include ""tensorflow/cc/ops/standard_ops.h"" include ""tensorflow/core/framework/tensor.h"" using namespace tensorflow; using namespace tensorflow::ops; int main() {     // Входные данные  предыдущие 5 OHLC свечей     float input_data[5][4] = {         {100.0, 110.0, 95.0, 105.0},         {105.0, 115.0, 100.0, 110.0},         {110.0, 120.0, 105.0, 115.0},         {115.0, 125.0, 110.0, 120.0},         {120.0, 130.0, 115.0, 125.0}     };     // Будущая OHLC свеча, которую нужно предсказать     float target_data[4] = { 125.0, 135.0, 120.0, 130.0 };     // Создание графа TensorFlow     Scope root = Scope::NewRootScope();     auto input = Placeholder(root, DT_FLOAT, Placeholder::Shape({ 5, 4 }));     auto target = Placeholder(root, DT_FLOAT, Placeholder::Shape({ 4 }));     // Определение модели     auto weights = Variable(root, { 4, 8 }, DT_FLOAT);     auto biases = Variable(root, { 8 }, DT_FLOAT);     auto output = Tanh(root, Add(root, MatMul(root, input, weights), biases));     // Определение функции потерь     auto loss = ReduceMean(root, Square(root, Sub(root, output, target)), { 0 });     // Определение оптимизатора     auto learning_rate = Const(root, 0.01f, {});     auto optimizer = GradientDescentOptimizer(root, learning_rate);     auto train_op = optimizer.minimize(root, loss);     // Создание сессии     ClientSession session(root);     // Обучение модели     Tensor input_tensor(DT_FLOAT, TensorShape({ 5, 4 }));     Tensor target_tensor(DT_FLOAT, TensorShape({ 4 }));     memcpy(input_tensor.flat().data(), input_data, sizeof(input_data));     memcpy(target_tensor.flat().data(), target_data, sizeof(target_data));     for (int i = 0; i ();     std::cout >, std::vector>, tensorflow::FunctionLibraryDefinition *, const tensorflow::DeviceSet &, tensorflow::Device *, std::unique_ptr> *)>"" не содержит классчлен ""type""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1015	 Ошибка (активно)	E0135	класс ""std::_Get_function_impl>, std::vector>, tensorflow::FunctionLibraryDefinition *, const tensorflow::DeviceSet &, tensorflow::Device *, std::unique_ptr> *)>"" не содержит члена ""type""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1017	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1028	 Ошибка (активно)	E0952	нетипизированный параметр шаблона не может иметь тип класса	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1028	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1028	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1045	 Ошибка (активно)	E0952	нетипизированный параметр шаблона не может иметь тип класса	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1045	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1045	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1075	 Ошибка (активно)	E0952	нетипизированный параметр шаблона не может иметь тип класса	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1075	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\functional	1075	 Ошибка (активно)	E0020	идентификатор ""jmp_buf"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\intrin.h	929	 Ошибка (активно)	E0020	идентификатор ""jmp_buf"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\intrin.h	930	 Ошибка (активно)	E0020	идентификатор ""_Kty"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	67	 Ошибка (активно)	E0864	pair не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	67	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	70	 Ошибка (активно)	E0864	less не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	72	 Ошибка (активно)	E0864	allocator не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	72	 Ошибка (активно)	E0020	идентификатор ""pair"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	72	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	72	 Ошибка (активно)	E0706	требуется запятая "","" или угловая скобка "">""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	72	 Ошибка (активно)	E0864	less не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	454	 Ошибка (активно)	E0864	allocator не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	454	 Ошибка (активно)	E0020	идентификатор ""pair"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	454	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	454	 Ошибка (активно)	E0706	требуется запятая "","" или угловая скобка "">""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	454	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map	701	 Ошибка (активно)	E0020	идентификатор ""element_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\memory	1613	 Ошибка (активно)	E0020	идентификатор ""element_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\memory	1619	 Ошибка (активно)	E0020	идентификатор ""element_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\memory	1661	 Ошибка (активно)	E0020	идентификатор ""element_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\memory	1715	 Ошибка (активно)	E0020	идентификатор ""element_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\memory	1766	 Ошибка (активно)	E0020	идентификатор ""native_handle_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	61	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	65	 Ошибка (активно)	E0239	недопустимый спецификатор вне объявления класса	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	67	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	67	 Ошибка (активно)	E0864	_Aligned_storage_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	69	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	74	 Ошибка (активно)	E0262	не является именем класса или структуры	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	76	 Ошибка (активно)	E0147	объявление несовместимо с ""void swap"" (объявлено в строке 111 из ""C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	266	 Ошибка (активно)	E0864	index_sequence не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	271	 Ошибка (активно)	E0864	index_sequence не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	278	 Ошибка (активно)	E0864	index_sequence не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	286	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\mutex	954	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	47	 Ошибка (активно)	E2386	""constexpr"" здесь не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	83	 Ошибка (активно)	E0834	недопустимая частичная специализация  уже выполнена полная специализация переменная ""_Is_ratio_v [с _Ty=]""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	83	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	83	 Ошибка (активно)	E0864	void_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	140	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	263	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	264	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	265	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	266	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	267	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	268	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	269	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	270	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	271	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	272	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	273	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	274	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	275	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	276	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	277	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	278	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\ratio	279	 Ошибка (активно)	E0020	идентификатор ""_Tuple"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	54	 Ошибка (активно)	E0020	идентификатор ""_FnVals"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	54	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	55	 Ошибка (активно)	E0493	отсутствуют экземпляры перегруженная функция ""std::invoke"", соответствующие заданному типу	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	55	 Ошибка (активно)	E0020	идентификатор ""_Indices"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	55	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	55	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	56	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	57	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	58	 Ошибка (активно)	E0020	идентификатор ""thread"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	109	 Ошибка (активно)	E0341	функция ""operator="" должна быть функциейчленом	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	109	 Ошибка (активно)	E0020	идентификатор ""thread"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	109	 Ошибка (активно)	E0147	объявление несовместимо с перегруженная функция ""swap"" (объявлено в строке 442 из ""C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\map"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	111	 Ошибка (активно)	E0020	идентификатор ""thread"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	111	 Ошибка (активно)	E0020	идентификатор ""_Other"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	111	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	111	 Ошибка (активно)	E0020	идентификатор ""native_handle_type"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	146	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	154	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	156	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	159	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	159	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	175	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	186	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	186	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	203	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	203	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	208	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	210	 Ошибка (активно)	E0771	ключевое слово explicit недопустимо	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	213	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	213	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	213	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	217	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	217	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	217	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	218	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	219	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	219	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	219	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	223	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	223	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	223	 Ошибка (активно)	E0864	basic_ostream не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	226	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	226	 Ошибка (активно)	E0864	basic_ostream не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	226	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	226	 Ошибка (активно)	E0864	hash не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	227	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	227	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	230	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	230	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	230	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	234	 Ошибка (активно)	E0325	встроенный спецификатор можно использовать только в объявлениях функций	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0020	идентификатор ""thread"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0020	идентификатор ""_Left"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0020	идентификатор ""thread"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0020	идентификатор ""_Right"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	238	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\thread	380	 Ошибка (активно)	E0020	идентификатор ""_crt_exit_return_mode"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\vcruntime_startup.h	39	 Ошибка (активно)	E0020	идентификатор ""_crt_argv_mode"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\vcruntime_startup.h	50	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\vcruntime_startup.h	54	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	52	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	71	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	77	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	253	 Ошибка (активно)	E2386	""constexpr"" здесь не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	259	 Ошибка (активно)	E0864	_Is_trivially_swappable_v не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	259	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	259	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	259	 Ошибка (активно)	E0864	common_type не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	267	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	267	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	267	 Ошибка (активно)	E0864	common_type не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	273	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	273	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	273	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	280	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	288	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0020	идентификатор ""is_convertible_v"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0029	требуется выражение	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0020	идентификатор ""common_type_t"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	296	 Ошибка (активно)	E0840	использование списка аргументов шаблона в объявлении основного шаблона не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	319	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	330	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	339	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	347	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	356	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	420	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	450	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	463	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	483	 Ошибка (активно)	E0020	идентификатор ""treat_as_floating_point_v"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	483	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	483	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	483	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	514	 Ошибка (активно)	E0864	ratio не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	515	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	524	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	532	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	539	 Ошибка (активно)	E0864	common_type_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	547	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	606	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	613	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	620	 Ошибка (активно)	E0864	enable_if_t не является шаблоном	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	628	 Ошибка (активно)	E0020	идентификатор ""treat_as_floating_point_v"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	628	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	628	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	628	 Ошибка (активно)	E0020	идентификатор ""nanoseconds"" не определен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	665	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	666	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	666	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	698	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	698	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	723	 Ошибка (активно)	E1835	атрибут ""nodiscard"" не применяется в этом случае	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	728	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	728	 Ошибка (активно)	E0040	требуется идентификатор	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	728	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Program Files\Microsoft Visual Studio\2022\Community\VC\Tools\MSVC\14.36.32532\include\__msvc_chrono.hpp	788	 Ошибка (активно)	E0020	идентификатор ""Placeholder"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	24	 Ошибка (активно)	E0020	идентификатор ""DT_FLOAT"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	24	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\ai.cpp	24	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\ai.cpp	25	 Ошибка (активно)	E0020	идентификатор ""Variable"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	28	 Ошибка (активно)	E0020	идентификатор ""Tanh"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	30	 Ошибка (активно)	E0020	идентификатор ""Add"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	30	 Ошибка (активно)	E0020	идентификатор ""MatMul"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	30	 Ошибка (активно)	E0020	идентификатор ""ReduceMean"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	33	 Ошибка (активно)	E0020	идентификатор ""Square"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	33	 Ошибка (активно)	E0020	идентификатор ""Sub"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	33	 Ошибка (активно)	E0020	идентификатор ""GradientDescentOptimizer"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	37	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	44	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\ai.cpp	44	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\ai.cpp	45	 Ошибка (активно)	E0020	идентификатор ""input_tensor"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	47	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Users\User\source\repos\ai\ai.cpp	47	 Ошибка (активно)	E0029	требуется выражение	ai	C:\Users\User\source\repos\ai\ai.cpp	47	 Ошибка (активно)	E0020	идентификатор ""target_tensor"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	48	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Users\User\source\repos\ai\ai.cpp	48	 Ошибка (активно)	E0029	требуется выражение	ai	C:\Users\User\source\repos\ai\ai.cpp	48	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\ai.cpp	56	 Ошибка (активно)	E0020	идентификатор ""prediction"" не определен	ai	C:\Users\User\source\repos\ai\ai.cpp	57	 Ошибка (активно)	E0254	использование имени типа не допускается	ai	C:\Users\User\source\repos\ai\ai.cpp	60	 Ошибка (активно)	E0029	требуется выражение	ai	C:\Users\User\source\repos\ai\ai.cpp	60	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	48	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	52	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	80	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	125	 Ошибка (активно)	E0020	идентификатор ""TensorProto"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	189	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	200	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	223	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	239	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	245	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	247	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	252	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	255	 Ошибка (активно)	E0020	идентификатор ""DT_INVALID"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	255	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Span""	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\scope.h	263	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\scope.h	263	 Ошибка (активно)	E0020	идентификатор ""TensorProto"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\ops\const_op.h	33	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\common_runtime\graph_constructor.h	65	 Ошибка (активно)	E0020	идентификатор ""AttrValue"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	109	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	160	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	169	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	180	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	188	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	195	 Ошибка (активно)	E0020	идентификатор ""OpDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	258	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	266	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	266	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	278	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	280	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	288	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	288	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	293	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""flat_hash_map""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	359	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	359	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	396	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	415	 Ошибка (активно)	E1455	объявленная с использованием ключевого слова override функциячлен не переопределят член базового класса	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	416	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	430	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	434	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	434	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	446	 Ошибка (активно)	E0020	идентификатор ""GradientDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	455	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	461	 Ошибка (активно)	E0020	идентификатор ""GradientDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	468	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	490	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	491	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	496	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	499	 Ошибка (активно)	E1455	объявленная с использованием ключевого слова override функциячлен не переопределят член базового класса	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	517	 Ошибка (активно)	E0020	идентификатор ""OpRegistrationData"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	518	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	531	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	540	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	560	 Ошибка (активно)	E0020	идентификатор ""OptimizedFunctionGraph"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	584	 Ошибка (активно)	E0020	идентификатор ""OptimizedFunctionGraph"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	592	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	603	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	603	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	613	 Ошибка (активно)	E0020	идентификатор ""GradientDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	615	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	620	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	620	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	642	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""FlatMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	642	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	642	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	643	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""FlatMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	643	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	643	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	645	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""FlatMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	645	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	645	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	671	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	727	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	727	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	727	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	731	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""flat_hash_map""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	731	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	731	 Ошибка (активно)	E0020	идентификатор ""ConfigProto"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	776	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	839	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	842	 Ошибка (активно)	E0020	идентификатор ""DataTypeVector"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	859	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	886	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	886	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	886	 Ошибка (активно)	E0020	идентификатор ""RendezvousInterface"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	889	 Ошибка (активно)	E0020	идентификатор ""CancellationManager"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	890	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	896	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	896	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	896	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	922	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	929	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	929	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	935	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	936	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	945	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	945	 Ошибка (активно)	E0020	идентификатор ""Env"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	977	 Ошибка (активно)	E0020	идентификатор ""ConfigProto"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	980	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1015	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1021	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1021	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""flat_hash_map""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1022	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1022	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1031	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1033	 Ошибка (активно)	E0283	использование полного имени не допускается	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1057	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1057	 Ошибка (активно)	E0283	использование полного имени не допускается	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1065	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1065	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1128	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1128	 Ошибка (активно)	E0020	идентификатор ""DataTypeVector"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1129	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1192	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1192	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1206	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\function.h	1207	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	56	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	58	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	61	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	69	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	80	 Ошибка (активно)	E0020	идентификатор ""AttrValue"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	97	 Ошибка (активно)	E0020	идентификатор ""AttrValue"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	98	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	106	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	108	 Ошибка (активно)	E0020	идентификатор ""TensorProto"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	109	 Ошибка (активно)	E0020	идентификатор ""NameAttrList"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	110	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	120	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	126	 Ошибка (активно)	E0020	идентификатор ""NameAttrList"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	127	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	152	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	159	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	160	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	161	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	168	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	168	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	169	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	172	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	172	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	175	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	175	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	175	 Ошибка (активно)	E0020	идентификатор ""AttrValue"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	182	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\node_def_builder.h	185	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	254	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	254	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	257	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	257	 Ошибка (активно)	E0020	идентификатор ""MemoryTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	258	 Ошибка (активно)	E0020	идентификатор ""MemoryTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	259	 Ошибка (активно)	E0020	идентификатор ""Env"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	262	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	276	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	277	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	278	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	279	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	282	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	286	 Ошибка (активно)	E0020	идентификатор ""DataTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	287	 Ошибка (активно)	E0020	идентификатор ""MemoryTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	288	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	294	 Ошибка (активно)	E0020	идентификатор ""DataTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	295	 Ошибка (активно)	E0020	идентификатор ""MemoryTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	298	 Ошибка (активно)	E0020	идентификатор ""DataTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	305	 Ошибка (активно)	E0020	идентификатор ""DataTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	306	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	322	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	351	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	354	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	355	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	359	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	359	 Ошибка (активно)	E0020	идентификатор ""MemoryTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	360	 Ошибка (активно)	E0020	идентификатор ""MemoryTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	361	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	423	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	423	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	428	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	443	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	448	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	464	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	469	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	471	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	472	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	473	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	474	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	475	 Ошибка (активно)	E0020	идентификатор ""TrackingAllocator"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	568	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	583	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	583	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	583	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	589	 Ошибка (активно)	E0020	идентификатор ""PerOpGpuDevice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	601	 Ошибка (активно)	E0020	идентификатор ""RendezvousInterface"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	632	 Ошибка (активно)	E0020	идентификатор ""SessionState"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	639	 Ошибка (активно)	E0020	идентификатор ""SessionMetadata"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	645	 Ошибка (активно)	E0020	идентификатор ""TensorStore"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	648	 Ошибка (активно)	E0020	идентификатор ""CancellationManager"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	652	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	655	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Span""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	655	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	655	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	658	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Span""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	658	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	658	 Ошибка (активно)	E0020	идентификатор ""DeviceContext"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	661	 Ошибка (активно)	E0020	идентификатор ""FrameAndIter"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	664	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	688	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	688	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	688	 Ошибка (активно)	E0020	идентификатор ""Env"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	703	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	711	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	711	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	711	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	724	 Ошибка (активно)	E0020	идентификатор ""MemoryType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	725	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	728	 Ошибка (активно)	E0020	идентификатор ""MemoryType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	729	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	737	 Ошибка (активно)	E0864	StatusOr не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	742	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	742	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	749	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	775	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	784	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	798	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	804	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	854	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	858	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	888	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	889	 Ошибка (активно)	E0020	идентификатор ""MemoryType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	890	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	901	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	906	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	912	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	914	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	917	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	918	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	988	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	990	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	996	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	999	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1006	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1007	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1009	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1010	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1011	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1012	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1018	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1019	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1020	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1021	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1026	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1029	 Ошибка (активно)	E0020	идентификатор ""DeviceContext"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1039	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1062	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1062	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1062	 Ошибка (активно)	E0020	идентификатор ""DataTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1140	 Ошибка (активно)	E0020	идентификатор ""DataTypeSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1141	 Ошибка (активно)	E0020	идентификатор ""CancellationManager"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1152	 Ошибка (активно)	E0020	идентификатор ""FrameAndIter"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1159	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1164	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1188	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1190	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1197	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1265	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1266	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1272	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1273	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1279	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1281	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1293	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1293	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1293	 Ошибка (активно)	E0135	пространство имен ""std"" не содержит члена ""unordered_set""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1297	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1297	 Ошибка (активно)	E0040	требуется идентификатор	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1297	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1304	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1304	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1304	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1311	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1311	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1311	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1313	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1313	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1313	 Ошибка (активно)	E0135	класс ""tensorflow::OpKernelContext"" не содержит члена ""eigen_device""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1325	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1325	 Ошибка (активно)	E0135	класс ""tensorflow::OpKernelContext"" не содержит члена ""eigen_device""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1328	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1328	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1372	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1373	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1375	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1379	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1379	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1380	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1380	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1383	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1383	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1385	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1385	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1388	 Ошибка (активно)	E0020	идентификатор ""DeviceBase"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1388	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1391	 Ошибка (активно)	E0439	требуется угловая скобка "">""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1391	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1400	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1400	 Ошибка (активно)	E0020	идентификатор ""PrioritizedDeviceTypeVector"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1401	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1402	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1490	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1490	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1497	 Ошибка (активно)	E0020	идентификатор ""NodeDef_ExperimentalDebugInfo"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1499	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1500	 Ошибка (активно)	E0020	идентификатор ""KernelDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1501	 Ошибка (активно)	E0020	идентификатор ""DeviceType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1506	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1506	 Ошибка (активно)	E0020	идентификатор ""KernelDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1507	 Ошибка (активно)	E0020	идентификатор ""KernelList"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1514	 Ошибка (активно)	E0020	идентификатор ""KernelList"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1517	 Ошибка (активно)	E0020	идентификатор ""KernelDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1518	 Ошибка (активно)	E0020	идентификатор ""KernelList"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1521	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1578	 Ошибка (активно)	E0147	объявление несовместимо с ""tsl::Status tensorflow::OpKernelContext::input_dtype(tensorflow::StringPiece name,  *dtype) const"" (объявлено в строке 724)	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1578	 Ошибка (активно)	E0020	идентификатор ""MemoryType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1585	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1591	 Ошибка (активно)	E0020	идентификатор ""MemoryType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1597	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1622	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1643	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1655	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1661	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1673	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1680	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1686	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1692	 Ошибка (активно)	E0020	идентификатор ""Tensor"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\op_kernel.h	1698	 Ошибка (активно)	E0059	недопустимый вызов функции в константном выражении	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\registration\registration.h	40	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\resource_base.h	51	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	100	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	100	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	100	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	126	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	127	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	305	 Ошибка (активно)	E0135	пространство имен ""tensorflow::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	305	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	305	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	324	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""DSizes""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	633	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_shape.h	633	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""DenseIndex""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	25	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	28	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	28	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	28	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	31	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	31	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	31	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	36	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	36	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	36	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	38	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	38	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	38	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	42	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	42	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	42	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	47	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	47	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	47	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	51	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	51	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	51	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	57	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	57	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	57	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	60	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	60	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	60	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	65	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	65	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	65	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	68	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	68	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	68	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	71	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	71	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	71	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	74	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	74	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	74	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	79	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	79	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	79	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	81	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	81	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	81	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	84	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	84	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	84	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	86	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	86	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	86	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	91	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	91	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	91	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	94	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	94	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	94	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	99	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	99	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	99	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	101	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""TensorMap""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	101	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	101	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	106	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	109	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	109	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	117	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	117	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""DSizes""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	132	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	132	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	184	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\tensor_types.h	190	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\type_index.h	91	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\framework\type_index.h	93	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	104	 Ошибка (активно)	E0020	идентификатор ""OpDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	105	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	107	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	111	 Ошибка (активно)	E0020	идентификатор ""DataTypeVector"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	112	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	115	 Ошибка (активно)	E0020	идентификатор ""DataTypeVector"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	116	 Ошибка (активно)	E0020	идентификатор ""AttrSlice"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	146	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	149	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	149	 Ошибка (активно)	E0020	идентификатор ""NodeProperties"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	253	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	279	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	279	 Ошибка (активно)	E0020	идентификатор ""AttrValue"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	304	 Ошибка (активно)	E0020	идентификатор ""NodeProperties"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	343	 Ошибка (активно)	E0020	идентификатор ""NodeProperties"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	358	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	562	 Ошибка (активно)	E0864	StatusOr не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	565	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	565	 Ошибка (активно)	E0020	идентификатор ""NodeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	619	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	630	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	631	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	637	 Ошибка (активно)	E0020	идентификатор ""FunctionDefLibrary"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	639	 Ошибка (активно)	E0020	идентификатор ""FunctionDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	646	 Ошибка (активно)	E0020	идентификатор ""GradientDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	652	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	802	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	802	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	802	 Ошибка (активно)	E0020	идентификатор ""FullTypeDef"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	833	 Ошибка (активно)	E0020	идентификатор ""NodeProperties"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	849	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	912	 Ошибка (активно)	E0135	пространство имен ""std"" не содержит члена ""map""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	912	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	912	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	916	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""optional""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	916	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph.h	916	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""flat_hash_map""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_debug_info_builder.h	133	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_debug_info_builder.h	133	 Ошибка (активно)	E0020	идентификатор ""GraphDebugInfo"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_debug_info_builder.h	137	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""StatusOr""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_debug_info_builder.h	138	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_debug_info_builder.h	138	 Ошибка (активно)	E0020	идентификатор ""GraphDebugInfo"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_debug_info_builder.h	143	 Ошибка (активно)	E0020	идентификатор ""NameRangeMap"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_node_util.h	54	 Ошибка (активно)	E0020	идентификатор ""NameRangeMap"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\graph_node_util.h	54	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\node_builder.h	59	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\node_builder.h	72	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\node_builder.h	80	 Ошибка (активно)	E0864	StatusOr не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\node_builder.h	130	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\node_builder.h	137	 Ошибка (активно)	E0020	идентификатор ""DataType"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\graph\node_builder.h	152	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\lib\gtl\array_slice.h	28	 Ошибка (активно)	E0040	требуется идентификатор	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\lib\gtl\array_slice.h	28	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\lib\gtl\array_slice.h	28	 Ошибка (активно)	E0135	пространство имен ""tsl::gtl"" не содержит члена ""InlinedVector""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\lib\gtl\inlined_vector.h	28	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\platform\errors.h	37	 Ошибка (активно)	E0135	пространство имен ""tsl"" не содержит члена ""StatusOr""	ai	C:\Users\User\source\repos\ai\include\tensorflow\core\platform\statusor.h	23	 Ошибка (активно)	E0864	NumTraits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	36	 Ошибка (активно)	E0864	NumTraits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	38	 Ошибка (активно)	E0864	NumTraits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	40	 Ошибка (активно)	E0864	NumTraits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	42	 Ошибка (активно)	E0864	NumTraits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	44	 Ошибка (активно)	E0864	scalar_product_traits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	48	 Ошибка (активно)	E0020	идентификатор ""EIGEN_STRONG_INLINE"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	115	 Ошибка (активно)	E0020	идентификатор ""EIGEN_STRONG_INLINE"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	118	 Ошибка (активно)	E0020	идентификатор ""EIGEN_STRONG_INLINE"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	122	 Ошибка (активно)	E0020	идентификатор ""EIGEN_STRONG_INLINE"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	125	 Ошибка (активно)	E0020	идентификатор ""EIGEN_STRONG_INLINE"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	130	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\fixedpoint_types.h	130	 Ошибка (активно)	E0757	переменная ""Eigen::QInt32"" не является именем типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\numeric_types.h	34	 Ошибка (активно)	E0864	NumTraits не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\framework\numeric_types.h	52	 Ошибка (активно)	E0864	hash не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\lib\gtl\flatset.h	39	 Ошибка (активно)	E0135	пространство имен ""tsl::internal"" не содержит члена ""FlatRep""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\lib\gtl\flatset.h	255	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\lib\gtl\flatset.h	255	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\lib\gtl\inlined_vector.h	28	 Ошибка (активно)	E0135	пространство имен ""Eigen"" не содержит члена ""bfloat16""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\bfloat16.h	24	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	40	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	41	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	42	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	43	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	44	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	45	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	46	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	47	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	48	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	49	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	50	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	51	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	52	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	53	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	54	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	55	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	56	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	57	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	149	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""StatusCode""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	150	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	275	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	283	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	290	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	296	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	350	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	358	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	365	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	371	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""string_view""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	584	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""string_view""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	596	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""string_view""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	601	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""string_view""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	609	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""string_view""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	614	 Ошибка (активно)	E0135	пространство имен ""tsl::error"" не содержит члена ""OK""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\errors.h	641	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\float8.h	22	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\float8.h	23	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\float8.h	24	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\float8.h	27	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\float8.h	28	 Ошибка (активно)	E0840	использование списка аргументов шаблона в объявлении основного шаблона не допускается	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	73	 Ошибка (активно)	E0840	использование списка аргументов шаблона в объявлении основного шаблона не допускается	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	87	 Ошибка (активно)	E0864	hash не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	96	 Ошибка (активно)	E0020	идентификатор ""string"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	96	 Ошибка (активно)	E0864	hash не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	103	 Ошибка (активно)	E0020	идентификатор ""tstring"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	103	 Ошибка (активно)	E0864	hash не является шаблоном	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	110	 Ошибка (активно)	E0020	идентификатор ""StringPiece"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	110	 Ошибка (активно)	E0135	пространство имен ""tsl"" не содержит члена ""hash""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	115	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	115	 Ошибка (активно)	E0840	использование списка аргументов шаблона в объявлении основного шаблона не допускается	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	118	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\hash.h	124	 Ошибка (активно)	E0020	идентификатор ""Condition"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	102	 Ошибка (активно)	E0020	идентификатор ""Condition"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	108	 Ошибка (активно)	E0020	идентификатор ""uint64"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	108	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	111	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	113	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	114	 Ошибка (активно)	E0135	пространство имен ""std"" не содержит члена ""cv_status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	239	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	240	 Ошибка (активно)	E0018	требуется круглая скобка "")""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	240	 Ошибка (активно)	E0020	идентификатор ""ConditionResult"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	245	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	248	 Ошибка (активно)	E0020	идентификатор ""ConditionResult"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	256	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\mutex.h	311	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	57	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	66	 Ошибка (активно)	E0239	недопустимый спецификатор вне объявления класса	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	71	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	71	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	73	 Ошибка (активно)	E0260	отсутствует явный тип (требуется ""int"")	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	76	 Ошибка (активно)	E0020	идентификатор ""RefCounted"" не определен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	76	 Ошибка (активно)	E0341	функция ""operator="" должна быть функциейчленом	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	77	 Ошибка (активно)	E0757	функцию ""RefCounted"" не является именем типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	77	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	78	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	90	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	90	 Ошибка (активно)	E0262	не является именем класса или структуры	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	144	 Ошибка (активно)	E1455	объявленная с использованием ключевого слова override функциячлен не переопределят член базового класса	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	152	 Ошибка (активно)	E0262	не является именем класса или структуры	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	155	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	160	 Ошибка (активно)	E0135	пространство имен ""std"" не содержит члена ""map""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	160	 Ошибка (активно)	E0065	требуется точка с запятой "";""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	160	 Ошибка (активно)	E0070	недопустимый неполный тип	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	217	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	297	 Ошибка (активно)	E0169	требуется объявление	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\refcount.h	297	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	57	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	60	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	63	 Ошибка (активно)	E0283	использование полного имени не допускается	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	72	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	73	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	73	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	74	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	78	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	78	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	79	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	85	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""StatusCode""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	85	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	86	 Ошибка (активно)	E0898	оператору, не являющемуся членом, требуется параметр с класса перечисляемого типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	90	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""StatusCode""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	90	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	91	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	104	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	104	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	105	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""Status""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\status.h	105	 Ошибка (активно)	E0135	пространство имен ""absl"" не содержит члена ""StatusOr""	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\statusor.h	87	 Ошибка (активно)	E0276	имя, за которым следует выражение ""::"", должно определять класс или пространство имен	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\stringpiece.h	33	 Ошибка (активно)	E0077	это объявление не содержит класс хранения или спецификатор типа	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\tstring.h	379	 Ошибка (активно)	E1670	квалификатор типа не разрешен на функции не элементам	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\tstring.h	379	 Предупреждение	C6386	Переполнение буфера при записи в ""new_ptr"".	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	274	 Предупреждение	C6387	""new_ptr"" может быть ""0"".	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	274	 Предупреждение	C6011	Разыменование пустого указателя ""str>u.large.ptr"". 	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	280	 Предупреждение	C6386	Переполнение буфера при записи в ""str>u.large.ptr"".	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	280	 Предупреждение	C6308	realloc может возвратить пустой указатель: присвоение пустого указателя переменной ""str>u.large.ptr"", которая передается в качестве аргумента функции realloc, приведет к утечке исходного блока памяти.	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	331	 Предупреждение	C6387	""new_ptr"" может быть ""0"".	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	335	 Предупреждение	C6011	Разыменование пустого указателя ""str>u.large.ptr"". Самое раннее расположение, где это могло произойти, см. в строке 335	ai	C:\Users\User\source\repos\ai\include\tensorflow\tsl\platform\ctstring_internal.h	339	 Ошибка	C1083	Не удается открыть файл включение: absl/status/status.h: No such file or directory,	ai	C:\Users\User\source\repos\ai\include\tensorflow\cc\framework\ops.h	24	",", Its unlikely for TF 2.7 version to receive any bug fixes except when we have security patches. There is a high possibility that this was fixed with later TF versions. Perhaps you can use the latest tf versions for your case.  The prebuilt binaries for windows are of win_amd64.whl type and seem not supporting for mingw_x86_64 architecture. You have an option for Build from source using MSYS shell. Please refer to the documentation here for same. Thank you!","tilakrayal, OK, thank you. So I will use the python from my DLL to write complete applications for windows and linux. Thank you. You can close the ticket. Tensorflow is not meant to be used in C++ although it is written in C++. My releases of my software will grow by 200 megabytes due to the need to invest python.",", Glad the issue was resolved. As mentioned above, moving this issue to the closed status. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1167,"以下是一个github上的tensorflow下的一个issue, 标题是(Since one week with a few different issues and two platforms I can't import Keras)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version SystemError: initialization of _pywrap_checkpoint_reader raised unreported exception  Custom code No  OS platform and distribution Mac13.4   Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I face the error ""SystemError: initialization of _pywrap_checkpoint_reader raised unreported exception"" when I import keras to build DL model! I worked on make sure that the TensorFlow library is installed also I update the TensorFlow library to the latest version. I need I help to resolve this issue because I think I trying a lot of recommendations! Thanks  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sarahshehri,Since one week with a few different issues and two platforms I can't import Keras," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version SystemError: initialization of _pywrap_checkpoint_reader raised unreported exception  Custom code No  OS platform and distribution Mac13.4   Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I face the error ""SystemError: initialization of _pywrap_checkpoint_reader raised unreported exception"" when I import keras to build DL model! I worked on make sure that the TensorFlow library is installed also I update the TensorFlow library to the latest version. I need I help to resolve this issue because I think I trying a lot of recommendations! Thanks  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-31T03:39:21Z,stat:awaiting response type:build/install subtype:macOS,closed,1,9,https://github.com/tensorflow/tensorflow/issues/61427," Could you please make sure to follow the steps here? Try to use the following;  In order to expedite the troubleshooting process, please provide a code snippet to reproduce the issue reported here. Thank you!",PROJECTcourseTWO.md,"  m/tensorflow/tensorflow/assets/46406878/de498264cced4829812e85239be1aa73"">",,">  Could you please make sure to follow the steps here? Try to use the following; >  >  >  > In order to expedite the troubleshooting process, please provide a code snippet to reproduce the issue reported here. Thank you! I worked on but without any positive changes! And I attached the python notebook file can take skinnier on it! And I'm waiting your help "," Thank you for your response! Could you please let me know what are the platforms you're using? If you are using jupyter notebook, we recommend using conda as it will automatically install all the necessary dependencies. create a new cell in your Jupyter notebook and run the command below;  It will install the latest TF version. Please make sure you have installed it. Remember to create a new environment specifically for TensorFlow to avoid conflicts with other Python packages. Thank you!",">  Thank you for your response! Could you please let me know what are the platforms you're using? If you are using jupyter notebook, we recommend using conda as it will automatically install all the necessary dependencies. create a new cell in your Jupyter notebook and run the command below; >  >  >  > It will install the latest TF version. Please make sure you have installed it. Remember to create a new environment specifically for TensorFlow to avoid conflicts with other Python packages. >  > Thank you! Thaaaaaaaaank u!!!! finally is resolving i installed the conda on Anaconda platform with using the Jupyter. Thank u again ", Thank you for the confirmation. Glad it worked fine for you. Could you please close this issue as it is resolved? Thank you!,Are you satisfied with the resolution of your issue? Yes No
1137,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.debugging.experimental.enable_dump_debug_info (Debugger V2) error with TPU)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.12 (but also 2.14 nightly)  Custom code Yes  OS platform and distribution Google Colab  Mobile device no  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version N/A (using TPU)  GPU model and memory _No response_  Current behavior? I'm trying to use the `tf.debugging.experimental.enable_dump_debug_info(...)` function with TPU. I've tested my code without the TPU strategy bit, and it works, I can use the Debugger V2 fine. I've also tested the code without the debugger bit and it trains fine as well. But together it gives me this error:  yeah very long. oh and I've tried `tf.config.set_soft_device_placement(True)` but no result  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ViniciusSuaiden,tf.debugging.experimental.enable_dump_debug_info (Debugger V2) error with TPU," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version tf 2.12 (but also 2.14 nightly)  Custom code Yes  OS platform and distribution Google Colab  Mobile device no  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version N/A (using TPU)  GPU model and memory _No response_  Current behavior? I'm trying to use the `tf.debugging.experimental.enable_dump_debug_info(...)` function with TPU. I've tested my code without the TPU strategy bit, and it works, I can use the Debugger V2 fine. I've also tested the code without the debugger bit and it trains fine as well. But together it gives me this error:  yeah very long. oh and I've tried `tf.config.set_soft_device_placement(True)` but no result  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-28T06:27:06Z,stat:awaiting tensorflower type:bug comp:tpus TF 2.12,open,0,4,https://github.com/tensorflow/tensorflow/issues/61421,"Hi   I have replicated the reported issue, please check out the gist here. This issue needs to be looked into. Thank you!!","Thanks, anjanappa! It's been a week and no update (I see the assignee is now ), and since I've tried to use the Debugger V2 to debug my model for a competition, I kind of have a deadline and this is the only way I found to do that. Therefore, I'd like to know if there's something I can do about it... maybe some guidance for a PR?  Thank you in advance!"," , Apologies for the delayed response, concerned team is currently looking into this issue. Will update you here once any new information is available. Thank you.","Thank you, , for the update. I appreciate it. I'll await further information :)"
309,"以下是一个github上的tensorflow下的一个issue, 标题是(Fixed the code on adam.py)， 内容是 (As requested in the issue https://github.com/tensorflow/tensorflow/issues/61407, modifying   to  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,tilakrayal,Fixed the code on adam.py,"As requested in the issue https://github.com/tensorflow/tensorflow/issues/61407, modifying   to  ",2023-07-27T11:23:48Z,type:docs-bug stale comp:keras size:XS,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61411,Is there a justification for the change? Don't take random suggestions into account if there is no source for the claim,", by checking the original Adam paper, in the last line of the while loop it's indeed `+ epsilon`.",Can you write a test to prove the correctness of the update?,Hi  Can you please check 's comments and keep us posted ? Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,"As this issue is related to Keras, the Keras repository code which was suggesting has the correct formula.  So moving this PR to closed status. https://github.com/kerasteam/keras/blob/cdffff886626e5a05bc5d54b8a4634f1e5db06cf/keras/optimizers/legacy/adam.pyL468"
1933,"以下是一个github上的tensorflow下的一个issue, 标题是(Failed building from source using clang compiler. Error: libtensorflow_framework.so.2 is a dangling symbolic link)， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**:  No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04.6 LTS. Building on Intel x86 CPU    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:    **TensorFlow installed from (source or binary)**: Source    **TensorFlow version (use command below)**: 2.13    **Python version**: 3.10.11    **Bazel version (if compiling from source)**: 5.3.0    **Clang/Compiler version (if compiling from source)**: Clang 16.0.6    **CUDA/cuDNN version**: None (Building on Intel x86 CPU)    **GPU model and memory**: None (Building on Intel x86 CPU)    **Exact command to reproduce**:   bazel build  config=mkl config=dbg verbose_failures  c opt copt=march=native spawn_strategy=sandboxed sandbox_debug //tensorflow/tools/pip_package:build_pip_package  Describe the problem Error while building Tensorflow 2.13 from source with clang 16.0.6 and bazel 5.3.0. I am using the versions that were tested compatible  from this link: https://www.tensorflow.org/install/sourcetested_build_configurations. Errors: ERROR: /home/ubuntu/builds/tensorflow/tensorflow/BUILD:1134:21: declared output 'tensorflow/libtensorflow_framework.so.2' is a dangling symbolic link ERROR: /home/ubuntu/builds/tensorflow/tensorflow/BUILD:1134:21: Executing genrule //tensorflow:libtensorflow_framework.so.2_sym [for host] failed: not all outputs were created or valid  Source code / logs Output from above command mentioned: Starting local Bazel server and connectin)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,vineel96,Failed building from source using clang compiler. Error: libtensorflow_framework.so.2 is a dangling symbolic link," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**:  No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04.6 LTS. Building on Intel x86 CPU    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:    **TensorFlow installed from (source or binary)**: Source    **TensorFlow version (use command below)**: 2.13    **Python version**: 3.10.11    **Bazel version (if compiling from source)**: 5.3.0    **Clang/Compiler version (if compiling from source)**: Clang 16.0.6    **CUDA/cuDNN version**: None (Building on Intel x86 CPU)    **GPU model and memory**: None (Building on Intel x86 CPU)    **Exact command to reproduce**:   bazel build  config=mkl config=dbg verbose_failures  c opt copt=march=native spawn_strategy=sandboxed sandbox_debug //tensorflow/tools/pip_package:build_pip_package  Describe the problem Error while building Tensorflow 2.13 from source with clang 16.0.6 and bazel 5.3.0. I am using the versions that were tested compatible  from this link: https://www.tensorflow.org/install/sourcetested_build_configurations. Errors: ERROR: /home/ubuntu/builds/tensorflow/tensorflow/BUILD:1134:21: declared output 'tensorflow/libtensorflow_framework.so.2' is a dangling symbolic link ERROR: /home/ubuntu/builds/tensorflow/tensorflow/BUILD:1134:21: Executing genrule //tensorflow:libtensorflow_framework.so.2_sym [for host] failed: not all outputs were created or valid  Source code / logs Output from above command mentioned: Starting local Bazel server and connectin",2023-07-26T11:38:48Z,stat:awaiting response type:build/install stale comp:mkl subtype: ubuntu/linux TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61398,"Hi  , Could you please confirm your `./configure` setup. I am getting a different error though in both r2.13 and master. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Does this issue resolved? I'm getting the same for TF 2.13 build.
1341,"以下是一个github上的tensorflow下的一个issue, 标题是(int8 tflite model allocate_tensors() silently stop python process.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.8.1, 2.13.0, '2.14.0dev20230706'  Custom code Yes  OS platform and distribution Windows 11, Windows 10 WSL with Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have converted a Resnet18 model from onnx to tflite. (onnx > tf > tflite) onnx to tf conversion is done by this repo tflite is converted to int8 precision using posttraining integer quantization link Netron can display the converted int8 model correctly. onnx model & tflite model link tflite int8 model link but when I try to do inference. calling the method allocate_tensors() stop the python process without showing any error/warning. if the tflite model is converted with fp32, this issue  doesn't happen. I have no idea how do to fix this issue or is there any workaround? thanks  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,bluesy7585,int8 tflite model allocate_tensors() silently stop python process.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.8.1, 2.13.0, '2.14.0dev20230706'  Custom code Yes  OS platform and distribution Windows 11, Windows 10 WSL with Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have converted a Resnet18 model from onnx to tflite. (onnx > tf > tflite) onnx to tf conversion is done by this repo tflite is converted to int8 precision using posttraining integer quantization link Netron can display the converted int8 model correctly. onnx model & tflite model link tflite int8 model link but when I try to do inference. calling the method allocate_tensors() stop the python process without showing any error/warning. if the tflite model is converted with fp32, this issue  doesn't happen. I have no idea how do to fix this issue or is there any workaround? thanks  Standalone code to reproduce the issue   Relevant log output ",2023-07-26T08:43:02Z,stat:awaiting response type:bug comp:lite comp:runtime TF 2.13,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61395,"I found a workaround for this issue.  instead of converting from tf to tflite, convert from keras to tflite works for me. (onnx > keras > tflite) onnx to keras conversion is done by onnx2keras package (pip install) keras to tflite using the same code above (only replace with tf.lite.TFLiteConverter.from_keras_model)",Hi   Thanks for the workaround.  I see the onnxTF library has not been updated recently and the conversion to TF might be causing the issue. Feel free to close the issue since it is resolved. Thanks.,Are you satisfied with the resolution of your issue? Yes No
1759,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot subclass dataset_ops.DatasetV2)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.x  Custom code Yes  OS platform and distribution Mac OS 13.0  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi, I'm from LanceDB team and we're trying to build native support for tf.data. See WIP PR here https://github.com/lancedb/lance/pull/1087 . Ideally, we'd like to simply subclass `tf.dataset_ops.DatasetV2` so that all the metadata needed to recreate the dataset can be pushed down to our file format that enabled parallelism elegantly. So, it'd be something like this  The above code complains that can not create LanceTfDataset to tf.Tensor/variant. Issue  what exactly is variant_tensor and how do we go about creating one? I read through the docs but couldn't find anything concrete. There was a mention that variant_tensor is a special tensor that tell about the type of the dataset and that it's equivalent to tf.Variant, but the above code doesn't work. Having a version of tf.dataset that we can use to capture extra metadata would allow us to improve the interface as well: so instead of lance.tf.data.from_dataset(uri, columns, filter, batch_size) we can just have from_lance(uri).filter(..).batch_size(...).shuffle(). So what's the way to go about subclassing tf Dataset?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AyushExel,Cannot subclass dataset_ops.DatasetV2," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.x  Custom code Yes  OS platform and distribution Mac OS 13.0  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Hi, I'm from LanceDB team and we're trying to build native support for tf.data. See WIP PR here https://github.com/lancedb/lance/pull/1087 . Ideally, we'd like to simply subclass `tf.dataset_ops.DatasetV2` so that all the metadata needed to recreate the dataset can be pushed down to our file format that enabled parallelism elegantly. So, it'd be something like this  The above code complains that can not create LanceTfDataset to tf.Tensor/variant. Issue  what exactly is variant_tensor and how do we go about creating one? I read through the docs but couldn't find anything concrete. There was a mention that variant_tensor is a special tensor that tell about the type of the dataset and that it's equivalent to tf.Variant, but the above code doesn't work. Having a version of tf.dataset that we can use to capture extra metadata would allow us to improve the interface as well: so instead of lance.tf.data.from_dataset(uri, columns, filter, batch_size) we can just have from_lance(uri).filter(..).batch_size(...).shuffle(). So what's the way to go about subclassing tf Dataset?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-26T06:59:17Z,stat:awaiting response type:feature stale comp:ops comp:data,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61394,", A Variant Tensor can be a Tensor of any data type.   Could you please find the explanation about **Variant Tensor** or **DT_Variant** in the following doc. https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/variant.hL54 ", well so subclassing should work on initializing it the way I do in the example right? But that doesn't work. Then how can I subclass Datasetv2,"Hi, Please find the below implementation of subclassing `dataset_ops.DatasetV2`. https://github.com/tensorflow/tensorflow/blob/872f84d3e25377b47abef273121e351ddb5131ff/tensorflow/python/data/ops/choose_from_datasets_op.pyL32 https://github.com/tensorflow/tensorflow/blob/872f84d3e25377b47abef273121e351ddb5131ff/tensorflow/python/data/ops/zip_op.pyL27",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1364,"以下是一个github上的tensorflow下的一个issue, 标题是(Issues running Transformer model example with estimator api)， 内容是 (Hello everyone! I am trying to run an Image classification training example with Vision Transformer from keras examples (https://keras.io/examples/vision/image_classification_with_vision_transformer/). Everything ran perfectly when I ran it as it is but I started facing issues when i switched training from `model.fit()` to `tf.estimator.train_and_evaluate()` (ofcourse I made the appropriate changes to first convert model to estimator). From what I understand ... the problem lies with saving and reloading the model which is done by the estimator api. The model has custom classes:  From looking at some related issues, I found how we need to provide a `get_config()` method to save and reload the model with custom classes so I made small personal modifications but now its sort of giving me a different issue I am unable to understand.  Error Log:  I thought it might be because of `PatchEncoder` class constructor has custom objects as argument  so i tried to do serialization/deserialization but to no vail. In any case, I would highly appreciate if someone can guide me as to where I am going wrong in this!  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ali-raza-tariq,Issues running Transformer model example with estimator api,"Hello everyone! I am trying to run an Image classification training example with Vision Transformer from keras examples (https://keras.io/examples/vision/image_classification_with_vision_transformer/). Everything ran perfectly when I ran it as it is but I started facing issues when i switched training from `model.fit()` to `tf.estimator.train_and_evaluate()` (ofcourse I made the appropriate changes to first convert model to estimator). From what I understand ... the problem lies with saving and reloading the model which is done by the estimator api. The model has custom classes:  From looking at some related issues, I found how we need to provide a `get_config()` method to save and reload the model with custom classes so I made small personal modifications but now its sort of giving me a different issue I am unable to understand.  Error Log:  I thought it might be because of `PatchEncoder` class constructor has custom objects as argument  so i tried to do serialization/deserialization but to no vail. In any case, I would highly appreciate if someone can guide me as to where I am going wrong in this!  ",2023-07-26T06:13:33Z,stat:awaiting response type:support type:others comp:model,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61393,"Hi razatariq , I am sorry to say that estimator API was not supported now and it will not work with TF2.x style code. Please refer to attached note below for same from the source.` > Warning: Estimators are not recommended for new code. Estimators run v1.Sessionstyle code which is more difficult to write correctly, and can behave unexpectedly, especially when combined with TF 2 code. Estimators do fall under our compatibility guarantees, but will receive no fixes other than security vulnerabilities. See the migration guide for details. However if you are passing nonpython objects (like layers etc) you need to implement class method `from_config` to make them serializable. You may refer more details and a simple demo on how to implement `from_config` here. Since you are using layers in PatchEncoder class you must implement `from_config` class method.It may be of some help but still as the warning note suggested above it may or may not work with estimator API. Thanks ! `","  thanks for responding quickly! I understand there might be some limitation to what we can achieve with Estimator using TF2.x code, unfortunately I am in a situation where I need to evaluate various models and other models were using Estimator Api (so to ensure fair enough comparison  its ideal to use the same training api). I will try my best to get it working unless i know for sure that it cannot be done this way. Anyway  thanks to your response i was able to correctly implement the serialization and move past the above error. But even though i am not having issue saving/loading the model  it complains about missing variable values from the saved checkpoints. this is how i am training the model:   and this is the error message i keep getting: ","Hi razatariq , We are not supporting estimator API now. You may find similar issue from SO here for reference. Please post the issue in Stack Overflow for support related issues where Community can also may be helpful. Thank you!",I understand ... thank you for the help!,Are you satisfied with the resolution of your issue? Yes No
775,"以下是一个github上的tensorflow下的一个issue, 标题是(PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.13.0  Custom code Yes  OS platform and distribution Linux  Mobile device _No response_  Python version 3.8  Bazel version 5.3.0  GCC/compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Nithin061,PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target, Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.13.0  Custom code Yes  OS platform and distribution Linux  Mobile device _No response_  Python version 3.8  Bazel version 5.3.0  GCC/compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-07-25T10:34:34Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux subtype:bazel,open,0,1,https://github.com/tensorflow/tensorflow/issues/61379,"hi , Can youplease help m to resovle the issue"
1215,"以下是一个github上的tensorflow下的一个issue, 标题是(`configure`: Error in detecting CUDA toolkit path)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 3b205a3  Custom code Yes  OS platform and distribution Linux Ubuntu 23.04  Python version 3.11  Bazel version 4.2.3  GCC/compiler version 12.2.0  CUDA/cuDNN version 11.8  GPU model and memory GTX 1050 Ti  4 GB  Current behavior? I am trying to using `configure` script before building Tensorflow from source. When I am trying to configure CUDA support using default list of base paths to look for CUDA libraries and headers, I get the following error:  I have included the path of each tool in the next section. I have tried different combinations for list of base paths and even changed `third_party/gpus/find_cuda_config.py` file to add default subdirectory paths but still get this error.  Standalone code to reproduce the issue Here's where everything is installed:  returns:  and  returns:  and  returns:  and  returns:   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sorousherafat,`configure`: Error in detecting CUDA toolkit path," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 3b205a3  Custom code Yes  OS platform and distribution Linux Ubuntu 23.04  Python version 3.11  Bazel version 4.2.3  GCC/compiler version 12.2.0  CUDA/cuDNN version 11.8  GPU model and memory GTX 1050 Ti  4 GB  Current behavior? I am trying to using `configure` script before building Tensorflow from source. When I am trying to configure CUDA support using default list of base paths to look for CUDA libraries and headers, I get the following error:  I have included the path of each tool in the next section. I have tried different combinations for list of base paths and even changed `third_party/gpus/find_cuda_config.py` file to add default subdirectory paths but still get this error.  Standalone code to reproduce the issue Here's where everything is installed:  returns:  and  returns:  and  returns:  and  returns:   Relevant log output _No response_",2023-07-25T09:56:31Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux,open,0,4,https://github.com/tensorflow/tensorflow/issues/61377,"Hi  , Could you please confirm the steps you followed to install cuda toolkit ? Thank you!","Hello, It was just a simple  Thanks in advance."," , Could you please take a look into this, this seems to be related with CUDA toolkit path. Thanks!","Confirmed on Debian 12. > Tensorflow 2.15 Debian 12 Python 3.11 Bazel 4.2.3 GCC 12.2 Cuda 11.8 CuDNN 8.5 It looks like a similar issue was fixed six years ago, so maybe this is a regression."
1506,"以下是一个github上的tensorflow下的一个issue, 标题是(StringLookup layer does not retrieve vocabulary after saving and loading the model)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.11, 2.12, 2.13  Custom code No  OS platform and distribution Linux Ubuntu 20.04.1  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We noticed we could pickle the model right after building it, but unpickling would fail after saving and loading it from the disk. Upon further investigation, we realized the error was due to the vocabulary of the StringLookup layer, which was becoming an empty list after the tf.keras.models.load_model operation.  The unpickling issue happens on TF 2.11 onwards. The unpickling worked on TF 2.8, 2.9, and 2.10, even though the empty vocabulary issue was still there.  Using the minimal reproducible example below, before saving the model, if we inspect the StringLookup layer we get:  After saving and loading to the disk, we get:   We were able to circumvent the issue by creating a new class as follows:  However, it would be nice if we didn't have to create this wrapper.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,brunolucatto,StringLookup layer does not retrieve vocabulary after saving and loading the model," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.11, 2.12, 2.13  Custom code No  OS platform and distribution Linux Ubuntu 20.04.1  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We noticed we could pickle the model right after building it, but unpickling would fail after saving and loading it from the disk. Upon further investigation, we realized the error was due to the vocabulary of the StringLookup layer, which was becoming an empty list after the tf.keras.models.load_model operation.  The unpickling issue happens on TF 2.11 onwards. The unpickling worked on TF 2.8, 2.9, and 2.10, even though the empty vocabulary issue was still there.  Using the minimal reproducible example below, before saving the model, if we inspect the StringLookup layer we get:  After saving and loading to the disk, we get:   We were able to circumvent the issue by creating a new class as follows:  However, it would be nice if we didn't have to create this wrapper.  Standalone code to reproduce the issue   Relevant log output ",2023-07-24T17:57:32Z,stat:awaiting response type:bug comp:keras TF 2.12,closed,1,18,https://github.com/tensorflow/tensorflow/issues/61369,"Hi , Pickling isn't natively supported in keras as it is generally not secure. Therefore I don't think this is actionable on Keras side, and overriding methods for `tf.keras.layers.serialize` is necessary.  Please refer to the similar issue here. Please look at the gist here. Please let us know if it works. Thank you!!","Hi anjanappa, thank you so much for the prompt reply. I am afraid your example on gist missed the part where it fails, which is in the deserialization, not in the serialization. I added the tf.keras.layers.deserialize function, and it throws the same error as the pickle one.  Moreover, I also added the proposed solution for the problem (i.e., changing the get_config method of the StringLookup class) to show that it also works using Keras' proper serialization.   As a side note, I am using pickle because I want to distribute the model on spark using broadcast, so I can make predictions using a pandas UDF more efficiently. The implementation of pyspark.broadcast itself uses pickle, I tried to change that by creating a custom broadcast function but it was not an easy task for me. Loading the model from the disk inside the pandas UDF is also an alternative to broadcast, but it is many times slower.","Hi anjanappa, Just following up to know if you were able to reproduce the error with the changes above. Please let me know if I can provide any further information.","Hi  , Please find the attached gist. As you can see in the gist, when we serialize, the vocabulary values aren't captured, it gives an empty list. Whereas the vocab size is getting captured. There is some issue in the source code. We'll check and get back to you. Thank you "," , can you please look into it",we are seeing the same issue using tf 2.6.2 with python 3.6.9," , It seems a valid issue for me. It needs to dig more for the root cause.","I have done some work, on this bug. The issue seems to be in this file load.py.  !image As I have highlighted, parse from string is generating the data as nodes via proto buff. !image The output nodes are as follows,  nodes {   node_id: 1   node_path: ""root.layer0""   identifier: ""_tf_keras_input_layer""   metadata: ""{\""class_name\"": \""InputLayer\"", \""name\"": \""input_1\"", \""dtype\"": \""int64\"", \""sparse\"": false, \""ragged\"": false, \""batch_input_shape\"": {\""class_name\"": \""__tuple__\"", \""items\"": [null, 1]}, \""config\"": {\""batch_input_shape\"": {\""class_name\"": \""__tuple__\"", \""items\"": [null, 1]}, \""dtype\"": \""int64\"", \""sparse\"": false, \""ragged\"": false, \""name\"": \""input_1\""}}""   version {     producer: 2     min_consumer: 1   } } nodes {   node_id: 2   node_path: ""root.layer1""   identifier: ""_tf_keras_layer""   metadata: ""{\""name\"": \""string_lookup\"", \""trainable\"": true, \""expects_training_arg\"": false, \""dtype\"": \""int64\"", \""batch_input_shape\"": null, \""stateful\"": false, \""must_restore_from_config\"": true, \""preserve_input_structure_in_config\"": false, \""autocast\"": true, \""class_name\"": \""StringLookup\"", \""config\"": {\""name\"": \""string_lookup\"", \""trainable\"": true, \""dtype\"": \""int64\"", \""invert\"": false, \""max_tokens\"": null, \""num_oov_indices\"": 1, \""oov_token\"": \""[UNK]\"", \""mask_token\"": null, \""output_mode\"": \""int\"", \""sparse\"": false, \""pad_to_max_tokens\"": false, \""idf_weights\"": null, \""vocabulary\"": null, \""vocabulary_size\"": 3, \""encoding\"": \""utf8\"", \""has_input_vocabulary\"": true}, \""inbound_nodes\"": [[[\""input_1\"", 0, 0, {}]]], \""shared_object_id\"": 1, \""build_input_shape\"": {\""class_name\"": \""TensorShape\"", \""items\"": [null, 1]}}""   version {     producer: 2     min_consumer: 1   } } nodes {   node_id: 3   node_path: ""root.layer_with_weights0""   identifier: ""_tf_keras_layer""   metadata: ""{\""name\"": \""dense\"", \""trainable\"": true, \""expects_training_arg\"": false, \""dtype\"": \""float32\"", \""batch_input_shape\"": null, \""stateful\"": false, \""must_restore_from_config\"": false, \""preserve_input_structure_in_config\"": false, \""autocast\"": true, \""class_name\"": \""Dense\"", \""config\"": {\""name\"": \""dense\"", \""trainable\"": true, \""dtype\"": \""float32\"", \""units\"": 10, \""activation\"": \""linear\"", \""use_bias\"": true, \""kernel_initializer\"": {\""class_name\"": \""GlorotUniform\"", \""config\"": {\""seed\"": null}, \""shared_object_id\"": 2}, \""bias_initializer\"": {\""class_name\"": \""Zeros\"", \""config\"": {}, \""shared_object_id\"": 3}, \""kernel_regularizer\"": null, \""bias_regularizer\"": null, \""activity_regularizer\"": null, \""kernel_constraint\"": null, \""bias_constraint\"": null}, \""inbound_nodes\"": [[[\""string_lookup\"", 0, 0, {}]]], \""shared_object_id\"": 4, \""input_spec\"": {\""class_name\"": \""InputSpec\"", \""config\"": {\""dtype\"": null, \""shape\"": null, \""ndim\"": null, \""max_ndim\"": null, \""min_ndim\"": 2, \""axes\"": {\""1\"": 1}}, \""shared_object_id\"": 7}, \""build_input_shape\"": {\""class_name\"": \""TensorShape\"", \""items\"": [null, 1]}}""   version {     producer: 2     min_consumer: 1   } in node_id:2 the vocabulary is getting dropped where as it is present in file content. Issue seems to be with protobuff and parsing. It's 2 Am and I have worked on this for straight 4 hours and am taking a break. If you can wait will resume working on it 🙂.","My bad, I think that there is some mistake in how model is saving metadata for the layers. Opened the model and looked at metadata: !image !image","Hi folks, has there been any work on this by any chance or is there a workaround for this? I am currently running into this issue as well. ", Isn't the workaround proposed in the original post working in your case? > We were able to circumvent the issue by creating a new class as follows: >  > ,"> We were able to circumvent the issue by creating a new class as follows: >  >  >  > However, it would be nice if we didn't have to create this wrapper. Hi  , The decorator tf.keras.utils.register_keras_serializable() is one of the way for serializing a class/method into Keras object which can then be saved as .keras model and the able to reload successfully. There are 3 ways we can do this as mentioned here in custom_objects serialization_and_saving guide . You can choose any one.","Hi , thanks for the reply! I think the main issue is not the decorator, but the fact that we need to create this class to make the serialization work. The only thing this new class is doing is ""saving again"" the vocabulary attribute of the instance, and all of this would be unnecessary if the StringLookup layer serialization was working properly. (*) Creating this class is a somewhat ugly workaround for the problem, as it does not address the root cause directly. This is the reason I did not submit it as a potential fix, although it has been working nicely so far. (*) _In the original post, I referred to this new class as a wrapper, which in hindsight makes it look like it was only the decorator that was making me unhappy. Sorry for the ambiguity there._",I ran into this issue recently when passing a keras model object to sklearn permutation_importance() and was hitting this error when using `n_jobs` in that function.  In my case i had a model object that has `StringLookup` layers i need to replace with the `MyStringLookup` layers. Using `clone_model` helped like this:   Here is a google colab to show what i mean. Just sharing this in case is useful for anyone else in a similar situation.,", I tried to execute the available code on Tensorflow v2.17 which contains the keras3.0, and observed the code was executed without any issue/error. Kindly find the gist of it here. Thank you!"," Hi, seems to be working indeed!  Thank you!",", Glad the issue got resolved. Could you please feel free to move this issue to closed status. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1096,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to save model when using EfficientNetB0)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I’m trying to use EfficientNetB0 to create a model and save the model to my local disk. However, when saving it, it throws the error below. > TypeError: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type . Also, I tried to downgrade tensorflow from V2.12.0 to V2.9.1, this works as expected. In other words, this is a bug in 2.12.0. Hope it helps and please fix this bug for V2.12.0  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Seferovic8,Unable to save model when using EfficientNetB0," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I’m trying to use EfficientNetB0 to create a model and save the model to my local disk. However, when saving it, it throws the error below. > TypeError: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type . Also, I tried to downgrade tensorflow from V2.12.0 to V2.9.1, this works as expected. In other words, this is a bug in 2.12.0. Hope it helps and please fix this bug for V2.12.0  Standalone code to reproduce the issue   Relevant log output ",2023-07-24T16:51:23Z,stat:awaiting response type:bug comp:model TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61366,"Hi  , The issue resolved in TF2.13v. Please refer to attached gist and may test yourself. Since it is resolved in latest version its unlikely to cherry pick for TF2.12 version.","Thank you, this works for me.",Are you satisfied with the resolution of your issue? Yes No,"Yes On Tue, 25 Jul 2023 at 16:41, googlemlbutler[bot]  wrote: > Are you satisfied with the resolution of your issue? > Yes >  > No >  > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you modified the open/close state.Message > ID: ***@***.***> >"
1464,"以下是一个github上的tensorflow下的一个issue, 标题是(converter issue )， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Ajim0907,converter issue ," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-07-24T07:36:16Z,stat:awaiting response stale TFLiteConverter,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61361,Hi   We see that template has not been filled. Could you please fill the issue template ? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
504,"以下是一个github上的tensorflow下的一个issue, 标题是(Add ComplexOp as a builtin to TFLite)， 内容是 (For CC(Add ComplexOp to TFLite) . This PR adds the complex op as a builtin to TFLite. I tried to follow instructions given to me in CC(Add ComplexOp to TFLite) . Unfortunately, I'm developing this PR on a Mac M1 and have linker errors when trying to build the TFLite testing suite.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,drubinstein,Add ComplexOp as a builtin to TFLite,"For CC(Add ComplexOp to TFLite) . This PR adds the complex op as a builtin to TFLite. I tried to follow instructions given to me in CC(Add ComplexOp to TFLite) . Unfortunately, I'm developing this PR on a Mac M1 and have linker errors when trying to build the TFLite testing suite.",2023-07-24T02:30:09Z,comp:lite size:L,open,6,33,https://github.com/tensorflow/tensorflow/issues/61359,I noticed that I have `legalizetf.mlir` tests failing due to the new tests I added. How do I go about fixing them?  I'm not really sure what I'm doing differently compared to say the test for `tfl.real` which I based my tests on. Quick edit  fixed the test.,"Bump. I've noticed that other people are making changes to similar files. Before I go and resolve the conflicts/regenerate the schema, is there any plan to review this PR in the near term?","Hi  Sorry for the delay, can you please resolve the conflicts? once it done we will process it further. Thank you!","Thanks  . I resolved all the conflicts. I have a similar PR, CC(Promote IRFFT2D to TFLite Builtin ops), that has similar conflicts as well that I'm also awaiting review for.","  , it looks like there are conflicts again and they seem to be happening faster than an assigned reviewer can get to this PR. Are there currently any plans related TFLite and HLO that may be delaying the review of this PR?",Hi  Can you please assist on above comments from . Thank you!,Hi wei Can you please assist on above https://github.com/tensorflow/tensorflow/pull/61359issuecomment1702645376 from . Thank you!,Hi wei /  Any update on this PR? Please. Thank you!,Hi wei /  Any update on this PR? Please. Thank you!,Hi wei /  Any update on this PR? Please. Thank you!,Hi  Can you please resolve conflicts? Thank you!,"Hi  , I resolved the PR conflicts. Does that mean I should expect a review soon and the tflite kernels are going to be stable for a bit?",Hi  Can you please resolve conflicts? Thank you!," as I've asked before, if I resolve the conflicts, will these files stay stable enough for an actual review? It's been 9 months since I've opened this PR and it feels like I've done conflict resolution a half dozen times with no review (or a hint of review) from the reviewers.",">  as I've asked before, if I resolve the conflicts, will these files stay stable enough for an actual review? It's been 9 months since I've opened this PR and it feels like I've done conflict resolution a half dozen times with no review (or a hint of review) from the reviewers. Hi  Sorry for the delay, please resolve the conflicts, we will process the PR for the review. Thank you so much!"," , I resolved the conflicts and pushed the updates.",Hi  Can you please review this PR? Thank you!,Hi  Can you please resolve conflicts? Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,"Gonna quote myself >  as I've asked before, if I resolve the conflicts, will these files stay stable enough for an actual review? It's been [11] months since I've opened this PR and it feels like I've done conflict resolution a half dozen times with no review (or a hint of review) from the reviewers.","> Gonna quote myself >  > >  as I've asked before, if I resolve the conflicts, will these files stay stable enough for an actual review? It's been [11] months since I've opened this PR and it feels like I've done conflict resolution a half dozen times with no review (or a hint of review) from the reviewers. Hi  Sorry for the delay.  Hi wei  Can you please assist on the above comment from . Thank you!",Hi wei  Can you please assist on the above https://github.com/tensorflow/tensorflow/pull/61359issuecomment2189985564 from . Thank you!,"Hi , Can you please resolve the conflicts? Thank you!","Hi  , I pushed changes resolving the conflicts. ","Hi wei, Can you please review this PR? Thank you !","Hi , Can you please resolve the conflicts? Thank you!","Gonna quote myself >  as I've asked before, if I resolve the conflicts, will these files stay stable enough for an actual review? It's been [13] months since I've opened this PR and it feels like I've done conflict resolution a dozen times with no review (or a hint of review) from the reviewers.",Hi  Sorry for the delay. Hi wei Can you please assist on the above comment  from . Thank you!,Any chance this is going to get looked at? Does this need to be moved over to LiteRT?, why close this PR?
1367,"以下是一个github上的tensorflow下的一个issue, 标题是(ColumnReduceKernel: min() type casting error and improvement)， 内容是 ( Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Windows 10 22H2  Mobile device _No response_  Python version Anaconda 2023.071  Bazel version 6.2.1  GCC/compiler version Visual Studio 2022 (build tools 14.36) + msys2x86_6420230718  CUDA/cuDNN version CUDA 11.8 + CUDNN 8.6.0 + TensorRT 8.5.3  GPU model and memory GTX 750 Ti 2GB  Current behavior? There are two type casting errors in reduction_gpu_kernels.cu.h under MSVC. One of them is fixed in https://github.com/tensorflow/tensorflow/pull/61339. Another is related to a TODO. in ColumnReduceKernel(), the TODO said the followings: > 1D array necessary due to bug in CUDA 9 compiler. > TODO(nluehr) revert to 2D array when compiler is ready. > This is to mimic the following, but without constructors: > __shared__ storage_type partial_sums[TF_RED_WARPSIZE * > (TF_RED_WARPSIZE + 1)]; Since latest version required CUDA 11, it's time to address the TODO and apply bug fix together.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,johnnkp,ColumnReduceKernel: min() type casting error and improvement," Issue type Performance  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Windows 10 22H2  Mobile device _No response_  Python version Anaconda 2023.071  Bazel version 6.2.1  GCC/compiler version Visual Studio 2022 (build tools 14.36) + msys2x86_6420230718  CUDA/cuDNN version CUDA 11.8 + CUDNN 8.6.0 + TensorRT 8.5.3  GPU model and memory GTX 750 Ti 2GB  Current behavior? There are two type casting errors in reduction_gpu_kernels.cu.h under MSVC. One of them is fixed in https://github.com/tensorflow/tensorflow/pull/61339. Another is related to a TODO. in ColumnReduceKernel(), the TODO said the followings: > 1D array necessary due to bug in CUDA 9 compiler. > TODO(nluehr) revert to 2D array when compiler is ready. > This is to mimic the following, but without constructors: > __shared__ storage_type partial_sums[TF_RED_WARPSIZE * > (TF_RED_WARPSIZE + 1)]; Since latest version required CUDA 11, it's time to address the TODO and apply bug fix together.  Standalone code to reproduce the issue   Relevant log output ",2023-07-23T07:59:49Z,awaiting review comp:ops type:performance TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61357,"I think following changes can solve the TODO: line 351364:  line 392: `min(blockDim.y, num_rows  blockIdx.y * blockDim.y); // MSVC type casting fix` These changes can be compiled successfully in Windows CUDA environment. Can someone confirm if that's the meaning of the TODO?",Hi   Proposed PR has been merged now. Could you please check and close this issue. Thank you!!,The mentioned PR does not include my proposed changes. I am going to create a PR for this issue.,Are you satisfied with the resolution of your issue? Yes No,Hi    this caused a lot of build errors due to  https://github.com/tensorflow/tensorflow/pull/61638
1585,"以下是一个github上的tensorflow下的一个issue, 标题是(esrgan re-convert to tflite fail)， 内容是 ( 1. System information  OS Platform and Distribution: macOS 12.2.1; Apple M1; MacBook Pro  TensorFlow installation : pip3 install tensorflow  TensorFlow library: 2.13.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces some errors  4. (optional) RNN conversion support model is esrgan  5. (optional) Any other info / logs case1.  enable optimize like ""tf.lite.Optimize.DEFAULT"",  load model fail: Didn't find op for builtin opcode 'DEQUANTIZE' version '5' case2. disable optimize, set_shape 50x50, run fail msg: Something went wrong when copying input buffer to input tensor case3. disable optimize, set_shape 640x360, run fail msg: signal 11 (SIGSEGV): stack pointer is in a nonexistent map; likely due to stack overflow.  function crash: SuperResolution.cpp>DoSuperResolution() line at: TfLiteInterpreterAllocateTensors)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,xufuji456,esrgan re-convert to tflite fail," 1. System information  OS Platform and Distribution: macOS 12.2.1; Apple M1; MacBook Pro  TensorFlow installation : pip3 install tensorflow  TensorFlow library: 2.13.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces some errors  4. (optional) RNN conversion support model is esrgan  5. (optional) Any other info / logs case1.  enable optimize like ""tf.lite.Optimize.DEFAULT"",  load model fail: Didn't find op for builtin opcode 'DEQUANTIZE' version '5' case2. disable optimize, set_shape 50x50, run fail msg: Something went wrong when copying input buffer to input tensor case3. disable optimize, set_shape 640x360, run fail msg: signal 11 (SIGSEGV): stack pointer is in a nonexistent map; likely due to stack overflow.  function crash: SuperResolution.cpp>DoSuperResolution() line at: TfLiteInterpreterAllocateTensors",2023-07-21T06:51:14Z,stat:awaiting response stale type:performance TFLiteConverter TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61348,"Hi   The ESRGAN expects the input shape of `50x50x3`, hence we need to resize the input tensor before allocating the tensors.  Please find the gist modified to be comptatible for TF2.13 and let us know if helps. Thanks. "," Thank you for your reply.  if I want to convert into 640x360 resolution, how should I do? I see here support reconvert model https://github.com/tensorflow/examples/blob/master/lite/examples/super_resolution/ml/super_resolution.ipynb","Hi   The ESRGAN produces x4 Super Resolution Image from images. If you want to convert to 640x360 resolution, you may need to pass 160x90 image and modify the input accordingly.  and after the conversion, accordingly we need to to resize the tensor   and the pass the input image matching the size. Thanks.","Hello   It does work, thanks a lot.  ESRGAN has a good result, However, it takes a lot of times. If I want to use SRGAN with x2 super resolution, for example, convert 640x360 into 1280x720. How to convert the model into TensorFlowlite, that running on platform of Android.","Hi   Glad it worked. If you would like to use SRGAN, you have convert SRGAN into TFLite model using different conversion options like `from_saved_model` format and `from_keras_model`. Please refer to this document on different ways of model for converting to TFLite. Once the model is converted with specified model input dimesnions, it can be used for inference on Android. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
1205,"以下是一个github上的tensorflow下的一个issue, 标题是(AssertionError: Tried to export a function which references an 'untracked' resource. TensorFlow objects(e.g. tf.Variable))， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.10  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? As you can see in the code below, the operation of multiplying **attn** by **temperature**  at **MDTA** is being performed. And the **temperature** is defined by tf.Variable(). The model using the attention module below runs normally until training(model.fit()), but an AssertionError occurs when saving the model. I would appreciate it if you could tell me how to make the **temperature** variable trackable.  Standalone code to reproduce the issue   Relevant log output In the vscodeterminal  In the JupyterNoetebook )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,gymoon10,AssertionError: Tried to export a function which references an 'untracked' resource. TensorFlow objects(e.g. tf.Variable)," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.10  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? As you can see in the code below, the operation of multiplying **attn** by **temperature**  at **MDTA** is being performed. And the **temperature** is defined by tf.Variable(). The model using the attention module below runs normally until training(model.fit()), but an AssertionError occurs when saving the model. I would appreciate it if you could tell me how to make the **temperature** variable trackable.  Standalone code to reproduce the issue   Relevant log output In the vscodeterminal  In the JupyterNoetebook ",2023-07-21T06:26:47Z,stat:awaiting response type:bug stale comp:keras TF 2.10,closed,0,9,https://github.com/tensorflow/tensorflow/issues/61347,"Hi   In order to expedite the troubleshooting process, please provide the complete code snippet to reproduce the issue reported. Thank you.","Hi anjanappa  I edited the code part as you mentioned.  There is no problem with compiling the model and applying the .fit() method, but an error is occurring when saving the trained model with h5 format. I also confirmed that there was no problem when I didn't use tf.Variable(). Thank you for your hard work.","Hi  , If you are using custom layer and its __init__ method has `non_python` arguments then in order to make it serializable/deserializable you need to explicitly override get_config() and from_config() methods. Please refer the attached documentation for more details. You need to change the code to something like below.  Please try this and let us know.Thanks!"," , Please make a note that the above code suitable for .`keras` format. ","I want to save the full network, not the self.temperature alone"," , I have given an example of class MDTA. You need to do same for all subclassed Classes in your code in order to get the complete model saved. This is needed for subclassed models/layers only.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1270,"以下是一个github上的tensorflow下的一个issue, 标题是(Unbounded Memory leak when using tf.py_function in tf.data.Dataset.map())， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04, Google Colab  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8 / 8.6  GPU model and memory various, e.g. 2080ti, 3080ti mobile, Colab T4  Current behavior? Using tf.py_function in a function that is applied to a tf.data.Dataset via its map() function causes a (C++level) memory leak. In my real training with more complex code inside the py_function, this lead to the python script eventually consuming upwards of 30 GB of RAM during a model.fit() loop, despite taking less that 3GB of RAM during the initial epoch. tf.py_function also more generally causes memory leaks in all kinds of places. See the flags at the top of the linked Collab for details.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Pyrestone,Unbounded Memory leak when using tf.py_function in tf.data.Dataset.map()," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04, Google Colab  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version 11.8 / 8.6  GPU model and memory various, e.g. 2080ti, 3080ti mobile, Colab T4  Current behavior? Using tf.py_function in a function that is applied to a tf.data.Dataset via its map() function causes a (C++level) memory leak. In my real training with more complex code inside the py_function, this lead to the python script eventually consuming upwards of 30 GB of RAM during a model.fit() loop, despite taking less that 3GB of RAM during the initial epoch. tf.py_function also more generally causes memory leaks in all kinds of places. See the flags at the top of the linked Collab for details.  Standalone code to reproduce the issue   Relevant log output ",2023-07-20T20:36:51Z,stat:awaiting tensorflower type:bug type:performance TF 2.13,open,0,6,https://github.com/tensorflow/tensorflow/issues/61344,"see also: CC(Memory leak when using py_function inside tf.data.Dataset) and CC(memory leak in tf.py_function) (both closed, but the issue reappeared in 2.13.0)","Hi  , I have replicated the reported behaviour and attached gist for reference.  I can observe memory increased from  batch:0 to batch:3600. Needs to be investigated.","Note for people finding this issue in the meantime: As a temporary (or permanent I suppose) **workaround** is using `tf.numpy_function` instead of `tf.py_function` in tf.data.Dataset.map().   It behaves very similarly, except the function then receives and returns numpy arrays instead of eager tensors.   The only other notable difference is that `tf.numpy_function` doesn't support gradient computation (which probably shouldn't matter in a dataset.map() call).", Thanks for your solution.,", COuld you please try to check in the latest tensorflow v2.17 where it contains the Keras3.0 version and also tried using tf.numpy_function instead of tf.py_function & observed the code was executed as expected. Thank you!","I ran some tests with 2.13,2.15, and 2.17, apparently the memory leak issue was actually fixed somewhere between 2.13 and 2.15.0   However, between 2.15.0 and 2.17, something in `tf.data` or `tf.py_function` became noticeably slower, (less than 1800 steps per hour instead of 3000 before). *2.13.0*:  Script log   *2.15.0*:   Script log   *2.17.0*:     Script log  "
1681,"以下是一个github上的tensorflow下的一个issue, 标题是( RuntimeError: Quantization to 16x8-bit not yet supported for op: 'FLOOR_MOD'   )， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab  TensorFlow installation (pip package or built from source):  pip  TensorFlow library (version, if pip package or github SHA, if built from source):  2.12.0  2. Code I have following model.  Then I custom one of the dense layers like so   The only change to original layer is following code:  Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",large language model,soudabehmousavi99, RuntimeError: Quantization to 16x8-bit not yet supported for op: 'FLOOR_MOD'   ," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): google colab  TensorFlow installation (pip package or built from source):  pip  TensorFlow library (version, if pip package or github SHA, if built from source):  2.12.0  2. Code I have following model.  Then I custom one of the dense layers like so   The only change to original layer is following code:  Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-07-20T15:43:03Z,stat:awaiting response stale type:performance TFLiteConverter TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61343," If 16x8 quantization is not supported for some operators in the model, then the model still can be quantized, but unsupported operators kept in float. The following option should be added to the target_spec to allow this.  Could you please have a look at this doc and let us know if it helps? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1911,"以下是一个github上的tensorflow下的一个issue, 标题是(`tf.data.Dataset` only supports Python-style iteration in eager mode or within tf.function.)， 内容是 (The first is the map function:     def map_function(example):         feature_map = {""wav_raw"": tf.io.FixedLenFeature([], tf.string)}         parsed_example = tf.io.parse_single_example(example, features=feature_map)         wav_slice = tf.io.decode_raw(parsed_example[""wav_raw""], out_type=tf.float64)         wav_slice = tf.cast(wav_slice, tf.float32) / 2 ** 15         return wav_slice The second one is the training process:      for epoch in range(args.num_epochs):         trainset = tf.data.TFRecordDataset(args.trainset_tfrecords_path)         trainset = trainset.map(map_func=map_function,                                 num_parallel_calls=num_cpus)   num_parallel_calls should be number of cpu cores         trainset = trainset.shuffle(buffer_size=args.batch_size * 200, reshuffle_each_iteration=True)         trainset = trainset.batch(batch_size=args.batch_size)         trainset = trainset.prefetch(buffer_size=args.batch_size)          train_loss for each epoch         train_loss_epoch = []         train_loss = 0.0          record the train time for each epoch         start = time.time()          MASK参数         EMA_MODEL来选择mask的index         binary_mask = RandomMaskingGenerator(input_size,frame_length,mask_ratio)          bmr:0为掩码，1为未掩码；          bm_T:1为掩码,0为未掩码；          bm,bm_T = binary_mask()         for step, _input in enumerate(trainset):             bm, bm_T, _ = binary_mask.random_mask(_input.shape[0],alpha_e_max).totally_random_mask(_input.shape[0])             print(""_input"",_input)              print(""bm_shape"", bm.shape)              print(""bm_T_shape"", bm_T.shape)             loss_value = train_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lmx666-gif,`tf.data.Dataset` only supports Python-style iteration in eager mode or within tf.function.,"The first is the map function:     def map_function(example):         feature_map = {""wav_raw"": tf.io.FixedLenFeature([], tf.string)}         parsed_example = tf.io.parse_single_example(example, features=feature_map)         wav_slice = tf.io.decode_raw(parsed_example[""wav_raw""], out_type=tf.float64)         wav_slice = tf.cast(wav_slice, tf.float32) / 2 ** 15         return wav_slice The second one is the training process:      for epoch in range(args.num_epochs):         trainset = tf.data.TFRecordDataset(args.trainset_tfrecords_path)         trainset = trainset.map(map_func=map_function,                                 num_parallel_calls=num_cpus)   num_parallel_calls should be number of cpu cores         trainset = trainset.shuffle(buffer_size=args.batch_size * 200, reshuffle_each_iteration=True)         trainset = trainset.batch(batch_size=args.batch_size)         trainset = trainset.prefetch(buffer_size=args.batch_size)          train_loss for each epoch         train_loss_epoch = []         train_loss = 0.0          record the train time for each epoch         start = time.time()          MASK参数         EMA_MODEL来选择mask的index         binary_mask = RandomMaskingGenerator(input_size,frame_length,mask_ratio)          bmr:0为掩码，1为未掩码；          bm_T:1为掩码,0为未掩码；          bm,bm_T = binary_mask()         for step, _input in enumerate(trainset):             bm, bm_T, _ = binary_mask.random_mask(_input.shape[0],alpha_e_max).totally_random_mask(_input.shape[0])             print(""_input"",_input)              print(""bm_shape"", bm.shape)              print(""bm_T_shape"", bm_T.shape)             loss_value = train_",2023-07-20T06:34:55Z,stale comp:data comp:tf.function,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61340,"gif, I tried to execute the mentioned code and it was failing with the different error. Kindly find the gist of it here and provide the complete code, dependencies and the tensorflow version you are using which helps to analyse the issue in an effective way.  **tfds** is compatible with both eager and graph modes, but that doesn't mean they can be used the same way in either context.  If you want a tensor representation of the inputs, you can use **outputs = dataset.make_one_shot_iterator().get_next().** Also when you apply the `tf.function` decorator to a Python function that uses `tf.data.Dataset`, Tensorflow 2.0 will automatically convert the Python function into a graph that can be optimized for performance. This can lead to significant performance improvements, especially when working with large datasets. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Closing this issue as stale. Please reopen if this is still a valid request. Thank you!
800,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: cython_sources when installing tflite-model-maker)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code Yes  OS platform and distribution ubuntu 20  Mobile device _No response_  Python version  3.10.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? when trying to install `tflitemodelmaker` i get an error:   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ljmerza,AttributeError: cython_sources when installing tflite-model-maker, Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v2.13.0rc27g1cb1a030a62 2.13.0  Custom code Yes  OS platform and distribution ubuntu 20  Mobile device _No response_  Python version  3.10.6  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? when trying to install `tflitemodelmaker` i get an error:   Standalone code to reproduce the issue   Relevant log output _No response_,2023-07-20T02:21:10Z,stat:awaiting tensorflower type:build/install TF 2.13 TFLiteModelMaker,open,1,19,https://github.com/tensorflow/tensorflow/issues/61337,facing this on macOS too. Any solutions for this?, There are a few dependencies like numpy that need a specific version installation. Did you try to upgrade the numpy version by using` pip install numpy==1.23.4`. Could you also use colab fallback as a workaround? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you., I tried your fix and I'm still running into same error,Hi    There is a known issue of tflite model maker installation if you are using python >=3.10. Please use Python 3.9 or Mediapipe Model Maker as a workaround. Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,> Hi   >  > There is a known issue of tflite model maker installation if you are using python >=3.10. Please use Python 3.9 or Mediapipe Model Maker as a workaround. >  > Thanks. Also mediapipemodelmaker is broken. On windows I get this error during setup when it starts to get PyYAML dependency ,Hi   Could you please try again as I was successfully able to install mediapipe model maker on ubuntu(colab). Please find the gist. Thanks.,> Hi  >  > Could you please try again as I was successfully able to install mediapipe model maker on ubuntu(colab). Please find the gist. >  > Thanks. I confirm that mediapipe model maker installation fails on Windows with the error mentioned above. (Python 3.11),"Hi , I was able to install if I downgraded Python to 3.9.17, can you try that out to see if you are able to continue that way? If you are using conda you can do so like this: ",> Hi   >  > There is a known issue of tflite model maker installation if you are using python >=3.10. Please use Python 3.9 or Mediapipe Model Maker as a workaround. >  > Thanks. Downgraded from 3.10.9 to Python 3.9.6.  Still experiencing the same error. % python3 version Python 3.9.6,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Problem is still here unsolved. This automatic issue close should be disabled or set to a reasonable amount of time. ,"Hi wangg, assigning this to you to consolidate tflitemodelmaker issues. Thanks.",I got the same issue and was able to fix by using this hack: ,"I was able to solve that dependency issue by installing `cython` and `pyyaml` before installing the model maker, based on that answer on Stackoverflow, with:  Until the next dependency conflict...","What ended up working for me was a combination of  and 's solutions. This is what I did, in order "
1339,"以下是一个github上的tensorflow下的一个issue, 标题是(Using F1 Score for Model Checkpoint throws an error)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Google Colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory T4 15GB  Current behavior? Was using `tf.keras.metrics.F1Score` in `model.compile`. It works well, it will return f1_score and val_f1_score after every epoch. However, the problem arises if I also include `tf.keras.callbacks.ModelCheckpoint` in the `model.fit`, I got an error after the first epoch training. The error are `The following argument(s) are not supported with the native Keras format: ['options']` if I use `monitor='val_loss'` and `ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()` if I use `monitor='val_f1_score'` . Additional context: I am training a multilabel classification model. This might be the cause.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,kurkurzz,Using F1 Score for Model Checkpoint throws an error," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13  Custom code Yes  OS platform and distribution Google Colab  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory T4 15GB  Current behavior? Was using `tf.keras.metrics.F1Score` in `model.compile`. It works well, it will return f1_score and val_f1_score after every epoch. However, the problem arises if I also include `tf.keras.callbacks.ModelCheckpoint` in the `model.fit`, I got an error after the first epoch training. The error are `The following argument(s) are not supported with the native Keras format: ['options']` if I use `monitor='val_loss'` and `ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()` if I use `monitor='val_f1_score'` . Additional context: I am training a multilabel classification model. This might be the cause.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-20T01:10:25Z,stat:awaiting response type:bug stale comp:apis TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/61336,"Hi  , Please provide the complete code snippet to reproduce the issue reported. I've tried to reproduce the issue here, please provide the dataset or dummy data. Thank you!!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"I am having the same issue but with tracking MSE. This is also seen by others (https://stackoverflow.com/questions/76701617/thefollowingargumentsarenotsupportedwiththenativekerasformatopti). Appears to be related to ModelCheckpoint and passing an ""options"" argument which should no longer be present in the latest version of Keras.","Hello, This issue occurs when you try to use the F1Score metric with the default value for the weight argument in a multiclass or multilabel problem. This works only for binary classification problems. To make this work, you need to add 'macro' or 'weighted' depending on your data class imbalance in the F1Score instance during model compilation.  This should fix the issue. ","Hi  , In the current implementation,for F1score metric if we go with default value for argument `average = None` and the use case is either `multiclass classification` or `multilabel classification` then this problem occurs. With all other options like `average = 'weighted'` or `'micro'` or `'macro'` it works as intended. Attached gist for reference. If `average=None`, no averaging is performed and `result()` will return the score for each class which is causing the error.","Hi  , Since monitor = val_f1_score returns f1_score for each class when averaging=None, it is not possible to `save_best_only` model as it it ambiguous to compare the arrays of multiple values which is best.Hence the error but ambiguous. For this case I am trying to propose a PR to fall back to `save_best_only = False` instead of raising an exception.",", I tried to execute the mentioned code with latest TensorFlow version2.17 which contains Keras 3.0,and observed that code was executing without any error/failure. Kindly find the gist here. Thank you",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
853,"以下是一个github上的tensorflow下的一个issue, 标题是([oneDNN] Add 2 new patterns for layernorm fusion)， 内容是 (coauthor:   Following pattern is seen in 3 models. It looks similar to InstanceNorm pattern but it is actually LayerNorm based on the reduction axis. Under right conditions, this pattern will be fused as LayerNorm to improve performance. !image With this change we saw ~20% improvement in performance for the 3 models These are the repo links for 2 of the 3 models BERT_LARGE : https://github.com/mlperf/training/tree/master/language_model/tensorflow/bert BERT_BASE : https://github.com/googleresearch/bert The other pattern is seen in another customer model and brings in 1020% improvement !modellevel pattern example)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",large language model,kanvi-nervana,[oneDNN] Add 2 new patterns for layernorm fusion,"coauthor:   Following pattern is seen in 3 models. It looks similar to InstanceNorm pattern but it is actually LayerNorm based on the reduction axis. Under right conditions, this pattern will be fused as LayerNorm to improve performance. !image With this change we saw ~20% improvement in performance for the 3 models These are the repo links for 2 of the 3 models BERT_LARGE : https://github.com/mlperf/training/tree/master/language_model/tensorflow/bert BERT_BASE : https://github.com/googleresearch/bert The other pattern is seen in another customer model and brings in 1020% improvement !modellevel pattern example",2023-07-19T22:29:34Z,awaiting review ready to pull comp:grappler size:L,closed,0,1,https://github.com/tensorflow/tensorflow/issues/61332,"Hi , Can you please take a look at this PR? Thank you!"
1009,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow/core/common_runtime/gpu/gpu_util.cc:293] GPU->CPU Memcpy failed)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 1.15  Custom code Yes  OS platform and distribution Windows  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda version = 10.0 cudnn=7.6.4 _No response_  GPU model and memory Geforce RTX 4070 TI 12 GB _No response_  Current behavior? I am using  gpu geforce rtx 4070 ti 12 gb  i add in my training file      config1 = tf.compat.v1.ConfigProto()     config1.gpu_options.allow_growth = True     session = tf.compat.v1.Session(config=config1) But Nothing happen I get this issue   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,HAMZA12337,tensorflow/core/common_runtime/gpu/gpu_util.cc:293] GPU->CPU Memcpy failed, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 1.15  Custom code Yes  OS platform and distribution Windows  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda version = 10.0 cudnn=7.6.4 _No response_  GPU model and memory Geforce RTX 4070 TI 12 GB _No response_  Current behavior? I am using  gpu geforce rtx 4070 ti 12 gb  i add in my training file      config1 = tf.compat.v1.ConfigProto()     config1.gpu_options.allow_growth = True     session = tf.compat.v1.Session(config=config1) But Nothing happen I get this issue   Standalone code to reproduce the issue   Relevant log output _No response_,2023-07-19T12:46:52Z,stat:awaiting response type:bug stale comp:gpu TF 1.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61327,", We see that you are using tf version 1.15, 1.x is not actively supported, please update to 2.x and let us know if you are facing the same issue. And also you have provided the code which is suitable for 1.x version. Could you please try to migrate your TensorFlow code from TensorFlow 1.x to TensorFlow 2 with the help of this official document. https://www.tensorflow.org/guide/migrate Also please try to install the tensorflow latest stable version by referring to the official build documentation. https://www.tensorflow.org/install Thank you!",But i don't now why i am using tensorflow 1.15 with gpu == geforce gtx 1070 it's work but with gpu rtx 4070 no,",  Its unlikely for TF 1.x version to receive any bug fixes. There is a high possibility that this was fixed with later TF versions. Perhaps you can use latest tf versions for your case.  https://www.tensorflow.org/install Could you please try to migrate your TensorFlow code from TensorFlow 1.x to TensorFlow 2 with the help of this official document. Also **tf.compat.v1.Session** API was designed for TensorFlow v1. See the TensorFlow v1 to TensorFlow v2 migration guide for instructions on how to migrate the rest of your code. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1060,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution Kaggle  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to train model below  Also to ensure that all the input and output have proper shape I run the code below  As a result of this error, the model was unable to undergo the training process.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Armanasq,tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_6/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution Kaggle  Mobile device _No response_  Python version 3.10.12  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I am trying to train model below  Also to ensure that all the input and output have proper shape I run the code below  As a result of this error, the model was unable to undergo the training process.  Standalone code to reproduce the issue   Relevant log output ",2023-07-19T09:36:07Z,stat:awaiting response type:bug stale comp:core TF 2.12,closed,0,19,https://github.com/tensorflow/tensorflow/issues/61324,"Hi , In order to expedite the troubleshooting process, please provide the complete code snippet to reproduce the issue reported here. I've tried to reproduce the issue here, could you please take a look and let me know if i'm missing something .  Please find a similar issue here and let us know if it helps. Thank you!!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Same issue,"Hi  , Please share colab link or simple standalone code with supporting files to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!","Here are the projects: Rice Classification MNIST Classification Always at the first epoch, I have: `20230809 13:10:29.937931: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout/dropout/SelectV22TransposeNHWCToNCHWLayoutOptimizer` It seems that adding a Dropout after a MaxPooling2D, Conv2D creates this problem. `TF version 1.7.0rc1` Do you need more information?","I got the same issue.  One notebook shows the issue, while the other.BuildDeepLearningModel) does not. Both of them are transfer learning. What is interesting to me is that I got this issue only when I try to use EfficientNets. At first, it was working fine (like it did in the second notebook, `kagglexy.h5drugipokusaj`), but my newer attempts always have this issue. I tried to replicate architecture from 2nd notebook but it still doesn't remove the issue. So, as far as I can tell, this maybe has something to do with the input and processing part. The 2nd notebook does have `Dropout` after pretrained part, `GlobalAveragePooling2D` and `BatchNormalization` (in this order) and it was not an issue in my case.","> I got the same issue. One notebook shows the issue, while the other.BuildDeepLearningModel) does not. >  > Both of them are transfer learning. What is interesting to me is that I got this issue only when I try to use EfficientNets. At first, it was working fine (like it did in the second notebook, `kagglexy.h5drugipokusaj`), but my newer attempts always have this issue. I tried to replicate architecture from 2nd notebook but it still doesn't remove the issue. So, as far as I can tell, this maybe has something to do with the input and processing part. >  > The 2nd notebook does have `Dropout` after pretrained part, `GlobalAveragePooling2D` and `BatchNormalization` (in this order) and it was not an issue in my case. UPDATE: I managed to fix the issue by recreating the architecture and adding `training=False`. **First version**:  **Second version**:  The final version similar to 2nd, but with `x = base_model(preprocessed_input)` changed to `x = base_model(preprocessed_input, training=False)`. Adding this fixed the issue in second version. The information for these changes was found in keras's documentation for transfer learning.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Confirmed the error even after the modification by  (similar to version 2, using MobileNet V2 for transfer learning). Here the code:   And the output:  TF 2.13.0 on cuDNN 8.6.0 and CUDA 12.2 on Linux x86_64. **Update: same code does not generate any error on MacBookPro M1 Pro with TF 2.13.0 and Metal backend**","anjanappa This bug appears in many open issues, including 61687, has there been any progress on fixing the issue?",fischer I think it is related to adding dropout after the 2D CNN. after removing them the error has been fixed. However I am not sure. I decided to use PyTorch.,"Same issue here on TF 2.14 with a custom model, with layers like below as others have mentioned previously: ","I have similar/same error: ""20231103 17:20:43.612803: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_10/dropout_31/dropout/SelectV22TransposeNHWCToNCHWLayoutOptimizer"" I can confirm it goes away when I comment out the dropout after the MaxPooling2D layers. ","See edumotya's response in CC(E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] layout failed: Invalid argument: size of values 0 does not match size of permutation 4.), as he suggests disabling the optimizer. This appears to have worked around the issue for me, although there's still something to be understood or resolved in the optimizer and/or Dropout's channelfirst vs channellast approach when the optimizer is enabled.","> Confirmed the error even after the modification by  (similar to version 2, using MobileNet V2 for transfer learning). Here the code: >  >  >  > And the output: >  >  >  > TF 2.13.0 on cuDNN 8.6.0 and CUDA 12.2 on Linux x86_64. >  > **Update: same code does not generate any error on MacBookPro M1 Pro with TF 2.13.0 and Metal backend** Hi  , I have tested your code and it seems working fine on colab though. Please check the gist and confirm . Hi  , Could you please confirm whether this is still an issue. If so please submit a minimal code snippet to reproduce the issue.  Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"using `tf.nn.dropout(x, 0.5)` throws `E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inencoder_decoder_1/decoder_1/decoder_block_1/dropout/SelectV22TransposeNHWCToNCHWLayoutOptimizer` However, replacing it with `tf.keras.layers.Dropout(0.5)` resolved the issue for me.  TF version: 2.17.0"
1082,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Lite Converter wraps unpack operator with dequantize/quantize)， 内容是 ( System information  Linux Ubuntu 20.04  TensorFlow installed from: pip source  TensorFlow versions: 2.12.0current master   Code Provide code to help us reproduce your issues using one of the following options:   Failure after conversion Input Model: !Screenshot from 20230719 110535 Output Model: !Screenshot from 20230719 112839 Behaviour in TF 2.11 and below is that no dequantize/quantize ops appear, which is expected.    Other info The conversion started failing with version TF 2.12.0. Note that the conversion succeeds intermittently when converting the same network many times, but on average it fails. This intermittent behaviour is still present if one runs the converter on a single core and keeps the representative dataset constant. Similar issues seems to be present when converting split operators as well. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,willisacs-arm,TensorFlow Lite Converter wraps unpack operator with dequantize/quantize," System information  Linux Ubuntu 20.04  TensorFlow installed from: pip source  TensorFlow versions: 2.12.0current master   Code Provide code to help us reproduce your issues using one of the following options:   Failure after conversion Input Model: !Screenshot from 20230719 110535 Output Model: !Screenshot from 20230719 112839 Behaviour in TF 2.11 and below is that no dequantize/quantize ops appear, which is expected.    Other info The conversion started failing with version TF 2.12.0. Note that the conversion succeeds intermittently when converting the same network many times, but on average it fails. This intermittent behaviour is still present if one runs the converter on a single core and keeps the representative dataset constant. Similar issues seems to be present when converting split operators as well. ",2023-07-19T09:31:11Z,stat:awaiting tensorflower type:bug TFLiteConverter ModelOptimizationToolkit TF 2.12,open,0,12,https://github.com/tensorflow/tensorflow/issues/61323,arm Did you try with the latest TF version 2.13 and let us know the outcome? Have a look at this reference for more information on quantization. Thank you!,Hi yes the behaviour is the same for all versions above 2.12,Are you satisfied with the resolution of your issue? Yes No,accidentally closed issue,Hi arm  I did observe that it does not add Quantize/Dequantize stubs for intermittent runs.  Could you please look into this issue? Please find the reproducible gist in TF 2.13. Thanks.,"Hi arm, so currently the quantization is unable to quantize the unpack operator, so it actually processes that op in the original bit size. Would you like a feature request to make it quantizable? Are you working with a system that requires 8bit operations Only?","Hi, just to reiterate, the quantization sometimes works already if one just tries it enough times, so this doesn't seem to require a new feature, unless the fact that the quantization sometimes works is the bug here. It also works in patches before 2.12.0.  Yes I am working with a system that requires int 16 or int 8 activations. ",Also if I understand it correctly the documentation says that the converter should throw an error if an operation cannot be quantized? https://www.tensorflow.org/lite/performance/post_training_quantizationinteger_only,"Hi arm,  yeah that documentation is incorrect, we have not finalized on intended behavior so we have not updated it to prevent further confusion. That being said, ""the quantization sometimes works already if one just tries it enough times"" doesn't sound good, is there any way you can provide us information on when it starts working? like... What is your model where this happens (especially which ops are included), and after how many times does it start working? If you can show us the converted state after each time, that'll also be great. Thanks!","> Hi arm >  > I did observe that it does not add Quantize/Dequantize stubs for intermittent runs. >  >  Could you please look into this issue? >  > Please find the reproducible gist in TF 2.13. >  > Thanks. Ah alright, thanks.  The model is the one that was provided in the first comment in this issue, it has an unpack/unstack operator. It has also been provided neatly by pjpratik in the gist quoted in this reply. To reproduce the issue, run the notebook/gist and then repeat the last 2 steps until a quantized operator without dequantize/quantize ops appear in the Netron window.  There seems to just be a random chance every time one runs the converter to get a functioning quantized unstack operator. A speculation would be that there's a memory overwrite somewhere. The behaviour is present even when running the converter on a single core and while keeping the representative dataset constant. The model file to convert was also kept constant. ","I was able to reproduce the somewhat random behavior after 7 attempts with the attached gist. , can you please take a look? Thanks.",did this has solution? i got this promblem too
710,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow and onednn logs)， 内容是 (Hi,      I am trying to analyse the call flow of tensorflow and onednn. I am setting up environment vars as  export ONEDNN_VERBOSE=1 export TF_CPP_MAX_VLOG_LEVEL=1   export omp_num_threads=1 I am collecting the logs. I was trying to map _mklops with onednn primitive. But here the onednn and mkl calls are random in log that is after 10 mkl calls I am seeing 20 onednn calls.  Is there any flags need to be set to get logs with correct mapping  or do we need to map manually filtered_intel_log.txt)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,akote123,Tensorflow and onednn logs,"Hi,      I am trying to analyse the call flow of tensorflow and onednn. I am setting up environment vars as  export ONEDNN_VERBOSE=1 export TF_CPP_MAX_VLOG_LEVEL=1   export omp_num_threads=1 I am collecting the logs. I was trying to map _mklops with onednn primitive. But here the onednn and mkl calls are random in log that is after 10 mkl calls I am seeing 20 onednn calls.  Is there any flags need to be set to get logs with correct mapping  or do we need to map manually filtered_intel_log.txt",2023-07-19T09:17:40Z,stat:awaiting tensorflower type:support comp:mkl,open,0,11,https://github.com/tensorflow/tensorflow/issues/61322,"Hi  , could you share the original verbose log, thanks!","Hi , I have uploaded here  vit_intel_log.zip  ","I guess the reason is that _mklops are logged by <<, where the outputs are fully buffered if they are redirected to a file, while oneDNN verbose always flush stdout immediately: https://github.com/search?q=repo%3Aoneapisrc%2FoneDNN+fflush&type=code"," , one more observation what I found is some ops are common_runtime/eager/execute./executor.cc , here I am not able to understand why there is two path for execution ","Hi , from the log I can see you are using xla, so for ops can not be jitted, they come to common_runtime/eager/execute.cc, otherwise they come to common_runtime/executor., suggest that you use trace viewer to trace executions.  "," , do we have file location tensorflow source code where checking happen whether to go common_runtime/eager/execute.."," , you can refer to this article: https://whatdhack.medium.com/tensorflowgraphgraphdefgrapplerxlamlirllvmetc615191e96ebc, see XLA Flow part and call stack"," , In tensorflow the single model can go in both XLA and oneDNN or is it like either it will use XLA or oneDNN only","Both. There may be different scenarios:  1. Some parts of the model go in XLA path, some parts go in oneDNN path. 2. Intel recently submitted a pilot PR to accelerate XLA’s Dot op with oneDNN. You can refer to this RFC: https://docs.google.com/document/d/1ZzMcrjxITJeN2IjjgbzUjHh4W1YgDUus3j25Dvn9ng/edit"," ,Thank you for the pointers I will got through it . Actually for pretrained models how we can enable XLA  both for inference and transfer learning","same as training, you can refer to https://www.tensorflow.org/xlaenable_xla_for_tensorflow_models"
690,"以下是一个github上的tensorflow下的一个issue, 标题是(import tensorflow error)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution windows 10  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? not able to import tensorflow  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,vinayk114,import tensorflow error, Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.12.0  Custom code Yes  OS platform and distribution windows 10  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? not able to import tensorflow  Standalone code to reproduce the issue   Relevant log output ,2023-07-18T15:38:04Z,stat:awaiting response type:build/install stale subtype:windows TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61316,"Hi   There is numpy dependency, please check if you've installed correct numpy version . https://github.com/tensorflow/tensorflow/blob/0db597d0d758aba578783b5bf46c889700a45085/tensorflow/tools/pip_package/setup.pyL97 You can install numpy by running **pip install numpy==1.22**. The compatible version for tensorflow v2.12 is numpy >= 1.22, <1.24. Please let us know if that helps? Thank you!!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
863,"以下是一个github上的tensorflow下的一个issue, 标题是(ImportError: undefined symbol after install)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 1.7.0  Custom code No  OS platform and distribution Linux4.14.0xilinxv2018.3armv7lwithpynqlinuxv2.6WFH  Mobile device no  Python version 3.6.5  Bazel version 0.10.0 (git)  GCC/compiler version GCC 7.3.0  CUDA/cuDNN version no  GPU model and memory _No response_  Current behavior? I'm facing with the ImportError  Undefined symbol when trying to import tensorflow after successfully compiling from source and installed Tensorflow 1.7.0 on a 32 bit architecture.   Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,helmunt1998,ImportError: undefined symbol after install, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 1.7.0  Custom code No  OS platform and distribution Linux4.14.0xilinxv2018.3armv7lwithpynqlinuxv2.6WFH  Mobile device no  Python version 3.6.5  Bazel version 0.10.0 (git)  GCC/compiler version GCC 7.3.0  CUDA/cuDNN version no  GPU model and memory _No response_  Current behavior? I'm facing with the ImportError  Undefined symbol when trying to import tensorflow after successfully compiling from source and installed Tensorflow 1.7.0 on a 32 bit architecture.   Standalone code to reproduce the issue   Relevant log output ,2023-07-18T15:04:06Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61315,"From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:    * For TFGPU  See point 1    * For TFCPU  See point 2  **1. Installing **TensorFlowGPU** (TF) prebuilt binaries** Make sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.    * If you have above configuration and using _**Windows**_ platform      * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.     * Refer windows setup guide.   * If you have above configuration and using _**Ubuntu/Linux**_ platform      * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.     * Refer linux setup guide.   * If error still persists then, apparently your CPU model does not support AVX instruction sets.     * Refer hardware requirements.  **2. Installing **TensorFlow** (TF) CPU prebuilt binaries** *TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.* Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load. Apparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:    * Try Google Colab to use TensorFlow.       * The easiest way to use TF will be to switch to google colab. You get preinstalled latest stable TF version. Also you can use   to install any other preferred TF version.       * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.       * All you need is a good internet connection and you are all set.    * Try to build TF from sources by changing CPU optimization flags. *Please let us know if this helps.*", You are using an older version of TF which is not actively supported. Could you upgrade to the latest TF version and follow this migration document to know more about this.  The older version might show these issues as many apis are being deprecated. Please let us know if that help? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1091,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow 2.13 distributed training fail)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Linux Ubuntu 20.04.3  Mobile device Linux Ubuntu 20.04.3  Python version 3.8.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA 11.7, cuDNN 8.6  GPU model and memory 3x NVIDIA GeForce RTX 3090  Current behavior? When trying to run multiple distributed trainings one after another, one of them fails with an `Collective ops is aborted by: ...` error.  The reproducer attached to this issue produces the following error:  When run with TF 2.12 there is no such error. The original code where I have encountered this problem results in  but I wasn't able to reproduce this with a small code snippet.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,nikita-savelyevv,TensorFlow 2.13 distributed training fail," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version 2.13.0  Custom code No  OS platform and distribution Linux Ubuntu 20.04.3  Mobile device Linux Ubuntu 20.04.3  Python version 3.8.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version CUDA 11.7, cuDNN 8.6  GPU model and memory 3x NVIDIA GeForce RTX 3090  Current behavior? When trying to run multiple distributed trainings one after another, one of them fails with an `Collective ops is aborted by: ...` error.  The reproducer attached to this issue produces the following error:  When run with TF 2.12 there is no such error. The original code where I have encountered this problem results in  but I wasn't able to reproduce this with a small code snippet.  Standalone code to reproduce the issue   Relevant log output ",2023-07-18T14:56:01Z,stat:awaiting tensorflower type:bug comp:dist-strat TF 2.13,open,5,15,https://github.com/tensorflow/tensorflow/issues/61314,I have the same issue source binary tensorflow 2.13.0 Python 3.9.1 CUDA 12.1.11 CUDnn 8.9.1.23 GPU 3x NVIDIA V100,"Hi savelyevv , From your attached code snippet i have changed this line: `train_dataset = mnist_test.cache().shuffle(10000).batch(batch_size) `  to : `train_dataset = mnist_train.cache().shuffle(10000).batch(batch_size) ` and then executed the code on a GCP VM with 4 GPUs. The logs are attached below.  When `devices=1` the code executes fine for me. When `devices>=2` for filling shuffle buffer its taking very much time. This should not be the case.There seems some problem wrt performance but not sure whether your reported behaviour able to replicable or not since I have stopped as the code taking too much time. The code used is attached as gist here.",I have also tested the same code snippet attached by savelyevv and found program hangs when devices=2 started executing. Logas attached below.  Tested code attached here as colab gist. Thanks!," Thanks for reaching out! I used `mnist_test` intentionally to slightly speed up the reproduction. I agree with your results. For me, when order of devices is set to `1, 2, 3`, the case `devices=2` also hangs as you describe. For the order `1, 3, 2`, the case `devices=2` produces the error I've attached in the ticket. Since the machine you run the code on has 4 GPUs, I would suppose that setting the order to something like `1, 4, 3, 2` would also lead to the error I attached. Anyway, I would assume that these two problems (hanging and throwing error) are related and may have the same cause.",Adding to distributed training hanging with `tensorflow==2.13.1` Small fashion mnist example to reproduce jit_compiled model fails to train and hangs:  `,Same issue here! Using 4GPU for distributed training on Ubuntu 22.04 with Tensorflow 2.13 hangs at the “compiled cluster using the XLA” line. Issue solved by downgrading to 2.12 ,"Same for me with RTX 8000 and A6000 setup in MirrorStrategy with NCCL and Hierarchical CrossDeviceOps. I get a huge block of `tensorflow/core/framework/local_rendezvous.cc:405 Local rendezvous recv item cancelled.` before first epoch, but it doesn't hang up for me and I can successfully train the model. I was a bit too excited with 2.13 fixing the ""placeholder tensor"" warning from 2.12. Would be nice to get some feedback from the team if reproducible.","`Device /job:localhost/replica:0/task:0/device:GPU:1 is joining a group with size 2, but that group has size 3 (group_key=1)` means that when you are running the function with 2 GPUs, the collective op from previous function call with 3 GPUs might still be pending. Generally it's not a good idea to create multiple `tf.dist.Strategy` in sequence in a production job, as they will share the same collective key and is very likely to cause arbitrary collapse between multiple allreduces. For this case, try to reset context at the beginning of each test case. Example: https://github.com/tensorflow/tensorflow/blob/2a7efd891d3b16ef82b462d76fd9e61d111bf901/tensorflow/python/distribute/mirrored_strategy_test.pyL355","I am facing similar issue described by dev. Ubuntu 22.04 and Tensorflow 2.13.0, but running from docker image using `gcr.io/deeplearningplatformrelease/tf2gpu.213.py310:m111` as a base, on Vertex AI, with 4 x T4 GPUs. I trained with mirror strategy, which defaults to NCCLAllReduce. The training hangs with 100% GPU and memory utilization. I turned on `NCCL_DEBUG=INFO`, and here is what I have in my logs: ","> Same issue here! Using 4GPU for distributed training on Ubuntu 22.04 with Tensorflow 2.13 hangs at the “compiled cluster using the XLA” line. Issue solved by downgrading to 2.12 You may refer to my issue in CC(Keras.fit stuck/error in TensorFlow 2.13/2.14 (TPU is fine, inference on GPU is fine, 2.11 GPU is fine)) . Currently, using RING instead of NCCL is a temporary workaround (https://github.com/edwardyehuang/iSeg/blob/master/utils/distribution_utils.py). Another workaround (2.13 only atm), use `conda install c condaforge tensorflowgpu`, instead docker or pip. Besides, if anyone has a tfnightly GPU wheel on Mar 17 and April 27, please share it with me so I can test it and see if the pull request https://github.com/tensorflow/tensorflow/pull/60001 or https://github.com/tensorflow/tensorflow/pull/59424 cause this issue.","> > Same issue here! Using 4GPU for distributed training on Ubuntu 22.04 with Tensorflow 2.13 hangs at the “compiled cluster using the XLA” line. Issue solved by downgrading to 2.12 >  > You may refer to my issue in CC(Keras.fit stuck/error in TensorFlow 2.13/2.14 (TPU is fine, inference on GPU is fine, 2.11 GPU is fine)) . >  > Currently, using RING instead of NCCL is a temporary workaround (https://github.com/edwardyehuang/iSeg/blob/master/utils/distribution_utils.py). >  > Another workaround (2.13 only atm), use `conda install c condaforge tensorflowgpu`, instead docker or pip. >  > Besides, if anyone has a tfnightly GPU wheel on Mar 17 and April 27, please share it with me so I can test it and see if the pull request CC([NVIDIA TF] CollectiveAllToAllV2 + NCCL alltoall fixes) or CC([NVIDIA XLA] Improve allreduce reassociation) cause this issue. Another thing worth to attention: Why the thirdparty (condaforge) conda build can avoid this issue? (the TensorFlow in the docker image is directly installed from pip)",same issue here. anyone finds solutions?,Upgrade the NVIDIA driver >= 545 and the issue should be addressed,"I got a similar error on the NVIDIA GPU while using tensorflowfederated and nest_asyncio packages. The error appeared when I updated tensorflowfederated package version from 0.38.0 to 0.73.0. I tried updating nest_asyncio, but it didn't help. So I just muted that message.  `import os` `os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""1""` Check for details.","Similar error. Fixed it by removing the steps_per_epoch argument from model.fit() and model.evaluate() import sys from matplotlib import pyplot from keras.utils import to_categorical from keras.models import Sequential from keras.layers import Conv2D from keras.layers import MaxPooling2D from keras.layers import Dense from keras.layers import Flatten from keras.optimizers import SGD from tensorflow.keras.preprocessing.image import ImageDataGenerator import tensorflow as tf import numpy as np physical_devices = tf.config.list_physical_devices('GPU') try:   tf.config.experimental.set_memory_growth(physical_devices[0], True) except:    Invalid device or cannot modify virtual devices once initialized.   pass   define cnn model def define_model():  model = Sequential()  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))  model.add(MaxPooling2D((2, 2)))  model.add(Flatten())  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))  model.add(Dense(1, activation='sigmoid'))   compile model  opt = SGD(learning_rate=0.001, momentum=0.9)  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])  return model  create data generator datagen = ImageDataGenerator(rescale=1.0/255.0) model = define_model()  prepare iterators train_it = datagen.flow_from_directory('/workspace/workspace/cats_and_dogs_data/dogsvscats/train/',  class_mode='binary', batch_size=64, target_size=(200, 200)) test_it = datagen.flow_from_directory('/workspace/workspace/cats_and_dogs_data/dogsvscats/test1/',  class_mode='binary', batch_size=64, target_size=(200, 200))  fit model history = model.fit(train_it, validation_data=test_it, epochs=20, verbose=1)  evaluate model _, acc = model.evaluate(test_it, verbose=1) print('> %.3f' % (acc * 100.0))"
804,"以下是一个github上的tensorflow下的一个issue, 标题是(snapshoting failure on dataset made from generator)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v2.12.0rc112g0db597d0d75  Custom code Yes  OS platform and distribution Linux 4e51bcd72cb8 5.15.109 (Colab)  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Simple snapshoting op with sharding fails when applied to a generatorbased dataset.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,maciejskorski,snapshoting failure on dataset made from generator, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version v2.12.0rc112g0db597d0d75  Custom code Yes  OS platform and distribution Linux 4e51bcd72cb8 5.15.109 (Colab)  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Simple snapshoting op with sharding fails when applied to a generatorbased dataset.  Standalone code to reproduce the issue   Relevant log output ,2023-07-18T14:37:30Z,stat:awaiting tensorflower type:bug comp:data TF 2.12,open,0,2,https://github.com/tensorflow/tensorflow/issues/61313,"  I was able to replicate this issue on colab using TF v2.12 ,2.13 and tfnightly. Please find the attached gists. Thank you!","Hi. I am a developer looking to get into open source. Have been using Tensorflow for a long time and also thinking of contributing to the repository. I had some questions to ask regarding this issue.   According to assesment is this a good issue to start on.   If yes, is there some guide on how I can test my changes on code for the same code, locally. "
1859,"以下是一个github上的tensorflow下的一个issue, 标题是(xla_cpu_gpu_device: MSVC compile errors)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Windows 10 22H2  Mobile device _No response_  Python version Anaconda 2023.071  Bazel version 6.2.1  GCC/compiler version Visual Studio 2022 (build tools 14.36) + msys2x86_6420230718  CUDA/cuDNN version CUDA 11.8 + CUDNN 8.6.0 + TensorRT 8.5.3  GPU model and memory GTX 750 Ti 2GB  Current behavior? This issue required two fixes. First, `external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py` adds too many unrelated include path to compilation command. Related scripts or header dependencies need to be fixed. Minimum command is just like: `nvcc v c x=c++ std=c++17 tensorflow/compiler/jit/xla_cpu_device. .,bazelout/x64_windowsopt/bin,external/eigen_archive, external/com_google_absl,external/com_google_protobuf/src,external/farmhash_archive/src,external/llvmproject/llvm/include, external/llvmraw/llvm/include,external/llvmproject/mlir/include,bazelout/x64_windowsopt/bin/external/llvmproject/mlir/include, external/tf_runtime/include o bazelout/x64_windowsopt/bin/tensorflow/compiler/jit/_objs/xla_cpu_device/xla_cpu_device.obj` Second, `nvcc` will pass the above command to `cl.exe`. Then MSVC will throw some syntax errors and stop. If I use `clangcl` provided by Visual Studio, some warnings may appear but the `.obj` compilation is successful. Following linux build migration to clang, I think the compiler path of `msvc_wrapper_for_nvcc.py` can change to `clangcl` to avoid syntax errors.  Standalone code to reproduce the issue   Rel)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,johnnkp,xla_cpu_gpu_device: MSVC compile errors," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Windows 10 22H2  Mobile device _No response_  Python version Anaconda 2023.071  Bazel version 6.2.1  GCC/compiler version Visual Studio 2022 (build tools 14.36) + msys2x86_6420230718  CUDA/cuDNN version CUDA 11.8 + CUDNN 8.6.0 + TensorRT 8.5.3  GPU model and memory GTX 750 Ti 2GB  Current behavior? This issue required two fixes. First, `external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py` adds too many unrelated include path to compilation command. Related scripts or header dependencies need to be fixed. Minimum command is just like: `nvcc v c x=c++ std=c++17 tensorflow/compiler/jit/xla_cpu_device. .,bazelout/x64_windowsopt/bin,external/eigen_archive, external/com_google_absl,external/com_google_protobuf/src,external/farmhash_archive/src,external/llvmproject/llvm/include, external/llvmraw/llvm/include,external/llvmproject/mlir/include,bazelout/x64_windowsopt/bin/external/llvmproject/mlir/include, external/tf_runtime/include o bazelout/x64_windowsopt/bin/tensorflow/compiler/jit/_objs/xla_cpu_device/xla_cpu_device.obj` Second, `nvcc` will pass the above command to `cl.exe`. Then MSVC will throw some syntax errors and stop. If I use `clangcl` provided by Visual Studio, some warnings may appear but the `.obj` compilation is successful. Following linux build migration to clang, I think the compiler path of `msvc_wrapper_for_nvcc.py` can change to `clangcl` to avoid syntax errors.  Standalone code to reproduce the issue   Rel",2023-07-18T07:28:01Z,stat:awaiting response type:build/install stale subtype:windows TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61310,The priority of this issue is higher than https://github.com/tensorflow/tensorflow/issues/60397. Some errors of that issue may be disappeared under `clangcl`.,"I know that 2.14 has applied fixes to `msvc_wrapper_for_nvcc.py`. It at least works up to 13000 compile actions with the following changes to `msvc_wrapper_for_nvcc.py`:  Then, the compilation stop at `tensorflow/compiler/xla/service/gpu/hlo_op_profiles.h` because the pb string is too long over MSVC limitation.",I also tried to setup LLVM 17.0.0rc1 and use `clangcl` instead. However it has errors such as `constexpr variable 'kRepHeaderSize' must be initialized by a constant expression`. Seems `clangcl` isn't ready for Windows build yet.,"Hi , can you please try LLVM 15.0.7. and refer to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/windows/cpu/pip/build_tf_windows_clangcl.sh",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1257,"以下是一个github上的tensorflow下的一个issue, 标题是(Parse output of `mobile_ssd_v2_float_coco.tflite`)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.11.1  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device Android  Python version _No response_  Bazel version 6.2.0  GCC/compiler version 12  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to use the model mobile_ssd_v2_float_coco.tflite on a C++ application, I'm able to execute the inference and get the results. Based on the Netron app I see that its output is: !image But I couldn't find an example code showing how to parse this output. I tried to look into https://github.com/tensorflow/tensorflow/issues/29054 and https://github.com/tensorflow/tensorflow/issues/40298 but the output of the model is different from the one provided here. Do you have any example code available in Java, Python, or even better in C++ to parse this model output?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,caiotoledo-lunasystems,Parse output of `mobile_ssd_v2_float_coco.tflite`," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.11.1  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device Android  Python version _No response_  Bazel version 6.2.0  GCC/compiler version 12  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I'm trying to use the model mobile_ssd_v2_float_coco.tflite on a C++ application, I'm able to execute the inference and get the results. Based on the Netron app I see that its output is: !image But I couldn't find an example code showing how to parse this output. I tried to look into https://github.com/tensorflow/tensorflow/issues/29054 and https://github.com/tensorflow/tensorflow/issues/40298 but the output of the model is different from the one provided here. Do you have any example code available in Java, Python, or even better in C++ to parse this model output?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-17T13:53:12Z,stat:awaiting response type:support stale comp:lite TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61299,"Hi lunasystems  The TensorFlow Lite Object Detection Demo example uses different models trained on COCO dataset.  In the example, TensorFlow Lite Task Library is used to parse the output which provides simple interface to use. Please check the post process function for the reference which is used by library to parse the output. Also, please check the demo example for  C++ Vision Task APIs. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,", Thanks for the support!",Are you satisfied with the resolution of your issue? Yes No
1440,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to hide TPUs)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.12  Custom code No  OS platform and distribution Kaggle Notebooks  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Unable to hide TPUs from TensorFlow. The consequence of this is that if we want to use JAX along with TensorFlow, only one of them will be able to initialize the TPU system, and the other will fail. We won't be able to use `tfds`, `tf.image` or any TF operation per se if we can't hide TPUs from being used by TF. I want all these operations to run on CPU only, and leverage JAX for TPU. Here is the code to test it on a TPU machine:  This also doesn't work:   Standalone code to reproduce the issue ```shell import tenorflow as tf tf.config.set_visible_devices([], device_type=""TPU_SYSTEM"") tf.config.set_visible_devices([], device_type=""TPU"") print(tf.config.list_logical_devices())  This also doesn't work: physical_devices = tf.config.list_physical_devices() tf.config.set_visible_devices(physical_devices[0], 'CPU')  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,AakashKumarNain,Unable to hide TPUs," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.12  Custom code No  OS platform and distribution Kaggle Notebooks  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Unable to hide TPUs from TensorFlow. The consequence of this is that if we want to use JAX along with TensorFlow, only one of them will be able to initialize the TPU system, and the other will fail. We won't be able to use `tfds`, `tf.image` or any TF operation per se if we can't hide TPUs from being used by TF. I want all these operations to run on CPU only, and leverage JAX for TPU. Here is the code to test it on a TPU machine:  This also doesn't work:   Standalone code to reproduce the issue ```shell import tenorflow as tf tf.config.set_visible_devices([], device_type=""TPU_SYSTEM"") tf.config.set_visible_devices([], device_type=""TPU"") print(tf.config.list_logical_devices())  This also doesn't work: physical_devices = tf.config.list_physical_devices() tf.config.set_visible_devices(physical_devices[0], 'CPU')  Relevant log output _No response_",2023-07-17T05:53:45Z,stat:awaiting tensorflower type:bug comp:tpus TF 2.12,open,1,10,https://github.com/tensorflow/tensorflow/issues/61293," Please follow this guide to know more about the usability of TPU using TF. I tried to replicate the issue as mentioned above, and didn't face the error reported. I was able to run the code as expected. Could you please have a look at this gist and confirm the same. In case you are using multiple TPUs you can also detect the TPUs as below;   Thank you!", I am not asking `How to use TPUs with TF?`. I have different problem on hand. I have a TPU cluster but I don't want TF to use it. I don't want TF to use any of the TPUs for processing. I want to hide the TPUs and move everything to CPU only. Please go through the issue again for the details, Sorry for the misread.   Could you please have a look at this issue. Thank you!, any suggestions?,"`tf.config.set_visible_devices`  `device_type` works for `CPU` or `GPU`, other devices will be left unaltered. For TPUs, you need to configure the logical devices as something like below. ",Thanks for the answer but this doesn't work. Error below ,Could you please attach the outcome of `tf.config.list_logical_devices()`,I have already done that in the code snippet at the top,Any updates on this?,"Team is currently looking into this. Meantime, can you please check by calling `context._reset_context()` to remove the TPUs from the logical device list. "
832,"以下是一个github上的tensorflow下的一个issue, 标题是(Build error with Clang 16)， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version master branch  Custom code No  OS platform and distribution Fedora 38  Mobile device _No response_  Python version _No response_  Bazel version Automatically chosen via Bazelisk  GCC/compiler version clang version 16.0.5 (Fedora 16.0.51.fc38)  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Cannot build `tfcompile` from the sources on the current master with Clang 16.0.5 (from Fedora repos).  Standalone code to reproduce the issue   Relevant log output  ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,zamazan4ik,Build error with Clang 16, Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version master branch  Custom code No  OS platform and distribution Fedora 38  Mobile device _No response_  Python version _No response_  Bazel version Automatically chosen via Bazelisk  GCC/compiler version clang version 16.0.5 (Fedora 16.0.51.fc38)  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Cannot build `tfcompile` from the sources on the current master with Clang 16.0.5 (from Fedora repos).  Standalone code to reproduce the issue   Relevant log output  ```,2023-07-16T12:53:20Z,type:build/install subtype: ubuntu/linux TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61289,"Hi  , Thanks for reporting.I have to setup required environment and then will try to replicate the issue and let you know. Thanks",Just to note  the issue can be easily fixed by adding the missing `cstdint` header and using `std::uint64_t` and `std::size_t` types (I did just this on my local TF copy).,"Hi  , If you are willing to contribute please feel free to create a Pull request. Thanks!",had the same issue installing 2.11.1 and 2.12.1 (only ones I tested). the solution was to add `include ` to tensorflow/tsl/lib/io/cache.h as outlined in the merged PR just above this post had to also do this here: tensorflow/lite/kernels/internal/spectrogram.cc,", The PR raised for the above mentioned build error has been merged. Could you please try to check and the provide the update on the same. https://github.com/tensorflow/tensorflow/pull/61503 https://github.com/matthewolsonintel/tensorflow/blob/master/tensorflow/tsl/lib/io/cache.hL19 Thank you!","I don't have such a compiler on my local machine anymore because currently, my machine uses Fedora 40 instead of 38 so Clang 16 is not available. If you believe that the issue is resolved by the PR mentioned above  feel free to close the issue. Thanks for the fix!",Are you satisfied with the resolution of your issue? Yes No
1878,"以下是一个github上的tensorflow下的一个issue, 标题是(`MeanAbsoluteError` returns ""nan"" when given empty tensors)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v1.12.196880g4499c968316 2.14.0dev20230714  Custom code No  OS platform and distribution macOS 13.2.1  Mobile device v  Python version 3.11.4  Bazel version n/a  GCC/compiler version n/a  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? When using `MeanAbsoluteError.update_state(y_true, y_pred)` if `y_true` and `y_pred` happen to be empty tensors of size 0, all subsequent call to   `MeanAbsoluteError.result()` will yield ""nan"" until the internal state of the metric is reset.  Since calling `MeanAbsoluteError.result()` before any result has been passed returns 0.0, I would expect empty tensors to be ignored when passed to `MeanAbsoluteError.update_state(y_true, y_pred)`. I've only tested this issue with `MeanAbsoluteError`, but it seems likely that it would happen with other metrics.  Standalone code to reproduce the issue  shell 20230714 14:54:43.650532: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. WARNING:tensorflow:From /Users/francois/.local/share/virtualenvs/sandboxw3BOTv5B/lib/python3.11/sitepackages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 20190101. Instructions for updating: The TensorFlow Distribut)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,FGRCL,"`MeanAbsoluteError` returns ""nan"" when given empty tensors"," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source binary  TensorFlow version v1.12.196880g4499c968316 2.14.0dev20230714  Custom code No  OS platform and distribution macOS 13.2.1  Mobile device v  Python version 3.11.4  Bazel version n/a  GCC/compiler version n/a  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? When using `MeanAbsoluteError.update_state(y_true, y_pred)` if `y_true` and `y_pred` happen to be empty tensors of size 0, all subsequent call to   `MeanAbsoluteError.result()` will yield ""nan"" until the internal state of the metric is reset.  Since calling `MeanAbsoluteError.result()` before any result has been passed returns 0.0, I would expect empty tensors to be ignored when passed to `MeanAbsoluteError.update_state(y_true, y_pred)`. I've only tested this issue with `MeanAbsoluteError`, but it seems likely that it would happen with other metrics.  Standalone code to reproduce the issue  shell 20230714 14:54:43.650532: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. WARNING:tensorflow:From /Users/francois/.local/share/virtualenvs/sandboxw3BOTv5B/lib/python3.11/sitepackages/tensorflow/python/ops/distributions/distribution.py:259: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 20190101. Instructions for updating: The TensorFlow Distribut",2023-07-14T19:06:49Z,stat:awaiting response type:bug stale comp:keras comp:core,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61281,"Hi  , I have gone through the issue and replicated the reported behaviour and attached gist for reference. What I observed is even with Numpy for empty arrays Numpy also generating `nan` only which is same as TF behaviour with empty Tensors of shape=(0,) . This is a different case which needs to be discussed. Tensorflow implemented numpy like behaviour for empty tensors. Can you check the numpy behaviour and comment. AFAIK it's possible to implement exception of ValueError if the input is empty tensor/array. But we need to take Dev team confirmation on this. Thanks!","Hi  , AFAIK by default `reset_state()` will be called at the end of each epoch/step during training. So in that case this should not be a problem. WDYT ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi   Sorry for the delay. I think the bug I'm perceiving here is not necessarily how the MAE is calculated by Tensorflow when the metric is called as in the following way: `tf.keras.metrics.mean_absolute_error(y_true, y_pred)`, which is perfectly consistent with numpy, but rather the way that the `MeanAbsoluteError` class accumulates the mae when called with `.update_state()`.  The way I conceptualize it, `MeanAbsoluteError` starts out with 0 data points and returns `0.0`, therefore adding “more” 0 data points, i.e. `mae.update_state([])`, should retain that behaviour of returning `0.0`. `reset_state()` doesn't necessarily solve the issue. For example, if batch no. 25 in an epoch of 100 batches passes an empty tensor to `update_state()`, then the metric's `result()` will return `nan` until the end of the epoch. If you were then to graph the MAE w.r.t. epochs, that graph would only be `nan` for all epochs.  The particular use case in which I encountered this bug is the following. I needed to plot the MAE for samples where the target value is above or below a certain threshold. Naturally, some batches contain none of these samples, resulting in an empty tensor. Let me know if I'm not understanding correctly the way these classes are intended to work.","Hi  , Apologies.This got slipped from my TODO list.This seems change in API design and needs to be addressed in Keras repo. Would you mind opening this issue at Keras repo? Thanks! Adding gist with Keras3 for reference.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1179,"以下是一个github上的tensorflow下的一个issue, 标题是(TfLite 2.13 with -DTFLITE_ENABLE_GPU=ON fails to build with Visual Studio 2019 and 2022)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.13  Custom code No  OS platform and distribution Windows 10  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version Visual Studio 2019 and 2022  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Building TfLite 2.13 with cmake and `DTFLITE_ENABLE_GPU=ON` fails if Visual Studio 2019 or 2022 is used. Tested on two different machines, it fails on both machines. Steps executed in Windows Command Prompt:  The cmake build command yields two errors:  To fix this, add `include ` to `tensorflow\lite\delegates\gpu\common\selectors\operation_selector.cc` and `tensorflow\lite\delegates\gpu\common\selectors\operation_selector.cc`  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,misterBart,TfLite 2.13 with -DTFLITE_ENABLE_GPU=ON fails to build with Visual Studio 2019 and 2022," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version tf 2.13  Custom code No  OS platform and distribution Windows 10  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version Visual Studio 2019 and 2022  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Building TfLite 2.13 with cmake and `DTFLITE_ENABLE_GPU=ON` fails if Visual Studio 2019 or 2022 is used. Tested on two different machines, it fails on both machines. Steps executed in Windows Command Prompt:  The cmake build command yields two errors:  To fix this, add `include ` to `tensorflow\lite\delegates\gpu\common\selectors\operation_selector.cc` and `tensorflow\lite\delegates\gpu\common\selectors\operation_selector.cc`  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-13T09:46:07Z,stat:awaiting tensorflower type:build/install comp:lite subtype:windows TF 2.13,closed,0,9,https://github.com/tensorflow/tensorflow/issues/61269,"Hi , thanks for reporting the issue. git & cmake are not available natively on windows command prompt so I have a couple of questions in order to reproduce your issue. Are you using powershell or command prompt? Are you using WSL? Are you using MinGW? Are you using git for windows? If you have trouble understanding these questions, a good first pass is to ask bard: https://bard.google.com/. Ex: ""How to tell if I'm using _______?"" Usually the more information you provide, the faster I am able to assist you. Thanks!","I'm using Windows Command Prompt. Installed Git with the Windows installer from https://gitscm.com/download/win Installed CMake with the Windows installer from https://cmake.org/download/ After installing, git and cmake are available in Windows Command Prompt By the way, you can also solve the two mentioned compile errors if your replace `std::any_cast` with `absl::any_cast`. I believe this is the preferable solution, because I notice you use `absl::any_cast` more often in the two C++ files in question.","Hi , our internal tests/tools show it compiles correctly with clang, Is there a way to adjust your cmake installation to use clang? (I'm currently guessing it is using gcc but I'm not sure).","I am using cmake with Visual Studio (also see title and opening post), so I'm using Microsoft Visual C++ (MSVC) compiler. As for your followup email: ""Hi , let us know if you have tried multiple models to help us look into the problem further."" The issue is building TfLite. I have to build TfLite before I can use TfLite models. To make things clear, I never asked for help. I reported an issue and posted a solution in my opening post and a second solution in my previous comment. I posted these solutions so that one of them could be applied to the TfLite code, so that other people using Visual Studio will not experience this error. Hopefully things are clear now.","Hi , there are complications/restrictions which make applying those solutions not that simple, but we'll take a deeper look, in the mean time, can you use bazel to unblock yourself? Generally the bazel workflow is better supported for windows/macos and the cmake workflow is better supported for *nix systems.","Hi , can you please take a look? Thanks", Have you been able to look at the matter yet?,"Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/165 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1296,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow-io package not possible on computer)， 内容是 ( Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version newest  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9 and 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have an Apple Mac Pro with an M1 chip and have been trying to get the example code from your website to compile on both my terminal and pycharm. I have installed the packed for tf metal and for macOS but when I attempt to install the TensorFlowio it doesn't work at all. After research online I saw this is an issue for others as well. Is there a way that the code at this link (https://www.tensorflow.org/tutorials/audio/transfer_learning_audio ) would be able to be done without TensorFlowio. In other words, is there an alternative so that it works the same? Or is there a solution to the package installation problem?  Standalone code to reproduce the issue )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,oliviafranken,TensorFlow-io package not possible on computer," Issue type Feature Request  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version newest  Custom code No  OS platform and distribution _No response_  Mobile device _No response_  Python version 3.9 and 3.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have an Apple Mac Pro with an M1 chip and have been trying to get the example code from your website to compile on both my terminal and pycharm. I have installed the packed for tf metal and for macOS but when I attempt to install the TensorFlowio it doesn't work at all. After research online I saw this is an issue for others as well. Is there a way that the code at this link (https://www.tensorflow.org/tutorials/audio/transfer_learning_audio ) would be able to be done without TensorFlowio. In other words, is there an alternative so that it works the same? Or is there a solution to the package installation problem?  Standalone code to reproduce the issue ",2023-07-12T19:41:50Z,stat:awaiting tensorflower type:build/install,open,0,13,https://github.com/tensorflow/tensorflow/issues/61264, Could you please try to install the tensorflow_io and try again.  Try with the following  I was able to run the code successfully after installing this module. Please have a look at this colab gist for reference.  Please find the log below;  Thank you!,"  I tried that and it didn't work... This is what I get every time I try to install the TensorFlow_io:  ERROR: Could not find a version that satisfies the requirement tensorflow==2.11.1 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0) ERROR: No matching distribution found for tensorflow==2.11.1",  Any other recommendations? I found out that TensorFlow_io doesn't work on apple computers that have the m1 chip... Is there another way to resolve this or is there something other than that package that I could use?,Please switch to using TF 2.13 instead of 2.11. That could possibly solve the issue.,  I am currently using 2.13,">  >  > I am currently using 2.13 Sorry, was confused by the error message that is looking at `tensorflow==2.11.1`: >  I tried that and it didn't work... This is what I get every time I try to install the TensorFlow_io: >  > ERROR: Could not find a version that satisfies the requirement tensorflow==2.11.1 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0) ERROR: No matching distribution found for tensorflow==2.11.1 Can you post the output of `pip list`, please?","> >  > > I am currently using 2.13 >  > Sorry, was confused by the error message that is looking at `tensorflow==2.11.1`: >  > >  I tried that and it didn't work... This is what I get every time I try to install the TensorFlow_io: > > ERROR: Could not find a version that satisfies the requirement tensorflow==2.11.1 (from versions: 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0) ERROR: No matching distribution found for tensorflow==2.11.1 >  > Can you post the output of `pip list`, please? Here is output of pip list: ","Oh, I think the issue is that TFIO did not have a release since Mar: https://pypi.org/project/tensorflowio/0.32.0/history, so the latest one is expecting TF 2.11. Tagging  for a new release now that TF 2.13 has just been released.","(sorry, closed by mistake, reopened)","> Oh, I think the issue is that TFIO did not have a release since Mar: https://pypi.org/project/tensorflowio/0.32.0/history, so the latest one is expecting TF 2.11. >  > Tagging  for a new release now that TF 2.13 has just been released. Ohhh I see. Thank you, I know a couple people have been having the same issue as me. Would you recommend I install TF 2.11 and try to work from that for right now? (I'm just curious as I need it for my job)","Let's try with that one, though I also see you are on a Mac with M1 and I think full support for that is coming only in 2.13. But hopefully it works? If not, I'd recommend trying the Google Colab Notebooks, if possible, as those run on Linux VMs and should work 99.999% of the time (plus, are very similar to Jupyter Notebooks, so experience transfers nicely). Of course, this is only if job requirements allow it.","> Let's try with that one, though I also see you are on a Mac with M1 and I think full support for that is coming only in 2.13. But hopefully it works? >  > If not, I'd recommend trying the Google Colab Notebooks, if possible, as those run on Linux VMs and should work 99.999% of the time (plus, are very similar to Jupyter Notebooks, so experience transfers nicely). Of course, this is only if job requirements allow it. yeah it won't even let me install the 2.11 version haha. I can try working on colab or something for now. When do you think the TFio release for 2.13 will be completed?",That depends on when  and other maintainers of TF IO can do the next release.
1899,"以下是一个github上的tensorflow下的一个issue, 标题是(The required input dimension and type changed after conversion of SAC algorithm)， 内容是 ( 1. System information  OS Platform and Distribution : Linux Ubuntu 22.04  TensorFlow installation : Pip Package  TensorFlow library: Tensorflow 2.12.1  2. Code most of them I followed the SAC Minitaur tutorial here https://www.tensorflow.org/agents/tutorials/7_SAC_minitaur_tutorial but with some modification to fit with my environment, also with additional function to convert to TFLite  https://colab.research.google.com/drive/1Eea5Fi861_h3TzH1eGUaPH9dSPBn3OJ?usp=sharing  3. Failure after conversion The Observation Spec reduced and changed from shape (5,), float32 to shape[1], int32 in this conversion > Observation Spec: BoundedArraySpec(shape=(5,), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=1.0) Reward Spec: ArraySpec(shape=(), dtype=dtype('float32'), name='reward') Action Spec: BoundedArraySpec(shape=(1,), dtype=dtype('float32'), name='action', minimum=0.6000000238418579, maximum=0.6000000238418579) Time step: TimeStep( {'discount': array(1., dtype=float32),  'observation': array([0.09387773, 0.45744053, 0.8837498 , 0.84389937, 0.5       ],       dtype=float32),  'reward': array(0., dtype=float32),  'step_type': array(0, dtype=int32)})  step = 0: AverageReturn = 0.000758, AverageEpisodeLength = 120.449997 step = 100: loss = 0.29556670784950256 step = 200: loss = 0.42344561219215393 step = 300: loss = 0.4886786639690399 step = 400: loss = 0.5600587129592896 step = 500: loss = 0.6421032547950745 step = 600: loss = 0.7184216380119324 step = 700: loss = 0.785315752029419 step = 800: loss = 0.8600273728370667 step = 900: loss = 0.9031595587730408 step = 1000: AverageReturn = 1.299191, Av)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,urplanet,The required input dimension and type changed after conversion of SAC algorithm," 1. System information  OS Platform and Distribution : Linux Ubuntu 22.04  TensorFlow installation : Pip Package  TensorFlow library: Tensorflow 2.12.1  2. Code most of them I followed the SAC Minitaur tutorial here https://www.tensorflow.org/agents/tutorials/7_SAC_minitaur_tutorial but with some modification to fit with my environment, also with additional function to convert to TFLite  https://colab.research.google.com/drive/1Eea5Fi861_h3TzH1eGUaPH9dSPBn3OJ?usp=sharing  3. Failure after conversion The Observation Spec reduced and changed from shape (5,), float32 to shape[1], int32 in this conversion > Observation Spec: BoundedArraySpec(shape=(5,), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=1.0) Reward Spec: ArraySpec(shape=(), dtype=dtype('float32'), name='reward') Action Spec: BoundedArraySpec(shape=(1,), dtype=dtype('float32'), name='action', minimum=0.6000000238418579, maximum=0.6000000238418579) Time step: TimeStep( {'discount': array(1., dtype=float32),  'observation': array([0.09387773, 0.45744053, 0.8837498 , 0.84389937, 0.5       ],       dtype=float32),  'reward': array(0., dtype=float32),  'step_type': array(0, dtype=int32)})  step = 0: AverageReturn = 0.000758, AverageEpisodeLength = 120.449997 step = 100: loss = 0.29556670784950256 step = 200: loss = 0.42344561219215393 step = 300: loss = 0.4886786639690399 step = 400: loss = 0.5600587129592896 step = 500: loss = 0.6421032547950745 step = 600: loss = 0.7184216380119324 step = 700: loss = 0.785315752029419 step = 800: loss = 0.8600273728370667 step = 900: loss = 0.9031595587730408 step = 1000: AverageReturn = 1.299191, Av",2023-07-12T13:38:32Z,stat:awaiting response type:bug comp:lite TFLiteConverter TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61260,Hi   Could you please provide the minimal reproducible code for the colab environment? Facing errors while executing the provided code. Thanks.,"Hi    as requested, I have updated the code in the colab https://colab.research.google.com/drive/1Eea5Fi861_h3TzH1eGUaPH9dSPBn3OJ?usp=sharing . I included the environment I used to run the training.","Hi   Thanks for the code. I have observed that `observation` has been converted with shape signature `[1,5]` with type FLOAT32 using TFLite Model Analyzer API. The model has   and as per model analyzer  Please find the gist here. Thanks.",So could you advice that this issue occurs because of incompatibility of the model or which root causes ? Because my conversion is very simple without any change in the conversion configuration.,"Hi   Based on the above gist, I don't see any issue in conversion process as the input shapes are not altered. You have to access `input_details[2]['shape']` and `input_details[2]['index']`, if the `observation` data is of the interest.  Thanks.","that solved my problem. thank you so much ! meanwhile, I have a small question on the Saved Model selection. I followed this https://www.tensorflow.org/agents/tutorials/7_SAC_minitaur_tutorial and realized that there are different Saved_Model.pb in different folder in the tempdir. if I would like to convert the policy for further use in TFLite, which one I should pick to convert to represent my trained SAC Model ?","Hi   The Tensorflow Agents is being maintained as separate repo. Could you please raise a ticket there for faster resolution? Please, let us know if we can help anything on TFLite. Feel free to close the issue if it is resolved. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1290,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.image.adjust_contrast fails on the tf.half data type)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I was trying tf.image.adjust_contrast but I find that it fails when I set the input tensor's data type to be `float16 (tf.half)`, this API raises error. However, if I set the input data type to be `bfloat16`, this API works properly.   Standalone code to reproduce the issue  shell NotFoundError: Could not find device for node: {{node AdjustContrastv2}} = AdjustContrastv2[T=DT_HALF] All kernels registered for op AdjustContrastv2:   device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_HALF]   device='CPU'; T in [DT_FLOAT]   device='GPU'; T in [DT_HALF]   device='GPU'; T in [DT_FLOAT]   device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_HALF]  [Op:AdjustContrastv2] name: ```)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,drewshark,tf.image.adjust_contrast fails on the tf.half data type," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I was trying tf.image.adjust_contrast but I find that it fails when I set the input tensor's data type to be `float16 (tf.half)`, this API raises error. However, if I set the input data type to be `bfloat16`, this API works properly.   Standalone code to reproduce the issue  shell NotFoundError: Could not find device for node: {{node AdjustContrastv2}} = AdjustContrastv2[T=DT_HALF] All kernels registered for op AdjustContrastv2:   device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_HALF]   device='CPU'; T in [DT_FLOAT]   device='GPU'; T in [DT_HALF]   device='GPU'; T in [DT_FLOAT]   device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_HALF]  [Op:AdjustContrastv2] name: ```",2023-07-11T16:05:56Z,awaiting review type:bug comp:apis comp:ops TF 2.13,open,0,1,https://github.com/tensorflow/tensorflow/issues/61246,"Hi  , Thanks for your time reporting this. I have replicated the issue with CPU runtime and attached cpugist here. As the error log suggests this Op with float16 as input dtype not implemented on CPU which we need to dig more to rectify this.May be we need to register this Op for CPU device with tf.float16 also. With GPU the code works as intended and can refer same in attached gpugist. Thanks!"
1315,"以下是一个github上的tensorflow下的一个issue, 标题是(Different reference order may cause other modules to be unavailable, e.g. xgboost, sklearn.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution centos 7.6  Mobile device _No response_  Python version python 3.10.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda=12.1  GPU model and memory 32510MiB  Current behavior? I was trying to import xgboost(or sklearn) and tensorflow modules at same time, but when I  imported modules by different order, it just return me error message that I can not handle it, I don't whether it a bug or some issues that can be fixed by myself?  and I also search something resource, which said that it was a bug caused by glibc : https://sourceware.org/bugzilla/show_bug.cgi?id=17090. and then I was trying to reintstall glibc on my server, unfortunately, the plan finally failed and now I am just trying to rebuild my whole environment by rollbacking to previous mirror backup, sad.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,h2222,"Different reference order may cause other modules to be unavailable, e.g. xgboost, sklearn."," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.11.0  Custom code Yes  OS platform and distribution centos 7.6  Mobile device _No response_  Python version python 3.10.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version cuda=12.1  GPU model and memory 32510MiB  Current behavior? I was trying to import xgboost(or sklearn) and tensorflow modules at same time, but when I  imported modules by different order, it just return me error message that I can not handle it, I don't whether it a bug or some issues that can be fixed by myself?  and I also search something resource, which said that it was a bug caused by glibc : https://sourceware.org/bugzilla/show_bug.cgi?id=17090. and then I was trying to reintstall glibc on my server, unfortunately, the plan finally failed and now I am just trying to rebuild my whole environment by rollbacking to previous mirror backup, sad.  Standalone code to reproduce the issue   Relevant log output ",2023-07-11T08:09:33Z,stat:awaiting response type:bug stale comp:apis TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61240,", The error occurred because you are trying to run the **32bit Python on a 64bit OS** which was incompatible. When I tried to execute the mentioned code with the compatible on the latest tensorflow `v2.13`, it was executed without any issues. Kindly find the gist of it here and please try with the right infra which helps to execute the code smoothly. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
964,"以下是一个github上的tensorflow下的一个issue, 标题是(Add inter scheduler support on AArch64)， 内容是 (This PR adds support for inter op scheduler in the oneDNN + ACL build. It enables the creation of more than 1 scheduler inside ACL to increase performance of models with parallel ops. For benchmarked NLP models the average performance increase is 9%, for CV classification models its around 2%. The below benchmarks were done with the following PR’s applied as patches: CC(Reduce MKL overheads on small shapes by not rewriting node to use MKL), CC(Improving the performance of TF models for aarch64.), CC(Adds matmul heuristic for oneDNN ACL builds on AArch64), CC(Support for jited block reorder on AArch64), CC(Update oneDNN reorder on AArch64), CC(Update to ACL 23.05.1, add ACL reorders)  !nlp_models_benchmarked !cv_models_benchmarked)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,davsva01,Add inter scheduler support on AArch64,"This PR adds support for inter op scheduler in the oneDNN + ACL build. It enables the creation of more than 1 scheduler inside ACL to increase performance of models with parallel ops. For benchmarked NLP models the average performance increase is 9%, for CV classification models its around 2%. The below benchmarks were done with the following PR’s applied as patches: CC(Reduce MKL overheads on small shapes by not rewriting node to use MKL), CC(Improving the performance of TF models for aarch64.), CC(Adds matmul heuristic for oneDNN ACL builds on AArch64), CC(Support for jited block reorder on AArch64), CC(Update oneDNN reorder on AArch64), CC(Update to ACL 23.05.1, add ACL reorders)  !nlp_models_benchmarked !cv_models_benchmarked",2023-07-10T19:21:52Z,comp:mkl size:L,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61235,    ,Please also resolve merge conflicts / rebase. Thank you! :),> Please also resolve merge conflicts / rebase. Thank you! :) The merge conflicts has been fixed.,"> cc: MKL: I don't think this will affect the x86 build. Yes, that is right. This patch doesn't anymore uses single LRU cache when Eigen scheduler is used so the changes in TF are all around `ifdefs` for AArch64 to detect that case and the rest of changes are in Arm Compute Library (ACL) to have ACL scheduler per interthread and create it via stream in oneDNN (AArch64 code path) when it is required. ",Hi  Can you please resolve conflicts? Thank you!,> Hi  Can you please resolve conflicts? Thank you! Merge conflicts fixed.
1355,"以下是一个github上的tensorflow下的一个issue, 标题是(Memory out of bounds in compiled tflite with emscripten.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have compiled tflite using cmake (without XNNPACK support) and emscripten (both latest 3.1.42 and 3.1.10).  When trying to perform inference at the browser with my model I get the following error: vmt.wasm:0x31cff Uncaught RuntimeError: memory access out of bounds     at vmt.wasm:0x31cff     at vmt.wasm:0x1f7a94     at vmt.wasm:0x3c4910     at vmt.wasm:0x65ace     at vmt.wasm:0x231c3e     at vmt.wasm:0x458a49     at vmt.wasm:0x517c60     at img.onload (index.html:772:28) This happens with all of my models at the very first operation (pad). When inspecting the .wasm file using chrome dev tools I see that the error happens at a ""memory.fill"" operation.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,af-filby,Memory out of bounds in compiled tflite with emscripten.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have compiled tflite using cmake (without XNNPACK support) and emscripten (both latest 3.1.42 and 3.1.10).  When trying to perform inference at the browser with my model I get the following error: vmt.wasm:0x31cff Uncaught RuntimeError: memory access out of bounds     at vmt.wasm:0x31cff     at vmt.wasm:0x1f7a94     at vmt.wasm:0x3c4910     at vmt.wasm:0x65ace     at vmt.wasm:0x231c3e     at vmt.wasm:0x458a49     at vmt.wasm:0x517c60     at img.onload (index.html:772:28) This happens with all of my models at the very first operation (pad). When inspecting the .wasm file using chrome dev tools I see that the error happens at a ""memory.fill"" operation.  Standalone code to reproduce the issue   Relevant log output ",2023-07-10T18:41:30Z,stat:awaiting response type:bug stale comp:lite type:performance TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61234,Some further digging on this I found out that there is probably an overflow in the paddings inside PadImpl: !image,"Hi filby, I am not too familiar with emscripten, can you help me understand how you compile and execute your model? Are you in the tensorflow directory when you do your cmake command? You are also saying you are using emcmake but didn't include it in your command, was that a mistake or are you using the emcmake command like this?:  When compiling your project with emscripten, it looks like you are using a CMakeLists.txt? Is that where this is set?  Can you share your CMakeLists.txt if this is the case? Can you also share a minimally reproducible toy model as well? Are you using node to execute the model? I am not familiar with the emscripten workflow, so any details you share will be welcomed. Preferably, include as many cmd line commands you are doing as if you are writing a script/dockerfile. Thanks for your help.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
435,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow GPU)， 内容是 (New versions of TensorFlow no longer support Windows native Gpus. If built in WSL2 Is there a shortcut to read data from Windows directory in WSL2? Because I need to use TensorFlow GPU to compute a lot of data. Copying to WSL2 is slow)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,KnSun99,TensorFlow GPU,New versions of TensorFlow no longer support Windows native Gpus. If built in WSL2 Is there a shortcut to read data from Windows directory in WSL2? Because I need to use TensorFlow GPU to compute a lot of data. Copying to WSL2 is slow,2023-07-09T17:05:54Z,type:support wsl2,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61225,"Hi  , Thanks for reaching us. Trying to access Windows files from WSL might be considerably slower than using the native Linux file system. Windows drives are mounted in the Linux at `/mnt/` directory. You can prefix /mnt/ to your local directory to access then in WSL. For example, your personal Users folder at `C:\Users\` is available at: `/mnt/c/Users/`. For more details you may refer the attached external sources from here source1 and source2. Please let us know if it helps. Thanks!",Thank you for the response! Will there be future versions that support Windows native GPU?," , Due to performance issues Windows native GPU support has been dropped. I doubt whether support for windows native GPU will bring back in near future.",Thanks for your reply!," , Please let us know if the issue is resolved for you. Please feel free to close if resolved.Let us know if you get any further issue. Thanks!",OK,Are you satisfied with the resolution of your issue? Yes No
1367,"以下是一个github上的tensorflow下的一个issue, 标题是(Migrate ops fuzzers to FuzzTest format)， 内容是 (Creates a set of fuzzers to FuzzTest style. One of the benefits is that this will reduce storage size required for the fuzzers, because the fuzzers will all be based off the same binary whereas the nonFuzzTest fuzzers will have a binary per fuzzer. This storage requirement has caused an issue on the OSSFuzz side: https://github.com/google/ossfuzz/issues/9792 Migrating to FuzzTest will make it easier to add new opsspecific fuzzers since we won't have to worry about disk size. The existing fuzzesr can be several GBs of storage and it quickly goes beyond what we have available at OSSFuzz. It would however be nice to reuse the existing fuzzer helper logic from fuzz_session.h so I added a macro similar to what we have for libFuzzer but simple for FuzzTest. I migrated a set of the existing fuzzers. I figured it would be nice to do a soft transition, so we can remove the existing fuzzers after the ones introduced in this PR has shown to run for a while. I'm also curious in whether we will see a difference in performance from the FuzzTest and libFuzzer harnesses. This PR supersedes https://github.com/tensorflow/tensorflow/pull/61122)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,DavidKorczynski,Migrate ops fuzzers to FuzzTest format,"Creates a set of fuzzers to FuzzTest style. One of the benefits is that this will reduce storage size required for the fuzzers, because the fuzzers will all be based off the same binary whereas the nonFuzzTest fuzzers will have a binary per fuzzer. This storage requirement has caused an issue on the OSSFuzz side: https://github.com/google/ossfuzz/issues/9792 Migrating to FuzzTest will make it easier to add new opsspecific fuzzers since we won't have to worry about disk size. The existing fuzzesr can be several GBs of storage and it quickly goes beyond what we have available at OSSFuzz. It would however be nice to reuse the existing fuzzer helper logic from fuzz_session.h so I added a macro similar to what we have for libFuzzer but simple for FuzzTest. I migrated a set of the existing fuzzers. I figured it would be nice to do a soft transition, so we can remove the existing fuzzers after the ones introduced in this PR has shown to run for a while. I'm also curious in whether we will see a difference in performance from the FuzzTest and libFuzzer harnesses. This PR supersedes https://github.com/tensorflow/tensorflow/pull/61122",2023-07-08T16:22:37Z,awaiting review ready to pull size:M,closed,0,1,https://github.com/tensorflow/tensorflow/issues/61221,CC  
1180,"以下是一个github上的tensorflow下的一个issue, 标题是(savedmodel convert to tflite and merge labels.  tx to new tflite model,but resulte is error by Xcode,  use python api is correct)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution mac os 12.6  Mobile device ios 16.1  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? convert savedmodel to tflite in ios is error model download  url  https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5 convert steps 1.  2.  script is use  offical metadata_writer_for_image_classifier.py use convert savedmodel to convert tflite （merge  labels.txt and  tflite） python api  result  is correct  ios is error  （selfconverted）  ios is correct （download tflite is correct ）   Standalone code to reproduce the issue  ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,fndppx,"savedmodel convert to tflite and merge labels.  tx to new tflite model,but resulte is error by Xcode,  use python api is correct", Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution mac os 12.6  Mobile device ios 16.1  Python version 3.10.0  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? convert savedmodel to tflite in ios is error model download  url  https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/classification/5 convert steps 1.  2.  script is use  offical metadata_writer_for_image_classifier.py use convert savedmodel to convert tflite （merge  labels.txt and  tflite） python api  result  is correct  ios is error  （selfconverted）  ios is correct （download tflite is correct ）   Standalone code to reproduce the issue  ```  Relevant log output _No response_,2023-07-08T04:32:10Z,stat:awaiting response type:bug comp:lite TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61219,"Hi   Can you please check if the preprocessing is done properly as I can see that the python api as well as model metadata normalize the values between [0,1]. Thanks.","> Hi   >  > Can you please check if the preprocessing is done properly as I can see that the python api as well as model metadata normalize the values between [0,1]. >  > Thanks. !251931780c3618d303dae4a85a3d2dcf0f340afe3.png but i use TensorFlowLiteTaskVision  this framework ，not found  model metadata normalize the values between [0,1]. only could set option 😂😂",Hi   The ImageClassifier API expects a TFLite model with mandatory TFLite Model Metadata. TensorFlow Lite Task Library can handle normalization for you if you set up NormalizationOptions in metadata. The downloaded tflite model contains the metadata and a file containing all the class labels. Can you try this steps with   Thanks.,> Hi  >  > The ImageClassifier API expects a TFLite model with mandatory TFLite Model Metadata. TensorFlow Lite Task Library can handle normalization for you if you set up NormalizationOptions in metadata. >  > The downloaded tflite model contains the metadata and a file containing all the class labels. >  > Can you try this steps with >  >  >  > Thanks. thank you very mach！！this way solve this issue！,Hi   Glad the issue is solved. Please feel free to close the issue. Thanks.,Are you satisfied with the resolution of your issue? Yes No
1002,"以下是一个github上的tensorflow下的一个issue, 标题是(import of DistributedDatasetInterface not valid anymore)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf.2.13.0  Custom code No  OS platform and distribution Mac OS Ventura 13.4  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Instantiating `DataHandler`  from `tensorflow.python.keras.engine.data_adapter` throws an error  `AttributeError: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'` The type `DistributedDatasetInterface` can now be found in ‎tensorflow/python/types/distribute.py  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,bogdan-galileo,import of DistributedDatasetInterface not valid anymore, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source binary  TensorFlow version tf.2.13.0  Custom code No  OS platform and distribution Mac OS Ventura 13.4  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Instantiating `DataHandler`  from `tensorflow.python.keras.engine.data_adapter` throws an error  `AttributeError: module 'tensorflow.python.distribute.input_lib' has no attribute 'DistributedDatasetInterface'` The type `DistributedDatasetInterface` can now be found in ‎tensorflow/python/types/distribute.py  Standalone code to reproduce the issue   Relevant log output ,2023-07-06T21:33:14Z,stat:awaiting tensorflower type:build/install subtype:macOS TF 2.13,open,2,5,https://github.com/tensorflow/tensorflow/issues/61204,Same here," I was able to replicate this issue in TF v2.13, please find the attached logs below;  Thank you!","galileo , Thanks for reporting. This seems regression issue as it is working in TF2.12v but breaking in TF2.13v. Attached gist for reference. Again this issue is not just Mac OS specific. ",Still not fixed in current master!,"Hello  , this problem doesn't occur in TF2.12.1, but there is still an error in the current version. I would greatly appreciate it if this could be addressed. Thank you!"
1485,"以下是一个github上的tensorflow下的一个issue, 标题是(Building TFLite for WASM using Bazel)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Emscripten  Mobile device _No response_  Python version _No response_  Bazel version 5.3.0  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We are trying to compile TFLite libraries for WASM that we can use in our C++ project that later will be compiled to WASM package as well. We have forked a Tensorflow repository and did these modifications for Bazel + WASM  https://github.com/affilby/tensorflow/commit/2defd39b957a73828b4791e48883e874a97b4bb4 and we try to build with this command: `bazel build config=wasm c opt //tensorflow/lite:tensorflowlite` The building process went smooth and we as an output we got `libtensorflowlite2.so` which I think is expected. BUT, the problem is that this `.so` file is only `50 KB` in size, and if we try to link it in our CMake we get an error `Unable to find library ltensorflowlite2` Could you please review our Bazel config and advise what we did wrong so we can finish this compilation successfully?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,L1onKing,Building TFLite for WASM using Bazel," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.13.0  Custom code Yes  OS platform and distribution Emscripten  Mobile device _No response_  Python version _No response_  Bazel version 5.3.0  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? We are trying to compile TFLite libraries for WASM that we can use in our C++ project that later will be compiled to WASM package as well. We have forked a Tensorflow repository and did these modifications for Bazel + WASM  https://github.com/affilby/tensorflow/commit/2defd39b957a73828b4791e48883e874a97b4bb4 and we try to build with this command: `bazel build config=wasm c opt //tensorflow/lite:tensorflowlite` The building process went smooth and we as an output we got `libtensorflowlite2.so` which I think is expected. BUT, the problem is that this `.so` file is only `50 KB` in size, and if we try to link it in our CMake we get an error `Unable to find library ltensorflowlite2` Could you please review our Bazel config and advise what we did wrong so we can finish this compilation successfully?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-06T11:34:54Z,stat:awaiting response type:build/install type:support stale comp:lite TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61200,"Hi , can you please take a look?","Hi , So I tried your bazel command, and as far as I can tell I don't believe building for WASM is not a valid config. I am unaware of any documentation that says it is supported and I get this error:  This is the closest thing I can find: https://js.tensorflow.org/api_tflite/0.0.1alpha.8/, are you following any resource which provided this command?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hello,  ! Did you manage to solve the problem? I'm trying to do the exact same thing, to no avail so far. Looks like the build recipe that worked a couple years ago doesn't work anymore."
661,"以下是一个github上的tensorflow下的一个issue, 标题是([REF] Introduce multiple streams execution in TensorFlow.)， 内容是 (Multiple Stream TensorFlow is developed based on the official TensorFlow. It leverages the features of modern GPUs to accelerate deep learning training and inference. This MultiStream implementation has successfully helped several customers migrate their RecSys TF models to the GPU and go online. For more details please visit README_MultiStream.md. This PR is used as a reference and will not be merged to master.  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,buptzyb,[REF] Introduce multiple streams execution in TensorFlow.,Multiple Stream TensorFlow is developed based on the official TensorFlow. It leverages the features of modern GPUs to accelerate deep learning training and inference. This MultiStream implementation has successfully helped several customers migrate their RecSys TF models to the GPU and go online. For more details please visit README_MultiStream.md. This PR is used as a reference and will not be merged to master.  ,2023-07-06T02:00:28Z,size:XL,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61185,"Hi  This PR is in draft, any update on this? Please. Thank you!","Hi  This PR is in draft, any update on this? Please. Thank you!","Hi  This PR is in draft, any update on this? Please. Thank you!"
794,"以下是一个github上的tensorflow下的一个issue, 标题是(Protobuf throwing Type error `TypeError: bases must be types` in m1 mac)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution MacOS monterey  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to import tensorflow producing the following error   Standalone code to reproduce the issue   Relevant log output  The protobuf version is `3.20.3`)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,gksoriginals,Protobuf throwing Type error `TypeError: bases must be types` in m1 mac, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.13  Custom code Yes  OS platform and distribution MacOS monterey  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? Trying to import tensorflow producing the following error   Standalone code to reproduce the issue   Relevant log output  The protobuf version is `3.20.3`,2023-07-05T20:42:08Z,type:build/install subtype:macOS TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61182," I tried to replicate the issue reported here and didn't face the issue, could you please have a look at the logs below and let me know if i am missing anything here. Thank you! ","Hey,  I installed TensorFlowmetal as well. But ya this looks good.  I created a new conda env with python 3.9 and installed everything again. Now it is working now. But still not working in the old environment. "," Thank you for the confirmation! Glad it worked fine for you, closing this issue for now. Thank you!",Are you satisfied with the resolution of your issue? Yes No
762,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/compiler/xla/service/gpu:fusion_merger_test fails on AARCH64)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/compiler/xla/service/gpu:fusion_merger_test unit test fails when run on AARCH64 machine.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,//tensorflow/compiler/xla/service/gpu:fusion_merger_test fails on AARCH64, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.17  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/compiler/xla/service/gpu:fusion_merger_test unit test fails when run on AARCH64 machine.  Standalone code to reproduce the issue   Relevant log output ,2023-07-05T16:03:35Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,open,0,2,https://github.com/tensorflow/tensorflow/issues/61180,  FYI,"Digging into this a bit. It fails on AARCH64 because  of ""Fused would run slower than unfused!"" which seems to be because the exec time gets calculated as 'inf'. Tracing back this comes as a result of the utilization by the consumer being 0. The difference with x86 is that although it also has 0 utilization by the consumer, the exec time comes out as 'inf'. So I think that both x86 and AARCH64 should fail and x86 only works by accident. But the question I have yet to answer is why the utilization by the consumer is 0."
1146,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow detects GPU but uses only CPU)， 内容是 ( Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.10.x  Custom code Yes  OS platform and distribution Windows x64  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version toolkit:11.2.2  cudnn: 8.1.0.77  GPU model and memory gtx 1070  Current behavior?  Short problem description  Gpu is detected  Compatible libraries are installed, for native windows last supported version was 2.10  Gpu is utilizied with `tf.compat.v1.Session`  Gpu is not used in `tf.compat.v1.InteractiveSession`  Gpu is not used without any session I know that, because with gpu time per sample is `~100us`, but without `4ms`  Checking gpu visibility  which yields:   Simple tensorflow benchmark  And full output of training:   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,GrzegorzKrug,Tensorflow detects GPU but uses only CPU," Issue type Support  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.10.x  Custom code Yes  OS platform and distribution Windows x64  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version toolkit:11.2.2  cudnn: 8.1.0.77  GPU model and memory gtx 1070  Current behavior?  Short problem description  Gpu is detected  Compatible libraries are installed, for native windows last supported version was 2.10  Gpu is utilizied with `tf.compat.v1.Session`  Gpu is not used in `tf.compat.v1.InteractiveSession`  Gpu is not used without any session I know that, because with gpu time per sample is `~100us`, but without `4ms`  Checking gpu visibility  which yields:   Simple tensorflow benchmark  And full output of training:   Standalone code to reproduce the issue   Relevant log output _No response_",2023-07-05T14:46:46Z,stat:awaiting response type:support stale comp:gpu subtype:windows TF 2.10,closed,0,6,https://github.com/tensorflow/tensorflow/issues/61178,Is this desired feature? Or Bug? Or have I done something wrong?," Solved `tensorflow=2.9.3` works for me I also measured total time of both operations with `time`. I do not remember all results, but both times are now comparable. In contrast I did install new environment, just for cpu, and it runs way slower so I can confirm that gpu is beeing used in some way.    compat.v1  Session does not use batch size for some reason, thats why time per step is so small.  Close or test? Not sure what happens with `tensorflow=2.10.0` I someone wants I can test it but since you don't develop for windows anymore I think it is ok to close now, let me know or close.","Hi, Since the native windows support has been discontinued, it is suggested to use the Windows WSL2 for windows 10 or later to use the GPU access. Please follow the details mentioned in the document here and let us know if you still face any issues. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
330,"以下是一个github上的tensorflow下的一个issue, 标题是(math grads, optimize one op away)， 内容是 (Instead of `x * reciprocal(y)`, do `x / y`. This saves one op. Instead of (reciprocal, mul), you only have div.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,albertz,"math grads, optimize one op away","Instead of `x * reciprocal(y)`, do `x / y`. This saves one op. Instead of (reciprocal, mul), you only have div.",2023-07-05T11:31:11Z,comp:ops size:S,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61177,Are you sure it's faster?  We have vectorized fastreciprocal routines that can be considerably faster than true division.,"I would expect that true division internally does whatever is most efficient? But also, I'm mostly interested in GPU usage, and this is elemwise, so a single op should really be faster than two ops. But I did not measure it. Maybe I'm understanding sth wrong.","> I would expect that true division internally does whatever is most efficient? The division op has specific accuracy requirements (i.e. within 1 ULP from the ""true"" result) which multiplying by the reciprocal does not have.  Fast reciprocal is similar to the fast sqrt hack, where there's a bit manipulation, then Newton step to improve accuracy.  This can be significantly faster than division. > But also, I'm mostly interested in GPU usage, and this is elemwise, so a single op should really be faster than two ops. >  > But I did not measure it. Maybe I'm understanding sth wrong. It might depend.  I'm mainly asking if you have evidence, rather than a generic ""one op is better than two"".","> I'm mainly asking if you have evidence, rather than a generic ""one op is better than two"". No, I don't. My reasoning is mostly based on just that. But I also did not really expect that `reciprocal` is not exactly the same as `1/x`, as the doc say. Maybe the docs then should be updated on `reciprocal` to clarify this? But then also, how do you decide when to do `x / y` and when to do `x * reciprocal(y)`? I see both code being used.","> But I also did not really expect that `reciprocal` is not exactly the same as `1/x`, as the doc say. Maybe the docs then should be updated on `reciprocal` to clarify this? Reciprocal is `1/x` (well, within an ULP or two), though isn't implemented using division.  But `x * (1/y)` has different accuracy guarantees than `x/y`. > But then also, how do you decide when to do `x / y` and when to do `x * reciprocal(y)`? I see both code being used. These particular instances in your PR _were_ `x/y`, and someone changed them to `x * reciprocal(y)`.  You're changing it back.  The current change is not documented as a performance improvement (it was put in along with another change), but knowing the author, it may have been, since he's the one who wrote the fast reciprocal code.  Hence I'm asking you for evidence that it makes a difference.","I see. I guess the author probably must have thought about it then. Maybe the author also had some good evidence in believing that this is faster. I was simply seeing this and thought that `x / y` would be simpler and faster, but from everything you explained, it seems likely that my initial thought was simply wrong.  I don't think I have the time to do any further benchmarking on this for now, so maybe we can then just close this PR. Or maybe you ask the original author about it?",I would want benchmarks now anyways.  Closing for now.  Feel free to reopen when you have time to collect benchmarks.
983,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/data/experimental/kernel_tests/service:distributed_save_ft_test is flaky)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/python/data/experimental/kernel_tests/service:distributed_save_ft_test fails occasionally x86 log https://source.cloud.google.com/results/invocations/c5169019316f43e1831067596d2aae9a/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5330158020/jobs/9656553237step:5:8169  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/data/experimental/kernel_tests/service:distributed_save_ft_test is flaky, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/python/data/experimental/kernel_tests/service:distributed_save_ft_test fails occasionally x86 log https://source.cloud.google.com/results/invocations/c5169019316f43e1831067596d2aae9a/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5330158020/jobs/9656553237step:5:8169  Standalone code to reproduce the issue   Relevant log output ,2023-07-04T14:03:34Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux,open,0,1,https://github.com/tensorflow/tensorflow/issues/61172,tf flaky test
953,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/distribute:parameter_server_strategy_v2_test_cpu is flaky)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/python/distribute:parameter_server_strategy_v2_test_cpu timeouts sometimes x86 log https://source.cloud.google.com/results/invocations/75eaa47f92bd47d59c7a020a0c67dda9/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5399333727/jobs/9806323589step:5:7344  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/distribute:parameter_server_strategy_v2_test_cpu is flaky, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/python/distribute:parameter_server_strategy_v2_test_cpu timeouts sometimes x86 log https://source.cloud.google.com/results/invocations/75eaa47f92bd47d59c7a020a0c67dda9/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5399333727/jobs/9806323589step:5:7344  Standalone code to reproduce the issue   Relevant log output ,2023-07-04T10:39:13Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,open,0,1,https://github.com/tensorflow/tensorflow/issues/61169,tf flaky test
967,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/data/experimental/kernel_tests/service:worker_tags_test is flaky)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/python/data/experimental/kernel_tests/service:worker_tags_test fails occasionally x86 log https://source.cloud.google.com/results/invocations/0bc426bfe5ae4fb6993f6199c00d1139/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5411569978/jobs/9834485829step:5:8675  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/data/experimental/kernel_tests/service:worker_tags_test is flaky, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version git HEAD  Custom code No  OS platform and distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current behavior? //tensorflow/python/data/experimental/kernel_tests/service:worker_tags_test fails occasionally x86 log https://source.cloud.google.com/results/invocations/0bc426bfe5ae4fb6993f6199c00d1139/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5411569978/jobs/9834485829step:5:8675  Standalone code to reproduce the issue   Relevant log output ,2023-07-03T16:32:51Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,open,0,1,https://github.com/tensorflow/tensorflow/issues/61166,tf flaky test
1254,"以下是一个github上的tensorflow下的一个issue, 标题是(assert_shapes does not return anything and cannot be used as control dependency)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.0dev20230606  Custom code Yes  OS platform and distribution Windows 11 x64  Mobile device NA  Python version 3.10  Bazel version NA  GCC/compiler version NA  CUDA/cuDNN version NA  GPU model and memory NA  Current behavior? Calling `tf.debugging.assert_shapes(...)` does not return anything. As a consequence, unlike other assert operations, trying to use this assert as a control dependency with `tf.control_dependencies` in graph mode fails with `TypeError: Can not convert a NoneType into a Tensor or Operation`. Presumably, this would be fixed by simply adding a `return` before the call to `assert_shapes` in `assert_shapes_v2` in `tensorflow/python/ops/check_ops.py`. But I'd rather someone familiar with the code to judge whether that is fine orif maybe there is was a reason why this op is not returned.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,javidcf,assert_shapes does not return anything and cannot be used as control dependency," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.0dev20230606  Custom code Yes  OS platform and distribution Windows 11 x64  Mobile device NA  Python version 3.10  Bazel version NA  GCC/compiler version NA  CUDA/cuDNN version NA  GPU model and memory NA  Current behavior? Calling `tf.debugging.assert_shapes(...)` does not return anything. As a consequence, unlike other assert operations, trying to use this assert as a control dependency with `tf.control_dependencies` in graph mode fails with `TypeError: Can not convert a NoneType into a Tensor or Operation`. Presumably, this would be fixed by simply adding a `return` before the call to `assert_shapes` in `assert_shapes_v2` in `tensorflow/python/ops/check_ops.py`. But I'd rather someone familiar with the code to judge whether that is fine orif maybe there is was a reason why this op is not returned.  Standalone code to reproduce the issue   Relevant log output ",2023-07-03T14:18:14Z,type:bug comp:ops awaiting PR merge,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61163, Could you please have a look at this commit and the similar issue? Please let me know if that helps? Thank you!," Thank you for your comment. I do not think that is the same issue, though. As far as I can tell, `assert_shapes_v2` still returns nothing (`None`) in the updated version, so the issue (`Can not convert a NoneType into a Tensor or Operation`) would still remain.", Thank you for the response!  I was able to replicate this issue on colab using TF v2.13 and tfnightly. Please find the attached gists. Thank you!,Are you satisfied with the resolution of your issue? Yes No,"This issue is still not fixed, looks like the PR was reverted: https://github.com/tensorflow/tensorflow/pull/61276. The revert message mentioned that it was due to many breakages. Would someone be able to review what the breakages were?"
1233,"以下是一个github上的tensorflow下的一个issue, 标题是(Vectorizing a mapping function containing tf.io.read_file in tf.data pipeline is not working.)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.12.0rc112g0db597d0d75 2.12.0  Custom code Yes  OS platform and distribution RHEL8 .8  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have a function that reads input files, does some processing and returns the files. Upon using that function to do processing without batching first works fine. i.e. `dataset.map(some_func).batch(batch_size)` I was trying to speed up the data pipeline by vectorizing the processing part by batching the dataset and then mapping it to the tf.py_function i.e `dataset.batch(batch_size).map(tf.py_func_wrapped_function)` I followed the tensorflow guide for optimizing pipeline performance  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AkshayRoyal,Vectorizing a mapping function containing tf.io.read_file in tf.data pipeline is not working.," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version v2.12.0rc112g0db597d0d75 2.12.0  Custom code Yes  OS platform and distribution RHEL8 .8  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? I have a function that reads input files, does some processing and returns the files. Upon using that function to do processing without batching first works fine. i.e. `dataset.map(some_func).batch(batch_size)` I was trying to speed up the data pipeline by vectorizing the processing part by batching the dataset and then mapping it to the tf.py_function i.e `dataset.batch(batch_size).map(tf.py_func_wrapped_function)` I followed the tensorflow guide for optimizing pipeline performance  Standalone code to reproduce the issue   Relevant log output ",2023-07-03T13:08:00Z,stat:awaiting tensorflower type:bug comp:apis comp:data TF 2.12,open,0,1,https://github.com/tensorflow/tensorflow/issues/61162,", I was able to reproduce the issue on tensorflow v2.12 and tfnightly. Kindly find the gist of it here."
1886,"以下是一个github上的tensorflow下的一个issue, 标题是(Built from source Tensorflow is not linking (undefined references))， 内容是 ( Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.9.0  Custom code Yes  OS platform and distribution Windows 10  Mobile device 11th Gen Intel(R) Core(TM) i71165G7, 4 Core(s), 8 Logical Processor(s)  Python version 3.9.13  Bazel version Bazel 5.0.0   GCC/compiler version gcc.exe (MinGWW64 x86_64ucrtposixseh, built by Brecht Sanders) 12.2.0  CUDA/cuDNN version Not used  GPU model and memory Not used  Current behavior? I am trying to build this open source project https://github.com/gvne/spleeterpp/tree/master that uses Tensorflow. When I use the online available CAPI builds (available here https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpuwindowsx86_642.9.0.zip), this works without an issue. However, when I build my dll and lib  files from source so I can take advantage from the `/:arch:AVX2`, I get the following errors:  I tried to make some edits to the source code to fix this, as mentioned here under step 11 from https://medium.com/vitroxpublication/deeplearningframeworkstensorflowbuildfromsourceonwindowspythonccpugpud3aa4d0772d8.  > Some Bug Fixing Before Compiling : > Before we start, we should edit the TensorFlow source code, because you will end up with linking errors (unresolved external symbols) as shown below if you follow the typical framework building steps. >  >  > Session and SessionOptions symbols are not exported > So what are these errors? >  > Dynamiclink library(DLL) can only expose a maximum of 60,000 symbols which is one of DLL limitation. As TensorFlow has more than 60,000 symbols, so we have to )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SuperKogito,Built from source Tensorflow is not linking (undefined references)," Issue type Build/Install  Have you reproduced the bug with TensorFlow Nightly? No  Source source  TensorFlow version 2.9.0  Custom code Yes  OS platform and distribution Windows 10  Mobile device 11th Gen Intel(R) Core(TM) i71165G7, 4 Core(s), 8 Logical Processor(s)  Python version 3.9.13  Bazel version Bazel 5.0.0   GCC/compiler version gcc.exe (MinGWW64 x86_64ucrtposixseh, built by Brecht Sanders) 12.2.0  CUDA/cuDNN version Not used  GPU model and memory Not used  Current behavior? I am trying to build this open source project https://github.com/gvne/spleeterpp/tree/master that uses Tensorflow. When I use the online available CAPI builds (available here https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpuwindowsx86_642.9.0.zip), this works without an issue. However, when I build my dll and lib  files from source so I can take advantage from the `/:arch:AVX2`, I get the following errors:  I tried to make some edits to the source code to fix this, as mentioned here under step 11 from https://medium.com/vitroxpublication/deeplearningframeworkstensorflowbuildfromsourceonwindowspythonccpugpud3aa4d0772d8.  > Some Bug Fixing Before Compiling : > Before we start, we should edit the TensorFlow source code, because you will end up with linking errors (unresolved external symbols) as shown below if you follow the typical framework building steps. >  >  > Session and SessionOptions symbols are not exported > So what are these errors? >  > Dynamiclink library(DLL) can only expose a maximum of 60,000 symbols which is one of DLL limitation. As TensorFlow has more than 60,000 symbols, so we have to ",2023-07-03T12:07:12Z,stat:awaiting tensorflower type:bug type:build/install subtype:windows TF 2.9 subtype:cpu-intel,closed,0,9,https://github.com/tensorflow/tensorflow/issues/61159,"According to this https://github.com/gvne/spleeterpp/blob/v0.1/docs/source/build.rst I should add the following lines to `tensorflow/tools/def_file_filter/def_file_filter.py.tpl`  However these steps are for TF 1.14.0, and when I try the above for TF 2.9, I get the following error:   ","moving the following lines to line 275 in the  `tensorflow/tools/def_file_filter/def_file_filter.py.tpl` causes a different error.   The build almost terminated correctly in this case, but eventually I ended up with these linking errors: "," , Could you please take a look into this. Thanks!","Hi,  could you please try the latest version of TF? TF 2.9.0 is out of support.","Hello ,  thank you for responding. Testing with the TF 2.12.0 yields the following logs:   I will try with TF 2.13.0 tomorrow. ",These are my error logs for the 2.13.0 version:  ,"Hi , please try MSVC 2019",Closing since Windows compilation is not longer supported,Are you satisfied with the resolution of your issue? Yes No
783,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.image.extract_patches error for tf.RaggedTensor inputs)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? `tf.image.extract_patches` should be able to extract patches from `ragged `tensors.  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,RaminNateghi,tf.image.extract_patches error for tf.RaggedTensor inputs, Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version tf 2.12.0  Custom code Yes  OS platform and distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? `tf.image.extract_patches` should be able to extract patches from `ragged `tensors.  Standalone code to reproduce the issue   Relevant log output ,2023-07-02T10:13:52Z,stat:awaiting response type:bug stale comp:ops comp:core TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61149,"Hi  , The reason for this behaviour is not all Ops supports Ragged Tensors. You can find the list of supported Ops here. For `tf.image` module only the following Ops support Ragged Tensors. > tf.image.adjust_brightness(image, delta) > tf.image.adjust_gamma(image, gamma=1, gain=1) > tf.image.convert_image_dtype(image, dtype, saturate=False, name=None) > tf.image.random_brightness(image, max_delta, seed=None) > tf.image.resize(images, size, method='bilinear', preserve_aspect_ratio=False, antialias=False, name=None) > tf.image.stateless_random_brightness(image, max_delta, seed) Hope this will resolve your query. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,", thank you for your explanation.","Hi  , Can we considered it as resolved now. Please feel free to close the issue if resolved for you. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1375,"以下是一个github上的tensorflow下的一个issue, 标题是(_SparseSparseMaximumGrad throws TypeError in forward gradient computation)， 内容是 ( Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.0dev20230630  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When the function has a `tf.sparse.maximum` call, the forwardmode gradient computation fails with `TypeError: _SparseSparseMaximumGrad() takes 2 positional arguments but 3 were given`. After inspection, i find that SparseTensor is not supported for differentiation. In the example code below, computing reversemode gradient of `y` (sparse tensor) will result in a `TypeError: Type SparseTensor is not supported as a gradient source or gradient target.` However, in the forward mode gradient computation, I am trying to compute gradient for a nonsparse tensor `complex_data`, and I think it should not be affected by the  `tf.sparse.maximum` call?  Standalone code to reproduce the issue   Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,trickiwoo,_SparseSparseMaximumGrad throws TypeError in forward gradient computation," Issue type Bug  Have you reproduced the bug with TensorFlow Nightly? Yes  Source source  TensorFlow version 2.14.0dev20230630  Custom code Yes  OS platform and distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current behavior? When the function has a `tf.sparse.maximum` call, the forwardmode gradient computation fails with `TypeError: _SparseSparseMaximumGrad() takes 2 positional arguments but 3 were given`. After inspection, i find that SparseTensor is not supported for differentiation. In the example code below, computing reversemode gradient of `y` (sparse tensor) will result in a `TypeError: Type SparseTensor is not supported as a gradient source or gradient target.` However, in the forward mode gradient computation, I am trying to compute gradient for a nonsparse tensor `complex_data`, and I think it should not be affected by the  `tf.sparse.maximum` call?  Standalone code to reproduce the issue   Relevant log output ",2023-06-30T19:23:24Z,stat:awaiting response type:bug stale comp:ops TF 2.13,closed,0,5,https://github.com/tensorflow/tensorflow/issues/61132,"Hi  , Thanks for reporting. I have replicated the issue with Tf2.12 and tfnightly as well and attached gist for reference. Needs to dig more to check the reason for this behaviour. Thanks!","Hi, I executed the code and encountered the same error. However, after making some changes and converting sparse tensors into dense tensors, the code worked. Please refer to this gist. Thanks",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
918,"以下是一个github上的tensorflow下的一个issue, 标题是(Internal error: Error applying delegate when trying to use TensorFlow Lite NNAPI delegate on Google Pixel 7)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tensorflowlite 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device Google Pixel 7  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When I try to use the NNAPI delegate to run the OpenAI whisper model on a Pixel 7, it crashes when trying to initialize the TFLite interpreter.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,soupslurpr,Internal error: Error applying delegate when trying to use TensorFlow Lite NNAPI delegate on Google Pixel 7,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tensorflowlite 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device Google Pixel 7  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When I try to use the NNAPI delegate to run the OpenAI whisper model on a Pixel 7, it crashes when trying to initialize the TFLite interpreter.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-30T04:21:02Z,stat:awaiting tensorflower type:bug TFLiteNNAPIDelegate TF 2.12,open,0,18,https://github.com/tensorflow/tensorflow/issues/61126,Hi   Could you please try using the nightly snapshot and let us know if you are still facing the issue? Thanks.,"Hello, thanks for responding. I just tried version 0.0.0nightlySNAPSHOT and the error still occurs.","Hi , There is a similar issue here: https://github.com/tensorflow/tensorflow/issues/61095, can you try 2.11 or 2.10 for now?","Hello , I just tried with both 2.11.0 and 2.10.0, and it didn't work, same error. Also tried with 2.0.0.","Hi , can you please let us know the minimum SDK (API Level) you are targeting? Also if you are comfortable exporting your Android project or a toy version which reproduces this issue that'll be extremely helpful! Including the .tflite model would be easiest, otherwise letting us know how you got it could also work.", The minimum SDK is 28 and target SDK is 33. Here is the project that reproduces this issue: https://github.com/soupslurpr/NNAPIwhispertest,"Also, I got the .tflite from running this google colab: https://colab.research.google.com/github/usefulsensors/openaiwhisper/blob/main/notebooks/generate_tflite_from_whisper.ipynb","Hi , I'm having issues opening the Android Studio project (hangs on loading), what platform are you using to open/edit your project? (MacOS, Windows, or *nix?), are there any dependencies you think I may need to install (Such as Java SDK version?)","> Hi , I'm having issues opening the Android Studio project (hangs on loading), what platform are you using to open/edit your project? (MacOS, Windows, or *nix?), are there any dependencies you think I may need to install (Such as Java SDK version?) I'm running Fedora, its using Java 17, that is probably why. I'm also using the latest alpha of Android Studio which also seems to be why it isn't working for you. You can try using the latest alpha of it, or use the below stable version.  I made a version that is compatible with the latest stable version of Android Studio here: https://github.com/soupslurpr/nnapiwhispertestandroidstudiostable",Are you satisfied with the resolution of your issue? Yes No,"Misclick, oops","It seems this project requires a real device or a machine which supports VTx or SVM. Hi , can you please take a look? Thanks!"," if you haven't figured it out yet, the tflite model file you use is the culprit and It's a weightsonly quantized one, which doesn't work with NNAPI delegate. ",">  if you haven't figured it out yet, the tflite model file you use is the culprit and It's a weightsonly quantized one, which doesn't work with NNAPI delegate. Ah, I see. Thanks for informing me of this. Do you know of a way to make it compatible?",">  if you haven't figured it out yet, the tflite model file you use is the culprit and It's a weightsonly quantized one, which doesn't work with NNAPI delegate. i have this problem with whispertiny.tflite model but i use many other models like this one: https://tfhub.dev/tulasiram58827/litemodel/hifigan/float16/1 and still get this error without any success :      Caused by: java.lang.IllegalArgumentException: Internal error: Error applying delegate:          at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method) and my code simply is: NnApiDelegate nnApiDelegate = new NnApiDelegate(); Interpreter.Options options = (new Interpreter.Options()).addDelegate(nnApiDelegate); Interpreter  mInterpreter = new Interpreter(tfliteModel,options); < where Error shows up   ","I meant to comment on this previously, but forgot. I've also been working with a TFLite model of Whisper and there are problems beyond quantization. If using the one from https://github.com/nyadlasys/whisper.tflite, many of the ops simply aren't supported for the GPU delegate. Some of these are the control flow ops in the decoding process (such as `If` and `While`). None of these types of control flow ops are supported by the GPU delegate (or the NNAPI version either probably). Additionally, there are computation ops that aren't supported either by the delegate (I forget it at the moment, but I believe it is something like `NDScatterAndUpdate` that causes problems). Regardless, without modifying the graph definition to only supported ops, how it was quantized won't matter.", how would you go about creating a tiny model that supports GPU or NNAPI?,">  how would you go about creating a tiny model that supports GPU or NNAPI? You would need to do a couple things:  First, you would need to separate the encoder and decoder and reimplement the control flow in whatever language you are using (presumably Java if you are using NNAPI).   Second, the particular op `NDScatterAndUpdate` is not supported. You would need to reimplement this functionality with supported ops (presumably possible, I'm not sure exactly how)."
1292,"以下是一个github上的tensorflow下的一个issue, 标题是(Migrate fuzzers to FuzzTest format)， 内容是 (Creates a set of fuzzers to FuzzTest style. One of the benefits is that this will reduce storage size required for the fuzzers, because the fuzzers will all be based off the same binary whereas the nonFuzzTest fuzzers will have a binary per fuzzer. This storage requirement has caused an issue on the OSSFuzz side: https://github.com/google/ossfuzz/issues/9792 Migrating to FuzzTest will make it easier to add new opsspecific fuzzers since we won't have to worry about disk size. The existing fuzzesr can be several GBs of storage and it quickly goes beyond what we have available at OSSFuzz. It would however be nice to reuse the existing fuzzer helper logic from fuzz_session.h so I added a macro similar to what we have for libFuzzer but simple for FuzzTest. I migrated a set of the existing fuzzers. I figured it would be nice to do a soft transition, so we can remove the existing fuzzers after the ones introduced in this PR has shown to run for a while. I'm also curious in whether we will see a difference in performance from the FuzzTest and libFuzzer harnesses.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,DavidKorczynski,Migrate fuzzers to FuzzTest format,"Creates a set of fuzzers to FuzzTest style. One of the benefits is that this will reduce storage size required for the fuzzers, because the fuzzers will all be based off the same binary whereas the nonFuzzTest fuzzers will have a binary per fuzzer. This storage requirement has caused an issue on the OSSFuzz side: https://github.com/google/ossfuzz/issues/9792 Migrating to FuzzTest will make it easier to add new opsspecific fuzzers since we won't have to worry about disk size. The existing fuzzesr can be several GBs of storage and it quickly goes beyond what we have available at OSSFuzz. It would however be nice to reuse the existing fuzzer helper logic from fuzz_session.h so I added a macro similar to what we have for libFuzzer but simple for FuzzTest. I migrated a set of the existing fuzzers. I figured it would be nice to do a soft transition, so we can remove the existing fuzzers after the ones introduced in this PR has shown to run for a while. I'm also curious in whether we will see a difference in performance from the FuzzTest and libFuzzer harnesses.",2023-06-29T09:34:09Z,size:M comp:core,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61122, ,Hi  Can you please review this PR ? Thank you!,This has been superseded by https://github.com/tensorflow/tensorflow/pull/61221 Closing
837,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/data/kernel_tests:snapshot_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/data/kernel_tests:snapshot_test sometimes fails x86 log https://source.cloud.google.com/results/invocations/8b60bfbab6b64503aa4362e8bbe1a094/log AARCH64 log  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/data/kernel_tests:snapshot_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/data/kernel_tests:snapshot_test sometimes fails x86 log https://source.cloud.google.com/results/invocations/8b60bfbab6b64503aa4362e8bbe1a094/log AARCH64 log  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T15:59:05Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,closed,0,3,https://github.com/tensorflow/tensorflow/issues/61116,tf flaky test,AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5378348054/jobs/9758026382step:5:8430,Are you satisfied with the resolution of your issue? Yes No
948,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/distribute/experimental/rpc:rpc_ops_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute/experimental/rpc:rpc_ops_test sometimes fails. x86 log https://source.cloud.google.com/results/invocations/e7ac5e3166d54f2ea095045cb52cc20f/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5348094575/jobs/9697499180step:5:8263  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/distribute/experimental/rpc:rpc_ops_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute/experimental/rpc:rpc_ops_test sometimes fails. x86 log https://source.cloud.google.com/results/invocations/e7ac5e3166d54f2ea095045cb52cc20f/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5348094575/jobs/9697499180step:5:8263  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T15:54:29Z,stat:awaiting tensorflower type:bug subtype: ubuntu/linux TF 2.13,open,0,1,https://github.com/tensorflow/tensorflow/issues/61115,tf flaky test
994,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/data/experimental/kernel_tests/service:local_workers_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/data/experimental/kernel_tests/service:local_workers_test sometimes fails or timeouts. x86 log https://source.cloud.google.com/results/invocations/e41a9dd419a34298b34f6a32eca50e08/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5383187293/jobs/9769619751step:5:8335  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/data/experimental/kernel_tests/service:local_workers_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/data/experimental/kernel_tests/service:local_workers_test sometimes fails or timeouts. x86 log https://source.cloud.google.com/results/invocations/e41a9dd419a34298b34f6a32eca50e08/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5383187293/jobs/9769619751step:5:8335  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T15:34:17Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux TF 2.13,open,0,1,https://github.com/tensorflow/tensorflow/issues/61113,tf flaky test
985,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/distribute/failure_handling:gce_failure_handler_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute/failure_handling:gce_failure_handler_test sometimes fails or timeouts. x86 log https://source.cloud.google.com/results/invocations/66d8ddaa3dbe4464837c053157b11659/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5354839739/jobs/9712379821step:5:12470  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/distribute/failure_handling:gce_failure_handler_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute/failure_handling:gce_failure_handler_test sometimes fails or timeouts. x86 log https://source.cloud.google.com/results/invocations/66d8ddaa3dbe4464837c053157b11659/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5354839739/jobs/9712379821step:5:12470  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T14:07:42Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux TF 2.13,open,0,1,https://github.com/tensorflow/tensorflow/issues/61111,tf flaky test
983,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/data/experimental/kernel_tests/service:auto_shard_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/data/experimental/kernel_tests/service:auto_shard_test will sometimes timeout. x86 log https://source.cloud.google.com/results/invocations/75230523dc0440adbcf306df3b94a119/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5383235016/jobs/9769729147step:5:8442  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",glm,elfringham,//tensorflow/python/data/experimental/kernel_tests/service:auto_shard_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/data/experimental/kernel_tests/service:auto_shard_test will sometimes timeout. x86 log https://source.cloud.google.com/results/invocations/75230523dc0440adbcf306df3b94a119/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5383235016/jobs/9769729147step:5:8442  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T13:20:03Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux subtype:bazel,open,0,1,https://github.com/tensorflow/tensorflow/issues/61109,tf flaky test
953,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/distribute:cross_device_ops_test_2gpu is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute:cross_device_ops_test_2gpu fails or timeouts sometimes x86 log https://source.cloud.google.com/results/invocations/3008a6bcb49f4776871c1c5ae046a470/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5379162649/jobs/9759994992step:5:9913  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/distribute:cross_device_ops_test_2gpu is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute:cross_device_ops_test_2gpu fails or timeouts sometimes x86 log https://source.cloud.google.com/results/invocations/3008a6bcb49f4776871c1c5ae046a470/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5379162649/jobs/9759994992step:5:9913  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T12:15:43Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,open,0,3,https://github.com/tensorflow/tensorflow/issues/61107,tf flaky test,"Thanks. This is a known issue due to portpicker cannot always guarantee getting a fresh, unused port for the tests. We don't really have a good strategy to deal with this problem at the moment, other than retrying the test. Any suggestions and/or contribution is highly welcomed.", If there was a way that the build/test process could start a singleton process with portpicker as a server that should resolve the problems with it not being thread safe but I am not a bazel expert and do not know if or how that could be achieved. Each usage of portpicker in a test would then call out to the singleton process with the server and hopefully get a unique port allocation. Alternatively or additionally making the code that establishes a network connection to be more robust so that it can detect and retry when it fails due to a port conflict.
971,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/distribute:moving_averages_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute:moving_averages_test fails sometimes. x86 log https://source.cloud.google.com/results/invocations/1e04806576db4dabb1a5093dd542b27d/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5383507734/jobs/9770356325step:5:8417 Looks like a network port conflict issue  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/distribute:moving_averages_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute:moving_averages_test fails sometimes. x86 log https://source.cloud.google.com/results/invocations/1e04806576db4dabb1a5093dd542b27d/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5383507734/jobs/9770356325step:5:8417 Looks like a network port conflict issue  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T11:56:02Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,open,0,1,https://github.com/tensorflow/tensorflow/issues/61105,tf flaky test
1007,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/distribute/failure_handling:failure_handler_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute/failure_handling:failure_handler_test will timeout sometimes x86 log https://source.cloud.google.com/results/invocations/302ca1a4593b430cb278038351228670/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5363735926/jobs/9731502578step:5:11034 Looks like a network port conflict.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,elfringham,//tensorflow/python/distribute/failure_handling:failure_handler_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/distribute/failure_handling:failure_handler_test will timeout sometimes x86 log https://source.cloud.google.com/results/invocations/302ca1a4593b430cb278038351228670/log AARCH64 log https://github.com/tensorflow/tensorflow/actions/runs/5363735926/jobs/9731502578step:5:11034 Looks like a network port conflict.  Standalone code to reproduce the issue   Relevant log output  ,2023-06-28T10:57:28Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,open,0,1,https://github.com/tensorflow/tensorflow/issues/61104,tf flaky test
1853,"以下是一个github上的tensorflow下的一个issue, 标题是(Build aar with models using tfops)， 内容是 (I am trying to build a small aar for specific ML models where one of them is using tfops, I don't want to use the nighty version due to its huge size.  I am following this documentation,  I downloaded the provided Dockerfile and I updated the following fields  commandlinetools to the latest version 9477386_latest  ANDROID_API_LEVEL to 33  ANDROID_BUILD_TOOLS_VERSION to 34.0.0.  I started the docker container, configured the workspace, cloned tensorflow from this repository and checked out to branch r2.13, downloaded bazel     System information    **OS Platform and Distribution > Linux**:    **TensorFlow downloaded from source**: r2.13    **Python version**: 3.11    **Bazel version**: 5.3.0  When I run the bash command ` bash tensorflow/lite/tools/build_aar.sh   input_models=model1.tflite,model2.tflite   target_archs=x86,x86_64,arm64v8a,armeabiv7a` with my models it fails with the following error log ... INFO: Analyzed target //tmp:tensorflowliteselecttfops (461 packages loaded, 50228 targets configured). INFO: Found 1 target... ERROR: /tensorflow_src/tensorflow/BUILD:1646:19: Action tensorflow/_api/v2/v2.py [for host] failed: (Exit 1): bash failed: error executing command /bin/bash c ... (remaining 1 argument skipped) 20230627 22:43:43.289759: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: SSE3, in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):   File ""/root/.cache/bazel/_bazel_root/43801f1e35f242f)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,LobnaMazhar,Build aar with models using tfops,"I am trying to build a small aar for specific ML models where one of them is using tfops, I don't want to use the nighty version due to its huge size.  I am following this documentation,  I downloaded the provided Dockerfile and I updated the following fields  commandlinetools to the latest version 9477386_latest  ANDROID_API_LEVEL to 33  ANDROID_BUILD_TOOLS_VERSION to 34.0.0.  I started the docker container, configured the workspace, cloned tensorflow from this repository and checked out to branch r2.13, downloaded bazel     System information    **OS Platform and Distribution > Linux**:    **TensorFlow downloaded from source**: r2.13    **Python version**: 3.11    **Bazel version**: 5.3.0  When I run the bash command ` bash tensorflow/lite/tools/build_aar.sh   input_models=model1.tflite,model2.tflite   target_archs=x86,x86_64,arm64v8a,armeabiv7a` with my models it fails with the following error log ... INFO: Analyzed target //tmp:tensorflowliteselecttfops (461 packages loaded, 50228 targets configured). INFO: Found 1 target... ERROR: /tensorflow_src/tensorflow/BUILD:1646:19: Action tensorflow/_api/v2/v2.py [for host] failed: (Exit 1): bash failed: error executing command /bin/bash c ... (remaining 1 argument skipped) 20230627 22:43:43.289759: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: SSE3, in other operations, rebuild TensorFlow with the appropriate compiler flags. Traceback (most recent call last):   File ""/root/.cache/bazel/_bazel_root/43801f1e35f242f",2023-06-27T23:07:39Z,stat:awaiting response type:build/install stale comp:lite TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61101,"Hi   This seems to be an error caused by Jax library. Have you configured https://www.tensorflow.org/lite/android/lite_buildconfigure_workspace_and_bazelrc and set the options accordingly? Also, can you please provide toy tflite model inorder to reproduce the issue? Thanks.","Hi   Yes, I followed the configurations and I made sure it was successful by printing the content of the `.tf_configure.bazelrc` file as follows > > more .tf_configure.bazelrc build action_env PYTHON_BIN_PATH=""/usr/bin/python3"" build action_env PYTHON_LIB_PATH=""/usr/lib/python3/distpackages"" build python_path=""/usr/bin/python3"" build:opt copt=Wnosigncompare build:opt host_copt=Wnosigncompare build action_env ANDROID_NDK_HOME=""/android/ndk"" build action_env ANDROID_NDK_API_LEVEL=""21"" build action_env ANDROID_BUILD_TOOLS_VERSION=""34.0.0"" build action_env ANDROID_SDK_API_LEVEL=""33"" build action_env ANDROID_SDK_HOME=""/android/sdk"" test flaky_test_attempts=3 test test_size_filters=small,medium test:v1 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial test:v1 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu test:v2 test_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,oss_serial,v1only test:v2 build_tag_filters=benchmarktest,no_oss,oss_excluded,gpu,v1only Are there any extra steps that I should do to install the Jax library in separate? Regarding the used tflite model, unfortunately I won't be able to share it because it is confidential to my job.","I tried another converted version of the model, and I ended up with a different error. > + bazel build c opt cxxopt=std=c++17 fat_apk_cpu=x86,x86_64,arm64v8a,armeabiv7a define=android_dexmerger_tool=d8_dexmerger define=android_incremental_dexing_tool=d8_dexbuilder define=xnn_enable_arm_fp16=false host_crosstool_top=//tools/cpp:toolchain //tmp:tensorflowlite > INFO: Options provided by the client: >   Inherited 'common' options: isatty=1 terminal_columns=179 > INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc: >   Inherited 'common' options: experimental_repo_remote_exec > INFO: Reading rc options for 'build' from /etc/bazel.bazelrc: >   'build' options: action_env=DOCKER_CACHEBUSTER=1687840109499695775 host_action_env=DOCKER_HOST_CACHEBUSTER=1687840109559438170 > INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc: >   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility > INFO: Reading rc options for 'build' from /tensorflow_src/.tf_configure.bazelrc: >   'build' options: action_env PYTHON_BIN_PATH=/usr/bin/python3 action_env PYTHON_LIB_PATH=/usr/lib/python3/distpackages python_path=/usr/bin/python3 action_env ANDROID_NDK_HOME=/android/ndk action_env ANDROID_NDK_API_LEVEL=21 action_env ANDROID_BUILD_TOOLS_VERSION=34.0.0 action_env ANDROID_SDK_API_LEVEL=33 action_env ANDROID_SDK_HOME=/android/sdk > INFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc: >   'build' options: deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils,tensorflow/core/tfrt/utils/debug > INFO: Found applicable config definition build:short_logs in file /tensorflow_src/.bazelrc: output_filter=DONT_MATCH_ANYTHING > INFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 > INFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: define=build_with_onednn_v2=true host_copt=w copt=Wnoall copt=Wnoextra copt=Wnodeprecated copt=Wnodeprecateddeclarations copt=Wnoignoredattributes copt=Wnoarraybounds copt=Wunusedresult copt=Werror=unusedresult copt=Wswitch copt=Werror=switch copt=Wnoerror=unusedbutsetvariable define=PREFIX=/usr define=LIBDIR=$(PREFIX)/lib define=INCLUDEDIR=$(PREFIX)/include define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include cxxopt=std=c++17 host_cxxopt=std=c++17 config=dynamic_kernels experimental_guard_against_concurrent_changes > INFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: define=dynamic_loaded_kernels=true copt=DAUTOLOAD_DYNAMIC_KERNELS > INFO: Analyzed target //tmp:tensorflowlite (1 packages loaded, 527 targets configured). > INFO: Found 1 target... > **ERROR: /tensorflow_src/tmp/BUILD:4:30: gen_selected_ops failed: (Segmentation fault): generate_op_registrations failed: error executing command bazelout/k8optexec50AE0418/bin/tensorflow/lite/tools/generate_op_registrations 'namespace=' ... (remaining 3 arguments skipped) > Target //tmp:tensorflowlite failed to build > Use verbose_failures to see the command lines of failed build steps. > INFO: Elapsed time: 1.788s, Critical Path: 0.90s > INFO: 2 processes: 2 internal. > FAILED: Build did NOT complete successfully** >  **Question**  Should I specify the used tfops while running the command as follows?  As I'm using the simpler command  as specified here","Hi , the simpler command should suffice as the script should look into the input models for the ops being used. Are you using custom ops? your other command seems to suggest so, perhaps can you or your team produce a simpler toy model with just the custom ops so that we can reproduce without violating confidentiality? Also this will help us identify if those are the cause of the issue.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1361,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.data.Dataset prefetch not fetching data asynchronously)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian/Linux 11  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? After implementing a data pipeline using tf.data.Dataset to pull image data from Google Cloud Storage, TensorBoard profiler shows that the GPU compute and CPU prefetch are running synchronously. I used data.Dataset.AUTOTUNE to determine the appropriate prefetch batch size. Monitoring GPU usage while the model is running confirms this with the GPU at 0% utilization to actually computing something for about a 2:1 ratio, which is reflected in the profiler. CPU usage when monitored does not appear to max out. I expected the prefetch to occur concurrently with GPU processing as described in the data.Dataset documentation and tutorials. !ch !cp !gp  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,zackwohl,tf.data.Dataset prefetch not fetching data asynchronously,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian/Linux 11  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? After implementing a data pipeline using tf.data.Dataset to pull image data from Google Cloud Storage, TensorBoard profiler shows that the GPU compute and CPU prefetch are running synchronously. I used data.Dataset.AUTOTUNE to determine the appropriate prefetch batch size. Monitoring GPU usage while the model is running confirms this with the GPU at 0% utilization to actually computing something for about a 2:1 ratio, which is reflected in the profiler. CPU usage when monitored does not appear to max out. I expected the prefetch to occur concurrently with GPU processing as described in the data.Dataset documentation and tutorials. !ch !cp !gp  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-26T19:39:17Z,stat:awaiting tensorflower type:bug comp:data type:performance TF 2.11,open,1,4,https://github.com/tensorflow/tensorflow/issues/61084,"Hi  , Thanks for reaching us. Could you able to submit a colab gist replicating the reported behaviour with an image dataset. Also can you confirm the behaviour with `buffer_size=1 or 2` instead of `tf.data.AUTOTUNE` just to cross check the behaviour. Thanks!","Hi , I tried running this with buffer_size=2, and it continued to run synchronously. I've attached images of the tensorboard profiler trace viewer. !gpu_2 !pf_2 How would I submit colab gist and what would you need in terms of data? I currently have my code in a jupyter notebook. Thanks","Hi , just wanted to follow up on next steps here.","Hi , I'm still awaiting a response."
1493,"以下是一个github上的tensorflow下的一个issue, 标题是(Requested feature_data_ size 536907080 doesn't match 1960; Feature generation failed;)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version V2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello Together, I'm having a Problem with the micro_speech example for arduino from this repo: https://github.com/tensorflow/tflitemicroarduinoexamples/tree/main/examples/micro_speech When trying to use this example with a new trained model from this jupyter noteboobk: https://github.com/tensorflow/tflitemicro/tree/main/tensorflow/lite/micro/examples/micro_speech/train I always get the same error message: Requested feature_data_ size 536907080 doesn't match 1960 Feature generation failed The only thing i changed in the notebook was the tensorflow version. This is because this notebook was using 1.x Version which is no longer supported by colab and i changed it to work with the latest 2.x version Can anyone help here? Greetings, Patrick  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Svobi27,Requested feature_data_ size 536907080 doesn't match 1960; Feature generation failed;,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version V2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello Together, I'm having a Problem with the micro_speech example for arduino from this repo: https://github.com/tensorflow/tflitemicroarduinoexamples/tree/main/examples/micro_speech When trying to use this example with a new trained model from this jupyter noteboobk: https://github.com/tensorflow/tflitemicro/tree/main/tensorflow/lite/micro/examples/micro_speech/train I always get the same error message: Requested feature_data_ size 536907080 doesn't match 1960 Feature generation failed The only thing i changed in the notebook was the tensorflow version. This is because this notebook was using 1.x Version which is no longer supported by colab and i changed it to work with the latest 2.x version Can anyone help here? Greetings, Patrick  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-24T15:13:55Z,type:bug comp:micro TF 2.8,closed,0,9,https://github.com/tensorflow/tensorflow/issues/61074,"Hi   I was able to run the example after making some changes for TF 2.x version, in TF 2.12 which is the latest stable version. Please find the gist here. Thanks.",Hello   Thanks for the response! I tried the arduino example with the model from your notebook but i still get the same error message unfortunatly...,  I see that at a ticket  CC(Unable to infer shape of placeholder) has been opened in TFLite Micro repo. Could you please close this issue as it being tracked there? Thanks., Done,"Hi   As mentioned earlier,  this issue can be closed here and the issue: https://github.com/tensorflow/tflitemicro/issues/2079 can be opened since it is related to TFLite Micro. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Sorry missunderstood! reopened the issue again in the TFLite Micro repo,Thanks for opening the issue in TFLite Micro repro. Closing it here.,Are you satisfied with the resolution of your issue? Yes No
1878,"以下是一个github上的tensorflow下的一个issue, 标题是(Call TensorFlowLite model with `CVPixelBuffer` from Camera)， 内容是 (Hey! Sorry I know this is offtopic and a question, but I couldn't find any examples or documentation on optimizing inputtensors for realtime usage. I'm the author of a very popular Camera library for mobile apps (React Native / VisionCamera) and I'm trying to add a TensorFlow Lite integration to the Camera. This should be as generic as possible and will allow the user to drop in any `.tflite` model which just gets called with the Camera frame (`CMSampleBuffer` on iOS, `android.media.Image` on Android) and returns _any_ data (output tensors). I started with implementing the iOS part in ObjectiveC and set up my TensorFlow code like this:  And then I have my Camera Frame Callback which gets called for every Frame the Camera ""sees"" (60 times a second at 60 FPS):  Now I have two problems: 1. The Frame is any arbitrary size, but the models are trained to specific sizes. So I'm obviously getting the following error:          I want to avoid Frame resizing here and ideally have the `TFLInterpreter` accept the Frame (`CMSampleBuffer`) _as is_ and do a stride/offset/jumps internally  is that even possible? If not, how can I figure out what Frame size I need to downscale to? 2. The `TFLInterpreter` can only be invoked with `NSData`, and my Frame is a `CMSampleBuffer` allocated on the GPU. Is there any way to avoid this GPU > CPU copy and stay on the GPU buffer the whole time? I have safe read access to that buffer in this callback. I've seen some MLKit samples (e.g. MLKit Object Detection iOS) and they allow you to just pass the `CMSampleBuffer` to the model  I'm wondering how this will be handled internally as it se)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mrousavy,Call TensorFlowLite model with `CVPixelBuffer` from Camera,"Hey! Sorry I know this is offtopic and a question, but I couldn't find any examples or documentation on optimizing inputtensors for realtime usage. I'm the author of a very popular Camera library for mobile apps (React Native / VisionCamera) and I'm trying to add a TensorFlow Lite integration to the Camera. This should be as generic as possible and will allow the user to drop in any `.tflite` model which just gets called with the Camera frame (`CMSampleBuffer` on iOS, `android.media.Image` on Android) and returns _any_ data (output tensors). I started with implementing the iOS part in ObjectiveC and set up my TensorFlow code like this:  And then I have my Camera Frame Callback which gets called for every Frame the Camera ""sees"" (60 times a second at 60 FPS):  Now I have two problems: 1. The Frame is any arbitrary size, but the models are trained to specific sizes. So I'm obviously getting the following error:          I want to avoid Frame resizing here and ideally have the `TFLInterpreter` accept the Frame (`CMSampleBuffer`) _as is_ and do a stride/offset/jumps internally  is that even possible? If not, how can I figure out what Frame size I need to downscale to? 2. The `TFLInterpreter` can only be invoked with `NSData`, and my Frame is a `CMSampleBuffer` allocated on the GPU. Is there any way to avoid this GPU > CPU copy and stay on the GPU buffer the whole time? I have safe read access to that buffer in this callback. I've seen some MLKit samples (e.g. MLKit Object Detection iOS) and they allow you to just pass the `CMSampleBuffer` to the model  I'm wondering how this will be handled internally as it se",2023-06-23T13:34:17Z,stat:awaiting response comp:lite comp:lite-support,closed,1,5,https://github.com/tensorflow/tensorflow/issues/61069,"Hi, , >1. The Frame is any arbitrary size, but the models are trained to specific sizes. So I'm obviously getting the following error: > > > >Input tensor at index (9142529056) expects data size (110592), but got (8355840). I want to avoid Frame resizing here and ideally have the TFLInterpreter accept the Frame (CMSampleBuffer) as is and do a stride/offset/jumps internally  is that even possible? If not, how can I figure out what Frame size I need to downscale to? Currently we do not support dynamic input shapes, see: https://www.tensorflow.org/lite/guide/inferencerun_inference_with_dynamic_shape_model Unfortunately, we do not plan to support it soon due to performance considerations. Typically this means the input needs to be preprocessed into a static shape. >2. The TFLInterpreter can only be invoked with NSData, and my Frame is a CMSampleBuffer allocated on the GPU. Is there any way to avoid this GPU > CPU copy and stay on the GPU buffer the whole time? I have safe read access to that buffer in this callback. I believe it can stay on the GPU Buffer, can you review this link and let me know if it answers your question? https://www.tensorflow.org/lite/ios/delegates/gpuinputoutput_buffers_using_c_api If this resolves your questions, please feel free to close the issue.","Thanks for your reply   I'm trying to use the C/C++ API instead of the ObjectiveC API > Note: The following technique is only available when you are using Bazel or building TensorFlow Lite yourself. C++ API can't be used with CocoaPods. There is a `TensorFlowLiteC` pod on CocoaPods, is that just shipping a prebuilt XCFramework? Am I expected to just use that? I'm in an environment where using bazel is really hard to set up and distribute.","Hi , TensorFlowLiteC is   https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/ios/TensorFlowLiteC.podspec CC(0.5.0 wheel install on Mac OS X using Homebrew python broken) So, if you're using the C/C++ API, then you have to use bazel/build from source to use the GPU API","Gotcha, thanks. I'll stick to the ObjectiveC APIs then since using bazel is not really possible in my environment.","No worries, , if you have no more open items for this issue please feel free to close."
1017,"以下是一个github上的tensorflow下的一个issue, 标题是(from tensorflow.python._pywrap_tensorflow_internal import * ImportError: libflatbuffers.so.2: cannot open shared object file: No such file or directory)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10.0  Custom Code Yes  OS Platform and Distribution CentOS Linux 7  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I was trying to import tensorflow, and then the following error occured:  I am not sure what went wrong here. It used to work fine, and the only thing I've done since then is to update nodejs through conda.   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sejin8642,from tensorflow.python._pywrap_tensorflow_internal import * ImportError: libflatbuffers.so.2: cannot open shared object file: No such file or directory,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10.0  Custom Code Yes  OS Platform and Distribution CentOS Linux 7  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I was trying to import tensorflow, and then the following error occured:  I am not sure what went wrong here. It used to work fine, and the only thing I've done since then is to update nodejs through conda.   Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-22T23:11:07Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.10,closed,0,4,https://github.com/tensorflow/tensorflow/issues/61064,", Could you please confirm whether you are trying to install the tensorflow v2.10 and following the steps provided on the tensorflow official document. https://www.tensorflow.org/install/pip Also please let us know the hardward configurations you are using and try to follow the tested build configurations which were provided here. https://www.tensorflow.org/install/sourcecpu Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
963,"以下是一个github上的tensorflow下的一个issue, 标题是(Crashes in model.save, wrapt error)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Fodera Linux  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Crashed when calling model.save() See log below. Worked after deinstalling tensorflow and wrapt. wrapt was 1.15.x and installing tensorflow and wrapt==1.14.1 The problem is that when installing tensorflow, the wrapt 1.15.x is installed automatically and this is not playing with tensorflow.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cmayer,"Crashes in model.save, wrapt error","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Fodera Linux  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Crashed when calling model.save() See log below. Worked after deinstalling tensorflow and wrapt. wrapt was 1.15.x and installing tensorflow and wrapt==1.14.1 The problem is that when installing tensorflow, the wrapt 1.15.x is installed automatically and this is not playing with tensorflow.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-22T22:29:39Z,stat:awaiting response type:bug stale TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/61063,", Could you please provide the complete standalone code to reproduce the issue, it helps us to analyse the issue in an effective way. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,I need some more time to prepare a stand alone example.,", Please provide the simple standalone code which helps us to analyse the issue. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1134,"以下是一个github上的tensorflow下的一个issue, 标题是(jacobian computation throws ValueError for LinearOperatorFullMatrix: object of type 'LinearOperatorFullMatrix' has no len())， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230621  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When computing jacobian for a `LinearOperatorFullMatrix`, TF throws an error: `ValueError: TypeError: object of type 'LinearOperatorFullMatrix' has no len()`. I think the problem here might be that `len()` or `shape` is not implemented for `LinearOperatorFullMatrix`. If I just take the shape of a `LinearOperatorFullMatrix`, I can see the same error.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,trickiwoo,jacobian computation throws ValueError for LinearOperatorFullMatrix: object of type 'LinearOperatorFullMatrix' has no len(),"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230621  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When computing jacobian for a `LinearOperatorFullMatrix`, TF throws an error: `ValueError: TypeError: object of type 'LinearOperatorFullMatrix' has no len()`. I think the problem here might be that `len()` or `shape` is not implemented for `LinearOperatorFullMatrix`. If I just take the shape of a `LinearOperatorFullMatrix`, I can see the same error.   Standalone code to reproduce the issue   Relevant log output  ",2023-06-22T13:59:15Z,stat:awaiting response type:bug type:feature stale comp:core TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/61060,"Hi  , I can able to replicate the behaviour reported behaviour and attached gist for reference. `tf.linalg.LinearOperatorFullMatrix` has no gradient implementation in TF2.12 but in tfnightly it seems implemented.  However `LinearOperatorFullMatrix` has an attribute called `shape` that can return the shape of its object.You can refer the same in gist.  IMO jacobians seems not implemented yet for `tf.linalg.LinearOperatorFullMatrix` which might be the reason for the error. It might be a feature request. I will escalate the issue to the Dev team and let's hear from them. Thanks!","Thanks  for looking into this! It is very interesting that for `LinearOperatorFullMatrix` objects `x.shape` can return the correct shape, but `tf.shape(x)` will result in an error. IMO this also seems to be an error in the `LinearOperatorFullMatrix` implementation (probably unrelated to the gradient implementation).","  It seems TensorFlow isn't able to handle this operation because `LinearOperatorFullMatrix` isn't a tensor, but a linear operator. So, we must make sure we're operating on tensor values within the context of the `GradientTape` and use `mat` directly, since `LinearOperatorFullMatrix` isn't directly supported as a gradient source or target. Try running ","Also, computing the gradient outside of the `with tf.GradientTape(persistent=True) as tape:` block as suggested by the console warning `WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.` is very straightforward: ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1251,"以下是一个github上的tensorflow下的一个issue, 标题是(the tf keras models load_model() used for loading ml model is not able to load model)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hi, I am trying to load my deep learning model using  **tensorflow keras models load_model ()** . when I run it for first time it got loaded but from next time** it is not loading**. Like it is in this function for more than 30 min.  I store my model in **.h5** format. model size is approx 13 MB. At the time of saving deep learning, I use model.save()  I am using a machine with 128 GB RAM.  I am using multiprocessing with no of worker 16. Sometime it worked and sometime is got stucked.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,purushottam22,the tf keras models load_model() used for loading ml model is not able to load model,"Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hi, I am trying to load my deep learning model using  **tensorflow keras models load_model ()** . when I run it for first time it got loaded but from next time** it is not loading**. Like it is in this function for more than 30 min.  I store my model in **.h5** format. model size is approx 13 MB. At the time of saving deep learning, I use model.save()  I am using a machine with 128 GB RAM.  I am using multiprocessing with no of worker 16. Sometime it worked and sometime is got stucked.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-22T12:42:38Z,stat:awaiting response type:feature stale comp:keras,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60951,", Could you please provide the complete standalone code to reproduce the issue which helps us to analyse the issue in an effective way. Thank you!","    def retrieve_model(self, model_path:str ,model_type:str):       '''       Desc: It retrieves the model object based on model type and its model path       :param model_path:string       :param model_type:string       :return:model_objet:object       '''       if model_type==""tensorflow"":         try:           print(model_path, type(model_path))           model_dir = model_path[0:10]           print(os.listdir(model_dir))           model_object=tf.keras.models.load_model(model_path, custom_objects=None, compile=True, options=None)           print(""model is loaded"")           print(model_object)           print(""*""*10)           return FileResults(model_object).get_model_object         except Exception as err:           print(""retrieve_model method failure reason is: {err}"") This is the code I used. I write some print statement to verify that in which line it is stopped. ",If I am running it alone it is working but when I use multiprocessing it got stuck.,", The code provided is not complete hence it would be difficult for us to pinpoint the issue. Please share complete stand alone code to replicate the issue or a colab gist with the error reported.? That will allow us to determine the source of the issue easily.  Could you please try to recompile after reloading.  https://www.tensorflow.org/api_docs/python/tf/keras/saving/load_model Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.
1433,"以下是一个github上的tensorflow下的一个issue, 标题是(android gpu delegate Failed to build program executable)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10 or 2.11  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? A bug happened! I test gpu delegate on oppo R9.  TfLiteInterpreterModifyGraphWithDelegate will reture error value. ERROR: Failed to build program executable  Build program failure:35:26: error: OpenCL extension 'cl_khr_3d_image_writes' is not supported pragma OPENCL EXTENSION cl_khr_3d_image_writes : enable                          ^ error: Compiler frontend failed (error code 58) ERROR: Falling back to OpenGL ERROR: TfLiteGpuDelegate Init: OpenGLbased API disabled ERROR: TfLiteGpuDelegate Prepare: delegate is not initialized ERROR: Node number 100 (TfLiteGpuDelegateV2) failed to prepare. ERROR: Restored original execution plan after delegate application failure. tflite gpu Delegate create failed!2  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,mengran1234,android gpu delegate Failed to build program executable,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10 or 2.11  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? A bug happened! I test gpu delegate on oppo R9.  TfLiteInterpreterModifyGraphWithDelegate will reture error value. ERROR: Failed to build program executable  Build program failure:35:26: error: OpenCL extension 'cl_khr_3d_image_writes' is not supported pragma OPENCL EXTENSION cl_khr_3d_image_writes : enable                          ^ error: Compiler frontend failed (error code 58) ERROR: Falling back to OpenGL ERROR: TfLiteGpuDelegate Init: OpenGLbased API disabled ERROR: TfLiteGpuDelegate Prepare: delegate is not initialized ERROR: Node number 100 (TfLiteGpuDelegateV2) failed to prepare. ERROR: Restored original execution plan after delegate application failure. tflite gpu Delegate create failed!2  Standalone code to reproduce the issue   Relevant log output _No response_,2023-06-21T02:54:44Z,stat:awaiting response type:bug stale comp:lite TFLiteGpuDelegate TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60936,", Could you please provide the complete standalone code to reproduce the issue which helps us to analyse the issue in an effective way. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
1522,"以下是一个github上的tensorflow下的一个issue, 标题是(fit() fails with CUDNN_STATUS_BAD_PARAM when using Conv3D and multi-GPU MirroredStrategy)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v1.12.195675g47602c0bad8 2.14.0dev20230620  Custom Code Yes  OS Platform and Distribution Rocky Linux release 8.6 (Green Obsidian)  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cuda_11.8.r11.8/compiler.31833905_0 / cuDNN version 8600  GPU model and memory 4 NVIDIA A100s w/ 80GB each  Current Behaviour? When executing a model fit that includes a `Conv3D` layer on multiple GPUs, I'm encountering a `CUDNN_STATUS_BAD_PARAM` error in the gradient computation step. No errors occur when running on a single GPU, nor when I swap out `Conv3D` with `AveragePooling3D` or `Conv2D`. However, `Conv3DTranspose` also fails.  With the `Graph execution error` traceback:  I'm running from the `tensorflow/tensorflow:nightlygpu` docker image.  Standalone code to reproduce the issue ```python import tensorflow as tf from tensorflow.keras import layers, models input_shape = (28, 28, 28, 1) num_samples = 10 x_data = tf.random.uniform((num_samples, *input_shape), 0, 1) y_data = tf.random.uniform((num_samples, *input_shape), 0, 1) multi_gpu=True  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ohinds,fit() fails with CUDNN_STATUS_BAD_PARAM when using Conv3D and multi-GPU MirroredStrategy,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v1.12.195675g47602c0bad8 2.14.0dev20230620  Custom Code Yes  OS Platform and Distribution Rocky Linux release 8.6 (Green Obsidian)  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cuda_11.8.r11.8/compiler.31833905_0 / cuDNN version 8600  GPU model and memory 4 NVIDIA A100s w/ 80GB each  Current Behaviour? When executing a model fit that includes a `Conv3D` layer on multiple GPUs, I'm encountering a `CUDNN_STATUS_BAD_PARAM` error in the gradient computation step. No errors occur when running on a single GPU, nor when I swap out `Conv3D` with `AveragePooling3D` or `Conv2D`. However, `Conv3DTranspose` also fails.  With the `Graph execution error` traceback:  I'm running from the `tensorflow/tensorflow:nightlygpu` docker image.  Standalone code to reproduce the issue ```python import tensorflow as tf from tensorflow.keras import layers, models input_shape = (28, 28, 28, 1) num_samples = 10 x_data = tf.random.uniform((num_samples, *input_shape), 0, 1) y_data = tf.random.uniform((num_samples, *input_shape), 0, 1) multi_gpu=True  ",2023-06-20T19:30:00Z,stat:awaiting response type:bug comp:dist-strat comp:gpu TF 2.13,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60935,"Hi  , For distribution training across multiple devices on same server you need to keep `batch_szie = 1* no of GPU devices` incase you want to calculate gradients after each single batch. Since you have 4 GPUs you need to keep batch_size=1*4 as minimum (multiples of 4). The no of devices can be found by using `mirrored_strategy.num_replicas_in_sync` for your case. Hence you need to pass `batch_size=batch_size*mirrored_strategy.num_replicas_in_sync` Please try the above change and let us know if it works. Thanks!","Hi , Thanks! Changing the fit line to  fixed the issue. ",Are you satisfied with the resolution of your issue? Yes No,"Despite performing the mentioned fixes, I still face the same issue. Please show some light Mr.  ",I am having this problem as well. It doesn't happen if I set batch size to the number of GPUs. I suspect it doesn't happen if the train set size is a multiple of batch size * n. GPUs.,"I've added padding to my train and validation sets and the issue doesn't happen anymore. Here is a snippet of how I did it:  When calling `model.predict` the padding is also needed, at least in some cases. I am using BiLSTM, CNN and Attention layers."
1844,"以下是一个github上的tensorflow下的一个issue, 标题是(Broken build due to LLVM)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Debian Bookworm plus Clang/LLVM 17.0.0 (experimental)  Mobile device not applicable  Python version 3.11.4  Bazel version 5.3.0  as per original configuration  GCC/Compiler version GCC 12.2.0 / Clang 16.0.6 / Clang 17.0.0  CUDA/cuDNN version NO  GPU model and memory nothing to do with that  Current Behaviour? Compilation fails due to: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/boringssl/archive/b9232f9e27e5668bc0414879dcdedb2a59ea75f2.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/659147817805d17c7be2d60bd7bbca7e780f9c82.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvmproject/archive/10939d1d580b9d3c9c2f3539c6bdb39f408179c0.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/91d765cad5599f9710973d3e34d4dc22583e2e79.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found  Standalone code to reproduce )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Ganesh-Devdas,Broken build due to LLVM,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Debian Bookworm plus Clang/LLVM 17.0.0 (experimental)  Mobile device not applicable  Python version 3.11.4  Bazel version 5.3.0  as per original configuration  GCC/Compiler version GCC 12.2.0 / Clang 16.0.6 / Clang 17.0.0  CUDA/cuDNN version NO  GPU model and memory nothing to do with that  Current Behaviour? Compilation fails due to: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/boringssl/archive/b9232f9e27e5668bc0414879dcdedb2a59ea75f2.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/659147817805d17c7be2d60bd7bbca7e780f9c82.zip failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvmproject/archive/10939d1d580b9d3c9c2f3539c6bdb39f408179c0.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/91d765cad5599f9710973d3e34d4dc22583e2e79.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found  Standalone code to reproduce ,2023-06-19T14:47:30Z,type:build/install subtype:bazel TF 2.12,closed,1,5,https://github.com/tensorflow/tensorflow/issues/60922,"Note that the issue is not the dependencies, but an error in LLVM  Project dependencies are specified as coming from multiple URLs (the upstream and the mirror). Bazel tries both and reports failure when the first attempt fails, but then look at the second URL and downloads the file from there. The build will be broken much faster if the dependency cannot be downloaded from _both_ upstream and the mirror.","I'm getting the same error while trying to build tensorflow 2.13 (CPU build) INFO: Found 1 target... ERROR: /root/.cache/bazel/_bazel_root/129f64c1bf7a2ba048cf317d8c31c367/external/llvmproject/llvm/BUILD.bazel:605:10: Compiling llvm/utils/TableGen/Attributes.cpp [for host] failed: undeclared inclusion(s) in rule 'project//llvm:llvmtblgen': this rule is missing dependency declarations for the following files included by 'llvm/utils/TableGen/Attributes.cpp':   'bazelout/host/bin/external/llvmproject/llvm/Demangle.cppmap'   'bazelout/host/bin/external/llvm_terminfo/terminfo.cppmap'   'bazelout/host/bin/external/llvm_zlib/zlib.cppmap' Target //tensorflow/tools/pip_package:build_pip_package failed to build Use verbose_failures to see the command lines of failed build steps. INFO: Elapsed time: 57.973s, Critical Path: 13.61s INFO: 355 processes: 159 internal, 196 local. FAILED: Build did NOT complete successfully","This is a nearly daily occurrence. You can wait until a fix lands or try building either from a stable release branch (`r2.13` for example), or if you want from the main branch, trying to find a commit from before a ""LLVM integrate"" one. Though now with the XLA and TSL separation, this might also be harder to do, you'd need to keep all of these in sync.","Also, closing this one, since the original issue has been resolved.",Are you satisfied with the resolution of your issue? Yes No
1209,"以下是一个github上的tensorflow下的一个issue, 标题是(F1 score error on multi class data)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v1.12.195639g08bd7e1a8e5 2.14.0dev20230618  Custom Code Yes  OS Platform and Distribution OS Ventura 13.0.1  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Implementing the F1 score available in the nightly builds on multiclass data such as below:  triggers the following error:  I've tried with multiple multiclass datasets and the same error is returned. The F1 score page says it should work with multiclass data https://www.tensorflow.org/api_docs/python/tf/keras/metrics/F1Score. Is there something I've missed regarding its implementation for multiclass data (such as somewhere to specify the number of classes?) or is this a bug?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Glfrey,F1 score error on multi class data,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v1.12.195639g08bd7e1a8e5 2.14.0dev20230618  Custom Code Yes  OS Platform and Distribution OS Ventura 13.0.1  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Implementing the F1 score available in the nightly builds on multiclass data such as below:  triggers the following error:  I've tried with multiple multiclass datasets and the same error is returned. The F1 score page says it should work with multiclass data https://www.tensorflow.org/api_docs/python/tf/keras/metrics/F1Score. Is there something I've missed regarding its implementation for multiclass data (such as somewhere to specify the number of classes?) or is this a bug?  Standalone code to reproduce the issue   Relevant log output _No response_,2023-06-19T11:45:23Z,type:bug comp:keras TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60920,"Hi  , Thanks for reporting. Unfortunately the attached drive file can't accessible for me. Could you please provide the access. I request you to provide colab gist for ease of access with a minimal code snippet which can help us to look into the issue. Thanks!","Hi , Thanks for your rapid response. I've transferred it over to colab here's the link https://colab.research.google.com/drive/1CoKr7DNBT3VDqSQlUAPfZPH0pYlj1cq?usp=sharing",> Note: This API is new and only available via pip install tfnightly. https://www.tensorflow.org/api_docs/python/tf/keras/metrics/F1Score,"  Yes I'm aware, my tests were with the nightly builds but thank you for sharing. ",", the error you mentioned in the first post doesn't match the error in the notebook, which confused me.  I looked into F1, and it seems it required input to be onehotencoded to make the metric work. I made a conversion to ohe in the notebook and it works. I also added a custom metric class that converts labels to ohe on the fly, which could lead to less memory consumption. "," huh, that's weird. I'm definitely on the nightly build at the moment I just checked. Either way, you're absolutely right. I completely overlooked the requirement for onehotencoding. My conversion to that representation of my labels has enabled it to work, so thank you very much!",Are you satisfied with the resolution of your issue? Yes No
1664,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorboard histogram onehot operation causing ResourceExhauseError: OOM)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to train a VGG16 model. I'm using a sample dataset of 4000 300x300 images in 14 classes, and running my code on a Google VM using an Nvidia L4 GPU with 20gb of memory. I am running python 3.7, tf version 2.11, and cuda version 12.1. My data is stored in GCS. When I run the model with the following TensorBoard callback: `tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)` I get this error at the end of the first epoch:  The error traces back to the tensorboard histogram object:  Interestingly it seems to be calling tf.one_hot and blowing up the gpu memory with a massive tensor regardless of whether I train the model with integer labels and spare categorical cross entropy or if I train it with one hot labels and cross entropy. I don't really understand what the tensor contains because its dimensions neither relate to the number of training examples or classes that I am using.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,vrunm,Tensorboard histogram onehot operation causing ResourceExhauseError: OOM,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to train a VGG16 model. I'm using a sample dataset of 4000 300x300 images in 14 classes, and running my code on a Google VM using an Nvidia L4 GPU with 20gb of memory. I am running python 3.7, tf version 2.11, and cuda version 12.1. My data is stored in GCS. When I run the model with the following TensorBoard callback: `tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)` I get this error at the end of the first epoch:  The error traces back to the tensorboard histogram object:  Interestingly it seems to be calling tf.one_hot and blowing up the gpu memory with a massive tensor regardless of whether I train the model with integer labels and spare categorical cross entropy or if I train it with one hot labels and cross entropy. I don't really understand what the tensor contains because its dimensions neither relate to the number of training examples or classes that I am using.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-19T05:35:02Z,stat:awaiting response type:bug stale comp:apis TF 2.8,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60917,"Hi  , The issue seems related to Memory resources and not problem with Tensorflow. If using one hot encoding it creates a very large sparse tensor which may require higher memory resources. As you have set `histogram_freq=1` it will create additional computations for weight histograms of each layer which needs higher memory resources.  You may try setting `histogram_freq=0` and check if the problem still exists then we need to check your code which is causing the large tensor computations.If no problem then its clear case of Higher memory requirement due to Histogram computations . Thanks!",The problem still exists with `histogram_freq=0`. I will look into making the code having large tensor computations.,If the problem exists with histogram_freq=0 then the problem might be related to memory intensive computations due to higher input tensors.With large input tensors this is expected behaviour. However providing the code snippet shall confirm the same.,"Setting histogram_freq=0 did solve the problem to some extent, but I am still surprised by the very high memory requirements for the histogram computations. "," , Setting `histogram_freq=1` needs storage of all weights into memory and for Larger models the weights are more and takes more memory as well. As you are using VGG16 model which has 138 million parameters which itself takes higher memory resource to store them. Any additional computations like histograms will add more load on memory. Thanks!",For these kind of computations what should be the value of histogram_freq? It worked for VGG16 but for models like ResNet and EfficientNet it did not work. What should be the value for those models?,"Hi  , It's all depends upon the Inputs sizes and Memory resources available. OOM errors are depends upon the input sizes and the Memory resources. Tensorflow can't have control on this. It has to be taken care by the users.  May be you can reduce `batch_size` in model.fit which is by default 32(you may try batch_size=16) . Also use the below code before importing Tensorflow in your code block.This may help if the OOM is due to Memory fragmentation. ",I tried using a smaller batch size and using the above code but still ran into this error. I am also experimenting with smaller CNN networks to reduce memory computations and also make the model train faster.,"Hi  , Could you please confirm the `batch_size` you used and let us knothe error. Maybe you can check with smaller networks since one_hot encoding is a large Tensor and may cause OOM error.",I had tried using a batch size of 16 and 8 and still ran into this error.,Could you please update the issue thread here https://github.com/kerasteam/tfkeras/issues/168,Sure will update it there.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1933,"以下是一个github上的tensorflow下的一个issue, 标题是(Uncaught exception in ZMQStream callback when running your example notebooks using latest or nightly docker image)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code No  OS Platform and Distribution Linux gpu02 6.2.112pve CC(Add support for Python 3.x) SMP PREEMPT_DYNAMIC PVE 6.2.112 (20230510T09:13Z) x86_64 x86_64 x86_64 GNU/Linux  Mobile device _No response_  Python version python3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Occurs when running any of your example notebooks: ``` [E 22:36:50.295 NotebookApp] Uncaught exception in ZMQStream callback     Traceback (most recent call last):       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback         f = callback(*args, **kwargs)       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback         return callback(self, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply         super()._on_zmq_reply(stream, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply         self.write_message(msg, binary=isinstance(msg, bytes))       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 339, in write_message         return self.ws_connection.write_message(message, binary=binary)       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1086, in write_message         fut = self._write_frame(Tru)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,deepcoder,Uncaught exception in ZMQStream callback when running your example notebooks using latest or nightly docker image,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code No  OS Platform and Distribution Linux gpu02 6.2.112pve CC(Add support for Python 3.x) SMP PREEMPT_DYNAMIC PVE 6.2.112 (20230510T09:13Z) x86_64 x86_64 x86_64 GNU/Linux  Mobile device _No response_  Python version python3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Occurs when running any of your example notebooks: ``` [E 22:36:50.295 NotebookApp] Uncaught exception in ZMQStream callback     Traceback (most recent call last):       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback         f = callback(*args, **kwargs)       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback         return callback(self, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply         super()._on_zmq_reply(stream, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply         self.write_message(msg, binary=isinstance(msg, bytes))       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 339, in write_message         return self.ws_connection.write_message(message, binary=binary)       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1086, in write_message         fut = self._write_frame(Tru",2023-06-18T22:44:17Z,stat:awaiting response type:bug stale TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60916,"  In order to expedite the troubleshooting process, please provide the example code snippet to reproduce the issue reported here. Thank you!","As I stated in my opening post, running any of the example programs that you provide in the Tensorflow CUDA docker image caused the failures referencing the ZMQStream message. In terms of helping you further with this, unfortunately for that, I have moved on to another docker image I found on Docker Hub that provides recent Tensorflow 2 version, cuda support and so far is working fine for me. ","Hi,  Thanks for reporting the issue. Feel free to close the issue if the issue is resolved in the latest docker version. For our latest docker images, please follow https://hub.docker.com/r/tensorflow/tensorflow/tags",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1123,"以下是一个github上的tensorflow下的一个issue, 标题是(Building tf-opt steps with prerequisites )， 内容是 (Click to expand!    Issue Type Documentation Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Linux Ubunto 18.04  Mobile device _No response_  Python version _No response_  Bazel version 6.1.2  GCC/Compiler version 9.2.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to build tfopt binary on branch v2.12 without any changes and gets different compilation errors. The command for compilation I use: `bazel build c opt tensorflow/compiler/mlir:tfopt` Can you share some prerequites for building and debugging `tfopt` binary (for debug/release mode). I would appriciate if there is docker builder I can use to it instead of changing my envrioment. Thanks, Aviad  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AviadCo,Building tf-opt steps with prerequisites ,"Click to expand!    Issue Type Documentation Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Linux Ubunto 18.04  Mobile device _No response_  Python version _No response_  Bazel version 6.1.2  GCC/Compiler version 9.2.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to build tfopt binary on branch v2.12 without any changes and gets different compilation errors. The command for compilation I use: `bazel build c opt tensorflow/compiler/mlir:tfopt` Can you share some prerequites for building and debugging `tfopt` binary (for debug/release mode). I would appriciate if there is docker builder I can use to it instead of changing my envrioment. Thanks, Aviad  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-18T20:11:34Z,awaiting review stat:awaiting tensorflower type:feature type:build/install comp:lite TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60915,"Hi   Can you try with latest stable version `r2.13` and let us know if you still face the error? Also, try `bazel clean expunge` before executing `bazel build c opt tensorflow/compiler/mlir:tfopt` There is no such docker build as of now for the `tfopt` binary. Thanks.","Hi  , thanks for the response! After moving to branch `r2.13` I manage to build tfopt with the following change: in `tensorflow/tensorflow.bzl`:  At least for me the symbolic link is refering to not existing path when running with `ln sf $$(realpath relativeto=$(RULEDIR) $<) $@`","Moreover, when I ran the lit tests using: `bazel test override_repository=""llvmraw=${LLVM_SRC}"" c opt t //tensorflow/compiler/mlir/... spawn_strategy=sandboxed j 60` Where `${LLVM_SRC}` was defined to my llvmproject clone, I had to remove some references to `""project//mlir:run_lit.sh""` in filegroups in the following files: ",Hi   Thanks for the fix. Please feel free to create a PR for the same. ,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"> tensorflow/tensorflow.bzl > Hi  , thanks for the response! After moving to branch `r2.13` I manage to build tfopt with the following change: in `tensorflow/tensorflow.bzl`: >  >  >  > At least for me the symbolic link is refering to not existing path when running with `ln sf $$(realpath relativeto=$(RULEDIR) $<) $@` Worked for me with the latest `nightly` branch, thanks!",Are you satisfied with the resolution of your issue? Yes No
1123,"以下是一个github上的tensorflow下的一个issue, 标题是(Add support for IO optimization)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Ubuntu  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Tensorflow's internal gcs filesystem's performance is really bad, a few optimizations we could so:  Leverage multicurl instead of easycurl to avoid TCP connections created every single request;  Explicitly use HTTP/2 instead of HTTP/1.1 for IO multiplexing;  Leverage more compression algorithm, like LZ4, ZSTD, etc;  Adopt zerocopy interface for input stream interface;  Reduce unnecessary mem allocation in gcs filesystem.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dentiny,Add support for IO optimization,"Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Ubuntu  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Tensorflow's internal gcs filesystem's performance is really bad, a few optimizations we could so:  Leverage multicurl instead of easycurl to avoid TCP connections created every single request;  Explicitly use HTTP/2 instead of HTTP/1.1 for IO multiplexing;  Leverage more compression algorithm, like LZ4, ZSTD, etc;  Adopt zerocopy interface for input stream interface;  Reduce unnecessary mem allocation in gcs filesystem.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-18T09:52:32Z,stat:awaiting tensorflower type:feature comp:apis,open,0,2,https://github.com/tensorflow/tensorflow/issues/60912, Any response?," , The request has been filed internally, once any new update is available, I will update it here. Thank you."
1870,"以下是一个github上的tensorflow下的一个issue, 标题是(Errors when custom gradients are being used in TPU)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When writing custom gradient modules in TensorFlow (not using tf.GradientTape()) and applying it using an existing optimizer causes errors. I don't see any visible difference in tf.GradientShape() gradients and custom ones.  Standalone code to reproduce the issue  shell Should be similar to below: AttributeError                            Traceback (most recent call last)  in ()      50       grads = tape.gradient(l, model.trainable_weights)      51       c = grads[0] > 52       opt.apply_gradients(zip(grads, model.trainable_weights))      53       print('Loss this batch: ' + closure().numpy())      54       opt.next_steps() 2 frames /usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py in apply_gradients(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)    1171         )    1172         if not skip_gradients_aggregation and experimental_aggregate_gradients: > 1173             grads_and_vars = self.aggregate_gradients(grads_and_vars)    1174         return super().apply_gradients(grads_and_vars, name=name)    1175  /usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py in aggregate_gradients(self, grads_and_vars)    1137           List of (gra)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,abhaskumarsinha,Errors when custom gradients are being used in TPU,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When writing custom gradient modules in TensorFlow (not using tf.GradientTape()) and applying it using an existing optimizer causes errors. I don't see any visible difference in tf.GradientShape() gradients and custom ones.  Standalone code to reproduce the issue  shell Should be similar to below: AttributeError                            Traceback (most recent call last)  in ()      50       grads = tape.gradient(l, model.trainable_weights)      51       c = grads[0] > 52       opt.apply_gradients(zip(grads, model.trainable_weights))      53       print('Loss this batch: ' + closure().numpy())      54       opt.next_steps() 2 frames /usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py in apply_gradients(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)    1171         )    1172         if not skip_gradients_aggregation and experimental_aggregate_gradients: > 1173             grads_and_vars = self.aggregate_gradients(grads_and_vars)    1174         return super().apply_gradients(grads_and_vars, name=name)    1175  /usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py in aggregate_gradients(self, grads_and_vars)    1137           List of (gra",2023-06-17T04:52:55Z,stat:awaiting tensorflower type:bug comp:ops TF 2.12,open,0,5,https://github.com/tensorflow/tensorflow/issues/60906," Thank you for raising the issue.  In order to expedite the troubleshooting process, please provide the complete code snippet to reproduce the issue reported here. Thank you!!",Hello  Apologies for the late reply. Thank you for looking into the issue. A sample reproducible code is given below:  Here's a reproducible Colab Link: https://colab.research.google.com/drive/1yj7pGuFSOttf1eM9ua3a_cCf3VdoU0Z?usp=sharing Please look into the issue and update us with any possible solution (even temporarily) to deal with the issue. Thank You.," I was able to replicate the issue in TF v2.12, v2.13 and faced **TypeError** in tfnightly. Please find the gist here. Could you please confirm the same? Thank you!","Hello   Yes. I think the issue here is common for 2.12/13. I'm not sure about tfnightly (for some reason I can't use them on my device due to some custom configurations, so I can confirm the same thing on Google Colab) but those modules certainly need a check. Thank you.", Thank you for the response!  Could you please take a look at this issue? Thank you!
1640,"以下是一个github上的tensorflow下的一个issue, 标题是(lossing too much accuracy)， 内容是 (I have a model composed of some tf.keras.layers.Conv1D and custom Upsampling1DLayer and CustomCropping1D layer: The model produces correct results after training but when I convert it to tflite with int8 quantization, my accuracy drops by more than 50%. I am unable to understand why is that? and how can I avoid this much loss. def tflite_conversion(model):     run_model = tf.function(lambda x: model(x))     concrete_func = run_model.get_concrete_function(tf.TensorSpec([1,6000,3], model.inputs[0].dtype))     MODEL_DIR = ""keras_lstm""     model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)     converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)     Choice=""_int8""     converter.optimizations = [tf.lite.Optimize.DEFAULT]     converter.inference_input_type = tf.int8   or tf.uint8     converter.inference_output_type = tf.int8   or tf.uint8     converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.TFLITE_BUILTINS]     converter.experimental_select_user_tf_ops = [Upscaling1D]     def generate_representative_dataset():         for i in range(int(x_train.shape[0]/100)):             print(i,end=""\r"")             yield [tf.expand_dims(x_train[i], axis=0)]     converter.representative_dataset = generate_representative_dataset     tflite_model = converter.convert()     open(""keras_lstm/model""+Choice+"".tflite"", ""wb"").write(tflite_model)     return tflite_model)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,TayyabaZainab0807,lossing too much accuracy,"I have a model composed of some tf.keras.layers.Conv1D and custom Upsampling1DLayer and CustomCropping1D layer: The model produces correct results after training but when I convert it to tflite with int8 quantization, my accuracy drops by more than 50%. I am unable to understand why is that? and how can I avoid this much loss. def tflite_conversion(model):     run_model = tf.function(lambda x: model(x))     concrete_func = run_model.get_concrete_function(tf.TensorSpec([1,6000,3], model.inputs[0].dtype))     MODEL_DIR = ""keras_lstm""     model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)     converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)     Choice=""_int8""     converter.optimizations = [tf.lite.Optimize.DEFAULT]     converter.inference_input_type = tf.int8   or tf.uint8     converter.inference_output_type = tf.int8   or tf.uint8     converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.TFLITE_BUILTINS]     converter.experimental_select_user_tf_ops = [Upscaling1D]     def generate_representative_dataset():         for i in range(int(x_train.shape[0]/100)):             print(i,end=""\r"")             yield [tf.expand_dims(x_train[i], axis=0)]     converter.representative_dataset = generate_representative_dataset     tflite_model = converter.convert()     open(""keras_lstm/model""+Choice+"".tflite"", ""wb"").write(tflite_model)     return tflite_model",2023-06-16T14:44:21Z,stat:awaiting response comp:lite type:performance TFLiteConverter,closed,0,12,https://github.com/tensorflow/tensorflow/issues/60903,"I have noticed that When i train just for 1 epoch and quantize it to int8, I lose 23% but when I train for more epoch I lose more then 30%. Why is the case.",Hi   Could you please provide the standalone code to reproduce the issue? The quantization aware training is supposed to give better model accuracy than post training quantization. Please refer to document for QAT and let us know if it helps. Thanks.,"Hello   Could you please try to use OPTIMIZE_FOR_SIZE while optimization and use the data type of float for input and output to get the better accuracy.  And also, try this :  def generate_representative_dataset():         for i in range(x_train.shape[0]):             print(i, end=""\r"")             yield [tf.expand_dims(x_train[i], axis=0)] I am not sure about this, But you can try this once ","> Hi  >  > Could you please provide the standalone code to reproduce the issue? >  > The quantization aware training is supposed to give better model accuracy than post training quantization. Please refer to document for QAT and let us know if it helps. >  > Thanks. Thank you for your reply. Here is a colab notebook: https://colab.research.google.com/drive/1iw4vJKyMuFTnOY6hyDFj2PJ2ZhBJlWDE?usp=sharing This are the results for my trail. I get different accuracy every time, the difference in accuracy can be from 1%  more then 50%: Testing X_test_results_quantized.csv TP= 145 TN= 1039 FP= 0 FN= 1316 accuracy: 0.4736 Testing X_test_results_normal.csv TP= 1441 TN= 1028 FP= 11 FN= 20 accuracy: 0.9876",> OPTIMIZE_FOR_SIZE   Thanks for your reply. I removed the int input and outputs but still face the same challenge. I didn't understand what you meant by OPTIMIZE_FOR_SIZE. Does this go somewhere here? converter.optimizations = [tf.lite.Optimize.DEFAULT],"  yeah, adjust the optimizations if needed.   converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]",">  >  > yeah, adjust the optimizations if needed. converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE] OPTIMIZE_FOR_SIZE also didn't work for me, still got 44% accuracy.",Hi   The issue with your code is not initialising the interpreter while testing the samples in the loop.  Please find the gist which obtained `98.04%` accuracy on the converted quantized tflite model. Thanks.,It seems to work now..Thank you very much. Is there any documentation on this? I would like to read a bit into that.,Hi   Glad it worked. Please check the documentation on steps involved in running a model in TFLite. Please feel free to close the issue since it is resolved. Thanks.,Are you satisfied with the resolution of your issue? Yes No,"Hello,  Thank you for your input on this. I am facing exactly the same issue (working with MobilenetV3 on int8 quantisation and observing big accuracy drop / kind of random results depending on a particular attempt  both with PTQ and QAT). The proposed solution did not work, may I please double check if it solved the issues in case of  ? Any chance you could please elaborate why it is required to call the following on every iteration? I thought it would be okay to call it only once before the cycle?   `interpreter = tf.lite.Interpreter(model_path='keras_lstm/model_int8.tflite')  interpreter.allocate_tensors()`  Thank you very much."
1865,"以下是一个github上的tensorflow下的一个issue, 标题是(Flutter - ""Select Tensorflow Ops"" not working)， 内容是 (**System information**  OS Platform and Distribution : Windows 11  Flutter version : 3.7.12  TensorFlow installed from (source or binary): tflite_flutter 0.10.1 (https://pub.dev/packages/tflite_flutter)  TensorFlow version (or github SHA if from source): 2.4.1 (implementation 'org.tensorflow:tensorflowlite:2.4.1') > in build.gradle Hello, I try to implement Google Android autocomplete project (https://github.com/tensorflow/examples/tree/master/lite/examples/generative_ai/android) on **flutter**.  Here is the detailed project implementation website(https://codelabs.developers.google.com/kerasnlptflite CC(未找到相关数据) ) for reference.  I created .tflite file using below given codes : .function def generate(prompt, max_length):     return gpt2_lm.generate(prompt, max_length) concrete_func = generate.get_concrete_function(tf.TensorSpec([], tf.string), 100) gpt2_lm.jit_compile = False converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],                                                             gpt2_lm) converter.target_spec.supported_ops = [   tf.lite.OpsSet.TFLITE_BUILTINS,  enable TensorFlow Lite ops.   tf.lite.OpsSet.SELECT_TF_OPS  enable TensorFlow ops. ] converter.allow_custom_ops = True converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.experimental_select_user_tf_ops = [""UnsortedSegmentJoin"", ""UpperBound""] converter._experimental_guarantee_all_funcs_one_use = True quant_generate_tflite = converter.convert()  Then I tried to implement generated .tflite model in flutter using **tflite_flutter** package as below(focussed) : import 'package:tflite_flutter/tflite_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gpt,galaturka,"Flutter - ""Select Tensorflow Ops"" not working","**System information**  OS Platform and Distribution : Windows 11  Flutter version : 3.7.12  TensorFlow installed from (source or binary): tflite_flutter 0.10.1 (https://pub.dev/packages/tflite_flutter)  TensorFlow version (or github SHA if from source): 2.4.1 (implementation 'org.tensorflow:tensorflowlite:2.4.1') > in build.gradle Hello, I try to implement Google Android autocomplete project (https://github.com/tensorflow/examples/tree/master/lite/examples/generative_ai/android) on **flutter**.  Here is the detailed project implementation website(https://codelabs.developers.google.com/kerasnlptflite CC(未找到相关数据) ) for reference.  I created .tflite file using below given codes : .function def generate(prompt, max_length):     return gpt2_lm.generate(prompt, max_length) concrete_func = generate.get_concrete_function(tf.TensorSpec([], tf.string), 100) gpt2_lm.jit_compile = False converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],                                                             gpt2_lm) converter.target_spec.supported_ops = [   tf.lite.OpsSet.TFLITE_BUILTINS,  enable TensorFlow Lite ops.   tf.lite.OpsSet.SELECT_TF_OPS  enable TensorFlow ops. ] converter.allow_custom_ops = True converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.target_spec.experimental_select_user_tf_ops = [""UnsortedSegmentJoin"", ""UpperBound""] converter._experimental_guarantee_all_funcs_one_use = True quant_generate_tflite = converter.convert()  Then I tried to implement generated .tflite model in flutter using **tflite_flutter** package as below(focussed) : import 'package:tflite_flutter/tflite_",2023-06-16T12:50:34Z,stat:awaiting response type:support stale comp:lite TF 2.4,closed,2,8,https://github.com/tensorflow/tensorflow/issues/60902, Thank you for opening this issue. You are using an older version of TF which is not actively supported. Could you please provide the entire tflite model to debug the issue if that persists in the newer version? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you., I experience the problem. Are you able to figure this out yet?,Hi   Can you try with latest nightly snapshot and see if you are still facing the issue?  Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Hi  were you able to resolve this issue? i am currently facing it.
996,"以下是一个github上的tensorflow下的一个issue, 标题是(TF 2 building from source fails)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version Commit hash: cd8247b47bd5ba25b26752b55ea54b52e5574183  Custom Code No  OS Platform and Distribution Redhat Enterprise Linux 8.7  Mobile device _No response_  Python version 3.10.4  Bazel version 5.4.0 (same as what's there in .bazelversion)  GCC/Compiler version clang 17.0.0  CUDA/cuDNN version CUDA 12.1, cuDNN 8.9.0  GPU model and memory H100  Current Behaviour? Hello, I'm unable to build TF from source on CUDA 12.1. It tries to download a bunch of things, but that's failing with the attached error. Please let me know what I can do to build it correctly. Thanks in advance.  Standalone code to reproduce the issue   Relevant log output  ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,bergentruckung,TF 2 building from source fails,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version Commit hash: cd8247b47bd5ba25b26752b55ea54b52e5574183  Custom Code No  OS Platform and Distribution Redhat Enterprise Linux 8.7  Mobile device _No response_  Python version 3.10.4  Bazel version 5.4.0 (same as what's there in .bazelversion)  GCC/Compiler version clang 17.0.0  CUDA/cuDNN version CUDA 12.1, cuDNN 8.9.0  GPU model and memory H100  Current Behaviour? Hello, I'm unable to build TF from source on CUDA 12.1. It tries to download a bunch of things, but that's failing with the attached error. Please let me know what I can do to build it correctly. Thanks in advance.  Standalone code to reproduce the issue   Relevant log output  ``` ",2023-06-16T12:50:06Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux subtype:bazel,open,0,5,https://github.com/tensorflow/tensorflow/issues/60901,", Have you tried the above query after trying the **bazel clean expunge** command. Could you try once and try repeating the above steps. And also make sure you follow the steps mentioned here. Also usually users get this error `PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: `unable to find valid certification path to requested target due to the system firewall. The system firewall restricts the application to connect to external systems. The firewall requires a valid certificate to allow access to the external systems. Could you please confirm, whether you're installing Bazel normally or via Bazelisk because Bazelisk is an easy way to install Bazel and automatically downloads the correct Bazel version for TensorFlow and if you're using Bazelisk then please download manually and please follow below steps: 1. wget https://github.com/bazelbuild/bazelisk/releases/download/v1.16.0/bazeliskdarwinarm64 (If you get any error with respect to certificate then you can use this command wget nocheckcertificate https://github.com/bazelbuild/bazelisk/releases/download/v1.16.0/bazeliskdarwinarm64 2. `chmod +x bazeliskdarwinarm64` 3. `sudo mv bazeliskdarwinarm64 /usr/local/bin/bazel` After that please try to run the below steps:  Also https://bazel.build/install/compilesourcebootstrapunix. please try to comment out 'for' statement and rebuild a binary version of bazel: https://github.com/bazelbuild/bazel/blob/master/src/main/cpp/blaze.ccL1015 Then use this to build tensorflow. Thank you!","Thanks, . >Have you tried the above query after trying the bazel clean expunge command. Could you try once and try repeating the above steps. And also make sure you follow the steps mentioned here. Yes, I've tried after running `bazel clean expunge` as well. Also, I've been following the exact same docs that you linked. >Also usually users get this error PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target due to the system firewall. The system firewall restricts the application to connect to external systems. The firewall requires a valid certificate to allow access to the external systems. What can I do to bypass this? What's the cert that is causing the problem? Since the error seems to indicate a java application (I'm guessing bazel?), is it possible to add the required cert to its java keystore/cert bundle? >Could you please confirm, whether you're installing Bazel normally or via Bazelisk because Bazelisk is an easy way to install Bazel and automatically downloads the correct Bazel version for TensorFlow and if you're using Bazelisk then please download manually and please follow below steps: Yes, I'm using `bazelisk` to install the correct version of `bazel`.",", were you able to check this?",Any updates here?,", any updates here?"
1886,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.test.gpu_device_name() leads to soft lockup and unusable system)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.16 (Conda 11.4)  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.4  GPU model and memory NVIDIA T4  Current Behaviour? We found that running `tf.test.gpu_device_name()` leads to a soft lockup and an unresponsive system. I apologise in advance, I don't know much about Tensorflow. But several of my coworkers do and I'm in charge of maintaining infrastructure. We have a virtual server for computeintensive tasks where we train models and work with large datasets. Yesterday at about 7 local time I found that I couldn't SSH into the server so I had to wait for IT to forcibly restart the server. At around 13 local time the server was back up and I looked through the kernel logs to find that there was a soft lockup kernel bug. This means that the server was still running, but some process wasn't releasing the CPU for more than 20 seconds, which meant that no other process could fulfill its tasks. Not even half an hour later and the server locked up again. I got a message from a coworker who suspected that they were at fault for the server locking up because they started running a very computeintensive Python script on the server last night. They opened a Python shell and typed in these two lines and watched the server lock up in real time.  I provided the relevant log output below. It required another hard reset from IT to get the server b)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mjugl,tf.test.gpu_device_name() leads to soft lockup and unusable system,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.16 (Conda 11.4)  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.4  GPU model and memory NVIDIA T4  Current Behaviour? We found that running `tf.test.gpu_device_name()` leads to a soft lockup and an unresponsive system. I apologise in advance, I don't know much about Tensorflow. But several of my coworkers do and I'm in charge of maintaining infrastructure. We have a virtual server for computeintensive tasks where we train models and work with large datasets. Yesterday at about 7 local time I found that I couldn't SSH into the server so I had to wait for IT to forcibly restart the server. At around 13 local time the server was back up and I looked through the kernel logs to find that there was a soft lockup kernel bug. This means that the server was still running, but some process wasn't releasing the CPU for more than 20 seconds, which meant that no other process could fulfill its tasks. Not even half an hour later and the server locked up again. I got a message from a coworker who suspected that they were at fault for the server locking up because they started running a very computeintensive Python script on the server last night. They opened a Python shell and typed in these two lines and watched the server lock up in real time.  I provided the relevant log output below. It required another hard reset from IT to get the server b",2023-06-16T12:20:44Z,stat:awaiting response type:bug subtype: ubuntu/linux TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60900,"Hi  , I think the problem is not with Tensorflow.I tested the same code in colab and it executes fine.Gist attached for reference. I request you to please refer the attached pip instructions guide to check the Hardware requirements and GPU setup process. I have seen from the attached logs GPU was not enabled which may be causing the problem.Please verify the GPU steps and confirm the same.  Coming to GPU drivers you can check the Nvidia website for compatible GPU driver for your GPU.Also Tensorflow tested configurations for CUDA and cuDNN can be found here. Thanks!","Hi , > I have seen from the attached logs GPU was not enabled which may be causing the problem.Please verify the GPU steps and confirm the same. I reinstalled the graphics drivers and verified they work. `nvidiasmi` reports that the GPU is indeed active. I'm also fairly confident the graphics drivers were correctly installed before. Unfortunately, I can only provide a screenshot of the CLI for now. !Screenshot_20230619_114937 > Also Tensorflow tested configurations for CUDA and cuDNN can be found here. Good point. I found that we're running CUDA 11.4 which is not officially tested with TF 2.12. After the graphics driver reinstallation I set up a fresh Tensorflow install as shown in the docs, this time with TF 2.11. I'm getting the same soft lockup (and an unresponsive server) when performing the ""Verify install"" step. !Screenshot_20230619_120227 You can also see that it is being shown in the process list of the `nvidiasmi` screenshot above.","Okay I just verified that this issue is not unique to Tensorflow. I ran the bandwidth test from the CUDA samples repository and found it also leads to a CPU soft lockup. So I can confirm that this is likely not an issue with Tensorflow. On the other hand, I've no idea where to go from here. The issue persists and I've no idea what to look for next.","Hi  , I am also quite confident that the issue might be related to your own environment as it is not replicable from our side. I have tried it on GCP VM and also can get desired result as per logs attached below.  The issue is specific to your own environment which I even don't have a clue on this.I believe the issue might be related to OS. I am attaching few references from Internet for similar issues which are related to OS.Please refer link1 and link2.  Please refer the above links and maybe you can get more help from internet community. As the issues is not relevant to TF can we mark it as closed.  Thanks!","Hi, thanks for investigating this further. The issue has been resolved and it didn't have anything to do with Tensorflow in the end. For anyone who might see this in the future: our IT department forgot to inform us that the licensing process to access the GPU has changed very recently and that we needed to make some modification to our guest VM. The most likely explanation is that the GPU slows down after extended unlicensed use and probably stops working entirely, leading to the lockup we experienced. We haven't encountered this issue since we reconfigured our guest VM. Again thanks so much for taking the time to investigate even though this really was an issue on our behalf.",Are you satisfied with the resolution of your issue? Yes No
1090,"以下是一个github上的tensorflow下的一个issue, 标题是(Build Issue with Native TF-2.12)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version TF 2.12  Custom Code No  OS Platform and Distribution Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8  Bazel version 6.2.1  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? While Building with Latest master build is getting failed.  **Error Message:** error: no match for 'operator=' (operand types are 'absl::lts_20220623::Status' and 'tsl::Status') Observing this Build failure after PR 60872 got merged. **Note:**  1. Build is successful if we checkout previous commit(Commit ID: 76addf724a4794222e780542180dc32747d04aa2). 2. With this PR we also observed Jobs Failure at the same place.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Alavandar08,Build Issue with Native TF-2.12,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version TF 2.12  Custom Code No  OS Platform and Distribution Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8  Bazel version 6.2.1  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? While Building with Latest master build is getting failed.  **Error Message:** error: no match for 'operator=' (operand types are 'absl::lts_20220623::Status' and 'tsl::Status') Observing this Build failure after PR 60872 got merged. **Note:**  1. Build is successful if we checkout previous commit(Commit ID: 76addf724a4794222e780542180dc32747d04aa2). 2. With this PR we also observed Jobs Failure at the same place.  Standalone code to reproduce the issue   Relevant log output  ,2023-06-16T08:53:15Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.12,closed,0,9,https://github.com/tensorflow/tensorflow/issues/60897,Hi !  Could you please have a look at this link and make sure the compatible versions are matching yours?   Please let us know the exact command you have used so that we could replicate the error reported here.  Thank you!,"Hi  I have tried the compatible versions provided with in the link. Still I am observing the same issue as mentioned above. command I used to build TF from source: 1. Installing prerequisites (Env, bazel version etc.,) 2. Configuring the Build: ./configure 3. Building the package: bazel build //tensorflow/tools/pip_package:build_pip_package I have created a PR to revert specific commit 60872 (After reverting commit in local, I was able to build the package). Please let me know the fix for the above issue. Thank you!",As mentioned in the previous comment. For the above PR that got merged master had failed through CI phase !image Even in CI we are observing the same error !image,"I am also facing the same issue. Not able to build the tensorflow in linux. If i checkout the commit id 76addf724a4, build goes through.", ,"Hi  , The proposed PR by you has been closed as there won't be any fresh release of Tf2.12. This seems to be resolved in TF2.13 onwards. Could you please check with latest version and let us know if this is still a problem. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1452,"以下是一个github上的tensorflow下的一个issue, 标题是(test)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,InfocuspSamyakVora,test," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-06-16T07:58:46Z,invalid TFLiteConverter,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60896,Please don't spam
1560,"以下是一个github上的tensorflow下的一个issue, 标题是(I can't link the libtensorflowlite_flex.so file in my C++ TFLite code on Android.)， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android  TensorFlow installed from (source or binary): from source  TensorFlow version (or github SHA if from source): v2.12.0 I am trying to load a Swin Transformer model using the Flex delegate in TFLite code implemented in C++. After writing the sample code, I built it separately for Ubuntu and Android. While the model loading and execution work fine on Ubuntu, the model doesn't even load on Android. When converting the model file, I received a message instructing me to use the flex delegate as follows  So, I build flex delegate, and link libtensorflowlite_flex.so file to my execute file. I built the TFLite for Android using the following commands:  However, when I try to run the sample code on Android, I receive an error message similar to what I would get if the Flex delegate was not linked:  Of course, I have added the build option ""noasneeded"" and confirmed through the ""readelf"" command that the built file is linking the libtensorflowlite_flex.so file. Here is my CMake file  My code and weight file can download at this link > Just run ""sh build_android.sh"" than you can build my code. I am unable to identify the cause of the issue. I would greatly appreciate it if someone could help me.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,woojinn8,I can't link the libtensorflowlite_flex.so file in my C++ TFLite code on Android.,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android  TensorFlow installed from (source or binary): from source  TensorFlow version (or github SHA if from source): v2.12.0 I am trying to load a Swin Transformer model using the Flex delegate in TFLite code implemented in C++. After writing the sample code, I built it separately for Ubuntu and Android. While the model loading and execution work fine on Ubuntu, the model doesn't even load on Android. When converting the model file, I received a message instructing me to use the flex delegate as follows  So, I build flex delegate, and link libtensorflowlite_flex.so file to my execute file. I built the TFLite for Android using the following commands:  However, when I try to run the sample code on Android, I receive an error message similar to what I would get if the Flex delegate was not linked:  Of course, I have added the build option ""noasneeded"" and confirmed through the ""readelf"" command that the built file is linking the libtensorflowlite_flex.so file. Here is my CMake file  My code and weight file can download at this link > Just run ""sh build_android.sh"" than you can build my code. I am unable to identify the cause of the issue. I would greatly appreciate it if someone could help me.",2023-06-16T06:11:43Z,type:build/install comp:lite comp:lite-flex TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60893,"Hi , thanks for reporting your issue. Help me understand your environment a little bit better, are you building for Android on a linux system? Are you testing your model on a linux system or an android system? Have you reviewed this link? https://www.tensorflow.org/lite/guide/ops_select If you are testing your converted model on android please follow the instructions there, otherwise I think you are testing on a linux system from the context of everything. Have you tried enabling SELECT_TF_OPS before conversion? example: ","> Hi , thanks for reporting your issue. Help me understand your environment a little bit better, are you building for Android on a linux system? Are you testing your model on a linux system or an android system? Have you reviewed this link? https://www.tensorflow.org/lite/guide/ops_select If you are testing your converted model on android please follow the instructions there, otherwise I think you are testing on a linux system from the context of everything. Have you tried enabling SELECT_TF_OPS before conversion? >  > example: >  >  Thank you so much for reply.  To explain in more detail,  1) I build my code building for Android on a linux system 2) And I testing my model on android system  > I copied the built executable file to an ARM core embedded device with Android 8.1 installed and excute. 3) I also read about ops_select page. So, I used the exact same code you provided as a example for conversion and successfully converted my TF model to a TFLite model.  > I enable ""tf.lite.OpsSet.TFLITE_BUILTINS"" & ""tf.lite.OpsSet.SELECT_TF_OPS"" when i convert. In this environment, I am still encountering the following error message. ","Hi , Thanks for the information, have you followed these instructions? https://www.tensorflow.org/lite/guide/ops_selectandroid_aar did you build a custom aar or did you use the big one here? https://central.sonatype.com/artifact/org.tensorflow/tensorflowliteselecttfops/2.12.0 This should be how you link the flex ops on android as stated on the documentation: ","> Hi , Thanks for the information, have you followed these instructions? https://www.tensorflow.org/lite/guide/ops_selectandroid_aar did you build a custom aar or did you use the big one here? https://central.sonatype.com/artifact/org.tensorflow/tensorflowliteselecttfops/2.12.0 >  > This should be how you link the flex ops on android as stated on the documentation: >  >  Hi  Thanks to reply. I kindly request your understanding as I am not familiar with Android and Java, so even if my questions may be incorrect, I would appreciate your patience and understanding. The information you have shown is understood as the settings required for using Select TensorFlow operators when creating an Android application using Java. What I want to do is similar to this link, but the difference is that the link runs on Ubuntu, whereas I want to run it on Android. In my case, I provide a .so library file which built in C for android OS. And I want users to use it either in C or in Java using JNI.  In this case, do I still need the setup you described? If so, linking the ""libtensorflowlite_flex.so"" file in a sample implemented in C is not possible?.","Hi , no worries, it seems I misidentified your workflow previously, you are using C++ with JNI to use C++/tflite on Android, is that correct? Are you doing this entirely outside of Android studio? If so, I recommend you try adjusting your workflow to use Android Studio, as package/linking issues are better managed there. Here's a very simple Android Project which uses JNI to call C++ code, perhaps you can use it as a skeleton to get what you started working: HelloWorldJNI.zip. Let me know if that helps or if you run into issues trying out this workflow.",Thank you  Thank you for advice. I'll try to use Android Studio.,Are you satisfied with the resolution of your issue? Yes No
1003,"以下是一个github上的tensorflow下的一个issue, 标题是(Spurious(?) type inference failed warning for flattened tf.data.Dataset with a RaggedTensor)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Mac OS  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? As far as I can tell the code still runs as expected, but a seemly spurious warning is still issued. The issue is pretty niche, removing the `_merge` function or the `vals` part to the initial dataset will make the error go away. This occurs on 2.11, 2.12, and nightly on mac.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,chrisc36,Spurious(?) type inference failed warning for flattened tf.data.Dataset with a RaggedTensor,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Mac OS  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? As far as I can tell the code still runs as expected, but a seemly spurious warning is still issued. The issue is pretty niche, removing the `_merge` function or the `vals` part to the initial dataset will make the error go away. This occurs on 2.11, 2.12, and nightly on mac.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-15T20:54:26Z,stat:awaiting tensorflower type:bug comp:data TF 2.12,open,0,3,https://github.com/tensorflow/tensorflow/issues/60890,"Hi  , I have replicated the same behaviour on Mac M1 and logs attached below for reference.  If the issue is specific to Mac M1 then this should be handled by the Apple team itself. Let me check the same code on Linux and confirm the same. Thanks!"," , The same behaviour reflected in Linux Environment also as per logs below. Needs to dig more to confirm the behaviour. ","Thanks for looking into this, I am also seeing this on linux machines. From my perspective It would be great if we could get confirmation that this warning can be safely ignored, otherwise it is really just annoyance."
716,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot upgrade to tensorflow-gpu==2.12.0 on Windows)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code No  OS Platform and Distribution Windows 11  Mobile device   Python version 3.9.13  Bazel version   GCC/Compiler version   CUDA/cuDNN version   GPU model and memory   Current Behaviour? I expected, that tensorflowgpu will be installed without errors.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,lmocsi,Cannot upgrade to tensorflow-gpu==2.12.0 on Windows,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code No  OS Platform and Distribution Windows 11  Mobile device   Python version 3.9.13  Bazel version   GCC/Compiler version   CUDA/cuDNN version   GPU model and memory   Current Behaviour? I expected, that tensorflowgpu will be installed without errors.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-15T17:22:55Z,type:build/install subtype:windows TF 2.12,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60886,"Please consult the first paragraph of TF 2.12 release notes: > Removed redundant packages tensorflowgpu and tfnightlygpu. These packages were removed and replaced with packages that direct users to switch to tensorflow or tfnightly respectively. Since TensorFlow 2.1, the only difference between these two sets of packages was their names, so there is no loss of functionality or GPU support. See https://pypi.org/project/tensorflowgpu for more details.",Are you satisfied with the resolution of your issue? Yes No
1503,"以下是一个github上的tensorflow下的一个issue, 标题是(Model containing LSTM does not run after conversion using ACTIVATIONS_INT16_WEIGHTS_INT8 quantization)， 内容是 (  System information Linux OpenSuse Tumbleweed  TensorFlow installation : pip  TensorFlow library : Tfnightly, occurs on earlier versions too   Code Converting a model containing an LSTM to a TFlite model quantized with int 16 activations and int8 weights results in an error when trying to allocate tensors to run the model subsequently.    Failure after conversion As noted above, the interpreter fails to allocate tensors for the the converted model  Any other info / logs Here is the traceback of the error:  RuntimeError                              Traceback (most recent call last) Cell In[48], line 2       1 interpreter = tf.lite.Interpreter(model_content = calibrated_model) > 2 interpreter.allocate_tensors() File ~/anaconda3/envs/tfnight/lib/python3.9/sitepackages/tensorflow/lite/python/interpreter.py:531, in Interpreter.allocate_tensors(self)     529 def allocate_tensors(self):     530   self._ensure_safe() > 531   return self._interpreter.AllocateTensors() RuntimeError: tensorflow/lite/kernels/unidirectional_sequence_lstm.cc:965 output_state != nullptr was not true.Node number 1 (UNIDIRECTIONAL_SEQUENCE_LSTM) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DerryFitz,Model containing LSTM does not run after conversion using ACTIVATIONS_INT16_WEIGHTS_INT8 quantization,"  System information Linux OpenSuse Tumbleweed  TensorFlow installation : pip  TensorFlow library : Tfnightly, occurs on earlier versions too   Code Converting a model containing an LSTM to a TFlite model quantized with int 16 activations and int8 weights results in an error when trying to allocate tensors to run the model subsequently.    Failure after conversion As noted above, the interpreter fails to allocate tensors for the the converted model  Any other info / logs Here is the traceback of the error:  RuntimeError                              Traceback (most recent call last) Cell In[48], line 2       1 interpreter = tf.lite.Interpreter(model_content = calibrated_model) > 2 interpreter.allocate_tensors() File ~/anaconda3/envs/tfnight/lib/python3.9/sitepackages/tensorflow/lite/python/interpreter.py:531, in Interpreter.allocate_tensors(self)     529 def allocate_tensors(self):     530   self._ensure_safe() > 531   return self._interpreter.AllocateTensors() RuntimeError: tensorflow/lite/kernels/unidirectional_sequence_lstm.cc:965 output_state != nullptr was not true.Node number 1 (UNIDIRECTIONAL_SEQUENCE_LSTM) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.",2023-06-15T15:11:18Z,type:bug comp:lite TFLiteConverter ModelOptimizationToolkit,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60884,I reproduced the error on Ubuntu with Python 3.8. Here's a snippet of what you were trying to do (without quantization) which runs fine: ,"Adding onto this, we can get close to what you were trying to do before using the following script  But, we can see that your error occurs when trying to replace  with an extra step  So, it seems that TF Lite is encountering an issue when trying to apply the operation set  to your LSTM model. In particular, it seems to fail to prepare the LSTM layer ( operation in your error message) when this operation set is used. For now, you can try using full integer or float quantization, and I'll try to see if this is a simple fix only pertaining to this specific kind of quantization.","Here are some comments from whomever implemented  in the  class. Convert model using only TensorFlow Lite operations with quantized int8   weights, int16 activations and int64 bias.   Specifying this will throw an error for operations that do not yet have   quantized implementations.   This quantization mode may be used in models for superresolution,   audio signal processing or image denoising. It improves accuracy   significantly, but only slightly increases the model size.   WARNING: These ops are currently experimental and have not yet been   finalized.   They are only compatible with CPU execution, and have not been optimized for   production."," I have found a fix. Try adding . For example,  Perhaps this should be implemented for you automatically, seeing as you couldn't find this documented anywhere."," thanks for your efforts on this, it was nice to see your reasoning, even if I was well aware of where and how the problem was happening.  However what you propose is not a solution to the problem. I was aware of the parameter you suggested to change and did not use it for a very good reason.  In effect, by setting converter.target_spec.supported_types = [tf.int8]  as you suggest,  you are telling the converter to ignore the fact that we want 168 quantization and and forcing it to quantize at int8 only. ","Hi   I was able to reproduce this issue. Please find the gist here. The similar issues on support for LSTM on 16x8 quantization is being  tracked here [ CC([RNN] Max and min for dynamic tensors should be recorded during calibration: Failed for tensor arg1 Empty min/max for tensor arg1)](https://github.com/tensorflow/tensorflow/issues/55267), [ CC([RNN] TFLite fails to convert LSTM to 16x8 quantization)](https://github.com/tensorflow/tensorflow/issues/59626)  Can you please look into this. Thank you.","I was also able to reproduce using the same gist, seems like a legitimate bug. Hi wei, can you please take a look?","Hi  ,  we're wondering if you may be able to resolve your issue by using AIEdgeTorch, you can find more information here: googleblog. I have actually created a simple script for converting an LSTM model here:  If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repos.","In the end, we resolved it by converting the tensorflow model to onnx and using onnxruntime. The onnx model works perfectly, so whatever optimizations the tflite converter is doing, it is killing performance of lstms On Wed, 12 Jun 2024 at 07:33, LakshmiKalaKadali ***@***.***> wrote: > Hi   , > > we're wondering if you may be able to resolve your issue by using > AIEdgeTorch , you can > find more information here: googleblog >  > . > > I have actually created a simple script for converting an LSTM model here: > > import torch > import torchvision > import ai_edge_torch > > rnn = torch.nn.LSTM(10, 20, 2) > sample_inputs = (torch.randn(5, 3, 10),) > > edge_model = ai_edge_torch.convert(rnn.eval(), sample_inputs) > edge_model.export(""rnn.tflite"") > > If you want to, you can actually try visualizing the result in > modelexplorer  as well. > > Please try them out and let us know if this resolves your issue. If you > still need further help, feel free to open a new issue at the respective > repos. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >","Hi , since your issue is resolved by other means, we are closing this issue as not planned. Thanks.",Are you satisfied with the resolution of your issue? Yes No
997,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow-Quantum Module Import Error)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version v2.11.00gd5b57ca93e5 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8  Bazel version 5.3.0  GCC/Compiler version gcc (Ubuntu 9.4.01ubuntu1~20.04.1) 9.4.0  CUDA/cuDNN version Build cuda_11.8.r11.8/compiler.31833905_0  GPU model and memory A100 highmem node  Current Behaviour? Still trying to get TFQ to work postpy 3.10 upgrade in colab ... the TF/TFQ nightly_build route seems to be getting me closer as I no longer receive ""Module Not Found"" when I try importing TFQ, however, I now receive the pauli error below.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,liv4unix,Tensorflow-Quantum Module Import Error,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version v2.11.00gd5b57ca93e5 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8  Bazel version 5.3.0  GCC/Compiler version gcc (Ubuntu 9.4.01ubuntu1~20.04.1) 9.4.0  CUDA/cuDNN version Build cuda_11.8.r11.8/compiler.31833905_0  GPU model and memory A100 highmem node  Current Behaviour? Still trying to get TFQ to work postpy 3.10 upgrade in colab ... the TF/TFQ nightly_build route seems to be getting me closer as I no longer receive ""Module Not Found"" when I try importing TFQ, however, I now receive the pauli error below.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-15T10:19:18Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux TF 2.11,open,0,13,https://github.com/tensorflow/tensorflow/issues/60880,"Tried again using last night's nightly ... same exact error as above when trying to import TFQ.  Also, the quantum scripts (/scripts/test_all.sh) all failed   output is included below: Testing All Bazel py_test and cc_tests. Loading:  Loading: 0 packages loaded Analyzing: 130 targets (0 packages loaded, 0 targets configured) WARNING: /root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/external/local_config_tf/BUILD:9259:8: target 'libtensorflow_framework.so' is both a rule and a file; please choose another name for the rule WARNING: /root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/external/local_config_tf/BUILD:9269:8: target 'test_log_pb2.py' is both a rule and a file; please choose another name for the rule DEBUG: Rule 'qsim' indicated that a canonical reproducible form can be obtained by modifying arguments sha256 = ""a975f83605bb5240b65cff20847b0e9173549951267f96d69b852c6bd941a676"" DEBUG: Repository qsim instantiated at:   /content/quantum/WORKSPACE:35:13: in  Repository rule http_archive defined at:   /root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/external/bazel_tools/tools/build_defs/repo/http.bzl:355:31: in  INFO: Analyzed 130 targets (0 packages loaded, 0 targets configured). INFO: Found 83 targets and 47 test targets... [2 / 17] [Prepa] BazelWorkspaceStatusAction stablestatus.txt ... (7 actions, 3 running) [10 / 25] Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc; 1s local ... (8 actions running) [11 / 25] Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc; 3s local ... (8 actions, 7 running) [17 / 28] Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc; 4s local ... (8 actions running) [18 / 29] Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc; 10s local ... (8 actions, 7 running) [18 / 29] Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc; 12s local ... (8 actions running) [18 / 29] 1 / 47 tests; Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc; 15s local ... (8 actions running) INFO: From Compiling tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc: In file included from tensorflow_quantum/core/ops/tfq_calculate_unitary_op.cc:32: ./tensorflow_quantum/core/src/util_qsim.h:496:13: warning: 'void tfq::BalanceTrajectory(const int&, const int&, std::vector >*)' defined but not used [Wunusedfunction]   496              ^~~~~~~~~~~~~~~~~ FAIL: //tensorflow_quantum/python/layers/high_level:noisy_pqc_test (see /root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/execroot/__main__/bazelout/k8opt/testlogs/tensorflow_quantum/python/layers/high_level/noisy_pqc_test/test.log) ERROR: /content/quantum/tensorflow_quantum/python/layers/high_level/BUILD:100:8: Testing //tensorflow_quantum/python/layers/high_level:noisy_pqc_test failed: Test failed, aborting ERROR: Test failed, aborting INFO: Elapsed time: 27.041s, Critical Path: 26.23s INFO: 46 processes: 30 internal, 16 local. INFO: Build completed, 1 test FAILED, 46 total actions INFO: Build completed, 1 test FAILED, 46 total actions Testing failed, please correct errors before proceeding. {==================== Test output for //tensorflow_quantum/python/layers/high_level:noisy_pqc_test: Traceback (most recent call last):   File ""/root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/execroot/__main__/bazelout/k8opt/bin/tensorflow_quantum/python/layers/high_level/noisy_pqc_test.runfiles/__main__/tensorflow_quantum/python/layers/high_level/noisy_pqc_test.py"", line 30, in      from tensorflow_quantum.python.layers.high_level import noisy_pqc   File ""/root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/execroot/__main__/bazelout/k8opt/bin/tensorflow_quantum/python/layers/high_level/noisy_pqc_test.runfiles/__main__/tensorflow_quantum/python/layers/high_level/noisy_pqc.py"", line 25, in      from tensorflow_quantum.python.layers.circuit_construction import elementary   File ""/root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/execroot/__main__/bazelout/k8opt/bin/tensorflow_quantum/python/layers/high_level/noisy_pqc_test.runfiles/__main__/tensorflow_quantum/python/layers/circuit_construction/elementary.py"", line 24, in      class AddCircuit(tf.keras.layers.Layer):   File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/util/lazy_loader.py"", line 58, in __getattr__     module = self._load()   File ""/usr/local/lib/python3.10/distpackages/tensorflow/python/util/lazy_loader.py"", line 41, in _load     module = importlib.import_module(self.__name__)   File ""/usr/lib/python3.10/importlib/__init__.py"", line 126, in import_module     return _bootstrap._gcd_import(name[level:], package, level)   File ""/usr/local/lib/python3.10/distpackages/keras/__init__.py"", line 21, in      from keras import models   File ""/usr/local/lib/python3.10/distpackages/keras/models/__init__.py"", line 18, in      from keras.engine.functional import Functional   File ""/usr/local/lib/python3.10/distpackages/keras/engine/functional.py"", line 26, in      from keras import backend   File ""/usr/local/lib/python3.10/distpackages/keras/backend.py"", line 35, in      from keras.engine import keras_tensor   File ""/usr/local/lib/python3.10/distpackages/keras/engine/keras_tensor.py"", line 19, in      from keras.utils import object_identity   File ""/usr/local/lib/python3.10/distpackages/keras/utils/__init__.py"", line 53, in      from keras.utils.feature_space import FeatureSpace   File ""/usr/local/lib/python3.10/distpackages/keras/utils/feature_space.py"", line 20, in      from keras.engine import base_layer   File ""/usr/local/lib/python3.10/distpackages/keras/engine/base_layer.py"", line 44, in      from keras.saving.legacy.saved_model import layer_serialization   File ""/usr/local/lib/python3.10/distpackages/keras/saving/legacy/saved_model/layer_serialization.py"", line 23, in      from keras.saving.legacy.saved_model import save_impl   File ""/usr/local/lib/python3.10/distpackages/keras/saving/legacy/saved_model/save_impl.py"", line 34, in      from keras.saving.legacy.saved_model import load as keras_load   File ""/usr/local/lib/python3.10/distpackages/keras/saving/legacy/saved_model/load.py"", line 29, in      from keras.protobuf import saved_metadata_pb2   File ""/usr/local/lib/python3.10/distpackages/keras/protobuf/saved_metadata_pb2.py"", line 5, in      from google.protobuf.internal import builder as _builder ImportError: cannot import name 'builder' from 'google.protobuf.internal' (/usr/local/lib/python3.10/distpackages/google/protobuf/internal/__init__.py) ================================================================================ //tensorflow_quantum/core/ops:batch_util_test                         NO STATUS //tensorflow_quantum/core/ops:circuit_execution_ops_test              NO STATUS //tensorflow_quantum/core/ops:cirq_ops_test                           NO STATUS //tensorflow_quantum/core/ops:tfq_adj_grad_op_test                    NO STATUS //tensorflow_quantum/core/ops:tfq_ps_util_ops_test                    NO STATUS //tensorflow_quantum/core/ops:tfq_simulate_ops_gpu_test               NO STATUS //tensorflow_quantum/core/ops:tfq_simulate_ops_test                   NO STATUS //tensorflow_quantum/core/ops:tfq_unitary_op_test                     NO STATUS //tensorflow_quantum/core/ops:tfq_utility_ops_test                    NO STATUS //tensorflow_quantum/core/ops/math_ops:fidelity_op_test               NO STATUS //tensorflow_quantum/core/ops/math_ops:inner_product_grad_test        NO STATUS //tensorflow_quantum/core/ops/math_ops:inner_product_op_test          NO STATUS //tensorflow_quantum/core/ops/math_ops:simulate_mps_test              NO STATUS //tensorflow_quantum/core/ops/noise:noisy_expectation_op_test         NO STATUS //tensorflow_quantum/core/ops/noise:noisy_sampled_expectation_op_test NO STATUS //tensorflow_quantum/core/ops/noise:noisy_samples_op_test             NO STATUS //tensorflow_quantum/core/serialize:op_serializer_test                NO STATUS //tensorflow_quantum/core/serialize:serializable_gate_set_test        NO STATUS //tensorflow_quantum/core/serialize:serializer_test                   NO STATUS //tensorflow_quantum/core/src:adj_util_test                           NO STATUS //tensorflow_quantum/core/src:circuit_parser_qsim_test                NO STATUS //tensorflow_quantum/core/src:program_resolution_test                 NO STATUS //tensorflow_quantum/core/src:util_qsim_test                          NO STATUS //tensorflow_quantum/datasets:cluster_state_test                      NO STATUS //tensorflow_quantum/datasets:spin_system_test                        NO STATUS //tensorflow_quantum/python:util_test                                 NO STATUS //tensorflow_quantum/python/differentiators:adjoint_test              NO STATUS //tensorflow_quantum/python/differentiators:differentiator_test       NO STATUS //tensorflow_quantum/python/differentiators:gradient_test             NO STATUS //tensorflow_quantum/python/differentiators:linear_combination_test   NO STATUS //tensorflow_quantum/python/differentiators:parameter_shift_test      NO STATUS //tensorflow_quantum/python/differentiators:parameter_shift_util_test NO STATUS //tensorflow_quantum/python/layers/circuit_construction:elementary_test NO STATUS //tensorflow_quantum/python/layers/circuit_executors:expectation_test NO STATUS //tensorflow_quantum/python/layers/circuit_executors:input_checks_test NO STATUS //tensorflow_quantum/python/layers/circuit_executors:sample_test      NO STATUS //tensorflow_quantum/python/layers/circuit_executors:sampled_expectation_test NO STATUS //tensorflow_quantum/python/layers/circuit_executors:state_test       NO STATUS //tensorflow_quantum/python/layers/circuit_executors:unitary_test     NO STATUS //tensorflow_quantum/python/layers/high_level:controlled_pqc_test     NO STATUS //tensorflow_quantum/python/layers/high_level:noisy_controlled_pqc_test NO STATUS //tensorflow_quantum/python/layers/high_level:pqc_test                NO STATUS //tensorflow_quantum/python/optimizers:rotosolve_minimizer_test       NO STATUS //tensorflow_quantum/python/optimizers:spsa_minimizer_test            NO STATUS //tensorflow_quantum/core/serialize:op_deserializer_test                 PASSED in 12.4s //tensorflow_quantum/python:quantum_context_test                         PASSED in 5.9s //tensorflow_quantum/python/layers/high_level:noisy_pqc_test             FAILED in 10.4s   /root/.cache/bazel/_bazel_root/bcb09a07ff13a4e9505bab5f8eac883a/execroot/__main__/bazelout/k8opt/testlogs/tensorflow_quantum/python/layers/high_level/noisy_pqc_test/test.log Executed 3 out of 47 tests: 2 tests pass, 1 fails locally and 44 were skipped. There were tests whose specified size is too big. Use the test_verbose_timeout_warnings command line option to see which ones these are.}","Output from today's run using the most recent nightly build. I am just using CPU, no GPU due to the length of compile time, and I decided to try branch instead of master to see if that made a difference.  It did not, same error persisted.  Quantum smoke tests are all still failing, and the tfq import still bombs out with the same pauli error.   See attached output 061723_tfq_import_err_v2.11.00gd5b57ca93e5.txt","Attempted nightly build using TF 2.12 and Python 3.9, but TFQ compile failed. I saved the colab to github for your review as the error was quite profound: https://github.com/liv4unix/quantum/blob/master/TF12_TFQ_nightly_bld_061823_bazelout_gccerr.ipynb",Hi ! I  faced the  same issue as reported here. By any chance did you try to downgrade the TF version  and try to build TF Quantum? There are some version incompatibility related issues occurring it seems. Please have a look at this doc and let me know if that helps? Thank you!,"Thank you for the response. I have attempted all steps, in each section of that tutorial using TF11 (and even tried TF12, just to see what would happen, yes, I know it's unsupported). None of the documented steps work, TFQ does not import in Colab any longer, as far as I can tell.   The latest daily build from source is still compiling using Py 3.9, but I am including a link for the pip install for py3.8.  Here, you will see that TFQ will not import on the pip install in Colab: ""no module named Cirq"" https://github.com/liv4unix/quantum/blob/master/TF11TFQnightlyPy38_062023.ipynb"," I have replicated the issue on colab using TF 2.12 and nightly, please find the attached gists for reference.  Thank you!","Last night's build from source, using 06202023_nightly image is complete and TFQ still does not import into my Colab [Pro+] environment: 1) tensorflowquantum does NOT show up in ""pip list"" as an installed package 2) the same ""cannot import name 'pauli_sum_pb2' from 'tensorflow_quantum.core.proto'"" persists on the TFQ import 3) the TFQ/bazel installation confirmation scripts (./scripts/test_all.sh) continue to FAIL All Colab job output is here: https://github.com/liv4unix/quantum/blob/master/TF_TFQ_Build_from_Source_Nightly_06212023.ipynb FYI: This is a CPU TF/TFQ build. However, my QNNCuda TF/TFQ build from source takes ~12 hours.","Attempted to roll back to Python 3.7 but the TFQ requirements file bombs out. It appears python 3.8 is the min required version for TFQ contrary to the install guide: https://www.tensorflow.org/quantum/install Output from ""Py 3.7, tfnightly2.11.0, and quantum.git"" can be found here: https://github.com/liv4unix/quantum/blob/master/TF_TFQ_Build_from_Source_Nightly_06222023.ipynb","While I've tested the pip installs for TFQ many times, I've never actually uploaded the colab notebooks.  Both python 3.8 and 3.9 fail to import TFQ with an identical error: ModuleNotFoundError: No module named 'tensorflow_quantum' This is differentiated from the pauli error observed when attempting to import TFQ, when building from source. Python 3.9: https://github.com/liv4unix/quantum/blob/master/Pip_install_Py39_TF_TFQ_062423.ipynb Python 3.8 https://github.com/liv4unix/quantum/blob/master/Pip_install_Py38_TF_TFQ_062423.ipynb","Hi Michael, Any ETA on when an update will be available? Just tested latest pip, nothing new ... and I won't bother testing nightlies until I hear from you as those builds hurt. I was really hoping to submit this latest (year's worth of) CirqTFQ stack!","After going through all my previous build jobs, the issue appears to be that bazel config is defaulting to Colab's builtin Python 10  bazel is not using the version of Python in the activated environment (py 3.8) I cannot figure out how to override.    I am attempting to once again hardcode the 3.8 python paths into the bazel config in the TF11 nightly build.  Will upload the output once the build is complete.","I was able to getTF11 bazel config script to execute successfully when I entered the FQPN for the activated py38_quantum_env lib and bin paths  However TFQ/nightly now bombs out with a new error on bazel build: ERROR: /content/quantum/tensorflow_quantum/core/src/BUILD:123:11: Compiling tensorflow_quantum/core/src/program_resolution.: (Exit 1): gcc failed: error executing command /usr/bin/gcc U_FORTIFY_SOURCE fstackprotector Wall Wunusedbutsetparameter Wnofreenonheapobject fnoomitframepointer g0 O2 'D_FORTIFY_SOURCE=1' DNDEBUG ffunctionsections ... (remaining 54 arguments skipped) In file included from bazelout/k8opt/bin/external/local_config_tf/include/tensorflow/tsl/platform/status.h:37,                  from bazelout/k8opt/bin/external/local_config_tf/include/tensorflow/core/platform/status.h:23,                  from bazelout/k8opt/bin/external/local_config_tf/include/tensorflow/core/lib/core/status.h:19,                  from ./tensorflow_quantum/core/src/program_resolution.h:25,                  from tensorflow_quantum/core/src/program_resolution.cc:16: bazelout/k8opt/bin/external/local_config_tf/include/tensorflow/tsl/protobuf/error_codes.pb.h:12:2: error: error This file was generated by a newer version of protoc which is    12  error incompatible with your Protocol Buffer headers. Full notebook is uploaded here: https://github.com/liv4unix/quantum/blob/master/TF_TFQ_Build_from_Source_Nightly_070823.ipynb",Is anyone even working on this?   Is there any way for me to access Sycamore without using Colab?  I am desperate to continue my research guys. Please help.
944,"以下是一个github上的tensorflow下的一个issue, 标题是( When will TFRT integration be fully released?)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version master, commit id 1bd12b4863759e44da4139628973f372655b14f6  Custom Code No  OS Platform and Distribution Linux  Mobile device _No response_  Python version _No response_  Bazel version 6.1.0  GCC/Compiler version 8.3.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Firstly, the TFRT integration is disable in `.bazelrc`. Comment out TFRT deleted packages in `.bazelrc`, add deps for tensorflow serving, fix some reference in `BUILD`, blah, blah, blah...The build is still broken.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ychensha, When will TFRT integration be fully released?,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version master, commit id 1bd12b4863759e44da4139628973f372655b14f6  Custom Code No  OS Platform and Distribution Linux  Mobile device _No response_  Python version _No response_  Bazel version 6.1.0  GCC/Compiler version 8.3.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Firstly, the TFRT integration is disable in `.bazelrc`. Comment out TFRT deleted packages in `.bazelrc`, add deps for tensorflow serving, fix some reference in `BUILD`, blah, blah, blah...The build is still broken.   Standalone code to reproduce the issue   Relevant log output  ",2023-06-15T07:21:45Z,stat:awaiting tensorflower type:support comp:runtime,open,0,3,https://github.com/tensorflow/tensorflow/issues/60876," , Could you please take a look into this, it is related to your commit https://github.com/tensorflow/tensorflow/commit/1bd12b4863759e44da4139628973f372655b14f6","  Hi, just to confirm, did you narrow down the failure to my commit? It is a very small change which doesn't add/remove any dependency to any file, and has nothing to do with TFRTI'd be surprised if it had anything to do with the failure reported here.","Understood, Thank you!"
1855,"以下是一个github上的tensorflow下的一个issue, 标题是(Bump requests from 2.28.2 to 2.31.0)， 内容是 (Bumps requests from 2.28.2 to 2.31.0.  Release notes Sourced from requests's releases.  v2.31.0 2.31.0 (20230522) Security   Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential forwarding of ProxyAuthorization headers to destination servers when following HTTPS redirects. When proxies are defined with user info (https://user:pass:8080), Requests will construct a ProxyAuthorization header that is attached to the request to authenticate with the proxy. In cases where Requests receives a redirect response, it previously reattached the ProxyAuthorization header incorrectly, resulting in the value being sent through the tunneled connection to the destination server. Users who rely on defining their proxy credentials in the URL are strongly encouraged to upgrade to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy credentials once the change has been fully deployed. Users who do not use a proxy or do not supply their proxy credentials through the user information portion of their proxy URL are not subject to this vulnerability. Full details can be read in our Github Security Advisory and CVE202332681.   v2.30.0 2.30.0 (20230503) Dependencies   ⚠️ Added support for urllib3 2.0. ⚠️ This may contain minor breaking changes so we advise careful testing and reviewing https://urllib3.readthedocs.io/en/latest/v2migrationguide.html prior to upgrading. Users who wish to stay on urllib3 1.x can pin to urllib3&lt;2.   v2.29.0 2.29.0 (20230426) Improvements  Requests now defers chunked requests to the urllib3 implementation to improve standardization. ( CC(Feature request to spe)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dependabot[bot],Bump requests from 2.28.2 to 2.31.0,"Bumps requests from 2.28.2 to 2.31.0.  Release notes Sourced from requests's releases.  v2.31.0 2.31.0 (20230522) Security   Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential forwarding of ProxyAuthorization headers to destination servers when following HTTPS redirects. When proxies are defined with user info (https://user:pass:8080), Requests will construct a ProxyAuthorization header that is attached to the request to authenticate with the proxy. In cases where Requests receives a redirect response, it previously reattached the ProxyAuthorization header incorrectly, resulting in the value being sent through the tunneled connection to the destination server. Users who rely on defining their proxy credentials in the URL are strongly encouraged to upgrade to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy credentials once the change has been fully deployed. Users who do not use a proxy or do not supply their proxy credentials through the user information portion of their proxy URL are not subject to this vulnerability. Full details can be read in our Github Security Advisory and CVE202332681.   v2.30.0 2.30.0 (20230503) Dependencies   ⚠️ Added support for urllib3 2.0. ⚠️ This may contain minor breaking changes so we advise careful testing and reviewing https://urllib3.readthedocs.io/en/latest/v2migrationguide.html prior to upgrading. Users who wish to stay on urllib3 1.x can pin to urllib3&lt;2.   v2.29.0 2.29.0 (20230426) Improvements  Requests now defers chunked requests to the urllib3 implementation to improve standardization. ( CC(Feature request to spe",2023-06-15T06:09:10Z,size:S dependencies python,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60875,"Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting ` rebase`.","Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting ` rebase`.","Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting ` rebase`.","Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting ` rebase`.","Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting ` rebase`.","Dependabot tried to update this pull request, but something went wrong. We're looking into it, but in the meantime you can retry the update by commenting ` rebase`.","OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting ` ignore this major version` or ` ignore this minor version`. If you change your mind, just reopen this PR and I'll resolve any conflicts on it."
962,"以下是一个github上的tensorflow下的一个issue, 标题是(New unit tests fails when built with gcc)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? The unit test fails with a pipeline error resulting in inability to read a file as it was not created correctly, the name seems to be wrong. The file that exists is 00000000.main.tensorflow_{anonymous}_NopPass_after.mlir but the file attempted to be read is 00000000.main.tensorflow_anonymous_namespace_NopPass_after.mlir  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,elfringham,New unit tests fails when built with gcc,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 6.1.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? The unit test fails with a pipeline error resulting in inability to read a file as it was not created correctly, the name seems to be wrong. The file that exists is 00000000.main.tensorflow_{anonymous}_NopPass_after.mlir but the file attempted to be read is 00000000.main.tensorflow_anonymous_namespace_NopPass_after.mlir  Standalone code to reproduce the issue   Relevant log output  ",2023-06-14T16:05:56Z,stat:awaiting tensorflower type:bug type:build/install subtype: ubuntu/linux,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60862,Testing on x86 shows that this fails when built with gcc but passes when built with clang.,Fixed by https://github.com/tensorflow/tensorflow/pull/62921,Are you satisfied with the resolution of your issue? Yes No
1380,"以下是一个github上的tensorflow下的一个issue, 标题是(Relu Grad Shape Issues)， 内容是 (Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Just trying to implement 3D CNN for CT images, and suddenly came across this error. Couldn't get much on the internet. Below is the snippet of the error. grads_and_vars = self.compute_gradients(loss, var_list, tape)     File ""/usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py"", line 275, in compute_gradients       grads = tape.gradient(loss, var_list) Node: 'gradient_tape/model_7/3dcnn/conv3d_24/ReluGrad' Inputs to operation gradient_tape/model_7/3dcnn/conv3d_24/ReluGrad of type ReluGrad must have the same size and shape.  Input 0: [1,0,1875,256] != input 1: [1,0,125,15,256] 	 [[{{node gradient_tape/model_7/3dcnn/conv3d_24/ReluGrad}}]] [Op:__inference_train_function_52480]  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,profhulk-MI,Relu Grad Shape Issues,"Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Just trying to implement 3D CNN for CT images, and suddenly came across this error. Couldn't get much on the internet. Below is the snippet of the error. grads_and_vars = self.compute_gradients(loss, var_list, tape)     File ""/usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py"", line 275, in compute_gradients       grads = tape.gradient(loss, var_list) Node: 'gradient_tape/model_7/3dcnn/conv3d_24/ReluGrad' Inputs to operation gradient_tape/model_7/3dcnn/conv3d_24/ReluGrad of type ReluGrad must have the same size and shape.  Input 0: [1,0,1875,256] != input 1: [1,0,125,15,256] 	 [[{{node gradient_tape/model_7/3dcnn/conv3d_24/ReluGrad}}]] [Op:__inference_train_function_52480]  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-14T04:35:19Z,stat:awaiting response stale type:others comp:keras TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60857,"MI, Could you please provide the complete standalone code or the colab gist to reproduce the issue which helps us to debug the issue in an effective way. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1919,"以下是一个github上的tensorflow下的一个issue, 标题是(CopyTensor::ViaDMA function, allocator type sometimes not match actual input underlying memory type)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0rc0  Custom Code Yes  OS Platform and Distribution CentOS Linux 7  Mobile device _No response_  Python version 3.7.5  Bazel version bazel 3.7.2  GCC/Compiler version gcc9  CUDA/cuDNN version cuda 11, cudnn 8  GPU model and memory Tesla V100S  Current Behaviour? In `CopyTensor::ViaDMA`, `alloc_attr `decides the direction of memory copy. However, sometimes `alloc_attr `does not keep the same as the Tensor pointer's underlying memory type. In my case,`src_alloc_attr.on_host()` is `True`, but `input>GetMemoryType()` equals to `kDevice`. So this results the memory copy direction in this function is cpu>gpu, but actually the direction should be gpu > gpu.  I think this bug does not reveal is because the cuda driver api, like `cuMemcpyHtoD()`, does not care about the direction if it's H to D or others, it only cares about the pointer attribute, if the src pointer is on device and dst pointer is also on device, even if we call `cuMemcpyHtoD()`, cuda driver would still do D to D copy. This feature would cover many bugs.  I haven't figured out where did the `on_host `attribute is set. From my understanding so far, same allocator object would be reused on different tensors, but the `on_host `attribute is oneway, once it's been set `on_host`, it cannot be unset later. This might cause some issue? Also, why wouln't we just use `input>GetMemoryType()` to decieds the memory copy direction, instead of the `on_host `attribute of `alloc_attr` I meet this issue when I run horovod unit test case. Add so)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,chengchen666,"CopyTensor::ViaDMA function, allocator type sometimes not match actual input underlying memory type","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0rc0  Custom Code Yes  OS Platform and Distribution CentOS Linux 7  Mobile device _No response_  Python version 3.7.5  Bazel version bazel 3.7.2  GCC/Compiler version gcc9  CUDA/cuDNN version cuda 11, cudnn 8  GPU model and memory Tesla V100S  Current Behaviour? In `CopyTensor::ViaDMA`, `alloc_attr `decides the direction of memory copy. However, sometimes `alloc_attr `does not keep the same as the Tensor pointer's underlying memory type. In my case,`src_alloc_attr.on_host()` is `True`, but `input>GetMemoryType()` equals to `kDevice`. So this results the memory copy direction in this function is cpu>gpu, but actually the direction should be gpu > gpu.  I think this bug does not reveal is because the cuda driver api, like `cuMemcpyHtoD()`, does not care about the direction if it's H to D or others, it only cares about the pointer attribute, if the src pointer is on device and dst pointer is also on device, even if we call `cuMemcpyHtoD()`, cuda driver would still do D to D copy. This feature would cover many bugs.  I haven't figured out where did the `on_host `attribute is set. From my understanding so far, same allocator object would be reused on different tensors, but the `on_host `attribute is oneway, once it's been set `on_host`, it cannot be unset later. This might cause some issue? Also, why wouln't we just use `input>GetMemoryType()` to decieds the memory copy direction, instead of the `on_host `attribute of `alloc_attr` I meet this issue when I run horovod unit test case. Add so",2023-06-14T03:09:42Z,stat:awaiting tensorflower type:bug comp:runtime TF 2.12,open,0,0,https://github.com/tensorflow/tensorflow/issues/60856
883,"以下是一个github上的tensorflow下的一个issue, 标题是(How to implement CollectiveAllReduceStrategy?)， 内容是 (Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2,9  Custom Code Yes  OS Platform and Distribution Ubuntu 18.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying use CollectiveAllReduceStrategy using tf 2.9, but couldn't find much information. Based on following image, is **CollectiveAllReduceStrategy** is **MultiWorkerMirrorStrategy**?  Thanks  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,purvang3,How to implement CollectiveAllReduceStrategy?,"Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2,9  Custom Code Yes  OS Platform and Distribution Ubuntu 18.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying use CollectiveAllReduceStrategy using tf 2.9, but couldn't find much information. Based on following image, is **CollectiveAllReduceStrategy** is **MultiWorkerMirrorStrategy**?  Thanks  Standalone code to reproduce the issue   Relevant log output  ",2023-06-12T20:52:51Z,stat:awaiting response stale comp:dist-strat type:others TF 2.9,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60847,running multiworkerstrategy using two node getting following error.  **Sample code**  **worker tf config** ,", Distribution strategy that uses collective ops for allreduce. It is similar to MirroredStrategy but it uses collective ops for reduction. By default it uses all local GPUs or CPU for singleworker training. When 'TF_CONFIG' environment variable is given, it parses cluster_spec, task_type and task_id from 'TF_CONFIG' and turns into a multiworker strategy which mirrores models on GPUs of all machines in a cluster. In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs. Could you please take a look at the below file where the details are mentioned for the CollectiveAllReduceStrategy. https://github.com/tensorflow/tensorflow/blob/6f650f54e4c16be4fe94bc9e2172077481b224ac/tensorflow/python/distribute/collective_all_reduce_strategy.py"," Thanks for reply. 1) Based on your answer, CollectiveAllReduceStrategy **is not** MultiWorkerStrategy. Right? If not, then how to implement CollectiveAllReduceStrategy. 2)  I followed above example as well below for MultiWorkerStrategy, but training hangs and doesn't proceed. how can I make it work? https://www.tensorflow.org/tutorials/distribute/multi_worker_with_ctl",using NCCL makes training hang. AUTO works fine. options = tf.distribute.experimental.CommunicationOptions(                                                                                                      implementation=tf.distribute.experimental.CommunicationImplementation.NCCL                                                                               )                                                                                                                                                            strategy = tf.distribute.MultiWorkerMirroredStrategy(communication_options=options)  ,CollectiveAllReduceStrategy is MultiWorkerMirrorStrategy. CollectiveAllReduceStrategy is a name we used in the implementation. Please refer to documentations of MultiWorkerMirrorStrategy.,"Thanks xinyi. That was I expected after reading code. Also as mentioned earlier, I am not able to run NCCL based communication. AUTO and RING works fine. NCCL version : 2.12.121+cuda11.6 CUDA version : 11.6 tensorflow version : 2.11",According to the error message it's saying that you have both CPU and GPU in your cluster. In this case NCCL cannot be used.,"xinyi . I am trying to run 2 nodes, each with 4 A100 gpus and same version of NCCL, cuda and tensorflow. I am running only on GPU. Also mentioned error is solved and there is no error when I use tf.distribute.experimental.CommunicationImplementation.RING or tf.distribute.experimental.CommunicationImplementation.AUTO. when I use tf.distribute.experimental.CommunicationImplementation.NCCL, **training hangs**, no error.","This is expected because there are some edge cases that tf.distribute.experimental.CommunicationImplementation.NCCL could not support. From experiences, AUTO and RING could cover more cases. And when using AUTO, it will fall back to the supported CommunicationImplementation type when running into these cases.",Thanks for reply xinyi. getting following error for my code. how can I resolve this? ,Could you please try adding tf.config.set_soft_device_placement(True)?,"Also, could you tell if this error is encountered when defining the model / compiling / model.fit /etc?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,it was packages issue. solved.,Are you satisfied with the resolution of your issue? Yes No
2016,"以下是一个github上的tensorflow下的一个issue, 标题是(Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context->paddings, 0) != op_context->dims (4 != 1) Node number 0 (PAD) failed to prepare.)， 内容是 (I have converted my DenseNet121 model to model.tflite and when i am loading it to android app and trying to make predictions, it's giving following errors : java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context>paddings, 0) != op_context>dims (4 != 1) Node number 0 (PAD) failed to prepare. at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method) at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensorsIfNeeded(NativeInterpreterWrapper.java:308) at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:248) at org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs(InterpreterImpl.java:101) at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:77) at org.tensorflow.lite.InterpreterImpl.run(InterpreterImpl.java:94) at org.tensorflow.lite.Interpreter.run(Interpreter.java:77) at com.example.appleleafdiseasedetection.DiseaseDetector$2.onClick(DiseaseDetector.java:72) at android.view.View.performClick(View.java:7743) at android.view.View.performClickInternal(View.java:7720) at android.view.View.access$3700(View.java:854) at android.view.View$PerformClick.run(View.java:29111) at android.os.Handler.handleCallback(Handler.java:938) at android.os.Handler.dispatchMessage(Handler.java:99) at android.os.Looper.loopOnce(Looper.java:210) at android.os.Looper.loop(Looper.java:299) at android.app.ActivityThread.main(ActivityThread.java:8309) at java.lang.reflect.Method.invoke(Native Method) at com.android.internal.os.RuntimeInit$M)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,khirmansaleem,"Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context->paddings, 0) != op_context->dims (4 != 1) Node number 0 (PAD) failed to prepare.","I have converted my DenseNet121 model to model.tflite and when i am loading it to android app and trying to make predictions, it's giving following errors : java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context>paddings, 0) != op_context>dims (4 != 1) Node number 0 (PAD) failed to prepare. at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method) at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensorsIfNeeded(NativeInterpreterWrapper.java:308) at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:248) at org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs(InterpreterImpl.java:101) at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:77) at org.tensorflow.lite.InterpreterImpl.run(InterpreterImpl.java:94) at org.tensorflow.lite.Interpreter.run(Interpreter.java:77) at com.example.appleleafdiseasedetection.DiseaseDetector$2.onClick(DiseaseDetector.java:72) at android.view.View.performClick(View.java:7743) at android.view.View.performClickInternal(View.java:7720) at android.view.View.access$3700(View.java:854) at android.view.View$PerformClick.run(View.java:29111) at android.os.Handler.handleCallback(Handler.java:938) at android.os.Handler.dispatchMessage(Handler.java:99) at android.os.Looper.loopOnce(Looper.java:210) at android.os.Looper.loop(Looper.java:299) at android.app.ActivityThread.main(ActivityThread.java:8309) at java.lang.reflect.Method.invoke(Native Method) at com.android.internal.os.RuntimeInit$M",2023-06-12T18:07:28Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60846,"Hi   can you please mention the input and output details of the model ? As mentioned here, please check your input shapes if your model can handle multiple inputs. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1225,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite: On device Training Fails. ERROR: Node number 69 (FlexReluGrad) failed to prepare.)， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu, 22.04  TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): r2.12 **Provide the text output from tflite_convert** I used On device training guide to convert to tflite model and then stored it as model.tflite Then I used this c++ code to invoke the ""train"" signature Runner and it fails. **Standalone code to reproduce the issue**   I get this output  , after compiling the file using CMakeLists.txt inside the /lite/examples/minimal/ directory and running the executable  I did refer to https://www.tensorflow.org/lite/guide/ops_select and I tried building the flex delegate library using   This runs for a long time, and suddenly the terminal gets killed after finishing like 70%.  Can someone suggest a way to include the flex delegate library using some hacks in CMakeLists.txt or any other alterative way)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Bhuvan-1,TFLite: On device Training Fails. ERROR: Node number 69 (FlexReluGrad) failed to prepare.,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu, 22.04  TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): r2.12 **Provide the text output from tflite_convert** I used On device training guide to convert to tflite model and then stored it as model.tflite Then I used this c++ code to invoke the ""train"" signature Runner and it fails. **Standalone code to reproduce the issue**   I get this output  , after compiling the file using CMakeLists.txt inside the /lite/examples/minimal/ directory and running the executable  I did refer to https://www.tensorflow.org/lite/guide/ops_select and I tried building the flex delegate library using   This runs for a long time, and suddenly the terminal gets killed after finishing like 70%.  Can someone suggest a way to include the flex delegate library using some hacks in CMakeLists.txt or any other alterative way",2023-06-12T17:55:05Z,stat:awaiting response stale comp:lite comp:lite-flex TF 2.12,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60845,Hi 1  To use the `select_ops` we require to build the flex delegate using bazel as mentioned and also recommended. I have tried it in Mac M1 and I was successfully able to be build the flex delegate. Please find the screenshot.  Can you try this steps for CMake and see if it works for you?," , The issue in my pc is that, when I try to build the library it runs for some time, and the terminal gets killed suddenly, probably due to Out Of Memory killer. So problem is with my pc ig. Where can I find a prebuilt library?",Hi 1 The pre built for binaries for different tools are available here but for flex delegate we may have to build on our own or try the 3rd party pre built binaries.  Check this prebuilt library and see if it works for your case. Thanks.,It gives me this error while linking I copied the library to /usr/local/lib  and the command used to compile is  **g++ example.cpp ltensorflowlite_flex** /usr/bin/ld: skipping incompatible /usr/local/lib/libtensorflowlite_flex.so when searching for ltensorflowlite_flex /usr/bin/ld: cannot find ltensorflowlite_flex: No such file or directory /usr/bin/ld: skipping incompatible /usr/local/lib/libtensorflowlite_flex.so when searching for ltensorflowlite_flex collect2: error: ld returned 1 exit status `,Hi 1  We need to link the `tensorflowlite_flex` in CMakeLists.txt and update the path to the `.so` file Sample code snippet  Thanks.,"I tried the above way, and got this usr/bin/ld: /mnt/c/Users/G BHUVAN REDDY/Desktop/TFL/LIBS/libtensorflowlite_flex.so: error adding symbols: file in wrong format collect2: error: ld returned 1 exit status make[2]: *** [CMakeFiles/demo.dir/build.make:166: demo] Error 1 make[1]: *** [CMakeFiles/Makefile2:1389: CMakeFiles/demo.dir/all] Error 2 make: *** [Makefile:130: all] Error 2","Hi 1, it looks like you are using WSL or WSL 2. Since it seems like your .so file is in the Windows File system and not the linux one. Generally unless something specifically tells you to you should never cross file system boundaries (In this case it seems cmake is trying to read in the mounted windows directory. Can you put the .so file in /usr/lib or where ever your other .so files are? Update your CMakeLists.txt to point to location as well. It might be helpful to upload your CMakeLists.txt file as well. Additionally please always let us know if you are using WSL/WSL 2 in the issue description as well. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,1 have you worked on model merger? i mean after on device you are saving model.ckpt. how you merging tflite model with model.ckpt for inference? ,"ankit , model.ckpt  only has the weights stored. So to use them, we need to use the `restore` function to restore the weights from model.ckpt into memory . Then we can run inference using the updated weights."
2065,"以下是一个github上的tensorflow下的一个issue, 标题是(java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context->paddings, 0) != op_context->dims (4 != 1) Node number 0 (PAD) failed to prepare.)， 内容是 (I have converted my DenseNet121 model to model.tflite and when i am loading it to android app and trying to make predictions, it's giving following errors :                                                                                                                                                                                  java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context>paddings, 0) != op_context>dims (4 != 1) Node number 0 (PAD) failed to prepare. 	at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method) 	at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensorsIfNeeded(NativeInterpreterWrapper.java:308) 	at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:248) 	at org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs(InterpreterImpl.java:101) 	at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:77) 	at org.tensorflow.lite.InterpreterImpl.run(InterpreterImpl.java:94) 	at org.tensorflow.lite.Interpreter.run(Interpreter.java:77) 	at com.example.appleleafdiseasedetection.DiseaseDetector$2.onClick(DiseaseDetector.java:72) 	at android.view.View.performClick(View.java:7743) 	at android.view.View.performClickInternal(View.java:7720) 	at android.view.View.access$3700(View.java:854) 	at android.view.View$PerformClick.run(View.java:29111) 	at android.os.Handler.handleCallback(Handler.java:938) 	at android.os.Handler.dispatchMessage(Handler.java:99) 	at android.os.Looper.loopOnce(Looper.java:210) 	a)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,khirmansaleem,"java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context->paddings, 0) != op_context->dims (4 != 1) Node number 0 (PAD) failed to prepare.","I have converted my DenseNet121 model to model.tflite and when i am loading it to android app and trying to make predictions, it's giving following errors :                                                                                                                                                                                  java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/pad.cc:79 SizeOfDimension(op_context>paddings, 0) != op_context>dims (4 != 1) Node number 0 (PAD) failed to prepare. 	at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors(Native Method) 	at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensorsIfNeeded(NativeInterpreterWrapper.java:308) 	at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:248) 	at org.tensorflow.lite.InterpreterImpl.runForMultipleInputsOutputs(InterpreterImpl.java:101) 	at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:77) 	at org.tensorflow.lite.InterpreterImpl.run(InterpreterImpl.java:94) 	at org.tensorflow.lite.Interpreter.run(Interpreter.java:77) 	at com.example.appleleafdiseasedetection.DiseaseDetector$2.onClick(DiseaseDetector.java:72) 	at android.view.View.performClick(View.java:7743) 	at android.view.View.performClickInternal(View.java:7720) 	at android.view.View.access$3700(View.java:854) 	at android.view.View$PerformClick.run(View.java:29111) 	at android.os.Handler.handleCallback(Handler.java:938) 	at android.os.Handler.dispatchMessage(Handler.java:99) 	at android.os.Looper.loopOnce(Looper.java:210) 	a",2023-06-12T17:34:44Z,type:support stale comp:lite TFLiteConverter,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60844,", Could you please provide the complete code or the colab gist and the tensorflow version you are using to reproduce the issue which helps us to analyse the issue in an effective way.  It looks like you have provided the dynamic tensors to the tflite. Could you please try to provide with **batch size = 1** and run the `interpreter` for every image in a loop. If the loaded model in TFLite does not have any defined **batch size**, converter will take the batch size as 1, and when you evaluate it with the different batch size, you are likely to end up with the problem which you are facing. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Closing this as stale. Please reopen if this is still a valid request. Thank you!,Are you satisfied with the resolution of your issue? Yes No
924,"以下是一个github上的tensorflow下的一个issue, 标题是(Image Segmenter | tflite-suuport | AttributeError: type object 'SegmentationOptions' has no attribute 'OutputType')， 内容是 (Click to expand!    Issue Type Documentation Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tflitesupport 0.1.0a1  Custom Code No  OS Platform and Distribution MacOS Ventura 13.4  Mobile device _No response_  Python version 3.8.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The syntax provided for using Image Segmenter  did not execute  in python environment.  Possible Fix: The line    should have been    Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,VIS-WA,Image Segmenter | tflite-suuport | AttributeError: type object 'SegmentationOptions' has no attribute 'OutputType',Click to expand!    Issue Type Documentation Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tflitesupport 0.1.0a1  Custom Code No  OS Platform and Distribution MacOS Ventura 13.4  Mobile device _No response_  Python version 3.8.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The syntax provided for using Image Segmenter  did not execute  in python environment.  Possible Fix: The line    should have been    Standalone code to reproduce the issue   Relevant log output  ,2023-06-12T06:50:40Z,type:docs-bug awaiting review stat:awaiting tensorflower type:bug comp:lite,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60836,"It seems the task module is not currently exposed in the package, I'm guessing by mistake, this is blocking testing of this.   wangg can you take a look?",Are you satisfied with the resolution of your issue? Yes No
1983,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow r2.13 build from source: cudnn_frontend_Operation.h:413:16: error: enumeration value ‘CUDNN_POINTWISE_RECIPROCAL’ not handled in switch [-Werror=switch])， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version r2.13  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 6.2.1  GCC/Compiler version 11.3.0  CUDA/cuDNN version 12.1/8.9.2.26  GPU model and memory NVIDIA GeForce 940MX  Current Behaviour? I was trying to build Tensorflow from source (branch r2.13). During the build the following error happend which halted the build execution: ERROR: /home/vyepishov/Documents/dev/git/tensorflow/tensorflow/compiler/xla/stream_executor/cuda/BUILD:377:11: Compiling tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc MD MF bazelout/k8opt/bin/tensorflow/compiler/xla/stream_executor/cuda/_objs/cudnn_plugin/cuda_dnn.pic.d ... (remaining 142 arguments skipped) In file included from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Operation.h:37,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_OperationGraph.h:36,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Heuristics.h:31,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_fronten)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,spamming4,Tensorflow r2.13 build from source: cudnn_frontend_Operation.h:413:16: error: enumeration value ‘CUDNN_POINTWISE_RECIPROCAL’ not handled in switch [-Werror=switch],"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version r2.13  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 6.2.1  GCC/Compiler version 11.3.0  CUDA/cuDNN version 12.1/8.9.2.26  GPU model and memory NVIDIA GeForce 940MX  Current Behaviour? I was trying to build Tensorflow from source (branch r2.13). During the build the following error happend which halted the build execution: ERROR: /home/vyepishov/Documents/dev/git/tensorflow/tensorflow/compiler/xla/stream_executor/cuda/BUILD:377:11: Compiling tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc MD MF bazelout/k8opt/bin/tensorflow/compiler/xla/stream_executor/cuda/_objs/cudnn_plugin/cuda_dnn.pic.d ... (remaining 142 arguments skipped) In file included from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Operation.h:37,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_OperationGraph.h:36,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Heuristics.h:31,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_fronten",2023-06-10T16:21:06Z,stat:awaiting response type:bug type:build/install stale TF 2.13,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60832,"Hi  , The issue might be due to the cuDNN version. TF2.13 tested on cuDNN 8.6 and CUDA 11.8. I am attaching a reference ticket CC(bazel compile error: enumeration value ‘CUDNN_POINTWISE_RECIPROCAL’ not handled in switch) of similar problem and where user able to get it resolved downgrading to cuDNN 8.6 version. Please refer to official tested build configurations.  Please also make a note that starting from Tf21.3 TF builds uses Clang 16.0 as compiler instead of GCC.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1292,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow lite selective build results _ZN6google8protobuf8internal26fixed_address_empty_stringE"" error, build fails with tne --config=monolithic setup, returning the Check failed: existing == nullptr (Tensor already registered) errror)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.13  Custom Code No  OS Platform and Distribution Ubuntu 22.04 lts, Ubuntu 23.04  Mobile device _No response_  Python version _No response_  Bazel version 6.1.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I tried to create the selective build of the tensorflow lite, following this guide.  The build succeeded and I added the tensorflowliteselecttfops.aar to the android studio project, yet it resulted in an error:  I noticed, there are fixes for this problem, e.g. here  one needs just add following line:   to the .bazelrc file.  But build with this configuration fails with the following error:   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,dachshund-ncu,"Tensorflow lite selective build results _ZN6google8protobuf8internal26fixed_address_empty_stringE"" error, build fails with tne --config=monolithic setup, returning the Check failed: existing == nullptr (Tensor already registered) errror","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.13  Custom Code No  OS Platform and Distribution Ubuntu 22.04 lts, Ubuntu 23.04  Mobile device _No response_  Python version _No response_  Bazel version 6.1.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I tried to create the selective build of the tensorflow lite, following this guide.  The build succeeded and I added the tensorflowliteselecttfops.aar to the android studio project, yet it resulted in an error:  I noticed, there are fixes for this problem, e.g. here  one needs just add following line:   to the .bazelrc file.  But build with this configuration fails with the following error:   Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-10T10:08:54Z,stat:awaiting tensorflower type:bug type:build/install comp:lite TF 2.13,closed,0,30,https://github.com/tensorflow/tensorflow/issues/60831,"Hi ncu, which way are you building? With Docker/ w/o Docker? Please provide exact steps so that we can reproduce your issue. This includes commands prior to docker commands, docker commands (if applicable), commands within the docker (if applicable).","Hi , the build steps are presented below:  Prepare docker envirnoment: 1. Download a docker file from here. 2. Edit the dockerfile:      change the lines:         From                  To          3. Build docker envirnoment:      4. Run docker:       Inside docker envirnoment: 1. Install android tools:      2. Clone tensorflow repository      3. Change working directory to the tensorflow repo      4. Checkout to the 2.13 release tag:      5. Add one line to the .bazelrc file:      6. Configure:           Inside the configure:                                                                7. Contents of the :      8. Build command          Note, that  and  are the tflite models, placed in the docker  directory. 9. Output message     ","Hi ncu, Thanks for providing detailed reproducing steps, this helps a lot! Following your instructions with some modifications I was able to build the tflite aar, however I see you are using a command that is dependent your tflite models. This will probably allow you to continue with a bigger aar file, I can't reproduce your issue with your specific tflite model as I don't have access to those models. To build the ""fatter"" aar, install your android tools as stated in the documentation:  Your version is probably fine if you do it line by line, but when I pasted it all it seemed to say No to the license. When building the aar, just for arm64v8a:  Let me know if this works for you. Please close if this is sufficient for you. If you need help w/ the specific model cases, please upload the additional models or at least a minimally reproducible toy model that reproduces the issue.","Hello, thank for your response! Unfortunately, the provided solution produces message:  Unfortunately I cannot share the input models, but I asked for some dummy models that utilize the same operatos. It results in the same error as stated above. You can find it attached to this message Thank you for support! model_small.tflite.zip","Hi ncu, can you provide me the exact steps that led to the above error message? I am unsure what you mean by ""the provided solution"". i.e. I'm trying to answer did it fail on the build step? were you able to build the aar successfully or did it fail after you integrated it? I'll try to build the aar w/ your dummy models.","Hi ncu, with your toy model I was able to build fine if I **don't** include this step:  do you absolutely need this configuration?","> Hi ncu, can you provide me the exact steps that led to the above error message? I am unsure what you mean by ""the provided solution"". i.e. I'm trying to answer did it fail on the build step? were you able to build the aar successfully or did it fail after you integrated it? I'll try to build the aar w/ your dummy models. Steps are exactly the same, as before, but instead of using  script I executed the build command, provided few messages prior:  It results in output:  And no .aar file is produced > Hi ncu, with your toy model I was able to build fine if I **don't** include this step: >  >  >  > do you absolutely need this configuration? Reason for adding config=monolithic to the .bazelrc file is to avoid other error:  during running the android project.  This appeared to fix this issue for some other users (see here and here and here ), yet fails to build in my case.","Hi ncu, there seems to be an issue with that command that doesn't output the aar... I was able to get the output if I made the aar really fat as in the documentation:  Can you try that and use that aar for now while I investigate the other part?","Hi , command provided from documentation:  produces only the  file, but not the ",Hi  I was wondering if my issue is still under consideration by you.,"Hi ncu, I'm still looking at it but was having an internal docker issue which I just resolved, I'll let you know when I have more information. Thanks.","I tried not editing the dockerfile but I'm running into the same issue:  Seems like the combination of the workaround  + your model is failing the build Hi , can you please take a look? Thanks.","I have the same problem. Had to add the workaround for tensorflow 2.13.0 but them i have this build error.  I had previously built an .aar that worked in tensorflow 2.9.3, but I am being asked to update the dependencies.","Hi ncu, can you provide for me reproducible steps for the root cause of the issue? > java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZN6google8protobuf8internal26fixed_address_empty_stringE"" referenced by ""/data/app/~~PgTBlp4bIwZ8yl02UBjqqg==/com.inseye.core.testyoruTyRORPvs5Ap3TE6dGw==/base.apk!/lib/x86_64/libtensorflowlite_flex_jni.so"". We shouldn't really rely on workarounds longterm and it seems like we fixed the ""official way"" before so let's try to actually fix the root cause here.","Dear , I provide the steps to reproduce this bug below  Prepare docker envirnoment: 1. Download a docker file from here. 2. Edit the dockerfile:      change the lines:         From                  To          3. Build docker envirnoment:      4. Run docker:       Inside docker envirnoment: 1. Install android tools:      2. Clone tensorflow repository      3. Change working directory to the tensorflow repo      4. Checkout to the 2.13 release tag:      5. Configure:           Inside the configure:                                                                6. Build command          Note, that  and  are the tflite models, placed in the docker  directory. I also attach the dummy model that contains the operators used. model_small.tflite.zip","Hi ncu, I was able to integrate the aar's into my default empty Android project fine (""Hello Android!""). I'm not really using any functionality though so maybe that's why I'm not running into the issue... how are you integrating the aar's into your project? and how are you using that functionality that is causing the error?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi  , the test is to run single inference through the network and then then the exception occurs `java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZN6google8protobuf8internal26fixed_address_empty_stringE"" referenced by ""/data/app/~~PgTBlp4bIwZ8yl02UBjqqg==/com.inseye.core.testyoruTyRORPvs5Ap3TE6dGw==/base.apk!/lib/x86_64/libtensorflowlite_flex_jni.so"". `","Hi , there's still a lot of missing context, can you please show me the Android Studio code? a full project export from a toy version (that just loads and runs inference) would be the easiest to share.","Dear , you'll find a dummy android studio project attached. You'll only need to change one line in inseye_tracker_core/build.gradle From  to  and run  from  in java>com.inseye.core (androidTest) dummy_tracker_core.zip","Hi ncu, thanks for the info it helps. , I was able to replicate with with ncu's project, I also rebuilt the aar using the official instructions: ",Any update on this issue? Ive ran into a similar error when building tensorflow select ops via docker on branch r2.13 on my model. ncu did you manage to find a workaround for your problem?,"Hi , can you please try with r2.15 or nightly. Also can you please share your reproduce steps the same way as above so that will give us more data to potentially solve the issue if it's the same issue. Thanks for your help.","> Hi , can you please try with r2.15 or nightly. Also can you please share your reproduce steps the same way as above so that will give us more data to potentially solve the issue if it's the same issue. Thanks for your help. Hi, thanks for responding. I will give r2.15 a try and let you know. Meanwhile, I downgraded to r2.9 and followed the official instructions using docker and I managed to build successfully. I didn't even need the config=monolithic as I didn't run into the _ZN6google8protobuf8internal26fixed_address_empty_stringE error. "," I'm providing my reproduce steps on r2.13 to get to the above issue. 1. Downloaded the official Docker file from here and put it into an empty directory. 2. Followed the official documentation and built the image:  docker build . t tflitebuilder f tfliteandroid.Dockerfile 3. Ran the container: docker run it v $PWD:/host_dir tflitebuilder bash 4. Inside the container, ran the following commands: sdkmanager \   ""buildtools;${ANDROID_BUILD_TOOLS_VERSION}"" \   ""platformtools"" \   ""platforms;android${ANDROID_API_LEVEL}""  5. Cloned tensorflow r2.13 branch with depth of 1: git clone https://github.com/tensorflow/tensorflow.git branch r2.13 depth 1 6. Changed working directory to the tensorflow repo: cd tensorflow 7. Executed configure file: python configure.py 8. Answered the questions like this: Please specify the location of python. [Default is /usr/bin/python3]: /usr/bin/python3 Please input the desired Python library path to use.  Default is [/usr/lib/python3/distpackages]: /usr/lib/python3/distpackages Do you wish to build TensorFlow with ROCm support? [y/N]: N Do you wish to build TensorFlow with CUDA support? [y/N]: N Do you wish to download a fresh release of clang? (Experimental) [y/N]: N Please specify optimization flags to use during compilation when bazel option ""config=opt"" is specified [Default is Wnosigncompare]: Wnosigncompare Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y 9. Finally, executed the build command: bash tensorflow/lite/tools/build_aar.sh \   input_models=path/to/models \   target_archs=arm64v8a,armeabiv7a Just like above, if I execute the build command without the monolitic option, I get the _ZN6google8protobuf8internal26fixed_address_empty_stringE error, and when I do insert the monolitic option in .bazelrc file with echo n ""build config=monolithic"" >> .bazelrc command, my build fails with Check failed: existing == nullptr (Tensor already registered) error.","I am encountering a similar error with 2.13 Anyone knows if 2.15 solves the error? Do you need  `echo n ""build config=monolithic"" >> .bazelrc`  command for 2.15?","> I am encountering a similar error with 2.13 >  > Anyone knows if 2.15 solves the error? Do you need >  > `echo n ""build config=monolithic"" >> .bazelrc` >  > command for 2.15? I tried with 2.15, same error is coming.",   Can you please help with possible debug options as this error is a major blocker in my project,"Hi, ncu  Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/167 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1111,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot pick GPU unavailable)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows 10 build 19045  0  Mobile device _No response_  Python version Python 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version Cuda compilation tools, release 12.1, V12.1.105 Build cuda_12.1.r12.1/compiler.32688072_0  GPU model and memory 1070 TI 8g   Current Behaviour? A bug happened! `  gpus = tf.config.experimental.list_physical_devices('GPU')` _This piece of code return empty array_ When in reallity have two GTX 1070  Description                  : NVIDIA GeForce GTX 1070 Ti x 2 at least hoped to get one I'm follow all installation step by step  verifying paths  I don't know what to do anymore  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Cazs03,Cannot pick GPU unavailable,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows 10 build 19045  0  Mobile device _No response_  Python version Python 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version Cuda compilation tools, release 12.1, V12.1.105 Build cuda_12.1.r12.1/compiler.32688072_0  GPU model and memory 1070 TI 8g   Current Behaviour? A bug happened! `  gpus = tf.config.experimental.list_physical_devices('GPU')` _This piece of code return empty array_ When in reallity have two GTX 1070  Description                  : NVIDIA GeForce GTX 1070 Ti x 2 at least hoped to get one I'm follow all installation step by step  verifying paths  I don't know what to do anymore  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-10T10:07:20Z,type:bug type:build/install comp:gpu TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60830,", If you are getting the empty list for the **gpus = tf.config.experimental.list_physical_devices('GPU')**, means the GPU installation was not happened correctly in your system. Could you please confirm whether you are trying to install the tf v2.12 on windows from pip or the build from source. Also please provide the complete error log and the steps you followed to install. It helps us to debug the issue in an effective way. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Sorry for delay. example snippet:  pip install tensorflow From https://developer.nvidia.com/cudadownloads Last version for windows And read and follow: https://www.tensorflow.org/install/gpu?hl=es419,My path: _C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1\bin; C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.1\libnvvp; C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common; C:\Program Files\NVIDIA Corporation\Nsight Compute 2023.1.1\; C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR; C:\cuda\bin_ EDIT: I have tried different versions of python different environments with conda Some concrete version of packages makes the difference I give up,Are you satisfied with the resolution of your issue? Yes No
1369,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to run RNN Model)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution WSL2 on Windows 11  Mobile device _No response_  Python version 3.8.12  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.2/8.1.0  GPU model and memory NVIDIA Quadro P4200, 16gb  Current Behaviour? After setting up the system to use gpu from WSL2 on windows 11, I am able to connect to GPU. But when I run  a tensorflow model, I am able to run CNN model on GPU but when i try to run RNN model I get the below mentioned message and the model does not run: ""W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at partitioned_function_ops.cc:115 : INVALID_ARGUMENT: No OpKernel was registered to support Op 'CudnnRNN' used by {{node CudnnRNN}} with these attrs: [seed=0, dropout=0, T=DT_FLOAT, input_mode=""linear_input"", direction=""unidirectional"", rnn_mode=""lstm"", seed2=0, is_training=true] Registered devices: [CPU, GPU] Registered kernels:    	 [[CudnnRNN]]""  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,abhinavchawla7,Unable to run RNN Model,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution WSL2 on Windows 11  Mobile device _No response_  Python version 3.8.12  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.2/8.1.0  GPU model and memory NVIDIA Quadro P4200, 16gb  Current Behaviour? After setting up the system to use gpu from WSL2 on windows 11, I am able to connect to GPU. But when I run  a tensorflow model, I am able to run CNN model on GPU but when i try to run RNN model I get the below mentioned message and the model does not run: ""W tensorflow/core/framework/op_kernel.cc:1780] OP_REQUIRES failed at partitioned_function_ops.cc:115 : INVALID_ARGUMENT: No OpKernel was registered to support Op 'CudnnRNN' used by {{node CudnnRNN}} with these attrs: [seed=0, dropout=0, T=DT_FLOAT, input_mode=""linear_input"", direction=""unidirectional"", rnn_mode=""lstm"", seed2=0, is_training=true] Registered devices: [CPU, GPU] Registered kernels:    	 [[CudnnRNN]]""  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-09T12:01:54Z,stat:awaiting tensorflower type:bug type:build/install comp:apis wsl2 TF 2.10,open,0,5,https://github.com/tensorflow/tensorflow/issues/60826,", TensorFlow 2.10 was the last TensorFlow release that supported GPUs on nativeWindows. Could you please provide any specific reason you are using WSL2 for 2.10, you can directly install the v2.12 on nativeWindows which was supported.  does the tf.test.is_gpu_available return False? If that's the case, then it definitely means the GPU is not configured correctly. Also, the error message somehow indicating that the GPU device is not there: Registered devices: [CPU,XLA_CPU,XLA_GPU] XLA_GPU is not same as GPU. May I know have you tried to execute the same code with the CPU only if yes is it working fine with the CPU ? If not please try it to run on either with CPU only or on Google Colab and check whether it is working as expected or not ? Thank you!","I am on windows 11 and i have installed CUDA on native windows.  As per the link: https://www.tensorflow.org/install/pipwindowsnative, it is said that TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2, or install tensorflow or tensorflowcpu and, optionally, try the TensorFlowDirectMLPlugin. so when i install tensorflow >2.10.* i am unable to see the gpu on wsl2.....and on installing directmlplugin i am unable to run RNN model only CNN model works.....I have NVIDIA 16gb GPU (8gb dedicated) and 32GB CPU.....RNN model works fiine with CPU but kernel crashes on GPU....while CNN works easily on both ",Awaiting for reply,Still no reply,"Sorry, I don't think I can help much here.  Assigning this one back to you . "
1098,"以下是一个github上的tensorflow下的一个issue, 标题是(What phone support tensorflow lite GPU delegate?)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Android 13  Mobile device Android 13  Python version 3.8.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I tested multiple mobile phones (including Xiaomi 12s Ultra, OnePlus 8, Honor Nova 10, Oppo Reno 9) using the example Android apk at https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android . On all of the devices, the app tells ""GPU is not supported"", but NNAPI and CPU is OK. Anything I can do to enable the GPU delegate on these Qualcomm Snapdragon devices?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ldfandian,What phone support tensorflow lite GPU delegate?,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Android 13  Mobile device Android 13  Python version 3.8.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I tested multiple mobile phones (including Xiaomi 12s Ultra, OnePlus 8, Honor Nova 10, Oppo Reno 9) using the example Android apk at https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android . On all of the devices, the app tells ""GPU is not supported"", but NNAPI and CPU is OK. Anything I can do to enable the GPU delegate on these Qualcomm Snapdragon devices?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-09T08:28:44Z,stat:awaiting response type:support stale comp:lite TFLiteGpuDelegate TF 2.12,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60825,Hi   Can you please add the following to the Android manifest in order to detect GPU delegate.  Thanks.,"> Hi  >  > Can you please add the following to the Android manifest in order to detect GPU delegate. >  >  >  > Thanks. Thanks for the quick response. I tried to add the following code in AndroidManifest.xml, but it does not work.  Btw, on the Xiaomi 12s Ultra, I checked that the file ""/system/vendor/lib64/libOpenCL.so"" does exist. However, it looks like it does not show in the ""/system/etc/public.libraries.txt"". Maybe it is the cause? Meaning that the mobile vendor blocks the GPU delegate? The content of ""/system/etc/public.libraries.txt"" and ""/etc/public.libraries.txt"" is like:  The content of ""/vendor/etc/public.libraries.txt"" and ""/system/vendor/etc/public.libraries.txt"" is like:  Here is the logcat info: ","An update, after adding those useslibrary/usesnativelibrary settings in AndroidManifest.xml, OnePlus 8T works but the other three devices still don't work... I compared the their content of /system/etc/public.libraries.txt, but find nothing different among these devices. What's the magic here?","Hi , Have you tried using our acceleration service to see which configuration might be optimal for each of your phones? https://www.tensorflow.org/lite/android/acceleration_service Have you checked the documentation here: https://www.tensorflow.org/lite/android/delegates/gpu_native ? Also for more information, are you using an emulator or the actual phones?","> Hi , >  > Have you tried using our acceleration service to see which configuration might be optimal for each of your phones? https://www.tensorflow.org/lite/android/acceleration_service >  > Have you checked the documentation here: https://www.tensorflow.org/lite/android/delegates/gpu_native ? >  > Also for more information, are you using an emulator or the actual phones? Thanks for the advice. Good to know it, but my phone does not have a Google play service installed~","No worries,  did the documentation help at all? Additionally please let us know if you are using emulators or actual phones or some combination of them. Thanks.","> No worries,  did the documentation help at all? Additionally please let us know if you are using emulators or actual phones or some combination of them. Thanks. All of these (Xiaomi 12s Ultra, OnePlus 8, Honor Nova 10, Oppo Reno 9) are real phones sold in China.","Hi , can you please take a look?",Triage to  . Could you help on this? Thanks!,"Hi , looking at the GPU's used in these devices (Adreno 730, Adreno 642L) we have full support. I was able to confirm this via the following commands: `bazel build c opt config=android_arm64 copt=DCL_DELEGATE_NO_GL third_party/tensorflow/lite/tools/benchmark:benchmark_model ` `adb push blazebin/third_party/tensorflow/lite/tools/benchmark/benchmark_model /data/local/tmp` `adb push test.tflite /data/local/tmp` `adb shell /data/local/tmp/benchmark_model use_gpu=true graph=/data/local/tmp/test.tflite` This way we can confirm whether your issue is confined to TFL code or something broader. Please run the above code & let me know how it goes, thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Actually, I have similar issue too. I cannot do GPU prediction on Phone.  Tensorflow : 2.9 Androind : 13 Phone  Samsung A73 5G I am getting this flag as False compatList.isDelegateSupportedOnThisDevice: false","Given TF Lite has been reimagined into LiteRT, how does this change things with the emulator and with hardware phones?  I have only seen the necessity for these libraries (e.g. `libOpenCL.so`) to be included in the manifest mentioned in the mediapipe documentation, and even then, for one use case.  I cannot find any reference to them in the litert samples."
1922,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite Android GPU delgate cannot run: TfLiteGpuDelegate Init: STRIDED_SLICE: Output batch don't match)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Android  Mobile device Android 13  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to run a modified resnet50 (as follows) on Android platform using TFLite GPU Delegate, I already replaced unsupported GATHER ops with STRIDED_SLICE ops. It works fine on my Linux server, Android CPU mode but not able to run on Adroid GPU delegate. As https://www.tensorflow.org/lite/performance/gpu said, STRIDED_SLICE should be a supported ops on GPU delegate... Anything can shed some lights on what I can do here? !image == Analyzer said: Your model looks compatible with GPU delegate with TFLite runtime version 2.12.0. But it doesn't guarantee that your model works well with GPU delegate. There could be some runtime incompatibililty happen.  Your TFLite model has '1' signature_def(s). == 22:25:53.970  W  Accessing hidden field Ljava/lang/Throwable;>detailMessage:Ljava/lang/String; (unsupported, reflection, allowed) 22:25:53.971  E  java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: STRIDED_SLICE: Output batch don't match                  TfLiteGpuDelegate Prepare: delegate is not initialized                  Node number 409 (TfLiteGpuDelegateV2) failed to prepare.                  Restored original execution plan after delegate application failure. 22:25:53.971  E  	at)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ldfandian,TFLite Android GPU delgate cannot run: TfLiteGpuDelegate Init: STRIDED_SLICE: Output batch don't match,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Android  Mobile device Android 13  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to run a modified resnet50 (as follows) on Android platform using TFLite GPU Delegate, I already replaced unsupported GATHER ops with STRIDED_SLICE ops. It works fine on my Linux server, Android CPU mode but not able to run on Adroid GPU delegate. As https://www.tensorflow.org/lite/performance/gpu said, STRIDED_SLICE should be a supported ops on GPU delegate... Anything can shed some lights on what I can do here? !image == Analyzer said: Your model looks compatible with GPU delegate with TFLite runtime version 2.12.0. But it doesn't guarantee that your model works well with GPU delegate. There could be some runtime incompatibililty happen.  Your TFLite model has '1' signature_def(s). == 22:25:53.970  W  Accessing hidden field Ljava/lang/Throwable;>detailMessage:Ljava/lang/String; (unsupported, reflection, allowed) 22:25:53.971  E  java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: STRIDED_SLICE: Output batch don't match                  TfLiteGpuDelegate Prepare: delegate is not initialized                  Node number 409 (TfLiteGpuDelegateV2) failed to prepare.                  Restored original execution plan after delegate application failure. 22:25:53.971  E  	at",2023-06-08T14:54:37Z,stat:awaiting response type:bug stale comp:lite TFLiteGpuDelegate TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60817,Hi   Can you please try in TF Nightly and let us know if you are still facing the issue? `implementation 'org.tensorflow:tensorflowlite*:0.0.0nightlySNAPSHOT'` Thanks.,"> Hi  >  > Can you please try in TF Nightly and let us know if you are still facing the issue? >  > `implementation 'org.tensorflow:tensorflowlite*:0.0.0nightlySNAPSHOT'` >  > Thanks. OK. I will try it. After some tuning on the ops, now STRIDED_SLICE op is not complained any more. But I get a new error message like this. What does it mean?  the related node is like: ","Hi   As suggested here, the whole path with SHAPE >STRIDED_SLICE > PACK is a static thing you can replace with a static tensor to support GPU delegate. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1173,"以下是一个github上的tensorflow下的一个issue, 标题是(GPU Delegate dynamic tensor input shape (Feature Request))， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution Android  Mobile device Android  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello, I'm writing you to ask, are there plans to implement dynamic input shape in gpu delegate in near future ?  Right now dynamic input shape working fine on cpu, but on gpu delegate I'm getting the issue  `java.lang.IllegalArgumentException: Internal error: Error applying delegate: ` This is very important feature, if this feature already exist and it is possible somehow to rung with dynamic shape will be good to have some information in documentation.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,OleksandrGrument,GPU Delegate dynamic tensor input shape (Feature Request),"Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution Android  Mobile device Android  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello, I'm writing you to ask, are there plans to implement dynamic input shape in gpu delegate in near future ?  Right now dynamic input shape working fine on cpu, but on gpu delegate I'm getting the issue  `java.lang.IllegalArgumentException: Internal error: Error applying delegate: ` This is very important feature, if this feature already exist and it is possible somehow to rung with dynamic shape will be good to have some information in documentation.   Standalone code to reproduce the issue   Relevant log output  ",2023-06-08T12:25:39Z,type:feature comp:lite TFLiteGpuDelegate TF 2.12,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60814,"Hi , in order to keep TFLite light, we have to compromise on some design choices such as dynamic input shapes. Currently we do not plan to implement this feature in the near future. Apologies we can't help you here soon."
1361,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.keras.Model.predict passing x=tf.keras.utils.Sequence causing exceptions  ValueError: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  will cause exceptions  The codes works well back in tf 2.4.0 and should still be working per release notes and the latest documentations. the `test_generator` is a subclass of `tf.keras.utils.Sequence` which works normally in tf 2.4.0 The return format for `__getitem__` is a tuple with a List element that indicate multiple inputs of the model  For an example, see below !image !image !image I assume some behavors behind the `predict` interface are changed after the 2.4.0 to 2.12.0 upgrades. Any idea how to fix it? Thx in advance.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Yuanjimengmengda,"tf.keras.Model.predict passing x=tf.keras.utils.Sequence causing exceptions  ValueError: Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  will cause exceptions  The codes works well back in tf 2.4.0 and should still be working per release notes and the latest documentations. the `test_generator` is a subclass of `tf.keras.utils.Sequence` which works normally in tf 2.4.0 The return format for `__getitem__` is a tuple with a List element that indicate multiple inputs of the model  For an example, see below !image !image !image I assume some behavors behind the `predict` interface are changed after the 2.4.0 to 2.12.0 upgrades. Any idea how to fix it? Thx in advance.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-08T10:16:56Z,stat:awaiting tensorflower type:bug comp:keras TF 2.12,open,0,4,https://github.com/tensorflow/tensorflow/issues/60813,"Hi  , As per documentation of model.predict the argument 'x' can be: `A generator or keras.utils.Sequence returning (inputs, targets) or (inputs, targets, sample_weights)` The generator should confirms the above behaviour. Can you please cross check whether the generator you are testing confirms the same. Also unfortunately I am unable to find reproducible code snippet. Please submit the same for looking into the issue. Thanks!","> Hi  , >  > As per documentation of model.predict the argument 'x' can be: >  > `A generator or keras.utils.Sequence returning (inputs, targets) or (inputs, targets, sample_weights)` >  > The generator should confirms the above behaviour. Can you please cross check whether the generator you are testing confirms the same. >  > Also unfortunately I am unable to find reproducible code snippet. Please submit the same for looking into the issue. >  > Thanks! Hi , Thx for your reply. I updated the test codes with a sample triggers the error. I can confirm the generator is legitmate as I have been using it for years on tf==2.4.0. Moreover, on tf==2.12.0, the generator works well in `model.fit` if a `y` is specified(I'm adding this to the sample codes so you could make sure the generator is legitmate). I also tried the same code on version tf==2.11.1, no exceptions occurred. Therefore, I think the problem lies in the changes between 2.11.1 and 2.12.0. Thanks.","Hi  , It seems with the updated code I can able to replicate the error. The code fails with TF2.12v and success with TF2.11 version. Attached gist for reference. We need to dig more further for commenting on this issue. Thanks!",The same problem exists in tfnightly  also.
999,"以下是一个github上的tensorflow下的一个issue, 标题是(Ragged String Input not working with GPU  - > non-DMA-copy attempted of tensor type: string)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution linux  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? consider this trivial tf.keras Model:   passing a ragged tensor will fail :  with ""nonDMAcopy attempted of tensor type: string"" whereas this works just fine  I am aware that there are many related issue open / i hope the small selfcontained example above is useful  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,citizenkeynes,Ragged String Input not working with GPU  - > non-DMA-copy attempted of tensor type: string,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution linux  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? consider this trivial tf.keras Model:   passing a ragged tensor will fail :  with ""nonDMAcopy attempted of tensor type: string"" whereas this works just fine  I am aware that there are many related issue open / i hope the small selfcontained example above is useful  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-08T09:26:02Z,stat:awaiting response type:bug stale comp:ops TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60812,", Basically, RaggedTensorVariant objects should never be copied to GPU, because we can't do anything useful with them there. But Placer isn't currently smart enough to figure that out (it just sees a Variant tensor, and doesn't know what kind of value it contains).  https://github.com/kerasteam/tfkeras/issues/128 https://github.com/kerasteam/tfkeras/issues/638 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1930,"以下是一个github上的tensorflow下的一个issue, 标题是( TensorFlow device (GPU:0) is being mapped to multiple devices when using tf.estimator api and set visible_device_list with hvd.local_rank())， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf 2.11  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04.1  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 12.0  GPU model and memory _No response_  Current Behaviour? I know there is a same issue, https://github.com/tensorflow/tensorflow/issues/58952, but it has been closed. The model implemented with tf.estimator api. horovod multicards job (horovodrun np 2 python xxx.py). it works well using 2.10, but throws Device mapping error when using TF2.11. FROM issue58952, It seems that this error is relative to this commit%3A). When calling context.is_cutom_device(), this API would create TFE_Context that would create TF devices. However, program would also create TF devices when create Session with the aboved mentioned config, and these two TF device creation would conflicts. It seems that the session_options used in the ensure_initialized function to create NewContext are inconsistent with the options used by the NewSession. The options used by NewSession are explicitly set through tf.ConfigProto.gpu_options.visible_device_list=hvd.localrank(). session_config should be at least consistent, or loaded once at most To reproduce this error, you need to install horovod and using multi card machine to run below code with: horovodrun np N python xxx.py where N denotes the number of processes to be started.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,mmseerrttt, TensorFlow device (GPU:0) is being mapped to multiple devices when using tf.estimator api and set visible_device_list with hvd.local_rank(),"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf 2.11  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04.1  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 12.0  GPU model and memory _No response_  Current Behaviour? I know there is a same issue, https://github.com/tensorflow/tensorflow/issues/58952, but it has been closed. The model implemented with tf.estimator api. horovod multicards job (horovodrun np 2 python xxx.py). it works well using 2.10, but throws Device mapping error when using TF2.11. FROM issue58952, It seems that this error is relative to this commit%3A). When calling context.is_cutom_device(), this API would create TFE_Context that would create TF devices. However, program would also create TF devices when create Session with the aboved mentioned config, and these two TF device creation would conflicts. It seems that the session_options used in the ensure_initialized function to create NewContext are inconsistent with the options used by the NewSession. The options used by NewSession are explicitly set through tf.ConfigProto.gpu_options.visible_device_list=hvd.localrank(). session_config should be at least consistent, or loaded once at most To reproduce this error, you need to install horovod and using multi card machine to run below code with: horovodrun np N python xxx.py where N denotes the number of processes to be started.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-08T02:39:01Z,stat:awaiting response type:bug comp:gpu TF 2.11,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60810,"Hi  , It seems you are using TF1.x related code which is not supported now. I have gone through the horovod documentation and found below notes.  Also Estimator API is deprecated now.Please refer below note for same. Warning: Estimators are not recommended for new code. Estimators run v1.Sessionstyle code which is more difficult to write correctly, and can behave unexpectedly, especially when combined with TF 2 code. Estimators do fall under our compatibility guarantees, but will receive no fixes other than security vulnerabilities. See the migration guide for details.",Are you satisfied with the resolution of your issue? Yes No
1868,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow freezes during training on Mac Studio)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf2.9  Custom Code No  OS Platform and Distribution MacOS Ventura 13.4/13.1  Mobile device Mac Studio  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Apple M1  Current Behaviour? When training a model on my Mac Studio, from time to time it seems that the training freezes, and an epoch takes much more time than usual, from x10 to x200. I have tried contacting Apple's support, and they are clueless about this phenomena. I also went through recent Mac related issues in this repository and found nothing relevant. Here is an example of the phenomena as seen in the training's output:   Standalone code to reproduce the issue  (Thank ChatGPT for the minimal working example) shell Metal device set to: Apple M1 Ultra systemMemory: 128.00 GB maxCacheSize: 48.00 GB 20230607 13:46:01.901374: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 20230607 13:46:01.901665: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) > physical PluggableDevice (device: 0, name: METAL, pci bus id: ) 20230607 13:46:01.992101: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz Epoch 1/1000 20230607 13:46:02.108687: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",chat,hovavalon,Tensorflow freezes during training on Mac Studio,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf2.9  Custom Code No  OS Platform and Distribution MacOS Ventura 13.4/13.1  Mobile device Mac Studio  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Apple M1  Current Behaviour? When training a model on my Mac Studio, from time to time it seems that the training freezes, and an epoch takes much more time than usual, from x10 to x200. I have tried contacting Apple's support, and they are clueless about this phenomena. I also went through recent Mac related issues in this repository and found nothing relevant. Here is an example of the phenomena as seen in the training's output:   Standalone code to reproduce the issue  (Thank ChatGPT for the minimal working example) shell Metal device set to: Apple M1 Ultra systemMemory: 128.00 GB maxCacheSize: 48.00 GB 20230607 13:46:01.901374: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support. 20230607 13:46:01.901665: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) > physical PluggableDevice (device: 0, name: METAL, pci bus id: ) 20230607 13:46:01.992101: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz Epoch 1/1000 20230607 13:46:02.108687: ",2023-06-07T10:47:45Z,stat:awaiting response type:bug stale subtype:macOS TF 2.9,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60800,"Try to update TensorFlow version with ""pip install upgrade tensorflow""","I did, and the problem still appears with tensorflow `2.12`.","Hi  , It seems the issue is Mac specific and Mac M1 related issues has to be addressed in the Apple metal plugin forum. But I observed earlier there is some issues related to the optimizer. Can you please replace the optimizer with legacy optimizer as below and test it with TF2.9, TF2.11, TF2.12 and let us know the outcome. `opt = tf.keras.optimizers.legacy.SGD()`","Hi , I am already using the legacy optimizer, at some point I got an error recommending that I do so."," , I tried to replicate the issue on Mac with tfnightly(2.14.0dev20230515) with `epochs=100` with the same test code you provided and its running fine.Please refer to logs below.   Can you try with latest nightly version and please confirm the behaviour. Also please confirm you have followed the Apple metal plugin instructions correctly.Please confirm you have installed tensorflowmetal and try retesting the code in a Fresh environment. Thanks!",I have followed the instructions given in the link when installing the application. Even on my computer 100 short epochs are not necessarily enough to replicate (even though at some times it is enough). ,"Hi  , Thanks for confirmation. I tried with 1000 epohs and executed 3 times successfully without the reported behaviour.Please refer to attached logs below.  CC(Tensorflow freezes during training on Mac Studio)_logs.txt Could you try with fresh environment and with tfnightly version. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1592,"以下是一个github上的tensorflow下的一个issue, 标题是(RuntimeError during 16x8 quantization in TFLite converter - ""Max and min for dynamic tensors should be recorded during calibration"")， 内容是 ( 1. System information  **OS Platform and Distribution**: *Ubuntu 22.04.1 LTS*  **TensorFlow installation**: *pip install tensorflow*  **TensorFlow library**: *tensorflow                    2.12.0* *tensorflowcpu                2.12.0* *tensorflowestimator          2.12.0* *tensorflowiogcsfilesystem  0.23.1* *tensorflowmodeloptimization 0.7.5*  2. Code Here is the Python script that can reproduce the issue:  The script defines a custom layer (CircularBufferLayer) and model (StreamingModel), uses the model on dummy data, and then attempts to quantize and convert the model into a TFLite model. The error seems to be related to the lack of dynamic range data for a particular tensor.  3. Failure after conversion The conversion process fails with a `RuntimeError: Max and min for dynamic tensors should be recorded during calibration`. The error specifically highlights the tensor `streaming_model/circular_buffer_layer/Minimum`. Here is the full traceback:   4. (optional) RNN conversion support Not applicable.  5. (optional) Any other info / logs I have attempted to use the `converter.experimental_enable_resource_variables = True` and `converter.allow_custom_ops = True` options in the TFLite converter to allow handling of the custom layer, but the issue persists.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,danielr55,"RuntimeError during 16x8 quantization in TFLite converter - ""Max and min for dynamic tensors should be recorded during calibration"""," 1. System information  **OS Platform and Distribution**: *Ubuntu 22.04.1 LTS*  **TensorFlow installation**: *pip install tensorflow*  **TensorFlow library**: *tensorflow                    2.12.0* *tensorflowcpu                2.12.0* *tensorflowestimator          2.12.0* *tensorflowiogcsfilesystem  0.23.1* *tensorflowmodeloptimization 0.7.5*  2. Code Here is the Python script that can reproduce the issue:  The script defines a custom layer (CircularBufferLayer) and model (StreamingModel), uses the model on dummy data, and then attempts to quantize and convert the model into a TFLite model. The error seems to be related to the lack of dynamic range data for a particular tensor.  3. Failure after conversion The conversion process fails with a `RuntimeError: Max and min for dynamic tensors should be recorded during calibration`. The error specifically highlights the tensor `streaming_model/circular_buffer_layer/Minimum`. Here is the full traceback:   4. (optional) RNN conversion support Not applicable.  5. (optional) Any other info / logs I have attempted to use the `converter.experimental_enable_resource_variables = True` and `converter.allow_custom_ops = True` options in the TFLite converter to allow handling of the custom layer, but the issue persists.",2023-06-07T10:18:58Z,stat:awaiting tensorflower type:bug comp:lite comp:runtime TFLiteConverter ModelOptimizationToolkit TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60799,Hi   I was able to reproduce this issue. Please find the gist here. Seems like int16x8 support is not available for `tf.minimum` builtin op which might be causing the issue. You can try `tf.lite.OpsSet.TFLITE_BUILTINS_INT8` if it works for your case. Thanks.,"Thanks for your response, . In line with your comment, I've reworked the `CircularBufferLayer` to avoid using the `tf.minimum` operation. However, when I attempted to convert the `StreamingModel`, I encountered this error: `RuntimeError: Max and min for dynamic tensors should be recorded during calibration: Failed for tensor streaming_model_3/circular_buffer_layer_3/add Empty min/max for tensor streaming_model_3/circular_buffer_layer_3/add` It seems strange to me that even the `tf.add` builtin operation is not supported by the tflite converter. Could it be possible that I'm incorrectly implementing the `CircularBufferLayer`? I'd appreciate your insight. Thanks!  Here's the revised implementation for the `CircularBufferLayer`: ","Hi , currently this looks like a bug with the new experimental feature. My current guess is that it is somehow not calibrating on the representative data set correctly for this type of conversion. , can you please take a look? I am able to replicate on tfnightly w/ the following script (model save path modified): Also as a gist ","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/168 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1272,"以下是一个github上的tensorflow下的一个issue, 标题是(Error building Tensorflow from source on Windows with /MT)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.9.3  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version 3.10  Bazel version 5.4  GCC/Compiler version MSVC (Visual Studio 2022)  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to build Tensorflow from source with flag /MT (I require this so that the tensorflow.dll does not require the vcruntime libraries on startup). I tried this command: bazel build tensorflow:tensorflow.dll copt=/MT But i got errors: c1xx: fatal error C1083: Cannot open source file: 'C:/Program\': No such file or directory MT c1xx: fatal error C1083: Cannot open source file: 'Files/Git/MT': No such file or directory (I run this in Git Bash). It seems, like something is wrong with spaces in path. But i builded tensorflow successfully without /MT flag.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,frodyan,Error building Tensorflow from source on Windows with /MT,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.9.3  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version 3.10  Bazel version 5.4  GCC/Compiler version MSVC (Visual Studio 2022)  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to build Tensorflow from source with flag /MT (I require this so that the tensorflow.dll does not require the vcruntime libraries on startup). I tried this command: bazel build tensorflow:tensorflow.dll copt=/MT But i got errors: c1xx: fatal error C1083: Cannot open source file: 'C:/Program\': No such file or directory MT c1xx: fatal error C1083: Cannot open source file: 'Files/Git/MT': No such file or directory (I run this in Git Bash). It seems, like something is wrong with spaces in path. But i builded tensorflow successfully without /MT flag.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-07T09:16:18Z,type:build/install type:performance TF 2.9,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60798,can you show the Error?,"Hi , please follow the steps mentioned in https://www.tensorflow.org/install/source_windows. I ran the build on my end and didn't get the above error.",", Could you please follow the steps mentioned on the official website of Tensorflow to build Tensorflow from source. Tensorflow suggests install all the prerequisite packages to avoid errors. Thank you!","Ok, I fixed the errors as follows: instead of using the copt flag, I added the following lines to the .bazelrc file:  I also replaced MD with MT in all .bzl and .bzl.tpl files. But the /MD flag still appears in the generated .params files. How can I build a library with the /MT flag? (Build is successful, but DLL still requires vcruntime libraries).",I rechecked. The /MT flag I added appears in the .params files after the /MD flag. The compiler issues a message that the /MT flag overrides /MD (Command line warning D9025 : overriding '/MD' with '/MT'). But still the DLL requires the vcruntime library to run.,"In order for the DLL to not require the vcruntime library to run, you also need to remove the `/DEFAULTLIB:msvcrt.lib` line from the tensorflow.dll2.params file before linking.",Are you satisfied with the resolution of your issue? Yes No
1849,"以下是一个github上的tensorflow下的一个issue, 标题是(could not run GPU on jupyter )， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I could not get Tensorflow to run on GPUs. TF sees the GPUs on terminal, but not on jupyter lab. **Edited** Found a solution to see it on jupyterlab, but must manually repeat . Still, erratic misconfiguration seems to happen.  Standalone code to reproduce the issue  NB : If I was to set   as in `https://www.tensorflow.org/install/pip` Somehow it messy with jupyter, bcause the selected kernel from jupyter would not correspond to the kernel set from the script. Now I can see the GPUs on jupyter, but still  it crashes! And before, on CPU, it was not. When I run this script, using this library : https://pypi.org/project/umaplearn/ installed as in the description:  the code fails with the log output below. If I close the jupyter lab connection, go back on the conda environment,  set again:  I and   And relaunch jupterlab, this time I get the GPU seen also in jupyter lab. Running   It yields  And cannot understand why it raise warning or error with `CPU` device, if I run on `GPU`.  Not even sure it falled back to CPU, actually.  Please advice how to sync jupter lab and conda. I did follow up with `ikernel` but it seems, after a lot of checking, that environment variables are not correctly read. Not sure if `kernel.json` fai)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,gg4u,could not run GPU on jupyter ,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I could not get Tensorflow to run on GPUs. TF sees the GPUs on terminal, but not on jupyter lab. **Edited** Found a solution to see it on jupyterlab, but must manually repeat . Still, erratic misconfiguration seems to happen.  Standalone code to reproduce the issue  NB : If I was to set   as in `https://www.tensorflow.org/install/pip` Somehow it messy with jupyter, bcause the selected kernel from jupyter would not correspond to the kernel set from the script. Now I can see the GPUs on jupyter, but still  it crashes! And before, on CPU, it was not. When I run this script, using this library : https://pypi.org/project/umaplearn/ installed as in the description:  the code fails with the log output below. If I close the jupyter lab connection, go back on the conda environment,  set again:  I and   And relaunch jupterlab, this time I get the GPU seen also in jupyter lab. Running   It yields  And cannot understand why it raise warning or error with `CPU` device, if I run on `GPU`.  Not even sure it falled back to CPU, actually.  Please advice how to sync jupter lab and conda. I did follow up with `ikernel` but it seems, after a lot of checking, that environment variables are not correctly read. Not sure if `kernel.json` fai",2023-06-06T20:06:53Z,type:bug type:feature comp:gpu TF 2.12,open,0,11,https://github.com/tensorflow/tensorflow/issues/60790,ther could be few reasons but the main is to Ensure that GPU drivers are installed und make sur you have the appropriate GPU drivers on your system.,"Hi  , Could you please confirm the OS you are using. Could you please confirm whether GPU drivers and nvidia toolkit installed and path variables set properly ? Refer to the documentation source here and confirm this was followed. Please share the output of `nvidiasmi` command and `python3 c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""` from Jupyter.  The error seems to be related to CUDA path setting. Can you try fresh installation of conda environment on Jupyter notebook and let us know the outcome.","OS => I don't know, I am using a university cluster, it must be linux but i don't know which. Note that I was eventually able to run on jupyter as well, but only if : I reset :  and  and when I launch jupyter lab, it must be launched from the same conda environment I reset  up those script. Kernel selection won't work anyway (in other words, I must launch jupyter lab from the same conda environment I intend to use the kernel, otherwise environment variables makes confusion and on jupyter Cuda won't be found). nvidiasmi:  From jupyter:  > Can you try fresh installation of conda environment on Jupyter notebook and let us know the outcome. I did it all yesterday, I spent a whole day, and did so many times. I won't touch again the installation. But to reproduce, I did the following:  create a conda env (as per instruction) and CUDA drivers  installed ikernel (to select the kernel in jupyter)  on terminal, TF read the GPU => OK!  on jupyter lab, I could select a different kernel, BUT inspecting on `!conda info` and `!which  python` it was keep referring to the base from where jupyter was launched, and that I pervously set the environment variables automatically (see ' script' below from https://www.tensorflow.org/install/pip).  It was messy to debug, because there were conflicts on `libdevice` in jupter, but not in terminal; probably because the environment variable instructing on the cuda libraries could not be found. Maybe some issues with `ikernel`  I don't have clue only guessing. I eventually got it to work without automating the variables :  but setting them manually, and then only launch the jupter lab from the conda environemnt corresponding to the kernel I will work with.",The attached commands from Documentation should fix system paths to be automatically configured when you activate the conda environment. I hope once you have created the conda environment and followed all the steps mentioned in documentation including the commands for Automatic enabling of system paths every time conda environment activated should fix the issue. This should be one time exercise only and then it should work every time when activated the respective conda environment.,"Unfortunately not, I see a mismatch between the conda or python (`which python`) listed in the jupyter notebook, and the selected kernel. Awkwardly, I was able to get TF see the GPUs on Jupyter, only if I created a virtual environment in python (`python m venv ./env`), and then tried to install cuda drivers from conda , but all other libraries via pip. However, there are always challenges, because, for example, some libraries, like ones using `cudf`, will fail (I ve just discovered that with aweful regret).  IT would be highly beneficial, in my opinion, if you could add a guide to install jupyter lab with multiple kernels, so to minismize error for users approaching TF on rermote cloud for first time. Assume people using remote servers. At my university, the help desk even asked me if it was necessary to use jupyter or conda virtual environment (which I actually would be .. knida necessary) to minimise error, and just keep one base  the default. But I am afraid that if I messy up something, I m kinda done.","What challenges are you facing with ? For resolving dependency issues with TF installed in a conda environment you can try creating a new environment with an earlier version of Python () or using tools like Libmamba (see https://www.anaconda.com/blog/afastercondaforagrowingcommunity/). Also, try running  or  from root outside of any virtual environment. Knowing more about your OS is crucial to determining whether this is a CUDA path issue."," , Could you please provide the OS details also.Thanks!","Hi , You might need to use  `conda install nb_conda_kernels` and may be also `conda install ipykernel` additionally for Jupyter. Could you please follow the instructions mentioned here at SO1 and SO2 and let us know it works.","Hi  this is an issue with using Jupyter Notebook itself. You can take a look at this issue on why jupyter doesn't call GPU and follow the work around. As for the documentation, tensorflow doesn't officially support Jupyter notebooks and I don't think this will be documented anywhere officially. Thanks!!","Hi, thanks for the support.  I can't summarize exactly what causes are responsible of the issues, I think the problem is conflicting environment variables. I had this constrains:  using a university cluster, the university discouraging in using conda env, just installed on the dedicated env  tensorflow encorages in using conda  external libraries complained if on conda (installs with pip conflicted). I temporarilly have resolved in creating a pip envionrment, and launching jupyter lab from there. Jupyter sees the GPUs, while if it was launched from conda, then TF was not seeing the GPU. Pytorch saw the GPUs on both. I followed : https://stackoverflow.com/questions/76101948/tensorflowgpurecognizedintheterminalbutnotinthejupyternotebook but for some reasons, `which python` on jupyter opened in a chosen  enviroment, was anyway pointing to the environment from where jupyter lab server was launched.","Hi , Unfortunately there is not much that can be done about this from our end. Please follow the process as mentioned above and this issue should be resolved."
1055,"以下是一个github上的tensorflow下的一个issue, 标题是(ELU int8 model quantized with Dequantize/Quantize stubs)， 内容是 (**System information**  Linux Ubuntu 20.04  TensorFlow installed from: docker `tensorflow/tensorflow:latestgpu`  TensorFlow version (or github SHA if from source): 2.12.0 **Standalone code to reproduce the issue**  Input model (Netron): !image  Output Model (Netron): !image **Any other info / logs** I understand that ELU isn't among the supported operators (?) although there's allegedly some code (?) from this commit.  I wonder why no exception is raised during the process despite `supported_ops` being set to the most strict options, and why does it default to this mixedprecision output model (if I am not mistaken, the elu is still run in floating point).   To be clear, the behavior I would expect is either an error or a fullint8 quantized model with no stubs layers wrapping ELU.  Thanks for your help!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,NickLucche,ELU int8 model quantized with Dequantize/Quantize stubs,"**System information**  Linux Ubuntu 20.04  TensorFlow installed from: docker `tensorflow/tensorflow:latestgpu`  TensorFlow version (or github SHA if from source): 2.12.0 **Standalone code to reproduce the issue**  Input model (Netron): !image  Output Model (Netron): !image **Any other info / logs** I understand that ELU isn't among the supported operators (?) although there's allegedly some code (?) from this commit.  I wonder why no exception is raised during the process despite `supported_ops` being set to the most strict options, and why does it default to this mixedprecision output model (if I am not mistaken, the elu is still run in floating point).   To be clear, the behavior I would expect is either an error or a fullint8 quantized model with no stubs layers wrapping ELU.  Thanks for your help!",2023-06-06T12:34:05Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60789,Hi   Thanks for reporting this issue.  I was able to reproduce this issue. Please find the gist here. Could you please look into this if this is intended behaviour? Thanks.,"Hi , thanks for reporting the issue. The documentation https://www.tensorflow.org/lite/performance/post_training_quantizationinteger_only suggests it should throw an error than a forced conversion. We will work on this as a bug.",thank you!,"Hi , can you please take a look? Thanks.","Hi , Your observation is right. ELU is not a natively supported activation function in Tensorflow Lite by default . The model converts the rest layers into INT8 leaving the  ELU as it is instead of throwing exception. As of now ELU is not having quantizable trait. The PR is created for the same.  Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
585,"以下是一个github上的tensorflow下的一个issue, 标题是('fashion_mnist' failed to load on TPU (try_gcs=True not working)!)， 内容是 (I am trying to replicate TensorFlow `autoencoder` (Source: Second example: Image denoising)  image cleaning example on TPU (in google colab).  Code :    Error   This code works fine with MNIST dataset but shows following error on Fashion MNIST. I think this might be the problem with `try_gcs` argument in tensorflow_datasets.load . )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MegaCreater,'fashion_mnist' failed to load on TPU (try_gcs=True not working)!,I am trying to replicate TensorFlow `autoencoder` (Source: Second example: Image denoising)  image cleaning example on TPU (in google colab).  Code :    Error   This code works fine with MNIST dataset but shows following error on Fashion MNIST. I think this might be the problem with `try_gcs` argument in tensorflow_datasets.load . ,2023-06-06T11:18:55Z,stat:awaiting response type:bug stale comp:tpus TF 2.12,closed,0,12,https://github.com/tensorflow/tensorflow/issues/60788,"Hi   Based on the error message you provided earlier, it seems that the issue is not related to the specific dataset being used (MNIST vs Fashion MNIST), but rather with how the data is being accessed from the TPU. The error message “File system scheme ‘[local]’ not implemented” suggests that the code is trying to access a local file system, but this is not supported by the TPU. TPUs are designed to work with cloud storage services such as Google Cloud Storage (GCS), and cannot directly access data stored on the local file system of the machine running the code. ""If you are using TPU Nodes, you need to store all data files read by the TensorFlow Dataset in Google Cloud Storage (GCS) buckets. If you are using TPU VMs, you can store data wherever you like. For more information on TPU Nodes and TPU VMs, refer to the TPU System Architecture documentation."" You can create a TPU VM, but it is not for free. You can use it by following this tutorial: “https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/experimental/mnist_jupyter/CloudTPUDemo.ipynb”. If you try changing the runtime to GPU, it should work correctly. One other approach you can try is to access data stored in a Google Cloud Storage bucket using Colab. Here is a link :""https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/keras_mnist_tpu.ipynb""",", It looks like model_dir is set to a local directory in /tmp/, can you double check to make sure that it is a path to a GCS bucket? It could be possible that it's creating a directory within data_dir which is a GCS path. Both data_dir and model_dir should be set to GCS buckets. You would need to have your data stored inside a GCS bucket and the Cloud TPUs should have access to that. Also  can you simply look up the IP address of your VM (something like **!curl ifconfig.me** in your Colab cell) and then look up which geolocation that IP belongs to."," it's dataset related only ....    ""https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/keras_mnist_tpu.ipynb"" this example is not useful because my code works fine on 'minst' dataset. "," are you talking about something like this ?   How can I access  ""gs://yourbucket/data"" ? I mean how can I get my bucket address ? (what will be the ""gs://yourbucket/"" ?)"," , You can access a bucket in the Cloud Dataprep UI by manually entering the Google Cloud Storage path.  https://cloud.google.com/storage/docs/accesspublicdata https://cloud.google.com/storage/docs/cloudconsole Thank you!"," its not working. I don't have cloud storage. And cloud bucket. I don't have any paid or pro access to google cloud. I am not using any cloud VM. I am using google colab TPU. So, how can I do all things in colab TPU environment? ","Hi   The very first answer mentions that the error is due to TPUs being able to pull data only from GCS.  Indeed `mnist` dataset exists in `gs://tfdsdata/datasets/mnist/` and hence everything works, but `fashion_mnist` is unfortunately not available through public TFDS GCS. You should create your own GCS bucket and store `fashion_mnist` there and then pull it using `tfds.load(data_dir=)`. ", I am using **colab (Colab's TPU)**. Can I use Google drive as cloud space ? ," , Yes you can mount your Google Drive and import the data.  ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1212,"以下是一个github上的tensorflow下的一个issue, 标题是(About nn.Linear convert to tflite model)， 内容是 ( 1. System information Linux Ubuntu 18.04 Tensorflow 2.8.0  2. Code I have a transformer model with **pytorch**, and I use **onnx_tf** to change` .onnx` to` .pb`, then change` .pb` to` .tflite`. The` .pb ` to` .tflite` code is:  Then I use **Netron** to check the tfilte model `qat_noquant_int8.tflite`, and I find the **nn.Linear** (which in **ONNX** is **MatMul**) in tflite model is disassembled into three operators: **spillfullyconnectedpack**, I dont know why and I don't want it to be dismantled.  Another question is there is a **DIV** operator in my model, I find that when tflite is quantized, it will automatically add a **Dequantize** before the **DIV** operator. This **Dequantize** is not in my code. I don't know why tflite will add **Dequantize** by itself, and I don't want it to be added. How should I modify the conversion tflite and statically quantize the code? Thank you very much!! The **MatMul** in onnx is  !onnx_image The **MatMu**l in tflite is: !tflite_image)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,puyiwen,About nn.Linear convert to tflite model," 1. System information Linux Ubuntu 18.04 Tensorflow 2.8.0  2. Code I have a transformer model with **pytorch**, and I use **onnx_tf** to change` .onnx` to` .pb`, then change` .pb` to` .tflite`. The` .pb ` to` .tflite` code is:  Then I use **Netron** to check the tfilte model `qat_noquant_int8.tflite`, and I find the **nn.Linear** (which in **ONNX** is **MatMul**) in tflite model is disassembled into three operators: **spillfullyconnectedpack**, I dont know why and I don't want it to be dismantled.  Another question is there is a **DIV** operator in my model, I find that when tflite is quantized, it will automatically add a **Dequantize** before the **DIV** operator. This **Dequantize** is not in my code. I don't know why tflite will add **Dequantize** by itself, and I don't want it to be added. How should I modify the conversion tflite and statically quantize the code? Thank you very much!! The **MatMul** in onnx is  !onnx_image The **MatMu**l in tflite is: !tflite_image",2023-06-05T07:35:22Z,stat:awaiting response stale comp:lite TFLiteConverter TF 2.8,closed,0,9,https://github.com/tensorflow/tensorflow/issues/60780,Hi   Could you please share a toy tflite model or code to reproduce the issue?  Thanks.,"> Hi  >  > Could you please share a toy tflite model or code to reproduce the issue? >  > Thanks. OK, there is my tflite model. qat_noquant_int8.zip and there is my onnx model  checkpoint_best.zip","Hi   Thanks for sharing. I have observed that Batch MatMul operation is being converted into into Split  multi FullyConnected  Pack.  TFlite converts model ops into simple supported operations that can be run in memory constrained devices like Edge devices  and micro controllers.  If you are facing any issue regarding quantization or want to disable quantization for any node , you can refer Quantization Debugger and do Selective Quantization. Thanks.",> 你好 >  > 感谢分享。 >  > 我观察到 Batch MatMul 操作正在转换为 Split  multi FullyConnected  Pack。 >  > TFlite 将模型操作转换为简单的支持操作，这些操作可以在边缘设备和微控制器等内存受限设备中运行。 >  > 如果您遇到有关量化的任何问题或想要禁用任何节点的量化，您可以参考量化调试器并执行选择性量化。 >  > 谢谢。 Thank you for your reply. The MatMul  operator is 'nn.Linear' in Pytorch. I am wondering why **nn.Linear** is **Batch MatMul** in tflite. How can I convert the Batch MatMul to norm MatMul? Can you help me?,Hi   The model can be analyzed using Model Analyzer API and it can be observed that multiple MatMul operations are generated. Please find the gist here. The TFlite converts model ops into  supported operations  that are natively supported by TensorFlow Lite. Is there any challenge in using the current conversion  in your use case? Thanks.,"> Hi  >  > The model can be analyzed using Model Analyzer API and it can be observed that multiple MatMul operations are generated. Please find the gist here. >  > The TFlite converts model ops into supported operations that are natively supported by TensorFlow Lite. >  > Is there any challenge in using the current conversion in your use case? >  > Thanks. This kind of splitting will be very slow in reasoning on my deployment platform, and I wonder if it can be merged. There is another problem. After my model is converted to tflite and statically quantized to in8, the model file size is larger than before it was not quantized. It is now about 5.6M. The file size of the model before quantization (I sent you earlier) It is about 3.6M. I compared the model structure before and after quantization, and tflite will automatically add a DeQuantize in front of the DIV operator, and then quantize it back after passing the DIV. I don't know if this part of the problem caused the model file to become larger after quantization. I don’t want to have this kind of operation. How should I do it? It is my quantized tflite model. qat_quant_static_int8.zip","Hi   Thanks for the information. The converter adds `Quantize` and `DeQuantize` stubs for the ops that do not support int8 quantization, to give floating point view. Also, can you try conversion in latest TFNightly and let us know your observation? The converter adds unfolding matmul operation by default which is disabled in nightly version. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
808,"以下是一个github上的tensorflow下的一个issue, 标题是(Is there a similar approach in TensorFlow2 when save large model?)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  Is there a similar approach in TensorFlow2 when save large model?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,SmileTM,Is there a similar approach in TensorFlow2 when save large model?,Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  Is there a similar approach in TensorFlow2 when save large model?  Standalone code to reproduce the issue   Relevant log output _No response_,2023-06-04T09:13:16Z,stat:awaiting response type:feature type:support TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60776,"You can always save a model before, during, and after training using the same `model.save()` API. Once loading, you can always continue training if you so desire. There is no need for a separate API (`save_pretrained`). Regarding sharding (`max_shard_size`), there is no such parameter, TF does automatic sharding. See https://www.tensorflow.org/api_docs/python/tf/saved_model/save, https://www.tensorflow.org/api_docs/python/tf/saved_model/SaveOptions and https://www.tensorflow.org/api_docs/python/tf/keras/Modelsave","Hi  , Apart from resources mentioned in above, you can also refer to attached tutorial links for end to end examples of creating,training, saving and loading the models. Please refer serialization_and_saving and save_and_load also for a demo. Tensorflow has options to save complete model architecture including optimizer state or only weights of the layers also. If you still looking for a particular use case please let us know. Thanks!",Thanks for the quick response.,Are you satisfied with the resolution of your issue? Yes No
992,"以下是一个github上的tensorflow下的一个issue, 标题是(Problem after installing new version using pip)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11 and 2.12  Custom Code No  OS Platform and Distribution Linux mint 20.1  Mobile device   Python version 3.9  Bazel version   GCC/Compiler version   CUDA/cuDNN version 11.8.0 from anaconda / nvidiacudnncu11==8.6.0.163 (from pip)  GPU model and memory rtx 3070 mobile 8 gb vram, 32 gb ram  Current Behaviour? After installing using this tutorial https://www.tensorflow.org/install/piplinux i can't import tensorflow. Here is an error. !image I've tried with 2.11, 2.12 TF installed using pip.  If I'm trying to install tfnightly, then I've got another error !image  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DaddyWesker,Problem after installing new version using pip,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11 and 2.12  Custom Code No  OS Platform and Distribution Linux mint 20.1  Mobile device   Python version 3.9  Bazel version   GCC/Compiler version   CUDA/cuDNN version 11.8.0 from anaconda / nvidiacudnncu11==8.6.0.163 (from pip)  GPU model and memory rtx 3070 mobile 8 gb vram, 32 gb ram  Current Behaviour? After installing using this tutorial https://www.tensorflow.org/install/piplinux i can't import tensorflow. Here is an error. !image I've tried with 2.11, 2.12 TF installed using pip.  If I'm trying to install tfnightly, then I've got another error !image  Standalone code to reproduce the issue   Relevant log output  ",2023-06-04T08:44:57Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux TF 2.11 TF 2.12 TF 2.13,closed,0,28,https://github.com/tensorflow/tensorflow/issues/60775,Can you run post the output of `python m pip list` and `python c 'import tensorflow'` run from the same environment?,Pip list: !Screenshot from 20230605 083319 import tensorflow: !Screenshot from 20230605 083331, Conda list just in case,"So, this is using latest `tfnightly`. I think there is an actual issue in these builds, but they are offered on a best effort basis, there is a rotation that looks at the build and tries to solve issues such as this before a release. Can you run the same on an environment where you use 2.13.0?","  As i said, I've met this problem using 2.11 and 2.12. Anyway, here is the output of those two commands. I've ran them on tensorflow 2.12 though, not 2.13.0. Pip tells me that there are only 2.13.0rc0, 2.13.0rc1are available. Do you want me to use them? !Screenshot from 20230605 184204 !Screenshot from 20230605 184222","Yes, please try `rc1`. Your initial screenshots were showing nightly, that's why I asked for a released version.","> Your initial screenshots were showing nightly That is because firstly I've tested 2.12 and 2.11, then I've seen that issue template requires testing on tfnightly and installed it instead of regular tf. Anyway, here is the outputs with 2.13.0rc1 !Screenshot from 20230605 190257 !Screenshot from 20230605 190303",The missing symbols is `tensorflow::OpKernel::TraceStringabi:cxx11 const` This makes me think you are combining wheels with the old C++ ABI and with the new one. Can you try recreating an empty environment and installing there?,  That is already recreated environment. I've deleted it and created again. It just has the same name.,Does the issue reproduce if you use `venv` instead of *conda?,Done. Same problem. tf is the venv's name. !Screenshot from 20230607 083302 !Screenshot from 20230607 083308,"There must be something wrong in your environment, as I cannot reproduce:   You do have some packages which don't exist on the fresh environment (`zipp` for example). You have 2 `nvidia*` wheels which also don't exist but could be causing issues. And you have an old version of `setuptools` (try `python m pip install upgrade pip setuptools` and try again?) My experiments are with python3.11.2: ","I've used python 3.9 on conda env, on venv i'm using python 3.8. I've tried what you asked (upgrade setup tools), here are results. !Screenshot from 20230608 080756 !Screenshot from 20230608 080802","And preventing move, I've installed python 3.11 and created venv using it. Same. !Screenshot from 20230608 083012 !Screenshot from 20230608 083908","~~Note that you skipped over the error in activating the virtual environment.~~ Edit: I reread the screenshot. In general, I'd recommend posting code/errors as formatted text, not images. Makes it easier to quote, crossreference, search Coming back to the issue, your last environment seems at a quick glance to be the same as mine. Will probably need to dig deeper into the binary, as it seems to be an issue specifically with your environment","In the last virtualenvironment, if you do `cd tf/lib/python3.11/sitepackages/tensorflow`, what is the output of `nm libtensorflow_cc.so.2  grep _ZNK10tensorflow8OpKernel                  U _ZNK10tensorflow8OpKernel10InputRangeESt17basic_string_viewIcSt11char_traitsIcEEPiS5_                  U _ZNK10tensorflow8OpKernel11TraceStringB5cxx11ERKNS_15OpKernelContextEb 000000000476d340 W _ZNK10tensorflow8OpKernel12const_tensorEv                  U _ZNK10tensorflow8OpKernel16ShapeTraceStringB5cxx11ERKNS_15OpKernelContextE ```",Same  !Screenshot from 20230609 074620,"I think I have an idea on what happens, but just to test, can you try `LD_DEBUG=libs python c ""import tensorflow as tf"" 2>file` and then attach the file? It is a large file, estimated to be several hundreds lines, but should give an idea on what libraries are attempted to be loaded.",Done file.txt,"Hi, I am experiencing the same issue: I am running inside pyenv virtualenv with venv name tensorflow.  Here is my environment:  Machine:  Output of LD_DEBUG=libs python c ""import tensorflow as tf"" 2>file.txt file.txt Hip","Hi, I am experiencing the same issue: I am running inside pyenv virtualenv with venv name tensorflow.  Here is my environment:  Machine:  Output of LD_DEBUG=libs python c ""import tensorflow as tf"" 2>file.txt file.txt Hip Additionally I tested a few other things but with no success: I noticed I had the ubuntu cuda toolkit installed which was 11 but the driver said 12. So I installed the latest 12.2 toolkit, but to no avail. I also Upgraded to a recent mainline kernel version 6.3.13, this also did not help. I am running out of ideas.","Ha, found it. Another installation had `tensorflow_framework.so` put in the library path. To find this take the path after `Import Error:` and put `ldd` in front of it. It will show you the offending library. Remove it in any way you deem appropriate. In my case it was wasmedge which was the culprit.  This is likely a problem with your installation, too. Hih."," Thanks, I will try.","  Okay, so which one of those libs i need to delete exactly?  !image","Hi DaddyWesker,  For me it was libtensorflow_framework. Check if /lib/x86_64linuxgnu/libtensorflow_framework.so.2 exists. Instead of deleting, renaming is better, as you can undo it. hih Johannes Dipl.Ing. (FH) JohannesMaria Frank Master CS UCL Birkbeck 30 Craster Square Newcastle upon Tyne NE3 3PL United Kingdom phone: +447400987848 email: ***@***.*** On Mon, Jul 24, 2023 at 11:19 AM DaddyWesker ***@***.***> wrote: >   > Okay, so which one of those libs i need to delete exactly? > [image: image] >  > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >","Well, for some reason renaming  /lib/libtensorflow_framework.so.2 does made a trick. At least tf is importing now and examples like   works well. I need to check it on some sort of NN. If everything is fine, then I'll close the issue. But still, why this so file is generating then when installing TF at the first place?..","Thanks for debugging the issue! It seems this is a new side effect that arises when you mix global TF installations with installs in a virtual environment. We recommend all TF installs should be done in a venv to prevent these contagions. TF has a large C++ component that needs to be shipped with the wheel in order for users to use it. We could have localized the shared lib (`.so` file) to within the wheel (like smaller `.so`s are), but `libtensorflow_framework` is needed also if you want to do TF from other languages. So, for example, if you want to use TF from, say, Rust, you'd install the wheel, then tell your build process to link against this `.so` (and a few others). There is no standard channel for distributing C++ artifacts, so it was decided to distribute them via the wheel and a GCS bucket. Recently, to reduce the number of builds, the GCS bucket was discontinued, so now users can get the shared objects only via the wheel. Overall, this issue points to a new debugging item for similar issues: we should ask users to confirm whether they have global TF installations or everything is in a venv. ",Are you satisfied with the resolution of your issue? Yes No
1832,"以下是一个github上的tensorflow下的一个issue, 标题是(inconsistent .proto file package names break gRPC message/field parsing in Wireshark)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? As noted in CC(proto files compiled with go: inconsistent package names: tensorflow.grpc tensorflow), there is inconsistency among the package names in the TensorFlow `.proto` files. Searching for `.proto` file package declarations within the codebase reveals a wide variety of package names, including `tensorflow.dummy`. https://github.com/search?q=repo%3Atensorflow%2Ftensorflow+%22package+tensorflow%22&type=code&p=2 This has a problematic effect when trying to parse the Protobuf fields in TensorFlow gRPC messages within the Wireshark network capturing tool. In Wireshark, the builtin parsing functionality requires the package/service names within the `.proto` files to match the package/service names in the captured gRPC messages, so currently, CoordinationService (`package tensorflow`) messages parse properly, while message types and field names in WorkerService (`package tensorflow.grpc`) messages cannot be parsed, and appear as _unknown_. Current workaround: using a script to replace all instances of `""tensorflow.grpc""` with `""tensorflow""` in the `.proto` files.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jrmcclurg,inconsistent .proto file package names break gRPC message/field parsing in Wireshark,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? As noted in CC(proto files compiled with go: inconsistent package names: tensorflow.grpc tensorflow), there is inconsistency among the package names in the TensorFlow `.proto` files. Searching for `.proto` file package declarations within the codebase reveals a wide variety of package names, including `tensorflow.dummy`. https://github.com/search?q=repo%3Atensorflow%2Ftensorflow+%22package+tensorflow%22&type=code&p=2 This has a problematic effect when trying to parse the Protobuf fields in TensorFlow gRPC messages within the Wireshark network capturing tool. In Wireshark, the builtin parsing functionality requires the package/service names within the `.proto` files to match the package/service names in the captured gRPC messages, so currently, CoordinationService (`package tensorflow`) messages parse properly, while message types and field names in WorkerService (`package tensorflow.grpc`) messages cannot be parsed, and appear as _unknown_. Current workaround: using a script to replace all instances of `""tensorflow.grpc""` with `""tensorflow""` in the `.proto` files.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-03T20:22:40Z,stat:awaiting tensorflower type:bug comp:core TF 2.12,open,0,0,https://github.com/tensorflow/tensorflow/issues/60773
1845,"以下是一个github上的tensorflow下的一个issue, 标题是(Inefficient count_nonzero)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The current implementation of `tf.math.count_nonzero` is extremely inefficient, when trying to count how often a boolean condition is true in a large tensor. This is because the operation first converts the boolean tensor into `tf.int64`, before feeding it to `tf.reduce_sum`. As that is an operation that is entirely bandwidthbound, instead of transferring `n` bytes for an input of `n` elements, now it has to transfer `n + 8n` for the cast operation, and an additional `8n` for the reduction, making this 17 times (!!) more inefficient than it needs to be. The benchmark below show the following: 1) Plain `count_nonzero` 2) The same implementation as count_nonzero, except that a superfluous comparison with zero is omitted (which is needed for other data types to convert to bool, but appears to not be optimized away even if the tensor is already of bool type). This gives a small speedup 3) Use `uint32` as accumulation type, instead of `int64`. This shows the tremendous effect of bandwidth. Here are a few suggestions for improvements, in increasing order of difficulty: 1) If the input is already of bool type, there is no need to do `gen_math_ops.not_equal(input, zero)` 2) if the input is of bool type and has less)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ngc92,Inefficient count_nonzero,"Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The current implementation of `tf.math.count_nonzero` is extremely inefficient, when trying to count how often a boolean condition is true in a large tensor. This is because the operation first converts the boolean tensor into `tf.int64`, before feeding it to `tf.reduce_sum`. As that is an operation that is entirely bandwidthbound, instead of transferring `n` bytes for an input of `n` elements, now it has to transfer `n + 8n` for the cast operation, and an additional `8n` for the reduction, making this 17 times (!!) more inefficient than it needs to be. The benchmark below show the following: 1) Plain `count_nonzero` 2) The same implementation as count_nonzero, except that a superfluous comparison with zero is omitted (which is needed for other data types to convert to bool, but appears to not be optimized away even if the tensor is already of bool type). This gives a small speedup 3) Use `uint32` as accumulation type, instead of `int64`. This shows the tremendous effect of bandwidth. Here are a few suggestions for improvements, in increasing order of difficulty: 1) If the input is already of bool type, there is no need to do `gen_math_ops.not_equal(input, zero)` 2) if the input is of bool type and has less",2023-06-03T18:23:30Z,stat:awaiting response stale comp:ops type:performance TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60772,"Hi  , I have replicated the reported behaviour on CPU runtime as per attached cpugist. But with GPU runtime the case is totally different. With `uint32` as dtype actually it is taking much more time than `int64` since some Ops with `unit32` as dtype are not supported on GPU . It seems this API implementation supports  `int64` for best performance. I tried with `int32` also where performance is not good at all compared to `int64` even though all Ops ran on GPU only. I have attached all the results in the attached gpugist. Please go through the results and shave your views. Thanks!","  Thanks for the replication.  First, your results seem to confirm that skipping the redundant comparison with zero leads to a measureable improvement in performance in both cases, so that should be a relatively straightforward improvement. The missing GPU kernels make the other improvements more tricky, though. I've now run the current `count_nonzeros` implementation also on GPU under the tf profiler, with the following results:  As you can see, the conversion to int64 actually takes *more* time than the reduction itself.",", The related PR which was raised for the implementation of the respective issue, has been reviewed and also merged. https://github.com/tensorflow/tensorflow/pull/60782  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1118,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot tune sequential model given get different results for each run)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to tune a sequential model. But if I rerun my tuning code, I get a different result for ""best parameters"" each time. I am not using GPUs. I have seeds set to a constant. My tuning code ran fine under an earlier tf version. But when I updated to latest, it stopped producing replicable results. Did a specific version give up on replicability? Is there a workaround for tuning?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,fickas,Cannot tune sequential model given get different results for each run,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to tune a sequential model. But if I rerun my tuning code, I get a different result for ""best parameters"" each time. I am not using GPUs. I have seeds set to a constant. My tuning code ran fine under an earlier tf version. But when I updated to latest, it stopped producing replicable results. Did a specific version give up on replicability? Is there a workaround for tuning?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-02T17:45:29Z,stat:awaiting response type:bug stale comp:keras TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60768,"It is common for the results of a machine learning model to vary slightly between runs, even when setting random seeds to a constant. While setting random seeds can help control for some sources of randomness and make your results more consistent between runs, it is still possible for the results to vary slightly. This is normal and to be expected. also the weights of a machine learning model will not be exactly the same after each run. The weights are initialized randomly at the beginning of training and are updated during training based on the data and the optimization algorithm used. As a result, the final weights of the model can vary slightly between runs. I can see that the results you got were not changing significantly.  Hopefully this was helpful",", The only sources of randomness in Keras are from Numpy's random module (weight inits) and from Theano (and those are all seeded with Numpy's random), e.g. dropout. Seeding the Numpy RNG should work. Also by default Keras's model.compile() sets the shuffle argument as True. You should the set numpy seed before importing keras. e.g.:  I can see that most of the provided Keras examples follow this pattern. Thank you!","Still a bit concerned about tuning. When I ran simple tuning algorithm on a Sequential model, I came out with different architectures as best on every rerun, i.e., different number of layers and different nodes in each layer. It is kind of hard to average architectures across reruns. My conjecture is this will also affect sklearn tuning algorithms, e.g., RandomSearch and HalvingSearch. They will not produce consistent ""best parameters"" on rerun. I plan to test this out in next couple days. I feel I am missing something because I would expect a hue and cry from the community if tuning libraries stopped working as expected and I have not seen any complaints. Also, it still seems something changed in a version update. As I said, I would get consistent results with early versions of 2, but an update to latest 2 version changed things. I did just try installing v2.8, and I now get consistent results with RandomSearchCV. When I use 2.12, I do not. So it appears something changed between 2.8 and 2.12.",", Thank you for opening this issue. Development of keras moved to another repository.  Could you please post this issue on kerasteam/keras repo. To know more please refer: https://discuss.tensorflow.org/t/kerasprojectmovedtonewrepositoryinhttpsgithubcomkerasteamkeras/1999 Thank you!","Calling tf.keras.utils.set_random_seed sets the Python seed, the NumPy seed, and the TensorFlow seed. Setting these seeds is necessary to ensure any random numbers your program generates are also deterministic. I tried to execute the code with the alternative approach by using tf.keras.utils.set_random_seed, and I was getting the same result while executing the mentioned code. Kindly find the gist of it here. Could you please have a look at this official document for reference. https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1447,"以下是一个github上的tensorflow下的一个issue, 标题是([TFLite] Cannot apply XNNPack delegate to simple model with Dense layer)， 内容是 ( 1. System information  OS Platform and Distribution: macOS ventura 13.2.1 In python, I'm using 2.11, for the c++ side, I used the latest main and followed the instructions to build tensorflow lite with cmake from this commit (f8066222ad6).  2. Code I have a tiny dummy model:  which I'm converting to tflite like so:  before saving. And then on the c++ side I'm trying to apply the xnnpack delegate:  However this fails with `WARNING: Attempting to use a delegate that only supports staticsized tensors with a graph that has dynamicsized tensors (tensor CC(Quantized ops?) is a dynamicsized tensor).`, where `tensor CC(Quantized ops?)` is `model/output/Tensordot/Reshape`. For some reason, that I don't quite understand, this part of the dense layer seems to be flagged as a dynamic tensor. Any idea, what might be the cause here? A bit of context: I'm actually looking into pruning using the PruneForLatencyOnXNNPack approach. I've skipped the training with pruning on this dummy model for now, but I have a more complex model, that I also pruned before conversion and it, too, fails on the dense layer.  As far as I can tell, the Dense layer should be supported, so I'm really confused.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,christian-steinmeyer,[TFLite] Cannot apply XNNPack delegate to simple model with Dense layer," 1. System information  OS Platform and Distribution: macOS ventura 13.2.1 In python, I'm using 2.11, for the c++ side, I used the latest main and followed the instructions to build tensorflow lite with cmake from this commit (f8066222ad6).  2. Code I have a tiny dummy model:  which I'm converting to tflite like so:  before saving. And then on the c++ side I'm trying to apply the xnnpack delegate:  However this fails with `WARNING: Attempting to use a delegate that only supports staticsized tensors with a graph that has dynamicsized tensors (tensor CC(Quantized ops?) is a dynamicsized tensor).`, where `tensor CC(Quantized ops?)` is `model/output/Tensordot/Reshape`. For some reason, that I don't quite understand, this part of the dense layer seems to be flagged as a dynamic tensor. Any idea, what might be the cause here? A bit of context: I'm actually looking into pruning using the PruneForLatencyOnXNNPack approach. I've skipped the training with pruning on this dummy model for now, but I have a more complex model, that I also pruned before conversion and it, too, fails on the dense layer.  As far as I can tell, the Dense layer should be supported, so I'm really confused.",2023-06-02T07:56:08Z,stat:awaiting response comp:lite TFLiteConverter comp:lite-xnnpack TF 2.11,closed,1,7,https://github.com/tensorflow/tensorflow/issues/60762,"if you change `img = tf.keras.layers.Input((40, 320, 1), name='img')` to `img = tf.keras.layers.Input((40, 320, 1), name='img', batch_size=1)`, mostly the issue will be gone. Without fixed batch (`batch_size=1`), there are some other nodes to handle dynamic batch size, some of them may not be delegatable.  To see the nodes I mentioned, check the tflite you have with netron or other visualization tools may help.","Hi steinmeyer  As  suggests, you can specify `batch_size=1` to avoid dynamic tensors. To add more, the `Reshape` operation after conversion is being flagged as dynamic tensor which can be observed in the gist and it is known limitation of XNNPack for not supporting the dynamic tensors. Thanks.","Thanks for getting back to me. That did the trick! In case anyone else comes across this. In order to change the input layer of an existing model, I've ended up using this code: ```py old_input_layer = model.get_layer(index=0) new_input_layer = tf.keras.layers.Input(         batch_size=1,         shape=old_input_layer.input.shape[1:],         dtype=old_input_layer.dtype,         name=old_input_layer.name,     ) new_model = tf.keras.models.clone_model(old_model, new_input_layer)  copy over the weights new_model.set_weights(old_model.get_weights())","> Thanks for getting back to me. That did the trick! >  > In case anyone else comes across this. In order to change the input layer of an existing model, I've ended up using this code: >  >  Thank you for this trick! However, using netron, I observed that the values of the kernel parameters are all changed after the convertion. And the output is totally different than the original model. Have you encountered such problem?",You might have to also copy over the weights (depends a bit on what exactly you are doing). ```python new_model.set_weights(old_model.get_weights()),> You might have to also copy over the weights (depends a bit on what exactly you are doing). >  >  Exactly! Thank you again!  It is strange that the man page of tf.keras.models.clone_model does not mention that ,"You're welcome! It only says: > ""Model cloning is similar to calling a model on new inputs, except that it creates new layers (and thus new weights) instead of sharing the weights of the existing layers."" which leaves some room for misinterpretation, I think. Glad it's working for you now!"
1908,"以下是一个github上的tensorflow下的一个issue, 标题是(Configure script automatically selects CUDA/cuDNN path instead of waiting for user input)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version TF 2.10  Custom Code No  OS Platform and Distribution Fedora 37  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 12.3.1  CUDA/cuDNN version 11.8,12.1/8.0  GPU model and memory GTX 1660 Ti, 6 GB  Current Behaviour? I am having multiple CUDA versions, and I am trying to build Tensorflow from source with CUDA support. Now the problem lays when I try to configure the build system using `./configure`. It will asks for relevant information for the build system. This includes: 1. Python path 2. Python packages path 3. Whether to support mROC 4. Whether to support CUDA 5. Whether to support TensorRT Now, when I select CUDA support. the script seems to automatically selects my CUDA/cuDNN versions, and does not give me the possibility to select it manually, which is contradictory to what the documentation suggests at  https://www.tensorflow.org/install/sourcegpu_support:  _""If your system has multiple versions of CUDA or cuDNN installed, explicitly set the version instead of relying on the default""_ Now, I was able to trace the issue exactly to the `configure.py` file.  In fact, I strongly suspects that there is a logical error on the section that parses the user input (Line 1244 on branch r2.11):  Now, from my understanding, the script will validate the given environment, and then if that fails will ask for user input. With that, on the first iteration of the loop, the validation will not contain the required environment variables. I was able to solve the)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ramizouari,Configure script automatically selects CUDA/cuDNN path instead of waiting for user input,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version TF 2.10  Custom Code No  OS Platform and Distribution Fedora 37  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 12.3.1  CUDA/cuDNN version 11.8,12.1/8.0  GPU model and memory GTX 1660 Ti, 6 GB  Current Behaviour? I am having multiple CUDA versions, and I am trying to build Tensorflow from source with CUDA support. Now the problem lays when I try to configure the build system using `./configure`. It will asks for relevant information for the build system. This includes: 1. Python path 2. Python packages path 3. Whether to support mROC 4. Whether to support CUDA 5. Whether to support TensorRT Now, when I select CUDA support. the script seems to automatically selects my CUDA/cuDNN versions, and does not give me the possibility to select it manually, which is contradictory to what the documentation suggests at  https://www.tensorflow.org/install/sourcegpu_support:  _""If your system has multiple versions of CUDA or cuDNN installed, explicitly set the version instead of relying on the default""_ Now, I was able to trace the issue exactly to the `configure.py` file.  In fact, I strongly suspects that there is a logical error on the section that parses the user input (Line 1244 on branch r2.11):  Now, from my understanding, the script will validate the given environment, and then if that fails will ask for user input. With that, on the first iteration of the loop, the validation will not contain the required environment variables. I was able to solve the",2023-06-02T04:15:37Z,stat:awaiting tensorflower type:bug type:build/install TF 2.10,open,0,4,https://github.com/tensorflow/tensorflow/issues/60760,"Hi  , Tensorflow preconfigures paths of the CUDA and cuDNN toolkits which are installed as per Official instructions in documentation using Conda.If the script able to detect the path automatically then it won't ask the user to mention the paths.If the path not able to detectable by script then it will prompt the users to mention the path.Please refer the below example for same.  So if the script is able to identify the path then tensorflow only facilitating the users right. However if you want to keep the cuda and cudnn libraries at a particular directory or want to use particular version of cuda/cudnn you can done this by removing cuda/cuDNN from standard download path and then the script will ask to enter the cuda path as seen in above example. I would like to know how you installed the cuda/cuDNN and how the path has been set. Also please confirm whether the auto detection is causing any particular problem for your case. Please elaborate. Thanks!","Hi  , First of all, thank you for your help. I installed both cuDNN and CUDA via Nvidia's RPM package. And so it is updated via the package manager. The installation is on the standard path `/usr/local/cuda`. Now to be more precise, for any update with version xx.y of CUDA. the package manager will: 1. install the update on `/usr/local/cudaxx.y` folder 2. set `/usr/local/cudax` and `/usr/local/cuda` as a symbolic to  `/usr/local/cudaxx.y` With this, I effectively have many CUDA versions installed on the path `/usr/local/cudaxx.y`, with the latest version acting as the default one. The path is set on login. In fact, my `~/.bashrc` file contain these two lines:  > However if you want to keep the cuda and cudnn libraries at a particular directory or want to use particular version of cuda/cudnn you can done this by removing cuda/cuDNN from standard download path and then the script will ask to enter the cuda path as seen in above example. I am going to slightly disagree on this. This should be the logical behaviour when there is exactly one installation (modulo some symbolic links).  But in my case, I have many different installations, and it will be better if the script asks for what version I expect. Also, the documentation itself hints that the script should do such behaviour upon detecting many CUDA versions, which is not what is happening.","Hi  , The script for ./configure can be found here. If you are interested then go through the source code and analyse the behaviour and may let us know if you have any pointers for this behaviour. Thanks!",  Please share your pointers on this issue. CC  toplay 
907,"以下是一个github上的tensorflow下的一个issue, 标题是(Check fail can be triggered in `tf.raw_ops.EmptyTensorList` due to overflow under jit compile mode.)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device Ubuntu 20.04  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Check fail can be triggered in `tf.raw_ops.EmptyTensorList` under jit compile mode. While in normal mode, it won't be triggered but through an InvalidArgumentError.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Lyutoon,Check fail can be triggered in `tf.raw_ops.EmptyTensorList` due to overflow under jit compile mode.,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device Ubuntu 20.04  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Check fail can be triggered in `tf.raw_ops.EmptyTensorList` under jit compile mode. While in normal mode, it won't be triggered but through an InvalidArgumentError.  Standalone code to reproduce the issue   Relevant log output  ",2023-06-02T03:41:51Z,stat:awaiting tensorflower type:bug comp:ops TF 2.13,open,0,3,https://github.com/tensorflow/tensorflow/issues/60758,"Hi  , Please report check fails and other vulnerabilities here. For more details, please check https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md and follow the instrcutions. I have tried to replicate the reported behaviour with tfnightly(2.14.0dev20230601) in colab but I have observed that it is raising the exception.I executed the code multiple times and observed only exception but not overflow as reported by you. Please refer the attached gist and confirm. Thanks!","Hi , please try this new one:  I've tested on colab, here is the screenshot. !image Thanks!"," , Thanks for the correction. I can see now the code crashes with Fatal error and raises `InvalidArgument` due to  Overflow. "
1122,"以下是一个github上的tensorflow下的一个issue, 标题是(error: undefined reference to 'tensorflow::TensorShapeBase<tensorflow::TensorShape>::TensorShapeBase(absl::Span<long const>)')， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.7  Bazel version 5.3.0  GCC/Compiler version gcc 9  CUDA/cuDNN version 11  GPU model and memory Tesla T4  Current Behaviour? When I run a build with `config=opt`, I get the following error:  However, compiling normally is fine. Checking llvmnm, I see these symbols in optimized build:  but these in normal:  I am building tensorflow from source and copying `libtensorflow_cc.so`, `libtensorflow_framework.so`, and include files into my project. However, the linking step fails as described above.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,p3achyjr,error: undefined reference to 'tensorflow::TensorShapeBase<tensorflow::TensorShape>::TensorShapeBase(absl::Span<long const>)',"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.7  Bazel version 5.3.0  GCC/Compiler version gcc 9  CUDA/cuDNN version 11  GPU model and memory Tesla T4  Current Behaviour? When I run a build with `config=opt`, I get the following error:  However, compiling normally is fine. Checking llvmnm, I see these symbols in optimized build:  but these in normal:  I am building tensorflow from source and copying `libtensorflow_cc.so`, `libtensorflow_framework.so`, and include files into my project. However, the linking step fails as described above.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-06-01T23:39:16Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60754,"Hi  , Could you please confirm the build command you have used along with the options selected during the `./configure` step. Also please check the tested configurations for build from source. Version  11.2 Could you please upgrade CUDA to 11.2,cuDNN to 8.1 and GCC to 9.3.1 and then try the build. Also please ensure you have C++17 environment. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1345,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Lite Model Maker model works on Python API but not on device (IOS/Android))， 内容是 (Hello, I hope all is well. I have recently created a MobileBERT model using the Python API of the tflite_model_maker library following the steps described in this page. You may find it attached in the following link (let me know if I can share it in any other way). The good news is that I have been able to run inference with the Python API by following the steps described in this article. However, my colleague has been encountering issues when trying to run the same model using the Swift and Android APIs after following this page.  After some time, he was effortlessly able to run inference on a different model made available through one of the sample apps found here. It is our belief that the issue may be from the MetaData but after inspecting both models' metadata (attached in the zip file), they seem to be exactly the same: MetaDatas.zip. Our issue is that the inference process is killed without clear reason after the model is loaded. As displayed in the image below: !MicrosoftTeamsimage With the following error:  Please advise and thank you for your time)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,carl-krikorian,Tensorflow Lite Model Maker model works on Python API but not on device (IOS/Android),"Hello, I hope all is well. I have recently created a MobileBERT model using the Python API of the tflite_model_maker library following the steps described in this page. You may find it attached in the following link (let me know if I can share it in any other way). The good news is that I have been able to run inference with the Python API by following the steps described in this article. However, my colleague has been encountering issues when trying to run the same model using the Swift and Android APIs after following this page.  After some time, he was effortlessly able to run inference on a different model made available through one of the sample apps found here. It is our belief that the issue may be from the MetaData but after inspecting both models' metadata (attached in the zip file), they seem to be exactly the same: MetaDatas.zip. Our issue is that the inference process is killed without clear reason after the model is loaded. As displayed in the image below: !MicrosoftTeamsimage With the following error:  Please advise and thank you for your time",2023-05-31T19:59:56Z,stat:awaiting response type:bug comp:lite,closed,0,12,https://github.com/tensorflow/tensorflow/issues/60743,"Hi krikorian, Thanks for reporting this issue. Can you please follow the instructions to fill out the issue template: https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md, this will help us identify what is different about your environment which may be causing the issue. Also can you clarify whether this is happening for the Swift API, Android API, or both? Also any additional real custom code you are executing will help as well. A minimal example to reproduce is preferred.","Hello , To answer your question, the issue was encountered on both Swift and Android. For the Swift API, the app would show the error displayed in the first comment, whereas for the Android API the app seemed to crash.   Have I written custom code (as opposed to using a stock example script provided in TensorFlow): For the Android app we used the sample app found here. Similarly for Swift we followed these instructions here. Here is a sample of the struct used for the Swift code in the first image:  The Python inference that worked was run using this code block   OS Platform and Distribution (e.g., Linux Ubuntu 16.04): The model was trained on the fallback version of Google Colab, It is no longer available but I believe it used either Ubuntu 20.04 or 18.04. The inference testing was made on Ubuntu 22.04 with the Python API and for the Android and Swift APIs on Mac OS 16.5.  Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on a mobile device: The issue was while running the app on emulators.  TensorFlow installed from (source or binary): The packages were install through pip on both Google Colab and the Ubuntu machine for training.  TensorFlow version (use command below): For the Python inference the version of Tensorflow was: v2.8.110g2ea19cbb575 2.8.2  Bazel version Not applicable  Python version / GCC/Compiler version Was trained on:   3.9.16 (main, Dec  7 2022, 01:11:51)    [GCC 9.4.0] Inference worked on Python API using:   3.7.11 (default, Jul 27 2021, 14:32:16)    [GCC 7.5.0]  CUDA/cuDNN version: CUDA Version: 12.0  GPU model and memory: Tesla T4 16 GB of Memory Let me know if I can provide any more specific or further information. Thank you for your time!","Hi krikorian, can you upload the .tflite model you used that ran into this issue? The code you used to produce the model would also be helpful (the code sample you provided appears to create one and run inference but doesn't do the actual conversion).","Hello ,  The model was attached in the first comment here: https://drive.google.com/file/d/1jeKm7EesBZqi_lgPrCSq_HwPapX54OlL/view?usp=sharing I would have zipped and sent it but the last time I did that it wiped the entire MedtaData. Here is the training script I used:  tflite_maker.zip","Hi krikorian, I am having trouble replicating the issue, let's focus on iOS/Swift for now. How are you installing the pod? How are you calling the library? How are you including the ""model.tflite"" file in the app? Is it part of the app's bundle? Exact steps, exact podfile and a minimal reproducing code example is preferred (Are you calling it in the app's init function?) Are you using an emulator? If so what is your exact target? Are you targeting arm64 or x86_64? Generally the more information and the clearer I can reproduce your environment the easier it will be for us to help you. Thanks for your help!","Hello    We are installing the pod using:    pod 'TensorFlowLiteSwift'   pod 'TensorFlowLiteTaskText', '~> 0.2.0'  This is we are calling the library:   guard let modelPath = Bundle.main.path(forResource: ""model"", ofType: ""tflite"") else { return }   self.tensorFlowBertNLClassifier = TFLBertNLClassifier.bertNLClassifier(modelPath: modelPath)   The model ""model.tflite"" is added in a folder: AppFolder > Classification > model.tflite  The model ""model.tflite"" is included in the target.  We are using a real device: iPhone XS with iOS 16.5 Thanks ","Hi krikorian, and , I was able to successfully build a minimal working example xcode app and tested it on an iPhone XS emulator with iOS **16.4** Here's my podfile (test60743 is my toy project)  Here's the main code of my toy app, everything else is default/unchanged:  output:  Can you check if you installed the podfiles properly? Do you all run into the same problem with a minimal example? (Feel free to use this toy example app to test).","Hi , I built the same example and had the same error.. This it the output: TestTextClassifierSwiftUI[33808:264743] Initialized TensorFlow Lite runtime. tensor>bytes == bytes FATAL I attached the sample I did (without the pods folder) TestTextClassifierSwiftUI.zip Not sure if related... which Xcode version are you using?","Hi , I'm using Xcode 14.3.1, good news, I am able to run into your issue w/ your project. The only thing I can spot that is different about yours and my toy app is the extra frameworks in the ""Pods"" folder. I tried removing the frameworks but that doesn't seem to fix it. Can you start a fresh project and follow these directions for including 'TensorFlowLiteTaskText'. 1. Go to your root project directory and do:  2. Open your Podfile and make it like this:  3. install the pod:  Add the model.tflite asset to your project and try running the toy app. This is to test to make sure that this works without the extra frameworks. If that works, try adding the frameworks one by one so we can pinpoint what's causing the problem.",hey .. I finally found the issue. The TensorFlowLiteTaskText library v 0.2.0 installed as described here https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_nl_classifierstep_1_import_cocoapods is crashing with the model we are using. However it is working fine when using the latest version 0.4.3. Thanks for your support.,", Awesome! Does this resolve the issue with android as well? If so, please feel free to close if you have no additional items.",Are you satisfied with the resolution of your issue? Yes No
1466,"以下是一个github上的tensorflow下的一个issue, 标题是(Failed to launch ptxas error when using nvidia/cuda runtime Docker image)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230531  Custom Code Yes  OS Platform and Distribution 20.04  Mobile device _No response_  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8.0 / cuDNN 8.7  GPU model and memory _No response_  Current Behaviour? I get the following warning when I run prediction using a 3D model (full log provided below):  I'm using a model that takes a 3D input and the error occurs when I have a `Conv3DTranspose` layer (which my model implements). I'm using the official `nvidia/cuda` image with runtime libraries, specifically the `nvcr.io/nvidia/cuda:11.8.0cudnn8runtimeubuntu20.0`. I don't get the warning when using the `devel` image, however, I want to stick with `runtime`, as it's much smaller and I don't need any of the compiling capabilities or dev tools. Does this warning have an impact on model inference and how can I fix it? Minimal Dockerfile and Python script to reproduce issue are provided below.  Standalone code to reproduce the issue Dockerfile:  `test.py`:  Steps to reproduce:   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,goncinious,Failed to launch ptxas error when using nvidia/cuda runtime Docker image,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230531  Custom Code Yes  OS Platform and Distribution 20.04  Mobile device _No response_  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8.0 / cuDNN 8.7  GPU model and memory _No response_  Current Behaviour? I get the following warning when I run prediction using a 3D model (full log provided below):  I'm using a model that takes a 3D input and the error occurs when I have a `Conv3DTranspose` layer (which my model implements). I'm using the official `nvidia/cuda` image with runtime libraries, specifically the `nvcr.io/nvidia/cuda:11.8.0cudnn8runtimeubuntu20.0`. I don't get the warning when using the `devel` image, however, I want to stick with `runtime`, as it's much smaller and I don't need any of the compiling capabilities or dev tools. Does this warning have an impact on model inference and how can I fix it? Minimal Dockerfile and Python script to reproduce issue are provided below.  Standalone code to reproduce the issue Dockerfile:  `test.py`:  Steps to reproduce:   Relevant log output  ",2023-05-31T11:29:44Z,stat:awaiting response type:bug type:build/install stale TF 2.13,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60737,"Hi  , Could you please try installing cudanvcc package using `conda install c ""nvidia/label/cuda11.8.0"" cudanvcc` and let us know if it helps. Thanks!","Thanks ! I'm already using Poetry for managing dependencies in my use case, so I'd prefer to avoid having to install `conda` just for this. Can I install `cudanvcc` without `conda`?"," , Actually with Docker environment there is no need to install cuda toolkit separately as nvidiadocker takes care of it. But this is applicable to standard tensorflow image not sure to user built images as you are trying to build your own image.Please refer to the official documentation for docker instructions. Please try `sudo apt install nvidiacudatoolkit` explicitly and let us know if helps.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi , thanks for your reply. > > Actually with Docker environment there is no need to install cuda toolkit separately as nvidiadocker takes care of it. But this is applicable to standard tensorflow image not sure to user built images as you are trying to build your own image.Please refer to the official documentation for docker instructions. Yes, I believe the same applies to the `devel` image from the official `nvidia/cuda` image. As mentioned above, it doesn't show the warning highlighted above. However, the point here is how to properly setup `ptxas` compilation while avoiding installing massive dependencies in the `runtime` image. > Please try sudo apt install nvidiacudatoolkit explicitly and let us know if helps. This indeed solves the issue above, but adds (4.6 GB) to the image, which  the purpose of using the slimmer `runtime` image. Click to expand!    Note that this method seems to install a deprecated version of `ptxas`, which we want to avoid too. See below: > 20230619 11:12:26.647185: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalidaddress errors.","Hi  , > Yes, I believe the same applies to the `devel` image from the official `nvidia/cuda` image. As mentioned above, it doesn't show the warning highlighted above. However, the point here is how to properly setup `ptxas` compilation while avoiding installing massive dependencies in the `runtime` image. AFAIK ptxas is a package that included in CUDA package itself and I am not sure this falls under TF scope.May be we need to confirm the same with Nvidia team. I believe devel images dont have this problem with ptxas path as per reference from the attached issues from Jax, link1 and link2. > 20230619 11:12:26.647185: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalidaddress errors. I can see this as logged as Error log may be due to the reason that it might miscompile XLA code."," , As per Official TF documentation for Docker support you might need to install Nvidia driver in host system and Nvidia container toolkit on docker, the instructions for which mentioned here. Could you please check whether the above resources solves your problem Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"I followed this guide  and had the same issue where jupyter notebook kernel was crashing because it couldn't find ptxas. `conda install c ""nvidia/label/cuda11.8.0"" cudanvcc` fixed the issue. Thanks."
881,"以下是一个github上的tensorflow下的一个issue, 标题是(JVP incorrect in forward mode for `tf.math.sign` and `tf.experimental.numpy.sign`)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tfnightly  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When I was trying to calculate jvp of `tf.math.sign` and `tf.experimental.numpy.sign` in forward mode, it gives `None` instead of a proper value.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,drewshark,JVP incorrect in forward mode for `tf.math.sign` and `tf.experimental.numpy.sign`,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tfnightly  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When I was trying to calculate jvp of `tf.math.sign` and `tf.experimental.numpy.sign` in forward mode, it gives `None` instead of a proper value.  Standalone code to reproduce the issue   Relevant log output  ",2023-05-31T09:46:44Z,stat:awaiting response type:bug stale comp:ops,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60736,", Could you please refer to the documentation of `tf.autodiff.ForwardAccumulator` where it was stated that **Forward mode** works best on functions with many outputs and few inputs. Since it does not hold on to intermediate activations, it is much more memory efficient than backprop where it is applicable. Reverse mode is more attractive when computing gradients of a scalarvalued function with respect to many inputs (e.g. a neural network with many parameters and a scalar loss). https://www.tensorflow.org/api_docs/python/tf/autodiff/ForwardAccumulator Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1889,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite SPARSE_TO_DENSE dimension mismatch issue when doing prediction)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Jupyter notebook on a server, CPU run  TensorFlow installation (pip package or built from source):   TensorFlow library (version, if pip package or github SHA, if built from source):  2.4.0  2. Code  Remark: data_list is the list of n data samples, each being a dict. Here I just want to loop over every data point and record the predictions. The inner loop is over the 23 * 3 = 69 model input tensors.  3. Failure after conversion SPARSE_TP_DENSE produces some strange error.  5. (optional) Any other info / logs Hi, I'm trying to do inference using TFLite model in a jupyter notebook. I have successfully converted the model to 'dynamic_range_int8_model.tflite'. However, when I use the model to do prediction using the above code, I get the following error with the interpreter.allocate_tensors() function: RuntimeError                              Traceback (most recent call last) /tmp/ipykernel_255/4027393990.py in       16          else:      17         interpreter.resize_tensor_input(input_index, data_list[i][required_input[""name""]].shape, strict = False) > 18         interpreter.allocate_tensors()      19         interpreter.set_tensor(input_index, data_list[i][required_input[""name""]])      20  /export/apps/python/3.7/lib/python3.7/sitepackagescustom/tensorflow/lite/python/interpreter.py in allocate_tensors(self)     257   def allocate_tensors(self):     258     self._ensure_safe() > 259     return self._interpreter.AllocateTensors()     260      261   def _safe_to_run(self): RuntimeError: tensorflow/lite/kernels/sparse_to_dense.c)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Lixiaoyun1993,TFLite SPARSE_TO_DENSE dimension mismatch issue when doing prediction," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Jupyter notebook on a server, CPU run  TensorFlow installation (pip package or built from source):   TensorFlow library (version, if pip package or github SHA, if built from source):  2.4.0  2. Code  Remark: data_list is the list of n data samples, each being a dict. Here I just want to loop over every data point and record the predictions. The inner loop is over the 23 * 3 = 69 model input tensors.  3. Failure after conversion SPARSE_TP_DENSE produces some strange error.  5. (optional) Any other info / logs Hi, I'm trying to do inference using TFLite model in a jupyter notebook. I have successfully converted the model to 'dynamic_range_int8_model.tflite'. However, when I use the model to do prediction using the above code, I get the following error with the interpreter.allocate_tensors() function: RuntimeError                              Traceback (most recent call last) /tmp/ipykernel_255/4027393990.py in       16          else:      17         interpreter.resize_tensor_input(input_index, data_list[i][required_input[""name""]].shape, strict = False) > 18         interpreter.allocate_tensors()      19         interpreter.set_tensor(input_index, data_list[i][required_input[""name""]])      20  /export/apps/python/3.7/lib/python3.7/sitepackagescustom/tensorflow/lite/python/interpreter.py in allocate_tensors(self)     257   def allocate_tensors(self):     258     self._ensure_safe() > 259     return self._interpreter.AllocateTensors()     260      261   def _safe_to_run(self): RuntimeError: tensorflow/lite/kernels/sparse_to_dense.c",2023-05-31T00:39:47Z,stat:awaiting response stale comp:lite TFLiteConverter TF 2.4,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60734,"Hi   Could you please provide the tflite model to reproduce the issue?  Also, can you please test in latest 2.12 version and let us know if the issue still persists? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
977,"以下是一个github上的tensorflow下的一个issue, 标题是([TF 2.0] Signature for unranked tensor not working as intended)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14  Custom Code Yes  OS Platform and Distribution Linux  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? trying to save a model where one of the functions in the model is defined as:  When I train the model, and try to build it, I get the following error:  Shouldn't specifying input signature as `None` imply that you can pass any input into this function? (unranked tensor)  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MeghnaNatraj,[TF 2.0] Signature for unranked tensor not working as intended,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14  Custom Code Yes  OS Platform and Distribution Linux  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? trying to save a model where one of the functions in the model is defined as:  When I train the model, and try to build it, I get the following error:  Shouldn't specifying input signature as `None` imply that you can pass any input into this function? (unranked tensor)  Standalone code to reproduce the issue   Relevant log output _No response_",2023-05-30T22:11:27Z,stat:awaiting tensorflower type:bug comp:apis,open,0,2,https://github.com/tensorflow/tensorflow/issues/60732,", Could you please provide the simple standalone code to reproduce the issue and help us to analyse the issue in an effective way. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.
1911,"以下是一个github上的tensorflow下的一个issue, 标题是(`tf.split` or `tf.transpose` cause errors for quantize-aware training with `quantize_apply`)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.7 & 2.12  Custom Code Yes  OS Platform and Distribution Ubuntu 18.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? We are trying to implement some network like ShuffleNetV2 but encounter some error when `quantize_apply` the model. !image I believe ShuffleNet or related ideas are popular in edge devices, please kindly help us to resolve this proble. Any advice is welcome. _I apologize for this should have been posted as an issue on Tensorflow Model Optimization. However, since it seems that this problem is not unique to me, I'm posting it here in the hope of receiving appropriate suggestions or assistance._  System information TensorFlow version (installed from source or binary): 2.7.0 TensorFlow Model Optimization version (installed from source or binary): 0.7.0 Python version: 3.8.13 **We also try on latest release of both module, but also not working.**  Describe the current behavior When running the provided code, either the `tf.transpose` or `tf.split` will cause error to Tensorflow Model Optimization. The error message due to `tf.split` before convolution layers:  The error message due to `tf.transpose`:   Standalone code to reproduce the issue Just run the following code you will get the error message due to `tf.split`.  You can just comment the following three lines of code will get the error message from `tf.transpose`. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Janus-Shiau,`tf.split` or `tf.transpose` cause errors for quantize-aware training with `quantize_apply`,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.7 & 2.12  Custom Code Yes  OS Platform and Distribution Ubuntu 18.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? We are trying to implement some network like ShuffleNetV2 but encounter some error when `quantize_apply` the model. !image I believe ShuffleNet or related ideas are popular in edge devices, please kindly help us to resolve this proble. Any advice is welcome. _I apologize for this should have been posted as an issue on Tensorflow Model Optimization. However, since it seems that this problem is not unique to me, I'm posting it here in the hope of receiving appropriate suggestions or assistance._  System information TensorFlow version (installed from source or binary): 2.7.0 TensorFlow Model Optimization version (installed from source or binary): 0.7.0 Python version: 3.8.13 **We also try on latest release of both module, but also not working.**  Describe the current behavior When running the provided code, either the `tf.transpose` or `tf.split` will cause error to Tensorflow Model Optimization. The error message due to `tf.split` before convolution layers:  The error message due to `tf.transpose`:   Standalone code to reproduce the issue Just run the following code you will get the error message due to `tf.split`.  You can just comment the following three lines of code will get the error message from `tf.transpose`. ",2023-05-26T17:33:07Z,stat:awaiting tensorflower type:bug comp:ops TF 2.12,open,1,5,https://github.com/tensorflow/tensorflow/issues/60714,"Hi Shiau , Thanks for reaching us. I have replicated the reported behaviour with TF2.12 and tfnightly(2.14.0dev20230528) and attached gists here TF2.12v and tfnightly. We need to dig more on this to confirm the root cause. Thanks!","Hi , Thank you for your prompt reply and assistance. Look forward to any update and appreciate your efforts in addressing my request.","I am new to opensource contributions, can you   Shiau explain me the issue so that I can work on it.","Hi  , You can refer contributing.md file for more details if you willing to contribute. Thanks!",I am facing the same issue. Any progress on it?
1555,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow can't communicate with GPU. ""None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms."" ""No algorithm worked!"")， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 22.04.2 LTS and Red Hat Enterprise Linux 9.2  Mobile device _No response_  Python version 3.10  Bazel version bazel 5.3.0  GCC/Compiler version 11.3.1  CUDA/cuDNN version 11.8  GPU model and memory Nvidia Quadro K620  2048MiB of memory  Current Behaviour? *This bug happens both in Linux Ubuntu 22.04.2 LTS and RHEL 9. I tested it on a liveusb Ubuntu installation, pip installing it with GPU support after getting tired of trying to solve it on rhel. It is somewhat related to the convolutional (Conv2d) layer, because fitting a model on a pip install with the use of only dense layers works fine. With a source install this error happens independently of model time. Using CLI or multiuser.target, leaving all the GPU resources to tf does not solve the issue. Reducing the Conv2d filters does not solve the problem, nor the bach_size The code should just have no errors. I can't exactly tell or understand the error output, so that's about all I can tell.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,o-clipe,"TensorFlow can't communicate with GPU. ""None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms."" ""No algorithm worked!""","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 22.04.2 LTS and Red Hat Enterprise Linux 9.2  Mobile device _No response_  Python version 3.10  Bazel version bazel 5.3.0  GCC/Compiler version 11.3.1  CUDA/cuDNN version 11.8  GPU model and memory Nvidia Quadro K620  2048MiB of memory  Current Behaviour? *This bug happens both in Linux Ubuntu 22.04.2 LTS and RHEL 9. I tested it on a liveusb Ubuntu installation, pip installing it with GPU support after getting tired of trying to solve it on rhel. It is somewhat related to the convolutional (Conv2d) layer, because fitting a model on a pip install with the use of only dense layers works fine. With a source install this error happens independently of model time. Using CLI or multiuser.target, leaving all the GPU resources to tf does not solve the issue. Reducing the Conv2d filters does not solve the problem, nor the bach_size The code should just have no errors. I can't exactly tell or understand the error output, so that's about all I can tell.  Standalone code to reproduce the issue   Relevant log output  ",2023-05-25T23:04:59Z,stat:awaiting response type:bug comp:keras TF 2.12,closed,1,8,https://github.com/tensorflow/tensorflow/issues/60713,"On the nightly version the error output is a bit different, maybe this is helpful: ","CLIPE, I tried to execute the mentioned code by importing the keras from tensorflow and it was executed without any issues on tensorflow v2.12. Kindly find the gist, GPUgist and below changes.  Thank you!"," based on the error message, what could this error be about? I did get it is not a global tf issue, it's probably hardware specific. Also, with CPU only the code runs perfectly.",Are you satisfied with the resolution of your issue? Yes No,"It is hardware specific. Tensorflow drowns my GPU with memory usage and fails itself. To solve this I just limited the GPU memory usage, to lower than what I can expend (I overflows the limit a bit — in my case a bit means 24% of GPU memory). 2048MiB of memory if just too little for most applications of machine learning.",Are you satisfied with the resolution of your issue? Yes No,How to limit GPU memory usage: https://stackoverflow.com/a/60069601/20940588,I got the same issues and limit the GPU memory usage does not work. Any other clues?
1828,"以下是一个github上的tensorflow下的一个issue, 标题是(Custom Keras Optimizer over TPU strategy error)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello, I'd wish to draw your attention to a bug that affects custom Optimizers extended from the class `tf.keras.optimizers.experimental.Optimizer`  while running on TPU clusters on native Google Colab.  While the code refuses to execute in order to compute gradients while using a custom optimizer  opt, it happens to run very well while using 'adam' on default settings. The standalone code to reproduce the problem is provided and doesn't requires any extra tool or dependency and can be easily pasted into Colab to run and inspect the execution for bug investigations. _______________________________________________________________________________________________________________________ Apart from that I wish addition of a new feature  *batch size* of the data being currently used by the optimizer to compute gradients, as we know is pretty straightforward in a single CPU/GPU, but becomes difficult while executing the same code in distributed systems. If possible, kindly amend my existing standalone code below to add that small tiny feature into my Optimizer. Thank You. Best Regards  Standalone code to reproduce the issue  ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,abhaskumarsinha,Custom Keras Optimizer over TPU strategy error,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.12.0rc112g0db597d0d75 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello, I'd wish to draw your attention to a bug that affects custom Optimizers extended from the class `tf.keras.optimizers.experimental.Optimizer`  while running on TPU clusters on native Google Colab.  While the code refuses to execute in order to compute gradients while using a custom optimizer  opt, it happens to run very well while using 'adam' on default settings. The standalone code to reproduce the problem is provided and doesn't requires any extra tool or dependency and can be easily pasted into Colab to run and inspect the execution for bug investigations. _______________________________________________________________________________________________________________________ Apart from that I wish addition of a new feature  *batch size* of the data being currently used by the optimizer to compute gradients, as we know is pretty straightforward in a single CPU/GPU, but becomes difficult while executing the same code in distributed systems. If possible, kindly amend my existing standalone code below to add that small tiny feature into my Optimizer. Thank You. Best Regards  Standalone code to reproduce the issue  ```  Relevant log output _No response_",2023-05-25T19:57:21Z,stat:awaiting response type:bug stale comp:keras TF 2.12,closed,1,9,https://github.com/tensorflow/tensorflow/issues/60711,"Ah, just a little bit of an embarrassing mistake from my side. The optimizer needs to be called inside strategy.scope() block for it to work.  Now, I'm just left with my second question only. > Apart from that I wish the addition of a new feature  batch size of the data being currently used by the optimizer to compute gradients, as we know is pretty straightforward in a single CPU/GPU, but becomes difficult while executing the same code in distributed systems. If possible, kindly amend my existing standalone code below to add that small tiny feature into my Optimizer. I'll close the issue after this.","Hi  , The Optimizers by default takes batch_size from model.fit only or from the tf.data.Dataset if set batch explicitly. I am not quite follow through your requirement of batch_size passing to Optimizer here. Normally for multi workers or nodes we can increase the batch_size by the no of GPUs we have. Suppose we want `batch_size` of `64` on each of the GPU and total no of GPUs enabled under distribution strategy can be got by `strategy.num_replicas_in_sync`. Please refer the below code.  Then BATCH_SIZE shall be passed to model.fit. Please refer to some official tutorials on how to configure distribution training on multiple workers here link1 and link2. If you still have any queries please come back and let us know. Thanks!","Reference: https://github.com/tensorflow/tensorflow/issues/60592issuecomment1563789462 Hello   Thank you so much for your response and for bearing me with regarding the issue. The thing is that we are working on some sort of special optimizer that works on variable _batch_sizes_ to make it work on some very specific nonconvex functions on very large distributed systems. So, I'm left with two requirements for now. 1. Have variable batch size for the optimizer (the optimizer decides the batch size of _$t_n$_ given the optimizer parameters at _$t_n1$_. 2. We manually specify the upper bound of the batch size, i.e. all the _batch_size at all t_i_ for i in 0, 1, 2, ... should be less than _upper_bound_ i.e. _batch_size at t_i < upper_bound._ In that case, we mask the last entries of our gradients with 0 and calculate the gradient of only the required first _batch_size_ at _t_i_ entries and train the network From my guess, 2 should be faster and should outperform 1 because the graph wouldn't need to be reconstructed using CUDA API for training the model, unlike case 1. Since we need this optimizer to run on distributed training settings on a very large system, I wanted to make sure if any of these features are implementable on Keras or not. (Masking the gradient of certain batch indices with 0). Thank you in Advance.","HI  , Thanks for your explanation on your requirement. If you want to customize the training step you need to build custom model class subclassing the `keras.Model` and need to override `train_step`. If you can able to accommodate your requirements in the `train_step` method then may be it can possible to implement your requirement.  Please have a look into sample tutorial for customizing the train_step of keras model training. Please have a look and let us know if it is helpful. Thanks!","Hello   Sorry for the late response. Yes, I've also checked to extend `tf.keras.Model` class and custom training step function. My only concern was whether this whole thing would be applicable to distribution strategies. The second thing is to mask certain batches to 0 while keeping the gradients from other batches. If this gives control over batchlevel editing and supports distribution, then this would definitely be helpful for me. Thank you so much.","  > Sorry for the late response. Yes, I've also checked to extend `tf.keras.Model` class and custom training step function. My only concern was whether this whole thing would be applicable to distribution strategies. Ofcourse custom models also can be used with distribution strategies.Please refer a sample tutorial. > The second thing is to mask certain batches to 0 while keeping the gradients from other batches. If this gives control over batchlevel editing and supports distribution, then this would definitely be helpful for me. Thank you so much. I am not quiet follow through you here. AFAIK if you want some batches to be masked Zero then there is no standard way in Tensorflow.This may not possible during training but you can try with tf.data.Dataset generators and implement your own logic for dataset generation. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1913,"以下是一个github上的tensorflow下的一个issue, 标题是(Dataset.ragged_batch does not produce correct specs with tf.py_function and tf.numpy_function)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution docker container nvcr.io/nvidia/tensorflow:23.04tf2py3 on Ubuntu 22.04.2 LTS host  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to train an object detection model where images may have a different number of bounding boxes. Also I want to add some augmentations, and since tf does not support augmentations of bounding boxes I choose albumentations to do the job. I can't use albumentations' augmentations directly, so I need to use either `tf.py_function` or `tf.numpy_function`. I used `Dataset.ragged_batch` instead of `Dataset.batch` (because the dimension of bbox tensor may vary), but it did not provide me the correct `element_spec` and I was unable to make it work. These are three scenarios that should help to understand the issue:  Scenario 1: I don't use any augmentations, `ragged_batch` returns the correct element spec, but I really need those augmentations   Scenario 2: I use `tf.numpy_function` fo perform the augmentations. The spec is incorrect, I can't batch the items   Scenario 3 I use `tf.py_function`, provide something, that looks like correct spec to `Tout` param:  but spec for image still does not look good  and I had to add an extra dimension for labels spec in order to convert it to `RaggedTensor` (which is probably not good as well). Model refuses )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,eawer,Dataset.ragged_batch does not produce correct specs with tf.py_function and tf.numpy_function,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution docker container nvcr.io/nvidia/tensorflow:23.04tf2py3 on Ubuntu 22.04.2 LTS host  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to train an object detection model where images may have a different number of bounding boxes. Also I want to add some augmentations, and since tf does not support augmentations of bounding boxes I choose albumentations to do the job. I can't use albumentations' augmentations directly, so I need to use either `tf.py_function` or `tf.numpy_function`. I used `Dataset.ragged_batch` instead of `Dataset.batch` (because the dimension of bbox tensor may vary), but it did not provide me the correct `element_spec` and I was unable to make it work. These are three scenarios that should help to understand the issue:  Scenario 1: I don't use any augmentations, `ragged_batch` returns the correct element spec, but I really need those augmentations   Scenario 2: I use `tf.numpy_function` fo perform the augmentations. The spec is incorrect, I can't batch the items   Scenario 3 I use `tf.py_function`, provide something, that looks like correct spec to `Tout` param:  but spec for image still does not look good  and I had to add an extra dimension for labels spec in order to convert it to `RaggedTensor` (which is probably not good as well). Model refuses ",2023-05-25T18:52:03Z,stat:awaiting tensorflower type:bug comp:data TF 2.12,open,1,1,https://github.com/tensorflow/tensorflow/issues/60710,"`py_function` not only effects `ragged_batch` but also later KerasCV layers in `.map` to operate. According to this discussion, the return value of `py_function` lost the information of its shape and rank. So the solution can be: 1. to manually set those information by `tensor.set_shape([None, None])`. 2. to return the shape (inside py_function) and assign it to outside tensor. Below are a small demo (the first one solution) showing that it works. However it's definetely a bug. the return value SHOULD know the shape and rank. Or at least this ""feature"" should be written in documentation. "
1100,"以下是一个github上的tensorflow下的一个issue, 标题是(Hexagon Libraries version `v1.20.0.9` not available)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v2.11.1  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device Android  Python version _No response_  Bazel version 6.2.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to use Hexagon delegates for Android and I couldn't find the proper `libhexagon_nn_skel*.so` libraries at https://www.tensorflow.org/lite/android/delegates/hexagonstep_2_add_hexagon_libraries_to_your_android_app_2 Could you share a link with the shared library built? As TensorFlow Lite `v2.11.1` requires `v1.20.0.9`. I've tried to use `v1.20.0.1` but got the following error:   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,caiotoledo-lunasystems,Hexagon Libraries version `v1.20.0.9` not available,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v2.11.1  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device Android  Python version _No response_  Bazel version 6.2.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to use Hexagon delegates for Android and I couldn't find the proper `libhexagon_nn_skel*.so` libraries at https://www.tensorflow.org/lite/android/delegates/hexagonstep_2_add_hexagon_libraries_to_your_android_app_2 Could you share a link with the shared library built? As TensorFlow Lite `v2.11.1` requires `v1.20.0.9`. I've tried to use `v1.20.0.1` but got the following error:   Standalone code to reproduce the issue   Relevant log output _No response_,2023-05-25T12:48:49Z,stat:awaiting response type:support stale comp:lite TFLiteHexagonDelegate TF 2.11,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60707,Hi lunasystems  The Hexagon delegates v1.20.0.9 is available in https://github.com/tensorflow/tensorflow/blob/d37fda11945d290f86b85a39f28bbddbbd0f6bee/third_party/hexagon/workspace.bzlL12 Download it here. Thanks.,", Thanks for your feedback. The link provided here doesn't have the libraries `libhexagon_nn_skel.so`, `libhexagon_nn_skel_v65.so`,  `libhexagon_nn_skel_v66.so`. I was expecting a link like the one for v1.20.0.1. I tried to use the link https://storage.cloud.google.com/download.tensorflow.org/tflite/hexagon_nn_skel_v1.20.0.9.run for `v1.20.0.9` but it didn't work.",It seems the documentation may not be up to date and the .run file isn't there for v1.20.0.9  Can you take a look? Alternatively is there a script or instructions on how we may compile the .so files manually?,lunasystems is there any progress/workaround?,"> lunasystems is there any progress/workaround? , no we have put this feature on pause on our side for now. We couldn't find any workaround.","Hi, lunasystems  I apologize for the delayed response, The NNAPI and Hexagon delegates are deprecated and no longer supported by TensorFlow Lite. For more information, see the NNAPI Migration Guide and TF Lite delegates documentation. Thank you for your cooperation and patience.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
2079,"以下是一个github上的tensorflow下的一个issue, 标题是(same Error as #35100 --W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. 	 [[{{node PyFunc}}]])， 内容是 (I am reproducing the code , I followed there requirement but when code reached to 44/100 epoch I got this error : `20230524 06:42:29.554799: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. 	 [[{{node PyFunc}}]]`. I tried to to update tensorflow but it stop working because of keras version.  Code requirements:  `Package                          Version   abslpy                          1.4.0 astor                            0.8.1 certifi                          2022.12.7 charsetnormalizer               3.1.0 colorama                         0.4.6 filelock                         3.12.0 fsspec                           2023.1.0 gast                             0.5.3 googlepasta                     0.2.0 grpcio                           1.51.3 h5py                             3.8.0 huggingfacehub                  0.14.1 idna                             3.4 importlibmetadata               6.0.0 joblib                           1.2.0 Keras                            2.2.4 KerasApplications               1.0.8 kerasbert                       0.80.0 kerasembedsim                  0.10.0 keraslayernormalization        0.16.0 kerasmultihead                 0.29.0 kerasposembd                   0.13.0 keraspositionwisefeedforward 0.8.0 KerasPreprocessing              1.1.2 kerasselfattention             0.51.0 kerastransformer                0.33.0 Markdown                         3.4.1 MarkupSafe                       2.1.2 mock                      )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,AnwarsaeedDMU,same Error as #35100 --W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. 	 [[{{node PyFunc}}]],"I am reproducing the code , I followed there requirement but when code reached to 44/100 epoch I got this error : `20230524 06:42:29.554799: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated. 	 [[{{node PyFunc}}]]`. I tried to to update tensorflow but it stop working because of keras version.  Code requirements:  `Package                          Version   abslpy                          1.4.0 astor                            0.8.1 certifi                          2022.12.7 charsetnormalizer               3.1.0 colorama                         0.4.6 filelock                         3.12.0 fsspec                           2023.1.0 gast                             0.5.3 googlepasta                     0.2.0 grpcio                           1.51.3 h5py                             3.8.0 huggingfacehub                  0.14.1 idna                             3.4 importlibmetadata               6.0.0 joblib                           1.2.0 Keras                            2.2.4 KerasApplications               1.0.8 kerasbert                       0.80.0 kerasembedsim                  0.10.0 keraslayernormalization        0.16.0 kerasmultihead                 0.29.0 kerasposembd                   0.13.0 keraspositionwisefeedforward 0.8.0 KerasPreprocessing              1.1.2 kerasselfattention             0.51.0 kerastransformer                0.33.0 Markdown                         3.4.1 MarkupSafe                       2.1.2 mock                      ",2023-05-25T02:33:48Z,stat:awaiting response type:support stale TF 1.15,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60702,"Hi  , Currently we are not supporting TF 1.x versions. Could you please migrate to TF2.x versions using the migration guide and then report the issue with the changed code. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
766,"以下是一个github上的tensorflow下的一个issue, 标题是(undefined reference to `cudaGraphDebugDotPrint' when compiling TensorFlow 2.12)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version 11.5/8.3  GPU model and memory NVidia RTX A5000  Current Behaviour? The error comes during linking. Please see the log output.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ujjwalnur,undefined reference to `cudaGraphDebugDotPrint' when compiling TensorFlow 2.12,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version 11.5/8.3  GPU model and memory NVidia RTX A5000  Current Behaviour? The error comes during linking. Please see the log output.  Standalone code to reproduce the issue   Relevant log output  ,2023-05-24T12:39:59Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.12,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60689,"Hi  , Request you to confirm the below things. 1. Command used for the build 2. Can you confirm whether you have followed the instructions here mentioned in documentation for enabling GPU setup. 3. Also for Tf 2.12 version recommended CUDA is 11.8, cuDNN is 8.6. You can find the recommended and tested configurations here. Also please test by adding the option `per_file_copt=//tensorflow/.*\.,O0` and let us know if it works. Providing exact build command and steps followed may help us if above also won't work. Thanks!","> Hi  , >  > Request you to confirm the below things. >  >     1. Command used for the build >  >     2. Can you confirm whether you have followed the instructions here mentioned in documentation for enabling GPU setup. >  >     3. Also for Tf 2.12 version recommended CUDA is 11.8, cuDNN is 8.6. You can find the recommended and tested configurations here. >  >  > Also please test by adding the option `per_file_copt=//tensorflow/.*\.,O0` and let us know if it works. >  > Providing exact build command and steps followed may help us if above also won't work. >  > Thanks! Command used for build : `bazel build config=opt config=cuda k //tensorflow/tools/pip_package:build_pip_package` I confirm that all the instructions were followed for enabling GPU setup. After enabling the option` per_file_copt=//tensorflow/.*\.,O0`  the code still does not link and gives the following error   ",I think that the following commit is responsible for the failed build :  de4440c2f8d0a84774afdef180d3ae4acab5398a (For v2.12 branch) The later commit aae3467d8c5c8ae0a18dbfedecce7b50f2ac5ce7 adds a check for `CUDA version>=12000` but has not been put as part of v2.12 branch Can you confirm that these changes need to be merged into v2.12 branch for a proper build ?  I can confirm that I was able to build v2.11 successfully on CUDA 11.5," , Thanks for the information.We have observed build failures with `config=cuda` and team already working on it. I request you to provide the steps on how you have configured the CUDA and cuDNN paths.","  CUDA and cudnn paths were given as base paths to the custom installed paths. These paths were setup using `configure.py`  These paths are properly setup. As I have already said, for v2.11 I used the same paths without error as inall the versions since v2. 3"," Any updates yet on this ? Even some technical explanations would be helpful because then I can take a look into this problem. Since I am a newbie to TF source code, a little help could go a long way.",   I have the same problem. tensorflow_version:2.12.0 cuda_version:11.6 tensorflow2.12.0/tensorflow/compiler/xla/stream_executor/cuda/cuda_graph.cc,"Hi  , Apologies for the delayed response. Could you please confirm the path setting instructions followed by you to enable CUDA and cuDNN paths. Could you please check the Nvidia instructions here for same and try the build and let us know the outcome.  Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
828,"以下是一个github上的tensorflow下的一个issue, 标题是(typing_extensions >= 4.6.0 causes pip unit test failure)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //bazel_pip/tensorflow/python/trackable:data_structures_test will fail with typing_extensions >= 4.6.0 installed when run as a pip test against an installed TensorFlow wheel.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,typing_extensions >= 4.6.0 causes pip unit test failure,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //bazel_pip/tensorflow/python/trackable:data_structures_test will fail with typing_extensions >= 4.6.0 installed when run as a pip test against an installed TensorFlow wheel.  Standalone code to reproduce the issue   Relevant log output  ,2023-05-24T09:25:30Z,stat:awaiting tensorflower type:bug type:support,open,0,11,https://github.com/tensorflow/tensorflow/issues/60687,", The related PR CC(Limit typing_extensions to less than 4.6.0 until it works) was merged and as requested the '**typing_extensions >= 3.6.6**', are changed to     '**typing_extensions>=3.6.6,<4.6.0**' with the mentioned merged PR.  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.pyL100. Could you please confirm whether changes are reflected as mentioned. Thank you!","The rough cause of error is here. The current getattribute for dictwrapper can return TypeError. When an attribute is not found it's instead expected to return AttributeError. Finding place that produces TypeError and replacing it with AttributeError should fix typing extensions incompatibility. typing 4.6 uses inspect.getattr_static which expects that failed attribute access using getattribute only triggers attribute error. This particular error will also be an error if you try to run tensorflow on python 3.12. The typing extensions change was motivated from here. edit: Minimal version of this error is,  The last line raises TypeError. On other hand `t.__dict__` properly raises AttributeError. DictWrapper's custom getattribute is rough area that needs bug fix. The error message comes from here. I've cross posted in cpython side as unsure whether this tensorflow bug or cpython bug.","FYI folks  over on typingextensions thinks this is an issue with wrapt, from https://github.com/python/typing_extensions/issues/216issuecomment1574225352 here's 's message: Looks to me like it's probably an issue with wrapt rather than typing_extensions or TensorFlow, actually. We discussed this a bit in https://github.com/python/cpython/issues/105134. Wrapt raises TypeError if you do object.__getattribute__(<some_wrapt_ObjectProxy_instance, '__dict__'). I know of no way to construct a class using pure Python that has this behaviour (wrapt achieves this behaviour by using a C extension), and it breaks some fundamental assumptions that the stdlib function inspect.getattr_static makes. That, in turn, breaks typing_extensions.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,A consequence of this is that Tensorflow is not compatible with Pydantic V2 due to the restraints on typing_extensions Is there any roadmap to loosen this?,"The root issue comes more from wrapt then tensorflow and is this one. I think downgrading wrapt version should be enough to work around this until that issue is closed. Specifically I think only wrapt 1.15 (or maybe 1.14+) causes an issue while tensorflow requirement is >1.11. Add an upper bound and we should be fine. This is not ideal long term fix and that is still resolve wrapt issue (or remove wrapt dependency). Second solution is set `WRAPT_DISABLE_EXTENSIONS=true`. wrapt has both c extension and pure python implementation. The former causes the error, while latter works fine.","Is anything being done to loosen the upper bound on typingextensions here?  This continues to cause issues on macOS. I have a Pipfile which includes `pydantic`, `pydanticsettings`, and `tensorflow` as packages. Locking packages with a prerelease flag using pipenv works fine with prerelease tag `2.13.0rc1`. However I cannot include tensorflow in this project without using the prerelease. Here is the output from pipenv when manually installing the latest pydanticsettings, which indicates that `tensorflowmacos` is the problem which seems to be related to the upperbound of typingextensions versions here. Everything installs just fine on a Windows OS with the most recent versions of packages  and without a prerelease flag.   ", You can see from https://github.com/tensorflow/tensorflow/pull/61387 that there is no longer an upper limit on typingextensions in git HEAD and that this will be picked up by the next release of TensorFlow which will be 2.14.0.,"Is this issue still active? It looks like it is about to cause an issue for kerascore with the 2.14 release, probably other things affected as well. https://colab.research.google.com/gist/mattdangerw/019d1ebcec746d6f7424248911cf16ae/tf214bug.ipynb More directly, with keras out of the picture, I think the minimal repro below will cause failures in the tensorflow 2.14 docker images (which have a more recent `typing_extensions`). "
1214,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow model training never started on dual 4090 GPUs)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 8.9.1.23  GPU model and memory dual rtx 4090  Current Behaviour? I just plugged my 2nd gpu (a second rtx 4090) into my machine, and when i tried to run the pretraining file for bert (from https://github.com/tensorflow/models/tree/master/official/legacy/bert) and used the flag num_gpus=2 the training never gets started. with nvidiasmi i see that both gpus are 100% utilized (see below) nvidiasmi Wed May 24 01:41:46 2023        ++  I thought it's something related to a bug in bert code, so i run the test code in https://keras.io/guides/distributed_training/ and still the same issue  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,FaisalQarah,Tensorflow model training never started on dual 4090 GPUs,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 8.9.1.23  GPU model and memory dual rtx 4090  Current Behaviour? I just plugged my 2nd gpu (a second rtx 4090) into my machine, and when i tried to run the pretraining file for bert (from https://github.com/tensorflow/models/tree/master/official/legacy/bert) and used the flag num_gpus=2 the training never gets started. with nvidiasmi i see that both gpus are 100% utilized (see below) nvidiasmi Wed May 24 01:41:46 2023        ++  I thought it's something related to a bug in bert code, so i run the test code in https://keras.io/guides/distributed_training/ and still the same issue  Standalone code to reproduce the issue   Relevant log output  ",2023-05-23T23:08:14Z,stat:awaiting response type:bug stale comp:gpu TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60685,", As mentioned above I tried to execute the code on tensorflow v2.12 GPU, https://keras.io/guides/distributed_training/ and it was executed without any issue/error. Kindly find the gist of it here. Also I request to try to run the basic model and test whether it is executing as expected or not and moreover it doesn't look like the tensorflow issue. Thank you!","keras code worked (it didn't stuck before training like last time??) and it shows the number of devices is 2. but when i execute the code, nvidiasmi shows that only the the first gpu is being utilized. Also, after the code is finished execution, it doesn't free the gpus vram from data. With bert code, when i change the number of gpus flag to 2 it shows that both gpus are 100% utilized but it gets stuck before starting the training at the  messages: INFO:tensorflow:batch_all_reduce: 134 allreduces with algorithm = nccl, num_packs = 1 I0525 02:47:56.682721 140068259058752 cross_device_ops.py:897] batch_all_reduce: 134 allreduces with algorithm = nccl, num_packs = 1 INFO:tensorflow:batch_all_reduce: 134 allreduces with algorithm = nccl, num_packs = 1 I0525 02:47:58.796215 140068259058752 cross_device_ops.py:897] batch_all_reduce: 134 allreduces with algorithm = nccl, num_packs = 1 also, there are this weird green tiles shown on my screen even though im using the cpu for displaying ",", Generally a model needs to be big enough in order to profit from GPU acceleration. If you would like a particular operation to run on a device of your choice, you can use `tf.device `to create a device context. For more details please refer to Use a GPU Also to find out which devices your operations and tensors are assigned to, put tf.debugging.set_log_device_placement as the first statement of your program. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,How did you solve it?,"i didn't. I still use each GPU individually. I tried different APIs and approaches but none of them worked. but on vast.ai i saw people rent their GPUs and you can see some of them have setup with dual 4090s but not sure if it work. probably if you use the same docker image that the vast ai provide maybe you can use both GPUs with ease. Whenever i need a setup with more than 24GB vram, i go and rent an A10080GB for a couple of weeks and continue my work on my local setup On Mon, Apr 8, 2024 at 11:49 AM JavaZero ***@***.***> wrote: > How did you solve it? > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >"
899,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Object Detection Project)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf1.x  Custom Code No  OS Platform and Distribution Macos Ventura  Mobile device Macbook air 2020 i3  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? So i am making an object detection projetc for school and i need help whenever i run this code this is the error that pops up. Please help it is due in a few days I have installed all neccesary modules, i think  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,akulthota,Tensorflow Object Detection Project,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf1.x  Custom Code No  OS Platform and Distribution Macos Ventura  Mobile device Macbook air 2020 i3  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? So i am making an object detection projetc for school and i need help whenever i run this code this is the error that pops up. Please help it is due in a few days I have installed all neccesary modules, i think  Standalone code to reproduce the issue   Relevant log output  ",2023-05-23T22:52:30Z,stat:awaiting response type:support stale comp:model TF 1.5.0,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60684,please help,i beg,"Hi  , It seems the issue is related to tensorflow models. For models we have separate repo. Can you also post the issue here where our team can have a look into it. Could you please confirm the tensorflow version you have used.Also please check whether protobuf is installed and which version it is.You can find the required packages here needed for TF.  Please note that 1.x versions are not supported now. Request you to migrate to 2.x versions and preferably latest versions. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1865,"以下是一个github上的tensorflow下的一个issue, 标题是(FailedPreconditionError: . is not a directory)， 内容是 (Good evening. I am trying to use Hyperband Tuner from keras_tuner, bet when I try to use it I get a FailedPreconditionError while creating the tuner.    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: no    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10* 64bit    **TensorFlow installed from (source or binary)**: pip install tensorflow in command line    **TensorFlow version (use command below)**: 2.12.0    **Python version**: 3.11.3    **Exact command to reproduce**: `import tensorflow as tf import keras_tuner print(tf.version.GIT_VERSION, tf.version.VERSION) def hyperband_objective_autoencoder():     return 1 hyperband_tuner = keras_tuner.Hyperband(     hypermodel = hyperband_objective_autoencoder )` Output: `v2.12.0rc112g0db597d0d75 2.12.0  FailedPreconditionError                   Traceback (most recent call last) Cell In[1], line 8       5 def hyperband_objective_autoencoder():       6     return 1 > 8 hyperband_tuner = keras_tuner.Hyperband(       9     hypermodel = hyperband_objective_autoencoder      10 ) File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\localpackages\Python311\sitepackages\keras_tuner\tuners\hyperband.py:418, in Hyperband.__init__(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)     391 def __init__(     392     self,     393     hypermodel=None,    (...)     404     **kwargs     405 ):     406     oracle = HyperbandO)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Floppa2003,FailedPreconditionError: . is not a directory,"Good evening. I am trying to use Hyperband Tuner from keras_tuner, bet when I try to use it I get a FailedPreconditionError while creating the tuner.    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: no    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10* 64bit    **TensorFlow installed from (source or binary)**: pip install tensorflow in command line    **TensorFlow version (use command below)**: 2.12.0    **Python version**: 3.11.3    **Exact command to reproduce**: `import tensorflow as tf import keras_tuner print(tf.version.GIT_VERSION, tf.version.VERSION) def hyperband_objective_autoencoder():     return 1 hyperband_tuner = keras_tuner.Hyperband(     hypermodel = hyperband_objective_autoencoder )` Output: `v2.12.0rc112g0db597d0d75 2.12.0  FailedPreconditionError                   Traceback (most recent call last) Cell In[1], line 8       5 def hyperband_objective_autoencoder():       6     return 1 > 8 hyperband_tuner = keras_tuner.Hyperband(       9     hypermodel = hyperband_objective_autoencoder      10 ) File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\localpackages\Python311\sitepackages\keras_tuner\tuners\hyperband.py:418, in Hyperband.__init__(self, hypermodel, objective, max_epochs, factor, hyperband_iterations, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)     391 def __init__(     392     self,     393     hypermodel=None,    (...)     404     **kwargs     405 ):     406     oracle = HyperbandO",2023-05-23T20:49:49Z,stat:awaiting response type:bug TF 2.12,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60682,", I was facing a different issue while executing the mentioned code on tensorflow v2.12. Kindly find the gist of it here and provide the dependencies.  Generally the error typically indicates that the system is not in state to execute the operation and requires preconditions to be met before successfully executing current operation. https://www.tensorflow.org/api_docs/python/tf/errors/FailedPreconditionError Thank you!","> , I was facing a different issue while executing the mentioned code on tensorflow v2.12. Kindly find the gist of it here and provide the dependencies. Thank you! Sorry, I solved the problem already. Turns out that tensorflow doesn't support nonenglish letters in directory paths.",Are you satisfied with the resolution of your issue? Yes No
812,"以下是一个github上的tensorflow下的一个issue, 标题是(api_compatibility_test fails on Python 3.11)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/tools/api/tests:api_compatibility_test fails on Python 3.11 See https://github.com/tensorflow/tensorflow/actions/runs/5053005537/jobs/9066419128step:6:5566  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,api_compatibility_test fails on Python 3.11,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/tools/api/tests:api_compatibility_test fails on Python 3.11 See https://github.com/tensorflow/tensorflow/actions/runs/5053005537/jobs/9066419128step:6:5566  Standalone code to reproduce the issue   Relevant log output  ,2023-05-23T16:40:28Z,stat:awaiting tensorflower type:bug type:build/install comp:mkl subtype: ubuntu/linux,open,0,3,https://github.com/tensorflow/tensorflow/issues/60679,"Hi  , I have tested the build on Ubuntu Aarch64 VM and the build failed.Logs are attached below. 60679_logs(Aarch build).txt"," , MKL   CC toplay ", Your build environment was not valid which is why it failed. You cannot use a generic Ubuntu AARCH64 VM.
1899,"以下是一个github上的tensorflow下的一个issue, 标题是(AdamW optimizer crashes on Model.fit() for tensorflow-macos v2.14.0-dev20230518)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0dev20230518  Custom Code Yes  OS Platform and Distribution MacOS 12.5.1 running on ARM architecture [M1 Pro chip]  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When calling Model.compile() with the AdamW optimizer, a warning is thrown saying that v2.11+ optimizers have a known slowdown on M1/M2 devices, and so the backend attempts to fallback to a legacy version. However, no legacy version of the AdamW optimizer exists. In a previous tfmacos version 2.12, this lead to an error during Model.compile() [see issue https://github.com/tensorflow/tensorflow/issues/60652]. In the current nightly, this error is not thrown  however, after calling model.compile(), the attribute model.optimizer is set to string 'adamw' instead of an optimizer object. Later, when we call model.fit(), this leads to an AttributeError, because model.optimizer.minimize() does not exist when model.optimizer is a string. Expected behaviour: correctly compile the model with either a v2.11+ optimiser without slowdown, or a legacycompatible implementation of the AdamW optimizer. I could attempt to contribute this  but there may be a steep learning curve! Then the model will train correctly with a valid AdamW optimizer when calling model.fit(). Note: a warning message suggests using the optimizer located at `tf.keras.optimizers.legacy.AdamW`, but this does not ex)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sbmenary,AdamW optimizer crashes on Model.fit() for tensorflow-macos v2.14.0-dev20230518,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0dev20230518  Custom Code Yes  OS Platform and Distribution MacOS 12.5.1 running on ARM architecture [M1 Pro chip]  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When calling Model.compile() with the AdamW optimizer, a warning is thrown saying that v2.11+ optimizers have a known slowdown on M1/M2 devices, and so the backend attempts to fallback to a legacy version. However, no legacy version of the AdamW optimizer exists. In a previous tfmacos version 2.12, this lead to an error during Model.compile() [see issue https://github.com/tensorflow/tensorflow/issues/60652]. In the current nightly, this error is not thrown  however, after calling model.compile(), the attribute model.optimizer is set to string 'adamw' instead of an optimizer object. Later, when we call model.fit(), this leads to an AttributeError, because model.optimizer.minimize() does not exist when model.optimizer is a string. Expected behaviour: correctly compile the model with either a v2.11+ optimiser without slowdown, or a legacycompatible implementation of the AdamW optimizer. I could attempt to contribute this  but there may be a steep learning curve! Then the model will train correctly with a valid AdamW optimizer when calling model.fit(). Note: a warning message suggests using the optimizer located at `tf.keras.optimizers.legacy.AdamW`, but this does not ex",2023-05-23T13:38:07Z,stat:awaiting response type:bug stale comp:keras,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60673,", I tried to execute the code on tensorflow 2.12 and tfnightly on colab, ubuntu and macos. Observed that the code got executed without any errors on both colab and ubuntu environments. Kindly find the gist and below screenshot for the reference  But whereas on tensorflowmacos, it is failing with the mentioned error.  As it is failing only on tensorflowmacos, we request to raise the concern on the macosapple forum for the quick resolution. Thank you!","Hi , thanks for reproducing the error and your response. Sure  I'm happy to raise this on the macos forum instead. Does this mean that tensorflowmacos is not maintained here but externally, and so I should raise future issues on the apple forum if they are problems with tensorflowmacos and not tensorflow? Thanks, Ste",", Yeah, as suggested it would be better, if you raise the issue on apple macos platform. If it is the tensorflow related issue, you can raise the issue here in this repo. As the issue is only on the tensorflowmacos, it is suggested to raise the issue in that forum. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Okay  thanks for the information  doing this now and happy to close the issue, and will raise future tfmacos problems there as well  thanks for your help!",Are you satisfied with the resolution of your issue? Yes No
695,"以下是一个github上的tensorflow下的一个issue, 标题是(//tensorflow/python/ops/ragged:ragged_cross_op_test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.8.13  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? Test sometimes fails with segfault  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,elfringham,//tensorflow/python/ops/ragged:ragged_cross_op_test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.8.13  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? Test sometimes fails with segfault  Standalone code to reproduce the issue   Relevant log output  ,2023-05-23T09:42:28Z,stat:awaiting tensorflower type:bug type:build/install comp:mkl subtype: ubuntu/linux,open,0,3,https://github.com/tensorflow/tensorflow/issues/60670,"I tried the build and it's failed. Please refer the attached logs below. 60670_logs.txt MKL  CC  , toplay ",x86 reproduction log https://source.cloud.google.com/results/invocations/1b8efc294d7b44e2a66e56071b03a3a0/log AARCH64 reproduction log https://github.com/tensorflow/tensorflow/actions/runs/5395781377/jobs/9798627617step:5:7398,tf flaky test
1902,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory)， 内容是 (Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory T4  Current Behaviour? **I had been training faster_rcnn_resnet50_v1_640x640_coco17_tpu8 model on my custom dataset in colab, all paths are correctly set in config file. Issue is on both GPU and CPU.   fine_tune_checkpoint: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/pretrained_model/faster_rcnn_resnet50_v1_640x640_coco17_tpu8/checkpoint/ckpt0""   fine_tune_checkpoint_type: ""detection""   data_augmentation_options {     random_horizontal_flip {     }   }   max_number_of_boxes: 100   unpad_groundtruth_tensors: false   use_bfloat16: true   works only on TPUs } train_input_reader: {   label_map_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/label_map.pbtxt""   tf_record_input_reader {     input_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/train/*.tfrecord""   } } eval_config: {   metrics_set: ""coco_detection_metrics""   use_moving_averages: false   batch_size: 1; } eval_input_reader: {   label_map_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/label_map.pbtxt""   shuffle: false   num_epochs: 1   tf_record_input_reader {     input_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/val/val.tfrecord""   } }** Its probably config file but I have set all parameters correctly and copy pasted absolute paths.  Stan)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",dspy,Pranil51,tensorflow.python.framework.errors_impl.NotFoundError: ; No such file or directory,"Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.8  GPU model and memory T4  Current Behaviour? **I had been training faster_rcnn_resnet50_v1_640x640_coco17_tpu8 model on my custom dataset in colab, all paths are correctly set in config file. Issue is on both GPU and CPU.   fine_tune_checkpoint: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/pretrained_model/faster_rcnn_resnet50_v1_640x640_coco17_tpu8/checkpoint/ckpt0""   fine_tune_checkpoint_type: ""detection""   data_augmentation_options {     random_horizontal_flip {     }   }   max_number_of_boxes: 100   unpad_groundtruth_tensors: false   use_bfloat16: true   works only on TPUs } train_input_reader: {   label_map_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/label_map.pbtxt""   tf_record_input_reader {     input_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/train/*.tfrecord""   } } eval_config: {   metrics_set: ""coco_detection_metrics""   use_moving_averages: false   batch_size: 1; } eval_input_reader: {   label_map_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/label_map.pbtxt""   shuffle: false   num_epochs: 1   tf_record_input_reader {     input_path: ""/content/drive/MyDrive/Obj_Detection/Faster_RCNN/data/val/val.tfrecord""   } }** Its probably config file but I have set all parameters correctly and copy pasted absolute paths.  Stan",2023-05-23T02:51:54Z,stat:awaiting response type:others subtype:windows TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60666,"Hi  , Tensorflow wont support GPU on Windows for versions TF>=2.11. You have to use WSL2 to enable GPU support.  Please refer the source for more details. However as you confirmed you are facing same problem with CPU also,I would like to get more context to have a look into the problem. Attached colab link has many dependencies from getting the data from your drive and custom models which are not sufficient to debug the issue.This might need access to source code related to TF and how it has been implemented. I Request you to submit minimal code snippet to reproduce the issue. This seems there is an issue with the distribution strategy you have implemented.May be providing more context with code snippet can enable us to dig the issue and resolve it. Thanks!","> Hi  , >  > Tensorflow wont support GPU on Windows for versions TF>=2.11. You have to use WSL2 to enable GPU support. Please refer the source for more details. >  > However as you confirmed you are facing same problem with CPU also,I would like to get more context to have a look into the problem. Attached colab link has many dependencies from getting the data from your drive and custom models which are not sufficient to debug the issue.This might need access to source code related to TF and how it has been implemented. I Request you to submit minimal code snippet to reproduce the issue. >  > This seems there is an issue with the distribution strategy you have implemented.May be providing more context with code snippet can enable us to dig the issue and resolve it. >  > Thanks! Hello , Thanks for the response. I import tensorflow as usual in colab only by using !pip install tensorflow. Also I havent got issue on windows, but on colab only. ","Hi  , Could you please confirm the model you are using and how you have configured. I am unable to replicate the issue in colab as per attached gist. Thanks!",I solved error by coppying project relevant directories to content folder from gdrive. ,"Hi  , If the issue resolved could you please spare some time to close the issue. Thanks!",Are you satisfied with the resolution of your issue? Yes No
1564,"以下是一个github上的tensorflow下的一个issue, 标题是(Memory leak in model fit with dataset from generator)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10, 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version None  GPU model and memory None  Current Behaviour? When creating a dataset from the generator, using Tensorflow V2.12.0 with Python 3.11, some memory is not released after training on each batch, leading to a linear increase in memory usage during the model fit step.  Standalone code to reproduce the issue  I then ran the code in a container and logged the memory usage.  shell With Python 3.11, I see an increment in memory usage over time, while it remains the same for Python 3.10. I am allocating the exact same resources to both of the containers. The columns are respectively: Seconds into the fitting step, memory usage tf_2.12_python_3.10, memory usage tf_2.12_python_3.11.  5	254.9	288.9 10	254.9	291 15	254.9	293.1 20	254.9	294.8 25	254.9	296.4 30	254.9	298.5 35	254.9	300.3 40	254.9	301.8 45	254.9	304 50	254.9	306.2 55	254.9	308.3 60	254.9	310.6 65	254.9	312.5 70	254.9	314.8 75	254.9	316.5 80	254.9	317.9 85	254.6	319.5 90	254.2	320.4 95	253.8	321.5 100	253	323.1 ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,arianmaghsoudnia,Memory leak in model fit with dataset from generator,"Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10, 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version None  GPU model and memory None  Current Behaviour? When creating a dataset from the generator, using Tensorflow V2.12.0 with Python 3.11, some memory is not released after training on each batch, leading to a linear increase in memory usage during the model fit step.  Standalone code to reproduce the issue  I then ran the code in a container and logged the memory usage.  shell With Python 3.11, I see an increment in memory usage over time, while it remains the same for Python 3.10. I am allocating the exact same resources to both of the containers. The columns are respectively: Seconds into the fitting step, memory usage tf_2.12_python_3.10, memory usage tf_2.12_python_3.11.  5	254.9	288.9 10	254.9	291 15	254.9	293.1 20	254.9	294.8 25	254.9	296.4 30	254.9	298.5 35	254.9	300.3 40	254.9	301.8 45	254.9	304 50	254.9	306.2 55	254.9	308.3 60	254.9	310.6 65	254.9	312.5 70	254.9	314.8 75	254.9	316.5 80	254.9	317.9 85	254.6	319.5 90	254.2	320.4 95	253.8	321.5 100	253	323.1 ``` ",2023-05-22T16:10:35Z,stat:awaiting response stale type:performance TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60659,", Thank you for reporting the issue. Could you please take a look at this relevant issue threads https://github.com/tensorflow/tensorflow/issues/58606, https://github.com/tensorflow/tensorflow/issues/57690, https://github.com/tensorflow/tensorflow/issues/56624. Also I would suggest you to have look at this article tf.data.Dataset generators with parallelization which may help you to solve your memory related issue. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
784,"以下是一个github上的tensorflow下的一个issue, 标题是(Fatal Python error: Aborted )， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.1 and 2.13.0.rc0  Custom Code Yes  OS Platform and Distribution Windows 11 22H2  Mobile device _No response_  Python version 3.10.11  Bazel version   GCC/Compiler version   CUDA/cuDNN version None  GPU model and memory None  Current Behaviour? TensorFlow crashes. I cannot currently reproduce it, but was able to catch one of many stack traces before it stopped being reproducible.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,bersbersbers,Fatal Python error: Aborted ,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.1 and 2.13.0.rc0  Custom Code Yes  OS Platform and Distribution Windows 11 22H2  Mobile device _No response_  Python version 3.10.11  Bazel version   GCC/Compiler version   CUDA/cuDNN version None  GPU model and memory None  Current Behaviour? TensorFlow crashes. I cannot currently reproduce it, but was able to catch one of many stack traces before it stopped being reproducible.  Standalone code to reproduce the issue   Relevant log output  ",2023-05-21T06:33:33Z,stat:awaiting response type:bug stale subtype:windows TF 2.13,closed,0,17,https://github.com/tensorflow/tensorflow/issues/60648,"Summarizing a few more observations:  I reinstalled Python 3.11.3 with TensorFlow 2.13.0rc0 and the issue is certainly still there.  I am sure I could consistently reproduce the issue with the code above. The issue would show instantly.  At the moment, however, it seems I cannot reproduce it at all with the code above.  The issue appears consistently when running my full test suite, however, that involves hourlong model training before.  Just the failing test alone seems to also crash sometimes, but it seems to be inconsistent and/or to take a while. See this test output where you see how many examples are working before the crash:   ","More info! I have changed my code a little bit and now I can reproduce the issue independently of my large code base. The key was to start with more data at once. I hope that is still the same issue as the stack trace has changed few some runs, but it also leads to an access violation:  The issue can now be reproduced in two ways: 1. `python test_crash.py`  Note that ""Done"" is never printed, but we do not get an error message, either. 2. `pytest s test_crash.py` Stack trace with 99 images:   Stack trace with 5 images:  Not sure why pytest reports all those loaded modules. I have them installed, but I don't see where I load them anywhere. I am running the code from an folder with only the test code and no subfolders. Here's my `pip list` for completeness: ","Hi  , Thanks for reporting the issue. Unfortunately I am not sure whether the issue is related to Tensorflow or the `tfkerasvis` library. The library `tfkerasvis` is not maintained by us. Hence i request you to provide a code snippet independent of other tools to replicate the behaviour. Then we can definitely able to look into the issue. Thanks!"," thanks for your reply, I will try to reproduce the issue without `tfkerasvis`. However:  Looking at https://github.com/keisen/tfkerasvis/blob/f2c65a51748468ab17279dca820999d767d7c434/tf_keras_vis/scorecam.py, I see only the TF public API being used. What would be different if I simply copied these 200 lines of code into my own reproducer, would that be any different?  Phrased another way, what could `tfkerasvis`s ScoreCAM implementation possibly do that would make you conclude that the segmentation fault deep inside TensorFlow would be caused by their use of the public TF API, and not TF itself? Anyway, as I said, I will try to come up with a reproducer that does not rely on `tfkerasvis`.","Hi  , As mentioned in the above comment, It would be better to understand if the issue is happening with only Tensorflow along with the Tensorflow code usage of `ScoreCAM`( not through tfkerasvis package). Sometimes the issue might be due to the incompatible package/code dependency between both."," I was able to reduce the code to this, independent of `tfkerasvis`:  The output of the two commands is this: `python test_crash.py`:  (`Done` is not printed) `python m pytest s test_crash.py`  (Note `Windows fatal exception: access violation`) The same code with 99, 50, 40, 38 examples crashes the same way. 25, 35, 37 seems to work. So this might be an OOM issue. However, running with the maximum working number of 37 examples leads to this memory graph, so I don't necessarily think I am running out of memory: !image In addition, if this was an OOM problem, I would expected a related error message. Yes, I see the warnings, but `pytest` crashes with an access violation, which I am not associating with OOM, really.","I'm able to get the output in colab, here is the Gist of it https://gist.github.com/sachinprasadhs/5d82d9e91da0e7fc6284612e9b87b95c. It did not consume much of memory either. It took me ~10 seconds in my M1 Mac.","I have since been to run the same code, in the same system, successfully, but am still able to repro the original problem. Where it works: Windows 10 native, 32 GB RAM Where it fails: Windows 11 via HyperV (hosted on the above Windows 10), 16 GB RAM I will experiment a bit more with the RAM allocation of the VM, but that may take some two weeks."," , Can you please look into this, issue seems to be happening only on specific windows version.","Hi  I ran the code on a machine with 8GB RAM with 4 cores and it worked fine. The snippet is shown below. I think there might be some other jobs running in the background which is sharing the RAM space.  >>> import tensorflow as tf >>> model = tf.keras.applications.VGG19(classes=2, weights=None) 20230607 21:30:34.503333: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory. 20230607 21:30:35.064035: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory. 20230607 21:30:35.320642: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 411041792 exceeds 10% of free system memory. 20230607 21:30:35.972187: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory. 20230607 21:30:36.089787: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory. >>> seed_inputs = [tf.zeros((99, *model.input.shape[1:]))] >>> print(""Start"")   Using python m pytest s test_crash.py Start >>> model(seed_inputs)  >>> print(""Done"")   Using python test_crash.py, Done is never printed! Done >>>",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"> I will experiment a bit more with the RAM allocation of the VM, but that may take some two weeks.",Something new to report?,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Not directly related, but search engines lead here, so just in case it helps someone: ""Fatal Python error: Aborted"" may also come from the incompatibility between your versions of CUDA and Tensorflow. If you ended up here with similar symptoms, it may be a good idea to doublecheck your versions according to these tables :) It's probably not the issue described above though, as I got dynamic linking errors instead of an access violation. Everything else was pretty much the same, this MRE even managed to reproduce the crash too."
1853,"以下是一个github上的tensorflow下的一个issue, 标题是(""Improve Performance of Convolutional Neural Networks on GPU"")， 内容是 (Currently, TensorFlow's performance for convolutional neural networks (CNNs) on GPU can be further optimized. The goal of this issue is to identify and implement improvements that enhance the speed and efficiency of CNN computations on GPU devices. This includes optimizing convolutional and pooling operations, leveraging GPUspecific optimizations, and exploring techniques such as kernel fusion and memory access optimizations. Expected Outcome: By addressing this issue, we aim to achieve significant performance improvements for CNN workloads on GPU, enabling faster training and inference times for deep learning models. This will enhance the overall efficiency and scalability of TensorFlow for CNNbased applications and empower researchers and practitioners to train and deploy models more effectively. Help Needed: Contributors with expertise in GPU programming, CUDA, and deep learning optimization techniques are encouraged to collaborate on this issue. The community's insights and contributions are valuable in identifying bottlenecks, proposing optimizations, and implementing efficient GPUaccelerated CNN operations in TensorFlow. Additionally, suggestions and insights from domain experts, performance profiling, and benchmarking results are welcome to drive this improvement initiative. Let's work together to make TensorFlow's GPU performance for CNNs even better! Please note that this issue is currently open and up for contributions. Feel free to join the discussion and contribute your expertise towards enhancing the performance of convolutional neural networks on GPU in TensorFlow.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Abhishekagrawal1404,"""Improve Performance of Convolutional Neural Networks on GPU""","Currently, TensorFlow's performance for convolutional neural networks (CNNs) on GPU can be further optimized. The goal of this issue is to identify and implement improvements that enhance the speed and efficiency of CNN computations on GPU devices. This includes optimizing convolutional and pooling operations, leveraging GPUspecific optimizations, and exploring techniques such as kernel fusion and memory access optimizations. Expected Outcome: By addressing this issue, we aim to achieve significant performance improvements for CNN workloads on GPU, enabling faster training and inference times for deep learning models. This will enhance the overall efficiency and scalability of TensorFlow for CNNbased applications and empower researchers and practitioners to train and deploy models more effectively. Help Needed: Contributors with expertise in GPU programming, CUDA, and deep learning optimization techniques are encouraged to collaborate on this issue. The community's insights and contributions are valuable in identifying bottlenecks, proposing optimizations, and implementing efficient GPUaccelerated CNN operations in TensorFlow. Additionally, suggestions and insights from domain experts, performance profiling, and benchmarking results are welcome to drive this improvement initiative. Let's work together to make TensorFlow's GPU performance for CNNs even better! Please note that this issue is currently open and up for contributions. Feel free to join the discussion and contribute your expertise towards enhancing the performance of convolutional neural networks on GPU in TensorFlow.",2023-05-20T08:28:55Z,stat:awaiting tensorflower type:performance TF 2.13,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60645,"To address the issue ""Improve Performance of Convolutional Neural Networks on GPU"" in TensorFlow, here are some potential areas to focus on for code improvements: 1. Utilize GPUAccelerated Operations:     Replace CPUbased operations with GPUaccelerated counterparts, such as `tf.nn.conv2d` for convolution and `tf.nn.max_pool` for pooling, to leverage the GPU's parallel processing capabilities. 2. Apply Optimized Convolution Implementations:     Explore optimized convolution algorithms, such as Winograd or FFTbased convolutions, that can provide faster computations for specific scenarios. 3. Employ Memory Optimization Techniques:     Implement memory optimizations, such as memory reuse and memory padding techniques, to minimize data transfers between the GPU and system memory, reducing memory overhead and improving performance. 4. Consider MixedPrecision Training:     Investigate the use of mixedprecision training, where lower precision (e.g., float16) is used for certain computations, to speed up training while maintaining acceptable accuracy. 5. Implement Kernel Fusion:     Investigate opportunities for kernel fusion, where multiple operations can be combined into a single GPU kernel, reducing memory accesses and improving computational efficiency. 6. Profile and Optimize Data Transfers:     Analyze data transfer patterns between the CPU and GPU, and optimize data movement to minimize unnecessary transfers and latency. These are just a few examples of areas to focus on for code improvements. It is recommended to further analyze the specific requirements and characteristics of your CNN models and identify bottlenecks using profiling tools to guide the optimization efforts. Additionally, leveraging TensorFlow's GPUspecific APIs and optimizing memory access patterns can further enhance the performance of CNN computations on GPU. Let's together collaborate in the TensorFlow community, participate in discussions, and consider the latest research and advancements in GPU optimization techniques to make meaningful contributions towards improving the performance of convolutional neural networks on GPU in TensorFlow.","To improve the performance of Convolutional Neural Networks (CNNs) on GPUs, you can consider implementing optimizations such as utilizing GPUspecific libraries, batching data, and using parallel computing techniques. Here's an example of Python code that showcases these optimizations:  In this code, we define a simple CNN model using the Keras API in TensorFlow. We compile the model with appropriate settings and load the CIFAR10 dataset. To improve GPU performance, we normalize the data, create a TensorFlow Dataset for efficient data loading, and enable GPU memory growth to avoid memory allocation errors. By utilizing GPUspecific libraries and implementing best practices for training CNNs, you can significantly improve the performance of your models on GPUs. Additionally, you can explore techniques like model parallelism and mixed precision training for further optimization. Remember to customize the code based on your specific use case and requirements.","Hi   The tensorflow provides Profiler to track the performance of TensorFlow models and  understand how the model performs on the host (CPU), the device (GPU), or on a combination of both the host and device(s). Also, we can use the profiler to do GPU performance analysis and get the maximum performance out of GPUs. Can you provide more specific context on the issue? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi   Thank you for reaching out with your question about improving the performance of Convolutional Neural Networks (CNNs) on GPUs. I appreciate your interest in optimizing the utilization of GPU resources. The code you provided is a great starting point for training a CNN model using TensorFlow and leveraging GPU capabilities. To further enhance the performance, I would recommend considering the following: 1. Utilize GPUspecific libraries: TensorFlow provides various GPUaccelerated operations and libraries, such as cuDNN, which can significantly speed up computations on GPUs. You can explore using these libraries to further optimize your CNN model. 2. Batch data processing: By batching your data, you can process multiple samples in parallel, taking advantage of the parallel processing capabilities of GPUs. This can lead to improved performance and faster training times. 3. Parallel computing techniques: TensorFlow provides functionalities like data parallelism and model parallelism, where you can distribute the computations across multiple GPUs or machines. This allows for increased scalability and can further boost the performance of your CNN models. Remember to customize these optimizations based on your specific use case and experiment with different techniques to find the best performance gains for your CNN model on GPUs. If you have any further questions or need more specific guidance, please feel free to provide additional context, and I'll be happy to assist you. Best regards, Abhishek","Most of the techniques listed, like mixed precision, are already implemented in TensorFlow. Others, like fusion, are enabled through XLA. Therefore I'll close this issue. If you have a specific optimization to improve performance of convolutions which you would like TensorFlow to implement, please file a new issue.",Are you satisfied with the resolution of your issue? Yes No
1257,"以下是一个github上的tensorflow下的一个issue, 标题是(""Improve GPU memory management for large-scale models"")， 内容是 (Currently, TensorFlow's GPU memory management can be challenging when training largescale models. This issue aims to improve the memory management strategies for GPU usage to optimize memory allocation and deallocation, reducing memory fragmentation and enabling more efficient training of large models. You can find this issue by going to the TensorFlow repository's ""Issues"" tab and using the search bar to search for the keywords ""GPU memory management largescale models."" Once you find the issue, make sure to read through the details and discussion to understand the specific challenges and proposed solutions. Feel free to contribute to this issue by commenting on it, discussing possible approaches, or even submitting a pull request with your proposed changes. Remember to familiarize yourself with the contribution guidelines and any specific instructions mentioned in the issue before getting started. Good luck, and I hope you find this issue interesting and valuable for your contributions to TensorFlow!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Abhishekagrawal1404,"""Improve GPU memory management for large-scale models""","Currently, TensorFlow's GPU memory management can be challenging when training largescale models. This issue aims to improve the memory management strategies for GPU usage to optimize memory allocation and deallocation, reducing memory fragmentation and enabling more efficient training of large models. You can find this issue by going to the TensorFlow repository's ""Issues"" tab and using the search bar to search for the keywords ""GPU memory management largescale models."" Once you find the issue, make sure to read through the details and discussion to understand the specific challenges and proposed solutions. Feel free to contribute to this issue by commenting on it, discussing possible approaches, or even submitting a pull request with your proposed changes. Remember to familiarize yourself with the contribution guidelines and any specific instructions mentioned in the issue before getting started. Good luck, and I hope you find this issue interesting and valuable for your contributions to TensorFlow!",2023-05-20T08:20:17Z,stat:awaiting tensorflower type:feature comp:gpu,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60644,"To address the issue of improving GPU memory management for largescale models in TensorFlow, several approaches can be considered. Here's an outline of the code changes you could make: 1. Utilize Tensorflow's memory growth feature:  Enabling memory growth allows the GPU memory allocation to be more flexible, preventing TensorFlow from allocating the entire GPU memory upfront. 2. Implement memory optimization techniques:  Use mixedprecision training: Reduce memory usage by performing computations with lower precision (e.g., float16) when possible.  Employ gradient checkpointing: Trade off memory consumption with increased computation by checkpointing intermediate activations during backpropagation.  Implement model parallelism: Partition large models across multiple GPUs, reducing the memory requirement per GPU. 3. Enable eager execution:  Eager execution can help you better understand the memory requirements of your operations and enable more granular control over memory usage. 4. Use TensorFlow Distributed Strategy: If you have access to a multiGPU or distributed environment, consider utilizing TensorFlow's Distributed Strategy, such as `tf.distribute.MirroredStrategy` or `tf.distribute.experimental.MultiWorkerMirroredStrategy`, to distribute the model across multiple GPUs or machines. This can help manage memory by spreading the workload. These are general approaches to improve GPU memory management for largescale models in TensorFlow. The specific implementation details may vary depending on your model architecture, training process, and requirements. It's recommended to thoroughly test and benchmark these changes on your specific use case to ensure they effectively address the memory management issue.","Thanks for filing feature request. TensorFlow as a product always aims to improve the quality of the product by adding new features and constantly  fixing the bugs to ensure best experience for users. Regarding the reported issue on GPU memory management, including the steps you have mentioned above, you can make use of our distribution strategies when multiple GPUs are available. Below is the document for more details. https://www.tensorflow.org/guide/distributed_training","There is no concrete bug or request brought up by this GitHub issue. We do try to reduce GPU memory consumption of TensorFlow and XLA, but this issue does not list any concrete memory management bugs or suggestions. The second post is a suggestion to users of TF, and not a suggestion for how TF itself could be improved. So closing this issue."
1175,"以下是一个github上的tensorflow下的一个issue, 标题是(Add MLIR side effects to `tf.XlaCallModule`.)， 内容是 (This change introduces updates to the `tf.XlaCallModule` op in order to support `jax2tf` native serialization. The `tf.XlaCallModule` op contains the StableHLO module, which may involve calling TF host callback functions through `stablehlo.custom_call`. To enable proper functionality, the following modifications were made: 1. The `Pure` trait in the automatically generated `tf.XlaCallModule` op's definition has been replaced with the `MemoryEffects` trait. 2. The `isStateful` flag has been set in the op declaration of `XlaCallModule` to indicate that it has stateful behavior. 3. The TensorFlow side effect analysis has been updated to recursively analyze the TF host callback functions invoked by `tf.XlaCallModule`. These changes ensure better compatibility and alignment with the `jax2tf` native serialization process, allowing for improved handling of side effects and seamless integration with TensorFlow. PiperOriginRevId: 533635753)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,Abhishekagrawal1404,Add MLIR side effects to `tf.XlaCallModule`.,"This change introduces updates to the `tf.XlaCallModule` op in order to support `jax2tf` native serialization. The `tf.XlaCallModule` op contains the StableHLO module, which may involve calling TF host callback functions through `stablehlo.custom_call`. To enable proper functionality, the following modifications were made: 1. The `Pure` trait in the automatically generated `tf.XlaCallModule` op's definition has been replaced with the `MemoryEffects` trait. 2. The `isStateful` flag has been set in the op declaration of `XlaCallModule` to indicate that it has stateful behavior. 3. The TensorFlow side effect analysis has been updated to recursively analyze the TF host callback functions invoked by `tf.XlaCallModule`. These changes ensure better compatibility and alignment with the `jax2tf` native serialization process, allowing for improved handling of side effects and seamless integration with TensorFlow. PiperOriginRevId: 533635753",2023-05-20T08:16:39Z,,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60643,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request."
1410,"以下是一个github上的tensorflow下的一个issue, 标题是(Add structured graph fuzzer)， 内容是 (Adds a fuzzer that creates computation graphs with a focus on making graphs that run proper. This is in comparison to the existing graph fuzzers (the ones in the same file) which struggle with coming up with graphs that are runnable. I think the existing graphs struggle with two issues:  reference names are just arbitrary strings, so it's likely the fuzzer will not have references correct  am not sure if ops are strings in the structs, but if so, the existing fuzzers may have a lot of ops that are invalid in that it will be a fuzzergenerated string (likely not match with the ops that are available) This fuzzer overcomes these by ensuring references always happen to names that are affiliated with nodes in the graph and also ops that are available as ops in tensorflow. Currently, it does have limitations in that not all graphs produced by this fuzzer will be valid graphs to run. However, many of them will and I've ensured coverage happens for a lot of the ops defined in the ops vector of the fuzzer. There are several areas it can be improved and it would be nice to do so, and I've left some comments in the code about this. It would be nice to iterate on these improvements though.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,DavidKorczynski,Add structured graph fuzzer,"Adds a fuzzer that creates computation graphs with a focus on making graphs that run proper. This is in comparison to the existing graph fuzzers (the ones in the same file) which struggle with coming up with graphs that are runnable. I think the existing graphs struggle with two issues:  reference names are just arbitrary strings, so it's likely the fuzzer will not have references correct  am not sure if ops are strings in the structs, but if so, the existing fuzzers may have a lot of ops that are invalid in that it will be a fuzzergenerated string (likely not match with the ops that are available) This fuzzer overcomes these by ensuring references always happen to names that are affiliated with nodes in the graph and also ops that are available as ops in tensorflow. Currently, it does have limitations in that not all graphs produced by this fuzzer will be valid graphs to run. However, many of them will and I've ensured coverage happens for a lot of the ops defined in the ops vector of the fuzzer. There are several areas it can be improved and it would be nice to do so, and I've left some comments in the code about this. It would be nice to iterate on these improvements though.",2023-05-18T16:50:36Z,ready to pull size:L comp:core,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60633,CC  ,I like it! :tada: 
432,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow not running)， 内容是 (Hello, I am trying to create a BERT token using the tensorflow_hub library for python but whenever I run the code, it just gets stuck doesn't show any response. Here's a screenshot to help: !Screen Shot 20230518 at 18 39 53)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,moses-mbaga,TensorFlow not running,"Hello, I am trying to create a BERT token using the tensorflow_hub library for python but whenever I run the code, it just gets stuck doesn't show any response. Here's a screenshot to help: !Screen Shot 20230518 at 18 39 53",2023-05-18T15:44:58Z,stat:awaiting response type:build/install stale,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60630,"Hi mbaga , From the error log it seems the error is related to conda environment. If you are using conda environment while installing it will prompt to ask some thing like `Do you wish the installer to initialize Miniconda3 by running conda init? [yes|no]:` and you need to type `yes` there. Once it was done then run `source ~/.bashrc` to enable conda command and then run `conda activate ` to activate it.You can find conda environment creation steps here for reference. If followed above steps and still facing the problem then you can try `conda init ` (eg: `conda init bash`) ,the `SHELL_NAME` can be `bash` or any others listed in the log. Please also refer to the conda websource here for more details. After following above steps if still having problem please let us know. Also please fill the issue at tensorflowhub repo here if the issue is only specific to tensorflowhub.Also request you to follow the issue template for reporting the issue which can be found here for tensorflow and tfhub . Thanks!","Noted, Let me try the above then I will get back to you. Thanks!","mbaga , Could you please confirm if the problem resolved for you. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
854,"以下是一个github上的tensorflow下的一个issue, 标题是(control_flow_ops_test unit test is flaky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/ops/parallel_for:control_flow_ops_test fails occasionally due to difference exceeding tolerance. See https://github.com/tensorflow/tensorflow/actions/runs/5012758324/jobs/8985082872step:5:29789  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,control_flow_ops_test unit test is flaky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.9.16  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? //tensorflow/python/ops/parallel_for:control_flow_ops_test fails occasionally due to difference exceeding tolerance. See https://github.com/tensorflow/tensorflow/actions/runs/5012758324/jobs/8985082872step:5:29789  Standalone code to reproduce the issue   Relevant log output  ,2023-05-18T15:22:49Z,stat:awaiting tensorflower type:bug type:build/install comp:ops subtype: ubuntu/linux,open,0,3,https://github.com/tensorflow/tensorflow/issues/60629,Fixed by merge of CC(Mark control_flow_ops_test as flaky) ,Are you satisfied with the resolution of your issue? Yes No," CC(Mark control_flow_ops_test as flaky) was undone along with removing flaky flag from other tests, so this issue still needs addressing."
1886,"以下是一个github上的tensorflow下的一个issue, 标题是(PyCharm cannot resolve Keras and Bidirectional and TimeDistributed)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0=mkl_py38ha5c4042_0  Custom Code Yes  OS Platform and Distribution Windows 10.0.22621 Build 22621  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.2 cudnn=8.1.0  GPU model and memory NVIDIA GeForce RTX 2060  6 GB GDDR6  Current Behaviour? I tried to `import` `tensorflow.keras` but `PyCharm` could not resolve it. So I tried to use `tensorflow.python.keras` (which is not advised), I could import a few modules but not `Bidirectional `or `TimeDistributed`. I have already deleted my environment and builed it from scratch with installing with pip and conda.  !PyCharm I tried the following issues, but sadly no succes:  https://github.com/tensorflow/tensorflow/issues/54180  https://github.com/microsoft/pylancerelease/issues/1066   Another issue while trying to get tensorflow.version  I tried to run `python c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`, but threw the following:  > Traceback (most recent call last): >   File ""C:\Users\lilon\miniconda3\envs\TETB\lib\sitepackages\requests\compat.py"", line 11, in  >     import chardet > ModuleNotFoundError: No module named 'chardet' >  > During handling of the above exception, another exception occurred: >  > Traceback (most recent call last): >   File """", line 1, in  >   File ""C:\Users\lilon\miniconda3\envs\TETB\lib\sitepackages\tensorflow\__init__.py"", line 52, in  >     from ._api.v2 import compat >   File ""C:\Users\lilon\mi)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lrstolk,PyCharm cannot resolve Keras and Bidirectional and TimeDistributed,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0=mkl_py38ha5c4042_0  Custom Code Yes  OS Platform and Distribution Windows 10.0.22621 Build 22621  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.2 cudnn=8.1.0  GPU model and memory NVIDIA GeForce RTX 2060  6 GB GDDR6  Current Behaviour? I tried to `import` `tensorflow.keras` but `PyCharm` could not resolve it. So I tried to use `tensorflow.python.keras` (which is not advised), I could import a few modules but not `Bidirectional `or `TimeDistributed`. I have already deleted my environment and builed it from scratch with installing with pip and conda.  !PyCharm I tried the following issues, but sadly no succes:  https://github.com/tensorflow/tensorflow/issues/54180  https://github.com/microsoft/pylancerelease/issues/1066   Another issue while trying to get tensorflow.version  I tried to run `python c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`, but threw the following:  > Traceback (most recent call last): >   File ""C:\Users\lilon\miniconda3\envs\TETB\lib\sitepackages\requests\compat.py"", line 11, in  >     import chardet > ModuleNotFoundError: No module named 'chardet' >  > During handling of the above exception, another exception occurred: >  > Traceback (most recent call last): >   File """", line 1, in  >   File ""C:\Users\lilon\miniconda3\envs\TETB\lib\sitepackages\tensorflow\__init__.py"", line 52, in  >     from ._api.v2 import compat >   File ""C:\Users\lilon\mi",2023-05-17T19:50:10Z,stat:awaiting response type:bug stale type:others comp:keras TF 2.13,closed,0,9,https://github.com/tensorflow/tensorflow/issues/60617,"Hi  , I have replicated the reported behaviour on Colab and attached screenshot below. https://screenshot.googleplex.com/4hm4Zj6zXvEvasR You can use the below code to get the Tensorflow version. `!python c ""import tensorflow as tf; print(tf.__version__)"" `","> Hi  , >  > I have replicated the reported behaviour on Colab and attached screenshot below. >  > https://screenshot.googleplex.com/4hm4Zj6zXvEvasR >  > You can use the below code to get the Tensorflow version. >  > `!python c ""import tensorflow as tf; print(tf.__version__)"" ` Thanks for the fast reply  ! I tried to open your link, but sadly cannot open it, it brings me to a single sign on page.  When I try your code, it does not recognize the exclamation mark in the PyTorch terminal or Anaconda Promt. When I use your code in a jupyter notebook, it gives the same error as I mentioned earlier. If I ask pip show tensorflow, it gives me: Version: 2.10.1  **EDIT** I reinstalled my entire env, the Anaconda shell gives me: 2.10.0  The powerschell is able to find keras tho:  >python c ""import tensorflow.keras as k; print(k.__version__)"" >2.10.0 On my old laptop, PyCharm is able to find keras, Bidirectional and TimeDistributed,  I run the same environment with Tensorflow==2.3.0", I cannot see your screenshot. ,"Hi  , I am attaching a colab gist for your reference. You please execute it and observe the behaviour. The problem is related to auto completion of path. You can still use the functionalities without problem except auto path resolution. Now Keras is available as stand alone package which might be reason that there is no problem with keras path resolution. Thanks","> Hi  , >  >  >  > I am attaching a colab gist for your reference. You please execute it and observe the behaviour. >  >  >  > The problem is related to auto completion of path. You can still use the functionalities without problem except auto path resolution. Now Keras is available as stand alone package which might be reason that there is no problem with keras path resolution. >  >  >  > Thanks >  >  I see, thankyou!  tfnightly is not an option for me. I'm on Windows Native, so I need v2.10 or lower.  Is there a way to fix the auto path resolution? Like changing the `__init__.py`"," , Now starting from 2.12v onwards Keras is a standalone package and there is no need to import tensorflow separately for this.I think this is the reason for the reported behaviour.Please try using keras as standalone package only.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
939,"以下是一个github上的tensorflow下的一个issue, 标题是(Custom shuffle layer leaks memory when run on Apple M1 GPU with `tensorflow-metal`)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution macOS 13.0 (22A380)  Mobile device Apple M1  Python version 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The following layer leaks memory during training with keras when running on an Apple M1 with `tensorflowmacos` and `tensorflowmetal` installed:  When run on the CPU alone it does not leak memory  Standalone code to reproduce the issue  ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,sirno,Custom shuffle layer leaks memory when run on Apple M1 GPU with `tensorflow-metal`,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution macOS 13.0 (22A380)  Mobile device Apple M1  Python version 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The following layer leaks memory during training with keras when running on an Apple M1 with `tensorflowmacos` and `tensorflowmetal` installed:  When run on the CPU alone it does not leak memory  Standalone code to reproduce the issue  ```  Relevant log output _No response_,2023-05-17T13:44:29Z,stat:awaiting response type:bug comp:gpu subtype:macOS TF 2.12,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60616,"Hi  , First thing I want to clear that `tensorflowmacos` was built and maintained by Apple itself .  Hence I tried to test the code first with Regular Tensorflow package `tensorflow`, for confirming the memory leakage problem exists with TF package also.I have executed the code on colab with GPU environment and observed no memory leakage(ran upto 175 epochs) and attached gist here for reference. This indicates the issue is specific to only `tensorflowmacos` package and shall be addressed by Apple tensorflowmetal developes. You can post the issue here . Thanks!",thanks for the response and the reference to the Apple forums. I will resubmit the issue in the Apple forums.,Are you satisfied with the resolution of your issue? Yes No
1092,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite Model maker installation issue in google colab notebook)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.3  Custom Code No  OS Platform and Distribution linux  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory V100  Current Behaviour? I am trying to install tflite model maker in colab using command `!pip install tflitemodelmaker` and it is taking so much disk space to install. I have 55 GB disk space left but installation is stopped in between due to no space error `ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device` I am attaching here logs of the installation. modelmakerissuecolab.txt  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dsbyprateekg,TFLite Model maker installation issue in google colab notebook,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.3  Custom Code No  OS Platform and Distribution linux  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory V100  Current Behaviour? I am trying to install tflite model maker in colab using command `!pip install tflitemodelmaker` and it is taking so much disk space to install. I have 55 GB disk space left but installation is stopped in between due to no space error `ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device` I am attaching here logs of the installation. modelmakerissuecolab.txt  Standalone code to reproduce the issue   Relevant log output  ,2023-05-17T06:09:17Z,stat:awaiting response type:bug comp:lite TF 2.3,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60612,", According to Colab Updated to Python 3.10 7: Colab’s fallback runtime version: Using the fallback runtime version temporarily allows access to the Python 3.9 runtime, and will be available until midMay. This is available from the Command Palette via the Use fallback runtime version command when connected to a runtime. Of note, this setting does not persist across sessions — the command will need to be invoked on each new session. As a temporary workaround, you can use the Colab fallback runtime version option to choose Python 3.9 and install tflitemodelmaker. By doing this you will get RuntimeError and it can be ignored. To access the command palette in Colab, presss cmd+shift+P and then type Use fallback runtime version and select it. !Screenshot 20230516 2 26 22 PM By following the above process, I was able to execute Model Maker Image Classification Tutorial 9. Thank you!", any time line when it will work with Python 3.10?,", Yes, there is an issue which was raised for the similar issue where it is under the developer's priority list. https://github.com/tensorflow/tensorflow/issues/60431 I request, could you please follow the respective issue for the updates and as the temporary workaround please try the above mentioned process. Thank you!","Thanks, I will follow.",Are you satisfied with the resolution of your issue? Yes No
1027,"以下是一个github上的tensorflow下的一个issue, 标题是(TF-Lite is 4x slower than Tensorflow on MacOS (and 2x slower in Colab))， 内容是 (Problem  Running a model with TFLite is 4x slower than running with tensorflow on my M1 MacOS.    1. System information  OS Platform and Distribution: **MacOS Ventura 13.2, on Apple M1 Macbook Air**  TensorFlow installation (pip package or built from source): **2.9.1, from pip**  2. Code Running the code in this Colab notebook, on MacOS, gives:  ... Clearly TFLite is much slower. If I run it it in Colab, notebook, TFLite is still about 1.8x slower. What is going on here?  I would expect TFLite to be faster.  Can this be fixed by adjusting some flags somewhere? This has been noticed before  see Stackoverflow question. **If this slowdown is unavoidable  is there some other way to serialize tensorflow functions so that they can be loaded again without slowdown?**)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,petered,TF-Lite is 4x slower than Tensorflow on MacOS (and 2x slower in Colab),"Problem  Running a model with TFLite is 4x slower than running with tensorflow on my M1 MacOS.    1. System information  OS Platform and Distribution: **MacOS Ventura 13.2, on Apple M1 Macbook Air**  TensorFlow installation (pip package or built from source): **2.9.1, from pip**  2. Code Running the code in this Colab notebook, on MacOS, gives:  ... Clearly TFLite is much slower. If I run it it in Colab, notebook, TFLite is still about 1.8x slower. What is going on here?  I would expect TFLite to be faster.  Can this be fixed by adjusting some flags somewhere? This has been noticed before  see Stackoverflow question. **If this slowdown is unavoidable  is there some other way to serialize tensorflow functions so that they can be loaded again without slowdown?**",2023-05-16T22:06:56Z,stat:awaiting response stale comp:lite type:performance TFLiteConverter TF 2.9 TF 2.13,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60609,"I am able to replicate locally on an Apple M1 Pro, MacOS Ventura 13.3.1, Tensorflow==2.13.0rc0 My results are a little different but the qualitative result is similar: Processed an image of shape (1080, 1920, 3) in 0.047 seconds Tensorflow Model execution stats:   Fraction of time spent detecting: 78%   Average time per frame (ms): 17   Average FPS: 58.99   Median time per frame (ms): 16   Median FPS: 60.69 TFLite Model execution stats:   Fraction of time spent detecting: 91%   Average time per frame (ms): 47   Average FPS: 21.29   Median time per frame (ms): 47   Median FPS: 21.40 Tensorflow is 2.77x times faster than TFLite","Thanks for confirming the issue To answer my previous question ""If this slowdown is unavoidable  is there some other way to serialize tensorflow functions so that they can be loaded again without slowdown?"" Yes, just use `tf.saved_model.save` instead of `tf.lite.TFLiteConverter.convert`. However, it would still be good have tflite running at a reasonable speed on Mac (I also observe about a 1.8x slowdown on windows vs pure tensorflow)","Hi , Can you please take a look?","  I have similar observations, and in my case TF Lite performs 6x slower than TensorFlow and 17x slower than pytorch. You can find the demo colab here.  The colab simply creates a sequential model of 4 `Dense` layers with 512 units in `pytorch` and `tensorflow`. And tests them with `4x1024x512` input tensor. Here are the test cases: * TensorFlow Eager execution * `torch` * TensorFlow with `tf.function` * TF Lite *  ONNX runtime with onnx model converted from the `torch` model And here are the results:   As one can see, TF Lite underperforms significantly on both M2 Pro and x86 processor in the colab. I could think that the performance issue in colab is caused by the lack of optimization for x86, but M2 pro is an arm64 processor and I think it should have no performance degradation on that.","Hi  , Give a try to check the  performance with AIEdgeTorch , you can find more information here: googleblog. If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know the result. If you still need further help, feel free to open a new issue at a relevant repo. Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1216,"以下是一个github上的tensorflow下的一个issue, 标题是(XLA CUBIN: CUDA_ERROR_OUT_OF_MEMORY)， 内容是 (Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8 and 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cuDNN version 8600  GPU model and memory NVIDIA A100 40GB PCIe, NVIDIA Tesla V100  Current Behaviour? Hi,  I'm trying to finetune a Bert based textclassification model. If I add `model.compile(jit_compile=True)`, I receive.   When I set `jit_compile=False`, everything runs fine. In the attached archive, you can find debug XLA HLOs. xla_debug.zip I faced the issue for TFhub models, tf_model_official ones and for one created manually using functional API. I also faced the issue on A100 and on V100 GPUs, with python 3.8 and 3.10 respectively.  Is this a known issue? Am I missing something?  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,artem-sereda,XLA CUBIN: CUDA_ERROR_OUT_OF_MEMORY,"Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8 and 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cuDNN version 8600  GPU model and memory NVIDIA A100 40GB PCIe, NVIDIA Tesla V100  Current Behaviour? Hi,  I'm trying to finetune a Bert based textclassification model. If I add `model.compile(jit_compile=True)`, I receive.   When I set `jit_compile=False`, everything runs fine. In the attached archive, you can find debug XLA HLOs. xla_debug.zip I faced the issue for TFhub models, tf_model_official ones and for one created manually using functional API. I also faced the issue on A100 and on V100 GPUs, with python 3.8 and 3.10 respectively.  Is this a known issue? Am I missing something?  Standalone code to reproduce the issue   Relevant log output  ",2023-05-16T16:26:19Z,stat:awaiting response stale type:others comp:gpu comp:xla TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60607,"Hi ,  I noticed that you assigned some labels to the issue. Could you already tell whether this is a compiler bug, or am I doing something wrong? Or does it need further investigation? ","sereda, Apologies for the delay. The error was stating that the issue was with memory allocation. Could you please try limiting GPU memory growth using any of the methods listed in this guide. https://www.tensorflow.org/guide/gpulimiting_gpu_memory_growth Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1031,"以下是一个github上的tensorflow下的一个issue, 标题是(`decode_image` can not load (or check properly) the bmp format )， 内容是 ( Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? On a dataset that contains bmp format files, the `tf.io.decode_image` or `tf.io.decode_bmp` method can not load the bmp files for some samples. This samples can be converted to png format but as I like to use built in decoding method for bmp image, I'm trying as follows but facing the issue for some bmp files and for some cases it loads correctly.   Standalone code to reproduce the issue samples  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,innat,`decode_image` can not load (or check properly) the bmp format ," Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? On a dataset that contains bmp format files, the `tf.io.decode_image` or `tf.io.decode_bmp` method can not load the bmp files for some samples. This samples can be converted to png format but as I like to use built in decoding method for bmp image, I'm trying as follows but facing the issue for some bmp files and for some cases it loads correctly.   Standalone code to reproduce the issue samples  ",2023-05-16T06:35:56Z,stat:awaiting tensorflower type:bug comp:apis TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60603,", Thank you for the issue. I tried to replicate the issue with the provided .bmp file, as mentioned it is failing with the same error. Kindly find the gist of it here. But when I tried with the different .bmp file it is working without any issue. Kindly find the gist of it here. rgb32.zip. As you mentioned, `decode_image` was working for some files and I suspect that some files might be corrupted which were not working for some cases. Thank you!"," Thanks for your quick test.  > I tried to replicate the issue with the provided .bmp file, as mentioned it is failing with the same error.  But when I tried with the different .bmp file it is working without any issue.  That's the primary issue, Because of that, I can't use `tf.io.decode_image` or `tf.io.decode_bmp` method inside the `tf.data` API. The above bmp file is not corrupted. It can be loaded with python libraries, please see below. ","the `1.bmp` is a 772x600 1bit bitmap. Current the bitmap decoder only supports depth = 8, 24,  or 32bit ","  Any update on this? As pointed out above, I think it should be supported.",", Apologies for the delay. , Could you please take a look at this issue. Thank you!",Are you satisfied with the resolution of your issue? Yes No
654,"以下是一个github上的tensorflow下的一个issue, 标题是(Issue while installing tensorflow-lite-maker on Google Colab)， 内容是 (While trying to install and run tensorflowlitemaker on google Colab I encountered many issues. I even tried following the example notebooks shown in the documentation here and encountered similar issues. Find output here:  The issue seems to be with python 3.10 version, unfortunately it doesn't seem possible to downgraded to previous versions of python on colab without running into errors. Please advise.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,carl-krikorian,Issue while installing tensorflow-lite-maker on Google Colab,"While trying to install and run tensorflowlitemaker on google Colab I encountered many issues. I even tried following the example notebooks shown in the documentation here and encountered similar issues. Find output here:  The issue seems to be with python 3.10 version, unfortunately it doesn't seem possible to downgraded to previous versions of python on colab without running into errors. Please advise.",2023-05-15T12:09:26Z,stat:awaiting response type:bug comp:lite TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60598,"krikorian, According to Colab Updated to Python 3.10 7: **Colab’s fallback runtime version:** Using the fallback runtime version temporarily allows access to the Python 3.9 runtime, and will be available until midMay. This is available from the Command Palette via the Use fallback runtime version command when connected to a runtime. Of note, this setting does not persist across sessions — the command will need to be invoked on each new session. As a temporary workaround, you can use the Colab fallback runtime version option to choose Python 3.9 and install tflitemodelmaker. By doing this you will get RuntimeError and it can be ignored. To access the command palette in Colab, presss cmd+shift+P and then type Use fallback runtime version and select it. !Screenshot 20230516 2 26 22 PM By following the above process, I was able to execute Model Maker Image Classification Tutorial 9. Thank you!","Hello ,  This indeed seems to have solved my issue. I managed to access the command palette through tools and after starting the notebook, the use fallback runtime became available. Many Thanks! As this workaround is temporary (and it seems it will be impossible after may), are there any plans to fix the issue with 3.10?","krikorian, Yes, there is an issue which was raised for the similar issue where it is under the developer's priority list.  https://github.com/tensorflow/tensorflow/issues/60431 I request, could you please follow the respective issue for the updates and as the alternative workaround is working in your case, Could you please feel free to move this issue to closed status. Thank you!","  I see, keep up the great work! Thanks again for the support!",Are you satisfied with the resolution of your issue? Yes No,"> krikorian, According to Colab Updated to Python 3.10 7: >  > **Colab’s fallback runtime version:** Using the fallback runtime version temporarily allows access to the Python 3.9 runtime, and will be available until midMay. This is available from the Command Palette via the Use fallback runtime version command when connected to a runtime. Of note, this setting does not persist across sessions — the command will need to be invoked on each new session. >  > As a temporary workaround, you can use the Colab fallback runtime version option to choose Python 3.9 and install tflitemodelmaker. By doing this you will get RuntimeError and it can be ignored. >  > To access the command palette in Colab, presss cmd+shift+P and then type Use fallback runtime version and select it. >  > !Screenshot 20230516 2 26 22 PM >  > By following the above process, I was able to execute Model Maker Image Classification Tutorial 9. >  > Thank you! Unfortunately, the falldown command has not been vailable now. "
854,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow global random generator is unable to generate integers)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0dev20230514  Custom Code Yes  OS Platform and Distribution macOS Ventura 13.2.1  Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Apple M2  Current Behaviour? An error is raised when trying to generate a random integer using the global random generator. Does not occur for float data types  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,estenhl,Tensorflow global random generator is unable to generate integers,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0dev20230514  Custom Code Yes  OS Platform and Distribution macOS Ventura 13.2.1  Mobile device _No response_  Python version 3.10.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Apple M2  Current Behaviour? An error is raised when trying to generate a random integer using the global random generator. Does not occur for float data types  Standalone code to reproduce the issue   Relevant log output  ,2023-05-15T09:35:04Z,stat:awaiting response type:bug comp:apis subtype:macOS TF 2.13,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60597,"Hi  , The issue exists only on Mac M1/M2 it seems.I have replicated the issue on Mac M1.  However on Colal(Linux) the code executes fine as per gist. Since Mac M1 installs Apple's TF Package the issue needs to be addressed by Apple itself.Please report the issue here. Thanks!","Ah, of course, thanks for looking into it!",Are you satisfied with the resolution of your issue? Yes No
1194,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot install tf-nightly-gpu on ubuntu with Python 3.9.16 or 3.10)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tfnightlygpu  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9.16 and 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to run `pip install tfnightlygpu` with Ubuntu 22.04, CUDA 12.1 on an RTX 4090 GPU with 24GB RAM and both Python 3.9.16 and Python 3.10. Installing just `tfnightly` installs ok but prevents my setup from using my GPU at all which is… not ideal :) My script also uses pytorch those bits are running fine so I don't think it's an issue with the CUDA setup itself.  Standalone code to reproduce the issue   Relevant log output **Note while the logs below show python 3.10 I have the same errors against Python 3.9.16**  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,boxabirds,Cannot install tf-nightly-gpu on ubuntu with Python 3.9.16 or 3.10,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tfnightlygpu  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9.16 and 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to run `pip install tfnightlygpu` with Ubuntu 22.04, CUDA 12.1 on an RTX 4090 GPU with 24GB RAM and both Python 3.9.16 and Python 3.10. Installing just `tfnightly` installs ok but prevents my setup from using my GPU at all which is… not ideal :) My script also uses pytorch those bits are running fine so I don't think it's an issue with the CUDA setup itself.  Standalone code to reproduce the issue   Relevant log output **Note while the logs below show python 3.10 I have the same errors against Python 3.9.16**  ",2023-05-14T09:37:16Z,stat:awaiting response type:bug type:build/install stale TF 2.13,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60594,"Hi  , Please use `pip install tfnightly` and it will take care of GPU package also. Starting from TF2.12 GPU package made redundant and both `tensorflowgpu` and `tfnightlygpu` were removed and replaced with packages that direct users to switch to `tensorflow` or `tfnightly` respectively. Please refer to release notes here.","Thanks. YesI just noticed that in the tfnightlygpu package README. I tried tgnightly and it said it didn’t detect my GPU. I have CUDA 12.1 on my RTX 4090. On Mon, 15 May 2023 at 05:04, SuryanarayanaY ***@***.***> wrote: > Hi   , > > Please use pip install tfnightly and it will take care of GPU package > also. Starting from TF2.12 GPU package made redundant and both > tensorflowgpu and tfnightlygpu were removed and replaced with packages > that direct users to switch to tensorflow or tfnightly respectively. > Please refer to release notes here > . > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >","Hi  , For GPU support please follow the official instructions mentioned here. Please go through the instructions and let us know if it helps and if not please let us know the commands you have used. Please ensure GPU driver has been installed and running. It can be confirmed with `nvidiasmi` command. Please verify this first and if this command displays info about CUDA driver then we need to go for CUDA toolkit and cuDNN installations and path settings as instructed in attached documentation resource. Thanks!","Thanks so much — apologies for being thick on this: the release notes I couldn’t find any instructions for installation, only build. I really want to avoid building TF myself. Are you saying I need to build TF to work with CUDA 12 and support the RTX 4090? Or was there another link? Apologies again and thanks very much in advance— I’m asking for specifics on this because I’ve spent over a day trying to get this going and my contingency of using a docker container with older TF versions and CUDA 11 seems to come with very significant performance impacts. On Mon, 15 May 2023 at 08:07, SuryanarayanaY ***@***.***> wrote: > Hi   , > > For GPU support please follow the official instructions mentioned here. > Please go through the instructions and let us know if it helps and if not > please let us know the commands you have used. > > Please ensure GPU driver has been installed and running. It can be > confirmed with nvidiasmi command. Please verify this first and if this > command displays info about CUDA driver then we need to go for CUDA toolkit > and cuDNN installations and path settings as instructed in attached > documentation resource. > > Thanks! > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >"," , > Thanks so much — apologies for being thick on this: the release notes I couldn’t find any instructions for installation, only build. I really want to avoid building TF myself. Are you saying I need to build TF to work with CUDA 12 and support the RTX 4090? Or was there another link? You need to setup GPU manually by following the instructions mentioned in documentation. It's not for Building Tensorflow itself. Even with Pip wheel of Tensorflow to enable GPU support you have to do some manual setups. The same mentioned here. However if you are using Docker container then you need to install and run nvidiadocker image first followed by tensorflowimage. The instructions are mentioned here. Please check and come back if still having queries. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1569,"以下是一个github上的tensorflow下的一个issue, 标题是(Error ""Genrules without outputs don't make sense"" when building the package builder for building TF from source)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version r2.12  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? FYI this looks similar to https://github.com/tensorflow/tensorflow/issues/12008, but that issue has been abandoned in 2018 hence I am creating a new one. When following this guide on building TensorFlow from source, I first encountered error like in https://github.com/tensorflow/tensorflow/issues/57761 and the solution described there (adding the `define=no_tensorflow_py_deps=true`) helped get past it.  Now I am encountering error ""Genrules without outputs don't make sense"" when trying to build the package builder with bazel. Included below are commands I run (just like in the guide) and their output. What actions can I take to resolve this error? I have tried to `bazel clean expunge`, `rm rf tensorflow`, and start again with steps provided in the guide with no success. Any pointers are appreciated. Thanks.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,berrylizzard,"Error ""Genrules without outputs don't make sense"" when building the package builder for building TF from source","Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version r2.12  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? FYI this looks similar to https://github.com/tensorflow/tensorflow/issues/12008, but that issue has been abandoned in 2018 hence I am creating a new one. When following this guide on building TensorFlow from source, I first encountered error like in https://github.com/tensorflow/tensorflow/issues/57761 and the solution described there (adding the `define=no_tensorflow_py_deps=true`) helped get past it.  Now I am encountering error ""Genrules without outputs don't make sense"" when trying to build the package builder with bazel. Included below are commands I run (just like in the guide) and their output. What actions can I take to resolve this error? I have tried to `bazel clean expunge`, `rm rf tensorflow`, and start again with steps provided in the guide with no success. Any pointers are appreciated. Thanks.  Standalone code to reproduce the issue   Relevant log output  ",2023-05-12T22:20:17Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.12,closed,1,4,https://github.com/tensorflow/tensorflow/issues/60588,", Tensorflow v2.12 is compatible with the python 3.83.1, GCC 9.3.1, Bazel  5.3.0, cuDNN 8.6, CUDA 11.8 which are mentioned on the official tensorflow document.  https://www.tensorflow.org/install/sourcegpu Could you please try with the tested build configurations and let us know if the installation was completed. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
938,"以下是一个github上的tensorflow下的一个issue, 标题是(rejection_resample loses track of ragged tensors)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0dev20230512  Custom Code No  OS Platform and Distribution Ubuntu 20.04.6  Mobile device _No response_  Python version 3.8.14  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? A `tf.data.Dataset` initialized from RaggedTensors normally will successfully batch into ragged batches. However after passing it through `rejection_resample`, it loses track of which input tensors were ragged, and so batching fails.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,chris-remedy,rejection_resample loses track of ragged tensors,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0dev20230512  Custom Code No  OS Platform and Distribution Ubuntu 20.04.6  Mobile device _No response_  Python version 3.8.14  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? A `tf.data.Dataset` initialized from RaggedTensors normally will successfully batch into ragged batches. However after passing it through `rejection_resample`, it loses track of which input tensors were ragged, and so batching fails.  Standalone code to reproduce the issue   Relevant log output  ",2023-05-12T10:16:39Z,stat:awaiting tensorflower type:bug comp:data TF 2.12,open,0,2,https://github.com/tensorflow/tensorflow/issues/60583,"It appears this can be worked around like this:  But that's pretty annoying. IDK if there's a shorter way to express the same thing. Also, it appears that the same problem applies generally to `Dataset.map`, i.e. this breaks in the same way: ","Hi remedy , I have replicated the reported behaviour and attached gist for reference. This needs to dig into more to confirm the root cause. Thanks!"
769,"以下是一个github上的tensorflow下的一个issue, 标题是(BrokenPipeError: [Errno 32] Broken pipe)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11.0  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.7.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When I run the program I get BrokenPipeError: [Errno 32] Broken pipe.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,NoteDance,BrokenPipeError: [Errno 32] Broken pipe,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11.0  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.7.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When I run the program I get BrokenPipeError: [Errno 32] Broken pipe.  Standalone code to reproduce the issue   Relevant log output _No response_,2023-05-12T10:16:23Z,type:support,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60582,Are you satisfied with the resolution of your issue? Yes No
841,"以下是一个github上的tensorflow下的一个issue, 标题是(TF 2.13.0-rc0 fails to compile on Ubuntu 22.04)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.13.0rc0  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04 / MacOS 13.3  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3.0  GCC/Compiler version gcc (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0  CUDA/cuDNN version 11.8  GPU model and memory Quadro RTX 6000  Current Behaviour? When compiling TF 2.13.0rc0 from source with default bazel parameters (see attached log) compilation fails.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,feranick,TF 2.13.0-rc0 fails to compile on Ubuntu 22.04,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.13.0rc0  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04 / MacOS 13.3  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3.0  GCC/Compiler version gcc (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0  CUDA/cuDNN version 11.8  GPU model and memory Quadro RTX 6000  Current Behaviour? When compiling TF 2.13.0rc0 from source with default bazel parameters (see attached log) compilation fails.   Standalone code to reproduce the issue   Relevant log output  ,2023-05-12T09:18:28Z,stat:awaiting response type:build/install subtype: ubuntu/linux subtype:macOS,closed,2,38,https://github.com/tensorflow/tensorflow/issues/60581,Log when compiling using CUDA: mochi_O3.txt,A similar issue is present for MacOS 13.3 using python 3.10. Log attached.  MacOS.txt,I'm trying to reproduce in Ubuntu 22.04 with all of the above conditions.  I'll let you know if I'm able to.,", Notes: I tried to replicate the issue using tf v2.13.0rc0 and CUDA 12.0 and was facing the below error when trying to configure the setup using ./configure. !Screenshot 20230516 2 40 47 PM","> , Notes: I tried to replicate the issue using tf v2.13.0rc0 and CUDA 12.0 and was facing the below error when trying to configure the setup using ./configure. !Screenshot 20230516 2 40 47 PM This is not related to the issue and in fact it is not a bug. Make sure you have Cuda 12.0 properly installed.","In both cases it's x86_64. The issue here seem to point to a configuration issue (see below). Yet, I am using a stock configuration, unless there is a specific python package with a noncompatible package... ERROR:  /home/nicola/.cache/bazel/_bazel_nicola/c53ed0be17816f9e0970b1ba234e403c/external/local_config_python/BUILD:78:8:  in outs attribute of genrule rule //:python_include:  Genrules without outputs don't make sense ERROR:  /home/nicola/.cache/bazel/_bazel_nicola/c53ed0be17816f9e0970b1ba234e403c/external/local_config_python/BUILD:78:8:  Analysis of target ***@***.***_config_python//:python_include' failed INFO: Repository cython instantiated at:    /home/nicola/Software/tensorflow/gpu/tensorflow/WORKSPACE:15:14: in   /home/nicola/Software/tensorflow/gpu/tensorflow/tensorflow/workspace2.bzl:972:21:  in workspace /home/nicola/Software/tensorflow/gpu/tensorflow/tensorflow/workspace2.bzl:706:20:  in _tf_repositories /home/nicola/Software/tensorflow/gpu/tensorflow/third_party/repo.bzl:136:21:  in tf_http_archive Repository rule _tf_http_archive defined at: /home/nicola/Software/tensorflow/gpu/tensorflow/third_party/repo.bzl:89:35:  in  ERROR: Analysis of target  '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: INFO: Elapsed time: 88.076s INFO: 0 processes. FAILED: Build did NOT complete successfully (388 packages loaded, 6429  targets configured) On 5/16/23 9:11 AM, Yeison Rodriguez wrote: > > I was not able to reproduce the error, my build succeeded. What is  > your system arch? > > — > Reply to this email directly, view it on GitHub  > ,  > or unsubscribe  > . > You are receiving this because you authored the thread.Message ID:  > ***@***.***> >","Hi, Thanks for reporting the bug, Since we are trying to figure out if this is regression issue.  Could you please help us with the below analysis and let us know if you see change in behavior. Please test against the 2.12.0 version with below configurations. GPU Version  11.8 ","On MacOS, the error is related but slightly different: ERROR: /Users/feranick/Desktop/tensorflow/tensorflow/BUILD:1134:21: declared output 'tensorflow/libtensorflow_framework.2.dylib' was not created by genrule. This is probably because the genrule actually didn't create this output, or because the output was a directory and the genrule was run remotely (note that only the contents of declared file outputs are copied from genrules run remotely) ERROR: /Users/feranick/Desktop/tensorflow/tensorflow/BUILD:1134:21: Executing genrule //tensorflow:libtensorflow_framework.2.dylib_sym failed: not all outputs were created or valid realpath: illegal option   usage: realpath [q] [path ...] Target //tensorflow/tools/pip_package:build_pip_package failed to build","> Hi, Thanks for reporting the bug, Since we are trying to figure out if this is regression issue. Could you please help us with the below analysis and let us know if you see change in behavior. >  > Please test against the 2.12.0 version with below configurations. >  >  GPU > Version	Python version	Compiler	Build tools	cuDNN	CUDA > tensorflow2.12.0	3.83.11	GCC 9.3.1	Bazel 5.3.0	8.6	11.8 On Ubuntu 22.04. TF 2.12.0 fails just as well (using the parameters below).  tensorflow2.12.0 python: 3.10.6	 GCC gcc (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0 Bazel 5.3.0 cuDNN: 8.6 (or nothing) CUDA: 11.8 (or nothing) (i.e. the issue is present regardless of using CUDA or not). Weirdly enough, it compiled just fine when released. I am not sure what changed, suggestions welcome. I am testing MacOS, will report shortly.","> I'm trying to reproduce in Ubuntu 22.04 with all of the above conditions. I'll let you know if I'm able to. If you are successful, can you please list your system configuration (including your list of python packages and version)?",I was not able to reproduce it in a fresh docker environment.,"On MacOS 13.3.1, TF 2.12.0 compiles just fine.  tensorflow2.12.0 python: 3.10.11 Apple clang version 14.0.3 (clang1403.0.22.14.1) Bazel 5.3.0","[UPDATE] I finally figured out the issue with Ubuntu. Compilation fails when Cython is newer than 0.29.28 is installed (currently the latest is 0.29.32). Cython needs to be v0.29.28, which is also that provided by Ubuntu via apt. Maybe this should be listed  in the recommended list of required software.  I am still trying to identifying the issue with MacOS, which seems to be  related (and yet compilation fails also with Cytin 0.29.28).","[UPDATE 2  MacOS] It turns out that for MacOS the issue is with realpath, as listed in issue CC(Build failed `not all outputs were created or valid` on `darwin/amd64`). While that issue is closed, the complete lack of documentation on how to fix it (which involves thirdparty libraries installed) in the documentation is still an issue. So for MacOS the issue is a duplicate of CC(Build failed `not all outputs were created or valid` on `darwin/amd64`), so I removed the MacOS from the issue title. It would be great to update the documentation to reflect the needs of realpath from Coreutils (via brew or macports) to successfully complete the build.","For Ubuntu the issue is not a duplicate, but again, documentation needs to be updated with information on the correct version number for Cython."," , Sorry for the late response. I have tried simple CPU build with r2.13 and its success. Is this issue is specific to any optimizations ?  ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Action is on Google here. I suggested a solution above. ," , From Tf2.13 onwards TF uses Clang 16.0.0 as compiler instead of GCC as per updated documentation. I will also test the build with Clang and update you results.","Hi  , Could you please try to compile it in the 2.13.0 or 2.13.0rc2 and let us know if that works for you. Thanks!","Yes, it compiles fine with 2.13.0. But that is not because of this specific release (compared to earlier rcs), but because, as mentioned above the use of the correct libraries. The issue is in the lack of any documentation of what version of cython is needed for compilation. Such info should be listed in the required libraries.","Hi,  Would it be possible for you to create a PR with the specific version of cython which worked for you.Thanks!","As described above there is no change needed in TF, just making sure that Cython is in the correct version: Compilation fails when Cython is newer than 0.29.28 is installed (currently the latest is 0.29.32). Cython needs to be v0.29.28, which is also that provided by Ubuntu via apt.  I am not sure what I should push as PR. Rather, this should be listed within the set of requirements for compilation...","I have also not been able to build on lubuntu 22.04.3 using docker.io. I follow the instructions on https://www.tensorflow.org/install/sourcelinux The following appears to work OK docker pull tensorflow/tensorflow:devel docker run it w /tensorflow_src v $PWD:/mnt e HOST_PERMS=""$(id u):$(id g)"" \     tensorflow/tensorflow:devel bash git pull  However, when running ./configure it fails to see the clang directories root:/tensorflow_src ./configure  You have bazel 6.1.0 installed. Please specify the location of python. [Default is /usr/bin/python3]:  Found possible Python library paths:   /usr/lib/python3/distpackages   /usr/local/lib/python3.8/distpackages Please input the desired Python library path to use.  Default is [/usr/lib/python3/distpackages] Do you wish to build TensorFlow with ROCm support? [y/N]:  No ROCm support will be enabled for TensorFlow. Do you wish to build TensorFlow with CUDA support? [y/N]:  No CUDA support will be enabled for TensorFlow. Do you want to use Clang to build TensorFlow? [Y/n]: Y   Clang will be used to compile TensorFlow. Please specify the path to clang executable. [Default is ]:  If I try to compile not using clang it does download and start to compile but fails at many points. Bazel command used is either: bazel build config=opt config=v2 //tensorflow/tools/pip_package:build_pip_package or  bazel build config=opt //tensorflow/tools/pip_package:build_pip_package When it starts is tells me python 3.9 chosen. I am compiling this on an old pre avx system.","Don't use clang when asked. Should work. On 9/12/23 9:43 AM, cuchio wrote: > > I have also not been able to build on lubuntu 22.04.3 using docker.io. > > I follow the instructions on  > https://www.tensorflow.org/install/sourcelinux > > The following appears to work OK > > docker pull tensorflow/tensorflow:devel > docker run it w /tensorflow_src v $PWD:/mnt e HOST_PERMS=""$(id  > u):$(id g)"" > tensorflow/tensorflow:devel bash > > git pull > > However, when running ./configure it fails to see the clang directories > > ***@***.***:/tensorflow_src ./configure > You have bazel 6.1.0 installed. > Please specify the location of python. [Default is /usr/bin/python3]: > > Found possible Python library paths: > /usr/lib/python3/distpackages > /usr/local/lib/python3.8/distpackages > Please input the desired Python library path to use. Default is  > [/usr/lib/python3/distpackages] > > Do you wish to build TensorFlow with ROCm support? [y/N]: > No ROCm support will be enabled for TensorFlow. > > Do you wish to build TensorFlow with CUDA support? [y/N]: > No CUDA support will be enabled for TensorFlow. > > Do you want to use Clang to build TensorFlow? [Y/n]: Y > Clang will be used to compile TensorFlow. > > Please specify the path to clang executable. [Default is ]: > > If I try to compile not using clang it does download and start to  > compile but fails at many points. > > Bazel command used is either: > > bazel build config=opt config=v2  > //tensorflow/tools/pip_package:build_pip_package > > or > > bazel build config=opt //tensorflow/tools/pip_package:build_pip_package > > When it starts is tells me python 3.9 chosen. > > I am compiling this on an old pre avx system. > > — > Reply to this email directly, view it on GitHub  > ,  > or unsubscribe  > . > You are receiving this because you were mentioned.Message ID:  > ***@***.***> > uhVVUHL7PrMAlHCnksw33Bcd ContentType: text/html; charset=UTF8 ContentTransferEncoding: 8bit             Don't use clang when asked. Should work.          On 9/12/23 9:43 AM, cuchio wrote:                 I have also not been able to build on lubuntu         22.04.3 using docker.io.       I follow the instructions on https://www.tensorflow.org/install/sourcelinux       The following appears to work OK       docker pull tensorflow/tensorflow:devel         docker run it w /tensorflow_src v $PWD:/mnt e           HOST_PERMS=&quot;$(id u):$(id g)&quot;          tensorflow/tensorflow:devel bash       git pull       However, when running ./configure it fails to see         the clang directories                You have bazel 6.1.0 installed.         Please specify the location of python. [Default is         /usr/bin/python3]:       Found possible Python library paths:         /usr/lib/python3/distpackages         /usr/local/lib/python3.8/distpackages         Please input the desired Python library path to use. Default is         [/usr/lib/python3/distpackages]       Do you wish to build TensorFlow with ROCm support?         [y/N]:         No ROCm support will be enabled for TensorFlow.       Do you wish to build TensorFlow with CUDA support?         [y/N]:         No CUDA support will be enabled for TensorFlow.       Do you want to use Clang to build TensorFlow? [Y/n]:         Y         Clang will be used to compile TensorFlow.       Please specify the path to clang executable.         [Default is ]:       If I try to compile not using clang it does download         and start to compile but fails at many points.       Bazel command used is either:       bazel build config=opt config=v2         //tensorflow/tools/pip_package:build_pip_package       or       bazel build config=opt         //tensorflow/tools/pip_package:build_pip_package       When it starts is tells me python 3.9 chosen.       I am compiling this on an old pre avx system.       —         Reply to this email directly, view it on GitHub, or unsubscribe.         You are receiving this because you were mentioned.Message           ID: &lt;tensorflow/tensorflow/issues/60581/1715753213@github.com&gt;       [ { ***@***.***"": ""http://schema.org"", ***@***.***"": ""EmailMessage"", ""potentialAction"": { ***@***.***"": ""ViewAction"", ""target"": ""https://github.com/tensorflow/tensorflow/issues/60581issuecomment1715753213"", ""url"": ""https://github.com/tensorflow/tensorflow/issues/60581issuecomment1715753213"", ""name"": ""View Issue"" }, ""description"": ""View this Issue on GitHub"", ""publisher"": { ***@***.***"": ""Organization"", ""name"": ""GitHub"", ""url"": ""https://github.com"" } } ]               uhVVUHL7PrMAlHCnksw33Bcd","To be clear: You can install clang (from Ubuntu's repos via apt), it will be recognized, and compilation will start. However, it will fail later on for the lack of the atomic library (if I remember correctly).  Easiest path is not to use clang for compilation.","I have tried, but it does still have problems. Many stops in build occurs.","> I have tried, but it does still have problems. Many stops in build occurs. File separate and detailed issue reports.","Will do. FYI, I do have the clang libraries on my machine.",Have you tried TF2.14.0rc?
1378,"以下是一个github上的tensorflow下的一个issue, 标题是(label_image CPU inference: Up to 4 CPUs are invoked, and other CPUs are idle)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.8  Custom Code Yes  OS Platform and Distribution Ubuntu18.04  Mobile device android  Python version 2.0  Bazel version 2.8  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello, TF teams: When using the **label_image** tool (path: tensorflow_src/tensorflow/tree/master/tensorflow/examples/label_image) to  my device CPU  with command `./label_image m mobilenet_quant_v1_224.tflite c 1000`,   fond that **Up to 4 CPUs are invoked, and other CPUs are idle**; I would like to ask, does your company have such settings _**Up to 4 CPUs can be invoked**_  in the code?  The status of the CPUs is shown in the figure (obtained by Qualcomm Snapdragon Profiler software). !726e6d15884e4e4ea2752c07c3f06c3b This device has 4 CPUs, so all of them are invoked. !2 This device has 8 CPUs, so only 4 of them are invoked. Very thanks megleo  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,megleo,"label_image CPU inference: Up to 4 CPUs are invoked, and other CPUs are idle","Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.8  Custom Code Yes  OS Platform and Distribution Ubuntu18.04  Mobile device android  Python version 2.0  Bazel version 2.8  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hello, TF teams: When using the **label_image** tool (path: tensorflow_src/tensorflow/tree/master/tensorflow/examples/label_image) to  my device CPU  with command `./label_image m mobilenet_quant_v1_224.tflite c 1000`,   fond that **Up to 4 CPUs are invoked, and other CPUs are idle**; I would like to ask, does your company have such settings _**Up to 4 CPUs can be invoked**_  in the code?  The status of the CPUs is shown in the figure (obtained by Qualcomm Snapdragon Profiler software). !726e6d15884e4e4ea2752c07c3f06c3b This device has 4 CPUs, so all of them are invoked. !2 This device has 8 CPUs, so only 4 of them are invoked. Very thanks megleo  Standalone code to reproduce the issue   Relevant log output _No response_",2023-05-12T02:43:45Z,stat:awaiting response stale comp:lite comp:runtime type:performance TF 2.8,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60579,"Since you are using .tflite model, I assume what you used was the the tflite label_image rather than the tf one. If you run `./label_image h`, you can find  However, setting the number of threads to be > 4 may not be what you want. As far as I know, no 8core Android devices have homogeneous cores, but usually multithread libraries do not deal with nonhomogeneous cores well. ",Hi   Could you please refer the above comment and let us know if it helps. Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1350,"以下是一个github上的tensorflow下的一个issue, 标题是(Failed to build r2.12 from sources (ShardedLRUCache))， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12  Custom Code No  OS Platform and Distribution Debian GNU/Linux 12 (bookworm) (docker)  Mobile device _No response_  Python version 3.11.2  Bazel version Bazelisk version: v1.16.0  GCC/Compiler version c++ (GCC) 13.1.0  CUDA/cuDNN version CPU only  GPU model and memory CPU only  Current Behaviour? I got a `marked 'override', but does not override` error while compiling TF r2.12 Step I have followed: 1. Install the latest GCC docker image: https://registry.hub.docker.com/_/gcc/ 2. Install Bazelisk 3. Install a Python virtual env 4. Install the relevant libraries (pip, numpy, wheel, packaging, requests, opt_einsum, keras_preprocessing, see [1]) 5. Cloned git clone https://github.com/tensorflow/tensorflow.git 6. git checkout r2.12 7. `./configure` (with the default options) 8. `bazel build //tensorflow/tools/pip_package:build_pip_package` References: [1] https://www.tensorflow.org/install/source?hl=fr  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,aquirin,Failed to build r2.12 from sources (ShardedLRUCache),"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12  Custom Code No  OS Platform and Distribution Debian GNU/Linux 12 (bookworm) (docker)  Mobile device _No response_  Python version 3.11.2  Bazel version Bazelisk version: v1.16.0  GCC/Compiler version c++ (GCC) 13.1.0  CUDA/cuDNN version CPU only  GPU model and memory CPU only  Current Behaviour? I got a `marked 'override', but does not override` error while compiling TF r2.12 Step I have followed: 1. Install the latest GCC docker image: https://registry.hub.docker.com/_/gcc/ 2. Install Bazelisk 3. Install a Python virtual env 4. Install the relevant libraries (pip, numpy, wheel, packaging, requests, opt_einsum, keras_preprocessing, see [1]) 5. Cloned git clone https://github.com/tensorflow/tensorflow.git 6. git checkout r2.12 7. `./configure` (with the default options) 8. `bazel build //tensorflow/tools/pip_package:build_pip_package` References: [1] https://www.tensorflow.org/install/source?hl=fr  Standalone code to reproduce the issue   Relevant log output  ",2023-05-12T00:37:18Z,stat:awaiting response type:build/install subtype: ubuntu/linux TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60577,"Hi  , GCC 13.1.0 not a tested configuration for TF2.12 and I am not sure of compatibility as it is not yet tested by TF team atleast for Tf2.12 version. Please find the Tested build configurations source here. Version  Bazel 5.3.0 I request you to test with above configurations and let us know if still having problem. Thanks!","Hi  , Thank you for the details. Yes GCC 13.1.0 is probably too recent. I compiled successfully TF2.11 with GCC9.3 and it is working fine. I will close this ticket, Thanks!",Are you satisfied with the resolution of your issue? Yes No,simple fix by including the header ,> simple fix by including the header > +include  but does this break builds on GCC 9.3.1?,> > simple fix by including the header >  > > +include >  > but does this break builds on GCC 9.3.1? no
1128,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Lite Converter: Full Integer Quantization Failure)， 内容是 ( 1. System information  OS Platform and Distribution: Linux Ubuntu 22.04.2 LTS  TensorFlow installation: pip package  TensorFlow library: v2.11.0  Python Version: 3.9  2. Code Provide code to help us reproduce your issues using one of the following options:  Code Snippet Example Full Integer Quantization performed on a simple model with 1x input of shape (1,), 2x Fully Connected layers with Relu Activations.   3. Failure after conversion The conversion is successful but the converter prints out the following message:  which indicates that the converter was not able to do a full integer quantization although https://www.tensorflow.org/lite/performance/post_training_quantizationinteger_only clearly states that a full integer quantization is possible as long as a representative data set is presented and the inference input type and inference output type are correctly set.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,oniigiirii,TensorFlow Lite Converter: Full Integer Quantization Failure," 1. System information  OS Platform and Distribution: Linux Ubuntu 22.04.2 LTS  TensorFlow installation: pip package  TensorFlow library: v2.11.0  Python Version: 3.9  2. Code Provide code to help us reproduce your issues using one of the following options:  Code Snippet Example Full Integer Quantization performed on a simple model with 1x input of shape (1,), 2x Fully Connected layers with Relu Activations.   3. Failure after conversion The conversion is successful but the converter prints out the following message:  which indicates that the converter was not able to do a full integer quantization although https://www.tensorflow.org/lite/performance/post_training_quantizationinteger_only clearly states that a full integer quantization is possible as long as a representative data set is presented and the inference input type and inference output type are correctly set.",2023-05-11T15:51:38Z,stat:awaiting response type:bug comp:lite TFLiteConverter TF 2.11,closed,1,3,https://github.com/tensorflow/tensorflow/issues/60574,Hi   I have tried to reproduce the issue and observed that model has INT8 qunatization which can be analyzed with TensorFlow Lite Model Analyzer and netron.  Please find the gist here and let us know if it helps. Thanks.,Oh. Thank you. The 'fully_quantize: 0' included in the warning message confused me and made me think that the converter failed at doing a full integer quantization.  I tested the model with int8 inputs and it worked as expected.,Are you satisfied with the resolution of your issue? Yes No
1925,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot convert serving signature function to concrete function for Large Language Models (Protobuf error))， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.4 LTS (Focal Fossa)  Mobile device _No response_  Python version 3.8  Bazel version None  GCC/Compiler version None  CUDA/cuDNN version None  GPU model and memory None (only CPU)  Current Behaviour? Hi! I am quantizing large language models. One step is to convert the LLM from Huggingface to Tensorflow v1.x. I found that when it comes to small models such as facebook/opt125m, gpt2 and gpt2medium, I succeeded to convert the model signatures serving function to a concrete function using `tensorflow.python.framework.convert_to_constants.convert_variables_to_constants_v2`. However, I failed when I applied that method to the serving function for some larger language models: such as gpt2large, EleutherAI/gptj6b and opt1.3b. They shared the same error as follows: Starting new session [libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/stubs/stringpiece.cc:50] size too big: 18446744072513763888 details: string length exceeds max size *** RuntimeError: size too big: 18446744072513763888 details: string length exceeds max size Could we fix or avoid that problem?  Standalone code to reproduce the issue  shell Gptlarge error log: 20230509 23:53:43.708718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_ids' with)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",large language model,Spycsh,Cannot convert serving signature function to concrete function for Large Language Models (Protobuf error),"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.4 LTS (Focal Fossa)  Mobile device _No response_  Python version 3.8  Bazel version None  GCC/Compiler version None  CUDA/cuDNN version None  GPU model and memory None (only CPU)  Current Behaviour? Hi! I am quantizing large language models. One step is to convert the LLM from Huggingface to Tensorflow v1.x. I found that when it comes to small models such as facebook/opt125m, gpt2 and gpt2medium, I succeeded to convert the model signatures serving function to a concrete function using `tensorflow.python.framework.convert_to_constants.convert_variables_to_constants_v2`. However, I failed when I applied that method to the serving function for some larger language models: such as gpt2large, EleutherAI/gptj6b and opt1.3b. They shared the same error as follows: Starting new session [libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/stubs/stringpiece.cc:50] size too big: 18446744072513763888 details: string length exceeds max size *** RuntimeError: size too big: 18446744072513763888 details: string length exceeds max size Could we fix or avoid that problem?  Standalone code to reproduce the issue  shell Gptlarge error log: 20230509 23:53:43.708718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_input_ids' with",2023-05-11T07:46:16Z,stat:awaiting response type:bug stale comp:apis TF 2.12,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60571,Thanks for reporting the issue. Could you please let us know the reason behind converting the model to Tensorflow 1.x version as you mentioned here  > `convert the LLM from Huggingface to Tensorflow v1.x`,"> Thanks for reporting the issue. >  > Could you please let us know the reason behind converting the model to Tensorflow 1.x version as you mentioned here >  > > `convert the LLM from Huggingface to Tensorflow v1.x` Yes absolutely. We want to do int8 quantization on some large language models (LLM) such as Facebook OPT and GPT, so we download the models from Huggingface, which are in Keras format. The path we use is to convert the Keras formatted LLMs to SavedModel, parse the GraphDef and insert our quantization steps. The problem we met is that we need to freeze the concrete function of that SavedModel to do further parsing and int8 quantization. The error occurred at https://github.com/intel/neuralcompressor/blob/master/neural_compressor/model/tensorflow_model.pyL277. One related question would be https://stackoverflow.com/questions/60974077/howtosavekerasmodelasfrozengraph. Just as what is done shown in the example, we called `func = model.get_concrete_function()` and invoke the `convert_variables_to_constants_v2(func)`, and when we do the `convert_variables_to_constants_v2`, we met this protobuf exceed max size problem. (*** RuntimeError: size too big: 18446744072513763888 details: string length exceeds max size). However for much smaller model, we verify that we did not meet that problem. (GPT2large failed, but GPT2medium succeeded) I have no idea on the number 18446744072513763888 and this looks super big. I do not think it is the size of a model or weights. The only hint is that this number is very close to 2^64. However the GPT2large on Huggingface only occupies about 3GB, which is far less than 2^64 bit. Another hint is that the `convert_variables_to_constants_v2` (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/convert_to_constants.pyL1138) expect models with no control flow or embedding related ops. However it is out of my knowledge scope.","Thanks for the clear explanation, The above steps which you have mentioned can be achieved through latest Tensorflow version 2.12. We don't encourage users to use Tensorflow 1.x version, since it is out of the support window. We don't have any plan to fix such old versions.  For Int8 quantization, you can refer the guide here https://www.tensorflow.org/lite/performance/post_training_quantization. For converting your model to TFLite specific format, you can refer the guide here https://www.tensorflow.org/lite/models/convertinput_model_formats. Saving the model saves the file in .pb format also. Please try with the latest version and let us know the outcome of it. Thanks!","Hi Sachin, TFLite is not the same path with ours, and I wonder whether there are any examples of TFLite to quantize models that have more than 1 billion parameters. Anyway, thanks for suggestions.","Hi  , For `LLM` models you can refer to our new tutorial which was published in our Google I/O annual developer conference. https://www.tensorflow.org/lite/examples/auto_complete/overview This tutorial walks you though Auto complete based on PaLM model, fine tuned on 1.5 Billion parameters. This model is based on `Keras NLP` and then converted to `TFLite` and TFLite runtime. This shows the quantization details and can be quantized into `Dynamic`, `FP16`, `Full Integer Quantization` specific.  Hope this helps you. Thank you!","Hi  , thanks for sharing! But it seems the first link needs a google SSO login and is invisible to outside. Is that tutorial opensource?","My bad, I updated the public link, PTAL. Thanks!",Thanks! We will check that.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
437,"以下是一个github上的tensorflow下的一个issue, 标题是([TFLite] flatbuffer64 support for TFlite)， 内容是 (Dear, flatbuffer has limit of 2G size. but for now, many models like stablediffusion, llama has the size larger than 2G, can not be convertted to tflite. Is there any plan TFlite update to flatbuffer64 ? Thanks)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llama,huanyingjun,[TFLite] flatbuffer64 support for TFlite,"Dear, flatbuffer has limit of 2G size. but for now, many models like stablediffusion, llama has the size larger than 2G, can not be convertted to tflite. Is there any plan TFlite update to flatbuffer64 ? Thanks",2023-05-11T03:02:39Z,stat:awaiting tensorflower type:feature TFLiteConverter TF 2.12,open,2,0,https://github.com/tensorflow/tensorflow/issues/60570
596,"以下是一个github上的tensorflow下的一个issue, 标题是(Training and validation accuracy and loss not changing?)， 内容是 (I am trying to train the following model for a binary classification task:  However, for some reason my training and validation accuracy and loss are not changing:  I have tried different optimizers and learning rates but they did not seem to help. Is there something wrong with my model? I know my data is pretty noisy. Thanks for any insights and help!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,WennPaper,Training and validation accuracy and loss not changing?,"I am trying to train the following model for a binary classification task:  However, for some reason my training and validation accuracy and loss are not changing:  I have tried different optimizers and learning rates but they did not seem to help. Is there something wrong with my model? I know my data is pretty noisy. Thanks for any insights and help!",2023-05-10T05:28:50Z,stat:awaiting tensorflower type:support comp:model,closed,1,10,https://github.com/tensorflow/tensorflow/issues/60555,"Hi ,  Could you please provide the dataset along with the preprocessing steps, so that we can replicate the issue from our end. Thank you!  ","Hi , Attached dataset is a tiny subset of my actual dataset. I was able to recreate my issue using this dataset by splitting it randomly for training (70%) and validation (30%). I did not have any preprocessing steps other than normalization.  Sample Data.zip","Check this code once.  batch_size = 1 num_epochs = 1000 model = tf.keras.models.Sequential([     tf.keras.layers.Conv2D(16, (5,2), activation='relu', input_shape=(252,4,1)),     tf.keras.layers.Conv2D(32, (4,2), activation='relu'),     tf.keras.layers.Conv2D(64, (3,2), activation='relu'),     tf.keras.layers.Conv2D(128, (2,1), activation='relu'),     tf.keras.layers.Flatten(),     tf.keras.layers.Dense(128, activation='relu'),     tf.keras.layers.Dense(64, activation='relu'),     tf.keras.layers.Dense(32, activation='relu'),     tf.keras.layers.Dense(16, activation='relu'),     tf.keras.layers.Dense(1, activation='sigmoid') ]) opt = Adam(learning_rate=0.001) model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy']) history = model.fit(     data_generator(x_train_list, y_train_list, batch_size),     batch_size=batch_size,     epochs=num_epochs,     steps_per_epoch=len(x_train_list)//batch_size,     validation_data=(x_val, y_val)) I am assuming there is an incorrect definition of input_shape = (242,4,1) but correct input_shape = (4, 252, 1) should be in my view because the First dimension represents the number of channels, and channels should be 4 instead of 252. Also, Order of the dimension is heights, width, channels. All the others look pretty good","But my input image size is 252x4. I don't see how transposing the images would make a difference, Maybe my input shape should be (1,252,4) since my images are grayscale?",", Unfortunately with the code provided above, we were not able to analyse the  issue where it went wrong. Could you please provide the complete standalone code or the colab gist which helps us to debug the issue in an effective way. Thank you! ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi , Here it is: ",", I tried to execute the mentioned code and it was failing with the different issue. Kindly find the gist of it here and provide the complete dependencies to analyse the issue in an effective way. Thank you!","Hi , The error was regarding the ""Sample Data"" folder location. I have attached my sample data in a zip file above. If you unzip that and use the correct folder address containing all the sample data in your computer for `os.chdir(r'Sample Data')`, the error should disappear.",Are you satisfied with the resolution of your issue? Yes No
1945,"以下是一个github上的tensorflow下的一个issue, 标题是(Large inconsistencies in tf.signal.stft's and tf.signal.inverse_stft's results with @tf.function decorator for certain inputs)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230509  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version N/A  GPU model and memory _No response_  Current Behaviour? `tf.signal.stft` and `tf.signal.inverse_stft` has large inconsistencies in their results with or without .function for some inputs. This issue seems to be unrelated to precision errors, as previously discussed under issues ( CC(tf.signal.stft has different results with or without .function) and CC(tf.signal.inverse_stft has inconsistent results with or without .function)), given that the inconsistencies can reach very high values, such as 7.530909102308483e+252+6.2143661415679e310j. I open this issue because the behavior still exists in the latest nightly version of tensorfow. Further investigation finds that it is because the results are different during each run and thus the inconsistencies are different, where sometimes the discrepancies are extremely large, while at other times they are relatively small. It appears that the inconsistencies are nondeterministic, which indicates a potential issue with the underlying implementation. I rerun the reproduction code several times and record the large inconsistencies below in the log file. The reproduction colab links are here: For tf.signal.stft, https://colab.research.google.com/drive/1WleKXby71iZXOL12r8nIN8B_jd2wJQks?usp=sharing. For tf.signal.inverse_stft, http)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jiannanWang,Large inconsistencies in tf.signal.stft's and tf.signal.inverse_stft's results with @tf.function decorator for certain inputs,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230509  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version N/A  GPU model and memory _No response_  Current Behaviour? `tf.signal.stft` and `tf.signal.inverse_stft` has large inconsistencies in their results with or without .function for some inputs. This issue seems to be unrelated to precision errors, as previously discussed under issues ( CC(tf.signal.stft has different results with or without .function) and CC(tf.signal.inverse_stft has inconsistent results with or without .function)), given that the inconsistencies can reach very high values, such as 7.530909102308483e+252+6.2143661415679e310j. I open this issue because the behavior still exists in the latest nightly version of tensorfow. Further investigation finds that it is because the results are different during each run and thus the inconsistencies are different, where sometimes the discrepancies are extremely large, while at other times they are relatively small. It appears that the inconsistencies are nondeterministic, which indicates a potential issue with the underlying implementation. I rerun the reproduction code several times and record the large inconsistencies below in the log file. The reproduction colab links are here: For tf.signal.stft, https://colab.research.google.com/drive/1WleKXby71iZXOL12r8nIN8B_jd2wJQks?usp=sharing. For tf.signal.inverse_stft, http",2023-05-09T20:14:39Z,stat:awaiting tensorflower type:bug comp:ops comp:autograph TF 2.12,open,0,1,https://github.com/tensorflow/tensorflow/issues/60549,"Hi  , Thanks for your time to bringing back this again. Yes, with CPU I also replicated the reported behaviour and the results are inconsistent and sometimes quiet large which indicates its not just Precision Errors as you mentioned.The behaviour replacted in attached gists stft_cpu and inverse_stft_cpu. As per documentation, both these APIs are implemented with GPU/TPU compatible Ops and hence with CPU I expected there might be inconsistency.You can find the source for this at the official documentations of both APIs stft and inverse_stft. Hence I tried with tfnightly version and with GPU environment and explicitly under `tf.device('GPU')` . The results here also inconsistent.But relatively `inverse_stft` has very less inconsistency and the differences in results are small compared to `stft` Please refer to GPU gists stft_gpu and inverse_stft . I believe this needs to be checked for inconsistency."
1939,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.linalg.matrix_rank  results has different results with or without @tf.function for numpy inputs under tensorflow-cpu)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230509  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version N/A  GPU model and memory _No response_  Current Behaviour? `tf.linalg.matrix_rank` has different results with or without `.function` when the input is a numpy tensor and **tensorFlowcpu** is used.  Interestingly, this issue does not occur when the numpy array is explicitly converted to a TensorFlow tensor before being passed as an argument to tf.linalg.matrix_rank. This explicit conversion shouldn't be necessary, as per the TensorFlow tutorial (https://www.tensorflow.org/tutorials/customization/basics:~:text=TensorFlow%20operations%20automatically%20convert%20NumPy%20ndarrays%20to%20Tensors), which states that ""TensorFlow operations automatically convert NumPy ndarrays to Tensors"". This discrepancy seems to indicate a bug that prevents the utilization of this automatic conversion feature. This issue was previously raised and discussed under issue ( CC(tf.linalg.matrix_rank has different results with or without .function)), where the proposed solution was the explicit conversion of numpy arrays to TensorFlow tensors. While this solution works, it does not align with the functionality of TensorFlow's automatic conversion of numpy arrays to tensors, and it requires users to perform an additional step that should not be necessary. In essence, this bug seems to affect the u)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,jiannanWang,tf.linalg.matrix_rank  results has different results with or without @tf.function for numpy inputs under tensorflow-cpu,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.14.0dev20230509  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version N/A  GPU model and memory _No response_  Current Behaviour? `tf.linalg.matrix_rank` has different results with or without `.function` when the input is a numpy tensor and **tensorFlowcpu** is used.  Interestingly, this issue does not occur when the numpy array is explicitly converted to a TensorFlow tensor before being passed as an argument to tf.linalg.matrix_rank. This explicit conversion shouldn't be necessary, as per the TensorFlow tutorial (https://www.tensorflow.org/tutorials/customization/basics:~:text=TensorFlow%20operations%20automatically%20convert%20NumPy%20ndarrays%20to%20Tensors), which states that ""TensorFlow operations automatically convert NumPy ndarrays to Tensors"". This discrepancy seems to indicate a bug that prevents the utilization of this automatic conversion feature. This issue was previously raised and discussed under issue ( CC(tf.linalg.matrix_rank has different results with or without .function)), where the proposed solution was the explicit conversion of numpy arrays to TensorFlow tensors. While this solution works, it does not align with the functionality of TensorFlow's automatic conversion of numpy arrays to tensors, and it requires users to perform an additional step that should not be necessary. In essence, this bug seems to affect the u",2023-05-09T19:42:32Z,stat:awaiting tensorflower type:bug comp:apis comp:tf.function,open,0,2,https://github.com/tensorflow/tensorflow/issues/60547,"In the first case, `tf.linalg.matrix_rank(**input)` is executed eagerly, meaning that the computation is immediately performed when the code is run. This is the default execution model in TensorFlow 2.x. In the second case, `fun_wrapper(input)` is decorated with `tf.function`, which compiles the function into a TensorFlow graph. This graph is then executed using the TensorFlow runtime To ensure consistency in the output, you can explicitly convert the numpy array to a TensorFlow tensor before passing it to `tf.linalg.matrix_rank`. For example:  Please refer to the gist with the same output in both the cases here. Thank you!","Hi synandi, Thank you for your response!  As stated in the issue, I'm wondering why the user needs to do the conversion explicitly. Because in the tutorial (https://www.tensorflow.org/tutorials/customization/basics:~:text=TensorFlow%20operations%20automatically%20convert%20NumPy%20ndarrays%20to%20Tensors), it states that ""TensorFlow operations automatically convert NumPy ndarrays to Tensors"". I would assume TensorFlow would handle numpy inputs by automatically converting it to tensors, instead of requiring the users to explicitly do the conversion."
852,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.meshgrid not working with tf.function)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.4.4  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When running the code, I would expect it to pass without error. But I am getting the following error. When deleting the .function decorator, it works as expected   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,josefondrej,tf.meshgrid not working with tf.function,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.4.4  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? When running the code, I would expect it to pass without error. But I am getting the following error. When deleting the .function decorator, it works as expected   Standalone code to reproduce the issue   Relevant log output _No response_",2023-05-09T12:42:34Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60543,Are you satisfied with the resolution of your issue? Yes No
379,"以下是一个github上的tensorflow下的一个issue, 标题是([tflite] delegate cos to NNAPI)， 内容是 (We need cosine for some networks, such as transformer positional encoding. Cosine is not directly supported by NNAPI, but we know $cos(x) = sin(\frac{\pi}{2}  x)$)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,freedomtan,[tflite] delegate cos to NNAPI,"We need cosine for some networks, such as transformer positional encoding. Cosine is not directly supported by NNAPI, but we know $cos(x) = sin(\frac{\pi}{2}  x)$",2023-05-09T09:20:47Z,comp:lite ready to pull size:S,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60542, and  could you tell me why Google internal checks FAILED?,The failures are unrelated to your pull request. I'm working on getting around the issue.
616,"以下是一个github上的tensorflow下的一个issue, 标题是(Add stricter type checking for tf.math.real)， 内容是 (Fix for tf.math.real so that it only accepts tensors with numeric entries as input. This makes it consistent with its documentation at https://www.tensorflow.org/api_docs/python/tf/math/real and raises a TypeError saying input must have numeric entries when called incorrectly. For more details, see issue CC(tf.math.real can accept string tensor, inconsistent with the documentation.).)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,alexrosen45,Add stricter type checking for tf.math.real,"Fix for tf.math.real so that it only accepts tensors with numeric entries as input. This makes it consistent with its documentation at https://www.tensorflow.org/api_docs/python/tf/math/real and raises a TypeError saying input must have numeric entries when called incorrectly. For more details, see issue CC(tf.math.real can accept string tensor, inconsistent with the documentation.).",2023-05-08T20:25:25Z,awaiting review ready to pull comp:ops size:XS,closed,0,0,https://github.com/tensorflow/tensorflow/issues/60540
1918,"以下是一个github上的tensorflow下的一个issue, 标题是(Support/Feature Request: Pre-processing very large corpus text file as tokens to train GPT Models.)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.9.018gd8ce9f9c301 2.9.1  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Suppose I've a very simple Python code like this:  The code does three things: 1. Load a file into RAM, split the contents of the file into words, i.e.  we have a list of words from the file in the order of the sentences. 2. Next, use two variables  input_tokens, output_tokens as list and append list of first `gpt_input` words in input_token and `gptinput`th word in output_token. This ensures that we have all `i` to `i + gpt_input` words in input_tokens and `i + 1` tokens in output_tokens, for all i = 0 to i = `total_tokens  1`. 3. Now, we reconstruct sentences with words input_tokens, i.e.  we condensate gpt_input words back to the sentences. Example: If the file has contents  like this:  The end result: input_tokens for gpt_input = 3:  output_tokens for gpt_input = 3:  So, now the problem is  the file or the text corpus which is needed to train a GPT Model can be very large! like upto  200300 GB and can't be loaded into RAM/memory directly. So, TensorFlow offers  tf.data class, with the set of tools to help loading, caching and training from very large datasets. But the problem is that, I don't see any way to create and preprocess text file corpus using tf.data class from the documentation.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gpt,abhaskumarsinha,Support/Feature Request: Pre-processing very large corpus text file as tokens to train GPT Models.,"Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.9.018gd8ce9f9c301 2.9.1  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Suppose I've a very simple Python code like this:  The code does three things: 1. Load a file into RAM, split the contents of the file into words, i.e.  we have a list of words from the file in the order of the sentences. 2. Next, use two variables  input_tokens, output_tokens as list and append list of first `gpt_input` words in input_token and `gptinput`th word in output_token. This ensures that we have all `i` to `i + gpt_input` words in input_tokens and `i + 1` tokens in output_tokens, for all i = 0 to i = `total_tokens  1`. 3. Now, we reconstruct sentences with words input_tokens, i.e.  we condensate gpt_input words back to the sentences. Example: If the file has contents  like this:  The end result: input_tokens for gpt_input = 3:  output_tokens for gpt_input = 3:  So, now the problem is  the file or the text corpus which is needed to train a GPT Model can be very large! like upto  200300 GB and can't be loaded into RAM/memory directly. So, TensorFlow offers  tf.data class, with the set of tools to help loading, caching and training from very large datasets. But the problem is that, I don't see any way to create and preprocess text file corpus using tf.data class from the documentation.",2023-05-08T18:34:35Z,stat:awaiting tensorflower type:feature type:support comp:data TF 2.12,open,0,6,https://github.com/tensorflow/tensorflow/issues/60539,"Hi  , If the text data is in a directory then you can use the API `tf.keras.utils.text_dataset_from_directory` to generate a tf.data.Dataset object from text files in the directory. Please refer the API documentation for more details. You can also refer this documentation guide on how to consume text data. Please refer to an end to end tutorial for handling text data here. Please go through and let us know if this is helpful. Thanks!","Hello   Thank you for your response. I've already checked all of them before and I don't see how they would be helpful to me in this case. 1.  `tf.keras.utils.text_dataset_from_directory` loads the text from different files. The output is an array of strings in the order of text. This is typically in contrast to my requirement  where I require output in the form of an array of tokens (or words, separated with a spacebar), not a sentence. For example: `[b'Hello', b'World!', b'I', b'love', b'TensorFlow']` and then preprocess them back to sentence and token (as in the example in my first post). 2. The second guide link on consuming text data is similar. It processes the data in the form of sentences and not tokens. 3. I've also checked the handling text data tutorial before. The goal of the preprocessing I require is fundamentally different from the one discussed in the tutorial. I also noticed `tf.strings.split` method to split the strings and map each sentence to one token, **this is again different from my requirement, where I actually require a flattened version of the tf.strings.split output** in the form of an array [1, m]. One way I can think to solve the issue is to write a generator function in Python that yields a preprocessed tokenized array of text tokens in the required array by reading a file in fragments each time and moving to the next iterator corresponding to the next fragment of the file, and use this generator with `tf.data`. But again, Python natively offers no such feature to **read files in the fragment of tokens** (but rather bytes, which I don't require).","Hello   The best I've got to do till now is this code:  which produces an output like this:  This is far, far from what I need, that you can see in the example I've provided in the very first post. Somewhat similar to this:  for `gpt_input = 3`","Hi  , For data preprocessing of `tf.data.Dataset` outputs you need to use `preprocessing` layers. For text vectorization TF have `tf.keras.layers.TextVectorization` layer and it has some builtin methods which may be helpful. Please refer the documentation source for more details. Thanks!","Hello   `tf.keras.layers.TextVectorization` has methods to deal with preprocessing **texts** into the matrices of numbers and arrays. But, for casting the text into numbers of the fixed array, I must get them in the desired format (or order), this is what `TextVectorization` doesn't seem to offer here. Thank you.","Hello   Here's my latest effort to help me load dataset using `tf.data.Dataset.from_generator`: ``` starting_chunk = 5 ending_chunk = 10 chunk_size = 1024 def read_file(f, vectorizer, chunk_size = 1024, starting_chunk = 0, ending_chunk = 2, gpt_input = 10):     i = 0     chunk = []     while True:         data = f.read(chunk_size)         if not data or i > ending_chunk:             break         if i >= starting_chunk and i ) with an unsupported type () to a Tensor.` It sounds like it is almost impossible to do it using TensorFlow library functions...  Thank You."
1568,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to run model.fit() in WSL environment)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows 11 installed with WSL Ubuntu  Mobile device _No response_  Python version python=3.9 and 3.11.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.8.0, nvidiacudnncu11==8.6.0.163  GPU model and memory NVIDIA GeForce RTX 3070 Laptop GPU and 32GB memory  Current Behaviour? A bug happened! I have no issue running the same code under windows environment (IDE: Jupyter Notebook). However, I have problem to run the same code in WSL environment (IDE: Jupyter Notebook). The code below is the root cause of the error message. (Note: train_set and validate_set is the output from imagedatagenerator flow_from_directory) history = model.fit(train_set, validation_data = validate_set, epochs = 10, verbose = 2) Error message:  20230509 01:04:47.558215: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 	 [[{{node Placeholder/_0}}]]  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,TP066335,Unable to run model.fit() in WSL environment,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows 11 installed with WSL Ubuntu  Mobile device _No response_  Python version python=3.9 and 3.11.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.8.0, nvidiacudnncu11==8.6.0.163  GPU model and memory NVIDIA GeForce RTX 3070 Laptop GPU and 32GB memory  Current Behaviour? A bug happened! I have no issue running the same code under windows environment (IDE: Jupyter Notebook). However, I have problem to run the same code in WSL environment (IDE: Jupyter Notebook). The code below is the root cause of the error message. (Note: train_set and validate_set is the output from imagedatagenerator flow_from_directory) history = model.fit(train_set, validation_data = validate_set, epochs = 10, verbose = 2) Error message:  20230509 01:04:47.558215: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 	 [[{{node Placeholder/_0}}]]  Standalone code to reproduce the issue   Relevant log output  ",2023-05-08T17:24:15Z,stat:awaiting tensorflower type:bug comp:apis wsl2 TF 2.12,closed,0,20,https://github.com/tensorflow/tensorflow/issues/60537,!Issue,", I was facing a different error while executing the given code. Kindly find the gist of it here and provide complete dependencies to analyse the issue and complete error as well.   Also if you are trying to execute the code on multigpu, Usually when you run the multi GPU distributed training in the eager mode, for each GPU it creates a new session and these sessions will not be synchronized since these are running in the eager mode and executes immediately. Even though `tf.distribute.Srategy` works well with both **eager** and **tf.function**, it works best with tf.function and eager mode is recommended for debug mode.                                                    ",I was getting same error on my single GPU also while trying model.fit(). However it worked perfectly on my cpu and google collab GPU. Not really sure why I was getting that error. Same GPU and memory as his. Followed the installation from this: https://www.tensorflow.org/install/pipwindowswsl2,"Hi  , I check your gist, actually you can remove that code because Google Colab needs to install scikeras separately. My issue is not with Google Colab, it is related to WSL in my own machine.  Besides, I'm using single gpu, not multigpu. Steps: 1. I setup my GPU for tensorflow according to this video, you may refer to this video for all my dependecies. https://www.youtube.com/watch?v=KinTNHO6IY 3. You may get the complete error from my attached IPNYB file.  4. I also attached a small dataset for your debugging.  data.zip Hi , yes, I'm having the same problem as yours."," Hi , Fyi, you may use my IPNYB file (data.zip) for debugging because I had simplified the codes to help your debugging. Besides, can you help me to remove ""DL_TP066335_xxxx.docx"". I accidentally uploaded the document here, I only able to remove the link, but not the physical document.",", I request you to take a look at this issue and comment from the developer where users are facing similar error and the issue is still open.Also I request to follow the similar issue which has been proposed to have the updates on the similar issue.Thank you!",", If you read their error message, you will notice their case is different from mine case. Besides, they are not using GPU.  Please ignore the rest of the alerts in my IPNYB file, because those aleart messages are common when using GPU. The only problem is the last error message which stop my training. 20230509 01:04:47.558215: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 	 [[{{node Placeholder/_0}}]] Please take note that I have no issue running the same code using my CPU in windows environment, the error message prompted when I'm using GPU to train the model in WSL environment.  Below is the statement from Tensorflow. In other words, we have no choice but to use WSL in order to use GPU.  ""Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2."" If you follow the same stesps to setup WSL, most likely you will get the same error when running my Python code in WSL environment.","Yeah I also fixed it, thanks.",", It would be greatly appreciated if you could share with me the steps on how to fix the issue.",I uninstalled everything and followed this guide: https://www.youtube.com/watch?v=ttxtV966jyQ then I isntalled tensorflow as it's shown in the tensorflow page,Thanks . The method to uninstalled everything not feasible for my machine. Maybe I will wait for  for solution on WSL.,"Hi  , Could you please share the outputs of following commands. I want to ensure whether GPU driver and CUDA path has been set or not properly. `nvidiasmi` `python3 c ""import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))""`","Hi , Thank you so much for your kind attention to this issue.  Please find the attached screenshot as per requested. Doc1.docx",Hi. I am having the same issue as . I get the same result running model.fit() as shown in the screenshot. I also followed the same instructions from tensorflow.org about how to install for Windows WSL2. I am submitting screenshots since my GPU and drivers are not quite the same. It appears to be a problem with running a GPU under WSL2. !Screenshot 20230525 211001 !Screenshot 20230525 211607 Hope this helps. Thank you for your attention to this. I look forward to running TensorFlow on this GPU.,"Hi  ,  Could you please try to import keras  as a backend to Tensorflow .  Let us know the outcome. Thanks!","Hi  , Thank you so much for your kind assistance, I really appreciate it. It appears that the issue is still stuck at the model.fit() step. I have attached the ipynb file for yor reference. Thank you. GPU.zip","Hi  Are you still stuck. Search ""WSL libcuda is not a symbolic link""","Hi ,  Thanks for the suggestion. I follow the instructions from this link  with regards to ""WSL libcuda is not a symbolic link"". I replaced the libcuda.so and libcuda.so.1 from C:\Windows\System32\lxss\lib. I'm pleased to share that I've made significant progress, as I am now **able to execute the model.fit() function**. However, an unfortunate **challenge remains  the GPU is not being utilized during the process**, as depicted in the attached screenshot. In conclusion, I am still unable to leverage the GPU for efficient model training. Thank you. GPU Screenshot.zip","Hello All, I have successfully resolved the issue by following the comprehensive steps provided by KGP Talkie in their tutorial on YouTube, which was posted two weeks ago.  Additionally, to enhance the solution, I executed the command ""conda install c condaforge cudatoolkit=11.2 cudnn=8.1.0"". As a result, my CNN training can run perfectly within the WSL environment. Last but not least, thanks a lot for your kind assistance and support.",Are you satisfied with the resolution of your issue? Yes No
1150,"以下是一个github上的tensorflow下的一个issue, 标题是(Getting error with using coco-ssd model with the latest tensorflow)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 4.5.0  Custom Code Yes  OS Platform and Distribution Windows  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? when I try to use the net.detect(frame), it throws me error: TypeError: _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__.util.convertBackendValuesAndArrayBuffer is not a function     at MathBackendCPU.readSync (backend_cpu.js:99:1)     at Engine.readSync (engine.js:943:1)     at Tensor.dataSync (tensor.js:297:1)     at d.infer (cocossd.es2017.esm.min.js:17:1) Even though I am using the latest tensorflow JS libraries.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hacktronics,Getting error with using coco-ssd model with the latest tensorflow,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 4.5.0  Custom Code Yes  OS Platform and Distribution Windows  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? when I try to use the net.detect(frame), it throws me error: TypeError: _tensorflow_tfjs_core__WEBPACK_IMPORTED_MODULE_0__.util.convertBackendValuesAndArrayBuffer is not a function     at MathBackendCPU.readSync (backend_cpu.js:99:1)     at Engine.readSync (engine.js:943:1)     at Tensor.dataSync (tensor.js:297:1)     at d.infer (cocossd.es2017.esm.min.js:17:1) Even though I am using the latest tensorflow JS libraries.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-05-08T16:55:32Z,stat:awaiting response type:support type:others,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60535,"Hi  , I believe this issue to be reported at TFJS repo. We have separate repo for TFJS which can be found here. Thanks!",Are you satisfied with the resolution of your issue? Yes No
1129,"以下是一个github上的tensorflow下的一个issue, 标题是(when argument batch_size is bool, tf.data.experimental.dense_to_ragged_batch works)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution win11  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? According to doc, the argument `batch_size` should be int64. But in following snippet code, when it's bool type, the API `tf.data.experimental.dense_to_ragged_batch` also works. If this is due to the type cast in API, then the documentation should make it clear that the argument `batch_size` can be bool type as well. If this is an unexpected type cast, then this issue should be fixed.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,cheyennee,"when argument batch_size is bool, tf.data.experimental.dense_to_ragged_batch works","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution win11  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? According to doc, the argument `batch_size` should be int64. But in following snippet code, when it's bool type, the API `tf.data.experimental.dense_to_ragged_batch` also works. If this is due to the type cast in API, then the documentation should make it clear that the argument `batch_size` can be bool type as well. If this is an unexpected type cast, then this issue should be fixed.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-05-08T13:32:25Z,type:docs-bug stat:awaiting response type:bug stale TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60531,Hi   Thank you for reporting the issue. I was able to replicate the issue in Colab using Tensorflow version 2.12 and tfnightly(2.14.0.dev20230510). Please find the gists here  TF v2.12 & tfnightly. ,"Hi , Apologies for the delay. The `tf.data.experimental.dense_to_ragged_batch` API works with `tf.dataset.Data`. As you are not applying the `tf.data.experimental.dense_to_ragged_batch` to a dataset, you are not seeing any error when passing invalid inputs. Kindly check the following code with an error when using batch_size=False.  **Error:**   Kindly refer to this gist. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.," Why when I am not applying the tf.data.experimental.dense_to_ragged_batch to a dataset, I cannot see any error when passing invalid inputs? I think maybe you should consider other data format rather than dataset, is this possible? Or does it need a lot of efforts to do validate on other data format?",", Looks like there is already an issue that was still open for the similar feature/issue. Could you please take a look at the issue and try to follow the similar thread for the update. https://github.com/tensorflow/tensorflow/issues/42349  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1545,"以下是一个github上的tensorflow下的一个issue, 标题是(Add more c apis correponding to python c apis.)， 内容是 (Hello everyone, I would like to submit this PR that adds some C APIs corresponding to those in `tensorflow/c/python_api.h`. The background behind this is that I am a developer of Tensorflow.NET, which is a .NET binding of Tensorflow and is still actively maintained. When adding new features, the best approach for us is to write C code by referring to Python code. However, sometimes Python uses C APIs defined in `tensorflow/c/python_api.h` but these APIs are not included in common externed C APIs, making it difficult for us to add the particular feature. To address this issue, I have added APIs in `tensorflow/c/python_api.h` to `tensorflow/c/c_api.h`, as these APIs are commonly required when adding features, with Tensorflow Python being the only reliable reference. I have tested this PR by compiling this branch on both Windows and Linux and it works. For example, the latest versions of Tensorflow.Redist 2.11 and Tensorflow.RedistWindowsGPU 2.10 both work smoothly. (We also successfully compiled the Linux GPU version, but it has not been released due to package size limits of NuGet) If adding too many APIs once is not encouraged, then I kindly request to add `TF_SetAttr`, `TF_UpdateEdge`, `TF_GetHandleShapeAndType`, and `TF_SetHandleShapeAndType`. Thank you very much for your consideration. :))请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,AsakusaRinne,Add more c apis correponding to python c apis.,"Hello everyone, I would like to submit this PR that adds some C APIs corresponding to those in `tensorflow/c/python_api.h`. The background behind this is that I am a developer of Tensorflow.NET, which is a .NET binding of Tensorflow and is still actively maintained. When adding new features, the best approach for us is to write C code by referring to Python code. However, sometimes Python uses C APIs defined in `tensorflow/c/python_api.h` but these APIs are not included in common externed C APIs, making it difficult for us to add the particular feature. To address this issue, I have added APIs in `tensorflow/c/python_api.h` to `tensorflow/c/c_api.h`, as these APIs are commonly required when adding features, with Tensorflow Python being the only reliable reference. I have tested this PR by compiling this branch on both Windows and Linux and it works. For example, the latest versions of Tensorflow.Redist 2.11 and Tensorflow.RedistWindowsGPU 2.10 both work smoothly. (We also successfully compiled the Linux GPU version, but it has not been released due to package size limits of NuGet) If adding too many APIs once is not encouraged, then I kindly request to add `TF_SetAttr`, `TF_UpdateEdge`, `TF_GetHandleShapeAndType`, and `TF_SetHandleShapeAndType`. Thank you very much for your consideration. :)",2023-05-08T07:40:07Z,awaiting review ready to pull size:M comp:core,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60528,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.", Sorry for the interruption but I met some problem of ci while I'm fresh to tensorflow. The ci `AMD ROCm  Community CI Build` said the bazel version does not match. However I didn't change any bazel version setting in this PR. Could you please help to see what I should do resolve this error?,"Could you please help with the ci error? The result showed `__main__.UserInputError: Invalid CLANG_COMPILER_PATH setting was provided 10 times in a row. Assuming to be a scripting mistake.`, which seems to be a clang config error. However I didn't modify related settings in this PR.",Hi  I've ported over this PR to the internal tool and am running it against the internal checks to see what all might be failing. I will update you if anything pops up. Nothing new should be required from you at this point.
658,"以下是一个github上的tensorflow下的一个issue, 标题是(skin cancer detection)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version vs code  Custom Code Yes  OS Platform and Distribution vs code  Mobile device vs code  Python version vs code  Bazel version vs code  GCC/Compiler version vs code  CUDA/cuDNN version vs code  GPU model and memory vs code  Current Behaviour? A bug happened!  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SAI557752,skin cancer detection,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version vs code  Custom Code Yes  OS Platform and Distribution vs code  Mobile device vs code  Python version vs code  Bazel version vs code  GCC/Compiler version vs code  CUDA/cuDNN version vs code  GPU model and memory vs code  Current Behaviour? A bug happened!  Standalone code to reproduce the issue   Relevant log output  ,2023-05-07T17:48:03Z,stat:awaiting response type:support stale comp:core TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60527,"code is this  history = model.fit (X_train, y_train, validation_split=0.2,epochs= 5,                       batch_size= batch_size, verbose=1, callbacks=[learning_rate_reduction])             list all data in history print(history.keys()) plt.plot('acc') plt.plot('val_acc') plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['train', 'test'], loc='upper left') plt.show() error is this ValueError                                Traceback (most recent call last) Cell In[12], line 1 > 1 history = model.fit (X_train, y_train, validation_split=0.2,epochs= 5,        2                      batch_size= batch_size, verbose=1, callbacks=[learning_rate_reduction])                  3  list all data in history       4 print(history.keys()) File ~\AppData\Roaming\Python\Python311\sitepackages\keras\utils\traceback_utils.py:70, in filter_traceback..error_handler(*args, **kwargs)      67     filtered_tb = _process_traceback_frames(e.__traceback__)      68      To get the full stack trace, call:      69      `tf.debugging.disable_traceback_filtering()` > 70     raise e.with_traceback(filtered_tb) from None      71 finally:      72     del filtered_tb File ~\AppData\Local\Temp\__autograph_generated_file6gyezdc5.py:15, in outer_factory..inner_factory..tf__train_function(iterator)      13 try:      14     do_return = True > 15     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)      16 except:      17     do_return = False ValueError: in user code:     File ""C:\Users\saiva\AppData\Roaming\Python\Python311\sitepackages\keras\engine\training.py"", line 1284, in train_function  *         return step_function(self, iterator)     File ""C:\Users\saiva\AppData\Roaming\Python\Python311\sitepackages\keras\engine\training.py"", line 1268, in step_function  **         outputs = model.distribute_strategy.run(run_step, args=(data,))     File ""C:\Users\saiva\AppData\Roaming\Python\Python311\sitepackages\keras\engine\training.py"", line 1249, in run_step  **         outputs = model.train_step(data)     File ""C:\Users\saiva\AppData\Roaming\Python\Python311\sitepackages\keras\engine\training.py"", line 1050, in train_step         y_pred = self(x, training=True)     File ""C:\Users\saiva\AppData\Roaming\Python\Python311\sitepackages\keras\utils\traceback_utils.py"", line 70, in error_handler         raise e.with_traceback(filtered_tb) from None     File ""C:\Users\saiva\AppData\Roaming\Python\Python311\sitepackages\keras\engine\input_spec.py"", line 298, in assert_input_compatibility         raise ValueError(     ValueError: Input 0 of layer ""sequential_1"" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 300, 300, 3)","Hi   Thank you for reporting the issue. Please share complete reproducible code in order to expedite the troubleshooting process. It seems like the error is due to the shape mismatch. Your input image is of shape (300, 300, 3) but the shape in the input layer is (244, 244, 3). Both the shapes should be the same. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi , here the input size of images is  300*300 but expected size is 224*224.   you can do the image resize before using them for training the model. using resize method you can do it.","Hi  , As you can see the error log which clearly states the reason. `ValueError: Input 0 of layer ""sequential_1"" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(None, 300, 300, 3)` As the Log itself suggests you are feeding the dataset of images which are of size (300, 300) but model is built to accept (224,224). Please change the argument `input_shape` of first layer model to `input_shape=(300,300,3)` like `model.add(layers.Dense(..., input_shape=(300,300,3)))`. Or If you have Input  layer defined explicitly then  `model.add(keras.Input(shape=(300, 300, 3)))` should resolve the error. Thanks!",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1108,"以下是一个github上的tensorflow下的一个issue, 标题是(How does average pooling function work in TensorFlow?)， 内容是 (Let us assume a tensor like this:  To apply the average pooling function, I will do this:  The result is:  I can follow the logic above:  **I think the logic is:**  The pooling filter is usually situated inside the tensor to perform the pooling operator. But when the entire filter does not situate inside the tensor (see the below figure for an example), we need to specify the number of elements of the filter that are situated inside the tensor (a). The following figure illustrates the logic for a 4 by 3 tensor, with pooling filter and stride sizes of 2 by 2, and padding the same. !image However, it is not always like this. For example, suppose the following tensor:  Then, I do this:  The result is like this:  If I wanted to follow the logic for the first example, I expected the result to be like this:  I am using TensorFlow 2.8.0. What mistake am I making?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ahmoosavi,How does average pooling function work in TensorFlow?,"Let us assume a tensor like this:  To apply the average pooling function, I will do this:  The result is:  I can follow the logic above:  **I think the logic is:**  The pooling filter is usually situated inside the tensor to perform the pooling operator. But when the entire filter does not situate inside the tensor (see the below figure for an example), we need to specify the number of elements of the filter that are situated inside the tensor (a). The following figure illustrates the logic for a 4 by 3 tensor, with pooling filter and stride sizes of 2 by 2, and padding the same. !image However, it is not always like this. For example, suppose the following tensor:  Then, I do this:  The result is like this:  If I wanted to follow the logic for the first example, I expected the result to be like this:  I am using TensorFlow 2.8.0. What mistake am I making?",2023-05-05T13:08:01Z,stat:awaiting response type:support stale comp:apis,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60509,"Hi   With padding = ""same"", pool_size =(4, 4) and stride = (4, 4) , the tensor would look like this  Padding = ""same"" tries to pad evenly left and right, but if the amount of columns to be added is odd, it will add the extra column to the right, as is the case in this example (the same logic applies vertically: there may be an extra row of zeros at the bottom). The output shape when using the ""same"" padding option is:   The logic would be  (1+2+3+0+6+7+8)/6 = 27/6 =4.5 (4+5+9+10)/4 = 28/4 = 7 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
432,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow is failing with Bazel@HEAD)， 内容是 (https://buildkite.com/bazel/bazelatheadplusdownstream/builds/2997 CC(Make Python/Numpy include paths configurable)e4ef95bb43c384ea7cd94dbf0b7d Platforms : Linux and Windows Logs :    Steps followed :    CC   )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,sgowroji,TensorFlow is failing with Bazel@HEAD,https://buildkite.com/bazel/bazelatheadplusdownstream/builds/2997 CC(Make Python/Numpy include paths configurable)e4ef95bb43c384ea7cd94dbf0b7d Platforms : Linux and Windows Logs :    Steps followed :    CC   ,2023-05-05T09:33:11Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux subtype:bazel,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60508,A bisect identified this commit to be the breaking change.,"That commit is intended and I thought it wouldn't affect Bazel but it looks like Tensorflow is still relying on the deprecated legacy whole archive behavior. The flag `incompatible_remove_legacy_whole_archive` was already flipped many releases ago but TF unflipped it in its bazelrc. This behavior has to stay, without this bug fix, part of the reason for the existence of cc_shared_library disappears since one of its main goals was to avoid linking libraries into the shared object that didn't need to be linked. With the legacy whole archive behavior, anything may be linked unnecessarily. For each error like this that you get you have two options, for both options you first have to find the cc_library that the missing symbol belongs to, then:  Add the `cc_library` as a direct dep of `cc_shared library` to `cc_shared_library.deps` (`cc_shared_library.roots` was renamed to `cc_shared_library.deps`)  Leave the library where it is and add `alwayslink=True`",/ , FYI,"Looks like `features=force_no_whole_archive` is an workaround for this, but TF should really migrate off depending on the old behaviour. ",gentle ping. TF has been broken on Bazel CI for a month now.,TensorFlow upgraded Bazel version from 5.3.0 to 6.1.0 two weeks ago. Can the Bazel team own the fix from here?,"How is the Bazel version upgrade relevant? In any case, I don't have the cycles to fix the TF build. The longer TF remains broken, the harder it is to fix the breakage. TF is failing with a different error now: https://buildkite.com/bazel/bazelatheadplusdisabled/builds/1692 CC(Make diag_op_test faster)ec5aa9941a89e11487dc4866b72",According to the churn policy most of the time spent on changes must be spent by the team mandating the change. TF is green at 6.1.0. It is broken at Bazel. It seems reasonable to me that the Bazel team helps resolve the majority the issue. CC  ,"We have spent plenty of time to bisect TF and identify the breaking change (https://github.com/bazelbuild/bazel/commit/661ebef465b08697a82fc3ee4c9fd540d953dc84), and as  explained, this is broken because TF still depends on the deprecated legacy feature (whole archive).  I found a workaround for TF by adding `features=force_no_whole_archive` as a build option, but eventually TF needs to migrate away from depending on the legacy behaviour. I guess we can add first apply the workaround to stop the bleed here, sent https://github.com/tensorflow/tensorflow/pull/60837",Are you satisfied with the resolution of your issue? Yes No
916,"以下是一个github上的tensorflow下的一个issue, 标题是(Memory Leak in mkl_graph_util.h)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.9  Bazel version 6.1.1  GCC/Compiler version clang 12.0.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? In mkl_graph_util.h, we create a thread_local hash set using `new`. But it doesn't look like we ever free this memory. AddressSanitizer reports a memory leak when running a program that uses this code. Maybe we can change this to `std::unique_ptr`?  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,p3achyjr,Memory Leak in mkl_graph_util.h,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.9  Bazel version 6.1.1  GCC/Compiler version clang 12.0.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? In mkl_graph_util.h, we create a thread_local hash set using `new`. But it doesn't look like we ever free this memory. AddressSanitizer reports a memory leak when running a program that uses this code. Maybe we can change this to `std::unique_ptr`?  Standalone code to reproduce the issue   Relevant log output  ",2023-05-05T02:07:29Z,stat:awaiting tensorflower type:bug comp:runtime TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60506, we have taken up this issue and are currently investigating it.," . I have a fix that is in line with what you mentioned. Since the variable is static, it has a life span till the program exists. So it should not cause a memory leak. The fix is being reviewed internally. Will create a PR with master branch soon. ",Sounds good! Functionally I don't think this would cause unbounded memory growth but I thought I'd report just for sanity :),Are you satisfied with the resolution of your issue? Yes No
1865,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Refuses to See my GPU All The Time)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.25.1  Custom Code Yes  OS Platform and Distribution Linux, Ubuntu 22.04.6  Mobile device _No response_  Python version Python 3.11  Bazel version N/A*  GCC/Compiler version 11.2  CUDA/cuDNN version 12  GPU model and memory Nvidia GT 1030 2gb  Current Behaviour? ``20230505 02:37:58.234754: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used. 20230505 02:37:58.270803: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used. 20230505 02:37:58.271133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230505 02:37:58.944800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT 20230505 02:37:59.878527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230505 02:37:59.878936: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,De-Been-Tech-Solutions,TensorFlow Refuses to See my GPU All The Time,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.25.1  Custom Code Yes  OS Platform and Distribution Linux, Ubuntu 22.04.6  Mobile device _No response_  Python version Python 3.11  Bazel version N/A*  GCC/Compiler version 11.2  CUDA/cuDNN version 12  GPU model and memory Nvidia GT 1030 2gb  Current Behaviour? ``20230505 02:37:58.234754: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used. 20230505 02:37:58.270803: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used. 20230505 02:37:58.271133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230505 02:37:58.944800: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT 20230505 02:37:59.878527: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230505 02:37:59.878936: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like ",2023-05-04T17:25:49Z,stat:awaiting tensorflower type:build/install type:support subtype: ubuntu/linux,open,0,36,https://github.com/tensorflow/tensorflow/issues/60503,"Hi  , I see from error log it seems CUDA driver was missing. Please install cuda driver compatible for your GPU. You can download driver from Nvidia website. You can cross check the driver installation with `nvidiasmi` which outputs driver details if installed and running. Please share output of the command `nvidiasmi`. Please confirm the TF version you are using and correct it in template.You can find tested configurations of cuda,cudnn wrt TF version etc from here. Once ensured Cuda driver installation then we should go for cuda toolkit installation and path setting. The instructions for the same can be found here.",I already have the Cuda driver. My version of CuDNN is version 12.,"The ``nvidiasmi`` command results in driver version 530, which should clearly tell you that the GPU is present.",I have also installed the Cuda Toolkit as well.," ,  Could you please confirm CUDA and cuDnn version you have installed ? Also have you followed instructions for CUDA path setting as instructed in documentation ? Can you confirm the commands you have used for cuda toolkit installation and path setting ?","Like I said, my CuDNN version is version 12. My Cuda Toolkit version is also the latest. I have followed the instructions given on the CuDNN and the Cuda Toolkit page.",You clearly didn't read the issue posted all the way through.,"> Like I said, my CuDNN version is version 12. Is that version you mentioned is CUDA or cuDNN ? Correct me if I am wrong, AFAIK latest version of cuDNN is 8.9 only. May be you have mentioned CUDA version right ? Also Our Tested configuration for latest version i.e TF2.12 are CUDA 11.8 and cuDNN 8.2. With other versions compatibility issues may arise. As per our documentation the recommended way for GPU setup is you have to create Conda environment and within that you need to install CUDA using conda and cudnn using pip.You need to follow the steps recommended as per documentation to install the cuda and cudnn toolkits and then configure the system paths as instructed in documentation.  I request you to please follow the instructions as per official documentation and then let us know if still having same problem.","I do not use Anaconda for something I can run in Python. The latest version of CuDNN is version 12. CuDNN version 8.9.0 is old, and therefore does not run on my machine. It won't install, nor run because its out of date.","To test this, create a VM, then run: ``python3 c import tensorflow as tf physical_devices = tf.config.list_physical_devices('GPU')`` It'll probably work for you.","Oh, by the way, Anaconda is exactly the same as Python 3, because you can run Python 3 code in it. Therefore I don't need it.","Just FYI, I exported all paths to their appropriate paths while I was at it.","Actually, I stand corrected on self observation, so my apologies on the CuDNN version. My Cuda driver is version 12, but CuDNN is indeed version 8.9.0.","Hi  , As confirmed please use tested configurations only.CUDA driver 12 might work.But you should have cuda toolkit 11.8 and cuDNN 8.6 installed. I am attaching below some of the logs below where i have successfully able to detect the GPU with official documentation steps and with tetsed configurations.  Request you to stick to tested configurations and let us know if the problem persists with those also. Thanks!","Ok then why has it failed with me even though I have done the exact same tests? Just FYI, Anaconda is just like Python as said previously.",I would absolutely love a system like yours.,This comes straight from following your instructions as well as TensorFlows: ``pip3 install nvidia cudnncu11==8.6.0.163 ERROR: Could not find a version that satisfies the requirement nvidia (from versions: none) ERROR: No matching distribution found for nvidia``,Why does the above command posted only work as the root user in a Python3.9 Anaconda activated environment?,"Hi  , I can able to download the cudnncu11==8.6.0.163 even in base environment on Ubuntu VM with X8664 architecture and logs attached below.  When I checked it on Mac M1 i found the reported error as you. This might be due to the fact that Mac M1 has Arm Architecture and probably there is no corresponding pip wheel for nvidiacudnncu11==8.6.0.163.  Can you confirm the architecture of your system using command `uname m`.  Secondly all the official instructions for CUDA and cuDNN path setting are linked to Conda environment.  Thanks",``uname m`` Returns the same architecture as you.,"Plus, I have to use a virtual environment to build the same nvidiacudnncu11==8.6.0.163 package as you, but an earlier version was installed, 8.5.0 in my case. But, it seems to have run, its just relying on code that is deprecated when running my G.A.N. script: python3 Remasterer.py Epoch 1/10 469/469 [==============================]  2s 2ms/step  loss: 0.3517  accuracy: 0.8991  val_loss: 0.2061  val_accuracy: 0.9383 Epoch 2/10 469/469 [==============================]  1s 2ms/step  loss: 0.1788  accuracy: 0.9480  val_loss: 0.1503  val_accuracy: 0.9539 Epoch 3/10 469/469 [==============================]  1s 2ms/step  loss: 0.1298  accuracy: 0.9612  val_loss: 0.1310  val_accuracy: 0.9601 Epoch 4/10 469/469 [==============================]  1s 2ms/step  loss: 0.1019  accuracy: 0.9692  val_loss: 0.1030  val_accuracy: 0.9688 Epoch 5/10 469/469 [==============================]  1s 2ms/step  loss: 0.0848  accuracy: 0.9735  val_loss: 0.1042  val_accuracy: 0.9677 Epoch 6/10 469/469 [==============================]  1s 2ms/step  loss: 0.0719  accuracy: 0.9776  val_loss: 0.1011  val_accuracy: 0.9683 Epoch 7/10 469/469 [==============================]  1s 2ms/step  loss: 0.0612  accuracy: 0.9809  val_loss: 0.0838  val_accuracy: 0.9742 Epoch 8/10 469/469 [==============================]  1s 2ms/step  loss: 0.0528  accuracy: 0.9836  val_loss: 0.0915  val_accuracy: 0.9711 Epoch 9/10 469/469 [==============================]  1s 2ms/step  loss: 0.0459  accuracy: 0.9857  val_loss: 0.0978  val_accuracy: 0.9689 Epoch 10/10 469/469 [==============================]  1s 2ms/step  loss: 0.0412  accuracy: 0.9869  val_loss: 0.0906  val_accuracy: 0.9719 313/313 [==============================]  0s 685us/step  loss: 0.0906  accuracy: 0.9719 Test accuracy: 0.9718999862670898 WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam. Traceback (most recent call last):   File &quot;/home/dbts2023/Desktop/venv/Remasterer.py&quot;, line 171, in &lt;module&gt;     gan.add(discriminator)   File &quot;/root/anaconda3/envs/tf/lib/python3.9/sitepackages/tensorflow/python/trackable/base.py&quot;, line 205, in _method_wrapper     result = method(self, *args, **kwargs)   File &quot;/root/anaconda3/envs/tf/lib/python3.9/sitepackages/keras/utils/traceback_utils.py&quot;, line 70, in error_handler     raise e.with_traceback(filtered_tb) from None   File &quot;/root/anaconda3/envs/tf/lib/python3.9/sitepackages/keras/engine/input_spec.py&quot;, line 280, in assert_input_compatibility     raise ValueError( ValueError: Exception encountered when calling layer &quot;sequential_4&quot; (type Sequential). Input 0 of layer &quot;conv2d_2&quot; is incompatible with the layer: expected axis 1 of input shape to have value 128, but received input with shape (None, 28, 28, 3) Call arguments received by layer &quot;sequential_4&quot; (type Sequential):   • inputs=tf.Tensor(shape=(None, 28, 28, 3), dtype=float32)   • training=None   • mask=None ","On my specific system, as it has a s***ty GPU, it runs in a much earlier version of Python environment as root as you can see. My issues now renewed by the fact that it needs developers like yourself to fix the Python code that I wrote: import os import numpy as np from PIL import Image os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""2"" os.environ[""CUDA_VISIBLE_DEVICES""] = ""0"" import requests import tensorflow as tf import random from tensorflow import keras from tensorflow.keras import layers from tensorflow.keras.optimizers import Adam from keras.models import Sequential from keras.layers import Dense def load_image_batch(batch_size, image_size, directory):  Load images from the directory images = [] for filename in os.listdir(directory): img = Image.open(os.path.join(directory, filename)) img = img.convert(""RGB"") img = img.resize((image_size, image_size), Image.BICUBIC) images.append(np.array(img)) images = np.array(images)  Define the Discriminator class class Discriminator(keras.Model):     def __init__(self, img_shape):         super(Discriminator, self).__init__()         self.model = keras.Sequential([             keras.layers.Flatten(input_shape=img_shape),             keras.layers.Dense(512, activation='relu'),             keras.layers.Dense(256, activation='relu'),             keras.layers.Dense(1, activation='sigmoid')         ])     def call(self, x):         validity = self.model(x)         return validity def load_image_batch(batch_size, image_size, directory):      Load images from the directory     images = []     for filename in os.listdir(directory):         img = Image.open(os.path.join(directory, filename))         img = img.convert(""RGB"")         img = img.resize((image_size, image_size), Image.BICUBIC)         images.append(np.array(img))     images = np.array(images)      Normalize pixel values to [1, 1]     images = (images.astype(np.float32)  127.5) / 127.5      Select a random batch of images     indices = np.random.randint(0, images.shape[0], batch_size)     batch = images[indices]     return batch  Generator model def make_generator_model():     model = keras.Sequential()     model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))     model.add(layers.BatchNormalization())     model.add(layers.LeakyReLU())     model.add(layers.Reshape((7, 7, 256)))     model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=""same"", use_bias=False))     model.add(layers.BatchNormalization())     model.add(layers.LeakyReLU())     model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=""same"", use_bias=False))     model.add(layers.BatchNormalization())     model.add(layers.LeakyReLU())     model.add(layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding=""same"", use_bias=False, activation=""tanh""))     img_shape = (28, 28, 1)     discriminator = Discriminator(img_shape=img_shape)     return model  Discriminator model def make_discriminator_model():     model = keras.Sequential()     model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding=""same"", input_shape=[64, 64, 3]))     model.add(layers.LeakyReLU())     model.add(layers.Dropout(0.3))     model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding=""same""))     model.add(layers.LeakyReLU())     model.add(layers.Dropout(0.3))     model.add(layers.Flatten())     model.add(layers.Dense(1))     return model  Define the generator and discriminator models generator = make_generator_model() discriminator = make_discriminator_model()  Compile the discriminator model discriminator.compile(loss=""binary_crossentropy"", optimizer=Adam(lr=0.0002, beta_1=0.5))  Combine the generator and discriminator models into a GAN gan = keras.Sequential() gan.add(generator) gan.add(discriminator)  Compile the GAN model gan.compile(loss=""binary_crossentropy"", optimizer=Adam(lr=0.0002, beta_1=0.5))  Train the GAN batch_size = 32 epochs = 100 directory = ""/Insert/Directory/Of_both_your_Python_Code_Location/And_Images_Here"" image_size = 64 training_images = load_image_batch(batch_size, image_size, directory) steps_per_epoch = len(training_images) // batch_size for epoch in range(epochs):      set model to training mode     model.train()  initialize training loss and number of training batches train_loss = 0 num_batches = 0  loop over training data in batches for inputs, labels in train_loader:      move inputs and labels to device     inputs = inputs.to(device)     labels = labels.to(device)      zero the parameter gradients     optimizer.zero_grad()      forward pass     outputs = model(inputs)      calculate loss     loss = criterion(outputs, labels)      backward pass and optimization     loss.backward()     optimizer.step()      update training loss and number of batches     train_loss += loss.item()     num_batches += 1  calculate average training loss train_loss /= num_batches  set model to evaluation mode model.eval()  initialize validation loss and number of validation batches val_loss = 0 num_val_batches = 0  turn off gradient calculation for validation with torch.no_grad():      loop over validation data in batches     for val_inputs, val_labels in val_loader:          move inputs and labels to device         val_inputs = val_inputs.to(device)         val_labels = val_labels.to(device)          forward pass         val_outputs = model(val_inputs)          calculate loss         val_loss += criterion(val_outputs, val_labels).item()         num_val_batches += 1  calculate average validation loss val_loss /= num_val_batches  print training and validation loss for each epoch print(f""Epoch {epoch + 1}/{epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}"")  at the end of each epoch, save the model torch.save(model.state_dict(), f""model_{epoch + 1}.pt"") ",> `uname m` Returns the same architecture as you. Please confirm the output result. Is it X86_64 or Arm ? > pip3 install nvidia cudnncu11==8.6.0.163 ERROR: Could not find a version that satisfies the requirement nvidia (from versions: none) ERROR: No matching distribution found for nvidia Did you able to resolve the above error now ? Can you confirm whether now GPU is able to detectable ? There are multiple issues being discussed. First of all let us complete one by one. Please confirm the reply to the above queries.,"I already confirmed this with you via ``nvidiasmi`` and ``uname r``. This system is not compatible with the version of cudnn your using. It installed cudnn version 8.5.0.96 as per pascel GPU. If I swapped out the GT 1030 with an RTX A2000, it would install cudnn version 8.6.0.163 without issue. Moving on. I cannot seem to figure out why my script just refuses to see the 1030 when, like I said previously, ``nvidiasmi`` can."," , With RTX A2000 you are able to use this GPU ? `nvidiasmi` command is not related to Tensorflow.It outputs Driver version, CUDA toolkit version it is compatible and also GPUs on local machine. For Tensorflow to detect GPU first we should ensure whether Nvidia driver is able to detect GPU. For Tensorflow to detect GPU we should follow the instructions for GPU setup as mentioned in documentation. So both are two different things.","Well, quit taking me around in circles. I followed all of the instructions in the guide. I was saying that my script wouldn't have had an issue if I had an RTX A2000 in the first place.",Not sure but it may be due to compatibility issue between GT 1030 and CUDA or cuDNN version or GT1030 GPU might not be supported.   Do you have any pointers here ?,"Huh, I see what my issue is here: I technically have 2 GPU's in my machine, and Tensorflow may be seeing the wrong one. GPU0: Intel HD 635 iGPU thats in the CPU itself. GPU1: Nvidia GT1030 2GB. Huh, even if the script is updated with: os.environ[""CUDA_VISIBLE_DEVICES""] = ""1"" instead of os.environ[""CUDA_VISIBLE_DEVICES""] = ""0"" it still fails. And it still failed with the quotations removed from CUDA_VISIBLE_DEVICES and TF_CPP_MIN_LOG_LEVEL. ``20230523 14:23:20.131376: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used. 20230523 14:23:20.166114: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used. 20230523 14:23:20.166452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230523 14:23:20.819630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT 20230523 14:23:21.647132: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230523 14:23:21.673109: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform. Skipping registering GPU devices...``","Hi  , First you can use the API tf.config.list_physical_devices('GPU') to list out the physical devices.Then If you want to set only specific GPU visible to Tensorflow then you can use the API `tf.config.set_visible_devices()` Below is example code for ignoring 1st GPU and making remaining all visible to Tensorflow. `tf.config.set_visible_devices(physical_devices[1:], 'GPU')` Please try this and let us know if ot works. Thanks!",I tried this and TensorFlow is so blind it cannot see my 1030.
832,"以下是一个github上的tensorflow下的一个issue, 标题是(Regression: //bazel_pip/tensorflow/python/kernel_tests/nn_ops:pooling_ops_3d_test fails)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? https://github.com/tensorflow/tensorflow/commit/f9becdcb81053e80b9c9034f3d4c31984f161dd1 introduced unit test failure when TF_ENABLE_ONEDNN_OPTS=1  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,Regression: //bazel_pip/tensorflow/python/kernel_tests/nn_ops:pooling_ops_3d_test fails,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? https://github.com/tensorflow/tensorflow/commit/f9becdcb81053e80b9c9034f3d4c31984f161dd1 introduced unit test failure when TF_ENABLE_ONEDNN_OPTS=1  Standalone code to reproduce the issue   Relevant log output  ,2023-05-04T09:41:47Z,type:bug,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60500,cc: MKL , ,"Thanks for the ping, will roll it back shortly",Fixed by https://github.com/tensorflow/tensorflow/commit/f0d77e35b28693d37f14f48ec8ed3c0133b8a09b,Are you satisfied with the resolution of your issue? Yes No
983,"以下是一个github上的tensorflow下的一个issue, 标题是(XLA cumsum not supported for int8 and int16)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0.dev20230503  Custom Code No  OS Platform and Distribution Google Colab  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? `tf.math.cumsum` is not supported for XLA with int8 and int16. I know that not all operations are supported by XLA, but this one seams so trivial. I assume it is an oversight.  Standalone code to reproduce the issue Google colab: https://colab.research.google.com/drive/1lqVjSjGmzYwLZfcfgVa8W02lWJ6XcqTkscrollTo=ex1xuaCfr6Y   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AndreasMadsen,XLA cumsum not supported for int8 and int16,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.14.0.dev20230503  Custom Code No  OS Platform and Distribution Google Colab  Mobile device _No response_  Python version 3.10.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? `tf.math.cumsum` is not supported for XLA with int8 and int16. I know that not all operations are supported by XLA, but this one seams so trivial. I assume it is an oversight.  Standalone code to reproduce the issue Google colab: https://colab.research.google.com/drive/1lqVjSjGmzYwLZfcfgVa8W02lWJ6XcqTkscrollTo=ex1xuaCfr6Y   Relevant log output  ",2023-05-03T16:51:04Z,stat:awaiting tensorflower type:feature comp:ops comp:xla,open,0,2,https://github.com/tensorflow/tensorflow/issues/60485,",  **tf.math.cumsum** will try to compute the cumulative sum of the tensor x along the axis. I tried to execute the code with the correct datatypes and it is working as intended. Kindly find the gist of it here. https://www.tensorflow.org/api_docs/python/tf/math/cumsum "," Please, read the issue description more carefully or run the Google Colab link (https://colab.research.google.com/drive/1lqVjSjGmzYwLZfcfgVa8W02lWJ6XcqTkscrollTo=ex1xuaCfr6Y) I attached. Your example uses `int64` (working), I'm complaining about `int8` and `int16` (not working). In your example make the following modification:  then the error will reproduce."
1138,"以下是一个github上的tensorflow下的一个issue, 标题是(Some unit tests fail pip test)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? The unit tests //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_2gpus, //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_cpu, //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_nccl_2gpus and //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_nccl_local_2gpus fail since commit https://github.com/tensorflow/tensorflow/commit/540a08ea4ddc93a632dd8583ddeae5be5ee75bff See https://github.com/tensorflow/tensorflow/actions/runs/4865981223/jobs/8676977815step:5:29731  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,elfringham,Some unit tests fail pip test,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution Ubuntu 20.04  Mobile device n/a  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour? The unit tests //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_2gpus, //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_cpu, //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_nccl_2gpus and //bazel_pip/tensorflow/dtensor/python/tests:multi_client_test_nccl_local_2gpus fail since commit https://github.com/tensorflow/tensorflow/commit/540a08ea4ddc93a632dd8583ddeae5be5ee75bff See https://github.com/tensorflow/tensorflow/actions/runs/4865981223/jobs/8676977815step:5:29731  Standalone code to reproduce the issue   Relevant log output  ",2023-05-03T09:06:15Z,type:bug,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60479,Fixed by https://github.com/tensorflow/tensorflow/commit/edc647632a2ec64e1d9a6a6dc699bad77e930738,Are you satisfied with the resolution of your issue? Yes No
1857,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow 2.11 and 2.14 Memory Issue)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  (Lambda Stack)  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version Driver Version: 525.105.17   CUDA Version: 12.0     GPU model and memory A6000    System 1TB RAM 2TB Swap  Current Behaviour? I have multiple models that have worked fine for months or years under version  in       13       14     if training_validation_split != None: > 15         history = midas_model.fit (training_dataset, epochs=num_epochs, validation_data=validation_dataset, callbacks=[tensorboard_cb, dhc_scheduler])      16     else:      17         history = midas_model.fit (training_dataset, epochs=num_epochs, callbacks=[tensorboard_cb, dhc_scheduler]) /usr/lib/python3/distpackages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)      68              To get the full stack trace, call:      69              `tf.debugging.disable_traceback_filtering()` > 70             raise e.with_traceback(filtered_tb) from None      71         finally:      72             del filtered_tb /usr/lib/python3/distpackages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)      50   try:      51     ctx.ensure_initialized() > 52     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,      53                                         inputs, attrs, num_outputs)      54   except core._NotOkStatusException as e: R)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,camda03,Tensorflow 2.11 and 2.14 Memory Issue,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  (Lambda Stack)  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version Driver Version: 525.105.17   CUDA Version: 12.0     GPU model and memory A6000    System 1TB RAM 2TB Swap  Current Behaviour? I have multiple models that have worked fine for months or years under version  in       13       14     if training_validation_split != None: > 15         history = midas_model.fit (training_dataset, epochs=num_epochs, validation_data=validation_dataset, callbacks=[tensorboard_cb, dhc_scheduler])      16     else:      17         history = midas_model.fit (training_dataset, epochs=num_epochs, callbacks=[tensorboard_cb, dhc_scheduler]) /usr/lib/python3/distpackages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)      68              To get the full stack trace, call:      69              `tf.debugging.disable_traceback_filtering()` > 70             raise e.with_traceback(filtered_tb) from None      71         finally:      72             del filtered_tb /usr/lib/python3/distpackages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)      50   try:      51     ctx.ensure_initialized() > 52     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,      53                                         inputs, attrs, num_outputs)      54   except core._NotOkStatusException as e: R",2023-05-02T14:23:56Z,stat:awaiting response stale comp:apis type:performance TF 2.11,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60469,", Could you please provide the complete code to debug the issue in an effective way. Also   the problem might be in the format_image method. It's not really formatting the images because the transformation is assigned to a variable images and the method is returning image (the same input) !Screenshot 20230503 5 09 48 PM Can you try reducing batch size? This error message is generated if the memory is not sufficient to manage the batch size. Thank you!",I'm currently uploading the code and (large) supporting data files to Dropbox.   The normal batch size is 32.  I also tried running with 8 and 16.  Both of these failed the same way. I'm not sure about the format image method reference. I'll let you know when the upload is done.  It's going to take quite awhile. What account should I open the folder to so that you can access it? Thanks!,"Here are the links to the source code and supporting files. Please let me know if you have trouble accessing, have questions, etc. Thanks! https://www.dropbox.com/s/ggfgh525ow3gfxd/TensorFlow%20Debug%20Files.tar.xz?dl=0 https://www.dropbox.com/s/n7zo4yrv988nc9y/TensorFlow%20Debugging%2060469.ipynb?dl=0",", The provided links which are mentioned contain the files of 10GB and more. It would be a very difficult and tedious process for us to replicate the issue with the huge amount of data. Could you please simplify and provide the code or data or colab gist, so that we can analyse the issue in an effective way. Thank you!",https://www.dropbox.com/s/3q9h77dzclg0twi/Tensorflow%2060469%20Small.tar.xz?dl=0 Here are versions of the supporting files with ten rows each in them. Thanks!,"I tried running this notebook on Google Colab.   I setup an instance with an A100 (my system has A6000s) and ran it using the ten row files. The instance is running TensorFlow 2.12. I got the errors listed below. If you'd like to get access to this instance please let me know. Hope this helps! Thanks! Epoch 1/100  ResourceExhaustedError                    Traceback (most recent call last) [](https://localhost:8080/) in () > 1 history = the_model.fit (training_dataset, epochs=num_epochs, validation_data=validation_dataset, callbacks=[tensorboard_cb]) 1 frames /usr/local/lib/python3.10/distpackages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)      50   try:      51     ctx.ensure_initialized() > 52     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,      53                                         inputs, attrs, num_outputs)      54   except core._NotOkStatusException as e: ResourceExhaustedError: Graph execution error: Detected at node 'gradient_tape/model/layer_1/MatMul/MatMul' defined at (most recent call last):     File ""/usr/lib/python3.10/runpy.py"", line 196, in _run_module_as_main       return _run_code(code, main_globals, None,     File ""/usr/lib/python3.10/runpy.py"", line 86, in _run_code       exec(code, run_globals)     File ""/usr/local/lib/python3.10/distpackages/ipykernel_launcher.py"", line 16, in        app.launch_new_instance()     File ""/usr/local/lib/python3.10/distpackages/traitlets/config/application.py"", line 992, in launch_instance       app.start()     File ""/usr/local/lib/python3.10/distpackages/ipykernel/kernelapp.py"", line 619, in start       self.io_loop.start()     File ""/usr/local/lib/python3.10/distpackages/tornado/platform/asyncio.py"", line 195, in start       self.asyncio_loop.run_forever()     File ""/usr/lib/python3.10/asyncio/base_events.py"", line 603, in run_forever       self._run_once()     File ""/usr/lib/python3.10/asyncio/base_events.py"", line 1909, in _run_once       handle._run()     File ""/usr/lib/python3.10/asyncio/events.py"", line 80, in _run       self._context.run(self._callback, *self._args)     File ""/usr/local/lib/python3.10/distpackages/tornado/ioloop.py"", line 685, in        lambda f: self._run_callback(functools.partial(callback, future))     File ""/usr/local/lib/python3.10/distpackages/tornado/ioloop.py"", line 738, in _run_callback       ret = callback()     File ""/usr/local/lib/python3.10/distpackages/tornado/gen.py"", line 825, in inner       self.ctx_run(self.run)     File ""/usr/local/lib/python3.10/distpackages/tornado/gen.py"", line 786, in run       yielded = self.gen.send(value)     File ""/usr/local/lib/python3.10/distpackages/ipykernel/kernelbase.py"", line 361, in process_one       yield gen.maybe_future(dispatch(*args))     File ""/usr/local/lib/python3.10/distpackages/tornado/gen.py"", line 234, in wrapper       yielded = ctx_run(next, result)     File ""/usr/local/lib/python3.10/distpackages/ipykernel/kernelbase.py"", line 261, in dispatch_shell       yield gen.maybe_future(handler(stream, idents, msg))     File ""/usr/local/lib/python3.10/distpackages/tornado/gen.py"", line 234, in wrapper       yielded = ctx_run(next, result)     File ""/usr/local/lib/python3.10/distpackages/ipykernel/kernelbase.py"", line 539, in execute_request       self.do_execute(     File ""/usr/local/lib/python3.10/distpackages/tornado/gen.py"", line 234, in wrapper       yielded = ctx_run(next, result)     File ""/usr/local/lib/python3.10/distpackages/ipykernel/ipkernel.py"", line 302, in do_execute       res = shell.run_cell(code, store_history=store_history, silent=silent)     File ""/usr/local/lib/python3.10/distpackages/ipykernel/zmqshell.py"", line 539, in run_cell       return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)     File ""/usr/local/lib/python3.10/distpackages/IPython/core/interactiveshell.py"", line 2975, in run_cell       result = self._run_cell(     File ""/usr/local/lib/python3.10/distpackages/IPython/core/interactiveshell.py"", line 3030, in _run_cell       return runner(coro)     File ""/usr/local/lib/python3.10/distpackages/IPython/core/async_helpers.py"", line 78, in _pseudo_sync_runner       coro.send(None)     File ""/usr/local/lib/python3.10/distpackages/IPython/core/interactiveshell.py"", line 3257, in run_cell_async       has_raised = await self.run_ast_nodes(code_ast.body, cell_name,     File ""/usr/local/lib/python3.10/distpackages/IPython/core/interactiveshell.py"", line 3473, in run_ast_nodes       if (await self.run_code(code, result,  async_=asy)):     File ""/usr/local/lib/python3.10/distpackages/IPython/core/interactiveshell.py"", line 3553, in run_code       exec(code_obj, self.user_global_ns, self.user_ns)     File """", line 1, in        history = the_model.fit (training_dataset, epochs=num_epochs, validation_data=validation_dataset, callbacks=[tensorboard_cb])     File ""/usr/local/lib/python3.10/distpackages/keras/utils/traceback_utils.py"", line 65, in error_handler       return fn(*args, **kwargs)     File ""/usr/local/lib/python3.10/distpackages/keras/engine/training.py"", line 1685, in fit       tmp_logs = self.train_function(iterator)     File ""/usr/local/lib/python3.10/distpackages/keras/engine/training.py"", line 1284, in train_function       return step_function(self, iterator)     File ""/usr/local/lib/python3.10/distpackages/keras/engine/training.py"", line 1268, in step_function       outputs = model.distribute_strategy.run(run_step, args=(data,))     File ""/usr/local/lib/python3.10/distpackages/keras/engine/training.py"", line 1249, in run_step       outputs = model.train_step(data)     File ""/usr/local/lib/python3.10/distpackages/keras/engine/training.py"", line 1054, in train_step       self.optimizer.minimize(loss, self.trainable_variables, tape=tape)     File ""/usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py"", line 542, in minimize       grads_and_vars = self.compute_gradients(loss, var_list, tape)     File ""/usr/local/lib/python3.10/distpackages/keras/optimizers/optimizer.py"", line 275, in compute_gradients       grads = tape.gradient(loss, var_list) Node: 'gradient_tape/model/layer_1/MatMul/MatMul' OOM when allocating tensor with shape[443156,3700] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc 	 [[{{node gradient_tape/model/layer_1/MatMul/MatMul}}]] Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.  [Op:__inference_train_function_30186]",", Could you please share the colab gist for the reference where you are trying to execute the code? Thank you!",https://colab.research.google.com/gist/camda03/7b93f3bcb8fc6474dc125798a2c3d034/tensorflowdebugging60469.ipynb Please let me know if this does or doesn't work for you or if you have questions. Thanks!,", The reason for this is the high amount of parameters (please check your model.summary()). You are exhausting the available memory, Could you can reduce the batch size, which would slow down the training process but let you fit the data. And also need to serialize your data(instead of loading everything in your GPU,RAM) by converting your data to TRFRecord files: https://www.tensorflow.org/guide/data https://www.tensorflow.org/tutorials/load_data/tfrecord","""The reason for this is the high amount of parameters (please check your model.summary())."" Again, this number of parameters worked just fine in TF <= 2.10. (I have had plenty of experience figuring out just how many parameters I can get into an A6000.) As I wrote above. ""Here is the model.  I have tried reducing the 3,700 width down to 3,400 but that doesn't help.  This exact model (3,700) works fine with <= 2.10 and has for months."" As I wrote above. ""The normal batch size is 32. I also tried running with 8 and 16. Both of these failed the same way."" In the gist I submitted, the following code appears. with tf.device('/CPU:0'):         training_dataset = tf.data.Dataset.from_tensor_slices((training_df_standardized, training_labels_df)).batch(batch_size).prefetch(dataset_prefetch)     validation_dataset = tf.data.Dataset.from_tensor_slices((validation_df_standardized, validation_labels_df)).batch(batch_size).prefetch(dataset_prefetch)     inference_dataset = tf.data.Dataset.from_tensor_slices((inference_df_standardized)).batch(batch_size).prefetch(dataset_prefetch) I've been putting the datasets in CPU (not GPU) ram for a long time.  This has worked well up until TF 2.11. With 2.11 and after, this doesn't work on my A6000s or even an A100 at Google Colab. This is all documented in the case notes to date (above). When I look at the links you sent, I find this. ""Note: While useful, these structures are optional. There is no need to convert existing code to use TFRecords, unless you are using tf.data and reading data is still the bottleneck to training. You can refer to Better performance with the tf.data API for dataset performance tips."" Again, the code I submitted ran just fine in TF <= 2.10.   I would understand this better if this was some new piece of code and I was having trouble with it.   That is not the case. The code that ran fine in <= 2.10 on an A6000 and on a system with 1TB of CPU ram now won't run even on an A100 at Google Colab.  What happened after TF 2.10? Are there any plans to address this (whatever it is) in later releases of TensorFlow? Please advise Thanks!","I have an update for you. This same code runs properly using TF 2.13, and it fails using 2.14. Here is a file showing runs with containers for 2.13 and 2.14 aka latest. Both runs were done using the same .ipynb file, the same data, and the same GPU on the same system. The only difference was the container and that is shown in the log. TensorFlow 2.13 and 2.14.txt The models are the same as the one I included in the gist I sent earlier. I have a model training now using 2.13. To summarize, a model that works on TF <= 2.10 doesn't work on 2.11, works on 2.13, and doesn't work on 2.14. I haven't tried 2.12. Thanks!","The reason for this is the high amount of parameters (please check your model.summary()). You are exhausting the available memory, Could you can reduce the batch size, which would slow down the training process but let you fit the data. Also could you please try in the latest TensorFlow v2.16 as most of the bugs are resolved. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1255,"以下是一个github上的tensorflow下的一个issue, 标题是(Docs problem. Notebook not found)， 内容是 (Hello, I am new to tensoflow and right now I am reading your gides, particularly guide about tf.function. There you have a link to guide for ""eager execution"", but I don't have access to it. Is it my problem or you have broken link? Guide for tf.function: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=J122XQYG7W6w Broken link, which is in the first block of code:  ""In TensorFlow 2, eager execution is turned on by default."" https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb Upd. Also there is broken link here https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=ocxXHVk7P2o (See the Transformer and Deep Dream tutorials for example). first link does not work Upd. 2 Another broken link https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=JeD2UyrbfVb To learn more, see the tf.data: Build TensorFlow input pipelines guide.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,Tialo,Docs problem. Notebook not found,"Hello, I am new to tensoflow and right now I am reading your gides, particularly guide about tf.function. There you have a link to guide for ""eager execution"", but I don't have access to it. Is it my problem or you have broken link? Guide for tf.function: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=J122XQYG7W6w Broken link, which is in the first block of code:  ""In TensorFlow 2, eager execution is turned on by default."" https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/eager.ipynb Upd. Also there is broken link here https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=ocxXHVk7P2o (See the Transformer and Deep Dream tutorials for example). first link does not work Upd. 2 Another broken link https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=JeD2UyrbfVb To learn more, see the tf.data: Build TensorFlow input pipelines guide.",2023-05-01T14:44:23Z,type:docs-bug comp:data awaiting PR merge TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60459,"Hi , Thank you for reporting the issue. The issue will move to closed status once the  CC(feed_previous argument for basic_rnn_seq2seq) is merged. Thanks! ","Also it would be nice if you would fix those links at the end  https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=IKyrEY5GVX3M Further reading To learn about how to export and load a Function, see the SavedModel guide. To learn more about graph optimizations that are performed after tracing, see the Grappler guide. To learn how to optimize your data pipeline and profile your model, see the Profiler guide.","> Also it would be nice if you would fix those links at the end https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/function.ipynbscrollTo=IKyrEY5GVX3M >  > Further reading To learn about how to export and load a Function, see the SavedModel guide. To learn more about graph optimizations that are performed after tracing, see the Grappler guide. To learn how to optimize your data pipeline and profile your model, see the Profiler guide.  I've added these changes in this commit. Thank you!","Thanks, on it.","Using https://www.tensorflow.org/guide/function as the reference. > ""In TensorFlow 2, eager execution is turned on by default."" This should now take you to https://www.tensorflow.org/guide/basics or the corresponding Colab/notebook > (See the Transformer and Deep Dream tutorials for example). Same here: https://www.tensorflow.org/text/tutorials/transformer and https://www.tensorflow.org/tutorials/generative/deepdream > To learn more, see the tf.data: Build TensorFlow input pipelines guide. And same here: https://www.tensorflow.org/guide/data Feel free to reopen the issue if you see any other links that need to be fixed. Thank you.",Are you satisfied with the resolution of your issue? Yes No
1077,"以下是一个github上的tensorflow下的一个issue, 标题是(How to download outdated versions of Tensorflow in Google Colab?)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.5  Custom Code Yes  OS Platform and Distribution Colab  Mobile device _No response_  Python version 3.11  Bazel version 3.7.2  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I have a project using Mask RCNN, and the project only works with Tensorflow 2.5, but this version is outdated and the pip doesn't support this version anymore, when I'm trying to build on colab using the ""Build from Source"" documentation,  When I try to use bazel I get an error while trying to build it ` Also when I try to use pip ` I get the following error `  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,luishbastos,How to download outdated versions of Tensorflow in Google Colab?,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.5  Custom Code Yes  OS Platform and Distribution Colab  Mobile device _No response_  Python version 3.11  Bazel version 3.7.2  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I have a project using Mask RCNN, and the project only works with Tensorflow 2.5, but this version is outdated and the pip doesn't support this version anymore, when I'm trying to build on colab using the ""Build from Source"" documentation,  When I try to use bazel I get an error while trying to build it ` Also when I try to use pip ` I get the following error `  Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-30T19:42:47Z,stat:awaiting response type:build/install type:support stale TF 2.5,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60453,"Hi  , Colab recently stopped support for Tensorflow Versions older than 2.8v. You can't download older versions directly with `pip install tensorflow==x` . The command `!pip install git+https://github.com/tensorflow/tensorflow.git.12` not even working with TF 2.12 versions which might be due to the way TF repo constructed,since `setup.py` not located at the root of tensorflow project directory but under sub directories at path here. Tensorflow team not actively supporting older TF versions and this might be the reason why Colab dropped support for TF<2.8 versions. Nevertheless you may ask the reason for same at `googlecolab` repo also if required. However for your case you may use Anaconda environment/jupyter notebook and install TF 2.5 version by `pip install tensorflow==2.5`.However we are not supporting older versions now and we recommend to use latest versions and we can be helpful in case of any problems with latest versions. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1022,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.compat.v1.nn.conv2d fails with assertion error: AttributeError: 'list' object has no attribute 'startswith')， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Linux/Mac  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I was trying to use tf.compat.v1.nn.conv2d because of the compatibility issue in my project. However, tf.compat.v1.nn.conv2d fails with the following error message:   Looks like the argument `data_format` is a list instead of a string inside this API.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,drewshark,tf.compat.v1.nn.conv2d fails with assertion error: AttributeError: 'list' object has no attribute 'startswith',"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Linux/Mac  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I was trying to use tf.compat.v1.nn.conv2d because of the compatibility issue in my project. However, tf.compat.v1.nn.conv2d fails with the following error message:   Looks like the argument `data_format` is a list instead of a string inside this API.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-30T09:57:53Z,stat:awaiting response type:bug comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60450,Can I work on this issue?   ,", **tf.compat.v1.nn.conv2d** was deprecated. Could you please try the **tf.nn.conv2d** which computes a 2D convolution given input and 4D filters tensors.  https://www.tensorflow.org/api_docs/python/tf/nn/conv2d Also kindly find the gist of it here where I tried with tf.nn.conv2d and the output was also as expected. Thank you!","Hi, thanks for letting me know that it is deprecated. I am closing this issue.",Are you satisfied with the resolution of your issue? Yes No
1887,"以下是一个github上的tensorflow下的一个issue, 标题是(Windows bazel says python is not an executable when building tflite)， 内容是 (Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    Trying to build TFLite   Windows 10    Windows Asus machine   source   r2.12    python 3.11.2    bazel 6.1.1    windows compiler    **CUDA/cuDNN version**:     Geforce GTX 960m   bazel build c opt //tensorflow/lite:tensorflowlite I'm trying to build c++ tflite for windows using bazel by following the official documentation. So far I've installed everything it want's me to and added them to PATH. Then I cloned the github repo and checked out to r2.12 branch. Then I ran python ./configure.py and selected default for everything (said yes to override eigen strong inline). When doing so it declared that my python is located on C:\Users\Asus\AppData\Local\Programs\Python\Python311\python.exe. After that running bazel build c opt //tensorflow/lite:tensorflowlite on the directory where I've cloned tensorflow in cmd casuses this er)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,turgut-baba,Windows bazel says python is not an executable when building tflite,"Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    Trying to build TFLite   Windows 10    Windows Asus machine   source   r2.12    python 3.11.2    bazel 6.1.1    windows compiler    **CUDA/cuDNN version**:     Geforce GTX 960m   bazel build c opt //tensorflow/lite:tensorflowlite I'm trying to build c++ tflite for windows using bazel by following the official documentation. So far I've installed everything it want's me to and added them to PATH. Then I cloned the github repo and checked out to r2.12 branch. Then I ran python ./configure.py and selected default for everything (said yes to override eigen strong inline). When doing so it declared that my python is located on C:\Users\Asus\AppData\Local\Programs\Python\Python311\python.exe. After that running bazel build c opt //tensorflow/lite:tensorflowlite on the directory where I've cloned tensorflow in cmd casuses this er",2023-04-29T18:56:01Z,stat:awaiting response type:bug type:build/install stale comp:lite subtype:windows TF 2.12,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60441,Hi baba could you please run the steps in the link below before running configure.py and let us know if you are still getting the errors? https://github.com/tensorflow/docs/blob/master/site/en/install/source_windows.mdoptionalenvironmentalvariablesetup,"baba, Could you please confirm whether you are trying to install from the build from source for the Windows. Also you are trying to install tensorflow v2.12 with the Bazel 6.1.1 which is not compatible.  For tensorflow v2.12 the compatible Bazel version is 5.3.0. Please take a look at the official tested build configurations from here and Could you try `bazel clean expunge` followed by bazel sync !Screenshot 20230503 9 47 32 AM Thank you!"," ,   I've set the environment variables and changed my bazel version to 5.3.0 but the error remains. The same message.","The only different thing I've noticed is that, naturally, the path is different but the error is still the same:  ","Hi baba, can you please try to run ""bazel clean expunge"" to make sure old bazel files are deleted? and then run the build command again. If you still get an error try the command in the image to make sure 'location to python.exe' is recognized as executable !image If it still does not work, please follow the steps below steps.txt"," Thanks, but now I'm getting this error: ",I've deleted python311 from my system and it solved the program. Now I'm getting this error: ,"Hi baba, please set the Java path as mentioned below. Add JAVA_HOME in the environmental variables set JAVA_HOME = C:\Program Files\Eclipse Adoptium\jdk17.0.4.101hotspot  If you still get an issue, run bazel clean expunge command to clear bazel cache and rererun the build command.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1937,"以下是一个github上的tensorflow下的一个issue, 标题是(TypeError: Unable to serialize 16.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10 and 2.12  Custom Code No  OS Platform and Distribution Windows 10   Mobile device _No response_  Python version 3.11.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory RTX M960 4GB  Current Behaviour? I have been unable to save my transformer model using any of the Tensorflow complete model saving functions. While running Tensorflow 2.10 I received the following using message attempting to save using tf.keras.models.save_model: TypeError: Unable to serialize 16.0 to JSON. Unrecognized type . I was able to successfully save and read the model weights back in.  I was unable to recover it's normalization layer. This issue was previously reported as a bug in 2.10 I uninstalled all python software and packages and the PyCharm IDE and installed python 3.11.3 and Tensorflow 2.12 and the latest PyCharm Community edition hoping that would correct the problem.  I used tf.keras.saving.save_model( ) using saved formats tf and keras. It did not correct the problem.   The model I am trying to save is a simplied version to the Tensorflow Translator tutorial at https://www.tensorflow.org/text/tutorials/transformer Here is a listing of the error message I received from PyCharm. It seems to have something to do with the python class tensorflow.python.framework.ops.EagerTensor Is there anything I can do with my model to dodge the issue Thank you in advance for your help. WARNING:absl:Found untraced functions such as _update_step_xla)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,cpodczerwinski,TypeError: Unable to serialize 16.0 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10 and 2.12  Custom Code No  OS Platform and Distribution Windows 10   Mobile device _No response_  Python version 3.11.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory RTX M960 4GB  Current Behaviour? I have been unable to save my transformer model using any of the Tensorflow complete model saving functions. While running Tensorflow 2.10 I received the following using message attempting to save using tf.keras.models.save_model: TypeError: Unable to serialize 16.0 to JSON. Unrecognized type . I was able to successfully save and read the model weights back in.  I was unable to recover it's normalization layer. This issue was previously reported as a bug in 2.10 I uninstalled all python software and packages and the PyCharm IDE and installed python 3.11.3 and Tensorflow 2.12 and the latest PyCharm Community edition hoping that would correct the problem.  I used tf.keras.saving.save_model( ) using saved formats tf and keras. It did not correct the problem.   The model I am trying to save is a simplied version to the Tensorflow Translator tutorial at https://www.tensorflow.org/text/tutorials/transformer Here is a listing of the error message I received from PyCharm. It seems to have something to do with the python class tensorflow.python.framework.ops.EagerTensor Is there anything I can do with my model to dodge the issue Thank you in advance for your help. WARNING:absl:Found untraced functions such as _update_step_xla,2023-04-29T01:20:01Z,stat:awaiting response type:bug stale comp:keras TF 2.12,closed,0,14,https://github.com/tensorflow/tensorflow/issues/60437,May you share the transformer model architecture you used so we can reproduce the error?," Good morning Zeyad; Thank you very much for helping. The attached file one_step_transformer_components.py contains the definition of the transformer I am trying to save when I experience the issue. I am using the transformer to do one step ahead time series predictions Here are the dimensions of the transformer I am trying to save. num_layers = 2num_heads = 2model_dimensions = 16ffn_units = 64features_shape = (1024, 3, 2)labels_shape = (1024, 3, 2)dropout_rate = 0.2 I tried decorating the transformed functions call() and predict with an .function() hoping it might dodge the issue by taking a different route through the save_model() logic.  I did not. I still received the same error message. While running TensorFlow 2.10. I also found that the tf.keras.layers.Normalization layer I was using was not doing its inversion calculations correctly so I coded the inversion myself in the transformer call() function. I have not yet tested the Normalization layer in version 2.12. Thank you again for helping RegardsCraig(630) 4530404     On Saturday, April 29, 2023 at 05:53:31 AM CDT, Zeyad Abd ElRaheem ***@***.***> wrote:   May you share the transformer model architecture you used so we can reproduce the error? — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***>","Hi , Apologies for the delay. I can see a different error when replicating the issue in Colab with Tensorflow 2.12. Please find the gist here. It would help us if you could share the complete reproducible code to expedite the troubleshooting process. Thank you! "," Good morning; Thank you again for helping. The attached file one_step_unit_tests.py contains a script that you can run with the file one_step_transformer_components.py that I provided in my previous email. It reproduces the error.  The output I received when I executed it follows; The following transformer member function fixes the error that you received when saving the tutorial tensor that you ran def get_config(self):  config = {  'd_model': self.model_dimensions,  'warmup_steps': self.warmup_steps,  }  return config RegardsCraig C:\Users\cpodc\AppData\Local\Programs\Python\Python311\python.exe D:\Craig\Python\one_step_unit_tests.py transformer_output[0].shape:  (1024, 3, 2)WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:absl:Found untraced functions such as _update_step_xla, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.Traceback (most recent call last):  File ""D:\Craig\Python\one_step_unit_tests.py"", line 30, in     tf.keras.saving.save_model( transformer, 'Output\\saved_transformer')  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\saving\saving_api.py"", line 145, in save_model    return legacy_sm_saving_lib.save_model(           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\utils\traceback_utils.py"", line 70, in error_handler    raise e.with_traceback(filtered_tb) from None  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 200, in encode    chunks = self.iterencode(o, _one_shot=True)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 258, in iterencode    return _iterencode(o, 0)           ^^^^^^^^^^^^^^^^^TypeError: Unable to serialize 16.0 to JSON. Unrecognized type . Process finished with exit code 1     On Monday, May 8, 2023 at 08:11:21 AM CDT, synandi ***@***.***> wrote:   Hi , Apologies for the delay. I can see a different error when replicating the issue in Colab with Tensorflow 2.12. Please find the gist here. It would help us if you could share the complete reproducible code to expedite the troubleshooting process. Thank you! — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you were mentioned.Message ID: ***@***.***>"," I forget to attach the file one_step_unit_tests,py.  Here is a copy of it. RegardsCraig     On Thursday, May 11, 2023 at 04:44:02 PM CDT, Craig Podczerwinski ***@***.***> wrote:     Good morning; Thank you again for helping. The attached file one_step_unit_tests.py contains a script that you can run with the file one_step_transformer_components.py that I provided in my previous email. It reproduces the error.  The output I received when I executed it follows; The following transformer member function fixes the error that you received when saving the tutorial tensor that you ran def get_config(self):  config = {  'd_model': self.model_dimensions,  'warmup_steps': self.warmup_steps,  }  return config RegardsCraig C:\Users\cpodc\AppData\Local\Programs\Python\Python311\python.exe D:\Craig\Python\one_step_unit_tests.py transformer_output[0].shape:  (1024, 3, 2)WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:absl:Found untraced functions such as _update_step_xla, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.Traceback (most recent call last):  File ""D:\Craig\Python\one_step_unit_tests.py"", line 30, in     tf.keras.saving.save_model( transformer, 'Output\\saved_transformer')  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\saving\saving_api.py"", line 145, in save_model    return legacy_sm_saving_lib.save_model(           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\utils\traceback_utils.py"", line 70, in error_handler    raise e.with_traceback(filtered_tb) from None  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 200, in encode    chunks = self.iterencode(o, _one_shot=True)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 258, in iterencode    return _iterencode(o, 0)           ^^^^^^^^^^^^^^^^^TypeError: Unable to serialize 16.0 to JSON. Unrecognized type . Process finished with exit code 1     On Monday, May 8, 2023 at 08:11:21 AM CDT, synandi ***@***.***> wrote:   Hi , Apologies for the delay. I can see a different error when replicating the issue in Colab with Tensorflow 2.12. Please find the gist here. It would help us if you could share the complete reproducible code to expedite the troubleshooting process. Thank you! — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you were mentioned.Message ID: ***@***.***>",  The code provided is not complete hence it would be difficult for us to pinpoint the issue. Please share complete stand alone code to replicate the issue or a colab gist with the error reported.? That will allow us to determine the source of the issue easily. Thank you!," Hello Syed; I am resending you the files onestep_unit_tests.py and one_step_transformer_components.py which are attached. Executing the file one_step_unit_tests.py will reproduce the problem.  The code in one_step_unit_tests.py uses the classes and functions defined in one_step_transformer_components.py. I just executed one_step_unit_tests.py on my laptop and received the following output.  I am using the PyCharm IDE. Thank you for helping.RegardsCraig(630) 4530404 D:\Craig\Python\Projects\ModelSaveProblem\Scripts\python.exe D:\Craig\Python\one_step_unit_tests.py transformer_output[0].shape:  (1024, 3, 2)WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:absl:Found untraced functions such as _update_step_xla, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.Traceback (most recent call last):  File ""D:\Craig\Python\one_step_unit_tests.py"", line 30, in     tf.keras.saving.save_model( transformer, 'Output\\saved_transformer')  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\saving\saving_api.py"", line 145, in save_model    return legacy_sm_saving_lib.save_model(           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\utils\traceback_utils.py"", line 70, in error_handler    raise e.with_traceback(filtered_tb) from None  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 200, in encode    chunks = self.iterencode(o, _one_shot=True)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 258, in iterencode    return _iterencode(o, 0)           ^^^^^^^^^^^^^^^^^TypeError: Unable to serialize 16.0 to JSON. Unrecognized type . Process finished with exit code 1     On Monday, May 8, 2023 at 08:11:21 AM CDT, synandi ***@***.***> wrote:   Hi , Apologies for the delay. I can see a different error when replicating the issue in Colab with Tensorflow 2.12. Please find the gist here. It would help us if you could share the complete reproducible code to expedite the troubleshooting process. Thank you! — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you were mentioned.Message ID: ***@***.***>"," Good morning; Have you been able to reproduce and identify a corrective action for this issue. Are there any work around actions I can take? Thank you for helping RegardsCraig     On Monday, May 15, 2023 at 03:38:30 PM CDT, Craig Podczerwinski ***@***.***> wrote:     Hello Syed; I am resending you the files onestep_unit_tests.py and one_step_transformer_components.py which are attached. Executing the file one_step_unit_tests.py will reproduce the problem.  The code in one_step_unit_tests.py uses the classes and functions defined in one_step_transformer_components.py. I just executed one_step_unit_tests.py on my laptop and received the following output.  I am using the PyCharm IDE. Thank you for helping.RegardsCraig(630) 4530404 D:\Craig\Python\Projects\ModelSaveProblem\Scripts\python.exe D:\Craig\Python\one_step_unit_tests.py transformer_output[0].shape:  (1024, 3, 2)WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:tensorflow:Skipping full serialization of Keras layer , because it is not built.WARNING:absl:Found untraced functions such as _update_step_xla, dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, positional_embedding_layer_call_fn, positional_embedding_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.Traceback (most recent call last):  File ""D:\Craig\Python\one_step_unit_tests.py"", line 30, in     tf.keras.saving.save_model( transformer, 'Output\\saved_transformer')  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\saving\saving_api.py"", line 145, in save_model    return legacy_sm_saving_lib.save_model(           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\sitepackages\keras\utils\traceback_utils.py"", line 70, in error_handler    raise e.with_traceback(filtered_tb) from None  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 200, in encode    chunks = self.iterencode(o, _one_shot=True)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^  File ""C:\Users\cpodc\AppData\Local\Programs\Python\Python311\Lib\json\encoder.py"", line 258, in iterencode    return _iterencode(o, 0)           ^^^^^^^^^^^^^^^^^TypeError: Unable to serialize 16.0 to JSON. Unrecognized type . Process finished with exit code 1     On Monday, May 8, 2023 at 08:11:21 AM CDT, synandi ***@***.***> wrote:   Hi , Apologies for the delay. I can see a different error when replicating the issue in Colab with Tensorflow 2.12. Please find the gist here. It would help us if you could share the complete reproducible code to expedite the troubleshooting process. Thank you! — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you were mentioned.Message ID: ***@***.***>",", We can see that the code which you provided was not sufficient for debugging the issue. Could you please provide the complete standalone code or the colab gist which helps to analyse the issue in an effective way.  And if you are trying to use efficientnet, please try to run below and also the PR which was merged. https://github.com/kerasteam/keras/pull/17498  Thank you!"," Good morning; Please send me a copy of the debugger output that you received when you executed the code that I sent you and a description of the environment in which you executed it. Thank you for helpingCraig     On Monday, June 19, 2023 at 11:18:34 AM CDT, tilakrayal ***@***.***> wrote:   , We can see that the code which you provided was not sufficient for debugging the issue. Could you please provide the complete standalone code or the colab gist which helps to analyse the issue in an effective way. Thank you! — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you were mentioned.Message ID: ***@***.***>",", Could you please find the gist of the code which you have mentioned and I was able to face a different error. Kindly provide the information for the same. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
676,"以下是一个github上的tensorflow下的一个issue, 标题是(Softmax API Mismatch on beta param between TF and TFL )， 内容是 (In TFL's reference for Softmax, a beta param is supported to be multiplied with logits. [Link]  However, in TF, the beta seems has not been supported yet [Link]. Is there any reason why it's only being supported in TFL not in TF now?  More background: I'm trying to test the beta param from Softmax with a model converted from TF to TFL. So if it doesn't support beta in TF, how could I insert beta into the TFL model?  Thanks,  Jerry )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Jerry-Ge,Softmax API Mismatch on beta param between TF and TFL ,"In TFL's reference for Softmax, a beta param is supported to be multiplied with logits. [Link]  However, in TF, the beta seems has not been supported yet [Link]. Is there any reason why it's only being supported in TFL not in TF now?  More background: I'm trying to test the beta param from Softmax with a model converted from TF to TFL. So if it doesn't support beta in TF, how could I insert beta into the TFL model?  Thanks,  Jerry ",2023-04-28T16:24:00Z,type:docs-bug stat:awaiting response comp:lite TFLiteConverter,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60435,"Hi, The original PR https://github.com/tensorflow/tensorflow/pull/42330 with the beta implementation in TFL has the detailed explanation, let me know if that helps you in understanding ","> Hi, The original PR CC(TFLite: reduced duplicated calculation of exp in softmax.h (float)) with the beta implementation in TFL has the detailed explanation, let me know if that helps you in understanding Thanks Sachin for the note. But I haven't found the explanation of why TFL is supporting the beta parameter while TF is not? That PR seems is only explaining the need to remove some duplicated calculations for exp.  Jerry  ",Hi Ge  The PR CC([tosa] Disable non1.0 beta parameter for Softmax) has been merged with the commit https://github.com/tensorflow/tensorflow/commit/ecbe847f8f3841898ea6dfa482b99a3bca7f4e6f with following lines https://github.com/tensorflow/tensorflow/blob/70c60acb6100651def0b8447783ecb65e273f155/tensorflow/compiler/mlir/tosa/transforms/legalize_common.ccL1493L1499 Could please confirm and close this issue if it is resolved? Thanks.,Are you satisfied with the resolution of your issue? Yes No
1317,"以下是一个github上的tensorflow下的一个issue, 标题是(Issue of ""type resource != float"" when trying to get frozen graph_def from a model of saved_model format)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.6.1810 (Core)  TensorFlow installation (pip package or built from source): pip install tensorflow  TensorFlow library (version, if pip package or github SHA, if built from source): 2.12.0  2. Code I am trying to use the code of this function to get frozen_graph_def from a TF model in saved_model format: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/convert_saved_model.pyL134 No error occurs during the process of conversion. But a bug is reported after I pass the frozen_graph_def to tf.import_graph_def()  The model is downloaded from this tfhub link: https://tfhub.dev/google/universalsentenceencodermultilingual/3  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Can't be loaded by using tf.import_graph_def() API.  5. (optional) Any other info / logs The code is run on Intel CLX Xeon CPU. The log of this bug: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,zehao-intel,"Issue of ""type resource != float"" when trying to get frozen graph_def from a model of saved_model format"," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.6.1810 (Core)  TensorFlow installation (pip package or built from source): pip install tensorflow  TensorFlow library (version, if pip package or github SHA, if built from source): 2.12.0  2. Code I am trying to use the code of this function to get frozen_graph_def from a TF model in saved_model format: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/python/convert_saved_model.pyL134 No error occurs during the process of conversion. But a bug is reported after I pass the frozen_graph_def to tf.import_graph_def()  The model is downloaded from this tfhub link: https://tfhub.dev/google/universalsentenceencodermultilingual/3  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Can't be loaded by using tf.import_graph_def() API.  5. (optional) Any other info / logs The code is run on Intel CLX Xeon CPU. The log of this bug: ",2023-04-26T15:03:51Z,comp:lite TFLiteConverter TF 2.12,closed,0,14,https://github.com/tensorflow/tensorflow/issues/60416,"Hi intel  The Value Error occurs  if input_map, or return_elements contains names that do not appear in graph_def, or graph_def is not wellformed (e.g. it refers to an unknown tensor). Also, the Saved Model serialisation format is only supported and the TFLite conversion from frozen graph is deprecated. Could you please try `from_saved_model` if you are trying convert a saved model from TFLite. Thanks.",Hi pjpratik， Thanks for your explanation and suggestions. They are very helpful! It seems that 'from_saved_model' only convert a saved_model to TFLite model. I would like to get a correct graph_def from the saved_model. Is that possible to achieve this by using TFLite API?,"Hi intel  As per documentation, the TFLite API supports converting a TensorFlow model to a TensorFlow Lite mode using `saved_model` format which is recommended by TFLite.  Converting from `frozen_graph`  is no longer supported in TF 2.x but can be accessed using `tf.compat.v1.lite.TFLiteConverter.from_frozen_graph` .  Thanks.","Hi  , I have tried  with the following code:  But an error occurs: !image It seems that some binary contents is printed and the execution is stopped at . Could you please look into it? Thanks","Hi intel  The TensorFlow Lite builtin operator library only supports a limited number of TensorFlow operators, not every model is convertible. To allow conversion, we can enable the usage of certain TensorFlow ops in their TensorFlow Lite model by using following syntax  Please find the working gist here and let us know if it helps. Thanks.","Hi  , Many thanks to your comments. I have tried your code and inspected the generated model.tflite with netron. I believe the model is correctly converted. By the way, I made some investigation. It seems that there is no official way to get graph_def from a TFLite model. In fact, I still need to find out how to get graph_def from the original saved_model. I have tried many ways, including the tf lite code I mentioned before, but none of them works. Could you give me some suggestions about this? Thank!",Hi intel  Getting a graph def from tflite is not supported. For getting a frozen graph from checkpoints you can try https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py An example of commandline usage is:  Thanks.,"Hi  , It's happy to hear that there is a stable method to get  a  from . But for this model, it is in  format. I saw some arguments related with  in the script you provided. Is there a similar usage of getting  a  from  with this script? Thanks","Hi intel  Importing from tensorflow.python or any other modules not supported, and can break unannounced as anything under tf.python.* is private, intended for development only, rather than for public use. As mentioned earlier, frozen graphs are deprecated and using Saved Model format is recommended. Is there any challenge to use Saved Model in your use case? Thanks.","Hi , Thanks for your explanation. So TensorFlow don't recommend to use  in version 2.X. The task I am handled is to apply 8bit quantization to the TF model mentioned above. And I need to firstly get the frozen graph from this model so that I can modify the model by change the Op type and fuse Op patterns. I am not able to apply this process to a . Thanks.",Hi intel  Sorry for delayed response. We can apply 8 bit quantization while converting the SavedModel to TFLite model by adding these flags:  Please refer to this documentation on converting using integer only quantization and let us know if it helps. Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Hi  ， Sorry for the late reply. I think this Issue could be closed. Really appreciate your patient comments!,Thanks for the confirmation. Closing this issue. Please feel free to reopen if you'd like to work on this further.
1592,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot currently create HexagonDelegate, but was working in the past)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version org.tensorflow:tensorflowlite:0.0.0nightlySNAPSHOT and org.tensorflow:tensorflowlitehexagon:0.0.0nightlySNAPSHOT with hexagon libraries v1.20.0.1  Custom Code Yes  OS Platform and Distribution Android 13  Mobile device Samsung Galaxy A71  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The HexagonDelegate was working fine via a Java Android app on my device (Samsung Galaxy A71 with Snapdragon 730), but then i changed some things on the project (libraries versions, manifest) because i had issues with running some transformer models on the GPU and since then it is not working and produces the error: Failed to load libhexagon_interface.so, Error: dlopen failed: library ""libadsprpc.so"" not found: needed by data/app/~~o6sPBobgR5gDMgV2fEROg==/com.example.8QtHh6qQZAELc86wE5E8IA==/lib/arm64/libhexagon_interface.so in namespace classloadernamespace I have also tried stable versions from 2.9.0 to 2.12.0 instead of the nightly snapshots and the error persists. I can share my project if someone could look into it.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,ioannispan,"Cannot currently create HexagonDelegate, but was working in the past","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version org.tensorflow:tensorflowlite:0.0.0nightlySNAPSHOT and org.tensorflow:tensorflowlitehexagon:0.0.0nightlySNAPSHOT with hexagon libraries v1.20.0.1  Custom Code Yes  OS Platform and Distribution Android 13  Mobile device Samsung Galaxy A71  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? The HexagonDelegate was working fine via a Java Android app on my device (Samsung Galaxy A71 with Snapdragon 730), but then i changed some things on the project (libraries versions, manifest) because i had issues with running some transformer models on the GPU and since then it is not working and produces the error: Failed to load libhexagon_interface.so, Error: dlopen failed: library ""libadsprpc.so"" not found: needed by data/app/~~o6sPBobgR5gDMgV2fEROg==/com.example.8QtHh6qQZAELc86wE5E8IA==/lib/arm64/libhexagon_interface.so in namespace classloadernamespace I have also tried stable versions from 2.9.0 to 2.12.0 instead of the nightly snapshots and the error persists. I can share my project if someone could look into it.  Standalone code to reproduce the issue   Relevant log output  ",2023-04-24T06:28:17Z,stat:awaiting response type:bug stale comp:lite TFLiteHexagonDelegate TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60407,", Could you you make sure that you're using the latest nightlies  may be clear the gradle cash ? We just cloned tensorflow examples and updated image classification example to include hexagon. I followed the guide by adding the gradle dep in build.gradle and created directory jniLibs/arm64v8a and included the files i got from the libhexagon_nn_skel extraction. as explained here Also please have a look at this issue https://github.com/tensorflow/tensorflow/issues/55364 and https://github.com/tensorflow/tensorflow/issues/53380 for the reference. Thank you!","  I've cleared the gradle cache and done all the steps in the guide, but the error persists. The issues you stated did not help. **UPDATE** I've tried using the TFLite Model Benchmark Tool with Android Apk (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark/android) to see if i'll have the same issue with Hexagon. In order to be able to use the Hexagon delegate i do the following:  where `libhexagon_interface.so` comes from this link from this guide and `libhexagon_nn_skel(_v65/6).so` come from this link (v1.20.0.1) from this guide.  When i set `use_hexagon=true` and **don't** specify the `hexagon_lib_path`, then the path is set to: `I tflite  : Hexagon lib path: [/data/app/~~K6aeHsxXcgmL2FRThR7mBQ==/org.tensorflow.lite.benchmarktPmERhUnFAHAenBJZq4OQw==/lib/arm64]` and i get the error:  But when i specify `hexagon_lib_path=/data/local/tmp/`, then the delegate is applied succesfully:  Does this help with the problem in my Android app in any way? Thanks","Hi   Although the documentation suggests to use v1.20.0.1 , the config has v1.20.0.9 as latest version to use for nightly snapshots which can be downloaded from here. Could you please try with `libhexagon_interface.so` using v1.20.0.9 and see if it resolves the issue? Thanks.","Hello   I think i am missing something. The link you provided for v1.20.0.9 does not contain `libhexagon_nn_skel(_v65/6).so` files. I copy the new `libhexagon_interface.so` to my Android `jniLibs/arm64v8a/` directory, but the error persists: `Failed to load libhexagon_interface.so, Error: dlopen failed: library ""libadsprpc.so"" not found: needed by /data/app/~~3WH2wsowpMNgALxjaSkcCw==/com.example.XTLMj82qPraRQM25waMKg==/lib/arm64/libhexagon_interface.so in namespace classloadernamespace` Should i put `libhexagon_interface.so` somewhere else? Thank you","Hi   I have observed that the  path for `hexagon_lib_path` has to be `/data/local/tmp/` as per the build file for the benchmark tool. https://github.com/tensorflow/tensorflow/blob/785f7f02f78c6af70ee79729ce95724e89a221bd/tensorflow/lite/tools/benchmark/BUILDL38 Are per the hexagon delegate documentation, >'libhexagon_interface.so' which holds the interface that the delegate uses. It must be available if you linked the hexagon_delegate library to TFLite. You can load it either from shell by overriding LD_LIBRARY_PATH=$LD_LIBRARY_PATH:""path to the so"", or add it inside your apk in a way it is available. >'libhexagon_nn_skel(_v65/_v66).so' which holds the DSP code. Use TfLiteHexagonInitWithPath(..) and provide the path to the directory which holds the shared libraries for the Hexagon NN on device. If you're using TfLiteHexagonInit() then You will need to set environment variable ""ADSP_LIBRARY_PATH"" to ""path_to_the_lib"";/system/lib/rfsa/adsp;/system/vendor/lib/rfsa/adsp;/dsp Note that separator here is ';' not ':' You can push all 3 files, and the library will pick the one needed based on the runtime. Or if you are sure of what you will use on the device then push only one of them. Could you please confirm if you are following this instructions to set `.so` files? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
754,"以下是一个github上的tensorflow下的一个issue, 标题是(error: undefined reference to 'TfLiteGpuDelegateBindGlBufferToTensor')， 内容是 (Hi  the amazing porygon~, I've checkouted the branch ""v2.10.0"" for deploying tflite on Android. In order to avoiding cpugpu memory copy, I used the function 'TfLiteGpuDelegateBindGlBufferToTensor' but got logs saying as the issue title during project configuration. BTW,  I had include ""tensorflow/lite/delegates/gpu/cl/gpu_api_delegate.h"" I had compiled ""libtensorflowlite.so"", ""libtensorflowlite_gpu_delegate.so"", and all those .h included by my project Please can you shed me some light? Thanks~)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,picard314,error: undefined reference to 'TfLiteGpuDelegateBindGlBufferToTensor',"Hi  the amazing porygon~, I've checkouted the branch ""v2.10.0"" for deploying tflite on Android. In order to avoiding cpugpu memory copy, I used the function 'TfLiteGpuDelegateBindGlBufferToTensor' but got logs saying as the issue title during project configuration. BTW,  I had include ""tensorflow/lite/delegates/gpu/cl/gpu_api_delegate.h"" I had compiled ""libtensorflowlite.so"", ""libtensorflowlite_gpu_delegate.so"", and all those .h included by my project Please can you shed me some light? Thanks~",2023-04-23T13:16:04Z,stat:awaiting tensorflower type:bug comp:lite TFLiteGpuDelegate TF 2.10,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60403,"Hi ， Sorry, I should have noticed that you are the Assignee right now. Please can you shed me some light on this issue? Thanks~",Hi   The `TfLiteGpuDelegateBindGlBufferToTensor` should be able to refer by inclusion of gpu_api_delegate.h https://github.com/tensorflow/tensorflow/blob/41c3f9ed867b91b8922c6f5828ecce63c85188dd/tensorflow/lite/delegates/gpu/cl/gpu_api_delegate.hL91 Could you please provide more details or a sample code snippet to reproduce the error? Thanks,"Hi   Thanks a lot for looking into my issue. I am sorry for replying late since I was swamped in a sudden urgent task. Android.tar.gz Here I paste a demo project which can reveal the error I have encountered. Please unzip this .tar.gz and check ""Android/README.txt"" first.  Besides, I'd like to ask whether or not your ""texture I/O"" supports TfLiteGpuDelegateV2. Thanks.","Hi,  and   May I lit up this issue again~ Thanks for your attention! Now I guess my ""libtensorflowlite_gpu_delegate.so"" (attached) may be incomplete. It was got by running bazel build c opt config android_arm64 copt DCL_DELEGATE_NO_GL copt DTFLITE_GPU_BINARY_RELEASE linkopt s tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so , with logs looking correct. What do you say please~ I am looking forward to your replies. Thanks again! Best, picard314","Hi,   Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here: https://github.com/googleaiedge/LiteRT/issues/176 Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
927,"以下是一个github上的tensorflow下的一个issue, 标题是(Cuda memory error)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/Compiler version visual studio  CUDA/cuDNN version 11.2/v8.2.1.32  GPU model and memory GTX 1650/ System Memory:8GB  Current Behaviour? I am trying to train a model for binary classification, with class1 dataset= 2716 and class 2 dataset= 2164,  The training did happened successfully but during prediction I got error.  The code is quite short so I will paste the whole code here,    Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Utkarsha666,Cuda memory error,"Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10  Custom Code Yes  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/Compiler version visual studio  CUDA/cuDNN version 11.2/v8.2.1.32  GPU model and memory GTX 1650/ System Memory:8GB  Current Behaviour? I am trying to train a model for binary classification, with class1 dataset= 2716 and class 2 dataset= 2164,  The training did happened successfully but during prediction I got error.  The code is quite short so I will paste the whole code here,    Standalone code to reproduce the issue   Relevant log output  ",2023-04-22T19:33:13Z,stat:awaiting response stale comp:keras type:performance TF 2.10,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60401,", Could you please try limiting GPU memory growth using any of the methods listed in this guide. https://www.tensorflow.org/guide/gpulimiting_gpu_memory_growth Could you please try using the latest Tensorflow version for windows which can be installed with WSL2. Also, from TensorFlow 2.12 CUDA and CuDNN dependency has been upgraded to 11.8 and 8.6 respectively. Refer the document here for installation instructions https://www.tensorflow.org/install/pip and let us know if you observe the same behavior in the latest Tensorflow version. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1455,"以下是一个github上的tensorflow下的一个issue, 标题是(The inferred shape of `tf.RaggedTensor.row_lengths(axis=2)` in Keras graph is incorrect for ragged tensor with uniform row lengths)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version TF 2.12, TF nightly 2.13.0dev20230420  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Assume a Keras graph gets a ragged tensor with uniform row lengths in the axis 1, so for example  Then `inputs.row_lengths(axis=2)` is a `KerasTensor` with a correct spec `RaggedTensorSpec(TensorShape([None, 64]), ...)`. However, when you index the first axis using a ""full"" slice, i.e.  you should get the same tensor  but you get a `KerasTensor` with an incorrect spec `RaggedTensorSpec(TensorShape([1, 64]), ...)`.  Standalone code to reproduce the issue A Colab notebook reproducing the issue both in TF 2.12.0 and in TF nightly 2.13.0dev20230420 can be found at https://colab.research.google.com/drive/1RKvNdB_81yKZkfzDpefIPJU2pgqZuYUY?usp=sharing The full source also follows:   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,foxik,The inferred shape of `tf.RaggedTensor.row_lengths(axis=2)` in Keras graph is incorrect for ragged tensor with uniform row lengths,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version TF 2.12, TF nightly 2.13.0dev20230420  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Assume a Keras graph gets a ragged tensor with uniform row lengths in the axis 1, so for example  Then `inputs.row_lengths(axis=2)` is a `KerasTensor` with a correct spec `RaggedTensorSpec(TensorShape([None, 64]), ...)`. However, when you index the first axis using a ""full"" slice, i.e.  you should get the same tensor  but you get a `KerasTensor` with an incorrect spec `RaggedTensorSpec(TensorShape([1, 64]), ...)`.  Standalone code to reproduce the issue A Colab notebook reproducing the issue both in TF 2.12.0 and in TF nightly 2.13.0dev20230420 can be found at https://colab.research.google.com/drive/1RKvNdB_81yKZkfzDpefIPJU2pgqZuYUY?usp=sharing The full source also follows:   Relevant log output  ",2023-04-22T18:30:48Z,stat:awaiting response type:bug stale comp:keras comp:ops TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60400,Hi  Thank you for reporting this issue! I was able to replicate the issue in Colab using Tensorflow 2.12 and tfnightly(2.13.0.dev20230424). Please find the gists  TF 2.12 & tfnightly.  Thank you!,"Hi  , The difference in results are due to 2 reasons.The code `inputs.row_lengths(axis=1)` outputs `KerasTensor` with `type_spec=TensorSpec` whereas inputs.row_lengths(axis=2) outputs` KerasTensor(type_spec=RaggedTensorSpec)`. Please note the difference here `TensorSpec` vs `RaggedTensorSpec`. When we apply index/slicing operation [:] , internally both calls __getitem__ method and you can find from the colab gist attached in comment, for axis=1 tf.__operators__.getitem' method called and for axis=2 'tf.__operators__.ragged_getitem' called and both are different methods and hence different results.  Here the axis and the type spec making the difference. However, I have tested the same with actual data and observed same result with same specs and values.Please refer the attached gist with the same operations performed on actual ragged tensor.Can you test also with some actual data and confirm if there is any difference.","Thanks for your answer! The problem is that  while it should be the same, because for any tensor (or ragged tensor) `a`, it should be the case that `a.shape == (a[:]).shape`. I understand the difference between `inputs.row_lengths(axis=1)` and `inputs.row_lengths(axis=2)`; I just included it in the example to show that for `axis=1` it is indeed the case that  The reported problem concerns only static shape inference; during the graph evaluation, the shape is correct. That means that even if `inputs.row_lengths(axis=2)[:].shape[0]` is `1`, the `tf.shape(inputs.row_lengths(axis=2)[:])[0]` can be something different than 1 (in the gist it is 5), which is incorrect  such incorrect static shape can cause problems during graph construction. We encountered the problem in a OCRlike task  given images of fixed height and dynamic width as ragged tensors, we wanted to extract the widths of the images. That can be achieved using for example `inputs.row_lengths(axis=2)[:, 0]`  but the `.shape` of that is reported as `(1,)`, which is clearly incorrect. So I believe this behavior is indeed a bug.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1821,"以下是一个github上的tensorflow下的一个issue, 标题是(I am noticing lower validation accuracy on my dataset between Tensorflow 2.4 and Tensorflow 2.9)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9 and 2.4  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to train an image classifier model using EfficientNetB1 on a custom dataset and I am trying out TensorFlow 2.4 and TensorFlow 2.9. I am using the exact same script with the same optimizer, augmentation, parameters, and dataset. I ran training 5 times and the results are around the same. Results:  TensorFlow 2.4: ~9798% Accuracy on the validation set.  TensorFlow 2.9: ~9395% Accuracy on the validation set More information: I am using Adam optimizer with 0.0001 lr, batch size of 16, using imagenet model weights, and categorical_crossentropy for my loss. I am using the same dataset on each version and I am using the same training script. I simply switch conda enviroments to TF 2.4 and 2.9. Did something change between both versions that cause this discrepancy? Did the EfficientNet model weights change? Is the way the validation accuracy are calculated is different? Are the opimizers implementations are different? I would appreciate your help and I would like some information on how to make it consistent between both versions. Thanks  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hlreicha,I am noticing lower validation accuracy on my dataset between Tensorflow 2.4 and Tensorflow 2.9,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9 and 2.4  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am trying to train an image classifier model using EfficientNetB1 on a custom dataset and I am trying out TensorFlow 2.4 and TensorFlow 2.9. I am using the exact same script with the same optimizer, augmentation, parameters, and dataset. I ran training 5 times and the results are around the same. Results:  TensorFlow 2.4: ~9798% Accuracy on the validation set.  TensorFlow 2.9: ~9395% Accuracy on the validation set More information: I am using Adam optimizer with 0.0001 lr, batch size of 16, using imagenet model weights, and categorical_crossentropy for my loss. I am using the same dataset on each version and I am using the same training script. I simply switch conda enviroments to TF 2.4 and 2.9. Did something change between both versions that cause this discrepancy? Did the EfficientNet model weights change? Is the way the validation accuracy are calculated is different? Are the opimizers implementations are different? I would appreciate your help and I would like some information on how to make it consistent between both versions. Thanks  Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-22T13:16:36Z,stat:awaiting response type:support stale TF 2.9,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60399,", I was facing a different issue while executing the given code. Kindly find the gist of it here. Also there might be below chances for the low validation accuracy. **1.** You are trying to apply some sort of preprocessing (zero meaning, normalizing, etc.) to either your training set or validation set, but not the other. **2.** If you built some layers that perform differently during training and inference from scratch, your model might be incorrectly implemented (e.g. are moving mean and moving standard deviation for batch normalization getting updated during training?  If using dropout, are weights scaled properly during inference?). This might be the case if your code implements these things from scratch and does not use Tensorflow builtin functions. **3.** Overfitting. I suspect that the other two options more likely in your specific situation as your validation accuracy might stuck at 50% for some epochs. Using a random sample from your validation set: It means your validation set at each evaluation step is different, so is your validationloss. Using a weighted lossfunction(which is used in case of highly imbalanced classproblems). At train step, you weigh your loss function based on classweights, while at dev step you just calculate the unweighted loss. In such case, though your network is stepping into convergence, you might see lots of fluctuations in validation loss after each trainstep. ","  Hi, thank you for your response. I can post more functioning code block later if it would help. The problem is that I am not getting low validation (remember, I am in the 90% range), I am getting lower validation score with TensorFlow 2.9 compared to TensorFlow 2.4. The code (loading image, preprocessing, model building, and etc) is all the same, it is the matter of me switching conda enviroments.  1. I am not doing any preprocessing other than dividing the image by 255.0 and it is applied to both train/val sets. This never caused issues in TensorFlow 2.4 2. I am not using any custom layers, I import my EfficienetNet model, flatten it, and add the  final dense layer. 3. I have not experienced this behavior I get these results after I ran my training script 5 times for each version.  TensorFlow 2.4: ~9798% Accuracy on the validation set.  TensorFlow 2.9: ~9395% Accuracy on the validation set I should specify I set my random seed values as well. Did something change between both versions that causes EfficientNet to lose its performance?","  Would you be able to create a complete script / Colab using standard datasets, for example in `tensorflow_datasets` https://github.com/tensorflow/datasets to replicate this issue?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1909,"以下是一个github上的tensorflow下的一个issue, 标题是(bazel compile error: enumeration value ‘CUDNN_POINTWISE_RECIPROCAL’ not handled in switch)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v2.12.0  Custom Code Yes  OS Platform and Distribution Linux Debian Bullseye  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version gcc (Debian 10.2.16) 10.2.1 20210110  CUDA/cuDNN version cuda_11.6.r11.6/compiler.31057947_0  GPU model and memory RTX A4000  Current Behaviour? bazel build config=cuda config=mkl //tensorflow/tools/pip_package:build_pip_package failed displaying following error messages ERROR: /mnt/data/kentwork/src/AI/tensorflow/tensorflow/compiler/xla/stream_executor/cuda/BUILD:376:11: Compiling tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc MD MF bazelout/k8opt/bin/tensorflow/compiler/xla/stream_executor/cuda/_objs/cudnn_plugin/cuda_dnn.pic.d ... (remaining 141 arguments skipped) In file included from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Operation.h:37,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_OperationGraph.h:36,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Heuristics.h:31,                  from bazelout/k8opt/bin/external/cudnn_frontend_arch)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kentosho,bazel compile error: enumeration value ‘CUDNN_POINTWISE_RECIPROCAL’ not handled in switch,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v2.12.0  Custom Code Yes  OS Platform and Distribution Linux Debian Bullseye  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version gcc (Debian 10.2.16) 10.2.1 20210110  CUDA/cuDNN version cuda_11.6.r11.6/compiler.31057947_0  GPU model and memory RTX A4000  Current Behaviour? bazel build config=cuda config=mkl //tensorflow/tools/pip_package:build_pip_package failed displaying following error messages ERROR: /mnt/data/kentwork/src/AI/tensorflow/tensorflow/compiler/xla/stream_executor/cuda/BUILD:376:11: Compiling tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc MD MF bazelout/k8opt/bin/tensorflow/compiler/xla/stream_executor/cuda/_objs/cudnn_plugin/cuda_dnn.pic.d ... (remaining 141 arguments skipped) In file included from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Operation.h:37,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_OperationGraph.h:36,                  from bazelout/k8opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend/third_party/cudnn_frontend/include/cudnn_frontend_Heuristics.h:31,                  from bazelout/k8opt/bin/external/cudnn_frontend_arch",2023-04-22T10:05:31Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.12,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60398,"It looks like you are encountering a compilation error when building TensorFlow with Bazel on your Debian Bullseye system using CUDA and MKL. The error is related to a missing switch case in the cudnn_frontend library. One possible solution to this issue is to update the cudnn_frontend library to a newer version that has the missing switch case. You can try updating the cudnn_frontend by running the following command: arduino Copy code bazel build config=cuda config=mkl config=monolithic //tensorflow/tools/pip_package:build_pip_package incompatible_remove_native_http_archive=false This command will build TensorFlow with CUDA, MKL, and the latest version of the cudnn_frontend library. If updating the cudnn_frontend library doesn't solve the issue, you can try disabling the config=mkl option when building TensorFlow with Bazel. You can do this by running the following command: arduino Copy code bazel build config=cuda //tensorflow/tools/pip_package:build_pip_package This command will build TensorFlow with only CUDA and without MKL. This might help you to identify whether the issue is related to the MKL library or not. If neither of these solutions works, you might want to provide more information such as the complete build log or the full error message to help us better understand the issue.","$ bazel build config=cuda config=mkl config=monolithic //tensorflow/tools/pip_package:build_pip_package incompatible_remove_native_http_archive=false ERROR: incompatible_remove_native_http_archive=false :: Unrecognized option: incompatible_remove_native_http_archive=false gives Unrecognized option error I also tried removing config mkl, which I can not get any improvement.",https://github.com/tensorflow/tensorflow/issues/60362 FYI. btw: tensorflow V2.12.0 requires 8.6cuDNN and 11.8 CUDA,"Hi  , Please look at the tested configurations here. For Tf2.12 version the tested configurations are GCC9.3.1 , CUDA11.8,cuDNN8.6. Can you please cross check with the tested configurations. Also I would like to know the sequence of steps followed for build.Have you installed cuDNN as per instructions ? I am interested to know the sequence of steps followed by you for GPU setup with CUDA,cuDNN toolkit installations etc. Official instructions as per documentation mentioned here.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,compile suceeded for gcc10.2.1 CUDA11.8 cuDNN8.9 with following patch it might be a wired patch ,"Hi  , This might be due to the fact that TF tested cuDNN version is 8.6 whereas you are trying to use different version 8.9 and hence the change in dependencies might be worked. I assume you haven't checked with cuDNN8.6 which is a tested configuration. If you have tested this but still fails please let us know. have you done the patch suitable for cuDNN8.9 directly please let us know.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"I try to build with cuDNN 8.6 instead of cuDNN8.9 and sucssess to build with no error.　Also, when using CuDNN 8.9, I had experienced an abnormal termination of python when running model.fit on sensorflow 2.12.0, but this phenomenon was　fixed by using CuDNN 8.6.",Are you satisfied with the resolution of your issue? Yes No,"> It looks like you are encountering a compilation error when building TensorFlow with Bazel on your Debian Bullseye system using CUDA and MKL. The error is related to a missing switch case in the cudnn_frontend library. >  > One possible solution to this issue is to update the cudnn_frontend library to a newer version that has the missing switch case. You can try updating the cudnn_frontend by running the following command: >  > arduino Copy code bazel build config=cuda config=mkl config=monolithic //tensorflow/tools/pip_package:build_pip_package incompatible_remove_native_http_archive=false This command will build TensorFlow with CUDA, MKL, and the latest version of the cudnn_frontend library. >  > If updating the cudnn_frontend library doesn't solve the issue, you can try disabling the config=mkl option when building TensorFlow with Bazel. You can do this by running the following command: >  > arduino Copy code bazel build config=cuda //tensorflow/tools/pip_package:build_pip_package This command will build TensorFlow with only CUDA and without MKL. This might help you to identify whether the issue is related to the MKL library or not. >  > If neither of these solutions works, you might want to provide more information such as the complete build log or the full error message to help us better understand the issue. Is this a chatgpt reply?"
1893,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: Unexpected result of `predict_function` (Empty batch_outputs))， 内容是 (I have the below model I'm working on. The intention is to forecast the 'Index' field based on the impacts from the fields A,B,C and D. The Date field is of the type 'MM/DD/YYYY'  `Import necessary libraries import pandas as pd import numpy as np from sklearn.preprocessing import MinMaxScaler from keras.models import Sequential from keras.layers import Dense, LSTM Load the dataset df = pd.read_csv('New Final.csv', usecols=['Date', 'Index', 'A', 'B', 'C', 'D']) df = df.sort_values('Date') df = df.set_index('Date') Normalize the data using MinMaxScaler scaler = MinMaxScaler(feature_range=(0, 1)) scaled_data = scaler.fit_transform(df) Split data into training and testing sets training_data_len = int(len(scaled_data) * 0.8) train_data = scaled_data[0:training_data_len, :] test_data = scaled_data[training_data_len:, :] Prepare the data for training def create_dataset(dataset, time_step=1):     data_X, data_y = [], []     for i in range(len(dataset)  time_step):         a = dataset[i:(i + time_step), :]         data_X.append(a)         data_y.append(dataset[i + time_step, 0])     return np.array(data_X), np.array(data_y) time_steps = 60 X_train, y_train = create_dataset(train_data, time_steps) X_test, y_test = create_dataset(test_data, time_steps) Build the model model = Sequential() model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))) model.add(LSTM(units=50, return_sequences=True)) model.add(LSTM(units=50)) model.add(Dense(units=1)) Compile the model model.compile(optimizer='adam', loss='mean_squared_error') model.compile(loss='mean_squared_error', optimizer='adam')请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Erangi2020,ValueError: Unexpected result of `predict_function` (Empty batch_outputs),"I have the below model I'm working on. The intention is to forecast the 'Index' field based on the impacts from the fields A,B,C and D. The Date field is of the type 'MM/DD/YYYY'  `Import necessary libraries import pandas as pd import numpy as np from sklearn.preprocessing import MinMaxScaler from keras.models import Sequential from keras.layers import Dense, LSTM Load the dataset df = pd.read_csv('New Final.csv', usecols=['Date', 'Index', 'A', 'B', 'C', 'D']) df = df.sort_values('Date') df = df.set_index('Date') Normalize the data using MinMaxScaler scaler = MinMaxScaler(feature_range=(0, 1)) scaled_data = scaler.fit_transform(df) Split data into training and testing sets training_data_len = int(len(scaled_data) * 0.8) train_data = scaled_data[0:training_data_len, :] test_data = scaled_data[training_data_len:, :] Prepare the data for training def create_dataset(dataset, time_step=1):     data_X, data_y = [], []     for i in range(len(dataset)  time_step):         a = dataset[i:(i + time_step), :]         data_X.append(a)         data_y.append(dataset[i + time_step, 0])     return np.array(data_X), np.array(data_y) time_steps = 60 X_train, y_train = create_dataset(train_data, time_steps) X_test, y_test = create_dataset(test_data, time_steps) Build the model model = Sequential() model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))) model.add(LSTM(units=50, return_sequences=True)) model.add(LSTM(units=50)) model.add(Dense(units=1)) Compile the model model.compile(optimizer='adam', loss='mean_squared_error') model.compile(loss='mean_squared_error', optimizer='adam'",2023-04-21T17:49:11Z,stat:awaiting response type:bug stale comp:keras,closed,2,4,https://github.com/tensorflow/tensorflow/issues/60394,", I tried to execute the mentioned code and it was failing due to a different error. Kindly find the gist of it here and also Have you got the chance to take a look at this PR which was raised for the similar error and it was open and under review with the Developer.  https://github.com/kerasteam/keras/pull/16216 https://github.com/kerasteam/keras/pull/18042 https://github.com/kerasteam/keras/issues/16202 Requesting you to follow the same issue for the updates. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1327,"以下是一个github上的tensorflow下的一个issue, 标题是(Compile tensorflow with static cuda libs)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Centos &  Mobile device _No response_  Python version Python3.9.16  Bazel version bazel5.3.0  GCC/Compiler version 9.3.1   CUDA/cuDNN version 11.2  GPU model and memory Quadro RTX 4000  Current Behaviour? I am trying to link TF with cuda static libs (cublas, cufft, cusparse etc). I have made some changes in the following files: 1. tensorflow/lite/toco/BUILD b/tensorflow/lite/toco/BUILD 2. tensorflow/tensorflow.bzl 3. tensorflow/compiler/mlir/tools/kernel_gen/BUILD 4. third_party/gpus/cuda_configure.bzl In the first 3 files I have added inkopts = if_not_windows([""lm"", ""Wl,ldl""]) + lrt_if_needed() + [""L/usr/local/cuda/lib64"", ""L/usr/local/cuda/extras/CUPTI/lib64"", ""lcuda"", ""lcudart"", ""lcublas"",""lcublasLt"",""lculibos"",""lcufft"", ""lcudnn"", ""lcurand"", ""lcupti"", ""lcusolver"", ""lcusparse""], In the fourth I have changed static = False to static = True.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,manospavlidakis,Compile tensorflow with static cuda libs,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Centos &  Mobile device _No response_  Python version Python3.9.16  Bazel version bazel5.3.0  GCC/Compiler version 9.3.1   CUDA/cuDNN version 11.2  GPU model and memory Quadro RTX 4000  Current Behaviour? I am trying to link TF with cuda static libs (cublas, cufft, cusparse etc). I have made some changes in the following files: 1. tensorflow/lite/toco/BUILD b/tensorflow/lite/toco/BUILD 2. tensorflow/tensorflow.bzl 3. tensorflow/compiler/mlir/tools/kernel_gen/BUILD 4. third_party/gpus/cuda_configure.bzl In the first 3 files I have added inkopts = if_not_windows([""lm"", ""Wl,ldl""]) + lrt_if_needed() + [""L/usr/local/cuda/lib64"", ""L/usr/local/cuda/extras/CUPTI/lib64"", ""lcuda"", ""lcudart"", ""lcublas"",""lcublasLt"",""lculibos"",""lcufft"", ""lcudnn"", ""lcurand"", ""lcupti"", ""lcusolver"", ""lcusparse""], In the fourth I have changed static = False to static = True.   Standalone code to reproduce the issue   Relevant log output  ",2023-04-20T14:00:14Z,stat:awaiting response type:build/install stale subtype:centos TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60387,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. Your shared link has expired. Could you please provide it again? Also, try using the latest version for better performance. Here, I am attaching the documentation to check all compatible versions. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1041,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow 2.11.1 bazel failed with option framework_shared_object=false)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf2.11.1  Custom Code No  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.8.10  Bazel version 5.3.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Tried to build Tensorflow 2.11.1 (and Tensorflow 2.12.0) using Tensorflow docker image: tensorflow/tensorflow:devel with option framework_shared_object=false. The build fails with the following error. (It's a build for CPU only). Using the same option, previous versions of Tensorflow (such as v2.10.1) build without error.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,tomchen1000,Tensorflow 2.11.1 bazel failed with option framework_shared_object=false,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf2.11.1  Custom Code No  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.8.10  Bazel version 5.3.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Tried to build Tensorflow 2.11.1 (and Tensorflow 2.12.0) using Tensorflow docker image: tensorflow/tensorflow:devel with option framework_shared_object=false. The build fails with the following error. (It's a build for CPU only). Using the same option, previous versions of Tensorflow (such as v2.10.1) build without error.   Standalone code to reproduce the issue   Relevant log output  ",2023-04-19T13:32:33Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux TF 2.11,open,0,7,https://github.com/tensorflow/tensorflow/issues/60368,"Hi  , Can you please cross check and confirm the command ? Is it `config=opt `? Your command getting error below, which is obvious.  What are the configurations you have opted in `./configure.py` step if you have used `config=opt` ? I tried building on a Ubuntu VM by omitting `config=opt` from your command and it seems similar errors with different ops replicated as reported by you. You may please check and confirm. "," ,  One observation is that even though you are using the flag `define framework_shared_object=false` its not being considered by bazel as in bazel the default setting is `framework_shared_object=true` and this can be override with `config=monolithic`. Please have a look at source here. https://github.com/tensorflow/tensorflow/blob/f318efaa1175af1e76a3b75f8ebae4f776518cb9/.bazelrcL218L222 From the logs attached above you can see `framework_shared_object=true` under `Info` log sets by default and it is not override anywhere.  When I added `config=monolithic` now `framework_shared_object=false` has been set. You can find the command and logs below.  Please try the above command and let us if it works. Thanks!","  No, it doesn't work either.  Got this error:  ImportError: libtensorflow_framework.so.2: cannot open shared object file: No such file or directory. See the command and logs below. ","The same error occurs in TensorFlow v2.11.0, v2.12.0 and v2.13.0rc0. All of the following will produce the same error.    ","Hi, Were you able to find a resolution for?  ",The error you're encountering seems to be related to missing references to certain symbols during the linking phase of the TensorFlow build. This might be due to changes in the codebase or build configurations between TensorFlow versions. Pull the docker image  Run the container Do a clean build cache bazel clean expunge Update bazel aptget install y bazel analyze for the verbos logs Check configuration flags and Build Without framework shared objects,"Same issue with Tensorflow 2.11.1, any updates for this solution?"
1957,"以下是一个github上的tensorflow下的一个issue, 标题是(Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/conv.cc:343 input->dims->size != 4 (3 != 4))， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution MacOS  Mobile device Linux (Android Oneplus)  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am working on this noise and echo cancellation on android. I used this tflite model created via https://colab.research.google.com/drive/1HzGdovqo0gg_xW1QL7ygbkYlWqbyMaKL?usp=sharingscrollTo=2kRjDbp7og1u Now I want to use a ShortArray() audioData and want to pass and get a ShortArray() data back with  removed echo and noise. I tried creating, tflite model, predict function works there, I incorporated it in android but whenever data is passed in the array it returns the error   Standalone code to reproduce the issue     I used this tflite model in android to run this      [1]: https://colab.research.google.com/drive/1HzGdovqo0gg_xW1QL7ygbkYlWqbyMaKL?usp=sharingscrollTo=2kRjDbp7og1u shell but whenever the app is running its crashing with this error  java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/conv.cc:343 input>dims>size != 4 (3 != 4)                                                                                                     Node number 5 (CONV_2D) failed to prepare.                                                                                                     	at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,gptshubham595,Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/conv.cc:343 input->dims->size != 4 (3 != 4),"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution MacOS  Mobile device Linux (Android Oneplus)  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I am working on this noise and echo cancellation on android. I used this tflite model created via https://colab.research.google.com/drive/1HzGdovqo0gg_xW1QL7ygbkYlWqbyMaKL?usp=sharingscrollTo=2kRjDbp7og1u Now I want to use a ShortArray() audioData and want to pass and get a ShortArray() data back with  removed echo and noise. I tried creating, tflite model, predict function works there, I incorporated it in android but whenever data is passed in the array it returns the error   Standalone code to reproduce the issue     I used this tflite model in android to run this      [1]: https://colab.research.google.com/drive/1HzGdovqo0gg_xW1QL7ygbkYlWqbyMaKL?usp=sharingscrollTo=2kRjDbp7og1u shell but whenever the app is running its crashing with this error  java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/conv.cc:343 input>dims>size != 4 (3 != 4)                                                                                                     Node number 5 (CONV_2D) failed to prepare.                                                                                                     	at org.tensorflow.lite.NativeInterpreterWrapper.allocateTensors",2023-04-19T09:14:34Z,stat:awaiting response type:support stale comp:lite TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60367,Hi  Thanks for reporting the issue. We see that the colab file you have shared has data access issues. Could you please provide a standalone code or a toy tflite model inorder to reproduce the issue? Thanks.,NoiseSuppressionModel.h5 Model.Tflite,"Hi   The input signature of the TFLite model is `'shape_signature': array([   1, 12000,     1]`. I have tested with random data with shape `[1,1200,1]` and model runs without any error. Please find the colab gist here and let us know if it helps. Thanks.",I tried this in android but i'm getting this error  ,"Hi   It is hard to say from the code snippet, but as mentioned earlier please check the input tensor shapes and resize before during inference. Also, If the loaded model in TFLite does not have any defined batch size, converter will take the batch size as 1, and when you evaluate it with the different batch size, you are likely to end up with the problem which you are facing. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
923,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow 2.12 bazel failed!Cuda11.2+cuDNN8.1+Tensorrt7.2 under Ubuntu2004)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf2.12  Custom Code Yes  OS Platform and Distribution Ubuntu2004  Mobile device _No response_  Python version 3.8  Bazel version 5.3  GCC/Compiler version 9.4  CUDA/cuDNN version CUDA11.2/cuDNN8.1  GPU model and memory _No response_ Current Behaviour? TensorRT Version: 7.2.3.4 CUDA Version: 11.2 CUDNN Version: 8.1.1.331 Operating System: Ubuntu20.04 https://github.com/tensorflow/tensorflow/blob/master/.bazelrc Bazel build latest 2.12 source code failed: Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Shuolongbj,Tensorflow 2.12 bazel failed!Cuda11.2+cuDNN8.1+Tensorrt7.2 under Ubuntu2004,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf2.12  Custom Code Yes  OS Platform and Distribution Ubuntu2004  Mobile device _No response_  Python version 3.8  Bazel version 5.3  GCC/Compiler version 9.4  CUDA/cuDNN version CUDA11.2/cuDNN8.1  GPU model and memory _No response_ Current Behaviour? TensorRT Version: 7.2.3.4 CUDA Version: 11.2 CUDNN Version: 8.1.1.331 Operating System: Ubuntu20.04 https://github.com/tensorflow/tensorflow/blob/master/.bazelrc Bazel build latest 2.12 source code failed: Standalone code to reproduce the issue   Relevant log output _No response_,2023-04-19T05:42:05Z,type:build/install subtype: ubuntu/linux subtype:bazel TF 2.12,closed,1,17,https://github.com/tensorflow/tensorflow/issues/60362,", same here. I am trying to build TensorFlow 2.12 in docker: ","When building from master, please always give the commit, given TF moves fast forward. Does it reproduce if you switch to a newer commit?","Sorry, I misread the link to the `.bazelrc` in master branch. Can you try a `bazel clean expunge` and then build again? Adding  and  for the Docker stuff too.","> When building from master, please always give the commit, given TF moves fast forward. >  > Does it reproduce if you switch to a newer commit? , TensorFlow fails to build from `r2.12` branch. I haven't tried master, because I try to locally rebuild 2.12 release. > Can you try a `bazel clean expunge` and then build again? I'll try it.","> Can you try a `bazel clean expunge` and then build again? , it didn't help. The same error: ","Could it be because 2.12 uses cuDNN 8.6, Cuda 11.8?","> Could it be because 2.12 uses cuDNN 8.6, Cuda 11.8?  Hmm, maybe I am using the wrong docker container. What's the right docker container with fresh cuda to build 2.12?",Tagging  ,Now I am trying the following docker (at least it has correct CUDA version): ,As for docker containers using the tensorflow/build ones would be the correct ones.  See: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/tf_sig_build_dockerfiles. I agree that it likely is the mismatch on the original issue as well.  The root level .bazelrc should get an update in the next few days as clang is migrated.   Until then https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/tf_sig_build_dockerfiles/devel.usertools/gpu_gcc.bazelrc has the bazelrc values being used in TF's CI. ,"Thanks Michael & Mihai. Those instructions Michael linked should work. I'll have to look into updating the https://www.tensorflow.org/install/sourcedocker_linux_builds docs. I guess they never got changed, as the SIG Build containers were not initially planned to be official.",I succeeded building TensorFlow 2.12 in `tensorflow/build:2.12python3.8` docker.,"Thank you all.       The relevant documents build from source have been updated to the latest version.well done! !image BTW: bazel.rc TensorRT 7 for CUDA 11.1 is compatible with CUDA 11.2 CUDA 11.2 must be 11.2 update 1,not 11.2 update 2, refer to here tensorrt723/supportmatrix nvrtc is deliver inside the CUDA toolkit, you can also install it separate, I find the links in: ubuntu1804 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cudanvrtc111_11.1.1051_amd64.deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cudanvrtcdev111_11.1.1051_amd64.deb ubuntu2004 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/cudanvrtc111_11.1.1051_amd64.deb https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64/cudanvrtcdev111_11.1.1051_amd64.deb ubuntu2204 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2204/x86_64/cudanvrtc111_11.1.1051_amd64.deb https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2204/x86_64/cudanvrtcdev111_11.1.1051_amd64.deb","In this case, we can close this?",Are you satisfied with the resolution of your issue? Yes No,"And，I sucessed  to build the latest 2.12 version with Cuda11.8+cuDNN8.6+Tensorrt**8.5.2.2**+JAX+Flax under Ubuntu2004 at last. you will continue to meet new ""DataType kFP8"" error as shown in the following information  if you use the tensorrt version between 8.5.3 and 8.6.0 of TensorRT. (API Reference: 8.5.3, 8.6.0) Execution platform: //:platform tensorflow/compiler/tf2tensorrt/convert/weights.cc: In member function ‘size_t tensorflow::tensorrt::convert::TRT_ShapedWeights::size_bytes() const’: tensorflow/compiler/tf2tensorrt/convert/weights.cc:61:10: error: enumeration value ‘kFP8’ not handled in switch [Werror=switch]    61           ^ cc1plus: some warnings being treated as errors Target //tensorflow/tools/pip_package:build_pip_package failed to build INFO: Elapsed time: 1276.053s, Critical Path: 83.16s INFO: 8084 processes: 3883 internal, 4201 local. FAILED: Build did NOT complete successfully",Are you satisfied with the resolution of your issue? Yes No
985,"以下是一个github上的tensorflow下的一个issue, 标题是(Divert calls to MklMatMulOp into BatchMatMulMkl for aarch64)， 内容是 (We observed that for most transformer models, the MklLMatMulOp node in tensorflow gets called. This operation requires an SGEMM BLAS interface which is not supported by the Arm Compute Library (ACL). Hence, when running with TF_ENABLE_ONEDNN_OPTS=1, the suboptimal gemm_api kernels are used in oneDNN (instead of the ACL ones).  Here, we divert calls to MklMatMulOp into BatchMatMulMkl for aarch64 which allows the ACL kernels to be used when running with TF_ENABLE_ONEDNN_OPTS=1 (rather than the gemm_api ones). This shows the speedups gained with this RP for a range of transformer models using 8 intra threads and a sequence length of 128: !speedup8threads And this is with 16 threads and also 128 for sequence length: !speedup16threads)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gemma,fadara01,Divert calls to MklMatMulOp into BatchMatMulMkl for aarch64,"We observed that for most transformer models, the MklLMatMulOp node in tensorflow gets called. This operation requires an SGEMM BLAS interface which is not supported by the Arm Compute Library (ACL). Hence, when running with TF_ENABLE_ONEDNN_OPTS=1, the suboptimal gemm_api kernels are used in oneDNN (instead of the ACL ones).  Here, we divert calls to MklMatMulOp into BatchMatMulMkl for aarch64 which allows the ACL kernels to be used when running with TF_ENABLE_ONEDNN_OPTS=1 (rather than the gemm_api ones). This shows the speedups gained with this RP for a range of transformer models using 8 intra threads and a sequence length of 128: !speedup8threads And this is with 16 threads and also 128 for sequence length: !speedup16threads",2023-04-18T16:32:56Z,ready to pull comp:mkl size:M,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60355,This commit seems to have introduced 4 unit test failures on ARM_CI. https://github.com/tensorflow/tensorflow/actions/runs/4743110078,"Hi   These are from `test_invalid_shape` in `tensorflow/python/kernel_tests/math_ops/tensordot_op_test.py` due to inconsistent error messages thrown by `MklMatMul` and `MklBatchMatMul`. The test started failing because this PR rewires the matmuls  uses `MklBatchMatMul` instead of `MklMatMul` The 2 error messages mean the same thing, but the one thrown by `MklBatchMatmul` is different from the one expected by the test (the one thrown by `MklMatMul`). This is the one currently being thrown: `lhs mismatch rhs shape: 2 vs. 3: [2,2] [3,2]` This is the expected one: `""Matrix sizeincompatible: In\[0\]: \[2,2\], In\[1\]: \[3,2\]"")` I'll put a PR very soon to standardize the error message between the 2 matmuls. Sorry for any inconveniences "
1288,"以下是一个github上的tensorflow下的一个issue, 标题是(RuntimeError: Given shapes, [1,784] and [784,100], are not broadcastable.Node number 1 (MUL) failed to prepare.)， 内容是 ( 1. System information I am using Google Colab. Gives the output Linux a0c9eeb98a07 5.10.147+ CC(Add support for Python 3.x) SMP Sat Dec 10 16:00:40 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux, when I run uname a. Tensorflow Version: 2.12.0  2. Code Reference TensorFlow Model Colab: The basic conversion to TFLite without any representative dataset works just fine. However, the problematic portions are cells 4, and 5, where I am trying to perform a TFLite conversion with a representative dataset.    3. Failure after conversion It throws the following error.  Following is the netron image and the problematic node info. !image I do not suspect the issue to be with the broadcasting of scalar r in the multiplication with W1_1, because the code here works just fine. The only difference in this new code is that the __call__ implementation only takes r as the input argument and returns the product of r and W1_1, which does not emit the error shown above, even though there is a broadcast.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,aanujdu,"RuntimeError: Given shapes, [1,784] and [784,100], are not broadcastable.Node number 1 (MUL) failed to prepare."," 1. System information I am using Google Colab. Gives the output Linux a0c9eeb98a07 5.10.147+ CC(Add support for Python 3.x) SMP Sat Dec 10 16:00:40 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux, when I run uname a. Tensorflow Version: 2.12.0  2. Code Reference TensorFlow Model Colab: The basic conversion to TFLite without any representative dataset works just fine. However, the problematic portions are cells 4, and 5, where I am trying to perform a TFLite conversion with a representative dataset.    3. Failure after conversion It throws the following error.  Following is the netron image and the problematic node info. !image I do not suspect the issue to be with the broadcasting of scalar r in the multiplication with W1_1, because the code here works just fine. The only difference in this new code is that the __call__ implementation only takes r as the input argument and returns the product of r and W1_1, which does not emit the error shown above, even though there is a broadcast.",2023-04-18T05:51:45Z,stat:awaiting response type:support stale comp:lite TFLiteConverter TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60345,Hi  Thanks for reporting the issue.  I was able to reproduce this issue. Please find the gist here. Thanks.,"The issue seems to be with the representative dataset which you are using.  Below is the corrected way to use the `representative_data_gen`.  With the above changes, I'm able to convert the model without any issues. Attaching the Gist for reference here https://gist.github.com/sachinprasadhs/fb4b62e7e37b5308217addbe9c2edd5f. ","Thanks for the response  . I can reproduce a working conversion with your code. However, I am still not sure what is the actual issue. Are you saying I need to specify the output as a dictionary with keys as the names of the variables I specify in the input signature? If that is the case, could you please let me know how I write the code if I want to use the train_images_flat array, and the random array as my representative dataset? The example you have given is for random inputs, which works for sure, but I want to know how to extend it for an actual usecase with real variables.  I tried the following code using the dictionary format, but it still gives me a similar error.  Error:  Maybe, what might help is, if you can clearly explain the set of rules I need to follow when I am using the representative_data_gen function, instead of a working example. Thanks,","Well in that case, according to the data which you have, you should provide in the below format.  Here is the working Gist. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1926,"以下是一个github上的tensorflow下的一个issue, 标题是(Importing Tensorflow on Databricks after setting a log configuration causes next cell to hang indefinitely)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.1  Custom Code Yes  OS Platform and Distribution Databricks runtime 11.3 LTS ML  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? On Databricks: importing tensorflow after setting a logz.io logging configuration casues the next cell to hang indefinitely roughly 50% of the time. In the screenshot below, I've cancelled a Databricks command after it spent over 10 minutes calculating `1+1` after a tensorflow import.  !tensorflow import example This only happens when I've set a logz.io logging configuration before importing tensorflow, as shown in the **Standalone code to reproduce this issue**.  Tensorflow seems to pick up the log configuration, as the import outputs this message when the logz.iotoken is invalid: !image And this _somehow_ seems to be related to the issue, as I've only had it happen after I've set the log configuration. The same issue occurs when using tfnightly. It can be observed by adding a magic command: `%pip install tfnightly` to the beginning of the standalone code below. Doing so reveals that tensorboard and logziopythonhandler have several common dependencies, and there could in principle be underlying conflicts. But please note that the issue also occurs with tensorflow 2.9.1 and logziopythonhandler 3.1.1, which were specifically chosen to not have versionconflicts in the common transitive dependencies:  Do an)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Henriklimseth,Importing Tensorflow on Databricks after setting a log configuration causes next cell to hang indefinitely,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.1  Custom Code Yes  OS Platform and Distribution Databricks runtime 11.3 LTS ML  Mobile device _No response_  Python version 3.9.5  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? On Databricks: importing tensorflow after setting a logz.io logging configuration casues the next cell to hang indefinitely roughly 50% of the time. In the screenshot below, I've cancelled a Databricks command after it spent over 10 minutes calculating `1+1` after a tensorflow import.  !tensorflow import example This only happens when I've set a logz.io logging configuration before importing tensorflow, as shown in the **Standalone code to reproduce this issue**.  Tensorflow seems to pick up the log configuration, as the import outputs this message when the logz.iotoken is invalid: !image And this _somehow_ seems to be related to the issue, as I've only had it happen after I've set the log configuration. The same issue occurs when using tfnightly. It can be observed by adding a magic command: `%pip install tfnightly` to the beginning of the standalone code below. Doing so reveals that tensorboard and logziopythonhandler have several common dependencies, and there could in principle be underlying conflicts. But please note that the issue also occurs with tensorflow 2.9.1 and logziopythonhandler 3.1.1, which were specifically chosen to not have versionconflicts in the common transitive dependencies:  Do an",2023-04-17T10:12:32Z,stat:awaiting response type:bug stale comp:runtime comp:apis TF 2.9,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60341,", Could you please try using get_statistics_html that generates the HTML objects and calling those instead of the visualize functions.  Then, try to visualize those functions with the DataBricks .displayHTML function. And also could you please refer to this https://github.com/tensorflow/tfx/issues/2194issuecomment1262088337 for the reference. Thank you!","  Thank you for the response. I'm not sure what you mean, though. I'm not calling any visualize functions. Everything simply hangs after importing tensorflow. If you still think I should call this `get_statistics_html`function, could you please tell me what the argument of the function should be? My code fails without any data. !image","This looks like an issue on the environment side, did you observe this behavior in any other platform.  If not, cloud you please help us with more information to investigate on this further. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
937,"以下是一个github上的tensorflow下的一个issue, 标题是(TPU Tensorflow mapping string label to int with )， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version None  GPU model and memory None  Current Behaviour? I currently get an error when trying to get my batch from a tf.dataset. I am mapping the string label in the tfrecord into int with tf.lookup.StaticHashTable.   Because of that I can't get the batch of my dataset, and train a model with TPU. It works fine with GPU.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Shiro-LK,TPU Tensorflow mapping string label to int with ,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version None  GPU model and memory None  Current Behaviour? I currently get an error when trying to get my batch from a tf.dataset. I am mapping the string label in the tfrecord into int with tf.lookup.StaticHashTable.   Because of that I can't get the batch of my dataset, and train a model with TPU. It works fine with GPU.  Standalone code to reproduce the issue   Relevant log output  ",2023-04-16T09:22:35Z,stat:awaiting response type:bug stale comp:tpus TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60336,  I was able to reproduce the issue on colab using tf2.12 and TPU but it is working as expected on the GPU. Please find the gist of TPU & GPU for reference. Thank you !,"Hi LK , At present not all Ops are executable with TPUs. The iter operation might be one of them. Also, from the error log:  `Executing noncommunication op  originally returned UnavailableError, and was replaced by InternalError to avoid invoking TF network error handling logic`   It seems `iter` operation not supported on TPUs. You can find the TPU supported Ops list here for reference. Please cross check the source and confirm. If you find anything missing here please revert back to us. Thanks!","Thank, I suppose this ops is not compatible for the moment, but it is not mentionned in this documentation. I succeed to make it works without changing anything though, but it may work one time every 20 attempt. Not sure how it is possible.  ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
991,"以下是一个github上的tensorflow下的一个issue, 标题是(Is there some way to set the data type of the tflite model to int8 here?)， 内容是 (Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution linux ubuntu 20  Mobile device linux ubuntu 20   Python version 3.10.6  Bazel version No bazel  GCC/Compiler version 9.4  CUDA/cuDNN version No cuda   GPU model and memory No Gpu  Current Behaviour? I'm new to tensorflow, I was doing mlir related work before, I'm trying to download a model to test what I'm doing, but I'm having a problem, the conv and matmul I implemented on mlir only support int8, I'd like to ask if there is a way to convert the data type of the tflite model here to int8.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,linuxlonelyeagle,Is there some way to set the data type of the tflite model to int8 here?,"Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution linux ubuntu 20  Mobile device linux ubuntu 20   Python version 3.10.6  Bazel version No bazel  GCC/Compiler version 9.4  CUDA/cuDNN version No cuda   GPU model and memory No Gpu  Current Behaviour? I'm new to tensorflow, I was doing mlir related work before, I'm trying to download a model to test what I'm doing, but I'm having a problem, the conv and matmul I implemented on mlir only support int8, I'd like to ask if there is a way to convert the data type of the tflite model here to int8.  Standalone code to reproduce the issue   Relevant log output  ",2023-04-15T09:17:33Z,comp:lite type:others TFLiteConverter TF 2.11,closed,0,14,https://github.com/tensorflow/tensorflow/issues/60334,"Yes, it is possible to convert the data type of a TensorFlow Lite (TFLite) model to int8. One way to do this is to use the TensorFlow Lite Converter, which provides options for quantizing and converting the data type of a TFLite model. To convert the data type of a TFLite model to int8, you can use the tf.lite.TFLiteConverter class in TensorFlow. Here's an example code snippet:  In this example, the original TFLite model is loaded using the tf.lite.Interpreter class, and a new TFLite converter is created with the int8 quantization configuration. The optimizations attribute is set to [tf.lite.Optimize.DEFAULT] to enable default optimizations, and the supported_ops attribute is set to [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] to specify that the converter should use the int8 quantization scheme. Finally, the convert() method of the TFLite converter is called to convert the model to int8, and the resulting model is saved to a file using the open() function. Note that the conversion to int8 may cause some loss of precision, which can affect the accuracy of the model. It is recommended to test the converted model thoroughly to ensure that it performs adequately for your use case.","I'll try it later.Thanks! > Yes, it is possible to convert the data type of a TensorFlow Lite (TFLite) model to int8. One way to do this is to use the TensorFlow Lite Converter, which provides options for quantizing and converting the data type of a TFLite model. I'll try it later.Thanks!",> converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') When i run    `converter = tf.lite.TFLiteConverter.from_saved_model('saved_model')` It says  Then I create saved_model.  It says  ,"The error message suggests that the SavedModel file you provided as input to the from_saved_model method does not contain the expected content. Specifically, the method is looking for a MetaGraphDef with the 'serve' tag, but it cannot find it in the SavedModel file you provided. To investigate further, you can use the saved_model_cli command line tool to inspect the contents of your SavedModel file. Here is an example command you can use:  This will show you all the available tagsets in the SavedModel file, and you can check if the 'serve' tag is present or not. If the 'serve' tag is not present, it is likely that the SavedModel was not exported with the correct signature or signature key. You can try exporting the model again with the correct signature, or you can modify the signature_def_map argument in the from_saved_model method to point to the correct signature key. Here is an example of how to specify the signature_def_map argument:  Here, serving_default is the name of the signature key, and input_signature is the input signature for the model. You should replace these with the correct values for your model.","One other question, the tflite file I downloaded only has a `'1?liteformat=tflite'`, do I need to do something else with it?","The `resnet_v2_101_1_default_1` directory holds my model.There is only  `'1?liteformat=tflite' ` inside.The saved_model directory  was created by me and I use `touch` to create `saved_model.pbtxt|saved_model.pb`,I think  I did it wrong.Should I do something else on `'1?liteformat=tflite'`. ","> One other question, the tflite file I downloaded only has a `'1?liteformat=tflite'`, do I need to do something else with it? This is the standard file format for models that have been optimized for use on mobile and embedded devices. Once you have downloaded the .tflite file, you can use it directly in your mobile or embedded application without any further processing. You will need to load the model into your application and use it to perform inference on your input data. To load the model into your application, you can use the TensorFlow Lite Interpreter API. The exact steps for loading the model and running inference will depend on the programming language and framework you are using in your application.","> The `resnet_v2_101_1_default_1` directory holds my model.There is only `'1?liteformat=tflite' ` inside.The saved_model directory was created by me and I use `touch` to create `saved_model.pbtxt|saved_model.pb`,I think I did it wrong.Should I do something else on `'1?liteformat=tflite'`. >  >  Based on the information provided, it seems like you have saved your model in TensorFlow Lite format (.tflite) in the ""resnet_v2_101_1_default_1"" directory. However, you have manually created a ""saved_model"" directory and its associated files (""saved_model.pbtxt"" and ""saved_model.pb"") in the same directory. This may have caused the files to be overwritten or not saved correctly. If you intend to use the TensorFlow SavedModel format instead of the TensorFlow Lite format, you can save your model using the following code:  This will create a directory named ""saved_model"" with the SavedModel files inside it. Alternatively, if you intend to use the TensorFlow Lite format, you can convert the SavedModel to TensorFlow Lite using the following code:  This will create a file named ""model.tflite"" containing the TensorFlow Lite model. Regarding the warnings related to missing libraries, it seems like TensorFlow is unable to load some GPUrelated libraries because you are running on a CPUonly system. These warnings can be safely ignored if you do not intend to use GPU acceleration for your model.","Sorry, I still can't solve this problem.Here is my current progress. the saved_model.pb and saved_model.pbtxt are ampty.  Then I run python. ","It seems that you are still facing issues with your TensorFlow Lite model conversion. Based on the error message you provided, it appears that the from_saved_model() function is unable to find the MetaGraphDef associated with the 'serve' tag in your SavedModel directory. To troubleshoot this issue, you can try using the saved_model_cli commandline tool to inspect the available tags in your SavedModel directory. Here's an example command you can use:  This should display information about the available tags and their associated MetaGraphDef signatures in your SavedModel directory. As for the NameError you encountered when running the from_saved_model() function with the signature_def_map parameter, it seems that the variable input_signature was not defined before it was used in the function call. You may need to define input_signature as a dictionary that maps the input tensor names to their corresponding shapes and types, like this:  Make sure to replace the placeholder values (batch_size, height, width, channels) with the actual input shapes and types that your model expects. I hope this helps you make progress in converting your TensorFlow Lite model. Let me know if you have any further questions or issues!","The following command will not output anything >  An error will be reported, I think we are using a different version of tensorflow.  >  This is my model, I think you can try it.Thanks!",Hi   The TFLite has `full integer quantization`  which converts 32bit floatingpoint numbers (such as weights and activation outputs) to the nearest 8bit fixedpoint numbers. We can enable that while converting the tensorflow/keras models to tflite model. Please refer this documentation on post training integer quantization. The model which you are trying is a tflite model and it seems to be missing. We can get `resnet_v2_101` from TF hub and convert to TF Lite model with int8 quantization. Please find the gist here doing the same. Thanks.,> Hi  >  > The TFLite has `full integer quantization` which converts 32bit floatingpoint numbers (such as weights and activation outputs) to the nearest 8bit fixedpoint numbers. We can enable that while converting the tensorflow/keras models to tflite model. >  > Please refer this documentation on post training integer quantization. >  > The model which you are trying is a tflite model and it seems to be missing. We can get `resnet_v2_101` from TF hub and convert to TF Lite model with int8 quantization. >  > Please find the gist here doing the same. >  > Thanks. Thank you  for your reply!,Are you satisfied with the resolution of your issue? Yes No
1081,"以下是一个github上的tensorflow下的一个issue, 标题是(KerasLegacyOptimizer fails type check in keras.optimizers.get (ValueError: Could not interpret optimizer identifier))， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory RTX 2070  Current Behaviour? I am trying to create a customer optimizer using KerasLegacyOptimizer as a lot of the examples in https://github.com/tensorflow/addons/tree/master/tensorflow_addons/optimizers are using. Looks like we are failing at this line https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizers.pyL118 Any ideas?  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ben-arnao,KerasLegacyOptimizer fails type check in keras.optimizers.get (ValueError: Could not interpret optimizer identifier),Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory RTX 2070  Current Behaviour? I am trying to create a customer optimizer using KerasLegacyOptimizer as a lot of the examples in https://github.com/tensorflow/addons/tree/master/tensorflow_addons/optimizers are using. Looks like we are failing at this line https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizers.pyL118 Any ideas?  Standalone code to reproduce the issue   Relevant log output  ,2023-04-14T21:03:27Z,stat:awaiting response type:bug comp:keras TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60332,"arnao  TensorFlow Addons (TFA) has ended development and introduction of new features. TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024. Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, KerasCV, and KerasNLP).  For more information see: https://github.com/tensorflow/addons/issues/2807  Please refer to this official document for further assistance: https://github.com/ianstenbit/kerascv/blob/master/.github/CONTRIBUTING.mdcontributingcustomops Thank you !",arnao  There are two issues in the code provided  1. `tensorflow.python.keras` is deprecated.  Please use `from tensorflow import keras` or `import keras`.  See Readme.md here  https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras 2. You can sublcass Legacy Optimizer directly from `keras.optimizers.legacy.Optimizer` and don't see a need to use TF Addons here.,I mean just sounds like at this point I have to rewrite the optimizer then. Maybe it should be noted somewhere a bit more explicitly that something like KerasLegacyOptimizer doesn't work with TF2. There are many examples online of writing optimizers the old way so it is a bit confusing.,Are you satisfied with the resolution of your issue? Yes No
439,"以下是一个github上的tensorflow下的一个issue, 标题是(Getting error while importing tensorflow)， 内容是 ( I was trying to import above modules in my PC Getting below error as no module found. Installed and reinstalled Tensorflow several times even in virtual environment this error is not going anywhere please help! )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sanket-2712,Getting error while importing tensorflow, I was trying to import above modules in my PC Getting below error as no module found. Installed and reinstalled Tensorflow several times even in virtual environment this error is not going anywhere please help! ,2023-04-14T15:05:51Z,type:support stale comp:keras,closed,0,9,https://github.com/tensorflow/tensorflow/issues/60329,"2712  Could you please provide more information(like TensorFlow version, OS, Python version, e.t.c) and detailed steps to replicate the issue reported here ? Thank you !",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"2712, I tried to execute the mentioned code on tensorflow v2.12 and it was executed without any errors. Kindly find the gist of it here and also please try to test the code on a new virtual environment with the latest stable version. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"I had the same issue.  I was using tensorflow (V2.12.0) on jupyterlab with anaconda3, python version (Python 3.9.12), to make a CNN for NLP and had to restart the kernel after a while.  Suddenly I could not import tensorflow or keras, same error message as above.  Tried uninstalling both tensorflow and keras, and reinstalling  many times.  Tried the suggested fixes by the error message (including user and /I with installation)  no luck here either.  Eventually went to file directory >(anaconda3, etc) > tensorflow > compiler > jit > ops > xla_ops.py (where the error was).  Opened in VS code and deleted line 13 ""from tensorflow.security.fuzzing.py import annotation_types as _atypes"".  Looked to see if ""_atypes"" was used anywhere else in the file  it wasn't.  Saved it.  Restarted kernel and ran all cells back in jupyterlab, and it works again.  Seems to have solved the issue!","cizauskas, The code mentioned by the actual user was able to execute without any issues/error. So, could you please raise another request from your side with all the required details to analyse the issue. Thank you!",I now believe the error came from installing and uninstalling a tensorflow nightly package ,Closing this as stale. Please reopen if this is still a valid request. Thank you!,Are you satisfied with the resolution of your issue? Yes No
925,"以下是一个github上的tensorflow下的一个issue, 标题是(protobuf have a problem)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.11.0  Custom Code Yes  OS Platform and Distribution win10  Mobile device _No response_  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.7  GPU model and memory _No response_  Current Behaviour? I don't know if there is a problem with my download or the version of tensorflow, that is, how to recompile protobuf. Can I download the tensorflow compressed package directly from GitHub and uninstall tensorflowIntel without uninstalling the gpu version.  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",text generation,stonecropa,protobuf have a problem,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.11.0  Custom Code Yes  OS Platform and Distribution win10  Mobile device _No response_  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.7  GPU model and memory _No response_  Current Behaviour? I don't know if there is a problem with my download or the version of tensorflow, that is, how to recompile protobuf. Can I download the tensorflow compressed package directly from GitHub and uninstall tensorflowIntel without uninstalling the gpu version.  Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-14T02:06:39Z,stat:awaiting response type:build/install type:support stale TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60320,", Hi, Thanks for opening the issue.  We have upgraded the protobuf dependency to 3.21.9 (4.21.9) for python from Tensorflow version 2.12, which was long awaited ask. **For Tensorflow and Tensorboard 2.12 version, the protobuf minimum version requirement is 'protobuf>=3.20.3,<5.0.0dev,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5'.** For any older Tensorflow version and new Tensorboard version the only version which acts as bridge between both is 3.20.3 The Tensorflow 2.12 is released, you can use Tensorboard 2.12 without any package conflict.  Please have a look at this issue for the reference. Thank you!","                                                                                              I installed tensorflow==2.12.0 in conda, and the conda list also shows that it is version 12, but it shows that it is version 11 in the VScode terminal, and the original error is still reported. My python is 3.8.16. Thanks.",", Apologies for the delay. It seems the error might be related to protobuf version. Could you please confirm the protobuf version installed? And also for the Tf2.11 version the required range versions should be **protobuf >= 3.9.2, < 3.20** .  Could you please check and confirm the same. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
323,"以下是一个github上的tensorflow下的一个issue, 标题是([NVIDIA XLA] FP8 Matmul BiasAdd fusion for high rank input)， 内容是 (This PR complete the coverage for FP8 matmul when input is high rank tensor.  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,wenscarl,[NVIDIA XLA] FP8 Matmul BiasAdd fusion for high rank input,This PR complete the coverage for FP8 matmul when input is high rank tensor.  ,2023-04-13T18:32:06Z,awaiting review ready to pull comp:xla size:M,closed,0,18,https://github.com/tensorflow/tensorflow/issues/60319,Hi  Can you please resolve conflicts? Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,This PR is not stale. It requires https://github.com/tensorflow/tensorflow/pull/60409 to be merged first. I'll reopen if automatically closed.,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you., The top of master seems to fail those tests in `gemm_rewrite_test.cc` which prevents from rebasing. ,Hi  Can you please review this PR ? Thank you!, thanks for addressing all my comments! Can you resolve conflicts?,>  thanks for addressing all my comments! Can you resolve conflicts? The gemm_rewrite_test did not pass for the current master. Could you take a look?,> The gemm_rewrite_test did not pass for the current master. Could you take a look? It's passing for me. I tried on https://github.com/openxla/xla/commit/d7b3b230abca3bc7adafeff7344aaafc6e6994dc with `bazel test //xla/service/gpu/tests:gemm_rewrite_test` and it passes. What commit are you synced to and what command are you using to run?,"I also tried on the TF repo at 35af49017480ee112fc8c9850862f1eb61d611ee, since this PR is on the TF repo. It still passes for me.","> I also tried on the TF repo at 35af490, since this PR is on the TF repo. It still passes for me. I tried the same commit, Used `TF_CUDA_CLANG=0` in .bazelrc. BatchRowTransposeFoldCheck, BatchFromMinorDimTransposeIsNotFolded, BatchedInstrLayoutTransposed, BatchedInstrLayoutBatchNotInMinorDim failed.",I'm also using `TF_CUDA_CLANG=0`. I'm using CUDA 12.1.1 with cuDNN 8.9.1. What version of CUDA/cuDNN are you using? And what's the error message?,> I'm also using `TF_CUDA_CLANG=0`. I'm using CUDA 12.1.1 with cuDNN 8.9.1. What version of CUDA/cuDNN are you using? And what's the error message? Seeing :  while testing BatchedInstrLayoutTransposed on Hopper.,What version of CUDA and cuDNN are you using?,> What version of CUDA and cuDNN are you using? cuda 12.1 + cudnn 8.9.2,"I think it's fine to just increase the test tolerance, since the error is almost within tolerances already.","> I think it's fine to just increase the test tolerance, since the error is almost within tolerances already. Fixes by CC(Increase gemm rewrite tests tolerance) ", can you sync past CC(Increase gemm rewrite tests tolerance)?
444,"以下是一个github上的tensorflow下的一个issue, 标题是(add missing floor operation)， 内容是 (Currently, the ""FLOOR"" operation is not properly supported on the GPU delegate. The underlying opencl/opengl implementation exists but the operation type is missing in operation_selector.cc, which prevents from using the floor op.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jeandsp,add missing floor operation,"Currently, the ""FLOOR"" operation is not properly supported on the GPU delegate. The underlying opencl/opengl implementation exists but the operation type is missing in operation_selector.cc, which prevents from using the floor op.",2023-04-13T15:33:48Z,stale comp:lite size:XS,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60317,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.",Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!, can you please take a look at this?,"Hi , Can you please review this PR ? Thank you!",Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Please add corresponding tests in tensorflow/lite/delegates/gpu/cl/kernels/elementwise_test./lite/delegates/gpu/gl/kernels/elementwise_test.cc. Thanks!,Hi  Can you please check 's comments and keep us posted ? Thank you!,Hi  Any update on this PR? Please. Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further.
1107,"以下是一个github上的tensorflow下的一个issue, 标题是(Backpropagation for all zero label vectors in softmax/crossentropy)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230413  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04.1 LTS  Mobile device _No response_  Python version Python 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version no GPU Used  GPU model and memory no GPU Used  Current Behaviour? The First approach to building a Softmax layer yields a non zero gradient in backpropagation for an all zero target vector. The second approach yields a zero gradient. I would expect the behaviour of the latter, as is mathematically correct.  I am a bit unsure whether this is intentended behaviour or not. If it is intended, where does the difference come from?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Janushki,Backpropagation for all zero label vectors in softmax/crossentropy,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230413  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04.1 LTS  Mobile device _No response_  Python version Python 3.10.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version no GPU Used  GPU model and memory no GPU Used  Current Behaviour? The First approach to building a Softmax layer yields a non zero gradient in backpropagation for an all zero target vector. The second approach yields a zero gradient. I would expect the behaviour of the latter, as is mathematically correct.  I am a bit unsure whether this is intentended behaviour or not. If it is intended, where does the difference come from?   Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-13T13:26:28Z,stat:awaiting tensorflower type:bug comp:keras comp:ops TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60314,", I was able to reproduce the issue on tensorflow v2.12 and nightly. Kindly find the gist of it here."," , Thanks for reporting the issue.  I was debugging this from my side as well. Meanwhile, Could you please provide some more details on the mathematical computation of both of the approaches.",Initial observation:  I was able to compare both the results outside gradient scope for forward computation and the results were identical. The issue seems to be happening in the gradient calculation.  Below is the code I tried to compare both results with a seed and detailed gist can be found here.    ,">  , Thanks for reporting the issue. I was debugging this from my side as well. Meanwhile, Could you please provide some more details on the mathematical computation of both of the approaches. Sorry for the late answer, I didnt have time last week. And thanks alot for your effort! The Categorical Crossentropie Loss is defined as: $$\sum_i y_i * \log(x_i)$$ if we add the information that $y_i = 0$ this leads to $$\sum_i y_i * \log(x_i)=\sum_i 0 * \log(x_i)=\sum_i 0=0$$ as the loss is constantly zero, the partial derivate for $x_i$ is zero aswell. Actually this should be independent of the pervious activation function.","Hi  , Thank you for the report. There was indeed a discrepancy in the results depending on the approach. This is now fixed in `tfnightly`. https://github.com/kerasteam/keras/commit/304bb3d9ab137dd26263381977890f00aac62e75 Specifically, this fixes the `Softmax` layer. After this change, the `Softmax` layer produces the same result as the `softmax` activation. Thanks, Fabien",Are you satisfied with the resolution of your issue? Yes No
1177,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Lite in Play Services, app is crashing when creating interpreter)， 内容是 (**System information**  Android Device information: samsung a13 (5793 events, 31% of total events), samsung m11q, Redmi olivewood, samsung j6lte, samsung m13, samsung j7velte, samsung on7xelte  TensorFlow Lite in Play Services SDK version: playservicestflitejava:16.0.1, playservicestflitegpu:16.1.0  Google Play Services version: don't know, never happened in dev devices. **Standalone code to reproduce the issue**  **Any other info / logs** We have started receiving this crash from 23 March 2023, app was updated a month ago before this(21st feb). When we stopped using GPU Delegate, toggled through Firebase Remote Config, the error went away. Samsung a13 device alone has registered 5793 crashes, which is 31% of total events, based on Play Store Console. title in the console is ""[libtensorflowlite_jni_gms_client.so] Java_com_google_android_gms_tflite_NativeInterpreterWrapper_createInterpreter"" backtrace: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sandeep5193,"TensorFlow Lite in Play Services, app is crashing when creating interpreter","**System information**  Android Device information: samsung a13 (5793 events, 31% of total events), samsung m11q, Redmi olivewood, samsung j6lte, samsung m13, samsung j7velte, samsung on7xelte  TensorFlow Lite in Play Services SDK version: playservicestflitejava:16.0.1, playservicestflitegpu:16.1.0  Google Play Services version: don't know, never happened in dev devices. **Standalone code to reproduce the issue**  **Any other info / logs** We have started receiving this crash from 23 March 2023, app was updated a month ago before this(21st feb). When we stopped using GPU Delegate, toggled through Firebase Remote Config, the error went away. Samsung a13 device alone has registered 5793 crashes, which is 31% of total events, based on Play Store Console. title in the console is ""[libtensorflowlite_jni_gms_client.so] Java_com_google_android_gms_tflite_NativeInterpreterWrapper_createInterpreter"" backtrace: ",2023-04-13T12:55:19Z,stat:awaiting response type:bug stale comp:lite TFLiteGpuDelegate TFLiteGooglePlayServices,closed,0,13,https://github.com/tensorflow/tensorflow/issues/60313,"It seems that the crash is happening in the TensorFlow Lite GPU delegate while trying to create an interpreter. One potential solution is to disable the GPU delegate and only use the CPU delegate. You can do this by removing the following line of code: arduino Copy code .addDelegateFactory(new GpuDelegateFactory()) If the issue persists, you could try updating your TensorFlow Lite in Play Services SDK to the latest version to see if the problem has been resolved in a newer release. Additionally, you can check if there are any compatibility issues between the Samsung a13 device and the TensorFlow Lite GPU delegate by checking the device's specifications and the minimum requirements for the GPU delegate. You may also want to check if any other apps on the device are experiencing similar crashes and try to isolate the issue by running the app on other devices. Finally, you could try reaching out to the TensorFlow community forums for more help and guidance.","Hi   Sorry for delayed response. We can enable the GPU delegate option in the TFlite initialization by  before adding `.addDelegateFactory(new GpuDelegateFactory())` Please refer this instructions on using GPU delegate. If the issue still persists, could you please provide a standalone code to reproduce this issue? Thanks.","The code I have mentioned is working fine for some time now. All of a sudden it started crashing on few devices, without any changes in our code. You still think by changing initialisation steps you have mentioned will solve the problem? On Mon, 17 Apr, 2023, 5:25 pm pjpratik, ***@***.***> wrote: > Hi   > > Sorry for delayed response. > > We can enable the GPU delegate option in the TFlite initialization by > > TfLite.initialize(context, >       TfLiteInitializationOptions.builder() >        .setEnableGpuDelegateSupport(true) >        .build()); > > before adding .addDelegateFactory(new GpuDelegateFactory()) > > Please refer this >  > instructions on using GPU delegate. > > If the issue still persists, could you please provide a standalone code to > reproduce this issue? > > Thanks. > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >",Hi   Was it working fine with GPU delegate on few cases?  I was checking if the the GPU delegate is not initialized that maybe causing the issue. Can you provide a reproducible code to better understand and investigate the issue. Thanks.,"hi  it was working very well in all devices. all of a sudden we started receiving this error in production, for few devices, exact numbers you can read in my first post. so we had to stop it. we are not able to reproduce this in our development devices, but code mentioned in the original post is the point of crash.","Given that it says [libtensorflowlite_jni_gms_client.so], this is beyond my understanding.   can this be assigned to the TFLite in GMS core team?","Hi, we have identified a compatibility issue between the TFLite runtime module and the GPU delegate module that might be the cause of this crash. The good news is, we are already in the process of rolling out an update that should fix the issue. I will post an update on this bug once the rollout is complete.", can I downgrade my tflite version to remedy this in the short term?,"We have finished the rollout, so devices should pick up the fix automatically. If you still encounter crashes, please let us know (ideally by filing a new bug, so we can distinguish different issues). Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"I am facing issue, I recently trained (25/12/2024) a model through Google Vertex AI(Auto ML Edge) and exported as TF Lite. When i add my model.tflite to my app , before making any predictions app is crashing without any error logging. But In the same app my previous trained model(2021) is working fine. Please help me"
945,"以下是一个github上的tensorflow下的一个issue, 标题是(Training stopping because of  BufferError: Existing exports of data: object cannot be re-sized or something wrong with tornado)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution NAME=""CentOS Linux"" VERSION=""7 (Core)""  Mobile device NAME=""CentOS Linux"" VERSION=""7 (Core)""  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version  11.8.0   GPU model and memory _No response_  Current Behaviour? The model training would just stop abruptly  https://colab.research.google.com/drive/1WiqyF7dCdnNBIANEY80Pxw_mVz4fyVS?usp=sharing  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,CaffineAddic,Training stopping because of  BufferError: Existing exports of data: object cannot be re-sized or something wrong with tornado,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution NAME=""CentOS Linux"" VERSION=""7 (Core)""  Mobile device NAME=""CentOS Linux"" VERSION=""7 (Core)""  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version  11.8.0   GPU model and memory _No response_  Current Behaviour? The model training would just stop abruptly  https://colab.research.google.com/drive/1WiqyF7dCdnNBIANEY80Pxw_mVz4fyVS?usp=sharing  Standalone code to reproduce the issue   Relevant log output  ",2023-04-13T05:24:00Z,stat:awaiting tensorflower type:bug comp:apis TF 2.12,open,0,28,https://github.com/tensorflow/tensorflow/issues/60309,", I tried to execute the mentioned code with the tensorflow v2.12 and it was executed without any issues. Kindly find the gist of it here and also looks like the error which you stated was related to tensorflow. The error which was mentioned was discussed in Tornado issue 2008. The current theory is that it only happens when threads are being used incorrectly, but this is not certain. Reference. Thank you!","Thanks for the reply, actually the code works well for 150 epochs with 100 steps per epoch but it stops with this error at any range of epochs from 70 to 200. ","https://github.com/CaffineAddic/HybridMorphproofofconcept.git Can you see if this one works, I used this code to train the models before but now after the update it's failing",", While I was accessing the issue, I was unable to view any code in the above link. Could you please provide the colab gist which helps to analyse the issue in an effective way. Thank you!",https://github.com/CaffineAddic/HybridMorphproofofconcept/blob/main/HybridMorph_proof%20of%20concept.ipynb,I am running it on my local machine ,Could you please provide the model_loc = 'Models/ and csv_loc = 'CSV/' datasets and the models which you are trying to execute the code in the reproducible format. Thank you!,There is no dataset needed to run this  One of the dataset is provided by the library other one is generated during the execution. Those two location are just to store the model weights as .h5 file and the other has the location of the CSV file where it will store errors per step. Just keep both as random temp folder. Thank you ,"Having the same issue right now while training models,  tornado version  6.3.2 and tensorflow version 2.12.0.",Anyone got any fix??,", Apologies for the delay. We are working on the issue and will update the status here. Thank you!","Thanks a lot for the reply, Good luck.",(also seeing this issue),"  , Could you please try to provide more information on this to debug the root cause of the issue.  Also, are you facing the similar behavior in other environments as well?","Yess, over multiple systems configurations, I have tried run it over multiple fresh installs of tf 2.12","I am getting the same error and stacktrace with a pytorch model with MPS backend from a jupyter notebook. The model continues training, but output stops streaming to jupyter. I suspect the problem is actually with jupyter and that websocket that allows streaming data from the python backend to the output cell. ",Did you find any fix for it ??,"Same here. The error just random shows up. Some times after 100 epochs, sometimes at much earlier. 20230726 17:43:54 [E 00:43:54.737 NotebookApp] Uncaught exception in zmqstream callback 20230726 17:43:54     Traceback (most recent call last): 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 634, in _handle_events 20230726 17:43:54         self._handle_recv() 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 663, in _handle_recv 20230726 17:43:54         self._run_callback(callback, msg) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback 20230726 17:43:54         f = callback(*args, **kwargs) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback 20230726 17:43:54         return callback(self, msg) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply 20230726 17:43:54         super()._on_zmq_reply(stream, msg) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply 20230726 17:43:54         self.write_message(msg, binary=isinstance(msg, bytes)) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 339, in write_message 20230726 17:43:54         return self.ws_connection.write_message(message, binary=binary) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1086, in write_message 20230726 17:43:54         fut = self._write_frame(True, opcode, message, flags=flags) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1061, in _write_frame 20230726 17:43:54         return self.stream.write(frame) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 540, in write 20230726 17:43:54         self._write_buffer.append(data) 20230726 17:43:54       File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 157, in append 20230726 17:43:54         b += data   type: ignore 20230726 17:43:54     BufferError: Existing exports of data: object cannot be resized 20230726 17:43:54 Exception in callback BaseAsyncIOLoop._handle_events(28, 1) 20230726 17:43:54 handle:  20230726 17:43:54 Traceback (most recent call last): 20230726 17:43:54   File ""/usr/lib/python3.8/asyncio/events.py"", line 81, in _run 20230726 17:43:54     self._context.run(self._callback, *self._args) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/tornado/platform/asyncio.py"", line 206, in _handle_events 20230726 17:43:54     handler_func(fileobj, events) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 634, in _handle_events 20230726 17:43:54     self._handle_recv() 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 663, in _handle_recv 20230726 17:43:54     self._run_callback(callback, msg) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback 20230726 17:43:54     f = callback(*args, **kwargs) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback 20230726 17:43:54     return callback(self, msg) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply 20230726 17:43:54     super()._on_zmq_reply(stream, msg) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply 20230726 17:43:54     self.write_message(msg, binary=isinstance(msg, bytes)) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 339, in write_message 20230726 17:43:54     return self.ws_connection.write_message(message, binary=binary) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1086, in write_message 20230726 17:43:54     fut = self._write_frame(True, opcode, message, flags=flags) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1061, in _write_frame 20230726 17:43:54     return self.stream.write(frame) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 540, in write 20230726 17:43:54     self._write_buffer.append(data) 20230726 17:43:54   File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 157, in append 20230726 17:43:54     b += data   type: ignore 20230726 17:43:54 BufferError: Existing exports of data: object cannot be resized","Some random times I was getting this error training the keras models and the training was being stopped. Seems like the problem is on threads sync streaming the large output. So, turning off the verbose of **fit()** method worked for me. **i.e:**  model.fit(trainX, trainY, ... , **verbose=0**) I guess you can also use **verbose=2** for showing just the final details for each epoch and it will work fine.",I will test it thank you  ," Uncaught exception in ZMQStream callback     Traceback (most recent call last):       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/event                                                                                                                        loop/zmqstream.py"", line 584, in _run_callback         f = callback(*args, **kwargs)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/event                                                                                                                        loop/zmqstream.py"", line 308, in stream_callback         return callback(self, msg)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/                                                                                                                        services/kernels/handlers.py"", line 572, in _on_zmq_reply         super()._on_zmq_reply(stream, msg)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/                                                                                                                        base/zmqhandlers.py"", line 256, in _on_zmq_reply         self.write_message(msg, binary=isinstance(msg, bytes))       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/w                                                                                                                        ebsocket.py"", line 339, in write_message         return self.ws_connection.write_message(message, binary=binary)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/w                                                                                                                        ebsocket.py"", line 1086, in write_message         fut = self._write_frame(True, opcode, message, flags=flags)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/w                                                                                                                        ebsocket.py"", line 1061, in _write_frame         return self.stream.write(frame)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/i                                                                                                                        ostream.py"", line 546, in write         self._handle_write()       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/i                                                                                                                        ostream.py"", line 976, in _handle_write         self._write_buffer.advance(num_bytes)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/i                                                                                                                        ostream.py"", line 182, in advance         assert 0  Traceback (most recent call last):   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/asyncio/events.py"", line 80                                                                                                                        , in _run     self._context.run(self._callback, *self._args)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/platf                                                                                                                        orm/asyncio.py"", line 206, in _handle_events     handler_func(fileobj, events)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/eventloop                                                                                                                        /zmqstream.py"", line 634, in _handle_events     self._handle_recv()   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/eventloop                                                                                                                        /zmqstream.py"", line 663, in _handle_recv     self._run_callback(callback, msg)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/eventloop                                                                                                                        /zmqstream.py"", line 584, in _run_callback     f = callback(*args, **kwargs)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/eventloop                                                                                                                        /zmqstream.py"", line 308, in stream_callback     return callback(self, msg)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/serv                                                                                                                        ices/kernels/handlers.py"", line 572, in _on_zmq_reply     super()._on_zmq_reply(stream, msg)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/base                                                                                                                        /zmqhandlers.py"", line 256, in _on_zmq_reply     self.write_message(msg, binary=isinstance(msg, bytes))   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/webso                                                                                                                        cket.py"", line 339, in write_message     return self.ws_connection.write_message(message, binary=binary)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/webso                                                                                                                        cket.py"", line 1086, in write_message     fut = self._write_frame(True, opcode, message, flags=flags)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/webso                                                                                                                        cket.py"", line 1061, in _write_frame     return self.stream.write(frame)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/iostr                                                                                                                        eam.py"", line 546, in write     self._handle_write()   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/iostr                                                                                                                        eam.py"", line 976, in _handle_write     self._write_buffer.advance(num_bytes)   File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/iostr                                                                                                                        eam.py"", line 182, in advance     assert 0 < size <= self._size AssertionError Still this error is persistent   ","I've encountered the same or a similar issue with TF 2.13. docker run gpus all  rm u $(id u):$(id g) p 8888:8888 p 6006:6006 v $PWD/:/tf/david_home   tensorflow/tensorflow:2.13.0gpujupyter In my case output of the notebook to Firefox has frozen but the training job still seems to be running.   FWIW when I run the same notebook using TF 2.13 with the LambdaStack, this does not happen i.e. output works as expected. E 12:40:01.689 NotebookApp] Uncaught exception in ZMQStream callback     Traceback (most recent call last):       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback         f = callback(*args, **kwargs)       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback         return callback(self, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply         super()._on_zmq_reply(stream, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply         self.write_message(msg, binary=isinstance(msg, bytes))       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 334, in write_message         return self.ws_connection.write_message(message, binary=binary)       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1081, in write_message         fut = self._write_frame(True, opcode, message, flags=flags)       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1056, in _write_frame         return self.stream.write(frame)       File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 533, in write         self._write_buffer.append(data)       File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 157, in append         b += data   type: ignore     BufferError: Existing exports of data: object cannot be resized [E 12:40:01.691 NotebookApp] Uncaught exception in zmqstream callback     Traceback (most recent call last):       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 634, in _handle_events         self._handle_recv()       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 663, in _handle_recv         self._run_callback(callback, msg)       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback         f = callback(*args, **kwargs)       File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback         return callback(self, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply         super()._on_zmq_reply(stream, msg)       File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply         self.write_message(msg, binary=isinstance(msg, bytes))       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 334, in write_message         return self.ws_connection.write_message(message, binary=binary)       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1081, in write_message         fut = self._write_frame(True, opcode, message, flags=flags)       File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1056, in _write_frame         return self.stream.write(frame)       File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 533, in write         self._write_buffer.append(data)       File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 157, in append         b += data   type: ignore     BufferError: Existing exports of data: object cannot be resized ERROR:asyncio:Exception in callback BaseAsyncIOLoop._handle_events(29, 1) handle:  Traceback (most recent call last):   File ""/usr/lib/python3.8/asyncio/events.py"", line 81, in _run     self._context.run(self._callback, *self._args)   File ""/usr/local/lib/python3.8/distpackages/tornado/platform/asyncio.py"", line 192, in _handle_events     handler_func(fileobj, events)   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 634, in _handle_events     self._handle_recv()   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 663, in _handle_recv     self._run_callback(callback, msg)   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback     f = callback(*args, **kwargs)   File ""/usr/local/lib/python3.8/distpackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback     return callback(self, msg)   File ""/usr/local/lib/python3.8/distpackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply     super()._on_zmq_reply(stream, msg)   File ""/usr/local/lib/python3.8/distpackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply     self.write_message(msg, binary=isinstance(msg, bytes))   File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 334, in write_message     return self.ws_connection.write_message(message, binary=binary)   File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1081, in write_message     fut = self._write_frame(True, opcode, message, flags=flags)   File ""/usr/local/lib/python3.8/distpackages/tornado/websocket.py"", line 1056, in _write_frame     return self.stream.write(frame)   File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 533, in write     self._write_buffer.append(data)   File ""/usr/local/lib/python3.8/distpackages/tornado/iostream.py"", line 157, in append     b += data   type: ignore BufferError: Existing exports of data: object cannot be resized",as  mentioned try keeping   verbose=2  This worked for me," , Is this still an issue? if the issue is resolved by changing verbose=0 to verbose=2, could you please close the issue. Also, use the latest TensorFlow version to get the latest updates. Thank you!","Ya essentially allowed me to start training but I cannot comment on the rest of users, also shouldn't training should happen with the default verbose value, tornado errors are still there if you want to I can close this issue, Thank you for your time and support.  "," Exception in callback      Traceback (most recent call last):       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/ioloop.py"", line 921, in _run         val = self.callback()       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/base/zmqhandlers.py"", line 188, in send_ping         self.ping(b'')       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/websocket.py"", line 445, in ping         self.ws_connection.write_ping(data)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/websocket.py"", line 1101, in write_ping         self._write_frame(True, 0x9, data)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/websocket.py"", line 1061, in _write_frame         return self.stream.write(frame)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/iostream.py"", line 540, in write         self._write_buffer.append(data)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/iostream.py"", line 157, in append         b += data   type: ignore     BufferError: Existing exports of data: object cannot be resized [I 01:36:07.003 NotebookApp] Saving file at /New_BRaTS/Brain_data/HybridMorph_proof of concept.ipynb [E 01:36:28.774 NotebookApp] Uncaught exception in ZMQStream callback     Traceback (most recent call last):       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/eventloop/zmqstream.py"", line 584, in _run_callback         f = callback(*args, **kwargs)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/zmq/eventloop/zmqstream.py"", line 308, in stream_callback         return callback(self, msg)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/services/kernels/handlers.py"", line 572, in _on_zmq_reply         super()._on_zmq_reply(stream, msg)       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/notebook/base/zmqhandlers.py"", line 256, in _on_zmq_reply         self.write_message(msg, binary=isinstance(msg, bytes))       File ""/home/saumya/anaconda3/envs/tf/lib/python3.9/sitepackages/tornado/websocket.py"", line 339, in write_message         return self.ws_connection.write_message(message, binary=binary Same error with verbose = 2. Any fixes ","> I am getting the same error and stacktrace with a pytorch model with MPS backend from a jupyter notebook. The model continues training, but output stops streaming to jupyter. I suspect the problem is actually with jupyter and that websocket that allows streaming data from the python backend to the output cell. Faced the same error and tried a lot of troubleshooting steps mentioned here including but not limited to clearing pytorch cuda memory. I agree that the training actually continues because I could hear my GPU wheezing. Ultimately ran the training through a .py script and that worked as expected. I know this isn't technically a solution but I hope it saves someone time. :)", comment about changing verbose to 2 works out well. After this I plan to migrate to pyTorch
1059,"以下是一个github上的tensorflow下的一个issue, 标题是(Optimize memory allocation and pair construction in ClientSession::Ru…)， 内容是 (Optimize vector capacity reservation in ClientSession::Run Description: This pull request addresses a minor optimization opportunity in the ClientSession::Run function. By reserving the capacity of the output_tensor_names and target_node_names vectors before filling them, we can potentially reduce the number of reallocations and improve performance. The specific changes made in this pull request are: Reserve capacity for output_tensor_names vector using fetch_outputs.size() before the loop that fills it. Reserve capacity for target_node_names vector using run_outputs.size() before the loop that fills it. Testing: I have tested this change locally with the existing test suite, and all tests passed successfully. Reviewers can test this change by running the test suite after applying the patch.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,VijayR19,Optimize memory allocation and pair construction in ClientSession::Ru…,"Optimize vector capacity reservation in ClientSession::Run Description: This pull request addresses a minor optimization opportunity in the ClientSession::Run function. By reserving the capacity of the output_tensor_names and target_node_names vectors before filling them, we can potentially reduce the number of reallocations and improve performance. The specific changes made in this pull request are: Reserve capacity for output_tensor_names vector using fetch_outputs.size() before the loop that fills it. Reserve capacity for target_node_names vector using run_outputs.size() before the loop that fills it. Testing: I have tested this change locally with the existing test suite, and all tests passed successfully. Reviewers can test this change by running the test suite after applying the patch.",2023-04-12T21:38:56Z,ready to pull size:S,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60305,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.",Hi  Can you please sign CLA. Thank you!,"> Hi  Can you please sign CLA. Thank you! Hi, I have already done that but I still see that missing CLA. Very strange!"
1150,"以下是一个github上的tensorflow下的一个issue, 标题是([tosa] [mlir] tfl.IfOp isn’t supported in tf-mlir-translate.)， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.5 LTS    TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): 45f08a0fcc90145b9c2b7057310762d6b0ebae85 **Standalone code to reproduce the issue**   test_tflite.preopt.mlir output:   **Any other info / logs**  The goal is to generate tfl.IfOp in MLIR  seems a lot of TF::IfOp is used everywhere and a TFL::IfOp is only instantiated during the flatbuffer export  Some TODOs here:       https://github.com/tensorflow/tensorflow/blob/ba8b52cad65f882bed982517a7b7cf60c598efab/tensorflow/compiler/mlir/lite/flatbuffer_export.ccL572      https://github.com/tensorflow/tensorflow/blob/524101303ff158b939923b36805474f2e4118a49/tensorflow/compiler/mlir/lite/transforms/pin_ops_with_side_effects.ccL48 Could anyone update the progress of the support of this operator? )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Jerry-Ge,[tosa] [mlir] tfl.IfOp isn’t supported in tf-mlir-translate.,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.5 LTS    TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): 45f08a0fcc90145b9c2b7057310762d6b0ebae85 **Standalone code to reproduce the issue**   test_tflite.preopt.mlir output:   **Any other info / logs**  The goal is to generate tfl.IfOp in MLIR  seems a lot of TF::IfOp is used everywhere and a TFL::IfOp is only instantiated during the flatbuffer export  Some TODOs here:       https://github.com/tensorflow/tensorflow/blob/ba8b52cad65f882bed982517a7b7cf60c598efab/tensorflow/compiler/mlir/lite/flatbuffer_export.ccL572      https://github.com/tensorflow/tensorflow/blob/524101303ff158b939923b36805474f2e4118a49/tensorflow/compiler/mlir/lite/transforms/pin_ops_with_side_effects.ccL48 Could anyone update the progress of the support of this operator? ",2023-04-12T17:25:46Z,stat:awaiting tensorflower type:feature comp:lite comp:lite-tosa,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60301,"[proposed Label] comp:litetosa, seems I don't have the access to config the labels.","Hi Ge, Yes, currently it is true that `tf.IfOp > tfl.IfOp` only happens at export time. Would you mind sharing the tflite model in question as well as how it was generated?","Thanks , I pushed the dummy model I used for testing here: https://github.com/JerryGe/tfl_models/tree/main It's generated by using the `tf.cond()` operator and the `tf.lite.TFLiteConverter.from_concrete_functions`  Then you ran the flatbuffer_translate code provided from above, you will get the `test_tflite.preopt.mlir` output I got.  Let me know if you need more details. ",Thanks Ge. We are prioritizing fixing this issue and having the if op be legalized appropriately. I think 12 weeks is when the fix will come.,">  Hi Luke, any updates here? Tks ","Hi Ge, we're still working on this. It's taking longer than expected since a lot of tests expect `tf.If` and the op is not entirely equivalent to `tfl.If` so it's not a trivial find/replace change. We also have internal downstream dependents which will need to be updated. Can you help provide additional detail and context about your need for this? Just trying to understand if it's a nuisance, blocker, or something in between. Thanks!",Thanks for the update! Don't worry and I can wait : ),"Hi , any updates on this issue? If it's done, then we can close it? ","If nobody plans to fix this, I will close this ticket by the end of this week. ",Nobody is responding to this issue. Close this ticket for now. 
1084,"以下是一个github上的tensorflow下的一个issue, 标题是([tosa] [mlir] tfl.relu_0_to_1 mlir dialect can’t be generated)， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.5 LTS    TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): 45f08a0fcc90145b9c2b7057310762d6b0ebae85 **Standalone code to reproduce the issue**   **Any other info / logs**  The goal is to generate tfl.relu_0_to_1 op in tfl dialect   The kernel was added here: https://github.com/tensorflow/tensorflow/commit/f11ab18461943d15fe562ce5bd07c3d1a50fd0de  Myself added the MLIR dialect here: https://github.com/tensorflow/tensorflow/commit/485f680eccae0a5f3f7b83319b1ddc3426fc601a  From the comments here https://github.com/tensorflow/tensorflow/pull/58078pullrequestreview1142611030 saying that Google will be finishing this.  Could anyone update the progress of the support of this operator? )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Jerry-Ge,[tosa] [mlir] tfl.relu_0_to_1 mlir dialect can’t be generated,"**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.5 LTS    TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): 45f08a0fcc90145b9c2b7057310762d6b0ebae85 **Standalone code to reproduce the issue**   **Any other info / logs**  The goal is to generate tfl.relu_0_to_1 op in tfl dialect   The kernel was added here: https://github.com/tensorflow/tensorflow/commit/f11ab18461943d15fe562ce5bd07c3d1a50fd0de  Myself added the MLIR dialect here: https://github.com/tensorflow/tensorflow/commit/485f680eccae0a5f3f7b83319b1ddc3426fc601a  From the comments here https://github.com/tensorflow/tensorflow/pull/58078pullrequestreview1142611030 saying that Google will be finishing this.  Could anyone update the progress of the support of this operator? ",2023-04-12T16:55:44Z,stat:awaiting tensorflower type:bug comp:lite comp:lite-tosa,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60300,"[proposed Label] comp:litetosa, seems I don't have the access to config the labels. ","Hi Ge, few questions: * how can I access the model in question; `relu0To1/test_relu0To1_13x21x3_qu8/model.tflite`? * What do we mean exactly by  ""generate relu_0_to_1"" op? Is this op present in the flatbuffer but not present in output mlir via the translate tool?     * If so, would you mind sharing how this tflite model was created?","> Hi Ge, few questions: >  > * how can I access the model in question; `relu0To1/test_relu0To1_13x21x3_qu8/model.tflite`? > * What do we mean exactly by  ""generate relu_0_to_1"" op? Is this op present in the flatbuffer but not present in output mlir via the translate tool? >    >   * If so, would you mind sharing how this tflite model was created? Hi Luke, thanks for following up with this.   That's a very dummy model created by using `tf.math.minimum(1.0, tf.math.maximum(0.0, a))` . I can see a relu with minimum there but ideally we should have relu0To1 right?   Link to the model file: https://github.com/JerryGe/tfl_models/blob/main/model_relu0To1.tflite   Yea, I am currently using the `tf.lite.TFLiteConverter.from_concrete_functions` to generate the tflite models. ",Ok I see the issue. While there is an op def for `relu_0_to_1` there is no logic to write them into the graph. I can add some logic to rewrite patterns such as the following:  to   I'll keep this thread posted with status of change. Also worth noting that the min/maxes commute so either ordering should be rewritten.,"Hi Ge, this should be all set with https://github.com/tensorflow/tensorflow/commit/0a2aab71fedfc92ce99b484a87e926bdfcbec1d9",Are you satisfied with the resolution of your issue? Yes No,"> Hi Ge, this should be all set with 0a2aab7 Yes, this is what I want and Thanks so much Luke!"
1915,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow.python.framework.errors_impl.NotFoundError: Key conv1/kernel not found in checkpoint)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows x64  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hi everyone, I'm a novice programmer, I decided to create a neural network for facial recognition. I have encountered such an error.  I suspect that this problem is that the error occurs when loading the weights of the test_nn model from the saved checkpoints. It reports that some variables in the saved checkpoint do not correspond to variables in the model, because there are no corresponding stored values for them. Or because of a mismatch of tensorflow library versions mit_data_processing.py  train_face_id.py  test_face_id.py ``` import numpy as np import cv2 import tensorflow.compat.v1 as tf tf.disable_v2_behavior() class FaceID:     def __init__(self):         model = tf.keras.Sequential()         net = tf.keras.applications.MobileNet(input_shape=(128, 128, 3), weights='imagenet', include_top=False)         model.add(net)         model.add(tf.keras.layers.GlobalAveragePooling2D())         self.features_extractor = model         self.x_holder = tf.placeholder(shape=[None, 1024], dtype=tf.float32)         fc_1 = tf.layers.Dense(units=512, activation=tf.nn.relu)(self.x_holder)         fc_2 = tf.layers.Dense(units=128, activation=tf.nn.sigmoid)(fc_1)         self.face_id = fc_2         self.sess = None     def load_network)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,TimofeyVO,tensorflow.python.framework.errors_impl.NotFoundError: Key conv1/kernel not found in checkpoint,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Windows x64  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Hi everyone, I'm a novice programmer, I decided to create a neural network for facial recognition. I have encountered such an error.  I suspect that this problem is that the error occurs when loading the weights of the test_nn model from the saved checkpoints. It reports that some variables in the saved checkpoint do not correspond to variables in the model, because there are no corresponding stored values for them. Or because of a mismatch of tensorflow library versions mit_data_processing.py  train_face_id.py  test_face_id.py ``` import numpy as np import cv2 import tensorflow.compat.v1 as tf tf.disable_v2_behavior() class FaceID:     def __init__(self):         model = tf.keras.Sequential()         net = tf.keras.applications.MobileNet(input_shape=(128, 128, 3), weights='imagenet', include_top=False)         model.add(net)         model.add(tf.keras.layers.GlobalAveragePooling2D())         self.features_extractor = model         self.x_holder = tf.placeholder(shape=[None, 1024], dtype=tf.float32)         fc_1 = tf.layers.Dense(units=512, activation=tf.nn.relu)(self.x_holder)         fc_2 = tf.layers.Dense(units=128, activation=tf.nn.sigmoid)(fc_1)         self.face_id = fc_2         self.sess = None     def load_network",2023-04-11T21:39:52Z,type:bug comp:keras TF 2.12,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60294,", I was facing a different issue while executing the mentioned code. Kindly find the gist of it here and provide required dependencies which helps to reproduce the issue.  When you give the validation data as a variable it throws the Graph execution error. (for instance when you try to write ""model.predict([[a,b]]))"". But when you give an integer or float (model.predict([[17,2]])) it works and execution will happen.  We can bypassed the problem by writing **""model.predict([[float(a),float(b)]])""** (We can also use the related type instead of float)  Also there are similar issues that are still with the developer and they are working on the same. https://github.com/kerasteam/tfkeras/issues/66 https://github.com/kerasteam/tfkeras/issues/639 Thank you!",">  If I understood your remark correctly, then what 1 file  mit_data_processing.py 2 file  train_face_id.py 3 file  test_face_id.py In this screenshot, the file name should not be !image",Are you satisfied with the resolution of your issue? Yes No
722,"以下是一个github上的tensorflow下的一个issue, 标题是(""Failed to connect to remote host: Connection refused"" on Colab TPU)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,davidkflau,"""Failed to connect to remote host: Connection refused"" on Colab TPU",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-11T07:02:47Z,stat:awaiting response type:bug stale comp:tpus TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60288,"Hi , Thank you for raising the issue! We were able to replicate the issue in Colab using Tensorflow 2.12 and TPU. Please find the gist here.  It seems like we have to dig deep into the issue. We'll update here soon. Thank you!","Hi  , At present not all Ops are executable with TPUs. The iter operation might be one of them. Also, from the error log:  It seems iter operation is not supported on TPUs. Please find the TPU supported Ops list here for reference.  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
713,"以下是一个github上的tensorflow下的一个issue, 标题是(tfp.stats.histogram weights argument bug when using multiple axes)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.9.1  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,joaozenobio,tfp.stats.histogram weights argument bug when using multiple axes,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.9.1  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-10T17:10:39Z,stat:awaiting response type:bug comp:apis TF 2.9,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60287,"If you read the tensorflow documentation for tfp.stats.histogram(https://www.tensorflow.org/probability/api_docs/python/tfp/stats/histogram), upon reading the description of 'axis', it says : ""Optional 0D or 1D integer Tensor with constant values."" which means that tensorflow expects the axis to be passed as a tensor to generate the required results. You can try passing the axis as a tensor, something like this : axis = tf.constant(0, 1)",", Looks like this issue is more related to tensorflow propability repo. Could you please raise the issue in the respective repo from here for further assistance.  https://github.com/tensorflow/probability/issues Thank you!",", I've tried using this code now:  It gives me the same error: ",", I will raise a new issue there and make a reference to this one, thanks.",", Please feel free to move this issue to closed status, as it has been tracked in the respective repo. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1180,"以下是一个github上的tensorflow下的一个issue, 标题是(Anyway to set the attr of operation after added to the gragh in C API?)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf2.11  Custom Code No  OS Platform and Distribution Windows and Linux  Current Behaviour? Hello, I'm a developer of Tensorflow.NET, which is a tensorflow binding for dotnet. When I implemented some feature, I could not find a C API to add attributes to an operation that has already been created and added to the graph. However, there is indeed such C API for python. It's located here. Among exported C APIs of `libtensorflow`, only the following API was found:  However, `TF_OperationDescription` is released after adding the operation to graph by calling `TF_FinishOperation`. Therefore I can't use the API to add attributes. Is there any other way for us to add attributes for operations which have been added to graph?  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,AsakusaRinne,Anyway to set the attr of operation after added to the gragh in C API?,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf2.11  Custom Code No  OS Platform and Distribution Windows and Linux  Current Behaviour? Hello, I'm a developer of Tensorflow.NET, which is a tensorflow binding for dotnet. When I implemented some feature, I could not find a C API to add attributes to an operation that has already been created and added to the graph. However, there is indeed such C API for python. It's located here. Among exported C APIs of `libtensorflow`, only the following API was found:  However, `TF_OperationDescription` is released after adding the operation to graph by calling `TF_FinishOperation`. Therefore I can't use the API to add attributes. Is there any other way for us to add attributes for operations which have been added to graph?  Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-10T04:43:53Z,stat:awaiting response type:support stale comp:apis TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60284,"Also, is there any corresponding C API for `GetHandleShapeAndType` and `SetHandleShapeAndType` in `python_api.h`?","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
680,"以下是一个github上的tensorflow下的一个issue, 标题是(windows link error)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Windows 10 professional  Mobile device _No response_  Python version 3.8.5 64bit  Bazel version 5.3.0  GCC/Compiler version visual studio 2019  CUDA/cuDNN version _No response_  GPU model and memory cpu model  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,yisir323,windows link error,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Windows 10 professional  Mobile device _No response_  Python version 3.8.5 64bit  Bazel version 5.3.0  GCC/Compiler version visual studio 2019  CUDA/cuDNN version _No response_  GPU model and memory cpu model  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-10T02:34:42Z,stat:awaiting tensorflower type:build/install subtype:windows TF 2.12 subtype:cpu-intel,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60283,the following are the two log files: err  副本.txt stdout23850.txt,", I was able to reproduce the issue on tensorflow v2.12. Kindly find the reference below.  Kindly check the below instructions.  You need to install the MSVC 2019 redistributable  Your CPU does not support AVX2 instructions  Your CPU/Python is on 32 bits  There is a library that is in a different location/not installed on your system that cannot be loaded."," , Could you please take a look into the issue. Thanks!","Hi, , sorry for the delayed response. Could you please run the above command again on the latest commit and let us know the issue you are facing?","Hi all, any chance there's been some progress on this issue ?",please check this issue https://github.com/tensorflow/tensorflow/issues/61226 Seems similar to this one.  Seems tensorflow_cc target not supported in windows in some tensorflow versions,Closing stale issue since Windows is now done as a partner build,Are you satisfied with the resolution of your issue? Yes No
1881,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: 'Delegate' object has no attribute '_library')， 内容是 (**System information**  ubuntu 18.04.6 lts  tfliteruntime installed from Source, Using 'sudo aptget install python3tfliteruntime' [version: 2.5.0]  Python Verison: 3.6  edgetpucompiler 16 amd64 **Provide the text output from tflite_convert** syncx:~/cubesatnet_improvised/tflite/python/examples/classification$ python3 classify_image.py \ >   model models/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite \ >   labels models/inat_bird_labels.txt \ >   input images/parrot.jpg Traceback (most recent call last):   File ""classify_image.py"", line 122, in      main()   File ""classify_image.py"", line 99, in main     interpreter = make_interpreter(args.model)   File ""classify_image.py"", line 73, in make_interpreter     {'device': device[0]} if device else {})   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 160, in load_delegate     delegate = Delegate(library, options)   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 89, in __init__     self._library = ctypes.pydll.LoadLibrary(library)   File ""/usr/lib/python3.6/ctypes/__init__.py"", line 426, in LoadLibrary     return self._dlltype(name)   File ""/usr/lib/python3.6/ctypes/__init__.py"", line 348, in __init__     self._handle = _dlopen(self._name, mode) OSError: libedgetpu.so.1: cannot open shared object file: No such file or directory Exception ignored in: > Traceback (most recent call last):   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 124, in __del__     if self._library is not None: AttributeError: 'Delegate' object has no attribute '_library' **Standalone code to reproduce the issu)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jukomol,AttributeError: 'Delegate' object has no attribute '_library',"**System information**  ubuntu 18.04.6 lts  tfliteruntime installed from Source, Using 'sudo aptget install python3tfliteruntime' [version: 2.5.0]  Python Verison: 3.6  edgetpucompiler 16 amd64 **Provide the text output from tflite_convert** syncx:~/cubesatnet_improvised/tflite/python/examples/classification$ python3 classify_image.py \ >   model models/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite \ >   labels models/inat_bird_labels.txt \ >   input images/parrot.jpg Traceback (most recent call last):   File ""classify_image.py"", line 122, in      main()   File ""classify_image.py"", line 99, in main     interpreter = make_interpreter(args.model)   File ""classify_image.py"", line 73, in make_interpreter     {'device': device[0]} if device else {})   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 160, in load_delegate     delegate = Delegate(library, options)   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 89, in __init__     self._library = ctypes.pydll.LoadLibrary(library)   File ""/usr/lib/python3.6/ctypes/__init__.py"", line 426, in LoadLibrary     return self._dlltype(name)   File ""/usr/lib/python3.6/ctypes/__init__.py"", line 348, in __init__     self._handle = _dlopen(self._name, mode) OSError: libedgetpu.so.1: cannot open shared object file: No such file or directory Exception ignored in: > Traceback (most recent call last):   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 124, in __del__     if self._library is not None: AttributeError: 'Delegate' object has no attribute '_library' **Standalone code to reproduce the issu",2023-04-09T18:12:20Z,comp:lite,closed,0,0,https://github.com/tensorflow/tensorflow/issues/60279
700,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in MatrixSolve)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in MatrixSolve,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-09T06:07:44Z,stat:awaiting response type:bug stale comp:ops TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60278,  I was able to reproduce the issue on Colab using tf 2.12 and tfnightly. Please find the gist of 2.12 and tfnightly for reference. Thank you !,"Hi  , The issue got resolved now with tfnightly(2.14.0dev20230514) and now TF is successfully able to raise the intended Error. Please refer to attached gist. Please check and confirm and let us know if we can close the issue as it resolved now. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
705,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in TridiagonalMatMul)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in TridiagonalMatMul,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-09T06:05:40Z,stat:awaiting response type:bug stale comp:ops TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60277,  I was able to reproduce the issue on Colab using TF v2.11 and tfnightly. Please find the gist of 2.12 and tfnightlyfor reference. Thank you !,"This should not be a real issue. The check failure is an overflow due to   This is similar to writing the overflow itself, it won't show up in a real model.","Hi  , This has been fixed. tested with TF2.16v and found raising an exception rather than check fail. Refer gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
703,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in MatrixLogarithm)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in MatrixLogarithm,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-09T05:57:00Z,stat:awaiting response type:bug stale comp:ops TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60275,", I was able to reproduce the issue on tensorflow v2.12 and nightly. Kindly find the gist and the screen shot for the reference. ",Hi   This has been fixed. tested with TF2.16v and found raising an exception rather than check fail.Please refer gist. Thanks!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
696,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in Cholesky)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in Cholesky,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-09T05:54:19Z,stat:awaiting response type:bug stale comp:ops TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60274, The gradient computation on GPU is faster for large matrices but not for large batch dimensions when the submatrices are small. In this case it might be faster to use the  cpu  > `,  I was able to reproduce the issue on Colab using tf 2.12 and tfnightly. Please find the gist of 2.12 and tfnightly for reference. Thank you!,"Hi  , The issue got resolved now with tfnightly(2.14.0dev20230514) and now TF is successfully able to raise the intended Error. Please refer to attached gist. Please check and confirm and let us know if we can close the issue as it resolved now. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
803,"以下是一个github上的tensorflow下的一个issue, 标题是(M2 GPU utilization decays from 50% to 10% in non batched inference for huggingface distilbert-base-cased)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tensorflowmacos 2.9, tensorflowmetal 0.5.0  Custom Code Yes  OS Platform and Distribution MacOS 13.3  Mobile device _No response_  Python version Python 3.10.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version N/A  GPU model and memory Apple M2 Max (unified memory)  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,kechan,M2 GPU utilization decays from 50% to 10% in non batched inference for huggingface distilbert-base-cased,"Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tensorflowmacos 2.9, tensorflowmetal 0.5.0  Custom Code Yes  OS Platform and Distribution MacOS 13.3  Mobile device _No response_  Python version Python 3.10.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version N/A  GPU model and memory Apple M2 Max (unified memory)  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-04-08T22:13:45Z,stat:awaiting response stale comp:apis comp:gpu subtype:macOS type:performance TF 2.9,closed,0,12,https://github.com/tensorflow/tensorflow/issues/60271,"More details: I found no evidence yet this is a heat throttling issue, 'cos after the huge drop in GPU utilization, other processes will overtake using the GPU. I wonder what's going on? Is there any profiling tips I can do to help investigate. I am aware I can ""fix"" this by doing batch inferences. (or just use CPU as some may recommend for non batch inference). But seeing this GPU utilization decay is still unsettling, since this can potentially happen for a training session (which is far longer). So I would like to know the root cause. I have experience in TF in colab (and GCP linux), and I don't quite remember seeing this sort of behavior. I understood M2 Max is new.","I found out this has something to do with the variation in length of input tokens from one inference to the next. It doesn't seem to like receiving lengths that vary greatly, maybe this causes some sort of weird fragmentation in GPU memory?? Here's the code that only extract IMDB sentences that has >512 tokens. And it is able to sustain GPU utilization, with ~30it/s.      print  Any ideas, is there a serious bug lurking behind? If you have instructions/tips on how to debug, I would be eager to try.","Hi  , I just tried the code on Linux environment just to cross check the behaviour but got an error. Please refer to attached gist and confirm whether the attached code is missing anything ?  Since you are using tensorflowmacos with metal plugin request you to please post the issue in Apple forum also.  Thanks!"," Thanks for looking into it.  I went to Colab notebook. That error I believed is due to incorrect import of tqdm. It should be: `from tqdm import tqdm` I will modify my code snippet to include the pip and imports from your notebook I changed it my own copy of colab notebook, and it worked. Please bear in mind this issue is not reproducible on Colab with GPU acceleration. It happens only with metal on apple silicon.  And yes, here is the issue I logged on their forum: https://developer.apple.com/forums/thread/727890?answerId=750313022 CC(未找到相关数据)022 I am aware it may be a bit complicated to triage in lot of cases where more than one group is involved. However, if you can provide me tips, I can try debug this as far as I could, and crosspost whatever I find over with Apple.  While I understood the problem, and know how to work around it, I felt that the Apple GPU is not fulfilling its potential, since aligning every input length to the max_len (to ensure data uniformity) may not memoryefficient.","Hi , I got a query here. I gone through the code and In the code I can't see anywhere you have used tensorflow or keras. Is that Transformers using tensorflow  at backend ? Is that the reason you posted issue here ? I am not sure whether the issue needs to be addressed here ? Please confirm the dependency with Tensorflow/keras. Thanks!"," This is the transformers module from HuggingFace. It sort of a higher level framework that sits atop both Tensorflow and Pytorch. The code snippet given is backed by TF, as indicated by the model name “ TFDistilBertForSequenceClassification”. While this code is only for inference, I can also reproduce this issue during training, (i.e. calling model.fit)"," , Thanks for the confirmation.You mean that `TFDistilBertForSequenceClassification` is completely built upon Tensorflow as backend right?  AFAIK, This is the problem with only Mac M2 as you confirmed its fine on Colab/Linux, this needs to be addressed by Apple and I see you have already logged a ticket there. I can see some response there and hope it will be addressed If the problem also observed with Linux/colab then we might also have a look into it.I see this is not the case here."," This issue is specific to Apple M2 Max with Metal (GPU). And yes, TFDistil**** means it is backed by tensorflow in the backend. When I get the chance, I will attempt to build a case where huggingface is not involved, and see if it can reproduce. "," , Thanks for confirmation. But we are not supporting `tensorflowmacos` and it is not same as `tensorflow`. If you can reproduce the behaviour with only `tensorflow` involved then we will definitely have a look into the issue. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1918,"以下是一个github上的tensorflow下的一个issue, 标题是(Doc Feature Request: For tf 2, explain how to distribute a pretrained model across multiple nodes.)， 内容是 (When I read the original TF paper, I was told that > Dataflow simplifies distributed execution, because it makes communication between subcomputations explicit. > It enables the same TensorFlow program to be deployed to a cluster of GPUs for training, a cluster of TPUs for serving, and a cellphone for mobile inference.  > Each operation resides on a particular device, such as a CPU or GPU in a particular task. A device is responsible for executing a kernel for each operation assigned to it. > (...) > The TensorFlow runtime places operations on devices, subject to implicit or explicit constraints in the graph. > The placement algorithm computes a feasible set of devices for each operation, calculates the sets of operations that must be colocated, and selects a satisfying device for each colocation group. I work with small models, so I have never need more than one device. But now large models are all the rage, and a lot of competition is about just getting the weights of a pretrained model and run them. So I want cluster all the GPUs of a room to just run a LLM, either adhoc, keras or HF.  I would expect a tutorial for this to be available somewhere. It is not. I guess one still needs to configure a cluster description and, if such option is available still in 2.x, launch an script in each machine to join them into a cluster. And then somehow launch a master script in some machine that loads the model, deploys its graph across the cluster, and runs it. Without needing any mirroring or any parameter collection, so that the current objects in distribute.strategy seem very big for such task. Perhaps eventually)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,arivero,"Doc Feature Request: For tf 2, explain how to distribute a pretrained model across multiple nodes.","When I read the original TF paper, I was told that > Dataflow simplifies distributed execution, because it makes communication between subcomputations explicit. > It enables the same TensorFlow program to be deployed to a cluster of GPUs for training, a cluster of TPUs for serving, and a cellphone for mobile inference.  > Each operation resides on a particular device, such as a CPU or GPU in a particular task. A device is responsible for executing a kernel for each operation assigned to it. > (...) > The TensorFlow runtime places operations on devices, subject to implicit or explicit constraints in the graph. > The placement algorithm computes a feasible set of devices for each operation, calculates the sets of operations that must be colocated, and selects a satisfying device for each colocation group. I work with small models, so I have never need more than one device. But now large models are all the rage, and a lot of competition is about just getting the weights of a pretrained model and run them. So I want cluster all the GPUs of a room to just run a LLM, either adhoc, keras or HF.  I would expect a tutorial for this to be available somewhere. It is not. I guess one still needs to configure a cluster description and, if such option is available still in 2.x, launch an script in each machine to join them into a cluster. And then somehow launch a master script in some machine that loads the model, deploys its graph across the cluster, and runs it. Without needing any mirroring or any parameter collection, so that the current objects in distribute.strategy seem very big for such task. Perhaps eventually",2023-04-08T20:59:21Z,stat:awaiting response type:feature stale comp:dist-strat,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60270,"  Running a large language model on a cluster of GPUs can be achieved with TensorFlow's distribution strategies. Since TensorFlow 2.x provides a much easier interface to work with, I'll outline a highlevel approach for you to follow using TensorFlow 2.x, Keras, and Horovod. Install the necessary packages: Install TensorFlow 2.x. Install Horovod, a distributed deep learning framework, which works well with TensorFlow, Keras, and other DL frameworks. Set up the cluster: For an inhouse cluster of GPUs, make sure all devices are connected to the same network and have the necessary GPU drivers and software installed (CUDA, cuDNN, etc.). For a cloudbased cluster, use the provider's GPUbased instances and set up a virtual private network (VPN) between the instances. Configure TensorFlow and Horovod: Import TensorFlow, Keras, and Horovod. Initialize Horovod by calling horovod.tensorflow.keras.init(). Prepare your model: Load your large language model using TensorFlow or Keras, e.g., tf.keras.models.load_model('path/to/model'). Wrap the model's optimizer with horovod.DistributedOptimizer(optimizer). Compile the model with the wrapped optimizer and appropriate loss and metric functions. Configure the training and evaluation steps: Set up your dataset and data pipeline. Wrap your dataset with tf.data.experimental.parallel_interleave() or tf.data.experimental.CsvDataset.from_generator() to distribute the data across multiple GPUs. Define a custom training loop or use the builtin model.fit() and model.evaluate() functions. With Horovod, the training and evaluation steps will be automatically distributed across the available GPUs. Run the training and evaluation: Use horovodrun to launch your script on all the available devices. For example, horovodrun np 4 H localhost:4 python your_script.py will run your script on 4 GPUs. This highlevel approach should provide a starting point for running a large language model on a cluster of GPUs using TensorFlow 2.x, Keras, and Horovod. You may need to finetune the configuration and code to adapt to your specific setup and requirements."," just to be sure can you confirm that if I use a model such that **it does not fit in one GPU** but its graph can be put across four GPUs, then horovod allows me to run inference? I can not see in the documentation any decent sample of model parallelism, not even GPUs in the same machine, and we are speaking of multinode clusters. Even if it does, I still think that a tensorflow only tutorial would be a good thing, as distributing graphs was one of the design goals of tensorflow, so it could be good to exhibit this capability.","Hi  , For training on multiple works you can go through the attached tutorials here and here.All these uses data parallelism concept. However if you are looking for model parallelism right now Tensorflow not supporting model parallelism.Please refer to the source here.Here Model parallelism refers to splitting the Model on to different Ops and placing them on to different devices/workers and executing the Ops in Parallel. Right now Tensorflow supports data Parallelism i.e. splitting the data into different devices/workers. If I am still missing something here please let me know. Thanks!","Thanks, yes, I was looking for model parallelism, I see that it is not supported for training, but I was hoping that some support for inference only, when the graph is already know and trained. There is some legacy information around where it is suggested to use submodels and tf.device() contexts, to deploy manually, but it is mainly for tensorflow 1.x and not sure if it really works across servers. What I was looking for was a recipe such as:  build the model.  from the model, obtain the graph.  for each node, launch a server for all the devices it manages, or allows allocation.  for the graph, loop manually across, using tf.device() or something similar to allocate each operation to a device.  or, alternatively, give to tf a list of all the target devices and let it to allocate as it needs.  execute.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
2149,"以下是一个github上的tensorflow下的一个issue, 标题是(Hey why you all are stopping the tensorflow GPU support for windows. It sucks you know. I am here sitting infront of my computer since 12 hours and trying to analyze whats going wrong and why my GPU is not showing on the tensorflow. And after some reserch I found that you are stopping the suppport . WHY?????????????????????????)， 内容是 (Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**:    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:    **TensorFlow installed from (source or binary)**:    **TensorFlow version (use command below)**:    **Python version**:    **Bazel version (if compiling from source)**:    **GCC/Compiler version (if compiling from source)**:    **CUDA/cuDNN version**:    **GPU model and memory**:    **Exact command to reproduce**: You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh You can obtain the TensorFlow version with:   Describe the problem Describe the prob)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Satya-prakash3,Hey why you all are stopping the tensorflow GPU support for windows. It sucks you know. I am here sitting infront of my computer since 12 hours and trying to analyze whats going wrong and why my GPU is not showing on the tensorflow. And after some reserch I found that you are stopping the suppport . WHY?????????????????????????,"Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**:    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:    **TensorFlow installed from (source or binary)**:    **TensorFlow version (use command below)**:    **Python version**:    **Bazel version (if compiling from source)**:    **GCC/Compiler version (if compiling from source)**:    **CUDA/cuDNN version**:    **GPU model and memory**:    **Exact command to reproduce**: You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh You can obtain the TensorFlow version with:   Describe the problem Describe the prob",2023-04-08T15:45:16Z,stat:awaiting response type:build/install stale subtype:windows TF 2.12,closed,1,4,https://github.com/tensorflow/tensorflow/issues/60268,"Hi, In this TensorFlow blog please see section ""Expanded GPU support on Windows"". Also please see TensorFlow install page and this page for more info. Please feel free to sign up to the mailing list announce.org to be notified of the most recent updates.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1100,"以下是一个github上的tensorflow下的一个issue, 标题是(TF Hangs when calculating validation sample weights)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version unknown 2.9.2  Custom Code Yes  OS Platform and Distribution MacOS 12.4  Mobile device NA  Python version Python 3.10.5  Bazel version NA  GCC/Compiler version NA  CUDA/cuDNN version NA  GPU model and memory NA  Current Behaviour? While using `validation_data` in `model.fit`, TF hangs when it's finished the first epoch (but before updating the progress bar with the validation loss).  Specifically, this happens when a 3tuple is passed to `validation_data`, where the third element is an array specifying the sample weights. This happens even if the sample weights are all `1.0`.  Standalone code to reproduce the issue   Relevant log output  At this point Tensorflow stops and I've got to interrupt it in order to get control back. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,beyarkay,TF Hangs when calculating validation sample weights,"Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version unknown 2.9.2  Custom Code Yes  OS Platform and Distribution MacOS 12.4  Mobile device NA  Python version Python 3.10.5  Bazel version NA  GCC/Compiler version NA  CUDA/cuDNN version NA  GPU model and memory NA  Current Behaviour? While using `validation_data` in `model.fit`, TF hangs when it's finished the first epoch (but before updating the progress bar with the validation loss).  Specifically, this happens when a 3tuple is passed to `validation_data`, where the third element is an array specifying the sample weights. This happens even if the sample weights are all `1.0`.  Standalone code to reproduce the issue   Relevant log output  At this point Tensorflow stops and I've got to interrupt it in order to get control back. ",2023-04-08T11:18:36Z,stat:awaiting response stale comp:keras subtype:macOS type:performance TF 2.9,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60267,"In addition to this, isn't it a bug that setting the `class_weight` parameter in `model.fit` does not apply those class weights to the `validation_data`? For example, this code:  results in `loss` values around 0.001, but `val_loss` values of around 4.0, because I have one very dominant class (~99% of the observations) and 49 classes in the remaining 1%. Shouldn't the `class_weight` dictionary be applied to the `val_loss` calculation if `validation_data` is provided?", is this a known issue? or is there any solution planned?,"Hello ! I was able to run the code successfully on colab using TF v2.12, please find the gist here and  try to upgrade the TF version to latest. Thank you!",I am unable to update to the latest version of TF because of this macos/metal bug. Is there any fix that I can use besides updating? (since it seems like apple isn't going to be fixing the issue super soon), Thank you for the response!  Could you please have a look at this issue? Thank you!,"Hi  , If you want to use latest tensorflowmacos with metal plugin, you need to use legacy optimizer. The constraint you have mentioned for updating to new version is due to the optimizer issue.Suppose if you are using `keras.optimizers.Adam(1e5)` replace it with `tf.keras.optimizers.legacy.Adam(1e5)` and it should work fine.  Please try this and let us know of still having any problem. Thanks!",Thanks! That works perfectly. Are there any differences between `keras.optimizers.Adam` and `tf.keras.optimizers.legacy.Adam` that I should know about which might cause me issues in the future?,"Okay nevermind, it's not working now for some reason. I'll paste the code I'm using (although I literally only used the legacy version of Adam) but it's having the same error. I've tried restarting my notebook, but no luck.  Code   And the output is: "," , I have replicated the issue with tensorflowmacos==2.11 version and its still an issue with 2.11 version also. The code hangs as reported and i have to interrupt it manually after around 2 minutes.For reference I have attached the logs below.  I have also tested with tensorflowmacos 2.12 versions and the same behaviour observed there also.Attched logs below for reference. 60267_logs(macos2.12).txt",Thanks for looking at it! Is there any hope for a fix?," , Do you have any pointers ? The same code works fine with tensorflow==2.12 on colab but fails with tensorflowmacos.  cc: toplay ","Hi , The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. So I tried with the lasted tensorFlow version and did not face any hanging problem.  !image Thank You.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
718,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot compile TensorFlow 2.10 with GPu support on Windows)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10  Custom Code No  OS Platform and Distribution Windows Server 2016  Mobile device _No response_  Python version 3.8.8  Bazel version 5.1.0  GCC/Compiler version _No response_  CUDA/cuDNN version 11.8/8.6  GPU model and memory Nvidia GeForce GTX 1080 Ti  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Rayndell,Cannot compile TensorFlow 2.10 with GPu support on Windows,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10  Custom Code No  OS Platform and Distribution Windows Server 2016  Mobile device _No response_  Python version 3.8.8  Bazel version 5.1.0  GCC/Compiler version _No response_  CUDA/cuDNN version 11.8/8.6  GPU model and memory Nvidia GeForce GTX 1080 Ti  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-07T13:16:27Z,stat:awaiting response type:build/install subtype:windows TF 2.10,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60264,"Oh, and I have already tried some workarounds, like creating a CUDNN_INSTALL_PATH environment variable and enablind the Developer mode, like suggested in this post : https://discuss.tensorflow.org/t/errorbuildingtensorflow28inwindows10/7984","The error message you are seeing suggests that there is an issue with the LLVM project in your TensorFlow build. Here are some possible steps you can try to resolve the error: Check your LLVM version: TensorFlow 2.10 requires LLVM 9.0, which you can download from the LLVM website. Make sure to download the correct version of LLVM that matches your system. Check your Bazel version: Make sure that you have installed the correct version of Bazel that matches the TensorFlow version you are trying to build. You can find the required Bazel version in the TensorFlow documentation. Clean the Bazel cache: Try cleaning the Bazel cache by running ""bazel clean"" in your TensorFlow source directory. This will clear any cached build artifacts that may be causing issues. Rebuild the LLVM project: Try rebuilding the LLVM project by running ""bazel build //external:llvmproject"" in your TensorFlow source directory. This will rebuild the LLVM project from scratch. Rebuild TensorFlow: Once you have rebuilt the LLVM project, try rebuilding TensorFlow by running ""bazel build config=opt //tensorflow/tools/pip_package:build_pip_package"" in your TensorFlow source directory. This will create a new TensorFlow pip package with GPU support.","Thank you very much for your answer. I'm using Bazel 5.1.0, which is the correct version that should be used with TF 2.10. I installed LLVM 9.0 on my system, however it does not seem to change anything (LLVM install folder has been added to the Windows Path) as it still tries to fetch the llvm project. Finally, i tried building the llvm project manually with the bazel command and had this error: ERROR: D:/tensorflow/tensorflow/WORKSPACE:15:14: in llvm_configure rule //external:llvmproject: Found reference to a workspace rule in a context where a build rule was expected; probably a reference to a target in that external repository, properly specified as //path/to/package:target, should have been specified by the requesting rule. A bazel clean did not help.","I have some updates. After some further manual cleaning another error came out: ERROR: An error occurred during the fetch of repository 'envoy_api':    Traceback (most recent call last):         File ""D:/tensorflow/bazelout/zfk46uyn/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 100, column 45, in _http_archive_impl                 download_info = ctx.download_and_extract( Error in download_and_extract: java.io.IOException: Error downloading [https://github.com/envoyproxy/dataplaneapi/archive/c83ed7ea9eb5fb3b93d1ad52b59750f1958b8bde.tar.gz] to D:/tensorflow/bazelout/zfk46uyn/external/envoy_api/temp17372839701998073658/c83ed7ea9eb5fb3b93d1ad52b59750f1958b8bde.tar.gz: Unknown host: codeload.github.com So it seems I have troubles fetching the envoy_api project now... In general I also have a lot of warnings stating that files were not found when trying to download some projects: WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/6ca793b5d862ef6c50f242d77a811f06cce9b60a.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvmproject/archive/0538e5431afdb1fa05bdcedf70ee502ccfcd112a.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found WARNING: Download from https://github.com/envoyproxy/dataplaneapi/archive/c83ed7ea9eb5fb3b93d1ad52b59750f1958b8bde.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException Unknown host: codeload.github.com","You can find the download link for the c83ed7ea9eb5fb3b93d1ad52b59750f1958b8bde.tar.gz file in the error message. Download the file and extract it to the D:/tensorflow/bazelout/zfk46uyn/external/envoy_api directory. Once the file is in the correct directory, try running the build command again and see if the issue is resolved. I'm afraid if this does not work, it may either be a network issue (your ISP forbids you from visiting the urls) or a bazel issue.","So, I am progressing a little bit. Basically I had troubles creating symlinks under my account for some reason. I started from the beginning from a fresh Windows account on my machine and this solved it. However, I am still running into issues when linking the project: ERROR: D:/tensorflow/tensorflow/tensorflow/BUILD:1034:21: Linking tensorflow/libtensorflow_framework.so.2.10.1 failed: (Exit 1189): link.exe failed: error executing command   cd /d D:/tensorflow/bazelout/zfk46uyn/execroot/org_tensorflow   SET INCLUDE=C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Tools\MSVC\14.34.31933\include;C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Tools\MSVC\14.34.31933\ATLMFC\include;C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Auxiliary\VS\include;C:\Program Files (x86)\Windows Kits\10\include\10.0.22000.0\ucrt;C:\Program Files (x86)\Windows Kits\10\\include\10.0.22000.0\\um;C:\Program Files (x86)\Windows Kits\10\\include\10.0.22000.0\\shared;C:\Program Files (x86)\Windows Kits\10\\include\10.0.22000.0\\winrt;C:\Program Files (x86)\Windows Kits\10\\include\10.0.22000.0\\cppwinrt;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um     SET LIB=C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Tools\MSVC\14.34.31933\ATLMFC\lib\x64;C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Tools\MSVC\14.34.31933\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.22000.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\\lib\10.0.22000.0\\um\x64     SET PATH=C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Tools\MSVC\14.34.31933\bin\HostX64\x64;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\VC\VCPackages;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files\Microsoft Visual Studio\2022\Professional\MSBuild\Current\bin\Roslyn;C:\Program Files\Microsoft Visual Studio\2022\Professional\Team Tools\Performance Tools\x64;C:\Program Files\Microsoft Visual Studio\2022\Professional\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\CommonExtensions\Microsoft\FSharp\Tools;C:\Program Files (x86)\Windows Kits\10\bin\10.0.22000.0\\x64;C:\Program Files (x86)\Windows Kits\10\bin\\x64;C:\Program Files\Microsoft Visual Studio\2022\Professional\\MSBuild\Current\Bin\amd64;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\Tools\;;C:\Windows\system32;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja;C:\Program Files\Microsoft Visual Studio\2022\Professional\Common7\IDE\VC\Linux\bin\ConnectionManagerExe     SET PWD=/proc/self/cwd     SET RUNFILES_MANIFEST_ONLY=1     SET TEMP=C:\Users\AURELI~1\AppData\Local\Temp     SET TMP=C:\Users\AURELI~1\AppData\Local\Temp   C:\Program Files\Microsoft Visual Studio\2022\Professional\VC\Tools\MSVC\14.34.31933\bin\HostX64\x64\link.exe out/x64_windowsoptexec50AE0418/bin/tensorflow/libtensorflow_framework.so.2.10.12.params  Configuration: 235f51f52e7e1d2ff49596414691042bdab9491882365c09175bc46cf2ee6814  Execution platform: //:platform LINK : warning LNK4044: option '/lm' non reconnue ; ignorée LINK : fatal error LNK1189: limite de 65535 objets dépassée pour la bibliothèque Target //tensorflow:tensorflow_cc.dll failed to build What I understood from the last LINK error (it is in french, it means ""Link error 1189 library limit of 65535 objects exceeded"") is that MSVC is trying to create a dll or a lib with too many objects in it. As I understood it is a MSVC limitation, however it is strange I did not encounter this error before, since I previously built the 2.4 TF version without any of this type. So, is there a means to overcome this limitation (seems unlikely), or to prevent TF from putting too many objects in the binaries? For example by choosing which objects to exclude from the compilation (I certainly do not need all that exists in the TensorFlow release)?"," , Could you please cross check with the tested configuration for TF2.10 versions (CUDA=11.2 and cuDNN=8.1) and let us know if the build has any problem. We can't guarantee that CUDA 11.8 works with Tf2.10v or not. But if the build fails with CUDA11.2 then definitely we will have a look . Thanks!",Thanks for the response. Actually I succeeded by downgrading to the 2.7 version (haven't tested 2.8 and 2.9) and using Python 3.9. The built went well with CUDA 11.8. I am not sure if I will have the time to retest the 2.10 build with lower versions of CUDA though.," , Higher CUDA versions may also work if taken care of backward compatibility.Since we have tested configurations and also documented them we recommend users to follow same and we guarantee that they work and if not will be taken care by us. In case your purpose resolved can we mark it as closed ? Please spare some time to close the issue and in future if have any problems please feel free to open a ticket. Thanks!",Are you satisfied with the resolution of your issue? Yes No
705,"以下是一个github上的tensorflow下的一个issue, 标题是(Windows bazel says python is not an executable when building)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version r2.12  Custom Code No  OS Platform and Distribution Widnows 10  Mobile device Asus pc  Python version 3.11  Bazel version 6.1.1  GCC/Compiler version msbuild 17.5.1+f6fdcf537  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,TurgutBababalim,Windows bazel says python is not an executable when building,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version r2.12  Custom Code No  OS Platform and Distribution Widnows 10  Mobile device Asus pc  Python version 3.11  Bazel version 6.1.1  GCC/Compiler version msbuild 17.5.1+f6fdcf537  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-07T10:51:38Z,stat:awaiting response type:build/install stale subtype:windows TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60263,"The error message you are seeing suggests that Bazel is unable to locate the Python executable specified in the PATH environment variable. Here are a few things you can try to fix the issue: 1. Verify that the Python executable is in your PATH: Make sure that the directory containing the Python executable is actually included in your PATH environment variable. You can verify this by running echo %PATH% in the Command Prompt and checking whether the directory containing the Python executable is listed. Next, Use the full path to the Python executable: Instead of relying on the PATH environment variable, you can try specifying the full path to the Python executable in the configure.py script. For example, you can try running python configure.py interpreter=C:/Users/Asus/AppData/Local/Programs/Python/Python311/python.exe. 2.Try using a different version of Python: It's possible that the version of Python you are using is not compatible with TensorFlow. You can try using a different version of Python (e.g., Python 3.7) and see if that resolves the issue and check your Bazel version: Make sure that you are using the correct version of Bazel that is compatible with TensorFlow 2.12. You can check the Bazel version requirements in the TensorFlow documentation. If all fails, then try using a prebuilt TensorFlow package: If you are still having issues building TensorFlow from source, you can try using a prebuilt TensorFlow package instead. You can download prebuilt TensorFlow packages for Windows from the TensorFlow website.","Hi , As per the official documentation, Tensorflow 2.12 is compatible with Bazel 5.3.0. Please try again with the supported versions. Kindly refer to the tested build configurations.  Thank you! ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1670,"以下是一个github上的tensorflow下的一个issue, 标题是(Collected Tensorflow profiles are not recognized in Tensorboard)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device n/a  Python version 3.9.16  Bazel version n/a  GCC/Compiler version n/a  CUDA/cuDNN version 11.8.0/8.6.0.163  GPU model and memory NVIDIA GeForce RTX 3080 Ti 12GiB  Current Behaviour? I am following the tutorial at https://www.tensorflow.org/tutorials/quickstart/beginner I modified the code according to the instructions at https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras in order to enable profiling for a range of batches during training. With this change, training seems to proceed as normal, with the logs indicating that a profiler session is created, and a profile is collected. The logs directory contains one nonempty `plugins/profile//.xplane.pb` file. But when I run tensorboard (either main or tbnightly) on the logs, it fails to detect a profile (the Profile tab is missing from the UI). I also confirm I ran `pip install U tensorboardpluginprofile` first. I would have expected one of these two outcomes: either (a) tensorboard would show me the profiles, or (b) if something went wrong either when collecting or displaying the profiles, an error message would have indicated it so I can fix the issue.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,stefanbucur,Collected Tensorflow profiles are not recognized in Tensorboard,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.13.0dev20230406  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device n/a  Python version 3.9.16  Bazel version n/a  GCC/Compiler version n/a  CUDA/cuDNN version 11.8.0/8.6.0.163  GPU model and memory NVIDIA GeForce RTX 3080 Ti 12GiB  Current Behaviour? I am following the tutorial at https://www.tensorflow.org/tutorials/quickstart/beginner I modified the code according to the instructions at https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras in order to enable profiling for a range of batches during training. With this change, training seems to proceed as normal, with the logs indicating that a profiler session is created, and a profile is collected. The logs directory contains one nonempty `plugins/profile//.xplane.pb` file. But when I run tensorboard (either main or tbnightly) on the logs, it fails to detect a profile (the Profile tab is missing from the UI). I also confirm I ran `pip install U tensorboardpluginprofile` first. I would have expected one of these two outcomes: either (a) tensorboard would show me the profiles, or (b) if something went wrong either when collecting or displaying the profiles, an error message would have indicated it so I can fix the issue.  Standalone code to reproduce the issue   Relevant log output  ",2023-04-07T03:33:16Z,comp:tensorboard stat:awaiting response type:bug stale TF 2.12,closed,1,9,https://github.com/tensorflow/tensorflow/issues/60262,Seems we have encountered similar problems.  Can you find `events.out.tfevents.*` in the directory where `plugins` is  located?,The Tf profile is working well for me. But I am not able to see any loss values in TensorBoard.,">  Yes, here is the full directory contents: ","I must have done something right, now it works fine.","Update: I was able to get it working, *under certain conditions*. If I do a `$ tensorboard logdir logs/` command, per the instructions in the tutorial, profiling will not work. If instead I run `tensorboard` on the specific subdir that contains the profile (`$ tensorboard logdir logs/fit/20230417090906/`), then the profile will show up, but **only after I refresh the browser window once**. Once I refresh the browser window, and I access the profile tab, `*.hlo_proto.pb` files start showing up alongside the original `*.xplane.pb` profile. Note that refreshing the window won't fix it in the original case (opening the toplevel `logs/` dir). Just a guess, but perhaps there is a regression in how tensorboard traverses the logs directory tree?","""Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.""",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
528,"以下是一个github上的tensorflow下的一个issue, 标题是(Fixed bug with DEBUG_MODE bug when performing from_tensor_slices on a ragged tensor)， 内容是 (Fixed bug with DEBUG_MODE bug when performing from_tensor_slices on a ragged tensor related to issue CC(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error) Thank you, if there are any suggestions feel free to comment.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,jsparson1,Fixed bug with DEBUG_MODE bug when performing from_tensor_slices on a ragged tensor,"Fixed bug with DEBUG_MODE bug when performing from_tensor_slices on a ragged tensor related to issue CC(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error) Thank you, if there are any suggestions feel free to comment.",2023-04-06T03:12:51Z,stale comp:data size:XS,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60250,"Please don't use ""add file""/""update file""/""fix file""/etc. commit messages. These are hard to reason about when looking at the history of the file/repository. Instead, please write explanatory git commit messages. The commit message is also the title of the PR if the PR has only one commit. It is thus twice important to have commit messages that are relevant, as PRs would be easier to understand and easier to analyze in search results. For how to write good quality git commit messages, please consult https://cbea.ms/gitcommit/ ","Note that the proposed fix is not really a fix  it just switches off eager mode for ragged tensor results, which is not what should happen. Instead, the problem is really the `ops.convert_to_tensor` on the following line: https://github.com/tensorflow/tensorflow/blob/06390d9be42502bb14c055be3978e5cd52a0f376/tensorflow/python/data/ops/structured_function.pyL240 The dataset elements can be ragged or sparse tensors, so this conversion must instead honor the type specs in `self._output_structure`. Maybe it is even the case that for ragged/sparse tensors, these must have been constructed explicitly in the mapping function and no further conversion is necessary (while for a usual tensor, the mapping function might return a Python list that needs to be converted to a tensor)? Last but not least, such a change requires tests to verify that the fix works and that the problem will never appear again (and apart the ragged tensors mentioned in CC(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error), it should also include support for sparse tensors).",Hi  Can you please check 's comments and keep us posted ? Thank you!,"> Hi  Can you please check 's comments and keep us posted ? Thank you!< Yes, I can and I plan on it right now I have some other stuff I'm dealing with, I will be able to work on improving my fix and writing tests in the coming days, thank you all for your feedback.","ข้อทราบข้อมูล ไฟล์งานที่คุณ ส่งคำขอดึง ระบบของเราด้วย เพราะข้อมูลที่คุณส่งมา ทั้งหมด คือไฟล์งานของ ทีม ระบบ GitHub ทั้งหมด ทีม Marketplace Khaokho29th เมื่อ 5 พ.ค. 2023 20:28 น. ""Josh Parson"" ***@***.***> เขียนว่า Hi   Can you please check  's comments and keep us posted ? Thank you! Yes I can and I plan on it right now I'm in the middle of exams, I will be able to work on improving my fix in the coming days, thank you all for your feedback. — Reply to this email directly, view it on GitHub , or unsubscribe  . You are receiving this because you are subscribed to this thread.Message ID: ***@***.***>","> Note that the proposed fix is not really a fix  it just switches off eager mode for ragged tensor results, which is not what should happen. >  > Instead, the problem is really the `ops.convert_to_tensor` on the following line: >  > https://github.com/tensorflow/tensorflow/blob/06390d9be42502bb14c055be3978e5cd52a0f376/tensorflow/python/data/ops/structured_function.pyL240 >  > The dataset elements can be ragged or sparse tensors, so this conversion must instead honor the type specs in `self._output_structure`. Maybe it is even the case that for ragged/sparse tensors, these must have been constructed explicitly in the mapping function and no further conversion is necessary (while for a usual tensor, the mapping function might return a Python list that needs to be converted to a tensor)? >  > Last but not least, such a change requires tests to verify that the fix works and that the problem will never appear again (and apart the ragged tensors mentioned in CC(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error), it should also include support for sparse tensors). I just got an opportunity to look at it again and I actually think its the previous line `print(""TestStart"")`  `ret = structure.to_tensor_list(self._output_structure, ret)`   `print(""TestEnd"")` Note only TestStart prints out TestStart 20230510 22:16:10.385226: W tensorflow/core/framework/op_kernel.cc:1817] INVALID_ARGUMENT: ValueError: Value [1 2] is not convertible to a tensor with dtype  and shape (). Traceback (most recent call last): a possible fix could be padding the ragged tensors but that's kind hacky I will look into an alternative solution","You are right that the crash already happens in `to_tensor_list`. Problem is that the ragged tensor has already been converted using the https://www.tensorflow.org/api_docs/python/tf/raw_ops/RaggedTensorToVariant, so the `_output_structure` contains just ""this is a Tensor of dtype variant"" instead of ""this is a ragged tensor"". But maybe we could modify the `TensorSpec._to_components` to be able to handle such situation  i.e., if it gets a ragged tensor and should convert it to `variant` dtype, it could use the above mentioned method to do it, instead of `ops.convert_to_tensor`? I just tried, but I could not make it work easily; maybe we should investigate more how exactly the processing works without the debug mode and handle the conversions raggeddense as it is done there.",Hi  Any update on this PR? Please. Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further.
442,"以下是一个github上的tensorflow下的一个issue, 标题是(Fixes error with DEBUG_MODE and ragged tensors for Dataset.from_tensor_slices())， 内容是 (This change fixes issue CC(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error). Thank you, if you have any changes feel free to comment)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,jsparson1,Fixes error with DEBUG_MODE and ragged tensors for Dataset.from_tensor_slices(),"This change fixes issue CC(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error). Thank you, if you have any changes feel free to comment",2023-04-05T22:39:30Z,size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60249,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request."
1286,"以下是一个github上的tensorflow下的一个issue, 标题是(In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version TF 2.12.0, TF nightly 2.13.0dev20230404  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Consider the following code creating ragged batches using `tf.data.Dataset.ragged_batch`:  The above code works fine in normal mode. However, if you enable debug mode using `tf.data.experimental.enable_debug_mode()`, the same code crashes with an error.  Standalone code to reproduce the issue I reproduced the error in https://colab.research.google.com/drive/1nf1BHjssx2YhF0ZbbgPg1QSALSS4Z89r?usp=sharing , both for TF 2.12.0 and TF nightly 2.13.0dev20230404. The code for triggering the bug is the following:   Relevant log output Here is the error printed by TF 2.12.0  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,foxik,"In tf.data.experimental.enable_debug_mode, tf.data.Dataset.ragged_batch fails with an error","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version TF 2.12.0, TF nightly 2.13.0dev20230404  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Consider the following code creating ragged batches using `tf.data.Dataset.ragged_batch`:  The above code works fine in normal mode. However, if you enable debug mode using `tf.data.experimental.enable_debug_mode()`, the same code crashes with an error.  Standalone code to reproduce the issue I reproduced the error in https://colab.research.google.com/drive/1nf1BHjssx2YhF0ZbbgPg1QSALSS4Z89r?usp=sharing , both for TF 2.12.0 and TF nightly 2.13.0dev20230404. The code for triggering the bug is the following:   Relevant log output Here is the error printed by TF 2.12.0  ",2023-04-05T10:26:05Z,stat:awaiting response type:bug stale comp:data TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60239,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1913,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite NNAPI Delegate converts INT8 UnidirectionalSequenceLSTM to incorrect NN operation type)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12.0  Custom Code No  OS Platform and Distribution Android 12, aarch64  Mobile device Pixel 4 xl  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue    To run on device with TFLite benchmark tool Whether to turn `disable_nnapi_cpu`  to true or false makes no difference.  shell  beginning of main 20230404 17:24:18.427 1903619036 tflite                  pid19036                            I  STARTING! 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Log parameter values verbosely: [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Min num runs: [50] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Min runs duration (seconds): [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Max runs duration (seconds): [150] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Interrun delay (seconds): [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Number of prorated runs per second: [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Num threads: [1] 20230404 17:24:18.428 1903619036 tflite           )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,q-ycong-p,TFLite NNAPI Delegate converts INT8 UnidirectionalSequenceLSTM to incorrect NN operation type,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.12.0  Custom Code No  OS Platform and Distribution Android 12, aarch64  Mobile device Pixel 4 xl  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue    To run on device with TFLite benchmark tool Whether to turn `disable_nnapi_cpu`  to true or false makes no difference.  shell  beginning of main 20230404 17:24:18.427 1903619036 tflite                  pid19036                            I  STARTING! 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Log parameter values verbosely: [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Min num runs: [50] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Min runs duration (seconds): [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Max runs duration (seconds): [150] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Interrun delay (seconds): [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Number of prorated runs per second: [1] 20230404 17:24:18.428 1903619036 tflite                  pid19036                            I  Num threads: [1] 20230404 17:24:18.428 1903619036 tflite           ",2023-04-05T00:46:36Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:lite TFLiteConverter ModelOptimizationToolkit TFLiteNNAPIDelegate TF 2.12,closed,0,9,https://github.com/tensorflow/tensorflow/issues/60234,I've checked a few NNAPI delegate related posts. It looks like  has knowledge on this topic? If so I'd really appreciate some pointer! Thanks!,Here is the dummy TFLite model to reproduce the NNAPI delegate issue: lstm_w_emb_and_dense_3.8b.tflite.zip,"Additionally, I've also tried the posttraining dynamic range quantization which I would prefer to use. The result TFLite model of such quantization has float32 weights. Running that model with `usennapi` enabled shows that LSTM is not partitioned on NNAPI delegate. With `setprop debug.nn.vlog 1`, logcat info still does not show why LSTM cannot be partitioned to NNAPI delegate. With the full integer INT8 quantization in post, at least I see that the entire graph is partitioned to NNAPI delegate. Would appreciate your thoughts here too!","Hi , any chance dev can take a look? Thanks!","For LSTM operation types, TFLite `builtin_ops.h` contains 3 variants `kTfLiteBuiltinLstm`, `kTfLiteBuiltinUnidirectionalSequenceLstm` and `kTfLiteBuiltinBidirectionalSequenceLstm` which is not distinguished by data types, see here. On the NNAPI side, there're more LSTM operation variants, especially the quantized op has a separate operation type `ANEURALNETWORKS_QUANTIZED_LSTM`, which is distinguished from the float `ANEURALNETWORKS_UNIDIRECTIONAL_SEQUENCE_LSTM` variant, here. My understanding is that a full int8 TFLite `kTfLiteBuiltinUnidirectionalSequenceLstm` should be converted to NNAPI `ANEURALNETWORKS_QUANTIZED_LSTM` instead of the float variant. However, in TFLite's `nnapi_delegate.cc`'s `Map` function, `kTfLiteBuiltinUnidirectionalSequenceLstm` is mapped to `ANEURALNETWORKS_UNIDIRECTIONAL_SEQUENCE_LSTM`, see here. This seems to lead to the NNAPI operation creation issue in post? Pls point out what i'm missing. Besides, the `Validate` function seems to check and ensure `kTfLiteBuiltinUnidirectionalSequenceLstm` is not hybrid  which is a bit confusing. Could someone explain to me pls?","Hi ycongp , we're wondering if you may be able to resolve your issue by using AIEdgeTorch, you can find more information here: googleblog. I have actually created a simple script for converting an LSTM model here:  If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repos.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
888,"以下是一个github上的tensorflow下的一个issue, 标题是(INVALID_ARGUMENT: You must feed a value for placeholder tensor while creating Dataset iterator)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10.6  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA Toolkit 11.8, cuDNN 8.6.0  GPU model and memory NVIDIA GeForce RTX 3060 Mobile, 6GB  Current Behaviour?  while creating dataset iterator. While the code works, such message is annoying when the iterator is created in a loop, as it happens every time.   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lychanl,INVALID_ARGUMENT: You must feed a value for placeholder tensor while creating Dataset iterator,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10.6  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA Toolkit 11.8, cuDNN 8.6.0  GPU model and memory NVIDIA GeForce RTX 3060 Mobile, 6GB  Current Behaviour?  while creating dataset iterator. While the code works, such message is annoying when the iterator is created in a loop, as it happens every time.   Relevant log output  ",2023-04-04T15:21:12Z,stat:awaiting response type:bug stale comp:data TF 2.12,closed,0,13,https://github.com/tensorflow/tensorflow/issues/60228,"Changed tensorflow version to 2.11.1, the same bug does not occur",", I tried to execute the mentioned code in the latest stable tensorflow v2.12 and it was executed without any issue/error. Kindly find the gist of it here. Thank you!",Using Tensorflow Datasets (tf.data.Dataset used in TFDS) I've been getting spammed with the same log with Tensorflow 2.12.x and was not an issue using the same setup from roughly 2.4/2.5 to present,"Running the test code, I see the same annoying issue in TF 2.12 `20230417 14:48:51.110417: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performancecritical operations. To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230417 14:48:52.662722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Could not find TensorRT 20230417 14:48:54.976207: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:54.977348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:55.362289: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:55.363494: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:55.364605: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:55.365682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:56.357589: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:56.358620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:56.359587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:56.360554: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:56.361518: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:48:56.362469: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.316204: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.317328: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.318322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.319325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.320306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.321258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22004 MB memory:  > device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9 20230417 14:49:03.322420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfsbuspciL344L355 20230417 14:49:03.323273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6609 MB memory:  > device: 1, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:09:00.0, compute capability: 7.5 20230417 14:49:03.724125: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32 	 [[{{node Placeholder/_0}}]] `",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,And what is the solution? Does any new version fix this problem?,"For me, this issue went away with TF v2.13.","I was able to run this in 2.14 without any error, please find the attached Gist for reference, let me know if I'm missing any detail here. https://gist.github.com/sachinprasadhs/8751bb475c90511f75bc03c033d2f30e",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1479,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow Lite Converter Issue)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,surajraoo,TensorFlow Lite Converter Issue," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-04-04T12:27:28Z,stat:awaiting response stale comp:lite TFLiteConverter,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60218,"Hi   We see that the issue template has not been filled, could you please do so as it helps us analyze the issue. Please refer to this guide to quickly get started on converting your model.  Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
692,"以下是一个github上的tensorflow下的一个issue, 标题是(api for model parallelism)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",large language model,pure-rgb,api for model parallelism,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-04-03T23:09:21Z,stat:awaiting response type:support stale comp:apis TF 2.12,closed,0,8,https://github.com/tensorflow/tensorflow/issues/60214,"`tf.keras.utils.multi_gpu_model` can be used to replicate a Keras model across multiple GPUs, using data parallelism. `tf.split` and `tf.concat`are lowlevel TensorFlow operations that can be used to split tensors across multiple devices and combine their results. As for training and inference of large language models on consumerlevel GPUs with limited memory TensorFlow provides several solutions, such as: **Gradient checkpointing**: This technique allows the model to be split into smaller pieces, which can be processed one at a time, reducing the amount of memory required. **Mixed precision training**: This technique uses lowerprecision floating point numbers (e.g., `float16`) for some parts of the computation, reducing memory usage and improving training speed. **Model pruning:** This technique involves removing some of the model parameters that are less important, reducing the memory required for both training and inference. while TensorFlow does not have builtin support for tensor parallelism like Hugging Face's PyTorch Transformers library, it is still possible to implement tensor parallelism in TensorFlow using the lowlevel APIs mentioned above, such as `tf.split` and `tf.concat`. ","> tf.keras.utils.multi_gpu_model Doesn't support. It is deprecated.  > Mixed precision training Good tools. But not a solutions for model parallel. > Gradient checkpointing Good tools. Doesn't support in tensorflow. (pytorch does, lol) > Model pruning Seriously! Any official proven example that shows effectiveness of this approach on LLM models? ","In TensorFlow, you can use the `tf.distribute` API with `tf.keras` to implement model parallelism for distributed training. Here's a brief overview of how to use it: 1. First, you need to define a `tf.distribute.Strategy` object that represents the distribution strategy you want to use. The `tf.distribute.MirroredStrategy` is commonly used for model parallelism, as it replicates the model across multiple devices and synchronizes the gradients during training. 2. Next, you need to create a `tf.keras` model and compile it as usual. However, you should set the `tf.distribute.Strategy` object as the `tf.keras` optimizer, using the `tf.distribute.Strategy.scope()` context manager. 3. Finally, you can train the model using the `tf.keras` API as usual, but wrapped in a `tf.distribute.Strategy.scope()` context manager. This will ensure that the model is replicated and synchronized across multiple devices during training. Here's an example code snippet that demonstrates how to implement model parallelism using `tf.distribute` with `tf.keras`:  This code defines a simple feedforward neural network with two hidden layers and trains it on the MNIST dataset using the `tf.keras` API with `tf.distribute.MirroredStrategy` for model parallelism. Note that the code is almost identical to the nondistributed version, except for the `tf.distribute.Strategy` object and the `tf.distribute.Strategy.scope()` context managers.",  What you did is called dataparallelism and not model parallelism. ,"I'm not sure if you can achieve Tensor parallel (TP) similar to hugging face implementation, closest one would be tf.split  which splits the Tensors into multiple tensors based on the provided axis, the challenge in this would be when using multiple devices to use the synchronous training.  For this issue, you may find  spatial parallel training useful. For model parallelism and data parallelism, you can refer `DTensor`, a concept which enables synchronous distributed training.  Below are the guides and tutorials which can be helpful for you. 1. Distributed Training with DTensors  2. DTensor Concepts",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
691,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot pip install tensorflow examples)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kedarps,Cannot pip install tensorflow examples,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-03T19:14:45Z,type:bug type:build/install TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60213,TensorFlow example package is not available on PyPI. We can clone the TensorFlow example repository from GitHub and run the examples. Use this following command in cell ` !git clone https://github.com/tensorflow/examples.git` It will download the repo Then navigate to following example you want,"I am able to git clone the repo, but in some notebooks the `tensorflow_examples` package is referenced. How to use that? This line fails: `from tensorflow_examples.models.pix2pix import pix2pix` This is from segmentation tutorial given here","> I am able to git clone the repo, but in some notebooks the `tensorflow_examples` package is referenced. How to use that? This line fails: >  > `from tensorflow_examples.models.pix2pix import pix2pix` >  > This is from segmentation tutorial given here   Thanks for reporting this issue.  As per this comment. Please clone the TensorFlow example repository from GitHub. Use `from examples.tensorflow_examples.models.pix2pix import pix2pix` instead of `from tensorflow_examples.models.pix2pix import pix2pix`, Now you can use 'pix2pix' package. please find the gist here for reference. Thank you !",Thankyou. It's working now.,Are you satisfied with the resolution of your issue? Yes No,it was solved also for me thanks
742,"以下是一个github上的tensorflow下的一个issue, 标题是(Keras model with Sparse Input failed to process symbolic Sparse Input after being saved and loaded again)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.4+  Custom Code Yes  OS Platform and Distribution CentOS   Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,diwen,Keras model with Sparse Input failed to process symbolic Sparse Input after being saved and loaded again,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.4+  Custom Code Yes  OS Platform and Distribution CentOS   Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-03T19:04:52Z,type:bug comp:keras TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60212,  This issue seems to be a keras issue.Please post this issue on kerasteam/keras repo. To know more see; https://discuss.tensorflow.org/t/kerasprojectmovedtonewrepositoryinhttpsgithubcomkerasteamkeras/1999. Thank you!," Thanks for reaching out regarding this issue! We recommend using the newer `.keras` format in TF 2.12. Please install TF 2.12 first and then try this format, as it is may solve many SavedModel related issues: model_dir = ""./test.keras"" model.save(model_dir, save_format=""keras_v3"") Make sure to use the `.keras` extension when saving and pass the `save_format` flag. Please let me know if this works, thanks!",I see. Thank you for the timely reply  and  !,Are you satisfied with the resolution of your issue? Yes No
747,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow Lite library is crashing in WASM library at 3rd inference)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.7.0  Custom Code Yes  OS Platform and Distribution Emscripten, Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,L1onKing,Tensorflow Lite library is crashing in WASM library at 3rd inference,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.7.0  Custom Code Yes  OS Platform and Distribution Emscripten, Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_",2023-04-03T14:07:06Z,stat:awaiting response type:support stale comp:lite TF 2.7,closed,0,15,https://github.com/tensorflow/tensorflow/issues/60210, Thanks for reporting the issue. Have you checked with latest stable version TF 2.12 and see if the issue still exists? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hello ! Thank you for your response. I am trying to figure out how to compile it using bazel. Bazel is a new thing to me, so far I don't understand how to work with it. Can you maybe guide me to some tutorial that explains how to build TFLite for WASM using Bazel? Thank you very much!","Hi   For C++ library, the TFLite provides `libtensorflowlite.so` which can be built using `bazel build config=elinux_aarch64 c opt //tensorflow/lite:libtensorflowlite.so`. I've created a sample gist to build the same using bazel which can be found here. Please refer to crosscompilation for ARM with Bazel here. Also, the TFLite supports for Tensorflow.js in which under the hood, the TFLite C++ runtime is packaged in a set of WASM modules with bazel. Please refer to this documentation for the detailed use and let us know if it helps. And, please find the relevant thread CC(tflite custom Bazel build for wasm target )  Thanks.","bazel build config=elinux_aarch64 c opt //tensorflow/lite:libtensorflowlite.so  so to my understanding, I need to run a command of such format from tensorflow repo directory. I have three questions on which I struggle to find an answer: 1. What is the `config` value if I want to build libtensorflowlite.a with WASM? 2. How to enable XNNPack during this build? 3. Where to find relevant public headers that I need to include in my project?  Thank you very much for your help!","Hi   >What is the config value if I want to build libtensorflowlite.a with WASM? The `config` value for WASM is not available in `.bazelrc` afaik.  We need to build the Bazel Emscripten toolchain manually using the instructions given here and set `confg=wasm`.  Also, the bazel build generates the `.so` sharable dynamic object file instead of `.a` as CMAKE does. >How to enable XNNPack during this build? The XNNPACK can be enable by adding `define tflite_with_xnnpack=true` during bazel build. As this comment suggests,  try the TFLite with TFjs which uses WASM backend given the bazel support for which comes with pre built binaries. Thanks.","Hi  !  Thank you for your recommendations, for the time being I am exploring this  https://github.com/tensorflow/tfjs/tree/master/tfjstflite So what I did: 1. Downloaded this repo 2. Navigated to tfjstflite folder where BUILD.bazel is located 3. Ran the command `bazel build //tfjstflite:tftflite` But I am having next output  It looks like the issue is in incompatibility of bazel and glibc. The output of `bazel version` on my machine:  Could you please advise what version of bazel should I use in order to make it run? Thank you very much!","Hi   The Bazel version 5.3.0 should be compatible. Moreover, you can build the `tfjstflite` using `yarn build` which inturn uses bazel with wasm backend.  Navigate to `tfjstflite` repo  Check for `yarn`  installation  Run `yarn build` Please check this gist provided with the `tfjstflite` build and can be tested  with`yarn test` with successful build. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi  ! Sorry for a long response, I was unavailable last week. Actually I did try `yarn build` command from `tfjstflite` folder, but that is the output I got: tfjs/tfjstflite$ yarn build 00h00m00s 0/0: : ERROR: [Errno 2] No such file or directory: 'build' yarn is installed and available in Terminal. Could you advise please?","**UPDATE** I have figured an issue with yarn and now `yarn build` command executes, but I have exactly the same issue: `libc.so.6: version `GLIBC_2.28' not found` Please advise how to fix it",Hi   Can you please check if latest `npm` and `nodejs` versions are installed? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
757,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow import error in virtual environment (vsc) - No module named 'tensorflow')， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.0  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version python 3.7.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,drishtia60,Tensorflow import error in virtual environment (vsc) - No module named 'tensorflow',Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.0  Custom Code Yes  OS Platform and Distribution Windows 10  Mobile device _No response_  Python version python 3.7.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-04-02T10:40:07Z,stat:awaiting response type:build/install stale subtype:windows TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60205,", There are at least 3 possible scenarios:  Also pip install tensorflow will install a version thats compatible with GPU and CPU. So it gives you that warning message. If you don't want to see warning messages and want to install the CPU only version, you could  pip install tensorflowcpu that's a smaller wheel file for the CPU only version. TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2, or install tensorflowcpu and, optionally, try the TensorFlowDirectMLPlugin https://www.tensorflow.org/install/pip?hl=enwindowsnative Also please take a look at this https://github.com/tensorflow/tensorflow/issues/57103 and https://github.com/tensorflow/tensorflow/issues/56976 with a similar error and try to uninstall all the dependencies and recreate a fresh conda env . Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
819,"以下是一个github上的tensorflow下的一个issue, 标题是(Detected unsupported operations when trying to compile graph XLA_GPU_JIT: ResizeNearestNeighborGrad)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  This is a shame because it limits the potential of XLA in GANs  Relevant log output ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,milmor,Detected unsupported operations when trying to compile graph XLA_GPU_JIT: ResizeNearestNeighborGrad,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  This is a shame because it limits the potential of XLA in GANs  Relevant log output ``` ,2023-04-02T03:43:17Z,stat:awaiting response type:bug stale comp:xla TF 2.12,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60203,"Hi , As a workaround, kindly set `interpolation=bilinear` in the **Upsampling2d** layer, which is compatible with GPUs. Kindly find the gist of working code here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
705,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in MatrixDeterminant)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230331  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in MatrixDeterminant,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230331  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-01T08:30:49Z,stat:awaiting response stat:awaiting tensorflower type:bug stale comp:ops TF 2.12,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60199,"Hi ,  I was able to replicate the issue in Ubuntu using tfnightly(2.13.0dev20230331). Please find the log below.  Thank you!",", This indicates the problem is due to a memory issue where the OS crashed in allocating the required memory which is expected. Also please refer to the developer https://github.com/tensorflow/tensorflow/issues/59168issuecomment1405633596 related to malloc with high input size which will eventually lead to an OS crash. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
704,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in TridiagonalSolve)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230331  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in TridiagonalSolve,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.13.0dev20230331  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-04-01T08:28:35Z,stat:awaiting tensorflower type:bug comp:ops,closed,0,2,https://github.com/tensorflow/tensorflow/issues/60198," I was able to replicate the issue on colab using TF v2.12 and tfnightly(2.13.0dev20230403), please find the attached gists. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1891,"以下是一个github上的tensorflow下的一个issue, 标题是(Add big-endian support to String TensorType in TFLite FlatBuffer models)， 内容是 (PR CC(Add bigendian support to TFLite FlatBuffers) has added bigendian support to numeric TensorTypes in TFLite FlatBuffers. However, since TFLite uses `tflite::DynamicBuffer` to encode vector of strings, the header of string buffer contains raw bytes which record the number of strings, the offsets of each string, etc., as shown in the following code snippet:  https://github.com/tensorflow/tensorflow/blob/864bf2ca8e4f314d9ad01d240d9e3fec2b653c93/tensorflow/lite/string_util.ccL78L87  Thus the String TensorType will have endianness issue if a TFLite model is used across platforms with different endianness formats. This PR aims to solve this issue in both C++ and Python code and uses the same guidelines on bigendian machines as PR CC(Add bigendian support to TFLite FlatBuffers) , such as: 1. Convert the string buffers from LE(littleendian) to BE(bigendian) format when loading a TFLite model from a file. 2. Convert the string buffers from BE to LE format when writing a serialized binary string of TFLite model to a file. 3. Keep the header of string buffers in BE format when the model/buffer is in memory. An argument `bool from_big_endian` was added to the function declaration of `FlatBufferModel::ByteSwapBuffer()` , because in this function we need to know the endianness of the raw bytes in the header of string buffer, so that we can read the `num_of_strings` data correctly. After applying this PR, the String TensorType will be correctly byteswapped along with other numeric TensorTypes when necessary. We've tested the code change on TensorFlow test suite, it won't cause any regressions on BE/LE platforms, and )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kun-lu20,Add big-endian support to String TensorType in TFLite FlatBuffer models,"PR CC(Add bigendian support to TFLite FlatBuffers) has added bigendian support to numeric TensorTypes in TFLite FlatBuffers. However, since TFLite uses `tflite::DynamicBuffer` to encode vector of strings, the header of string buffer contains raw bytes which record the number of strings, the offsets of each string, etc., as shown in the following code snippet:  https://github.com/tensorflow/tensorflow/blob/864bf2ca8e4f314d9ad01d240d9e3fec2b653c93/tensorflow/lite/string_util.ccL78L87  Thus the String TensorType will have endianness issue if a TFLite model is used across platforms with different endianness formats. This PR aims to solve this issue in both C++ and Python code and uses the same guidelines on bigendian machines as PR CC(Add bigendian support to TFLite FlatBuffers) , such as: 1. Convert the string buffers from LE(littleendian) to BE(bigendian) format when loading a TFLite model from a file. 2. Convert the string buffers from BE to LE format when writing a serialized binary string of TFLite model to a file. 3. Keep the header of string buffers in BE format when the model/buffer is in memory. An argument `bool from_big_endian` was added to the function declaration of `FlatBufferModel::ByteSwapBuffer()` , because in this function we need to know the endianness of the raw bytes in the header of string buffer, so that we can read the `num_of_strings` data correctly. After applying this PR, the String TensorType will be correctly byteswapped along with other numeric TensorTypes when necessary. We've tested the code change on TensorFlow test suite, it won't cause any regressions on BE/LE platforms, and ",2023-03-31T16:01:40Z,comp:lite ready to pull size:M,closed,0,13,https://github.com/tensorflow/tensorflow/issues/60190,"Hi  , Hope all is well with you and thanks for helping us review the previous TFLite related PRs. Could you please review this PR when you have a chance? Thanks again!","Hi  , Could you please take a look at this PR when you have some time? Thank you very much!",Hi  Can you please review this PR ? Thank you!,"Hi  , Could you please review this PR when you have a chance?  Thank you very much!","Hi wei , Thank you so much for reviewing this PR.  I've made changes as per your review comment. Could you please take a look again? Thanks!","Hi wei , Could you please review this PR again? Thank you very much!","Hi wei , Could you please take a look at the code change when you have a chance? Thanks!","Hi wei , I think the failures in `Py+CPP Test Suite` check are not related to the code changes in this PR, since the changes are specific to BigEndian systems and most are enclosed in `if FLATBUFFERS_LITTLEENDIAN == 0` macros. However, I'm not sure why the `feedback/copybara  Google internal checks` failed, since I couldn't access the logs. Could you please take a look? Thank you very much!","Hi  , Since I couldn't access the logs, could you please help check why the `feedback/copybara  Google internal checks` failed?   Thank you very much!","> Hi  , >  > Since I couldn't access the logs, could you please help check why the `feedback/copybara  Google internal checks` failed? >  > Thank you very much! Hi lu20 Sorry for the delay in response. We will check it. Thank you so much!","Hi  , Do you have any updates reg this PR?  Thank you very much!","> Hi  , >  > Do you have any updates reg this PR? >  > Thank you very much! Hi lu20 Sorry for the delay in response. We are working on this PR internally. Thank you so much!", Thanks for letting me know!
978,"以下是一个github上的tensorflow下的一个issue, 标题是(Enable secure grpc++/grpc deps and ssl features on s390x)， 内容是 (Since `boringssl` has not been supported on s390x yet, `//:grpc_unsecure` and `//:grpc++_unsecure` deps used to be chosen when building TensorFlow on s390x. However, we can enable secure grpc++/grpc deps and ssl related features for TensorFlow on s390x via `openssl` by using `TF_SYSTEM_LIBS=""boringssl""` flag in bazel commands. This PR aims to enable the abovementioned features on s390x by removing the specific `grpc_unsecure` and `grpc++_unsecure` deps from BUILD files and adding the `TF_SYSTEM_LIBS=""boringssl""` flag as a default option for Bazel during the configuration stage on s390x. After applying the above change, the following test cases would pass on s390x:  Fixes https://github.com/tensorflow/tensorflow/issues/51770 .)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kun-lu20,Enable secure grpc++/grpc deps and ssl features on s390x,"Since `boringssl` has not been supported on s390x yet, `//:grpc_unsecure` and `//:grpc++_unsecure` deps used to be chosen when building TensorFlow on s390x. However, we can enable secure grpc++/grpc deps and ssl related features for TensorFlow on s390x via `openssl` by using `TF_SYSTEM_LIBS=""boringssl""` flag in bazel commands. This PR aims to enable the abovementioned features on s390x by removing the specific `grpc_unsecure` and `grpc++_unsecure` deps from BUILD files and adding the `TF_SYSTEM_LIBS=""boringssl""` flag as a default option for Bazel during the configuration stage on s390x. After applying the above change, the following test cases would pass on s390x:  Fixes https://github.com/tensorflow/tensorflow/issues/51770 .",2023-03-31T14:56:16Z,ready to pull size:S,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60189,Thanks  !,Looks like the following error shown in the PR checking logs wasn't caused by the code change in this PR:    Could you please help me check the status of this PR? Please let me know if there is any change I should make at my end. Thank you very much!,"Hi  , Could you please help me check the status of this PR? Thank you very much!","> Hi  , >  > Could you please help me check the status of this PR? >  > Thank you very much! Hi lu20 This PR is processing internally. Thank you so much!", Thanks for checking!
665,"以下是一个github上的tensorflow下的一个issue, 标题是(Tflite benchmark app build issues)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution macos  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mescoulan-gpsw,Tflite benchmark app build issues,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution macos  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-31T14:28:44Z,stat:awaiting response type:bug type:build/install stale comp:lite subtype:macOS TF 2.8,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60188,Hi gpsw Thanks for reporting the issue. I was able to successfully build the benchmark model with r2.12 version on MacOS with Bazel 5.3.0 as per the instructions given here. Please find the screenshot below.  The `configure` options are given for your reference.  Can you try you using r2.12 and using this and let us know if the issue still exists? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hello  , sorry for late reply. By using r2.12, bazel 5.3.0 and the exact same configure options as you I was able to build successfully. Thank you !"
664,"以下是一个github上的tensorflow下的一个issue, 标题是(Linker Errors while building tensorflow from source)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.7  Bazel version 6.1.1  GCC/Compiler version LLVM 12  CUDA/cuDNN version 11, 8  GPU model and memory T4  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,p3achyjr,Linker Errors while building tensorflow from source,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.7  Bazel version 6.1.1  GCC/Compiler version LLVM 12  CUDA/cuDNN version 11, 8  GPU model and memory T4  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-03-31T07:10:47Z,stat:awaiting response type:bug type:build/install stale subtype: ubuntu/linux TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60184,"I should mention that I am using my own toolchain, but is it essentially just clang. Code here: https://github.com/p3achyjr/p3achyGo/blob/main/toolchain/BUILD I noticed that the generated CUDA toolchain file adds CUDA include paths, whereas I just add c/c++ include paths. Could this have something to do with it? At any rate, is there a principled way to include tensorflow in a bazel project without building the entire thing statically every time? It's very hard to know which target to build just from perusing the source code (do I use `:tensorflow_cc`? `:tensorflow_framework`? Do I define my own `transitive_hdrs` rule?)","  Sorry for the late reply, As per the documentation, TF v2.11.0 requires 8.1 cuDNN and 11.2 CUDA version.Could you please make sure to follow the instructions mentioned here and check the tested build configuration as well. Please let us know if it helps? Thank you!","I tried using gcc 8 and gcc 9 today, and both failed. gcc8 gave the standard ""lld undefined symbol"". gcc failed much more catastrophicallyIt says the following command failed.  When I run this by hand, it spits out tons of linker errors, such as:  Maybe you could take a look at how I've setup the build? I don't know if I'm using it right. https://github.com/p3achyjr/p3achyGo/blob/main/cc/nn/BUILD"," , Could you please confirm are you using the TF standard Build instructions mentioned here. Are you getting the error during `./configure` ? Can you provide exact commands you have used to replicate the reported error ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1905,"以下是一个github上的tensorflow下的一个issue, 标题是(How to evaluate a pretrained TF mobilenet_v2 saved_model for accuracy on test dataset)， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04    **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**:2.11    **Python version**: 3.9  Describe the problem How can i use a pretrained saved_model and find its accuracy on a test dataset? I have mobilenet_v2 saved model which is sourced from https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5 I have an imagenet validation dataset consisting of 50000 images, and a labels.txt file consisting of ground truth labels for those 50000 images.  I also have ImageNetLabels.txt sourced from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt consisting of 1001 imagenet classes.  How do I preprocess this data so that i can run evaluate() function to find test_data loss and accuracy of this pretrained model? I am currently using the below script, but it doesn't seem to work:  I get the below error here: > Traceback (most recent call last): >   File ""test1234.py"", line 74, in  >     loss, accuracy = m.evaluate(dataset) >   File ""/home/mtk/.local/lib/python3.8/sitepackages/keras/utils/traceback_utils.py"", line 70, in error_handler >     raise e.with_traceback(filtered_tb) from None >   File ""/tmp/__autograph_generated_filemqiwcebs.py"", line 15, in tf__test_function >     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope) > ValueError: in user code: >  >     File ""/home)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,suyash-narain,How to evaluate a pretrained TF mobilenet_v2 saved_model for accuracy on test dataset," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04    **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**:2.11    **Python version**: 3.9  Describe the problem How can i use a pretrained saved_model and find its accuracy on a test dataset? I have mobilenet_v2 saved model which is sourced from https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5 I have an imagenet validation dataset consisting of 50000 images, and a labels.txt file consisting of ground truth labels for those 50000 images.  I also have ImageNetLabels.txt sourced from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt consisting of 1001 imagenet classes.  How do I preprocess this data so that i can run evaluate() function to find test_data loss and accuracy of this pretrained model? I am currently using the below script, but it doesn't seem to work:  I get the below error here: > Traceback (most recent call last): >   File ""test1234.py"", line 74, in  >     loss, accuracy = m.evaluate(dataset) >   File ""/home/mtk/.local/lib/python3.8/sitepackages/keras/utils/traceback_utils.py"", line 70, in error_handler >     raise e.with_traceback(filtered_tb) from None >   File ""/tmp/__autograph_generated_filemqiwcebs.py"", line 15, in tf__test_function >     retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope) > ValueError: in user code: >  >     File ""/home",2023-03-31T00:51:24Z,stat:awaiting response type:support stale comp:apis TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60181,"it seems that the labels in the validation set are not in the correct format for the model's output. MobileNetV2 outputs a 1001dimensional vector, where each element represents the probability of the input image belonging to a specific class. The validation set labels are just integers representing the class index. To preprocess the data, you need to convert the labels to onehot vectors. You can use the tf.one_hot function for this purpose","> it seems that the labels in the validation set are not in the correct format for the model's output. MobileNetV2 outputs a 1001dimensional vector, where each element represents the probability of the input image belonging to a specific class. The validation set labels are just integers representing the class index. >  > To preprocess the data, you need to convert the labels to onehot vectors. You can use the tf.one_hot function for this purpose Hi    I was missing the onehot vectors and once I converted the labels to onehot, the error disappeared. But on evaluation, I was getting really bad accuracy on test data, to the tune of 0.1% accuracy on pretrained mobilenetv2 sourced from tfhub, which is totally incorrect.  for test data, I was using imagenet_val dataset consisting of 50000 images.   val.txt consists of 50000 ground truth labels for the imagenet_val dataset.  ImageNetLabels.txt was downloaded from  https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt  on using the below script:  i get the results as: > loss:  10.239829063415527 > accuracy:  0.0009599999757483602 am i missing something here? my val.txt and imagenetlabels.txt file are attached thanks val.txt ImageNetLabels.txt","issue might be with the evaluation process or the dataset suyash here is some possibilities>  make sure image is in correct format(JPEG)  check preprocess function working correctly  check if class_map dict map each class name to correct index you could print out dict and compare to ImageNetLabel.text if there any mismatch  Try evaluating the model on a smaller subset of the dataset (e.g. 100 images) to see if the accuracy improves. If it does, then the issue might be with the size of the dataset or the distribution of the classes  Finally, you could try retraining the model on the ImageNet dataset hope this helps you suyash On Fri, 31 Mar 2023 at 15:24, Suyash ***@***.***> wrote: > it seems that the labels in the validation set are not in the correct > format for the model's output. MobileNetV2 outputs a 1001dimensional > vector, where each element represents the probability of the input image > belonging to a specific class. The validation set labels are just integers > representing the class index. > > To preprocess the data, you need to convert the labels to onehot vectors. > You can use the tf.one_hot function for this purpose > > Hi   > I was missing the onehot vectors and once I converted the labels to > onehot, the error disappeared. But on evaluation, I was getting really bad > accuracy on test data, to the tune of 0.1% accuracy on pretrained > mobilenetv2 sourced from tfhub, which is totally incorrect. > >     for test data, I was using imagenet_val dataset consisting of 50000 >    images. >     val.txt consists of 50000 ground truth labels for the imagenet_val >    dataset. >     ImageNetLabels.txt was downloaded from >    https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt > > on using the below script: > > import tensorflow as tf > import tensorflow_hub as hub > import numpy as np > import os > > m = tf.keras.Sequential([hub.KerasLayer(""https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/4"", output_shape=(1001,))]) > m.build([None, 224, 224, 3])  Batch input shape. > > images = '/home/mtk/Downloads/ILSVRC2012_img_val/' > classes = '/home/mtk/Documents/tflite_models/imagenet_classes.txt' > labels ='/home/mtk/Documents/val.txt' > labels ={} > > with open(labels, 'r') as f: > 	label_name = [line.strip() for line in f.readlines()] > > class_map = {} > with open(classes, 'r') as f: > 	classes = [line.strip() for line in f] > 	for i, class_name in enumerate(classes): > 		class_map[class_name] = i > > test_labels=[] > for label in label_name: > 	if label in class_map: > 		test_labels.append(class_map[label]) > 	else: > 		print(f""label '{label} not found in class_map"") > > print(type(test_labels)) > test_labels = tf.one_hot(test_labels, 1001) > > image_paths = [os.path.join(images, filename) for filename in os.listdir(images)] > > dataset = tf.data.Dataset.from_tensor_slices((image_paths, test_labels)) > > def preprocess_image(image_path): > 	image = tf.io.read_file(image_path) > 	image = tf.image.decode_jpeg(image, channels=3) > 	image = tf.image.resize(image, [224,224]) > 	image = tf.image.convert_image_dtype(image, tf.float32) > 	image = tf.cast(image, tf.float32) / 255.0 > 	return image > > dataset = dataset.map(lambda image_path, label: (preprocess_image(image_path), label)) > dataset = dataset.batch(batch_size=32) > > model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) > loss, accuracy = model.evaluate(dataset) > > print('loss: ', loss) > print('accuracy: ', accuracy) > > i get the results as: > > loss: 10.239829063415527 > accuracy: 0.0009599999757483602 > > am i missing something here? > my val.txt and imagenetlabels.txt file are attached > > thanks > val.txt  > ImageNetLabels.txt >  > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you were mentioned.Message ID: > ***@***.***> >",narain Could you refer to the comment above and let us know if there is any update? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"> narain Could you refer to the comment above and let us know if there is any update? Thank you! Hi, , apologies for the late reply.  Is it possible for you to provide with a sample script on how to preprocess data from a subset of imagenet correctly? My current method took into consideration all the bullet points asked by you and yet my accuracy lies around 01%, which is surely incorrect. thanks ","narain Sorry for the late response! On subsets with fewer training images, the model needs to be trained for more epochs and the hyperparameters need to be adjusted as a requirement. This will give a better performance of the model. For preprocessing data from subset of imagenet kindly have a look at this article. I tried to replicate the issue reported here and faced a different error. Please find the gist and let me know if I am missing something here.   Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1048,"以下是一个github上的tensorflow下的一个issue, 标题是(Build failed `not all outputs were created or valid` on `darwin/amd64`)， 内容是 ( Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version faf4a8eb61d6344997e1860de30e6eae434b4411  Custom Code No  OS Platform and Distribution MacOS 13.3 (22E252) Apple M1 Pro  Mobile device N/A  Python version 3.11  Bazel version bazel 5.3.0  GCC/Compiler version Apple clang version 14.0.0 (clang1400.0.29.202)  CUDA/cuDNN version N/A  GPU model and memory 16GB RAM, no NVIDIA GPU  Current Behaviour?  Build logs   Expect no error  Standalone code to reproduce the issue 1. Prepare a computer with Mac M1 chip 2. Do `git clone https://github.com/tensorflow/tensorflow` 3. Install dependencies such as clang and bazel 4. Do `bazel build verbose_failures //tensorflow/tools/pip_package:build_pip_package`  Relevant log output *See above*)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,zyxkad,Build failed `not all outputs were created or valid` on `darwin/amd64`," Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version faf4a8eb61d6344997e1860de30e6eae434b4411  Custom Code No  OS Platform and Distribution MacOS 13.3 (22E252) Apple M1 Pro  Mobile device N/A  Python version 3.11  Bazel version bazel 5.3.0  GCC/Compiler version Apple clang version 14.0.0 (clang1400.0.29.202)  CUDA/cuDNN version N/A  GPU model and memory 16GB RAM, no NVIDIA GPU  Current Behaviour?  Build logs   Expect no error  Standalone code to reproduce the issue 1. Prepare a computer with Mac M1 chip 2. Do `git clone https://github.com/tensorflow/tensorflow` 3. Install dependencies such as clang and bazel 4. Do `bazel build verbose_failures //tensorflow/tools/pip_package:build_pip_package`  Relevant log output *See above*",2023-03-30T13:35:30Z,type:build/install subtype:macOS,closed,1,16,https://github.com/tensorflow/tensorflow/issues/60179,"A recent commit (https://github.com/tensorflow/tensorflow/commit/51a8992bb9daba2364ac4bb931af1010d554f0fa) used  nonstandard GNU `realpath relative`. Quick workaround is to use GNU realpath (in coreutils). On my mac, I used macport to  install realpath to `/opt/local/libexec/gnubin`, then add `/opt/local/libexec/gnubin` before `/usr/bin` when running bazel.","> A recent commit (51a8992) used nonstandard GNU `realpath relative`. Quick workaround is to use GNU realpath (in coreutils). On my mac, I used macport to install realpath to `/opt/local/libexec/gnubin`, then add `/opt/local/libexec/gnubin` before `/usr/bin` when running bazel. Can you give a more specific command to explain how to do it? I don't know how to install GNU realpath. Thanks very much.","> > A recent commit (51a8992) used nonstandard GNU `realpath relative`. Quick workaround is to use GNU realpath (in coreutils). On my mac, I used macport to install realpath to `/opt/local/libexec/gnubin`, then add `/opt/local/libexec/gnubin` before `/usr/bin` when running bazel. >  > Can you give a more specific command to explain how to do it? I don't know how to install GNU realpath. Thanks very much. I am a long time macports user, but I guess most people use homebrew, which I am not familiar. with For macports, I use `ports install coreutils` to install GNU realpath.","> For macports, I use `ports install coreutils` to install GNU realpath. For homebrew is the same command, just do `brew install coreutils` :)","After install that, I got new error: ","Well, actually, it's an ""old"" linker error, see, https://github.com/tensorflow/tensorflow/issues/58368 > After install that, I got new error: >  > ","> Well, actually, it's an ""old"" linker error, see, CC(TF 2.11.0/2.12 fails to build in MacOS 13   XCode 14.1  issue with ld linker) The new version of `XCode 14.3` include an updated version of the linker `ld` which fixes the original issue https://github.com/tensorflow/tensorflow/issues/58368. Unless there are other issues unrelated to the linker bug, this issue is resolved as well, and if so, this bug report should be closed.","Hi  , I have replicated the reported error. ","The build fails with clang 14.0.0.   , Could you please try with XCode 14.3 version as mentioned in **comment1492839793** and confirm if still a problem with it.","> The new version of `XCode 14.3` include an updated version of the linker `ld` which fixes the original issue CC(TF 2.11.0/2.12 fails to build in MacOS 13   XCode 14.1  issue with ld linker). Unless there are other issues unrelated to the linker bug, this issue is resolved as well, and if so, this bug report should be closed. No, my issue is if I don't install `realpath`, then the build will falid. I'm not sure is that solved?","I have a event later for an hour, so I will test after that",Build successed! :),Are you satisfied with the resolution of your issue? Yes No," , Thanks for the update and we are glad that your issue resolved. Please confirm whether upgrading XCode version worked for you or any other hacks so that it will help the larger community who visit this ticket. Thanks!",Solved environment: Commit: 55939be39409283c4b35a62049fe548a2de3ce44 **XCode: 14.3** **clang**  **bazel 5.3.0**," Hello, building `TensorFlow 2.13` on my Apple M1 also encountered the same issue. Could you confirm if you were able to build it successfully with just the command `brew install coreutils`, without any other modifications?"
730,"以下是一个github上的tensorflow下的一个issue, 标题是(Building TF from source instructions clarification wrt Python packages)， 内容是 (Click to expand!    Issue Type Documentation Feature Request  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version TF 2.11  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,freddan80,Building TF from source instructions clarification wrt Python packages,Click to expand!    Issue Type Documentation Feature Request  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version TF 2.11  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-30T10:39:22Z,type:feature type:build/install type:docs-feature,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60175,", Could you please confirm whether you are facing the issue with protobuf  3.19.4 or protobuf  3.20.3? Also there is an issue which was already raised for the similar issue CC(//tensorflow/python/util/protobuf:protobuf_compare_test fails with protobuf > 3.20.3) which was already assigned to the developer for the investigation. Thank you!",Hi   protobuf                     3.19.4 => doesn't work protobuf                     3.20.3 => works,"Hi  , The requirements for building the pippackage are listed in setup.py under `REQUIRED_PACKAGES` which is located here. Even documentation also having a note mentioned. Please refer below snapshot of same.  Thanks!","Thx. I was hoping for a `requirements.txt` with all musthave dependencies listed, it's just simple and unambiguous. Anyways, `setup.py` has the protobuf issues listed, so they're being worked on. I'll check back next time I need to build from source to see if I run into an issue. Feel free to close this ticket in the meanwhile."," , Closing the issue as per confirmation. Please feel free to open new ticket if you have any problems in your future builds. Thanks!",Are you satisfied with the resolution of your issue? Yes No
761,"以下是一个github上的tensorflow下的一个issue, 标题是(JVP using tf.autodiff.ForwardAccumulator becomes None under graph execution)， 内容是 (I'm new to Tensorflow. I'm trying to compute a JacobianVector Product using tf.autodiff.ForwardAccumulator with a train function looks something like the code below. The jvp looks fine under eager execution. However, the jvp becomes a list of Nones when activate graph execution using .function.  What could be the issue here?  Tensorflow Version tf 2.6.0  Python version 3.7  Train code  grad1 and grad2 are correctly computed under both eager mode and graph mode. The only problem is with the jvp.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,LeeroyClaim,JVP using tf.autodiff.ForwardAccumulator becomes None under graph execution,"I'm new to Tensorflow. I'm trying to compute a JacobianVector Product using tf.autodiff.ForwardAccumulator with a train function looks something like the code below. The jvp looks fine under eager execution. However, the jvp becomes a list of Nones when activate graph execution using .function.  What could be the issue here?  Tensorflow Version tf 2.6.0  Python version 3.7  Train code  grad1 and grad2 are correctly computed under both eager mode and graph mode. The only problem is with the jvp.",2023-03-29T14:59:40Z,type:support comp:autograph 2.6.0,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60164,"When using **tf.autodiff.ForwardAccumulator** with **.function**, the forwardpass is executed during tracing, which means that the **ForwardAccumulator** instance is not being executed during the graph execution. To fix this, you can wrap the **ForwardAccumulator** instance with **tf.custom_gradient**. ","> When using **tf.autodiff.ForwardAccumulator** with **.function**, the forwardpass is executed during tracing, which means that the **ForwardAccumulator** instance is not being executed during the graph execution. To fix this, you can wrap the **ForwardAccumulator** instance with **tf.custom_gradient**. >  >  Thank you so much for replying. I managed to get the code to work under eager mode using the following code, yet when I turn on graph mode using .function I got ""ValueError: Tried to convert 'input' to a tensor and failed. Error: None values not supported."". I guess it is because ""grad1"" is None when first building the graph. Is there something I can do? ", you can try explicitly converting your input to a **tf.Tensor** before computing the gradients. You can also try setting a default value for **grad1** in case it is not being computed properly,>  Turns out the error comes from somewhere else in my loss function. The code is all good now. Much thanks.,Are you satisfied with the resolution of your issue? Yes No
403,"以下是一个github上的tensorflow下的一个issue, 标题是([oneDNN] Enabling optimized implementation for FP32 Eigen Leakyrelu)， 内容是 (This PR enables the optimized implementation for FP32 using the new Eigen LeakyRelu functor leading to approximately 55% performance gain on average.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,othakkar,[oneDNN] Enabling optimized implementation for FP32 Eigen Leakyrelu,This PR enables the optimized implementation for FP32 using the new Eigen LeakyRelu functor leading to approximately 55% performance gain on average.,2023-03-29T00:50:08Z,awaiting review ready to pull size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60155,   Benchmark  1.127747369  
717,"以下是一个github上的tensorflow下的一个issue, 标题是(Correct way to implement RNN if looping over tensor is yet not allowed)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution MaxOS 12.3.1   Mobile device   Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory M1 Max 26 cores GPU 32 GB ram  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AlbertoSinigaglia,Correct way to implement RNN if looping over tensor is yet not allowed,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution MaxOS 12.3.1   Mobile device   Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory M1 Max 26 cores GPU 32 GB ram  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-28T19:51:01Z,type:support,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60153,"**use **tf.cond** to conditionally execute the loop based on the input length** In the code, the for loop is iterating over a **tf.Tensor** object created by **tf.range(tf.shape(inputs)[1])**. This tensor has a symbolic shape, which means that its size is not known until runtime. TensorFlow's AutoGraph cannot handle iterating over such symbolic tensors, as it requires knowing the size of the tensor at graph construction time.   OUTPUT ","thank you so much, finally I was able to do it with your hint... please consider adding more examples in the docs for `tf.while_loop`, in order to make it work I had to fight for a while with `shape_invariants` and what to do if I want more than one input for the body of the loop... Also, I would like to ask what should I use in the `shape_invariants` if I have a list of vector (say for example the state of a LSTM, which is [h_state, m_state]) Anyway, thank you so much"," It's my pleasure to help. If you have a list of vectors as the state of a LSTM in TensorFlow, you can use a tuple of TensorShape objects in the **shape_invariants** argument of the **tf.function** decorator to specify the shape of each vector.","  that makes total sense, thank you so much",Are you satisfied with the resolution of your issue? Yes No
716,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.data.Dataset.from_generator crashes with abortion)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230208  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,trickiwoo,tf.data.Dataset.from_generator crashes with abortion,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230208  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-28T17:06:53Z,stat:awaiting response type:bug stale comp:data TF 2.12,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60149,"Tensorflow Version 2.13.0dev20230208 python 3.8 version OS : WSL CUDA/cuDNN version 12.0/8.8.1.3 Nvidia RTX 2060 (6GB) import tensorflow as tf import numpy as np ds = tf.data.Dataset.from_tensors([1]).repeat(1) def gen():   for _ in ds:     yield _ ds = tf.data.Dataset.from_generator(     gen, output_types=tf.int32) list(ds.take(2).as_numpy_iterator()) Relevant log output Your kernel may have been built without NUMA support. 20230331 22:33:41.003743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3854 MB memory:  > device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5   There is no error with your code.  import tensorflow as tf print(""TensorFlow Nightly version:"", tf.__version__) TensorFlow Nightly version: 2.13.0dev20230331","   As per  documentation of tf.data.Dataset.repeat ""`The default behavior (if count is None or 1) is for the dataset to be repeated indefinitely`"". I was able to execute the given code with a positive value. please find the gist here for reference. Thank you!"," Thanks for the reference. This bug does only exists with `repeat(1)`. In my understanding, crashes like this seem to be a vulnerability according to https://github.com/tensorflow/tensorflow/issues/60121issuecomment1485230826, so I have also reported this bug to the Google OSS VRP program."," I tried and can still reproduce this bug in `2.13.0dev20230402` locally and on Colab, can you try again on Colab?", I ran the previous code on a jupyter kernel in a window subsystem for Linux. I would try colab ," , Our team is looking into it Google OSS VRP program and will get back to you. Thanks for reporting.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. I tried some alternative solutions, and they worked fine for me. I hope this will be useful for you. I am providing the gist here for your reference. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1842,"以下是一个github上的tensorflow下的一个issue, 标题是(ImportError: Traceback)， 内容是 (I have this error after installing Tensorflow, when I try to import it. ImportError                               Traceback (most recent call last) File ~\anaconda3\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:62      61 try: > 62   from tensorflow.python._pywrap_tensorflow_internal import *      63  This try catch logic is because there is no bazel equivalent for py_extension.      64  Externally in opensource we must enable exceptions to load the shared object      65  by exposing the PyInit symbols with pybind. This error will only be      66  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      67       68  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Routine di inizializzazione della libreria di collegamento dinamico (DLL) non riuscita. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[1], line 1 > 1 import tensorflow as tf File ~\anaconda3\lib\sitepackages\tensorflow\__init__.py:37      34 import sys as _sys      35 import typing as _typing > 37 from tensorflow.python.tools import module_util as _module_util      38 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader      40  Make sure code inside the TensorFlow codebase can use tf2.enabled() at import. File ~\anaconda3\lib\sitepackages\tensorflow\python\__init__.py:36      27 import traceback      29  We aim to keep this file minimal and ideally remove completely.      30  If you a)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Giamy98,ImportError: Traceback,"I have this error after installing Tensorflow, when I try to import it. ImportError                               Traceback (most recent call last) File ~\anaconda3\lib\sitepackages\tensorflow\python\pywrap_tensorflow.py:62      61 try: > 62   from tensorflow.python._pywrap_tensorflow_internal import *      63  This try catch logic is because there is no bazel equivalent for py_extension.      64  Externally in opensource we must enable exceptions to load the shared object      65  by exposing the PyInit symbols with pybind. This error will only be      66  caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.      67       68  This logic is used in other internal projects using py_extension. ImportError: DLL load failed while importing _pywrap_tensorflow_internal: Routine di inizializzazione della libreria di collegamento dinamico (DLL) non riuscita. During handling of the above exception, another exception occurred: ImportError                               Traceback (most recent call last) Cell In[1], line 1 > 1 import tensorflow as tf File ~\anaconda3\lib\sitepackages\tensorflow\__init__.py:37      34 import sys as _sys      35 import typing as _typing > 37 from tensorflow.python.tools import module_util as _module_util      38 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader      40  Make sure code inside the TensorFlow codebase can use tf2.enabled() at import. File ~\anaconda3\lib\sitepackages\tensorflow\python\__init__.py:36      27 import traceback      29  We aim to keep this file minimal and ideally remove completely.      30  If you a",2023-03-28T11:27:53Z,type:build/install stale,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60141,"  We see that the issue template has not been filled, could you please do so as it helps us analyze the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced] and Could you please make sure to follow the instructions mentioned here and check the tested build configuration as well. Please let us know if it helps?  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Commenting to keep this issue active. I am also facing the same issue when i try importing some modules from tensor on my local machine (visual studio code),"  we are waiting for more details from the user who raises the issue. For further assistance, Could you please raise the new issue here with the required details. Thank you !",Closing this as stale. Please reopen if this is still a valid request. Thank you!,Are you satisfied with the resolution of your issue? Yes No
712,"以下是一个github上的tensorflow下的一个issue, 标题是(Internal error on Attention over LSTM with ragged input)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04 LTS on Windows WSL2  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.7/8.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,diogoff,Internal error on Attention over LSTM with ragged input,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04 LTS on Windows WSL2  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.7/8.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-28T10:56:09Z,stat:awaiting response type:bug comp:keras wsl2 TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60140,"Hi , I was able to replicate the issue in Colab using TF v2.1. Please find the gist here. As a workaround, if you don't want to keep the output of the LSTM layer at each timestep, you can set `return_sequences=False` in the LSTM layer, it will output only the last hidden state of the LSTM layer, which is a fixedsize vector.  Kindly refer to the gist of working code here. Thank you!","For my application, I need to keep the outputs of the LSTM at each time step. Also, note that with `return_sequences=False` the output shape does not appear to conform to the input shapes required for Attention:  query tensor of shape `[batch_size, Tq, dim]`  value tensor of shape `[batch_size, Tv, dim]` Finally, note that it runs fine if we skip the LSTM layer. In this case, we are providing all the timesteps to Attention. So I don't see a reason why it shouldn't work after the LSTM as well.","Hi  , The `keras.layers.Attention` layer supposed to be used with Dense or CNN networks but not for RNN networks. For source please refer the source code below.Attention class subclasses the `BaseDenseAttention` class. https://github.com/kerasteam/keras/blob/f9336cc5114b4a9429a242deb264b707379646b7/keras/layers/attention/attention.pyL30L31 And the build method of the attention class calls `super().build(input_shape)` as per source below. https://github.com/kerasteam/keras/blob/f9336cc5114b4a9429a242deb264b707379646b7/keras/layers/attention/attention.pyL169 From the `BaseDenseAttention` class there is a note saying this would be used for CNN or Dense but not for RNN. https://github.com/kerasteam/keras/blob/f9336cc5114b4a9429a242deb264b707379646b7/keras/layers/attention/base_dense_attention.pyL32L36 Is that make sense for why we are getting the error ? Please check and come back. Thanks!","Although I confirm what you say, I don't think the problem has to do with RNN vs. CNN. I think the problem has to do with ragged vs. nonragged input. To show this, I've prepared this sample code:  This runs without issue. So why shouldn't it run with ragged input?","Hi  , Thanks for pointing the Ragged Tensor Input. The error is arising from calculating gradients for a Ragged Tensor on GPU device. This support is not enabled yet which is still under development stage. Please refer to the code below.The Op is enabled for CPU only now. https://github.com/tensorflow/tensorflow/blob/25ab98cf17d86a1e2d6fb0c8172f2c8a9ecde110/tensorflow/core/kernels/ragged_tensor_to_variant_op.ccL343L354 Workaround is to use CPU runtime when used Ragged tensor within a model. With CPU only runtime the code executes fine.Please refer the attached gist.",Are you satisfied with the resolution of your issue? Yes No
1354,"以下是一个github上的tensorflow下的一个issue, 标题是(The Windows MSVC to clang migration linker issue)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12  Custom Code No  OS Platform and Distribution Microsoft Windows Server 2019 Datacenter  Mobile device _No response_  Python version Python 3.10  Bazel version 5.3.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  Background We have switch the TensorFlow compilation from MSVC to clangcl and resolved two compile errors. The compilation is complete but there is a link issue before we can complete package TensorFlow to wheel.  How to reproduce 1. Fix the const expression error     a. Add file to third_party\tf_runtime_clangcl.patch with content       b. Update workspace file at third_party\tf_runtime\workspace.bzl at line 19.  2. Bypass the Google ABSL compilation error     a. Create file at third_party\absl\comd_google_absl_remove_static_assert.patch      b. Modify the file at third_party\absl\workspace.bzl at line 46   Standalone code to reproduce the issue  Build with command    Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shangerxin,The Windows MSVC to clang migration linker issue,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.12  Custom Code No  OS Platform and Distribution Microsoft Windows Server 2019 Datacenter  Mobile device _No response_  Python version Python 3.10  Bazel version 5.3.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  Background We have switch the TensorFlow compilation from MSVC to clangcl and resolved two compile errors. The compilation is complete but there is a link issue before we can complete package TensorFlow to wheel.  How to reproduce 1. Fix the const expression error     a. Add file to third_party\tf_runtime_clangcl.patch with content       b. Update workspace file at third_party\tf_runtime\workspace.bzl at line 19.  2. Bypass the Google ABSL compilation error     a. Create file at third_party\absl\comd_google_absl_remove_static_assert.patch      b. Modify the file at third_party\absl\workspace.bzl at line 46   Standalone code to reproduce the issue  Build with command    Relevant log output  ,2023-03-27T23:55:56Z,stat:awaiting response type:build/install stale subtype:windows TF 2.12 subtype:cpu-intel,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60136,"This specific issue is caused by `OpRegistrationData` type being defined as struct OpRegistrationData but declared in failing translation unit as class OpRegistrationData. Clang apparently makes the difference here (unlike msvc) and it can't find the symbol with ` class` attribute while it is defined only as `struct`.  Changing class OpRegistrationData to `struct OpRegistrationData` fixes this spcific issue,  and build passes further, but then fails on linking `_pywrap_internal` .dll on bfloat16.so symbols duplicate issue. Trying to fix that now.",OK. I will pull the latest code and verified on my end too. ,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1389,"以下是一个github上的tensorflow下的一个issue, 标题是(Make time series_from_array() more intuitive to use)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0 (Tensorflowmacos)  Custom Code Yes  OS Platform and Distribution MacOS 13.2.1  Mobile device _No response_  Python version 3.10.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? TimeseriesGenerator() is deprecated, and Tensorflow docs encourage the use of time series_from_array() instead. However, this is not intuitive to use, requiring far more boilerplate code to achieve the same effect. In addition, the results are not as expected. I spent hours debugging my code to realise time series_from_array() is not behaving as expected. Using the code below, I would expect there to be 6 different inputs and outputs, however, there are only 3. Running the same code with TimeseriesGenerator(), without the [:4] and [4:] indexing, produces the expected 6 inputs and outputs.  Standalone code to reproduce the issue   Relevant log output   Code for TimeseriesGenerator() (expected output)   Expected output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,James-Tipping,Make time series_from_array() more intuitive to use,"Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0 (Tensorflowmacos)  Custom Code Yes  OS Platform and Distribution MacOS 13.2.1  Mobile device _No response_  Python version 3.10.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? TimeseriesGenerator() is deprecated, and Tensorflow docs encourage the use of time series_from_array() instead. However, this is not intuitive to use, requiring far more boilerplate code to achieve the same effect. In addition, the results are not as expected. I spent hours debugging my code to realise time series_from_array() is not behaving as expected. Using the code below, I would expect there to be 6 different inputs and outputs, however, there are only 3. Running the same code with TimeseriesGenerator(), without the [:4] and [4:] indexing, produces the expected 6 inputs and outputs.  Standalone code to reproduce the issue   Relevant log output   Code for TimeseriesGenerator() (expected output)   Expected output  ",2023-03-27T22:59:29Z,stat:awaiting response type:feature stale comp:keras subtype:macOS TF 2.10,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60135,"Hi Tipping , The API is working as intended.  Suppose for below code:  Here data is x[:4] means data of 6 Rows and 3 columns. With `sequence_length=4` and default `sequence_stride=1`  and  `sampling_rate=1` we can get 3 data points (64+1=3) and for these data points the target indices are y[4:] i.e. starting from index4 to next 3 i.e. upto index6 which are `[5,6,7]` respectively. Hence the first data point will be:   and corresponding target point is `5`. I am not sure why you are expecting other result. Could you please explain what is misleading here ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi , thank you for your reply. The issue is that timeseries_dataset_from_array is touted as a replacement for TimeseriesGenerator, when in fact they have different outputs. In fact, I would argue the output from TimeseriesGenerator is the expected result. Looking above at my examples, it is clear in this case that I require 6 different outputs, and not 3 outputs. Take the example of someone predicting stock market closing values. If we have data points for 120 days, and we want to use the previous 30 days as input, it's intuitive that there would be 90 (120  30) input sets, and 90 output sets of data. This isn't the case with timeseries_dataset_from_array. I came across this by following the (very well written) documentation for timeseries_dataset_from_array, as it was recommended instead of TimeseriesGenerator. Thus, either the documentation could be changed to reflect that they do not produce the same results, or the implementation could be changed. Please feel free to correct me if I'm misunderstanding.","Hi Tipping , There is implementation differences between `timeseries_dataset_from_array` and `TimeseriesGenerator` APIs.  From `timeseries_dataset_from_array` API , the `targets` should be: targets   This means we need to supply the data of same length corresponding to input timesteps. Consider this example code below:  With the API `timeseries_dataset_from_array` we have more flexibility than that of `TimeseriesGenerator`. Hence `timeseries_dataset_from_array` not exactly same copy as `TimeseriesGenerator` but with some more additional flexibility. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
559,"以下是一个github上的tensorflow下的一个issue, 标题是(Memory leak in forward pass (e.g., of ResNet50 model) with TensorFlow 2.12.0 and Python 3.11)， 内容是 (The following minimal example reproduces the memory leak I ran into. (No GPU, just CPU.) `memleak.py`:  `Dockerfile`:  Output (`docker build rm .`):  When using the same TensorFlow version (`2.12.0`) but with Python `3.10.10` (instead of `3.11.2`), the memory usage does not grow.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Dobiasd,"Memory leak in forward pass (e.g., of ResNet50 model) with TensorFlow 2.12.0 and Python 3.11","The following minimal example reproduces the memory leak I ran into. (No GPU, just CPU.) `memleak.py`:  `Dockerfile`:  Output (`docker build rm .`):  When using the same TensorFlow version (`2.12.0`) but with Python `3.10.10` (instead of `3.11.2`), the memory usage does not grow.",2023-03-27T15:36:35Z,stat:awaiting response type:bug comp:keras TF 2.12,closed,4,21,https://github.com/tensorflow/tensorflow/issues/60131,Have you tried using ResNet50V2 I got a similar issue when I ran your code but when I tried it with ResNet50V2 I did not get a memory leak  ,"I just tested with `ResNet50V2`, and I get the memory leak there too: https://gist.github.com/Dobiasd/d2cabf576e1dd518610a2387b7772ecd Did you use the provided `Dockerfile` to make sure you have the same versions of Python and TensorFlow?","yeah my version of TensorFlow was wrong I was using the most up to date version from source, with the docker file I get the memory leak with ResNet50V2 as well",Hi! Thank you for sharing! Could you help us out by running a bisect using your dockerfile?  You can use the nightly releases to pinpoint the version where it first appears. That alone should narrow it down a lot. But if you can identify the commit too that would be great!, Could you please refer to the comment above and update on the same? Thank you!,"I just tried to (available versions of `tfnightly` shown by `pip`, `2.12.0.dev20230105` being the oldest one), but some versions throw an error right from the beginning. Here are my results (focusing on the transitions where something changes):  `2.12.0.dev20230105`: error  `2.12.0.dev20230127`: error  `2.12.0.dev20230201`: memleak  `2.12.0.dev20230203`: memleak  `2.13.0.dev20230206`: error  `2.13.0.dev20230405`: memleak So I did not find the version that introduced the memleak, because it looks like it was introduced before the earliest version, which can be tested that way. For further attempts, feel free to use the code, I provided, on your own. :wink:",I have replicated the issue on Colab also with tfnightly version and with python 3.9.16. Please refer the attached gist for details.,Yea I raised this issue a long time ago. `model.predict` has memory leak in more recent version of Tensorflow. It still open. It stopped us from upgrading TF on our production backend. https://github.com/tensorflow/tensorflow/issues/58676,"cc:  ,  ",See also CC(tf.random.normal() causes RAM usage to keep growing),Any news on this ? The issue is still present in tfnighly and not specific to keras `Dockerfile`  `memleak.py`: ,I ran `memray` against the same python script in 3.10 and 3.11   The memory flamegraphs look quite different py310 https://drive.google.com/file/d/1zLqk2jRJqnc9l_ZRwWuN_VU6SL82gc/view?usp=drive_link py311 https://drive.google.com/file/d/1USJ9f5rkoza_wAnTG5iig1Bf2zuF03Da/view?usp=drive_link,"Hi  , This got fixed. I have checked the code with latest Tf versions TF2.15( with python3.11v) and tfnightly(with python3.10) and no memory leak observed now. Please refer attached gist. Could you please verify and confirm. Thanks!","Just tested changing `tensorflow==2.12.0` to `tensorflow==2.15.0.post1` (the latest TF 2.15) in my original example, and the memory leak still exists: https://gist.github.com/Dobiasd/e1a5bd31378a92b690388bb62dffbcee Can you reproduce it? (maybe try to do it not in a Jupyter Notebook, but with Docker as in my example)"," In your gist you're not actually running against a python3.11 kernel, simply print `sys.version` to check... It seems that there's no easy way to install python3.11 in colab except for something like https://colab.research.google.com/drive/13C50iNZRjMRyepe_3xAtMKUQdIkKK0kS",For an additional data point I ran the above gist with python 3.11.8 and tensorflow 2.16.1 with the following results. Memory usage after 100 run(s) (in MiB): 867.309 Memory usage after 200 run(s) (in MiB): 893.266 Memory usage after 300 run(s) (in MiB): 872.895 Memory usage after 400 run(s) (in MiB): 898.473 Memory usage after 500 run(s) (in MiB): 884.656 Memory usage after 600 run(s) (in MiB): 900.805 Memory usage after 700 run(s) (in MiB): 905.102 Memory usage after 800 run(s) (in MiB): 915.559 Memory usage after 900 run(s) (in MiB): 947.211 Memory usage after 1000 run(s) (in MiB): 942.445 Memory usage after 1100 run(s) (in MiB): 967.773 Memory usage after 1200 run(s) (in MiB): 993.973 Memory usage after 1300 run(s) (in MiB): 983.297 Memory usage after 1400 run(s) (in MiB): 977.977 Memory usage after 1500 run(s) (in MiB): 988.398 Memory usage after 1600 run(s) (in MiB): 998.324 Memory usage after 1700 run(s) (in MiB): 1033.254 Memory usage after 1800 run(s) (in MiB): 1028.336 Memory usage after 1900 run(s) (in MiB): 1047.902 Memory usage after 2000 run(s) (in MiB): 1039.895 I also tested python 3.11.8 and tensorflow 2.13.1 & tensorflow 2.15.1 both versions also have the memory leak.,For others running into this issue I tested predict_on_batch approach instead of using the __call__ method and the memory leak is not present.  Memory usage after 100 run(s) (in MiB): 962.145 Memory usage after 200 run(s) (in MiB): 981.012 Memory usage after 300 run(s) (in MiB): 981.910 Memory usage after 400 run(s) (in MiB): 981.195 Memory usage after 500 run(s) (in MiB): 976.898 Memory usage after 600 run(s) (in MiB): 980.027 Memory usage after 700 run(s) (in MiB): 971.473 Memory usage after 800 run(s) (in MiB): 973.348 Memory usage after 900 run(s) (in MiB): 977.871 Memory usage after 1000 run(s) (in MiB): 981.832 Memory usage after 1100 run(s) (in MiB): 982.309 Memory usage after 1200 run(s) (in MiB): 982.062 Memory usage after 1300 run(s) (in MiB): 984.105 Memory usage after 1400 run(s) (in MiB): 798.184 Memory usage after 1500 run(s) (in MiB): 800.445 Memory usage after 1600 run(s) (in MiB): 799.742 Memory usage after 1700 run(s) (in MiB): 801.027 Memory usage after 1800 run(s) (in MiB): 802.859 Memory usage after 1900 run(s) (in MiB): 801.484 Memory usage after 2000 run(s) (in MiB): 802.805 This test was run with python 3.11.8 and tensorflow 2.13.1,", Could you please confirm, whether this is the same issue where we are tracking in the kerasteam/Keras repo. https://github.com/kerasteam/keras/issues/19500 Please correct me if I understand the right. Thank you","Yes, the two issues are similar. The difference is, that in this one here, opened in 202303, the memory usage leaked slowly but steadily. In the other one, opened in 202404, the memory grows very quickly immediately and then stays somewhat constant.",", Could you please follow that latest issue for the updates, as this is the older one ,please feel free to move this issue to the closed status. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1866,"以下是一个github上的tensorflow下的一个issue, 标题是(Build failure - stablehlo ""File name too long"")， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git 1dce1ddd62b4d9f7434bffa347defe0ad286bfab Mar 26  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04.2 LTS  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   shell Clone official TF repo at 1dce1ddd62b4d9f7434bffa347defe0ad286bfab (Mar 26): Use default configure: $ bazel build //tensorflow/tools/pip_package:build_pip_package  g++ (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0 Copyright (C) 2021 Free Software Foundation, Inc. This is free software; see the source for copying conditions.  There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. udaygpulaptop:~/csa/courses/e0255/2023/e0255asst2/tensorflow$ bazel build //tensorflow/tools/pip_package:build_pip_package INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=146 INFO: Reading rc options for 'build' from /home/uday/csa/courses/e0255/2023/e0255asst2/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /home/uday/csa/courses/e0255/2023/e0255asst2/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_s)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,bondhugula,"Build failure - stablehlo ""File name too long""","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git 1dce1ddd62b4d9f7434bffa347defe0ad286bfab Mar 26  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04.2 LTS  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   shell Clone official TF repo at 1dce1ddd62b4d9f7434bffa347defe0ad286bfab (Mar 26): Use default configure: $ bazel build //tensorflow/tools/pip_package:build_pip_package  g++ (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0 Copyright (C) 2021 Free Software Foundation, Inc. This is free software; see the source for copying conditions.  There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. udaygpulaptop:~/csa/courses/e0255/2023/e0255asst2/tensorflow$ bazel build //tensorflow/tools/pip_package:build_pip_package INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=146 INFO: Reading rc options for 'build' from /home/uday/csa/courses/e0255/2023/e0255asst2/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /home/uday/csa/courses/e0255/2023/e0255asst2/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_s",2023-03-27T04:56:52Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.12,closed,0,18,https://github.com/tensorflow/tensorflow/issues/60126,CC: eph ,`/home/uday/.cache/bazel/_bazel_uday/77f8878d03275bdd27457b5be533415a/external/stablehlo/temp12753699981416543916: /home/uday/.cache/bazel/_bazel_uday/77f8878d03275bdd27457b5be533415a/external/stablehlo/stablehlo/testdata/vmap_dot_general_batch_dimensions_lhs_float32_8_4_3_3_4__rhs_float32_4_8_3_4_2__dimensionnumbers____4_3___3_2_____0_1___1_0_dynamic.mlir.0_9_0.bc`  ,"Hi folks! Thank you for reporting  we'll look into this shortly. In the meanwhile, do you happen to know what's the maximum filename length expected here? `/home/uday/.cache/bazel/_bazel_uday/77f8878d03275bdd27457b5be533415a/external/stablehlo/stablehlo/testdata/vmap_dot_general_batch_dimensions_lhs_float32_8_4_3_3_4__rhs_float32_4_8_3_4_2__dimensionnumbers____4_3___3_2_____0_1___1_0_dynamic.mlir.0_9_0.bc` is 252 characters long, and I'm not currently sure if this limit is imposed by Bazel, by Java or by something else.","> Hi folks! Thank you for reporting  we'll look into this shortly. >  > In the meanwhile, do you happen to know what's the maximum filename length expected here? `/home/uday/.cache/bazel/_bazel_uday/77f8878d03275bdd27457b5be533415a/external/stablehlo/stablehlo/testdata/vmap_dot_general_batch_dimensions_lhs_float32_8_4_3_3_4__rhs_float32_4_8_3_4_2__dimensionnumbers____4_3___3_2_____0_1___1_0_dynamic.mlir.0_9_0.bc` is 252 characters long, and I'm not currently sure if this limit is imposed by Bazel, by Java or by something else. Although Java is reporting this via an exception, I think it's the OS file system that's imposing the limit  it might be the 255 byte limit (see https://en.wikipedia.org/wiki/Ext4) that this is exceeding. Can you go with `dims` instead of `dimensions` everywhere in that? I don't know if that'll provide a guarantee though.","I've tried to reproduce this on my machine which has the same version of Bazel and of Python, although it runs a different distribution of Linux (gLinux rather than Ubuntu  not sure if that matters  although my filesystem is ext4, the same as yours) and unfortunately wasn't able to reproduce the issue. Fwiw the equivalent path to the problematic file in the Bazel cache on my machine has 275 characters in it, and it seems to work properly. (My home directory is located elsewhere, and the path to that is longer than `/home/$USER`). Can you tell more about the problem that you're encountering? Did it start happening only recently? Is there anything that could be unusual about the environment, or it's pretty much a stock configuration? By the way, I'm open to abbreviating the filenames as needed, but would like to debug this a bit further, so that we get this right the first time and make sure this doesn't happen again.","> I've tried to reproduce this on my machine which has the same version of Bazel and of Python, although it runs a different distribution of Linux (gLinux rather than Ubuntu  not sure if that matters  although my filesystem is ext4, the same as yours) and unfortunately wasn't able to reproduce the issue. >  > Fwiw the equivalent path to the problematic file in the Bazel cache on my machine has 275 characters in it, and it seems to work properly. (My home directory is located elsewhere, and the path to that is longer than `/home/$USER`). >  > Can you tell more about the problem that you're encountering? Did it start happening only recently? Is there anything that could be unusual about the environment, or it's pretty much a stock configuration? >  > By the way, I'm open to abbreviating the filenames as needed, but would like to debug this a bit further, so that we get this right the first time and make sure this doesn't happen again. Even I wasn't able to reproduce this on another Ubuntu 22.04 LTS  so, it looks like there was something different with that environment or the file system configuration. I'll be able to post more details tomorrow.",I'd like to help work on this issue., Thank you for your offer to help! Can you try to reproduce this issue? This is currently an open question  how to reproduce and minimize the bug (because the most straightforward approach of cloning the repo and running Bazel works fine).,"Just on a related note, I've been trying to build OpenXLA (outside of tensorflow), who also depends on `stablehlo`, and see the same problem during my build:  I'm compiling it using a vanilla `tensorflow/tensorflow:develgpu` docker, with the exception that I upgraded Bazel to 6.1.1 (likely unrelated).","I crossposted the issue in `openxla/stablehlo` repository, in https://github.com/openxla/stablehlo/issues/1364. Also I checked the largest files are 142 chars in length, and using zip from the command line they extract normally. It could be an indication of an issue with the Java class doing this (?? I have no idea what goes inside bazel)","I ran into the same issue, the filename length is 146 char, which is larger than what cryptfs supports (143 chars). This fs is used at least by some linux distros when using an encrypted home directory. A simple workaround is to symlink $HOME/.cache/bazel to a directory on a standard ext4 partition, tensorflow should then build correctly.","Thanks, yes, I mentioned the same in the cross issue  https://github.com/openxla/stablehlo/issues/1364 (I notice I linked it wrong above, apologies). They suggest they are going to configure it to limit them to be shorter, but I did the same, I linked the source code directory to a directory in a plain (unenctrypted) ext4 partition, and it's been working fine.",This issue is indeed due to the file system not supporting file names of that length as  describes. I had ecryptfs on Ubuntu 22.04 for my home dir.  Having the bazel cache or the entire home dir on a typical ext4 or xfs will workaround the issue., fleiner The best suggestion I could give you is to try LONGPATHTOOL. It always helps me to resolve problems with path too long or filename too long. Thank you.,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1855,"以下是一个github上的tensorflow下的一个issue, 标题是(Build from source on Windows failed)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  TensorFlow installation (pip package or built from source): Built from cource  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11 and 2.12 both  2. Code bazel build config=opt //tensorflow/tools/pip_package:build_pip_package Link that i am following.  https://www.tensorflow.org/install/source_windows Steps i followed   1 Install Python and add path to enviornment variable , Python version 3.10.10 2 install additional package  pip3 install U six numpy wheel packaging pip3 install U keras_preprocessing nodeps 3 install bazel  version 5.3.0  path added to enviornment variable.  4 Install MSYS2  version  20230318 added usr/bin path to enviornment variable.  5 ran below command for aditional package  pacman S git patch unzip 6 Install Visual C++ Build Tools 2019 7 cloned tf library   git clone https://github.com/tensorflow/tensorflow.git cd tensorflow 8 run python ./configure.py with default setting 9 ran bazel  bazel build config=opt //tensorflow/tools/pip_package:build_pip_package and bazel run failed Error Message  D:\TFlite\tensorflow>bazel build config=opt //tensorflow/tools/pip_package:build_pip_package INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=211 INFO: Reading rc options for 'build' from d:\tflite\tensorflow\.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Options provided by the client:   'build' options: python_path=C:/Users/Nupur/AppData/Local/Microsoft/WindowsApps/python.exe INFO: Reading rc opt)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,MaheshwariAnkit,Build from source on Windows failed," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  TensorFlow installation (pip package or built from source): Built from cource  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11 and 2.12 both  2. Code bazel build config=opt //tensorflow/tools/pip_package:build_pip_package Link that i am following.  https://www.tensorflow.org/install/source_windows Steps i followed   1 Install Python and add path to enviornment variable , Python version 3.10.10 2 install additional package  pip3 install U six numpy wheel packaging pip3 install U keras_preprocessing nodeps 3 install bazel  version 5.3.0  path added to enviornment variable.  4 Install MSYS2  version  20230318 added usr/bin path to enviornment variable.  5 ran below command for aditional package  pacman S git patch unzip 6 Install Visual C++ Build Tools 2019 7 cloned tf library   git clone https://github.com/tensorflow/tensorflow.git cd tensorflow 8 run python ./configure.py with default setting 9 ran bazel  bazel build config=opt //tensorflow/tools/pip_package:build_pip_package and bazel run failed Error Message  D:\TFlite\tensorflow>bazel build config=opt //tensorflow/tools/pip_package:build_pip_package INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=211 INFO: Reading rc options for 'build' from d:\tflite\tensorflow\.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Options provided by the client:   'build' options: python_path=C:/Users/Nupur/AppData/Local/Microsoft/WindowsApps/python.exe INFO: Reading rc opt",2023-03-25T13:25:22Z,stat:awaiting response type:build/install stale subtype:windows TFLiteConverter TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60112,", I checked the error log and observed that the  **Python** library was not being detected which means the issue is with the path setting.  And also please make sure that all the required packages which was mentioned in the setup.py were installed before the bazel build. And while installing the bazel, please try to follow the mentioned steps. Could you please confirm whether you have followed the instructions mentioned here  Below are the options from `.bazelrc` file for **AVX** instructions ","Python path configuration  !image configuration.py  !image Error after bazel run  C:\Users\Anmaheshwari\TF_2\tensorflow>bazel build config=opt //tensorflow/tools/pip_package:build_pip_package INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=172 INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Options provided by the client:   'build' options: python_path=C:/Users/Anmaheshwari/python/python.exe INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow\.tf_configure.bazelrc:   'build' options: action_env PYTHON_BIN_PATH=C:/Users/Anmaheshwari/python/python.exe action_env PYTHON_LIB_PATH=C:/Users/Anmaheshwari/python/lib/sitepackages python_path=C:/Users/Anmaheshwari/python/python.exe copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions define=override_eigen_strong_inline=true INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc:   'build' options: deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils INFO: Found applicable config definition build:short_logs in file c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:opt in file c:\users\anmaheshwari\tf_2\tensorflow\.tf_configure.bazelrc: copt=/arch:AVX host_copt=/arch:AVX INFO: Found applicable config definition build:windows in file c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc: copt=/W0 host_copt=/W0 copt=/Zc:__cplusplus host_copt=/Zc:__cplusplus copt=/D_USE_MATH_DEFINES host_copt=/D_USE_MATH_DEFINES features=compiler_param_file copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions cxxopt=/std:c++17 host_cxxopt=/std:c++17 config=monolithic copt=DWIN32_LEAN_AND_MEAN host_copt=DWIN32_LEAN_AND_MEAN copt=DNOGDI host_copt=DNOGDI copt=/Zc:preprocessor host_copt=/Zc:preprocessor linkopt=/DEBUG host_linkopt=/DEBUG linkopt=/OPT:REF host_linkopt=/OPT:REF linkopt=/OPT:ICF host_linkopt=/OPT:ICF verbose_failures features=compiler_param_file INFO: Found applicable config definition build:monolithic in file c:\users\anmaheshwari\tf_2\tensorflow\.bazelrc: define framework_shared_object=false define tsl_protobuf_header_only=false experimental_link_static_libraries_once=false INFO: Repository local_execution_config_python instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:962:19: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:96:27: in _tf_toolchains   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/tools/toolchains/remote_config/configs.bzl:6:28: in initialize_rbe_configs   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/tools/toolchains/remote_config/rbe_config.bzl:158:27: in _tensorflow_local_config Repository rule local_python_configure defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl:279:41: in  INFO: Repository local_config_python instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:962:19: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:106:21: in _tf_toolchains Repository rule python_configure defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl:298:35: in  ERROR: An error occurred during the fetch of repository 'local_execution_config_python':    Traceback (most recent call last):         File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 212, column 22, in _create_local_python_repository                 _check_python_bin(repository_ctx, python_bin)         File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 145, column 25, in _check_python_bin                 auto_config_fail(""define %s='%s' is not executable. Is it the python binary?"" % (         File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail                 fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)) Error in fail: Configuration Error: define PYTHON_BIN_PATH='C:/Users/Anmaheshwari/python/python.exe' is not executable. Is it the python binary? ERROR: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: fetching local_python_configure rule //external:local_execution_config_python: Traceback (most recent call last):         File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 212, column 22, in _create_local_python_repository                 _check_python_bin(repository_ctx, python_bin)         File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 145, column 25, in _check_python_bin                 auto_config_fail(""define %s='%s' is not executable. Is it the python binary?"" % (         File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail                 fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)) Error in fail: Configuration Error: define PYTHON_BIN_PATH='C:/Users/Anmaheshwari/python/python.exe' is not executable. Is it the python binary? INFO: Repository stablehlo instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:965:28: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:83:14: in _initialize_third_party   C:/users/anmaheshwari/tf_2/tensorflow/third_party/stablehlo/workspace.bzl:11:20: in repo   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository termcolor_archive instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:972:21: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:388:20: in _tf_repositories   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository eigen_archive instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:965:28: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:65:11: in _initialize_third_party   C:/users/anmaheshwari/tf_2/tensorflow/third_party/eigen3/workspace.bzl:14:20: in repo   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository cpuinfo instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:972:21: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:166:20: in _tf_repositories   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository sobol_data instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:965:28: in workspace   C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:82:15: in _initialize_third_party   C:/users/anmaheshwari/tf_2/tensorflow/third_party/sobol_data/workspace.bzl:6:20: in repo   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in  INFO: Repository go_sdk instantiated at:   C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:23:14: in    C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace0.bzl:135:20: in workspace   C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:36:27: in grpc_extra_deps   C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/io_bazel_rules_go/go/private/sdk.bzl:431:28: in go_register_toolchains   C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/io_bazel_rules_go/go/private/sdk.bzl:130:21: in go_download_sdk Repository rule _go_download_sdk defined at:   C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/io_bazel_rules_go/go/private/sdk.bzl:117:35: in  ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Configuration Error: define PYTHON_BIN_PATH='C:/Users/Anmaheshwari/python/python.exe' is not executable. Is it the python binary? INFO: Elapsed time: 1.792s INFO: 0 processes. FAILED: Build did NOT complete successfully (34 packages loaded, 194 targets configured)     currently loading: project//llvm ... (11 packages)     Fetching ; fetching     Fetching ; fetching     Fetching ; fetching     Fetching ; fetching     Fetching ...ingssl; Extracting C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/boringssl/temp13612522096612888484/c00d7ca810e93780bd0c8ee4eea28f4f2ea4bcdc\ .tar.gz C:\Users\Anmaheshwari\TF_2\tensorflow>",Any update?,Any update?,any update?,"Hi ankit, the error is due to incorrect Python path set up. Please try following commands, also set Python path in Environmental Variable Set your PATH  set PATH=C:/Tools/bazel set PATH=path/to/python_virtualenv/Scripts set PATH=C:/Python310/Scripts set PATH=C:/Python310 Python  set PYTHON_BIN_PATH=path/to/python_virtualenv/Scripts/python.exe set PYTHON_LIB_PATH=path/to/python virtualenv/lib/sitepackages set PYTHON_DIRECTORY=path/to/python_virtualenv/Scripts","Hi  , Looking at the log it seems the error is due to python path. Please refer to the above comment in setting path and let us know if it helps. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
733,"以下是一个github上的tensorflow下的一个issue, 标题是(If we have any detail information of each CI in tensorflow Github? )， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sanbuphy,If we have any detail information of each CI in tensorflow Github? ,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-03-25T03:19:04Z,type:support,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60111,"> In github repository u can find CI(continious integrity). It contains pipelines in workflows directory used for build, run, test and deploy of tensorflow code for projects. For windows you have '**windowsci.yml**' pipelines which uses visual studio to build and run. For mac you have there is '**macosci.yml**' For linu7x it is '**linuxci.yml**' >  > Now to build and test pipeline used is '**nightlypippackage.yml**' For tensorflow doc we use '**docspresubmit.yml**' To buld, run and release the packages we use '**release.yml**' You can look over many pipelines in workflows directory. Thank you very much!",Are you satisfied with the resolution of your issue? Yes No,"> In github repository u can find CI(continious integrity). It contains pipelines in workflows directory used for build, run, test and deploy of tensorflow code for projects. For windows you have '**windowsci.yml**' pipelines which uses visual studio to build and run. For mac you have there is '**macosci.yml**' For linu7x it is '**linuxci.yml**' >  > Now to build and test pipeline used is '**nightlypippackage.yml**' For tensorflow doc we use '**docspresubmit.yml**' To buld, run and release the packages we use '**release.yml**' You can look over many pipelines in workflows directory. Hi!  , Can you tell me the difference between CI that runs on GitHub Actions and CI that runs on Jenkins? Or, when is a full CI run, and when is a partial CI run? What determines this? Thank you very much."
815,"以下是一个github上的tensorflow下的一个issue, 标题是(Build 2.11.1 from source in arm , Error in repository_rule: in call to repository_rule(), parameter 'remotable' is experimental and thus unavailable with the current flags)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.1  Custom Code No  OS Platform and Distribution Linux EulerOS(CentOS)  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,nickkchenn,"Build 2.11.1 from source in arm , Error in repository_rule: in call to repository_rule(), parameter 'remotable' is experimental and thus unavailable with the current flags",Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.1  Custom Code No  OS Platform and Distribution Linux EulerOS(CentOS)  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-24T14:11:53Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60099,"Hi  , Could you please confirm the command used for build. I am getting the error below because of the {{ extra_options }}. Is it related to the the java environment? If I exclude {{ extra_options }} this then build starts compiling. For me the command `bazel host_jvm_args=Djavax.net.ssl.trustStore='/usr/local/java/jre/lib/security/cacerts'  host_jvm_args=Djavax.net.ssl.trustStorePassword='changeit' build jobs=16  copt=""mtune=generic"" copt=""march=armv8a"" copt=""O3""  //tensorflow/tools/pip_package:build_pip_package verbose_failures` seems working.  I see from your log the build failed within 76.7 seconds. For me the compiling happened more than 1 hour and then my VM got disconnected and hence can't share the logs.Will try again and share the complete logs. If you can confirm the argument `{{ extra_options }} ` seems stopping me from build and getting build fail error immediately as below. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Attaching the logs below which overrides the error reported and starts compiling. 
1402,"以下是一个github上的tensorflow下的一个issue, 标题是([JAX] The use of jax.Array.at fails experimental_from_jax)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Darwin Kernel Version 22.3.0  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0   2. Code  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab  full example  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Conversion works  Interpreter fails at invoke  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,krzysztofrusek,[JAX] The use of jax.Array.at fails experimental_from_jax," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Darwin Kernel Version 22.3.0  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0   2. Code  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab  full example  3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Conversion works  Interpreter fails at invoke  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. ",2023-03-23T20:34:46Z,stat:awaiting response type:support stale TFLiteConverter TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60090,"To fix this, the expected output of the **_update** function should be printed before and after the interpreter is invoked, and the output of the interpreter should be captured and printed. This can be done using the following code: ","> To fix this, the expected output of the **_update** function should be printed before and after the interpreter is invoked, and the output of the interpreter should be captured and printed. This can be done using the following code: >  >  Nope, still got the same  error  (the same happens for tf 2.12) https://colab.research.google.com/drive/1VGVrdBBqN_0qrvZC_w99ZxVTJqp6_9Nt?usp=sharing",PS The same functionality can one implemented with `jax.nn.one_hot` and this works. So clearly the issue is with at.  does it make sense to try the path Jax>jax2tf>tf.lite or is this under the hood of `tf.lite.TFLiteConverter.experimental_from_jax` ?,  Sorry for the late reply.   Could you please look into this? I was able to reproduce the issue on Colab using TFv2.12. Please find the gist here for reference. Thank you !,"Hi  The error occurs while we are updating a scalar value and as the error suggests when we use `jp.ones((1,2))` and try to update `x.at[0].set[4]`, it runs without any error.  Please find the gist here.    Could you please check if this is intended behaviour?  Thanks.",Hi  thanks for the hint. This is some workaround.,Hi   The latest nightly TF 2.14.0dev20230716 says  So the right way is to jax>jax2tf>lite moving forward. Please find the resolved gist for the same. Thanks. ,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1860,"以下是一个github上的tensorflow下的一个issue, 标题是(Selectively build TFLite for iOS failure)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution MacOS Ventura 13.1  Mobile device N/A  Python version 3.9.16  Bazel version 5.3  GCC/Compiler version 14.0.0  CUDA/cuDNN version N/A  GPU model and memory N/A  Current Behaviour?  shell There is no code involved. To reproduce: 1. git fetch a new project 2. Copy the toy model I provided into its root directory 3. Run `bash tensorflow/lite/ios/build_frameworks.sh input_models=tflite_model_vocab_changes_run_18026681_full_dataset.tflite target_archs=x86_64,armv7,arm64` command It will compile for a couple minutes, and fail finally. shell $ bash tensorflow/lite/ios/build_frameworks.sh input_models=tflite_model_vocab_changes_run_18026681_full_dataset.tflite target_archs=x86_64,armv7,arm64 INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=314 INFO: Reading rc options for 'build' from /Users/ghe/projects/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /Users/ghe/projects/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shar)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,heguanyu,Selectively build TFLite for iOS failure,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution MacOS Ventura 13.1  Mobile device N/A  Python version 3.9.16  Bazel version 5.3  GCC/Compiler version 14.0.0  CUDA/cuDNN version N/A  GPU model and memory N/A  Current Behaviour?  shell There is no code involved. To reproduce: 1. git fetch a new project 2. Copy the toy model I provided into its root directory 3. Run `bash tensorflow/lite/ios/build_frameworks.sh input_models=tflite_model_vocab_changes_run_18026681_full_dataset.tflite target_archs=x86_64,armv7,arm64` command It will compile for a couple minutes, and fail finally. shell $ bash tensorflow/lite/ios/build_frameworks.sh input_models=tflite_model_vocab_changes_run_18026681_full_dataset.tflite target_archs=x86_64,armv7,arm64 INFO: Options provided by the client:   Inherited 'common' options: isatty=1 terminal_columns=314 INFO: Reading rc options for 'build' from /Users/ghe/projects/tensorflow/.bazelrc:   Inherited 'common' options: experimental_repo_remote_exec INFO: Reading rc options for 'build' from /Users/ghe/projects/tensorflow/.bazelrc:   'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shar",2023-03-23T18:37:09Z,stat:awaiting tensorflower type:build/install comp:lite TF 2.12,closed,0,34,https://github.com/tensorflow/tensorflow/issues/60088,Attached the toy model that you can use to reproduce this issue. toy_tflite_model_20230308.tflite.zip,Hi  I was successfully able to build the TFLite framework.  Please refer the screenshot here.   I have used `toy_tflite_model_20230308.tflite` which is provided as a toy model rather than `tflite_model_vocab_changes_run_18026681_full_dataset.tflite` which is mentioned in the command which I don't think is an issue. Can you try at your end again freshly and let us know if the issue still persists? Thanks.,Yes it still persist with a brand new git cloned repo !image, Thanks for the information.  Could you please look into this issue. Thanks.,"Hi  after updating to the latest tensorflow code base, I'm now seeing another different error.. can you please take a look? Thanks "," , As per your comment here https://github.com/tensorflow/tensorflow/issues/59853issuecomment1481642687, Could you pleas let me know what part of Tensorflow has to be looked into, so that I can assign it to the specific team. Thanks!",I did a git pull again this morning and the error is back to the `declared output 'tensorflow/libtensorflow_framework.2.dylib' was not created by genrule.` I'd updated the python to python3.10 but error persist. can someone help? Thanks ,"Hey , the error we are getting are from tensorflow/BUILD file. looks like the error occurred when we generate the tensorflow shared library `tensorflow/libtensorflow_framework.2.dylib`. Could you help triage to someone from the tensorflow side? I don't know if this is a build config issue or something changed. Thanks  Also , can you try if tesorflow 2.11.0 has this issue? Thanks!"," , Could you please look into this. cc: toplay  > Hey , the error we are getting are from tensorflow/BUILD file. looks like the error occurred when we generate the tensorflow shared library `tensorflow/libtensorflow_framework.2.dylib`. Could you help triage to someone from the tensorflow side? I don't know if this is a build config issue or something changed. Thanks >  >  >  > Also , can you try if tesorflow 2.11.0 has this issue? Thanks!","From the logs, it might possibly be a realpath issue I have seen in one of our other builds.   Are you using the GNU version of realpath? If not, could you install it and try building again?","Hi  I tried installing coreutils as your suggestion, but not getting luck. Is version 9.2 correct?  ","Yeah, I believe the latest version should work. Note that the GNU utilities are installed with a 'g' prefix. That is, the gnu version is `grealpath` where as Bazel runs using just `realpath` so it is possible that the macOS version is still getting picked up. Can you try replacing the macOS utilities with the GNU utilities? Once you have replaced the defaults with GNU utilities, run `realpath help`. If it points to the GNU version, it should print out its usage and other info. The default macOS version just throws an error like the one above in https://github.com/tensorflow/tensorflow/issues/60088issuecomment1499766349. ","> Hey , the error we are getting are from tensorflow/BUILD file. looks like the error occurred when we generate the tensorflow shared library `tensorflow/libtensorflow_framework.2.dylib`. Could you help triage to someone from the tensorflow side? I don't know if this is a build config issue or something changed. Thanks >  >  >  > Also , can you try if tesorflow 2.11.0 has this issue? Thanks! Sorry but no luck when I tried the same command after `git checkout v2.11.0` "," Thanks for the guide. After installing realpath according to your instruction, previous error was gone, however it now shows another error.. `ModuleNotFoundError: No module named 'packaging' Target //tensorflow/lite/ios/tmp:TensorFlowLiteSelectTfOps_framework failed to build`  is this specific to SelectTfOps? I'm using v2.11.0.  ",Yeah this new error is specific to SelectTfOps. This seems like a python issue? The error is in `tensorflow/python/tools/BUILD`.  do you have any idea what might be the issue here?, Is the packaging module installed? ,"  I haven't installed `packaging`. As an iOS engineer, python is not often used, so the python is pretty much in vanilla state.  After installing it and rerunning the script, now it asks me to install `requests` module...  With both modules pip installed, I'm finally build successfully! However still seeing another issue  I tried looking for the file, according to the instruction, at `bazelbin/tensorflow/lite/ios/tmp/TensorFlowLiteC_framework.zip` and it was also missing..(there is no tmp directory). Any idea what's the reason and where should look for this file?   Also, can your team please add these dependencies, along with the above gnu utility tricks, to either Prerequisites in the official instruction, or just put them into the build scripts? I asked my colleagues and they are seeing same errors as myself. I believe this would be beneficial to a lot more people in iosTF community. ","> With both modules pip installed, I'm finally build successfully! However still seeing another issue >  >  >  > I tried looking for the file, according to the instruction, at `bazelbin/tensorflow/lite/ios/tmp/TensorFlowLiteC_framework.zip` and it was also missing..(there is no tmp directory). Any idea what's the reason and where should look for this file? >  Sorry but I don't know whats happening here.  do you know? > Also, can your team please add these dependencies, along with the above gnu utility tricks, to either Prerequisites in the official instruction, or just put them into the build scripts? I asked my colleagues and they are seeing same errors as myself. I believe this would be beneficial to a lot more people in iosTF community. Thanks for letting us know! Maybe it would be useful to put these in a FAQs or as comments in the build scripts but I'll leave the decision up to  and the TF Lite team.","Thanks nitins17 for the help! Hi heguanyu, sorry for the inconvenience. Glad to hear that it finally build successfully! Since you already have the build file under `tensorflow/lite/ios/tmp/`, can you just try running this command `bazel build c opt config=ios ios_multi_cpus=arm64 use_top_level_targets_for_symlinks define=tflite_with_xnnpack=false //tensorflow/lite/ios/tmp:TensorFlowLiteSelectTfOps_framework`? I think all these problems might come from different MacOs versions. The build command works fine for an older OS version. > Also, can your team please add these dependencies, along with the above gnu utility tricks, to either Prerequisites in the official instruction, or just put them into the build scripts? I asked my colleagues and they are seeing same errors as myself. I believe this would be beneficial to a lot more people in iosTF community. Thanks for the suggestion! We'll update our public website."," I think the BUILD file in tmp was deleted after the build is successful, seeing ",Just pulled from master branch and still seeing the file not found error.  ,Hi   Bumping up this thread again  can you help checking what might be the issue that file get missing? Thank you!,I am able to replicate on r2.13 branch: ,"Hi, just to clarify, how are you running the script? The following command works for me.  Are you running the command under `/Users/pisethk/git/tensorflow`?   Looking at the error you got, it seems that the tmp directly is not successfully created. ","> Target //tensorflow/lite/ios/tmp:TensorFlowLiteSelectTfOps_framework uptodate: >   bazelout/applebin_iosios_x86_64optST74bbdaf492e7/bin/tensorflow/lite/ios/tmp/TensorFlowLiteSelectTfOps_framework.zip Hi really sorry for the late reply. If you look at the log, the framework is already successfully built and the artifact can be found at  `bazelout/applebin_iosios_x86_64optST74bbdaf492e7/bin/tensorflow/lite/ios/tmp/TensorFlowLiteSelectTfOps_framework.zip`. The script tensorflow/lite/ios/build_frameworks.sh will always delete the temporary directory `tensorflow/lite/ios/tmp/` at the end of the script, so your next command failed. ","Hi  Thanks! I do find it in that folder! 2 more question tho: 1. I noticed the size is huge(180+MB for zip file, and 738MB after decompress), is this expected at all? The original framework size is only around 4MB...   3. Is it possible to fix the script so that the zip file will be copied to some fixed location, instead of a temporary path that I have to look up from the stdout everytime? That will help automating some processes in the CD pipeline.  Thank you!","> I noticed the size is huge(180+MB for zip file, and 738MB after decompress), is this expected at all? The original framework size is only around 4MB... Hi , yes unfortunately the binary size with selected ops will be larger because it links in TF kernels. What are the targeted archs you built for? You probably only need `arm64`?"," We noticed that the bazel script logic is that  if it detects any select operators in the model, it will add ALL select operators into the binary, whether or not it is being used in the model. Is there any way to ONLY include the operators that being used by the tflite model? As per your 2nd suggestion, limiting the architect to only arm64 will just cut the size in half  down to 364MB  but it is still too huge for a iOS device...",Hi  this is what the script is supposed to do. Here we only generate targets for your models https://github.com/tensorflow/tensorflow/blob/54751245dfb6c551e5118c6bd279baf806f784cb/tensorflow/lite/ios/build_frameworks.shL92 .  Could you run the following command and check if the ops_list.txt contains exactly the ops you need? ,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.
1857,"以下是一个github上的tensorflow下的一个issue, 标题是(Build from source on Windows failing )， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows   TensorFlow installation (pip package or built from source): Build from source on Windows  TensorFlow library (version, if pip package or github SHA, if built from source): 2.12 bazel version  5.3 python version  3.9  i am following below link  https://www.tensorflow.org/install/source_windows command that I am  running   bazel build //tensorflow/tools/pip_package:build_pip_package Error message  Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/downloads/tf/tensorflow2.12.0/tensorflow2.12.0/third_party/repo.bzl:89:35: in  ERROR: C:/users/anmaheshwari/downloads/tf/tensorflow2.12.0/tensorflow2.12.0/tensorflow/core/BUILD:511:11: //tensorflow/core:ops depends on //tensorflow/compiler/mlir/tensorflow:mlir_passthrough_op in repository @ which failed to fetch. no such package 'project//mlir': Failed to find python3 binary ERROR: Analysis of target '//tensorflow/lite/delegates/flex:tensorflowlite_flex' failed; build aborted: INFO: Elapsed time: 297.423s INFO: 0 processes. FAILED: Build did NOT complete successfully (87 packages loaded, 331 targets configured)     currently loading: tensorflow/lite/schema ... (4 packages)     Fetching ; fetching     Fetching ...ri/grgp23z7/external/flatbuffers; Extracting C:/users/anmaheshwari/_bazel_anmaheshwari/grgp23z7/external/flatbuffers/temp5290822748239123909/v2.0.6.tar.gz     Fetching ; fetching     Fetching https://storage.googleapis.com/mirror.tensorflow.org/github.com/abseil/abseilcpp/archive/273292d1cfc0a94a65082ee350509af1d113344d.tar.gz C:\Users\Anmaheshwari\D)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,AIML-ankit,Build from source on Windows failing ," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows   TensorFlow installation (pip package or built from source): Build from source on Windows  TensorFlow library (version, if pip package or github SHA, if built from source): 2.12 bazel version  5.3 python version  3.9  i am following below link  https://www.tensorflow.org/install/source_windows command that I am  running   bazel build //tensorflow/tools/pip_package:build_pip_package Error message  Repository rule _tf_http_archive defined at:   C:/users/anmaheshwari/downloads/tf/tensorflow2.12.0/tensorflow2.12.0/third_party/repo.bzl:89:35: in  ERROR: C:/users/anmaheshwari/downloads/tf/tensorflow2.12.0/tensorflow2.12.0/tensorflow/core/BUILD:511:11: //tensorflow/core:ops depends on //tensorflow/compiler/mlir/tensorflow:mlir_passthrough_op in repository @ which failed to fetch. no such package 'project//mlir': Failed to find python3 binary ERROR: Analysis of target '//tensorflow/lite/delegates/flex:tensorflowlite_flex' failed; build aborted: INFO: Elapsed time: 297.423s INFO: 0 processes. FAILED: Build did NOT complete successfully (87 packages loaded, 331 targets configured)     currently loading: tensorflow/lite/schema ... (4 packages)     Fetching ; fetching     Fetching ...ri/grgp23z7/external/flatbuffers; Extracting C:/users/anmaheshwari/_bazel_anmaheshwari/grgp23z7/external/flatbuffers/temp5290822748239123909/v2.0.6.tar.gz     Fetching ; fetching     Fetching https://storage.googleapis.com/mirror.tensorflow.org/github.com/abseil/abseilcpp/archive/273292d1cfc0a94a65082ee350509af1d113344d.tar.gz C:\Users\Anmaheshwari\D",2023-03-23T12:29:57Z,stat:awaiting response type:build/install stale TFLiteConverter TF 2.12,closed,0,7,https://github.com/tensorflow/tensorflow/issues/60083,"ankit Could you please confirm if you are using TF v2.12 which is the latest version? As per the tested build configuration listed here please let us know if the build from source on windows is not failing now! For installing TF lite with CMake, please refer to this.   Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"C:\Users\Anmaheshwari\TF_2\tensorflow>bazel build config=opt //tensorflow/tools/pip_package:build_pip_package INFO: Options provided by the client: Inherited 'common' options: isatty=1 terminal_columns=172 INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: Inherited 'common' options: experimental_repo_remote_exec INFO: Options provided by the client: 'build' options: python_path=C:/Users/Anmaheshwari/python/python.exe INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: 'build' options: define framework_shared_object=true define tsl_protobuf_header_only=true define=use_fast_cpp_protos=true define=allow_oversize_protos=true spawn_strategy=standalone c opt announce_rc define=grpc_no_ares=true noincompatible_remove_legacy_whole_archive enable_platform_specific_config define=with_xla_support=true config=short_logs config=v2 define=no_aws_support=true define=no_hdfs_support=true experimental_cc_shared_library experimental_link_static_libraries_once=false incompatible_enforce_config_setting_visibility INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow.tf_configure.bazelrc: 'build' options: action_env PYTHON_BIN_PATH=C:/Users/Anmaheshwari/python/python.exe action_env PYTHON_LIB_PATH=C:/Users/Anmaheshwari/python/lib/sitepackages python_path=C:/Users/Anmaheshwari/python/python.exe copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions define=override_eigen_strong_inline=true INFO: Reading rc options for 'build' from c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: 'build' options: deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_jitrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils INFO: Found applicable config definition build:short_logs in file c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: output_filter=DONT_MATCH_ANYTHING INFO: Found applicable config definition build:v2 in file c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: define=tf_api_version=2 action_env=TF2_BEHAVIOR=1 INFO: Found applicable config definition build:opt in file c:\users\anmaheshwari\tf_2\tensorflow.tf_configure.bazelrc: copt=/arch:AVX host_copt=/arch:AVX INFO: Found applicable config definition build:windows in file c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: copt=/W0 host_copt=/W0 copt=/Zc:__cplusplus host_copt=/Zc:__cplusplus copt=/D_USE_MATH_DEFINES host_copt=/D_USE_MATH_DEFINES features=compiler_param_file copt=/d2ReducedOptimizeHugeFunctions host_copt=/d2ReducedOptimizeHugeFunctions cxxopt=/std:c++17 host_cxxopt=/std:c++17 config=monolithic copt=DWIN32_LEAN_AND_MEAN host_copt=DWIN32_LEAN_AND_MEAN copt=DNOGDI host_copt=DNOGDI copt=/Zc:preprocessor host_copt=/Zc:preprocessor linkopt=/DEBUG host_linkopt=/DEBUG linkopt=/OPT:REF host_linkopt=/OPT:REF linkopt=/OPT:ICF host_linkopt=/OPT:ICF verbose_failures features=compiler_param_file INFO: Found applicable config definition build:monolithic in file c:\users\anmaheshwari\tf_2\tensorflow.bazelrc: define framework_shared_object=false define tsl_protobuf_header_only=false experimental_link_static_libraries_once=false INFO: Repository local_execution_config_python instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:962:19: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:96:27: in _tf_toolchains C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/tools/toolchains/remote_config/configs.bzl:6:28: in initialize_rbe_configs C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/tools/toolchains/remote_config/rbe_config.bzl:158:27: in _tensorflow_local_config Repository rule local_python_configure defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl:279:41: in INFO: Repository local_config_python instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:962:19: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:106:21: in _tf_toolchains Repository rule python_configure defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl:298:35: in ERROR: An error occurred during the fetch of repository 'local_execution_config_python': Traceback (most recent call last): File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 212, column 22, in _create_local_python_repository _check_python_bin(repository_ctx, python_bin) File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 145, column 25, in _check_python_bin auto_config_fail(""define %s='%s' is not executable. Is it the python binary?"" % ( File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)) Error in fail: Configuration Error: define PYTHON_BIN_PATH='C:/Users/Anmaheshwari/python/python.exe' is not executable. Is it the python binary? ERROR: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: fetching local_python_configure rule //external:local_execution_config_python: Traceback (most recent call last): File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 212, column 22, in _create_local_python_repository _check_python_bin(repository_ctx, python_bin) File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/py/python_configure.bzl"", line 145, column 25, in _check_python_bin auto_config_fail(""define %s='%s' is not executable. Is it the python binary?"" % ( File ""C:/users/anmaheshwari/tf_2/tensorflow/third_party/remote_config/common.bzl"", line 12, column 9, in auto_config_fail fail(""%sConfiguration Error:%s %s\n"" % (red, no_color, msg)) Error in fail: Configuration Error: define PYTHON_BIN_PATH='C:/Users/Anmaheshwari/python/python.exe' is not executable. Is it the python binary? INFO: Repository stablehlo instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:965:28: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:83:14: in _initialize_third_party C:/users/anmaheshwari/tf_2/tensorflow/third_party/stablehlo/workspace.bzl:11:20: in repo C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in INFO: Repository termcolor_archive instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:972:21: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:388:20: in _tf_repositories C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in INFO: Repository eigen_archive instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:965:28: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:65:11: in _initialize_third_party C:/users/anmaheshwari/tf_2/tensorflow/third_party/eigen3/workspace.bzl:14:20: in repo C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in INFO: Repository cpuinfo instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:972:21: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:166:20: in _tf_repositories C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in INFO: Repository sobol_data instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:15:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:965:28: in workspace C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace2.bzl:82:15: in _initialize_third_party C:/users/anmaheshwari/tf_2/tensorflow/third_party/sobol_data/workspace.bzl:6:20: in repo C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:136:21: in tf_http_archive Repository rule _tf_http_archive defined at: C:/users/anmaheshwari/tf_2/tensorflow/third_party/repo.bzl:89:35: in INFO: Repository go_sdk instantiated at: C:/users/anmaheshwari/tf_2/tensorflow/WORKSPACE:23:14: in C:/users/anmaheshwari/tf_2/tensorflow/tensorflow/workspace0.bzl:135:20: in workspace C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/com_github_grpc_grpc/bazel/grpc_extra_deps.bzl:36:27: in grpc_extra_deps C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/io_bazel_rules_go/go/private/sdk.bzl:431:28: in go_register_toolchains C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/io_bazel_rules_go/go/private/sdk.bzl:130:21: in go_download_sdk Repository rule _go_download_sdk defined at: C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/io_bazel_rules_go/go/private/sdk.bzl:117:35: in ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Configuration Error: define PYTHON_BIN_PATH='C:/Users/Anmaheshwari/python/python.exe' is not executable. Is it the python binary? INFO: Elapsed time: 1.792s INFO: 0 processes. FAILED: Build did NOT complete successfully (34 packages loaded, 194 targets configured) currently loading: project//llvm ... (11 packages) Fetching https://github.com/boringssl; fetching Fetching ; fetching Fetching ; fetching Fetching ; fetching Fetching ...ingssl; Extracting C:/users/anmaheshwari/_bazel_anmaheshwari/unnl57ya/external/boringssl/temp13612522096612888484/c00d7ca810e93780bd0c8ee4eea28f4f2ea4bcdc .tar.gz C:\Users\Anmaheshwari\TF_2\tensorflow>","Hi ankit  Looks like this is duplicate of issue CC(Build from source on Windows failed) . Can you please close this issue, since it is already being tracked there? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1005,"以下是一个github上的tensorflow下的一个issue, 标题是(`pip install tensorflow-gpu` gives `setuptools.extern.packaging.requirements.InvalidRequirement`)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Ubuntu 22.10  Mobile device _No response_  Python version Python 3.10.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? My GPU [AMD Ryzen™ 9 6900HX with Radeon™ Graphics × 16] wasn't detected on the regular `pip install tensorflow`, StackOverflow told others to `pip install tensorflowgpu` which gave me:  FYI: Running versions setuptools67.6.0 wheel0.40.0 pip23.0.1  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SamuelMarks,`pip install tensorflow-gpu` gives `setuptools.extern.packaging.requirements.InvalidRequirement`,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code No  OS Platform and Distribution Ubuntu 22.10  Mobile device _No response_  Python version Python 3.10.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? My GPU [AMD Ryzen™ 9 6900HX with Radeon™ Graphics × 16] wasn't detected on the regular `pip install tensorflow`, StackOverflow told others to `pip install tensorflowgpu` which gave me:  FYI: Running versions setuptools67.6.0 wheel0.40.0 pip23.0.1  Standalone code to reproduce the issue   Relevant log output _No response_",2023-03-22T22:23:50Z,stat:awaiting response type:bug type:build/install stale TF 2.12,closed,2,6,https://github.com/tensorflow/tensorflow/issues/60074,", From tensorflow v2.12, removed redundant packages **tensorflowgpu and tfnightlygpu**. These packages were removed and replaced with packages that direct users to switch to **tensorflow or tfnightly respectively**.  Please take a look at the official release doc for the reference. https://github.com/tensorflow/tensorflow/releases Since TensorFlow 2.1, the only difference between these two sets of packages was their names, so there is no loss of functionality or GPU support. See https://pypi.org/project/tensorflowgpu for more details. https://pypi.org/project/tensorflowgpu/ `Tensorflowgpu` has been removed. Please install tensorflow instead. The tensorflow package supports GPU accelerated operations via Nvidia CUDA. Thank you!","Ah, ok. Just to confirm, TensorFlow doesn't support my Navi 22 [Radeon RX 6700/6700 XT/6750 XT / 6800M]? (I might need to look closer into ROCm)",", The **!pip install tensorflowgpu and tfnightlygpu** were removed from tensorflow v2.12. We can directly use **pip install tensorflow** for the gpu. https://pypi.org/project/tensorflowgpu/  Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1908,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLITE mobilenetv2 conversion from tf leads to poor accuracy on imagenet evaluation tool)， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04    **TensorFlow installed from (source or binary)**: Binary    **TensorFlow version (use command below)**: 2.11    **Python version**: 3.9  Describe the problem Mobilenetv2 converted from TF to TFLITE using default MLIR converter leads to poor accuracy on tflite imagenet evaluation tool. On imagenet evaluation tool I get the below output: > INFO: Num evaluation runs: 50000 > INFO: Preprocessing latency: avg=3837.7(us), std_dev=0(us) > INFO: Inference latency: avg=16046.3(us), std_dev=486(us) > INFO: Top1 Accuracy: 0.43192 > INFO: Top2 Accuracy: 0.5436 > INFO: Top3 Accuracy: 0.60002 > INFO: Top4 Accuracy: 0.6364 > INFO: Top5 Accuracy: 0.66124 > INFO: Top6 Accuracy: 0.68194 > INFO: Top7 Accuracy: 0.69918 > INFO: Top8 Accuracy: 0.71268 > INFO: Top9 Accuracy: 0.72398 > INFO: Top10 Accuracy: 0.73382 I used imagenet ILSVRC2012_img_val dataset with mobilenet labels downloaded from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt. I ran the evaluation on all 50000 images. Top1 accuracy came to 43% whereas official mobilenetv2 top1 accuracy is ~72%. I did not quantize the model and used the default float32.  what can be the cause of this delta in accuracy? If i remove `converter.optimizations = [tf.lite.Optimize.DEFAULT]` from script,   i still get 43% Top1 accuracy on imagenet. Shouldn't tflite models have similar accuracy to tf models? When i quantize the model to use uint8/int8, )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,suyash-narain,TFLITE mobilenetv2 conversion from tf leads to poor accuracy on imagenet evaluation tool," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04    **TensorFlow installed from (source or binary)**: Binary    **TensorFlow version (use command below)**: 2.11    **Python version**: 3.9  Describe the problem Mobilenetv2 converted from TF to TFLITE using default MLIR converter leads to poor accuracy on tflite imagenet evaluation tool. On imagenet evaluation tool I get the below output: > INFO: Num evaluation runs: 50000 > INFO: Preprocessing latency: avg=3837.7(us), std_dev=0(us) > INFO: Inference latency: avg=16046.3(us), std_dev=486(us) > INFO: Top1 Accuracy: 0.43192 > INFO: Top2 Accuracy: 0.5436 > INFO: Top3 Accuracy: 0.60002 > INFO: Top4 Accuracy: 0.6364 > INFO: Top5 Accuracy: 0.66124 > INFO: Top6 Accuracy: 0.68194 > INFO: Top7 Accuracy: 0.69918 > INFO: Top8 Accuracy: 0.71268 > INFO: Top9 Accuracy: 0.72398 > INFO: Top10 Accuracy: 0.73382 I used imagenet ILSVRC2012_img_val dataset with mobilenet labels downloaded from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt. I ran the evaluation on all 50000 images. Top1 accuracy came to 43% whereas official mobilenetv2 top1 accuracy is ~72%. I did not quantize the model and used the default float32.  what can be the cause of this delta in accuracy? If i remove `converter.optimizations = [tf.lite.Optimize.DEFAULT]` from script,   i still get 43% Top1 accuracy on imagenet. Shouldn't tflite models have similar accuracy to tf models? When i quantize the model to use uint8/int8, ",2023-03-22T21:04:00Z,stat:awaiting response stale comp:lite type:performance TF 2.11,closed,0,14,https://github.com/tensorflow/tensorflow/issues/60072,narain  Could you please provide detailed steps of the tflite imagenet evaluation tool to replicate the issue reported here ? Thank you!,"> narain Could you please provide detailed steps of the tflite imagenet evaluation tool to replicate the issue reported here ? >  > Thank you!  Please find the detailed steps I exercised towards building the provided tflite imagenet evaluation tool:  clone tensorflow from github: > $ git clone ""https://github.com/tensorflow/tensorflow.git"" > $ cd tensorflow  Download ILSVRC validation dataset consisting of 50k images from  http://imagenet.org/request: ILSVRC2012_img_val https://imagenet.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar  Download ILSVRC 2012 dev kit: ILSVRC2012_devkit_t12 (tasks1&2) https://imagenet.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz  Generate Ground Truth Labels: > python /tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification/generate_validation_labels.py \ > ilsvrc_devkit_dir=path/to/ILSVRC2012_devkit_t12 \ > validation_labels_output=output_labels.txt  Download imagenet labels from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt  Build and run on Ubuntu desktop: > bazel run c opt \ >    \ >   //tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification:run_eval \ >   model_file=mbnv2_model_test1.tflite \ >   ground_truth_images_path=path/to/ILSVRC2012_img_val \ >   ground_truth_labels=path/to/output_labels.txt \ >   model_output_labels=path/to/ImageNetLabels.txt \ >   output_file_path=accuracy_output.txt \ >   num_images=0  Run on all images. >  When i run this on a tflite model sourced from tfhub: https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz i get the below results: > INFO: Num evaluation runs: 50000 > INFO: Preprocessing latency: avg=3790.96(us), std_dev=0(us) > INFO: Inference latency: avg=6675.06(us), std_dev=206(us) > INFO: Top1 Accuracy: 0.71922 > INFO: Top2 Accuracy: 0.82604 > INFO: Top3 Accuracy: 0.86718 > INFO: Top4 Accuracy: 0.8892 > INFO: Top5 Accuracy: 0.90452 > INFO: Top6 Accuracy: 0.9152 > INFO: Top7 Accuracy: 0.9234 > INFO: Top8 Accuracy: 0.9298 > INFO: Top9 Accuracy: 0.93518 > INFO: Top10 Accuracy: 0.9394 Top1 ~72% which is very close to actual mobilenetv2 accuracy on imagenet. But when i run the same tool on the converted tflite model which I had mentioned in issue, i get accuracy of 43% ",Is it because of the way image is being processed before bring provided as input to the model? I convert the model in the similar way as the mnist example provided here: https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb do i need to further preprocess the images?,"Hi    I changed my representative dataset, and used images from imagenet dataset for my representative dataset to convert model to int8 and uint8 format.  On checking the accuracy against the imagenet evaluation tool, Igot the following accuracies: **accuracy for INT8 tflite:** > INFO: Num evaluation runs: 50000 > INFO: Preprocessing latency: avg=3807.62(us), std_dev=0(us) > INFO: Inference latency: avg=5723.94(us), std_dev=96(us) > INFO: Top1 Accuracy: 0.63438 > INFO: Top2 Accuracy: 0.7515 > INFO: Top3 Accuracy: 0.80124 > INFO: Top4 Accuracy: 0.83126 > INFO: Top5 Accuracy: 0.8516 > INFO: Top6 Accuracy: 0.86576 > INFO: Top7 Accuracy: 0.87676 > INFO: Top8 Accuracy: 0.88508 > INFO: Top9 Accuracy: 0.89138 > INFO: Top10 Accuracy: 0.89808 >  But interesting thing to note is if i don't convert this model to int8 tflite and let it remain as default float32 tflite model, my accuracies are way lower: **accuracy for fp32 tflite:**  >  > INFO: Num evaluation runs: 50000 > INFO: Preprocessing latency: avg=3837.7(us), std_dev=0(us) > INFO: Inference latency: avg=16046.3(us), std_dev=486(us) > INFO: Top1 Accuracy: 0.43192 > INFO: Top2 Accuracy: 0.5436 > INFO: Top3 Accuracy: 0.60002 > INFO: Top4 Accuracy: 0.6364 > INFO: Top5 Accuracy: 0.66124 > INFO: Top6 Accuracy: 0.68194 > INFO: Top7 Accuracy: 0.69918 > INFO: Top8 Accuracy: 0.71268 > INFO: Top9 Accuracy: 0.72398 > INFO: Top10 Accuracy: 0.73382 this is odd. shouldn't top1 accuracies of float32 be higher than INT8? mobilenetv2 fp32 should give me ~71% whereas int8 should give me about ~63% according to data mentioned here: https://www.tensorflow.org/lite/performance/model_optimizationquantization","Hi narain  The input images for the tensorflow hub model are expected to have color values in the range [0,1], following the common image input conventions as per the documentation. Also, we might have to apply `softmax` activation as the model returns raw logits as per the this colab. Please check this example on image classification using tensorflow hub. Thanks.","Hi   thank you for your reply. So you mean to say I cannot use the imagenet classification evaluation tool for tflite with models sourced from tfhub since they require input image color values in range [0,1] but the imagenet tool fails with that? the output from the imagenet tool seems like softmax activation is already applied as i get top classifications between [01] how can i use the tflite imagenet classification tool against this mobilenetv2 modle sourced from tfhub to get correct accuracies?  if i source the model from keras application layers as below: > model = tf.keras.applications.mobilenet_v2.MobileNetV2( >     input_shape=None, >     alpha=1.0, >     include_top=True, >     weights='imagenet', >     input_tensor=None, >     pooling='avg', >     classes=1000, >     classifier_activation='softmax' > ) > converter = tf.lite.TFLiteConverter.from_keras_model(model) > tflite_file = ""mobilenet_v2_keras_model.tflite"" > with open(tflite_file, 'wb') as f: >        f.write(converter.convert()) in this case i get perfect accuracies (~71.9%) as mentioned in official documentation)  while running against imagenet evaluation tool provided by tflite.  So what different thing i need to do against models sourced from tfhub to get similar accuracies as i am getting with keras application layer model? thanks","Hi narain  I have observed that the default normalization the tool does is for the output range `[1,1]`.  https://github.com/tensorflow/tensorflow/blob/0c7968df89e4e3edb7c48d6b0f50e3a9a477f81a/tensorflow/lite/tools/evaluation/stages/image_preprocessing_stage.hL168 The Mobilenetv2 from  keras application applies the `tf` normalization which normalizes to the output range `[1,1]`. Please check the source code below https://github.com/kerasteam/kerasapplications/blob/06fbeb0f16e1304f239b2296578d1c50b15a983a/keras_applications/mobilenet.pyL84 https://github.com/kerasteam/kerasapplications/blob/06fbeb0f16e1304f239b2296578d1c50b15a983a/keras_applications/imagenet_utils.pyL42 For the tool to normalize the data in `[0,1]`, replace   `AddNormalizationStep(127.5, 1.0 / 127.5);` with `AddNormalizationStep(0.0, 1.0 / 255.0);` and run the tool. I have tested with fp32 model converted from tf hub with code below   and obtained the following results.  Thanks.",thanks   this worked for me.  Is there a similar evaluation tool for pretrained tf models as well? I am trying to use the same pretrained tf model on the same dataset https://imagenet.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar  and ground truth labels generated using  > python /tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification/generate_validation_labels.py > ilsvrc_devkit_dir=path/to/ILSVRC2012_devkit_t12 > validation_labels_output=output_labels.txt How do i preprocess such a dataset wherein i have 50000 images in a test directory and a labels.txt file containing ground truth labels for these 50000 images and use the same against the pretrained mobilenet_v2 saved_model downloaded from: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5 thanks,"Hi narain, glad it worked. I see that a ticket has already been opened CC(How to evaluate a pretrained TF mobilenet_v2 saved_model for accuracy on test dataset) for that issue and it is being tracked there.  Feel free to close this issue if it is resolved. Thanks.","Hi   thanks for your reply. I had one more question. What are the official accuracies for mobilenet_v2 and quantized mobilenet_v2 on imagenet? for fp32, I know it should be 72.9% for int8/uint8 it is 63.7% (post training quantization) or 70.9% (quantization aware training) as mentioned here https://www.tensorflow.org/lite/performance/model_optimizationquantization but when I evaluate the accuracy on quantized mobilenet_v2 model sourced from https://tfhub.dev/tensorflow/litemodel/mobilenet_v2_1.0_224_quantized/1/default/, I get accuracy of 71.5% which is higher than both the mentioned methods. When I quantize model sourced from https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5 and perform post training quantization on the same using a representative dataset consisting of 100 images from imagenet dataset, I still get a 71.30% accuracy for int8 and 71.25% accuracy for uint8 quantized tflite model when in reality i should be getting 63% right? But when I perform post training quantization on model sourced from keras application layers, > model = tf.keras.applications.mobilenet_v2.MobileNetV2( > input_shape=None, > alpha=1.0, > include_top=True, > weights='imagenet', > input_tensor=None, > pooling='avg', > classes=1000, > classifier_activation='softmax' > ) in this case, I get an accuracy of 63.43% on int8 and 63.69% on uint8 quantized models while running the imagenet evaluation tool.  which models were the original accuracies as mentioned in documentation obtained upon?  thanks","Hi narain  I think the reported accuracies are using the test set of 100,000 images whereas here it is being tested on val data. Incase of quantized tflite models, the models might have been trained using QAT and when tested on val data might report higher accuracies as. Inorder to reproduce the reported accuracies, we might need to replicate the experiments with the same test data the models are tested on.  Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,>  thanks   I will close this issue,Are you satisfied with the resolution of your issue? Yes No
693,"以下是一个github上的tensorflow下的一个issue, 标题是(Issue with tensorflow/Cleverhans)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.*  Custom Code Yes  OS Platform and Distribution windows 10 64b  Mobile device Google colab  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory NVIDIA T4 Tensor Core GPU  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,fabixs,Issue with tensorflow/Cleverhans,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.*  Custom Code Yes  OS Platform and Distribution windows 10 64b  Mobile device Google colab  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory NVIDIA T4 Tensor Core GPU  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-22T18:54:15Z,stat:awaiting response type:build/install stale subtype:windows TF 2.11,closed,0,9,https://github.com/tensorflow/tensorflow/issues/60069,"This error typically occurs when using an older version of TensorFlow with code that was written for a newer version. In this case, it looks like the code is trying to access the **GraphKeys** attribute of the **tensorflow** module, which was removed in **TensorFlow 2.0**. To fix this error, you can try replacing **tf.GraphKey**s with **tf.compat.v1.GraphKeys** throughout your code. This should allow it to run with TensorFlow 2.0 and newer versions. and there can be also other issue like It's possible that the CleverHans library is not installed on your system or it is not installed correctly. You can try reinstalling it using the following command: ","Hello, thanks for replying. I saw a description like that on internet, I tried it but it seems like it doesn't work on google colab. Maybe i need to try more deeply again.  Thanks anyway. On Sat, Mar 25, 2023, 9:29 PM Durgesh Patel ***@***.***> wrote: > This error typically occurs when using an older version of TensorFlow with > code that was written for a newer version. In this case, it looks like the > code is trying to access the *GraphKeys* attribute of the *tensorflow* > module, which was removed in *TensorFlow 2.0*. > > To fix this error, you can try replacing *tf.GraphKey*s with > *tf.compat.v1.GraphKeys* throughout your code. This should allow it to > run with TensorFlow 2.0 and newer versions. > > and there can be also other issue like It's possible that the CleverHans > library is not installed on your system or it is not installed correctly. > You can try reinstalling it using the following command: > > !pip install cleverhans==3.1.0 > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >", Deprecated apis are causing this issue in your implementation. Could you try to use the newer apis by replacing tf.GraphKeys with tf.compat.v1.GraphKeys in your code. Please install the Cleverhans again and rerun the kernel which will install the libraries. Thank you!,"  I appreciate your reply. But I don't have any line tf.GraphKeys in my code, that's why I'm pretty confused. Looks, this is the header of the code right here: google colab points out an error from line 4 to line 9 . 1)import logging 2)import numpy as np 3)import tensorflow.compat.v1 as tf tf.disable_v2_behavior() 4)from cleverhans.attacks import SaliencyMapMethod, FastGradientMethod 5)from cleverhans.utils_tf import model_train , model_eval, batch_eval,  model_argmax 6)from cleverhans.attacks_tf import jacobian_graph 7)from cleverhans.utils import other_classes 8)from cleverhans.attacks import CarliniWagnerL2 9)from cleverhans.utils_keras import KerasModelWrapper  This error is : AttributeError: module 'tensorflow' has no attribute 'GraphKeys' Not only I installed Cleverhans3.1.0 but I also installed tensorflow 2.11.0, keras 2.11.0, and all required packages As I said before, I don't have any place in my code where I used tf.GraphKey. This error is gonna drive me crazy, I have already tried several methods without getting a good solution. Thanks in advance to anyone who can suggest me a better way to solve this problem. On Sat, Mar 25, 2023, 9:29 PM Durgesh Patel ***@***.***> wrote: > This error typically occurs when using an older version of TensorFlow with > code that was written for a newer version. In this case, it looks like the > code is trying to access the *GraphKeys* attribute of the *tensorflow* > module, which was removed in *TensorFlow 2.0*. > > To fix this error, you can try replacing *tf.GraphKey*s with > *tf.compat.v1.GraphKeys* throughout your code. This should allow it to > run with TensorFlow 2.0 and newer versions. > > and there can be also other issue like It's possible that the CleverHans > library is not installed on your system or it is not installed correctly. > You can try reinstalling it using the following command: > > !pip install cleverhans==3.1.0 > > — > Reply to this email directly, view it on GitHub > , > or unsubscribe >  > . > You are receiving this because you authored the thread.Message ID: > ***@***.***> >"," I was able to replicate the issue on colab, please find the gist here.  Thank you!"," , Is that third party library `cleverhans` using TF 1. versions ? I am sorry to say we are not supporting TF1.x versions currently. Also this is related to third party library `cleverhans` which we are not the right team to address. If you can share a code snippet(2.X version) that can reproduce this error without any third party libraries we will have a look.  Thanks !",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
951,"以下是一个github上的tensorflow下的一个issue, 标题是(Calling tf.reduce_mean() along the ragged dimension of a tf.RaggedTensor created using from_uniform_row_length returns a tensor with the wrong shape.)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230322  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04.1 LTS  Mobile device _No response_  Python version 3.8.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.5  GPU model and memory _No response_  Current Behaviour? Calling tf.reduce_mean() along the ragged dimension of a tf.RaggedTensor created using from_uniform_row_length returns a tensor with the wrong shape.   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,melissamullen,Calling tf.reduce_mean() along the ragged dimension of a tf.RaggedTensor created using from_uniform_row_length returns a tensor with the wrong shape.,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230322  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04.1 LTS  Mobile device _No response_  Python version 3.8.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.5  GPU model and memory _No response_  Current Behaviour? Calling tf.reduce_mean() along the ragged dimension of a tf.RaggedTensor created using from_uniform_row_length returns a tensor with the wrong shape.   Standalone code to reproduce the issue   Relevant log output  ,2023-03-22T15:03:16Z,stat:awaiting response type:bug stale comp:ops TF 2.12,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60067, Do you mind if I take on this issue? Looks like a good beginner issue to me, I am able to reproduce this from the master build. Let me see what's the right approach here,", Thank you for raising the issue. I tried to execute the given code and it was executed as mentioned. The **Uniform_row_length** method can be used to create RaggedTensors with multiple uniform outer dimensions. For example, a **RaggedTensor** with shape `[2, 2, None]` can be constructed with this method from a RaggedTensor values with shape `[4, None]`  **tf.math.Reduce_mean** reduces `input_tensor` along the dimensions given in axis by computing the mean of elements across the dimensions in axis. Unless keepdims is true, the rank of the tensor is reduced by 1 for each of the entries in axis, which must be unique. If keepdims is true, the reduced dimensions are retained with length 1.  Kindly find the gist of it here. Gist1  Gist2 Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1884,"以下是一个github上的tensorflow下的一个issue, 标题是(How to save average weights of checkpoints using Tensorflow 2.X?)， 内容是 (HELP NEEDED !!! Hi, everyone. I found a scrit to load serials of checkpoints for a model and save average weights of them in TensorFlow1. https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/avg_checkpoints.py Which is very useful to improve the performance of the model. But in TensorFlow2， the saved checkpoints like this: !image How to average the weights of parameters for them? I tried to write a script but the output checkpoint seems not as we expected, anyone can give some helps? Thanks a lot in advance. Here is my script: ` import os import numpy as np import tensorflow as tf	 from absl import app from absl import flags from absl import logging FLAGS = flags.FLAGS flags.DEFINE_string(""checkpoints"","""", 					""Commaseparated list of checkpoints to average."") flags.DEFINE_integer(""num_last_chekpoints"", 0, 					""Average the last N saved checkpoints."" 					"" If the checkpoints flag is set, this is ignored."") flags.DEFINE_string(""prefix"", """", 					""Prefix (e.g., directory) to append to each checkpoint."") flags.DEFINE_string(""output_path"", ""/tmp/averaged.ckpt"", 					""Path to output the averaged checkpoint to."") def checkpoint_exists(path): 	return (tf.io.gfile.exists(path) or tf.io.gfile.exists(path + "".index"")) def main(argv): 	if FLAGS.checkpoints: 		 Get the checkpoints list from flags and run some basic checks. 		checkpoints = [c.strip() for c in FLAGS.checkpoints.split("","")] 		checkpoints = [c for c in checkpoints if c] 		if not checkpoints: 			raise ValueError(""No checkpoints provided for averaging."") 		if FLAGS.prefix: 			checkpoints = [FLAGS.prefix + c for c in checkpoints] 	els)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,yjiangling,How to save average weights of checkpoints using Tensorflow 2.X?,"HELP NEEDED !!! Hi, everyone. I found a scrit to load serials of checkpoints for a model and save average weights of them in TensorFlow1. https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/avg_checkpoints.py Which is very useful to improve the performance of the model. But in TensorFlow2， the saved checkpoints like this: !image How to average the weights of parameters for them? I tried to write a script but the output checkpoint seems not as we expected, anyone can give some helps? Thanks a lot in advance. Here is my script: ` import os import numpy as np import tensorflow as tf	 from absl import app from absl import flags from absl import logging FLAGS = flags.FLAGS flags.DEFINE_string(""checkpoints"","""", 					""Commaseparated list of checkpoints to average."") flags.DEFINE_integer(""num_last_chekpoints"", 0, 					""Average the last N saved checkpoints."" 					"" If the checkpoints flag is set, this is ignored."") flags.DEFINE_string(""prefix"", """", 					""Prefix (e.g., directory) to append to each checkpoint."") flags.DEFINE_string(""output_path"", ""/tmp/averaged.ckpt"", 					""Path to output the averaged checkpoint to."") def checkpoint_exists(path): 	return (tf.io.gfile.exists(path) or tf.io.gfile.exists(path + "".index"")) def main(argv): 	if FLAGS.checkpoints: 		 Get the checkpoints list from flags and run some basic checks. 		checkpoints = [c.strip() for c in FLAGS.checkpoints.split("","")] 		checkpoints = [c for c in checkpoints if c] 		if not checkpoints: 			raise ValueError(""No checkpoints provided for averaging."") 		if FLAGS.prefix: 			checkpoints = [FLAGS.prefix + c for c in checkpoints] 	els",2023-03-22T10:23:59Z,type:support comp:model,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60064,">  Thanks a lot for the help, but unfortunately the problem is still exisit. The averaged checkpoint have changed almost every name of the variables (1. change the '/' to '.S' ; 2. add '.ATTRIBUTES/VARIABLE_VALUE' to each variable again). Here is the var_list of single checkpoint and the averaged checkpoint with tf.train.list_variables (Left is the single checkpoint and the right is the averaged checkpoint). And I checked the single checkpoint and averaged checkpoint in TF1, they have the same variable name, what's wrong with it?  !image", Thank you for raising an issue! Could you please specify the TF version you are using and provide the standalone code to replicate this one? Thank you!,">  Thank you for raising an issue! Could you please specify the TF version you are using and provide the standalone code to replicate this one? Thank you! OK, I use the TensorFlow2.2 and TensorFlow2.4. You can use the attach scripts to replicate the issue (the name of the variable of the averaged checkpoint replace the string ""/"" with "".S""). Please delete the suffix of "".txt"" before run it. avg_checkpoints.py.txt gen_checkpoints.py.txt Thanks a lot for the help!!!"," Thank you for the response! FYI, the older version of TF is not actively supported. It is now recommended to use the latest TF version. I am trying to replicate it in the latest TF version and update you soon. Thank you!", I tried to replicate this issue on the latest TF version 2.12 and faced different results. Could you please check this gist and confirm the same? Thank you!,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,">  I tried to replicate this issue on the latest TF version 2.12 and faced different results. Could you please check this gist and confirm the same? Thank you! Thanks a lot for the detail experiments and the replay, I'm sorry for the late reply. I solve this problem with the following step: 1. build model `model = Model() pred = model.predict()  may use model.call() is also ok` 2. create train Checkpoint `ckpt = tf.train.Checkpoint(model=model)` 3. restore parameter of each checkpoint, get weights and average  4. set weights and save model  Must use model.call() or model.predict() one time, otherwise can't get the weights of the checkpoint, I still do not understand the reason, maybe someone may look into it who is interested.","> This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you. Thank you, the problem have been solved, you can feel free to close it.", Thank you for the update! Closing the issue as the issue has been resolved.  Thank you!,Are you satisfied with the resolution of your issue? Yes No
1014,"以下是一个github上的tensorflow下的一个issue, 标题是([MSVC]Tensorflow failed to error C2678: binary '==': no operator found which takes a left-hand operand of type 'const _Ty')， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version master branch, commit: 48246a6  Custom Code No  OS Platform and Distribution Windows Server 2022  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output build.zip transpose.zip **Or you can follow below steps to reproduce the issue with .i file Repro Steps:** 1.Download transpose.zip and unzip it 2.Open VS2022 x64 Native Tools command. 3.cl.exe transpose.i /TP /c /EHsc /std:c++17 )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Eva-An,[MSVC]Tensorflow failed to error C2678: binary '==': no operator found which takes a left-hand operand of type 'const _Ty',"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version master branch, commit: 48246a6  Custom Code No  OS Platform and Distribution Windows Server 2022  Mobile device _No response_  Python version 3.9  Bazel version 5.3.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output build.zip transpose.zip **Or you can follow below steps to reproduce the issue with .i file Repro Steps:** 1.Download transpose.zip and unzip it 2.Open VS2022 x64 Native Tools command. 3.cl.exe transpose.i /TP /c /EHsc /std:c++17 ",2023-03-22T08:22:03Z,stat:awaiting response type:build/install stale subtype:windows subtype:cpu-intel,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60062,"Hi An, please try MSVC 2019 (set BAZEL_VC=C:\Program Files(x86)\Microsoft Visual Studio\2019\Enterprise\VC). ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.","Hi  , Thank you for your reply and info. After using the newer commit of tensorflow in our test, this issue no longer exists. I think this ticket can be closed. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
513,"以下是一个github上的tensorflow下的一个issue, 标题是([tosa] Specify the accumulator type in avg_pool)， 内容是 (Tosa supports fp16 and fp32 accumulator type for fp16 input, but no way to tell for average pooling whether accumulator should be fp16 or fp32 from input type. note that this PR needs to collaborate with https://reviews.llvm.org/D146317 that add a new accumulator attribute type.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,tatwaichong,[tosa] Specify the accumulator type in avg_pool,"Tosa supports fp16 and fp32 accumulator type for fp16 input, but no way to tell for average pooling whether accumulator should be fp16 or fp32 from input type. note that this PR needs to collaborate with https://reviews.llvm.org/D146317 that add a new accumulator attribute type.",2023-03-21T19:01:27Z,size:S comp:lite-tosa,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60058,Hi  Can you please resolve conflicts? Thank you!,Hi  Any update on this PR? Please. Thank you!,I believe this is waiting an upstream change to be submitted and would be integrated along with that.,This was landed successfully as part off the LLVM integrate.
1917,"以下是一个github上的tensorflow下的一个issue, 标题是(Efficientnet B7 classification conversion from tf to tflite fails tflite imagenet evaluation test)， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**: No    **TensorFlow installed from (source or binary)**: Binary    **TensorFlow version (use command below)**: 2.11    **Python version**: 3.9  Describe the problem I am trying to convert efficientnet_b7_classification model available in tfhub: https://storage.googleapis.com/tfhubmodules/tensorflow/efficientnet/b7/classification/1.tar.gz to tflite I use the below code snippet to convert the saved model to tflite: > import tensorflow as tf > converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') > tflite_model = converter.convert() > with open('model.tflite', 'wb') as f: >   f.write(tflite_model) on visualizing the model on netron, i saw that the input to the model is of shape (1,1,1,3). whereas, the input to efficientnet_b7 is 600x600. So the converted model should have the shape (1,600,600,3), but i don't see this. The output of the model is of the shape (1,1000). > I try to change the input shape using the below snippet: > model = tf.saved_model.load('saved_model') > concrete_func = model.signatures[""serving_default""] > concrete_func.inputs[0].set_shape([1,600,600,3]) > converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],model) > tflite_model = converter.conver But on visualizing the model, i still see the input shape as (1,1,1,3), and output shape is (1,)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,suyash-narain,Efficientnet B7 classification conversion from tf to tflite fails tflite imagenet evaluation test," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**: No    **TensorFlow installed from (source or binary)**: Binary    **TensorFlow version (use command below)**: 2.11    **Python version**: 3.9  Describe the problem I am trying to convert efficientnet_b7_classification model available in tfhub: https://storage.googleapis.com/tfhubmodules/tensorflow/efficientnet/b7/classification/1.tar.gz to tflite I use the below code snippet to convert the saved model to tflite: > import tensorflow as tf > converter = tf.lite.TFLiteConverter.from_saved_model('saved_model') > tflite_model = converter.convert() > with open('model.tflite', 'wb') as f: >   f.write(tflite_model) on visualizing the model on netron, i saw that the input to the model is of shape (1,1,1,3). whereas, the input to efficientnet_b7 is 600x600. So the converted model should have the shape (1,600,600,3), but i don't see this. The output of the model is of the shape (1,1000). > I try to change the input shape using the below snippet: > model = tf.saved_model.load('saved_model') > concrete_func = model.signatures[""serving_default""] > concrete_func.inputs[0].set_shape([1,600,600,3]) > converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func],model) > tflite_model = converter.conver But on visualizing the model, i still see the input shape as (1,1,1,3), and output shape is (1,",2023-03-21T01:54:12Z,stat:awaiting response stat:awaiting tensorflower type:support stale comp:lite TFLiteConverter TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/60053,narain  Could you please try to convert the model by using `hub.load()` or `hub.KerasLayer()` as per Doc1  & Doc2 then try to evaluate tflite model. Please find the gist here for reference and let us know if still issue persists. Thank you !,"> narain Could you please try to convert the model by using `hub.load()` or `hub.KerasLayer()` as per Doc1 & Doc2 then try to evaluate tflite model. Please find the gist here for reference and let us know if still issue persists. >  > Thank you ! Hi, i tried to convert the model using `hub.load()` or `hub.KerasLayer()` as specified in the colab gist sent by you. I still get the same error.  if i use the below method: > import tensorflow as tf > import tensorflow_hub as hub >  > m = tf.keras.Sequential([hub.KerasLayer(""https://tfhub.dev/tensorflow/efficientnet/b7/classification/1"")]) > m.build([None, 600, 600, 3]) Batch input shape. >  > m.save('model') >  > converter = tf.lite.TFLiteConverter.from_saved_model(""/content/model"") > converter.target_spec.supported_ops = [ >     tf.lite.OpsSet.TFLITE_BUILTINS,   enable TensorFlow Lite ops. >     tf.lite.OpsSet.SELECT_TF_OPS,   enable TensorFlow ops. > ] >  > tflite_file = ""effnetB7_model.tflite"" > with open(tflite_file, 'wb') as f: >   f.write(converter.convert())  the input shape becomes (1,600,600,3) as desired, and has the output shape (1,1000). The official ImageNetLabels.txt available at https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt has total of 1001 labels ranging from (01000). So in that way, the output shape for this model should be (1,1001). When I run it against tflite imagenet evaluation tool, i get the same error` 'model_output_ not set correctly'`. If i remove 0background label from label file to bring total labels to 1000, i still get the same error.  I get similar error results if i use `hub.load()`",narain  Could you please provide detailed steps of tflite imagenet evaluation test to replicate the issue reported here ? Thank you!," Please find the detailed steps I exercised towards building the provided tflite imagenet evaluation tool: 1. clone tensorflow from github: >     $ git clone ""https://github.com/tensorflow/tensorflow.git"" >     $ cd tensorflow  2. Download ILSVRC validation dataset consisting of 50k images from http://imagenet.org/request: ILSVRC2012_img_val https://imagenet.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar 3. Download ILSVRC 2012 dev kit: ILSVRC2012_devkit_t12 (tasks1&2) https://imagenet.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz 4. Generate Ground Truth Labels: >     python /tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification/generate_validation_labels.py \ >     ilsvrc_devkit_dir=path/to/ILSVRC2012_devkit_t12 \ >     validation_labels_output=output_labels.txt 5. Download imagenet labels from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt 6. Build and run on Ubuntu desktop: > bazel run c opt >       >     //tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification:run_eval >     model_file=mbnv2_model_test1.tflite >     ground_truth_images_path=path/to/ILSVRC2012_img_val >     ground_truth_labels=path/to/output_labels.txt >     model_output_labels=path/to/ImageNetLabels.txt >     output_file_path=accuracy_output.txt >     num_images=0  Run on all images.","Hi narain  Sorry for the delayed response. As the tool for evaluation is based on ILSVRC 2012 task, the classes with shape [1,1001] are only accepted for the evaluation. The tensorflow hub provides modules trained on ImageNet (ILSVRC2012CLS) which return the output shapes as `[1,1001]` and can be evaluated using the tool. Please find the list of models here. Thanks.","Hi   Your reply confuses me. If i use a mobilenetv2 tflite model created using keras application layers as below: > model = tf.keras.applications.mobilenet_v2.MobileNetV2( > input_shape=None, > alpha=1.0, > include_top=True, > weights='imagenet', > input_tensor=None, > pooling='avg', > classes=1000, > classifier_activation='softmax' > ) > converter = tf.lite.TFLiteConverter.from_keras_model(model) > tflite_file = ""mobilenet_v2_keras_model.tflite"" > with open(tflite_file, 'wb') as f: >       f.write(converter.convert()) i get output model shape as [1.1000]. I run this model against imagenet labels having 1000 classes from 11000 (removing 0background), and it works. Same way, if i run efficientnetlite4 downloaded from https://tfhub.dev/tensorflow/efficientnet/lite4/classification/2, and run it against imagenet labels having 1000 classes from 11000 after removing 0background class, it still works.  Its just the efficientnet B7 downloaded from tfhub and converted to tflite that fails. even the classification accuracy on individual images is off the charts.  So what changes can i make to execute efficientnet B7 perfectly against imagenet evaluation tool, or increase accuracy of tflite model. I think this model was also trained against imagenet dataset. thanks > Hi narain >  > Sorry for the delayed response. >  > As the tool for evaluation is based on ILSVRC 2012 task, the classes with shape [1,1001] are only accepted for the evaluation. The tensorflow hub provides modules trained on ImageNet (ILSVRC2012CLS) which return the output shapes as `[1,1001]` and can be evaluated using the tool. >  > Please find the list of models here. >  > Thanks.",Hi narain Thanks for the clarification. Sorry for the delayed response. I was able to reproduce this issue. Please find the screenshot here.   Could you please look into this? Thanks.,"Hi narain  , we're wondering if you may be able to resolve your issue by using AIEdgeTorch, you can find more information here: googleblog. I have actually created a simple script for converting your efficientnet_b7 model here and verified the input shape of the generated tflite model:   If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
684,"以下是一个github上的tensorflow下的一个issue, 标题是([TF-TRT] Fix repeated layer name bug)， 内容是 ( Issue When there are multiple invocations of `SqueezeTensor` in a layer, the converter will complain:   This happens despite passing `op_instance` to `SqueezeTensor`. The root cause is `op_instance` not being propagated to `PrepareTensorForShape`.   Fix Propagate the `op_instance` argument to the internal `PrepareTensorForShape` call. Tested that a >1000 node graph completed with no issues. Add unit test coverage to prevent this issue from happening again.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,aboubezari,[TF-TRT] Fix repeated layer name bug," Issue When there are multiple invocations of `SqueezeTensor` in a layer, the converter will complain:   This happens despite passing `op_instance` to `SqueezeTensor`. The root cause is `op_instance` not being propagated to `PrepareTensorForShape`.   Fix Propagate the `op_instance` argument to the internal `PrepareTensorForShape` call. Tested that a >1000 node graph completed with no issues. Add unit test coverage to prevent this issue from happening again.",2023-03-20T16:17:26Z,ready to pull size:XS comp:gpu:tensorrt,closed,0,13,https://github.com/tensorflow/tensorflow/issues/60045, thanks for the PR! Good catch. Would you mind adding one tiny unittest that shows without your fix it fails and with your fix it works? That way I can merge it and make sure it doesn't happen again,">  thanks for the PR! Good catch. >  > Would you mind adding one tiny unittest that shows without your fix it fails and with your fix it works? That way I can merge it and make sure it doesn't happen again I'm working on building the unittests properly on my machine, will get back to you, thanks"," I tried reproducing the issue on `convert_nodes_test.cc`, but I'm realizing that this is not a conversiontime error, but this is something that happens when we attempt to execute the engine at inference time, so the UT is not useful at the moment.  Since this is a lowrisk change, what do you think about merging it as is? ","    friendly ping here, what do we think is the best next step forward?","> I tried reproducing the issue on convert_nodes_test.cc, but I'm realizing that this is not a conversiontime error, but this is something that happens when we attempt to execute the engine at inference time, so the UT is not useful at the moment. TFTRT code is not executed at runtime. There is conversion aka. segmentation time and engine build time (which happens prior the first execution). It should still be possible to write a unittest. If you can identify which layer is leading to the problem, we should be able to replicate very simply with a unittest. Indeed the problem is fairly simple and low risk, however it is of good practice to merge a change/bugfix with a unittest :) If you are not able to write the unittest please provide a 12 layers networks that shows the issues. Don't forget to set `minimum_segment_size=1` Feel free to use this template to show us the problem: ","Hey ,  I wanted to confirm whether this is an inference time error not, so I reran my own test case with a custom layer.  As you can see below, the engine is created successfully, and when we execute the tensorrt network created by the converter, the inference fails in tensorrt and falls back to the native segment, which I don't want. With this change, the failure is resolved.  I am working on a reproducible error with native tensorflow components. Based on this, do you have recommendations on how to catch it in a unittest?  Here's the log: ","Actually, I do this conversion warning:   Let me keep trying to resurface this :) ","Ok, I realized what I was missing: I was not calling `BuildAndRun` in the unittest to actually build & test the network.  I've added the unittest and confirmed that it fails without my change and passes with it.      can we take one more look? It should be ready 👍 ", Unittest results  **Command**:   **With my change:**  **Without my change:**  ," quick ping, let me know if there's anything else, I think we're close here :) ",    another friendly ping :) Could we take a look please? We should be all good now with unittest coverage. ,"    one last ping for a while. I'm going on vacation for 23 weeks after today so would be great to take a look in that time, thanks!",LGTM approved
707,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in MatrixSquareRoot)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.13.0dev20230317  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in MatrixSquareRoot,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.13.0dev20230317  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-18T10:29:13Z,stat:awaiting response type:bug stale comp:ops TF 1.12,closed,0,10,https://github.com/tensorflow/tensorflow/issues/60035,"Hi , Thank you for reporting the issue! I was able to replicate the issue in Ubuntu 20.04. Please find the screenshot below. We are trying to dig deep into the issue, we'll update here soon.  !image Thank you!    ",I too replicated the same error as reported. ,"From the API document,   https://www.tensorflow.org/api_docs/python/tf/raw_ops/MatrixSquareRoot,  ""The input is a tensor of shape [..., M, M] whose innermost 2 dimensions form square matrices. "", The input does not form a square matries for innermost 2 dimensions.    ,  could you share more background info why you choose such shape input ? Thanks ","  Hi, I am a security researcher, and I was testing the TensorFlow API to ensure its security. Although the input shape may not be the expected input according to the documentation or the code, it can pose a security risk, as it can lead to a crash. Therefore, this kind of input need to be checked and reported with proper error message, instead of throwing a crash. I hope this answers your question. If you have any further inquiries or concerns, please do not hesitate to let me know.","Thanks a lot for the explain, .  It makes sense. I will take a look how to add this check.", Please don't file vulnerabilities on GitHub. Please consult https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md and follow rules for responsible disclosure.,"Hi  , The issue got resolved now with tfnightly(2.14.0dev20230514) and now TF is successfully able to raise the intended Error. Please refer to attached gist. Please check and confirm and let us know if we can close the issue as it resolved now. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
703,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in CholeskyGrad)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.13.0dev20230317  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shijy16,A check fail can be triggered in CholeskyGrad,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.13.0dev20230317  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-18T10:22:30Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/60034," Thank you for reporting this issue!   While reproducing the issue on colab using TF v2.11, I faced the following error log as the session crashed. Please find the gist here. Mar 26, 2023, 6:28:42 PM  WARNING:root:kernel b01c86be927343159125c491e703869b restarted Thank you!","Hi  , The issue has been resolved in Tf2.16v. Please refer attached gist.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1872,"以下是一个github上的tensorflow下的一个issue, 标题是( About Android calling TensorFlow Lite crash problem)， 内容是 ( 1. Problem overview   I recently reported an error when importing the Tensorflow Lite model using Android Studio, but I did not find the problem after searching. I hope you can help me. The following is the detailed information  2. System information     implementation 'org.tensorflow:tensorflowlite:2.11.0'     implementation 'org.tensorflow:tensorflowliteselecttfops:0.0.0nightly'     implementation 'org.tensorflow:tensorflowlitesupport:0.1.0'     implementation 'org.tensorflow:tensorflowlitemetadata:0.1.0'     Android 12.0 x86_64  3. Code       public MyModelRunner(Context context) throws IOException {               try {                   interpreter = new Interpreter(loadModelFile(context));               } catch (IOException e) {                   e.printStackTrace();               }           }     private MappedByteBuffer loadModelFile(Context context) throws IOException {         AssetFileDescriptor fileDescriptor = context.getAssets().openFd(""new_model.tflite"");         FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());         FileChannel fileChannel = inputStream.getChannel();         long startOffset = fileDescriptor.getStartOffset();         long declaredLength = fileDescriptor.getDeclaredLength();         return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);     }  4. (optional)  info / logs 20230317 18:02:45.343 2267022670 libc                    com.example.myproject01              A  Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 22670 (ple.myproject01), pid 22670 (ple.myproject01) 20230317 18:)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,polarbbb, About Android calling TensorFlow Lite crash problem," 1. Problem overview   I recently reported an error when importing the Tensorflow Lite model using Android Studio, but I did not find the problem after searching. I hope you can help me. The following is the detailed information  2. System information     implementation 'org.tensorflow:tensorflowlite:2.11.0'     implementation 'org.tensorflow:tensorflowliteselecttfops:0.0.0nightly'     implementation 'org.tensorflow:tensorflowlitesupport:0.1.0'     implementation 'org.tensorflow:tensorflowlitemetadata:0.1.0'     Android 12.0 x86_64  3. Code       public MyModelRunner(Context context) throws IOException {               try {                   interpreter = new Interpreter(loadModelFile(context));               } catch (IOException e) {                   e.printStackTrace();               }           }     private MappedByteBuffer loadModelFile(Context context) throws IOException {         AssetFileDescriptor fileDescriptor = context.getAssets().openFd(""new_model.tflite"");         FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());         FileChannel fileChannel = inputStream.getChannel();         long startOffset = fileDescriptor.getStartOffset();         long declaredLength = fileDescriptor.getDeclaredLength();         return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);     }  4. (optional)  info / logs 20230317 18:02:45.343 2267022670 libc                    com.example.myproject01              A  Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0xfffffff4 in tid 22670 (ple.myproject01), pid 22670 (ple.myproject01) 20230317 18:",2023-03-17T10:43:59Z,stat:awaiting response type:support stale comp:lite TFLiteConverter TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/60030,"Hi  Thanks for reporting the issue. Can you confirm the model is in `Assets` folder.  Please check this relevant thread  CC(A/libc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xb9124f40 in tid 9093 (superresolution), pid 9093 (superresolution)) and see if t helps. If not, can you please provide the steps you have followed to encounter issue. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1661,"以下是一个github上的tensorflow下的一个issue, 标题是(Reduce MKL overheads on small shapes by not rewriting node to use MKL)， 内容是 (We observed that when you run networks that have layers with smaller input and overall lower compute density overhead into MKL path dominates useful compute so in that case it is better to call default, Eigen, path. This patch introduces changes to MKL layout pass where a liner analytical model is used to decide based on compute density and number of threads to either rewrite node to use MKL code path or leave it as it is. It propagates input shapes of the operation by decorating node with _input_shapes attribute number of threads used to parallelise operation by reading it from device on which operation is expected to execute (in this case CPUDevice) which, are then retrived in MKL layout pass and passed to the analytical model. With this approach we have observed speedup for models available on TFHub as shown in the two attached graphs when running with 8 and 16 cores on NeoverseV1 platform. Before shows results without this patch and after shows results with the patch relative when same models are ran with TF_ENABLE_ONEDNN_OPTS=0. Overall for 8 cores we see ~1.2x average speedup over TF_ENABLE_ONEDNN_OPTS=0 for 8 cores and ~1.12x for 16 cores. !8cores_results !16cores_results In addition to analytical model improvements for convolution, fused convolution, fused batch normalisation and swish, this patch also moves code for merging sigmoid and multiplication from remapper... cc:   )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,milpuz01,Reduce MKL overheads on small shapes by not rewriting node to use MKL,"We observed that when you run networks that have layers with smaller input and overall lower compute density overhead into MKL path dominates useful compute so in that case it is better to call default, Eigen, path. This patch introduces changes to MKL layout pass where a liner analytical model is used to decide based on compute density and number of threads to either rewrite node to use MKL code path or leave it as it is. It propagates input shapes of the operation by decorating node with _input_shapes attribute number of threads used to parallelise operation by reading it from device on which operation is expected to execute (in this case CPUDevice) which, are then retrived in MKL layout pass and passed to the analytical model. With this approach we have observed speedup for models available on TFHub as shown in the two attached graphs when running with 8 and 16 cores on NeoverseV1 platform. Before shows results without this patch and after shows results with the patch relative when same models are ran with TF_ENABLE_ONEDNN_OPTS=0. Overall for 8 cores we see ~1.2x average speedup over TF_ENABLE_ONEDNN_OPTS=0 for 8 cores and ~1.12x for 16 cores. !8cores_results !16cores_results In addition to analytical model improvements for convolution, fused convolution, fused batch normalisation and swish, this patch also moves code for merging sigmoid and multiplication from remapper... cc:   ",2023-03-16T23:54:21Z,ready to pull comp:mkl size:L,closed,0,14,https://github.com/tensorflow/tensorflow/issues/60026,Hi  Can you please resolve conflicts? Thank you!,> Some more comments. I'll post more tomorrow. Sorry for the delay! Thanks . I have tried to address all your comments in https://github.com/tensorflow/tensorflow/pull/60026/commits/450f4feac896baa6b7d75d82b02973f73cf990b6,MKL Any feedback on this PR? Thank you!,"> MKL Any feedback on this PR? Thank you! , abuzaina, ,   do you maybe have any comments about the PR? Many thanks.","Hi, we have couple main concerns : 1. Moving the fusion to mkl_layout_pass is not a good idea. From design perspective, we should preferably do all fusions in remapper with proper ifdef INTEL_MKL and  IsMKLEnabled() checks.  2. oneDNN would be the right place to handle optimizations for processor (or instruction set) variations instead of adding in mkl_layout_pass. Both these changes applied for other fusions and primitives, can easily explode mkl_layout_pass code. ","Hi , thank you very much for your reply and the concerns that you have raised. I have couple of questions/comments that I have put below: > 1. Moving the fusion to mkl_layout_pass is not a good idea. From design perspective, we should preferably do all fusions in remapper with proper ifdef INTEL_MKL and  IsMKLEnabled() checks. I can see that there are few other fusions already present in `mkl_layout_pass` such as merging convolution with bias (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/mkl_layout_pass.ccL3048). Is there expectations that those fusions will also move to `remapper`? > Both these changes applied for other fusions and primitives, can easily explode mkl_layout_pass code. I think the same argument could be applied to `remapper` too as adding fusions there it will also make it explode in terms of code size? What influences decisions where graph rewriting pass should be? My impression was that lowering op to oneDNN should be in `mkl_layout_pass`, while fusion and other (highlevel?) optimisations should be in `remapper` that might benefit other lowlevel libraries (such as Eigen). > 2. oneDNN would be the right place to handle optimizations for processor (or instruction set) variations instead of adding in mkl_layout_pass. The optimisation that we are doing with heuristic here is that we are choosing between lowering operation to be executed using oneDNN (i.e. rewriting it to be _Mkl) or executing operation using Eigen library so that is not possible to do in oneDNN as that decision is made before a call is made to oneDNN. , do you think that it might be introducing a new layout pass for AArch64 that would be called instead of `mkl_layout_pass`. We are already seeing some divergence in terms of fusion or lowering ops to onedNN such as here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/grappler/optimizers/remapper.ccL4603 and https://github.com/tensorflow/tensorflow/pull/60723  Thanks, Milos.","Hi , right, you will see some fusions currently happening in mkl_layout_pass but they are very old (56 years old). They need to be moved to remapper whenever possible. All new fusions have been added to remapper. We also added a pattern_matcher in remapper, which is easy and convenient to define patterns. take a look here . It's easier to match patterns than with code. So, you can try using it to do all fusions in grappler. Using IsMKLEnabled() and ifdef in remapper seems ok. You can probably define another functions that does the conditions checks to fuse or not. So, I recommend keeping fusions in remapper. With respect to the logic to decide whether to use Mkl* version of the op or use Eigen, it's ok if you want to keep it in mkl_layout_pass as long as it doesn't affect Intel CPU code. But based on multiple HWs arch, it is easy to see it get complicated.  We typically try to use generic conditions for shape/size. ", Could you please add some unit tests.,Hi  Any update on this PR? Please. Thank you!,">  So, you can try using it to do all fusions in grappler. Using IsMKLEnabled() and ifdef in remapper seems ok. You can probably define another functions that does the conditions checks to fuse or not. So, I recommend keeping fusions in remapper. Thanks  for indepth explanation. I have now reverted the change and put back fusion back that was removed from the mapper. In order to be able to decide whether to fuse or not on AArch64 I have added new function as per your suggestion in a new header file `mkl_heuristics.h` that can check now whether we want to fuse or not and use it in remapper. The same function is also used in layout pass too when decision needs to be made there.  > With respect to the logic to decide whether to use Mkl* version of the op or use Eigen, it's ok if you want to keep it in mkl_layout_pass as long as it doesn't affect Intel CPU code.  All the code that we are added is either guarded by `DNNL_AARCH64_USE_ACL` or reverts to default behaviour so it doesn't affect Intel's CPU code.",">  Could you please add some unit tests. Thanks  for the comment. I have added new tests in `mkl_herustics_test.cc` to test method for calculating FLOPS and threshold. The rest of changes do not introduce any new behaviour that is not covered already by existing tests that are in tests for `remapper_test.cc` and `mkl_remapper_test.cc`. Furthermore, in this change PR: https://github.com/tensorflow/tensorflow/pull/60160 we have extended convolution benchmark to take into account rewriting of nodes using layout pass so that tests that we get best performance when running convolutions. ",> Could you please help fix PY+CPP Ubuntu CPU build failures? Sorry about this . I believe that commit a1f135e should fix the failures as ordering of included headers was not correct in `mkl_heuristics_test.cc`,Could you please help take a look at `//tensorflow/core/common_runtime/eager:context_test` failure?  I believe this comes from the changes in //tensorflow/core/common_runtime/optimize_function_graph_utils.cc. https://github.com/tensorflow/tensorflow/pull/60026/filesdiffcf5de83fc2a1e4038beb6f3994daae6bb9bc321f8eb05a6e125980ab4b598680R556R562,> Could you please help take a look at `//tensorflow/core/common_runtime/eager:context_test` failure? Thanks . Commit 2701cc4 should make the test to pass. I have restricted to only check for number of threads for intra op if it is local device because that is common path that is used when doing MKL layout pass. I have also moved to set it inside of `PreprocessAndPartitionGraph()` instead of `OptimizeFunctionGraph()` as MKL layout pass is called from former.
692,"以下是一个github上的tensorflow下的一个issue, 标题是(Saving Custom Model Not Working)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.0  Custom Code Yes  OS Platform and Distribution Colab Notebook  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,aecelaya,Saving Custom Model Not Working,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.0  Custom Code Yes  OS Platform and Distribution Colab Notebook  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-16T21:46:24Z,stat:awaiting response type:support comp:keras TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/60022,", If your model contains custom objects or custom layers then you need to define **get_config** and **from_config** methods in the Model. Then during model.save() you need to pass an argument to custom_objects with dictionary of custom objects. Please refer to attached source for a minimal example. You may also refer to the keras https://github.com/kerasteam/tfkeras/issues/64. Please try to recreate the model accordingly. Thanks!","Thank you for the reply! I tried what you suggested, but I still see the same error. For now, I can move forward without needing to save the model. I'll revisit this issue later. Thank you!",Are you satisfied with the resolution of your issue? Yes No
303,"以下是一个github上的tensorflow下的一个issue, 标题是(Clarifying language in the Breaking Changes section in RELEASE.md)， 内容是 (Clarifying language in the Breaking Changes section)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,joefernandez,Clarifying language in the Breaking Changes section in RELEASE.md,Clarifying language in the Breaking Changes section,2023-03-16T17:05:35Z,,closed,0,0,https://github.com/tensorflow/tensorflow/issues/60017
664,"以下是一个github上的tensorflow下的一个issue, 标题是(bug feedback)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,wangdadaba,bug feedback,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-16T07:52:30Z,stat:awaiting response type:bug stale comp:keras TF 2.8,closed,0,6,https://github.com/tensorflow/tensorflow/issues/60007,"  I was able to execute a given code without error on colab using TF v2.11 & TF v2.8. `model(x, training = fasle)` and `model.predict()` getting the same results. Could you please confirm the same and find the gist of 2.11 and 2.8 for reference. Thank you !","我猜测可能是gpu得问题，我关闭了gpu进行测试结果是正确的，当我开启了gpu之后，结果仍然有问题。我使用的是docker容器，网址https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow/tags  nvcr.io/nvidia/tensorflow:22.04tf2py3 . >  I was able to execute a given code without error on colab using TF v2.11 & TF v2.8. `model(x, training = fasle)` and `model.predict()` getting the same results. Could you please confirm the same and find the gist of 2.11 and 2.8 for reference. >  > Thank you ! I guessed that there might be a problem with the GPU, I turned off the GPU to test correctly, and when I turned on the GPU, the results are still problematic. I'm using a docker container with URLs ：https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow/tags  taf：nvcr.io/nvidia/tensorflow:22.04tf2py3 .",  I was able to get similar results on the GPU as well  on Colab using tf2.11. Please find the gist here  Could you please try the latest docker container(nvcr.io/nvidia/tensorflow:23.02tf2py3) and let us know if it still persists. Thank you !,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
352,"以下是一个github上的tensorflow下的一个issue, 标题是([tosa] Legalize tfl.Rsqrt to tosa.Rsqrt)， 内容是 ( [Simply as what the title is saying]  QI16 version seems is pending here: https://github.com/tensorflow/tensorflow/pull/58406)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Jerry-Ge,[tosa] Legalize tfl.Rsqrt to tosa.Rsqrt, [Simply as what the title is saying]  QI16 version seems is pending here: https://github.com/tensorflow/tensorflow/pull/58406,2023-03-16T00:35:52Z,awaiting review size:M,closed,0,1,https://github.com/tensorflow/tensorflow/issues/60005, gently remind of this patch for review : )
493,"以下是一个github上的tensorflow下的一个issue, 标题是([oneDNN] Fixing a failure in mkl_fused_batch_norm_op_test)， 内容是 (This PR fixes a failure in a test that was enabled recently by this PR. The reference values are slightly changed due to use of different gemmapi. That resulted in a one value mismatch. So we are updating the test by adding relative error tolerance.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gemma,mahmoud-abuzaina,[oneDNN] Fixing a failure in mkl_fused_batch_norm_op_test,This PR fixes a failure in a test that was enabled recently by this PR. The reference values are slightly changed due to use of different gemmapi. That resulted in a one value mismatch. So we are updating the test by adding relative error tolerance.,2023-03-15T16:36:03Z,ready to pull size:XS,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59999
1843,"以下是一个github上的tensorflow下的一个issue, 标题是(Strange Autograph Error)， 内容是 (Hey TFTeam/Community, I faced a strange error. First of all we whereable to workaround it by adapting the tensorflow.python.autograph.impl.api code.  Background:    Packaging our application with pyinstaller, using efficient detection. In development everything works as fine, after packaging wiht pyinstaller somehow the following tf_stack module breaks with the following error: Unable to cast Python instance to C++ type. (at least this is because it retrieved a None value) At the end of this post I attached the whole error trace (as json string):). If you go a little bit up in the errortrace you will find that this error occured at tensorflow.python.autograph.impl.api:436. At the with StacktraceMapper statement. So we had a look at this and found this here: !Pasted Graphic 4 When we printed the effective_source_map variable. When the error occured it was just None. When everything worked well it had a value that pointed to a tensorflow py file. (Have no idea what this is all about). And here things get very strange: I tried some parameters like multi_strategy and batch_size.  > When I used in my tests only 4 images for training it worked with a batch_size >= 2 and single_strategy in my packaged pyinstaller version.   > When I used more images I had to increase the batch_size, elsewise the error occured again for example with 12 images I needed at last a batch_size of 3 with 24: 4 with 55 it worked with 10 (haven't tried below for the 55 image case).   > If I use multi Strategy and train on 3 Graphic cards everything works also very well. Only on single gpu I had to increase the batch_size. So our solution )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pokecheater,Strange Autograph Error,"Hey TFTeam/Community, I faced a strange error. First of all we whereable to workaround it by adapting the tensorflow.python.autograph.impl.api code.  Background:    Packaging our application with pyinstaller, using efficient detection. In development everything works as fine, after packaging wiht pyinstaller somehow the following tf_stack module breaks with the following error: Unable to cast Python instance to C++ type. (at least this is because it retrieved a None value) At the end of this post I attached the whole error trace (as json string):). If you go a little bit up in the errortrace you will find that this error occured at tensorflow.python.autograph.impl.api:436. At the with StacktraceMapper statement. So we had a look at this and found this here: !Pasted Graphic 4 When we printed the effective_source_map variable. When the error occured it was just None. When everything worked well it had a value that pointed to a tensorflow py file. (Have no idea what this is all about). And here things get very strange: I tried some parameters like multi_strategy and batch_size.  > When I used in my tests only 4 images for training it worked with a batch_size >= 2 and single_strategy in my packaged pyinstaller version.   > When I used more images I had to increase the batch_size, elsewise the error occured again for example with 12 images I needed at last a batch_size of 3 with 24: 4 with 55 it worked with 10 (haven't tried below for the 55 image case).   > If I use multi Strategy and train on 3 Graphic cards everything works also very well. Only on single gpu I had to increase the batch_size. So our solution ",2023-03-15T13:17:16Z,stat:awaiting response stale comp:autograph,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59996,", In order to expedite the troubleshooting process, could you please provide a complete code and the TensorFlow version you are using. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Dear , Thank you for your response regarding my earlier request. I appreciate your suggestion to provide a simplified code example. However, I must reiterate that this error occurred in a highly complex application built on top of TensorFlow, and providing a full code example would take weeks due to the intricacies involved. Nonetheless, I wanted to bring this error to your attention because we were able to fix it by adapting the TensorFlow code itself. While this error has low priority for us because we were able to find a workaround, it could still be a significant issue for other users who do not have the same resources or expertise. As I mentioned earlier, we believe that this error is related to packaging with PyInstaller and how the CurrentModuleFilter() method references modules. It would be extremely helpful if TensorFlow could provide more detailed documentation or even a dedicated feature to help users avoid this error in the future. Thank you for your time and attention to this matter.  Best regards",", Apologies for the delay. Without the reproducible code, it would be difficult for us to debug the issue. In order to expedite the troubleshooting process, could you please provide a minimal code snippet and the TensorFlow version you are using.  Also could you please try to execute the below code before the main code, which might work in some cases.  https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter experimental_op_resolver_type   Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Closing this as stale. Please reopen if this is still a valid request. Thank you!
697,"以下是一个github上的tensorflow下的一个issue, 标题是(S3_USE_HTTPS 0 is being ignored - TF insists on HTTPS)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution cos_containerd  Mobile device _No response_  Python version 3.9.2  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,edi-bice,S3_USE_HTTPS 0 is being ignored - TF insists on HTTPS,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution cos_containerd  Mobile device _No response_  Python version 3.9.2  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-14T18:56:03Z,type:bug comp:cloud TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59990,"Hi bice,  Setting `os.environ['S3_USE_HTTPS'] = '0'` in TensorFlow can cause an error because TensorFlow by default uses HTTPS to communicate with S3. If you set S3_USE_HTTPS to '0', you are telling TensorFlow to use plain HTTP to communicate with S3, which can cause a security issue because the traffic is not encrypted and can be intercepted and modified by attackers. Additionally, some S3 endpoints may not even allow nonHTTPS connections, so setting S3_USE_HTTPS to '0' could result in connection failures or other errors. Therefore, it is generally not recommended to set S3_USE_HTTPS to '0' in TensorFlow. Thank you!", agree completely but should have made it clearer that this is TF running in TFX/KFP pipelines on Kubeflow accessing its clusterlocal Minio storage via S3 protocol etc. Minio is bundled with Kubeflow and at least the gcpblueprint distribution seems to have it configured without SSL.,"On a different Kubeflow 1.6 deployment on GCP, it seems to be making request against http endpoint though regardless of the value in os.environ['S3_USE_HTTPS'] (whether 0 or 1) and regardless of os.environ['S3_ENDPOINT'] being '10.12.2.51:9000' or 'http://10.12.2.51:9000' as is reported by Minio pod logs. 20230315 12:26:40.083090: I tensorflow/c/logging.cc:34] Making request to http://10.12.2.51:9000/edi_bice/models/clientXYZ/model_arch/poisson_model/model_layers.json `20230315 12:26:30.063771: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.063836: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.063851: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.063857: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.063867: I tensorflow/c/logging.cc:34] Initializing config loader against fileName /home/jovyan/.aws/credentials and using profilePrefix = 0 20230315 12:26:30.063874: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.063879: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.063885: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.063890: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.063896: I tensorflow/c/logging.cc:34] Initializing config loader against fileName /home/jovyan/.aws/config and using profilePrefix = 1 20230315 12:26:30.063902: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.063907: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.063913: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.063918: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.063948: I tensorflow/c/logging.cc:34] Unable to open config file /home/jovyan/.aws/credentials for reading. 20230315 12:26:30.063955: I tensorflow/c/logging.cc:34] Failed to reload configuration. 20230315 12:26:30.063961: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.063970: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.063979: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.063988: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.064001: I tensorflow/c/logging.cc:34] Unable to open config file /home/jovyan/.aws/config for reading. 20230315 12:26:30.064010: I tensorflow/c/logging.cc:34] Failed to reload configuration. 20230315 12:26:30.064042: I tensorflow/c/logging.cc:34] Initializing Curl library with version: 7.85.0, ssl version: BoringSSL 20230315 12:26:30.064059: I tensorflow/c/logging.cc:34] ClientConfiguration will use SDK Auto Resolved profile: [default] if not specified by users. 20230315 12:26:30.064080: W tensorflow/c/logging.cc:37] Retry Strategy will use the default max attempts. 20230315 12:26:30.064096: I tensorflow/c/logging.cc:34] Creating AWSHttpResourceClient with max connections 2 and scheme http 20230315 12:26:30.064108: I tensorflow/c/logging.cc:34] Initializing CurlHandleContainer with size 2 20230315 12:26:30.064128: I tensorflow/c/logging.cc:34] ClientConfiguration will use SDK Auto Resolved profile: [default] if not specified by users. 20230315 12:26:30.064139: W tensorflow/c/logging.cc:37] Retry Strategy will use the default max attempts. 20230315 12:26:30.064164: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.064176: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.064187: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.064196: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.064207: I tensorflow/c/logging.cc:34] Initializing config loader against fileName /home/jovyan/.aws/credentials and using profilePrefix = 0 20230315 12:26:30.064218: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.064227: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.064237: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.064250: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.064261: I tensorflow/c/logging.cc:34] Checking HOME for the home directory. 20230315 12:26:30.064271: I tensorflow/c/logging.cc:34] Environment value for variable HOME is /home/jovyan 20230315 12:26:30.064280: I tensorflow/c/logging.cc:34] Home directory is missing the final / appending one to normalize 20230315 12:26:30.064288: I tensorflow/c/logging.cc:34] Final Home Directory is /home/jovyan/ 20230315 12:26:30.064301: I tensorflow/c/logging.cc:34] Setting provider to read credentials from /home/jovyan/.aws/credentials for credentials file and /home/jovyan/.aws/config for the config file , for use with profile default 20230315 12:26:30.064314: I tensorflow/c/logging.cc:34] Setting process credentials provider to read config from default 20230315 12:26:30.064332: W tensorflow/c/logging.cc:37] Token file must be specified to use STS AssumeRole web identity creds provider. 20230315 12:26:30.064344: I tensorflow/c/logging.cc:34] Setting sso credentials provider to read config from default 20230315 12:26:30.064357: I tensorflow/c/logging.cc:34] The environment variable value AWS_CONTAINER_CREDENTIALS_RELATIVE_URI is  20230315 12:26:30.064366: I tensorflow/c/logging.cc:34] The environment variable value AWS_CONTAINER_CREDENTIALS_FULL_URI is  20230315 12:26:30.064375: I tensorflow/c/logging.cc:34] The environment variable value AWS_EC2_METADATA_DISABLED is  20230315 12:26:30.064386: I tensorflow/c/logging.cc:34] ClientConfiguration will use SDK Auto Resolved profile: [default] if not specified by users. 20230315 12:26:30.064397: W tensorflow/c/logging.cc:37] Retry Strategy will use the default max attempts. 20230315 12:26:30.064409: I tensorflow/c/logging.cc:34] Creating AWSHttpResourceClient with max connections 2 and scheme http 20230315 12:26:30.064419: I tensorflow/c/logging.cc:34] Initializing CurlHandleContainer with size 2 20230315 12:26:30.064430: I tensorflow/c/logging.cc:34] Creating Instance with default EC2MetadataClient and refresh rate 300000 20230315 12:26:30.064448: I tensorflow/c/logging.cc:34] Added EC2 metadata service credentials provider to the provider chain. 20230315 12:26:30.064477: I tensorflow/c/logging.cc:34] Found credential in environment with access key id minio 20230315 12:26:30.064491: I tensorflow/c/logging.cc:34] Found secret key 20230315 12:26:30.064547: I tensorflow/c/logging.cc:34] Initializing CurlHandleContainer with size 25 20230315 12:26:30.064729: I tensorflow/c/logging.cc:34] No content body, contentlength headers 20230315 12:26:30.064795: I tensorflow/c/logging.cc:34] Found credential in environment with access key id minio 20230315 12:26:30.064811: I tensorflow/c/logging.cc:34] Found secret key 20230315 12:26:30.064824: I tensorflow/c/logging.cc:34] Using cached empty string sha256 e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 because payload is empty. 20230315 12:26:30.064870: I tensorflow/c/logging.cc:34] Canonical Header String: amzsdkinvocationid:CD99676793DA4B24AC07CF3DBD6AC7A3 amzsdkrequest:attempt=1 contenttype:application/xml host:10.12.2.51:9000 xamzapiversion:20060301 xamzcontentsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 xamzdate:20230315T122630Z 20230315 12:26:30.064883: I tensorflow/c/logging.cc:34] Signed Headers value:amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate 20230315 12:26:30.064913: I tensorflow/c/logging.cc:34] Canonical Request String: HEAD /edi_bice/models/clientXYZ/model_arch/poisson_model/model_layers.json amzsdkinvocationid:CD99676793DA4B24AC07CF3DBD6AC7A3 amzsdkrequest:attempt=1 contenttype:application/xml host:10.12.2.51:9000 xamzapiversion:20060301 xamzcontentsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 xamzdate:20230315T122630Z amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 20230315 12:26:30.064938: I tensorflow/c/logging.cc:34] Final String to sign: AWS4HMACSHA256 20230315T122630Z 20230315/useast1/s3/aws4_request e3cae3b1a464d54b492c8a1e21c4a99785ea29c76e307538f7af5db540f48360 20230315 12:26:30.064952: I tensorflow/c/logging.cc:34] Final computed signing hash: 89accf1cc9a4a9570c50324fa82195ca53aaae9764b2c70bdbafec1fe976609f 20230315 12:26:30.064965: I tensorflow/c/logging.cc:34] Signing request with: AWS4HMACSHA256 Credential=minio/20230315/useast1/s3/aws4_request, SignedHeaders=amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate, Signature=89accf1cc9a4a9570c50324fa82195ca53aaae9764b2c70bdbafec1fe976609f 20230315 12:26:30.064977: I tensorflow/c/logging.cc:34] Request Successfully signed 20230315 12:26:30.064997: I tensorflow/c/logging.cc:34] Making request to http://10.12.2.51:9000/edi_bice/models/clientXYZ/model_arch/poisson_model/model_layers.json 20230315 12:26:30.065011: I tensorflow/c/logging.cc:34] Including headers: 20230315 12:26:30.065021: I tensorflow/c/logging.cc:34] amzsdkinvocationid: CD99676793DA4B24AC07CF3DBD6AC7A3 20230315 12:26:30.065032: I tensorflow/c/logging.cc:34] amzsdkrequest: attempt=1 20230315 12:26:30.065042: I tensorflow/c/logging.cc:34] authorization: AWS4HMACSHA256 Credential=minio/20230315/useast1/s3/aws4_request, SignedHeaders=amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate, Signature=89accf1cc9a4a9570c50324fa82195ca53aaae9764b2c70bdbafec1fe976609f 20230315 12:26:30.065052: I tensorflow/c/logging.cc:34] contenttype: application/xml 20230315 12:26:30.065063: I tensorflow/c/logging.cc:34] host: 10.12.2.51:9000 20230315 12:26:30.065073: I tensorflow/c/logging.cc:34] useragent: awssdkcpp/1.8.186 Linux/5.15.01024gke x86_64 GCC/7.3.1 20230315 12:26:30.065082: I tensorflow/c/logging.cc:34] xamzapiversion: 20060301 20230315 12:26:30.065091: I tensorflow/c/logging.cc:34] xamzcontentsha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 20230315 12:26:30.065100: I tensorflow/c/logging.cc:34] xamzdate: 20230315T122630Z 20230315 12:26:30.065111: I tensorflow/c/logging.cc:34] Attempting to acquire curl connection. 20230315 12:26:30.065119: I tensorflow/c/logging.cc:34] No current connections available in pool. Attempting to create new connections. 20230315 12:26:30.065128: I tensorflow/c/logging.cc:34] attempting to grow pool size by 2 20230315 12:26:30.065153: I tensorflow/c/logging.cc:34] Pool grown by 2 20230315 12:26:30.065166: I tensorflow/c/logging.cc:34] Connection has been released. Continuing. 20230315 12:26:30.065177: I tensorflow/c/logging.cc:34] Returning connection handle 0x557f0495ca40 20230315 12:26:30.065186: I tensorflow/c/logging.cc:34] Obtained connection handle 0x557f0495ca40 20230315 12:26:40.081483: I tensorflow/c/logging.cc:34] HTTP/1.1 503 Service Unavailable 20230315 12:26:40.081573: I tensorflow/c/logging.cc:34] contentlength: 91 20230315 12:26:40.081592: I tensorflow/c/logging.cc:34] contenttype: text/plain 20230315 12:26:40.081603: I tensorflow/c/logging.cc:34] date: Wed, 15 Mar 2023 12:26:39 GMT 20230315 12:26:40.081612: I tensorflow/c/logging.cc:34] server: envoy 20230315 12:26:40.081620: I tensorflow/c/logging.cc:34]  20230315 12:26:40.081647: I tensorflow/c/logging.cc:34] Returned http response code 503 20230315 12:26:40.081655: I tensorflow/c/logging.cc:34] Returned content type text/plain 20230315 12:26:40.081661: I tensorflow/c/logging.cc:34] Releasing curl handle 0x557f0495ca40 20230315 12:26:40.081680: I tensorflow/c/logging.cc:34] Releasing curl handle 0x557f0495ca40 20230315 12:26:40.081689: I tensorflow/c/logging.cc:34] Notified waiting threads. 20230315 12:26:40.081713: I tensorflow/c/logging.cc:34] Request returned error. Attempting to generate appropriate error codes from response 20230315 12:26:40.081737: E tensorflow/c/logging.cc:40] HTTP response code: 503 Resolved remote host IP address:  Request ID:  Exception name:  Error message: No response body. 4 response headers: contentlength : 91 contenttype : text/plain date : Wed, 15 Mar 2023 12:26:39 GMT server : envoy 20230315 12:26:40.081762: W tensorflow/c/logging.cc:37] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer. 20230315 12:26:40.081771: I tensorflow/c/logging.cc:34] Server time is Wed, 15 Mar 2023 12:26:39 GMT, while client time is Wed, 15 Mar 2023 12:26:40 GMT 20230315 12:26:40.081778: W tensorflow/c/logging.cc:37] Request failed, now waiting 0 ms before attempting again.`","Same code (and library versions) seems to work on Kubeflow 1.5 deployed on GCP via gcpblueprints `20230314 21:59:13.723573: I tensorflow/c/logging.cc:34] No content body, contentlength headers 20230314 21:59:13.723658: I tensorflow/c/logging.cc:34] Found credential in environment with access key id minio 20230314 21:59:13.723680: I tensorflow/c/logging.cc:34] Found secret key 20230314 21:59:13.723696: I tensorflow/c/logging.cc:34] Using cached empty string sha256 e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 because payload is empty. 20230314 21:59:13.723766: I tensorflow/c/logging.cc:34] Canonical Header String: amzsdkinvocationid:5D5AC5F050914804A1BEEE45C33DAC84 amzsdkrequest:attempt=1 contenttype:application/xml host:10.12.2.51:9000 xamzapiversion:20060301 xamzcontentsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 xamzdate:20230314T215913Z 20230314 21:59:13.723792: I tensorflow/c/logging.cc:34] Signed Headers value:amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate 20230314 21:59:13.723830: I tensorflow/c/logging.cc:34] Canonical Request String: HEAD /edi_bice/models/clientXYZ/model_arch/poisson_model/model_layers.json amzsdkinvocationid:5D5AC5F050914804A1BEEE45C33DAC84 amzsdkrequest:attempt=1 contenttype:application/xml host:10.12.2.51:9000 xamzapiversion:20060301 xamzcontentsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 xamzdate:20230314T215913Z amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 20230314 21:59:13.723874: I tensorflow/c/logging.cc:34] Final String to sign: AWS4HMACSHA256 20230314T215913Z 20230314/useast1/s3/aws4_request 1238bfb28a22deb82193ab1d9129bc2f72feaf1e511c934ff9912ff3f5ff759a 20230314 21:59:13.723911: I tensorflow/c/logging.cc:34] Final computed signing hash: 9aff3e1cfabe7f6bdabb78953a14b1d3da73a4ea72035a8da890706f7f115c4d 20230314 21:59:13.723931: I tensorflow/c/logging.cc:34] Signing request with: AWS4HMACSHA256 Credential=minio/20230314/useast1/s3/aws4_request, SignedHeaders=amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate, Signature=9aff3e1cfabe7f6bdabb78953a14b1d3da73a4ea72035a8da890706f7f115c4d 20230314 21:59:13.723956: I tensorflow/c/logging.cc:34] Request Successfully signed 20230314 21:59:13.723986: I tensorflow/c/logging.cc:34] Making request to http://10.12.2.51:9000/edi_bice/models/clientXYZ/model_arch/poisson_model/model_layers.json 20230314 21:59:13.724013: I tensorflow/c/logging.cc:34] Including headers: 20230314 21:59:13.724031: I tensorflow/c/logging.cc:34] amzsdkinvocationid: 5D5AC5F050914804A1BEEE45C33DAC84 20230314 21:59:13.724054: I tensorflow/c/logging.cc:34] amzsdkrequest: attempt=1 20230314 21:59:13.724069: I tensorflow/c/logging.cc:34] authorization: AWS4HMACSHA256 Credential=minio/20230314/useast1/s3/aws4_request, SignedHeaders=amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate, Signature=9aff3e1cfabe7f6bdabb78953a14b1d3da73a4ea72035a8da890706f7f115c4d 20230314 21:59:13.724085: I tensorflow/c/logging.cc:34] contenttype: application/xml 20230314 21:59:13.724108: I tensorflow/c/logging.cc:34] host: 10.12.2.51:9000 20230314 21:59:13.724124: I tensorflow/c/logging.cc:34] useragent: awssdkcpp/1.8.186 Linux/5.4.217+ x86_64 GCC/7.3.1 20230314 21:59:13.724137: I tensorflow/c/logging.cc:34] xamzapiversion: 20060301 20230314 21:59:13.724161: I tensorflow/c/logging.cc:34] xamzcontentsha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 20230314 21:59:13.724177: I tensorflow/c/logging.cc:34] xamzdate: 20230314T215913Z 20230314 21:59:13.724200: I tensorflow/c/logging.cc:34] Attempting to acquire curl connection. 20230314 21:59:13.724216: I tensorflow/c/logging.cc:34] Connection has been released. Continuing. 20230314 21:59:13.724241: I tensorflow/c/logging.cc:34] Returning connection handle 0x55d7fe080310 20230314 21:59:13.724542: I tensorflow/c/logging.cc:34] Obtained connection handle 0x55d7fe080310 20230314 21:59:13.798382: I tensorflow/c/logging.cc:34] HTTP/1.1 200 OK 20230314 21:59:13.798456: I tensorflow/c/logging.cc:34] acceptranges: bytes 20230314 21:59:13.798481: I tensorflow/c/logging.cc:34] contentlength: 717 20230314 21:59:13.798505: I tensorflow/c/logging.cc:34] contentsecuritypolicy: blockallmixedcontent 20230314 21:59:13.798525: I tensorflow/c/logging.cc:34] contenttype: application/json 20230314 21:59:13.798546: I tensorflow/c/logging.cc:34] etag: ""a88e35987284c3a006ee88c43f902a7a"" 20230314 21:59:13.798635: I tensorflow/c/logging.cc:34] lastmodified: Thu, 04 Feb 2021 19:21:01 GMT 20230314 21:59:13.798665: I tensorflow/c/logging.cc:34] server: istioenvoy 20230314 21:59:13.798684: I tensorflow/c/logging.cc:34] vary: Origin 20230314 21:59:13.798703: I tensorflow/c/logging.cc:34] xamzrequestid: 174C680A1BEFE503 20230314 21:59:13.798722: I tensorflow/c/logging.cc:34] xxssprotection: 1; mode=block 20230314 21:59:13.798743: I tensorflow/c/logging.cc:34] date: Tue, 14 Mar 2023 21:59:13 GMT 20230314 21:59:13.798764: I tensorflow/c/logging.cc:34] xenvoyupstreamservicetime: 68 20230314 21:59:13.798789: I tensorflow/c/logging.cc:34] xenvoydecoratoroperation: minioservice.kubeflow.svc.cluster.local:9000/* 20230314 21:59:13.798849: I tensorflow/c/logging.cc:34]  20230314 21:59:13.798892: I tensorflow/c/logging.cc:34] Returned http response code 200 20230314 21:59:13.798919: I tensorflow/c/logging.cc:34] Returned content type application/json 20230314 21:59:13.798939: I tensorflow/c/logging.cc:34] Releasing curl handle 0x55d7fe080310 20230314 21:59:13.798964: I tensorflow/c/logging.cc:34] Releasing curl handle 0x55d7fe080310 20230314 21:59:13.799030: I tensorflow/c/logging.cc:34] Notified waiting threads. 20230314 21:59:13.799069: I tensorflow/c/logging.cc:34] Request returned successful response. 20230314 21:59:13.799099: I tensorflow/c/logging.cc:34] Request successful returning. 20230314 21:59:13.799232: I tensorflow/c/logging.cc:34] No content body, contentlength headers 20230314 21:59:13.799291: I tensorflow/c/logging.cc:34] Found credential in environment with access key id minio 20230314 21:59:13.799315: I tensorflow/c/logging.cc:34] Found secret key 20230314 21:59:13.799331: I tensorflow/c/logging.cc:34] Using cached empty string sha256 e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 because payload is empty. 20230314 21:59:13.799428: I tensorflow/c/logging.cc:34] Canonical Header String: amzsdkinvocationid:6E5C4870932F495A8CA3BA80DEC0DB7A amzsdkrequest:attempt=1 contenttype:application/xml host:10.12.2.51:9000 xamzapiversion:20060301 xamzcontentsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 xamzdate:20230314T215913Z 20230314 21:59:13.799458: I tensorflow/c/logging.cc:34] Signed Headers value:amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate 20230314 21:59:13.799510: I tensorflow/c/logging.cc:34] Canonical Request String: GET /edi_bice listtype=2&maxkeys=1&prefix=models0.000000clientXYZ0.000000model_arch0.000000poisson_model0.000000model_layers.json0.000000 amzsdkinvocationid:6E5C4870932F495A8CA3BA80DEC0DB7A amzsdkrequest:attempt=1 contenttype:application/xml host:10.12.2.51:9000 xamzapiversion:20060301 xamzcontentsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 xamzdate:20230314T215913Z amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 20230314 21:59:13.799561: I tensorflow/c/logging.cc:34] Final String to sign: AWS4HMACSHA256 20230314T215913Z 20230314/useast1/s3/aws4_request 47c1d82682b93d2b38c74ff49c8d39ea99c2a055e73ae8713f12cfe941631e4b 20230314 21:59:13.799581: I tensorflow/c/logging.cc:34] Final computed signing hash: 0e2b24c44f0bb058d251d2bddaab0f002dcaf531a9ca48bbafe2ea1d6a45ec1b 20230314 21:59:13.799607: I tensorflow/c/logging.cc:34] Signing request with: AWS4HMACSHA256 Credential=minio/20230314/useast1/s3/aws4_request, SignedHeaders=amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate, Signature=0e2b24c44f0bb058d251d2bddaab0f002dcaf531a9ca48bbafe2ea1d6a45ec1b 20230314 21:59:13.799634: I tensorflow/c/logging.cc:34] Request Successfully signed 20230314 21:59:13.799666: I tensorflow/c/logging.cc:34] Making request to http://10.12.2.51:9000/edi_bice?listtype=2&maxkeys=1&prefix=models0.000000clientXYZ0.000000model_arch0.000000poisson_model0.000000model_layers.json0.000000 20230314 21:59:13.799743: I tensorflow/c/logging.cc:34] Including headers: 20230314 21:59:13.799805: I tensorflow/c/logging.cc:34] amzsdkinvocationid: 6E5C4870932F495A8CA3BA80DEC0DB7A 20230314 21:59:13.799846: I tensorflow/c/logging.cc:34] amzsdkrequest: attempt=1 20230314 21:59:13.799896: I tensorflow/c/logging.cc:34] authorization: AWS4HMACSHA256 Credential=minio/20230314/useast1/s3/aws4_request, SignedHeaders=amzsdkinvocationid;amzsdkrequest;contenttype;host;xamzapiversion;xamzcontentsha256;xamzdate, Signature=0e2b24c44f0bb058d251d2bddaab0f002dcaf531a9ca48bbafe2ea1d6a45ec1b 20230314 21:59:13.800022: I tensorflow/c/logging.cc:34] contenttype: application/xml 20230314 21:59:13.800108: I tensorflow/c/logging.cc:34] host: 10.12.2.51:9000 20230314 21:59:13.800226: I tensorflow/c/logging.cc:34] useragent: awssdkcpp/1.8.186 Linux/5.4.217+ x86_64 GCC/7.3.1 20230314 21:59:13.800283: I tensorflow/c/logging.cc:34] xamzapiversion: 20060301 20230314 21:59:13.800301: I tensorflow/c/logging.cc:34] xamzcontentsha256: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855 20230314 21:59:13.800315: I tensorflow/c/logging.cc:34] xamzdate: 20230314T215913Z 20230314 21:59:13.800344: I tensorflow/c/logging.cc:34] Attempting to acquire curl connection. 20230314 21:59:13.800640: I tensorflow/c/logging.cc:34] Connection has been released. Continuing. 20230314 21:59:13.800677: I tensorflow/c/logging.cc:34] Returning connection handle 0x55d7fe080310 20230314 21:59:13.800793: I tensorflow/c/logging.cc:34] Obtained connection handle 0x55d7fe080310 20230314 21:59:13.878099: I tensorflow/c/logging.cc:34] HTTP/1.1 200 OK 20230314 21:59:13.878238: I tensorflow/c/logging.cc:34] acceptranges: bytes 20230314 21:59:13.878309: I tensorflow/c/logging.cc:34] contentlength: 319 20230314 21:59:13.878331: I tensorflow/c/logging.cc:34] contentsecuritypolicy: blockallmixedcontent 20230314 21:59:13.878356: I tensorflow/c/logging.cc:34] contenttype: application/xml 20230314 21:59:13.878371: I tensorflow/c/logging.cc:34] server: istioenvoy 20230314 21:59:13.878396: I tensorflow/c/logging.cc:34] vary: Origin 20230314 21:59:13.878411: I tensorflow/c/logging.cc:34] xamzrequestid: 174C680A2038EBCD 20230314 21:59:13.878427: I tensorflow/c/logging.cc:34] xxssprotection: 1; mode=block 20230314 21:59:13.878451: I tensorflow/c/logging.cc:34] date: Tue, 14 Mar 2023 21:59:13 GMT 20230314 21:59:13.878470: I tensorflow/c/logging.cc:34] xenvoyupstreamservicetime: 75 20230314 21:59:13.878495: I tensorflow/c/logging.cc:34] xenvoydecoratoroperation: minioservice.kubeflow.svc.cluster.local:9000/* 20230314 21:59:13.878510: I tensorflow/c/logging.cc:34]  20230314 21:59:13.878530: I tensorflow/c/logging.cc:34] 319 bytes written to response. 20230314 21:59:13.878573: I tensorflow/c/logging.cc:34] Returned http response code 200 20230314 21:59:13.878594: I tensorflow/c/logging.cc:34] Returned content type application/xml 20230314 21:59:13.878608: I tensorflow/c/logging.cc:34] Response contentlength header: 319 20230314 21:59:13.878621: I tensorflow/c/logging.cc:34] Response body length: 319 20230314 21:59:13.878644: I tensorflow/c/logging.cc:34] Releasing curl handle 0x55d7fe080310 20230314 21:59:13.878665: I tensorflow/c/logging.cc:34] Releasing curl handle 0x55d7fe080310 20230314 21:59:13.878687: I tensorflow/c/logging.cc:34] Notified waiting threads. 20230314 21:59:13.878711: I tensorflow/c/logging.cc:34] Request returned successful response. 20230314 21:59:13.878731: I tensorflow/c/logging.cc:34] Request successful returning.`",Are you satisfied with the resolution of your issue? Yes No
757,"以下是一个github上的tensorflow下的一个issue, 标题是(Using Teachable Machine to make a Audio model for Python)， 内容是 (I have been trying to make an AI model that will listen to user input. Depending on the user's input/command the program will carry out functions etc. I am trying to use a model I have trained from the teachable machine, but the model is not in a format that can be used in Python. From what I have seen Python requires a .h5. However, TFLite.js is only available to export/download in. When I try to use this in my program I get hit with errors. What steps can I take to import an Audio model for a Python system?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,setter43,Using Teachable Machine to make a Audio model for Python,"I have been trying to make an AI model that will listen to user input. Depending on the user's input/command the program will carry out functions etc. I am trying to use a model I have trained from the teachable machine, but the model is not in a format that can be used in Python. From what I have seen Python requires a .h5. However, TFLite.js is only available to export/download in. When I try to use this in my program I get hit with errors. What steps can I take to import an Audio model for a Python system?",2023-03-14T13:16:00Z,stat:awaiting response type:support stale comp:lite,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59985,", For Simple audio recognition and Audio classification, there are prebuilt models available on the official tensorflow.org.  The model demonstrates how to preprocess audio files in the WAV format and build and train a basic automatic speech recognition (ASR) model for recognizing ten different words. Also I tried to execute the demonstrated code for the Audio recognition which was executed successfully. Kindly find the gist of it here and the reference. https://www.tensorflow.org/tutorials/audio/simple_audio https://www.tensorflow.org/lite/examples/audio_classification/overviewget_started Thank you!","I want to use my own Audio classification AI model that I build using Teachable Machine. I run into a number of issues when trying to adapt the model.py in the git project keywordspotting. I can get the model working. Then I try to point the program to my own AI and it fails. `mendeljet:~/newtest/projectkeywordspotter$ python3 run_model.py model_file soundclassifier_with_metadata.tflite Traceback (most recent call last):   File ""run_model.py"", line 60, in      main()   File ""run_model.py"", line 50, in main     interpreter = model.make_interpreter(args.model_file)   File ""/home/mendel/newtest/projectkeywordspotter/model.py"", line 211, in make_interpreter     {'device': device[0]} if device else {})   File ""/usr/lib/python3/distpackages/tflite_runtime/interpreter.py"", line 351, in __init__     experimental_preserve_all_tensors)) ValueError: Could not open 'soundclassifier_with_metadata.tflite'. mendeljet:~/newtest/projectkeywordspotter$ `",", Could you please confirm whether you are using this teachable machine official link to make an audio model. https://teachablemachine.withgoogle.com/train/audio The pre trained lite models in TF hub provide metadata. However, you can add metadata given a tflite model using TFLIte meta data writer API. Please find the overview of adding metada here along with the examples. And also were you able to get the tflite file, if yes could you provide the code which you are using to test which helps to analyse. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"  Teachable Machine with Google gives you the option to download your model after it has been trained See for TensorFlow Keras  Click on it It would generate a zip file with the name converted_keras There would be 2 files in it: 1) 1 would be your trained model in .h5 format 2) 1 would be a simple text file with labels https://teachablemachine.withgoogle.com/train/audio Once check for your dataset, it's source and how you are uploading it to be trained My recommendation would be to create the dataset on your own",I am using Teachable Machine for my audio model. I don't have the option to export in .h5 for audio. Just .js or .tflite. tflite would be compatible with the google coral I am working with. But the sample app Git link just leads to an error and it's hard to find an example where I can take my AI model and just plug and play. !image,"Hi   Sorry for the delayed response. Under the hood Teachable Machine uses Tensorflow.js, a library for machine learning in Javascript, to train and run the models you make in your web browser as given here. The option to download `.h5` file might not be available yet. Could you please to this issue in  teachablemachinecommunity repo for faster resolution? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1874,"以下是一个github上的tensorflow下的一个issue, 标题是(`nan` while doing inference in C++ with half precision)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.7  Bazel version 6.1.0  GCC/Compiler version LLVM 12  CUDA/cuDNN version 11.6  GPU model and memory Tesla T4  Current Behaviour?   Standalone code to reproduce the issue  C++  shell 20230314 05:08:59.641765: I cc/scripts/play_model.cc:94] nan 20230314 05:08:59.641818: I cc/scripts/play_model.cc:95] nan 20230314 05:08:59.655568: I cc/scripts/play_model.cc:119]  Model Stats  20230314 05:08:59.655609: I cc/scripts/play_model.cc:120] Top Move: Loc(0, 0) 20230314 05:08:59.655621: I cc/scripts/play_model.cc:121] Win: nan Loss: nan 20230314 05:08:59.655677: I cc/scripts/play_model.cc:123] Board 0  ○ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 1  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 2  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 3  ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ 4  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 5  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 6  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 7  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 8  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 9  ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ 10 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 11 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 12 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 13 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 14 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 15 ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ 16 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 17 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 18 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅    A B C D E F G H I )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,p3achyjr,`nan` while doing inference in C++ with half precision,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device _No response_  Python version 3.7  Bazel version 6.1.0  GCC/Compiler version LLVM 12  CUDA/cuDNN version 11.6  GPU model and memory Tesla T4  Current Behaviour?   Standalone code to reproduce the issue  C++  shell 20230314 05:08:59.641765: I cc/scripts/play_model.cc:94] nan 20230314 05:08:59.641818: I cc/scripts/play_model.cc:95] nan 20230314 05:08:59.655568: I cc/scripts/play_model.cc:119]  Model Stats  20230314 05:08:59.655609: I cc/scripts/play_model.cc:120] Top Move: Loc(0, 0) 20230314 05:08:59.655621: I cc/scripts/play_model.cc:121] Win: nan Loss: nan 20230314 05:08:59.655677: I cc/scripts/play_model.cc:123] Board 0  ○ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 1  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 2  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 3  ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ 4  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 5  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 6  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 7  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 8  ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 9  ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ 10 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 11 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 12 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 13 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 14 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 15 ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ ⋅ ⋅ + ⋅ ⋅ ⋅ 16 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 17 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ 18 ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅ ⋅    A B C D E F G H I ",2023-03-14T05:41:15Z,type:bug TF 2.11,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59982,"   Thanks for reporting this issue. Looks like inputs are not being provided to the model's session.  Also, the minimal reproducible code for the issue is incomplete.  Can you please provide the steps you have followed and also did you try setting up the dtype policy to mixed_float16. Thanks.","Thanks for getting backthe dtype policy is set to mixed_float16 in python. Not sure how to do that in c++. I also ended up solving this as it turns out my tensors were not zeroinitialized. I wonder if there's a way to do that automatically? Also let me know if there is a better way to do half precision in C++, as right now I need to construct and run a graph to cast my tensors from float > half > back to float every time I want to call into my model.",Are you satisfied with the resolution of your issue? Yes No,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi, Could you please check the `ZerosLike` function https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/zeroslike which returns tensor of zeros. For half precision in C++, to the best of knowledge I can think of `Requantize` OP https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/requantize, check if that helps you. Thanks!","``` using namespace tensorflow; const static std::vector kInputNames = {     ""serving_default_args_0:0"", }; const static std::vector kOutputNames = {     ""StatefulPartitionedCall:0"", }; int main(int argc, char** argv) {   SavedModelBundleLite model_bundle_;   LoadSavedModel(SessionOptions(), RunOptions(), ""/tmp/model"",                  {""serve""}, &model_bundle_);   Tensor input_features(DataType::DT_HALF,                         {1, 8, 8});   input_features.flat_half().setZero(); // Initialize to zero   std::vector> inputs{       std::make_pair(kInputNames[0], input_features),   };   std::vector output_buf = {       Tensor(DataType::DT_FLOAT, {1, 6, 6}),   };   // Run inference with mixed precision   Status status = model_bundle_.GetSession()>Run(       {ops::Cast(scope, input_features, DataType::DT_HALF)},       {kOutputNames[0]}, {}, &output_buf);   if (!status.ok()) {     LOG(ERROR) ();   for (int i = 0; i ** so that the Run() method can fill in the output values. After running inference, the code prints out the values of the output tensor for debugging purposes.",Thanks all! I think we can close this :),Are you satisfied with the resolution of your issue? Yes No
1864,"以下是一个github上的tensorflow下的一个issue, 标题是(Can't convert openimages_v4/ssd/mobilenet_v2)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux   TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab I follow the code to convert a saved model to tflite from tensorflow website here : https://www.tensorflow.org/lite/models/convert/convert_modelsconvert_a_savedmodel_recommended_ The model I want to convert is this one :  https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 I would like to use it in the android example of tensorflow lite:  https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected. The conversion is unsuccessful.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  Am I missing something in my conversion? I am new to this so maybe I am doing something wrong (first time doing a model conversion)? Thank you for your help i)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,chauxb,Can't convert openimages_v4/ssd/mobilenet_v2," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux   TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab I follow the code to convert a saved model to tflite from tensorflow website here : https://www.tensorflow.org/lite/models/convert/convert_modelsconvert_a_savedmodel_recommended_ The model I want to convert is this one :  https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 I would like to use it in the android example of tensorflow lite:  https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected. The conversion is unsuccessful.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.  Am I missing something in my conversion? I am new to this so maybe I am doing something wrong (first time doing a model conversion)? Thank you for your help i",2023-03-12T18:27:47Z,stat:awaiting response type:bug stale TFLiteConverter TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59965,Hi  Thanks for reporting this issue. Can you please mention the steps you have followed for using the hub model and tflite conversion. I have tried converting the https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1 model and was able to successfully convert into tflite model. Please find the gist here and let us know if it helps. Thanks.,Hello   First thank you for your answer and the help you gave me. Your gist indeed works very well and I was able to convert the model. I think what I was not doing is using the tensorflow hub  with the kera layers and using the flag as you did. Here is the exact code I used :  Edit : it seems tensorflow lite metadata needs metadata to work in the app : is it not provided by pretrained models ? ,"Hi   The pre trained lite models in TF hub provide metadata. However, you can add metadata given a tflite model using TFLIte meta data writer API. Please find the overview of adding metada here along with examples. Please feel free to close the issue if it is resolved. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1833,"以下是一个github上的tensorflow下的一个issue, 标题是(SavedModel in C++ with Multiple Signatures gives ""You must feed a value for placeholder tensor 'infer_float_board_state' with dtype float and shape [?,19,19,7]"")， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device n/a  Python version 3.9  Bazel version 6.1.0  GCC/Compiler version LLVM 12  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour?  I see a method `GetSignatureDefs` in `SavedModelBundleLite`, but no way to actually use them. How can I call the signature that I actually need? shell Python class Model(tf.keras.Model):   def __init__(self): super(Model, self).__init__()   def call(self, x):     return x + 1.0   .function(input_signature=[       tf.TensorSpec([None, 1], tf.float32),   ])   def sig_a(self, x):     return self(x)   .function(input_signature=[       tf.TensorSpec([None, 1], tf.float16),   ])   def sig_a(self, x):     return self(x) model.save(local_path,                      signatures={                          'sig_a': model.sig_a,                          'sig_b': model.sig_b                      })  const static std::vector kInputNames = {     ""sig_a_x:0"" }; const static std::vector kPlaceHolderNames = {     ""sig_b_x:0"" }; const static std::vector kOutputNames = {     ""StatefulPartitionedCall:0"", }; int main(int argc, char** argv) {   model = LoadSavedModel(session_options_, run_options_, path,                         {tensorflow::kSavedModelTagServe}, &model_bundle_);   model.GetSession()>Run(, , , ); }   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,p3achyjr,"SavedModel in C++ with Multiple Signatures gives ""You must feed a value for placeholder tensor 'infer_float_board_state' with dtype float and shape [?,19,19,7]""","Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 10  Mobile device n/a  Python version 3.9  Bazel version 6.1.0  GCC/Compiler version LLVM 12  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour?  I see a method `GetSignatureDefs` in `SavedModelBundleLite`, but no way to actually use them. How can I call the signature that I actually need? shell Python class Model(tf.keras.Model):   def __init__(self): super(Model, self).__init__()   def call(self, x):     return x + 1.0   .function(input_signature=[       tf.TensorSpec([None, 1], tf.float32),   ])   def sig_a(self, x):     return self(x)   .function(input_signature=[       tf.TensorSpec([None, 1], tf.float16),   ])   def sig_a(self, x):     return self(x) model.save(local_path,                      signatures={                          'sig_a': model.sig_a,                          'sig_b': model.sig_b                      })  const static std::vector kInputNames = {     ""sig_a_x:0"" }; const static std::vector kPlaceHolderNames = {     ""sig_b_x:0"" }; const static std::vector kOutputNames = {     ""StatefulPartitionedCall:0"", }; int main(int argc, char** argv) {   model = LoadSavedModel(session_options_, run_options_, path,                         {tensorflow::kSavedModelTagServe}, &model_bundle_);   model.GetSession()>Run(, , , ); }   Relevant log output  ",2023-03-10T21:52:50Z,stat:awaiting response stat:awaiting tensorflower type:support stale comp:runtime TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59956,"To call a specific signature, you need to use the **GetSignatures()** method to get a map of all available signatures and their corresponding input and output tensors. You can then use this map to create input and output tensor maps that you can pass to **Session::Run()**. ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
486,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.io.FixedLenSequenceFeature shows error when padding value for unformant serialized features)， 内容是 (I got an error when deserialize the data like the following code. the sequence data would be like   I want to use  to fit sequence data into a dense tensor with padded value 1.  The traceback is like:  ···)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Zaoyee,tf.io.FixedLenSequenceFeature shows error when padding value for unformant serialized features,I got an error when deserialize the data like the following code. the sequence data would be like   I want to use  to fit sequence data into a dense tensor with padded value 1.  The traceback is like:  ···,2023-03-10T03:51:10Z,stat:awaiting response type:bug stale TF 2.11,closed,0,9,https://github.com/tensorflow/tensorflow/issues/59950," The error indicates the number of values in the sequence feature with name f1 does not match the expected output shape, which is [] (empty shape).  FixedLenSequenceFeature expects all lists to have a length of 3.  To fix the error, you can either ensure that all lists in the sequence have the same length, or you can use a VarLenFeature to allow sequences of different lengths. Hope this helps.","Thanks for your quick reply.   I was expected `FixedLenSequenceFeature` is able to pad a default value for the missing, as shown in API doc. I checked the doc,  the comment shows it should allow me to get a dense result for the sequence data instead of using `VarLenFeature` for sparse result. Is it possible to handle that?","Hi  , Could you please fill the issue in the attached format here. I tried replicating the issue and refer to attached gist. It seems there is some difference in error trace.Could you please check and confirm. Thanks!"," , I did some debugging here.For `tf.io.FixedLenSequenceFeature()` if passed `default_value=None` the reported error by you arising.If I pass the Input as Non Ragged Tensor then the error will be gone.  I assume you are trying to pass input as Sparse tensor and padding it with some default value(`""1""` here).This seems not supported by the API `tf.io.parse_single_sequence_example`.  From the API `tf.io.FixedLenSequenceFeature()` see the highlighted line for the argument `default_value` below.  > default_value | Scalar value to be used to pad multiple Examples to their maximum length. **_Irrelevant for parsing a single Example or SequenceExample_**. Defaults to """" for dtype string and 0 otherwise (optional). This states this is irrelevant for parsing a single example or SeqneceExample in our case we have used the API `tf.io.parse_single_sequence_example` which is used for parsing a single SequenceExample proto.Combination of both are not allowed. I hope this explains the reason for the error.Please also refer to the attached gist."," , Really appreciate your work. I understand what you say, but the method description still confuse me. The following is descripted in `parsing_ops.py`. >  `sequence_features` contains `VarLenFeature`, `RaggedFeature`, and   `FixedLenSequenceFeature` objects. Each `VarLenFeature` is mapped to a   `SparseTensor`; each `RaggedFeature` is mapped to a `RaggedTensor`; and each   `FixedLenSequenceFeature` is mapped to a `Tensor`, each of the specified type.   The shape will be `(T,) + df.dense_shape` for `FixedLenSequenceFeature` `df`,   where `T` is the length of the associated `FeatureList` in the   `SequenceExample`. For instance, `FixedLenSequenceFeature([])` yields a scalar   1D `Tensor` of static shape `[None]` and dynamic shape `[T]`, while   `FixedLenSequenceFeature([k])` (for `int k >= 1`) yields a 2D matrix `Tensor`   of static shape `[None, k]` and dynamic shape `[T, k]`. , which i understand should allow me to use a general `FixedLenSequenceFeature` for `tf.io.parse_single_sequence_example`. Besides, i was wondering if I am able to parse the `**'actors'**` features in the example using ``FixedLenSequenceFeature``. / "," , For this case it seems `tf.io.parse_single_sequence_example` not working when `context_features =FixedLenSequenceFeature()` with Sparse input. Workaround seems to use` tf.io.VarLenFeature()` instead of `FixedLenSequenceFeature()`. Could you confirm whether this works for your case or do you have your case to use only with` FixedLenSequenceFeature()` ? ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1927,"以下是一个github上的tensorflow下的一个issue, 标题是(Why is the graph for the 'TFOpLambda' layer's 'call' method not stored in the SavedModel object_graph_def? )， 内容是 ( Describe the problem I work on importing TensorFlow models into MATLAB, this includes deserializing the SavedModel format, identifying the different tf.keras.layers present in the SavedModel and creating an equivalent deep learning network in MATLAB.  In TensorFlow 2.3.0 and earlier , if we use a TF symbol (like: tf.nn.relu()) between tf.keras.layers instances, it was serialized as a 'TensorFlowOpLayer', that was similar to a layer subclassing tf.keras.layer, i.e., the graph for its 'call' method (call_and_return_conditional_losses) was stored in the SavedModel. Specifically, this 'call_and_return_conditional_losses' function was stored as a child of the node corresponding to the TensorFlowOpLayer in the SavedModel's object_graph_def.  In TensorFlow 2.6.0 and later, a TF symbol used between tf.keras.layers instances is serialized as a 'TFOpLambda' layer. Saving models containing these TFOpLambda layers into a SavedModel does not serialize the graph for its 'call' method (call_and_return_conditional_losses) anymore. There is no child node of the TFOpLambda node in the SavedModel's object_graph_def that corresponds to the 'call_and_return_conditional_losses' function anymore.  This creates a problem for me since I rely on decoding the 'call_and_return_conditional_losses' function, in order to import these TensorFlowOpLayer / TFOpLambda into MATLAB. Consider the following model as an example:  Saving this in TensorFlow 2.3.0 will give you a TensorFlowOpLayer that has its 'call' graph serialized, containing the tf.raw_ops.Relu node that I use to concretely identify this as a ReLU activation operation.  Model:)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,meghendra,Why is the graph for the 'TFOpLambda' layer's 'call' method not stored in the SavedModel object_graph_def? ," Describe the problem I work on importing TensorFlow models into MATLAB, this includes deserializing the SavedModel format, identifying the different tf.keras.layers present in the SavedModel and creating an equivalent deep learning network in MATLAB.  In TensorFlow 2.3.0 and earlier , if we use a TF symbol (like: tf.nn.relu()) between tf.keras.layers instances, it was serialized as a 'TensorFlowOpLayer', that was similar to a layer subclassing tf.keras.layer, i.e., the graph for its 'call' method (call_and_return_conditional_losses) was stored in the SavedModel. Specifically, this 'call_and_return_conditional_losses' function was stored as a child of the node corresponding to the TensorFlowOpLayer in the SavedModel's object_graph_def.  In TensorFlow 2.6.0 and later, a TF symbol used between tf.keras.layers instances is serialized as a 'TFOpLambda' layer. Saving models containing these TFOpLambda layers into a SavedModel does not serialize the graph for its 'call' method (call_and_return_conditional_losses) anymore. There is no child node of the TFOpLambda node in the SavedModel's object_graph_def that corresponds to the 'call_and_return_conditional_losses' function anymore.  This creates a problem for me since I rely on decoding the 'call_and_return_conditional_losses' function, in order to import these TensorFlowOpLayer / TFOpLambda into MATLAB. Consider the following model as an example:  Saving this in TensorFlow 2.3.0 will give you a TensorFlowOpLayer that has its 'call' graph serialized, containing the tf.raw_ops.Relu node that I use to concretely identify this as a ReLU activation operation.  Model:",2023-03-10T00:24:12Z,,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59948," Pls check whether the solution works for you or not. Regarding your first question, as far as I know, there is no way to force the serialization of the 'call' method graph for TFOpLambda layers in newer versions of TensorFlow. This change in serialization was made intentionally, and it is not recommended to rely on internal details of the SavedModel format in order to recreate a model in another framework. Regarding your second question, the main benefit of using TFOpLambda layers over TensorFlowOpLayers is that they are more general and flexible. TFOpLambda layers allow you to use any TensorFlow operation (not just those provided by tf.keras.layers) as a layer in your model. This can be useful for example when you want to use a custom TensorFlow operation that is not available as a prebuilt layer in tf.keras. TFOpLambda layers also allow you to easily wrap a TensorFlow function (or any Python function) as a layer. This can be useful when you want to use a complex computation that cannot be expressed as a single TensorFlow operation, but you still want to treat it as a layer in your model. One possible solution would be to manually reconstruct the 'call' method graph for TFOpLambda layers based on their metadata. In the example you provided, the metadata contains information about the function used ('nn.relu') and its inbound nodes (in this case, the previous layer 'conv1d_13'). "," thank you so much for your quick answer! To an extent, I am already using the solution you suggested. What I am doing right now is to map these wellknown activation function names, viz. nn.relu, math.tanh to implementations in MATLAB and using the inbound nodes for the function arguments.  But for arbitrary TensorFlow or Python functions wrapped in TFOpLambda layers, this won't be the case. Hence my follow up question is:    While the metadata for the TFOpLambda layer in this example specifies the name of the function being used (say, nn.relu), is the graph for this function serialized somewhere in the SavedModel? "," In general, the graph for a function wrapped in a TFOpLambda layer is not serialized in the SavedModel format. When you define a TFOpLambda layer using a TensorFlow or Python function, what gets saved in the SavedModel is the name of the function, as well as any arguments that were passed to the function at the time the layer was created. When the SavedModel is loaded and the TFOpLambda layer is instantiated, the function is reconstructed using the name and arguments that were saved. However, the actual graph for the function is not included in the SavedModel, and must be available at runtime in order for the layer to work. For wellknown activation functions like nn.relu or math.tanh, the implementation of the function is typically available in most frameworks, including MATLAB. This allows you to map the function name to the implementation and use it in your MATLAB code. However, for arbitrary TensorFlow or Python functions wrapped in TFOpLambda layers, the implementation may not be available in other frameworks. In this case, you would need to manually.", thanks for the clarification.
1491,"以下是一个github上的tensorflow下的一个issue, 标题是(Fails to build tf-opt with llvm-project repository override)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9  Custom Code Yes  OS Platform and Distribution mac(M2)  Mobile device _No response_  Python version 3.9.16  Bazel version 5.3.0  GCC/Compiler version 15.0.5 (llvm version)  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output shell ERROR: /Volumes/back/mlir_project/tensorflow/tensorflow/compiler/mlir/BUILD:219:13: error loading package 'project//llvm': at /private/var/tmp/_bazel_isolateya/af219aaee912b96bcf0876417404d886/external/llvmproject/llvm/config.bzl:8:5: cannot load 'project//:vars.bzl': no such file and referenced by '//tensorflow/compiler/mlir:tfmlirtranslate' ERROR: Analysis of target '//tensorflow/compiler/mlir:tfmlirtranslate' failed; build aborted: Analysis failed INFO: Elapsed time: 27.395s INFO: 0 processes. FAILED: Build did NOT complete successfully (54 packages loaded, 247 targets configured)     currently loading: project//llvm     Fetching ; Building xcodelocator     Fetching https://storage.googleapis.com/.../abseilcpp/archive/273292d1cfc0a94a65082ee350509af1d113344d.tar.gz  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,tfruan2000,Fails to build tf-opt with llvm-project repository override,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9  Custom Code Yes  OS Platform and Distribution mac(M2)  Mobile device _No response_  Python version 3.9.16  Bazel version 5.3.0  GCC/Compiler version 15.0.5 (llvm version)  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output shell ERROR: /Volumes/back/mlir_project/tensorflow/tensorflow/compiler/mlir/BUILD:219:13: error loading package 'project//llvm': at /private/var/tmp/_bazel_isolateya/af219aaee912b96bcf0876417404d886/external/llvmproject/llvm/config.bzl:8:5: cannot load 'project//:vars.bzl': no such file and referenced by '//tensorflow/compiler/mlir:tfmlirtranslate' ERROR: Analysis of target '//tensorflow/compiler/mlir:tfmlirtranslate' failed; build aborted: Analysis failed INFO: Elapsed time: 27.395s INFO: 0 processes. FAILED: Build did NOT complete successfully (54 packages loaded, 247 targets configured)     currently loading: project//llvm     Fetching ; Building xcodelocator     Fetching https://storage.googleapis.com/.../abseilcpp/archive/273292d1cfc0a94a65082ee350509af1d113344d.tar.gz  ",2023-03-09T13:33:22Z,type:build/install,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59946,Are you satisfied with the resolution of your issue? Yes No
682,"以下是一个github上的tensorflow下的一个issue, 标题是(Errors building Tensorflow from source)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.10.10  Bazel version 5.3.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mikcla,Errors building Tensorflow from source,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.10.10  Bazel version 5.3.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-09T09:43:30Z,stat:awaiting response type:build/install stale subtype:windows TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59943,"Hi  , Thanks for reporting the issues. Could you please confirm whether you have followed all the instructions mentioned here. Also the options from .bazelrc file for AVX instructions:  The command you have used copt=march=native might be for linux only. Could you try the remaining two options. Also for TF2.11 tested Bazel version is 5.3.0 which some times may raise compatibility issues.Please see tested configurations from here.","I have follwed the instructions to my best abillty, and i am using TF 2.11.0 and Bazel 5.3.0. And what command should i type? You typed 3.",Did you tried adding `copt=/arch=AVX ` `copt=/arch=AVX2` to the command ? Please confirm.,   I was able to run the bazel build config=opt copt=march=native //tensorflow/tools/pip_package:build_pip_package successfully for TF 2.11.0 with Bazel 5.3.0 on Windows 10 and for Python 3.10. I think this error is related to the path/environmental variable setup," I think so to, but I don't how to fix this, I have tried to set system variables, change the path in one of the config files and also tried to change the path in cmd. I am using windows 11 btw. I’m sorry I don't have everything on hand because I kept moving on with my project, so I took some steps back, and ran simply ran pip install. However I’m willing to try to build from source again some time, but want to have something new to try beforehand."," , From the error log I observed that Python3 library not being detected.This seems issue with some path setting.Also please ensure all the REQUIRED_PACKAGES mentioned in setup.py installed before bazel build. While installing bazel please ensure all these steps mentioned here were followed correctly or not.As other contributor confirmed that he succeeded the build with same commands of your's it might be mostly related to your environment. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi  Python path setup, please follow the commands below.  To check the path setup of a specific variable if the path set up is correct run sample commands: 'echo %PATH%' or echo %PYTHON_BIN_PATH% set PATH=path/to/python [e.g. (C:/Python310)] set PATH=path/to/python/Scripts [e.g. (C:/Python310/Scripts)]  set PYTHON_BIN_PATH=path/to/python_virtualenv/Scripts/python.exe  set PYTHON_LIB_PATH=path/to/python virtualenv/lib/sitepackages  set PYTHON_DIRECTORY=path/to/python_virtualenv/Scripts "
1363,"以下是一个github上的tensorflow下的一个issue, 标题是(Experimental feature support for TFLite selective build )， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11tfliteandroid  Custom Code No  Current Behaviour? I have followed the tutorial and made my TextCNN model have the ability of ondevicetraining. It works well with the prebuilt library for tensorflowlite. When trying to reduce the binary size  with the docker environment I found that the Java API such as `InterpreterrunSignature` is a part of experimental feature, which not enabled by the tensorflow/lite/tools/build_aar.sh. I have tried to add `experimental = True` to `tflite_custom_android_library()` function on line 73 of the `build_aar.sh` and rebuild, got the `tensorflowlite.aar` and `tensorflowliteselecttfops.aar`.  It seems that `tensorflowlite.aar` does have the experimental feature code and works. But `tensorflowliteselecttfops.aar` failure to run on Android device with error:  I could not find any flag like `experimental = True` for selecttfops to enable. Is it possible to enable experimental features for TFLite selective build?  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,heruoxin,Experimental feature support for TFLite selective build ,"Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11tfliteandroid  Custom Code No  Current Behaviour? I have followed the tutorial and made my TextCNN model have the ability of ondevicetraining. It works well with the prebuilt library for tensorflowlite. When trying to reduce the binary size  with the docker environment I found that the Java API such as `InterpreterrunSignature` is a part of experimental feature, which not enabled by the tensorflow/lite/tools/build_aar.sh. I have tried to add `experimental = True` to `tflite_custom_android_library()` function on line 73 of the `build_aar.sh` and rebuild, got the `tensorflowlite.aar` and `tensorflowliteselecttfops.aar`.  It seems that `tensorflowlite.aar` does have the experimental feature code and works. But `tensorflowliteselecttfops.aar` failure to run on Android device with error:  I could not find any flag like `experimental = True` for selecttfops to enable. Is it possible to enable experimental features for TFLite selective build?  Relevant log output _No response_",2023-03-09T08:11:52Z,type:feature,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59941,"The problem has been solved. https://github.com/tensorflow/tensorflow/issues/59102 add the option echo n ""build config=monolithic"" >> /tensorflow_src/.bazelrc can avoid the _ZNK6google8protobuf7Message11GetTypeNameEv error."
793,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow2.11  build error   /root/tensorflow/tensorflow/lite/python/BUILD:68:10 Middleman _middlemen/tensorflow_Slite_Spython_Stflite_Uconvert-runfiles failed:)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.11  Custom Code Yes  OS Platform and Distribution centos7.6  Mobile device _No response_  Python version python3.7.12  Bazel version 5.0.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,south-ocean,Tensorflow2.11  build error   /root/tensorflow/tensorflow/lite/python/BUILD:68:10 Middleman _middlemen/tensorflow_Slite_Spython_Stflite_Uconvert-runfiles failed:,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.11  Custom Code Yes  OS Platform and Distribution centos7.6  Mobile device _No response_  Python version python3.7.12  Bazel version 5.0.0  GCC/Compiler version 9.4.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-09T05:57:43Z,stat:awaiting response type:build/install stale comp:lite subtype:centos TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59940,use the same setting in the centos8 can build tensorflow2.11 successfully.  but i want use the version with centos7.,"ocean, On CentOS7 while installing the python3 package, it might give the Python 3.6 interpreter which was not supported for the tensorflow 2.11. Please take a look at the official doc link for the reference and try to install the tf v2.11 with a compatible version as mentioned. !Screenshot 20230313 1 36 18 PM And kindly try this command and comment from the contributor: `bazel build config=opt per_file_copt=//tensorflow/.*\.,O0 tensorflow/tools/pip_package:build_pip_package` Thank you!","Thank you  for your reply, actually, i have  installed  the python3.7 and upgraded the gcc to 9.4, it also meet the error.","ocean, Apologies for the delay. And kindly try this command and https://github.com/tensorflow/tensorflow/issues/56665 from the https://github.com/tensorflow/tensorflow/issues/44692issuecomment932906041  and also try install tensorflow with python v3.8. **bazel build config=opt per_file_copt=//tensorflow/.*\.,O0 tensorflow/tools/pip_package:build_pip_package** Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
711,"以下是一个github上的tensorflow下的一个issue, 标题是(third_party/icu/data missing big-endian conversion data files)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04 s390x  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version gcc 9  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jonathan-albrecht-ibm,third_party/icu/data missing big-endian conversion data files,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04 s390x  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version gcc 9  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-08T15:42:14Z,stat:awaiting tensorflower type:build/install subtype: ubuntu/linux,open,0,24,https://github.com/tensorflow/tensorflow/issues/59935,"Hi albrechtibm , Could you please confirm the bazel command you have used for the tests?  Thankyou!","Hi , here is the bazel command I used that will run the failed tests:  Note that when building on s390x, there are some extra changes required for ssl (`TF_SYSTEM_LIBS=""boringssl""`) and xnnpack (`define=tflite_with_xnnpack=false` since not available on s390x) that are unrelated to the unicode tests. I've dug into it a bit more and I'll add some more info in a follow up comment.","Hi , Following the instructions in https://github.com/tensorflow/tensorflow/blob/6537d7f689b234c7f945fe3b5d094317716148b0/third_party/icu/data/BUILD.bazelL16L43 I was able to generate the bigendian format files on a littleendian x86_64 VM with icu version release691. After creating icudt69l_dat.c: * generate the bigendian .dat file with `icupkg tb ./icudt69l.dat icudt69b.dat` * generate the bigendian icudt69b_dat.c file with `genccode icudt69b.dat` * add the conversion wrapper function with `echo ""U_CAPI const void * U_EXPORT2 uprv_getICUData_conversion() { return icudt69b_dat.bytes; }"" >> icudt69b_dat.c` Then the icudt69b_dat.c can be gzip'd and split to a set of eg. icu_conversion_data_big_endian.c.gz.* files. The `conversion_files` filegroup (https://github.com/tensorflow/tensorflow/blob/6537d7f689b234c7f945fe3b5d094317716148b0/third_party/icu/data/BUILD.bazelL44L47) can also be updated to select the bigendian files on s390x. Something like this:  With those changes in place, the unicode tests all pass and I didn't see any regressions in other tests when running the full test suite.","Hi, Could you please check the comment on the above linked PR and explain on handling bigendian conversion( which is solved in your case).","H , Thanks for helping with this.  Your PR also needs to include the bigendian conversion which can be generated from the littleendian .dat file. My comment above (https://github.com/tensorflow/tensorflow/issues/59935issuecomment1466304945) explains how to do that: You will need to follow all of the existing instructions to generate the littleendian conversion files in: https://github.com/tensorflow/tensorflow/blob/6537d7f689b234c7f945fe3b5d094317716148b0/third_party/icu/data/BUILD.bazelL16L43 then follow these instructions to generate the bigendian conversion files. > After creating icudt69l_dat.c: >  > * generate the bigendian .dat file with `icupkg tb ./icudt69l.dat icudt69b.dat` > * generate the bigendian icudt69b_dat.c file with `genccode icudt69b.dat` > * add the conversion wrapper function with `echo ""U_CAPI const void * U_EXPORT2 uprv_getICUData_conversion() { return icudt69b_dat.bytes; }"" >> icudt69b_dat.c` >  > Then the icudt69b_dat.c can be gzip'd and split to a set of eg. icu_conversion_data_big_endian.c.gz.* files. >  Finally the new bigendian conversion files will need to be included in your PR. Let me know if you have any questions and I will try to help.","Thanks for pointing me to the details, would you be interested to work on this PR, since you already have the workflow ready. I can go ahead and close the PR.","Hi , I'll need to get internal approval on my side before I can submit a PR and it could take some time. I appreciate your time looking at this. If you are still interested I could work with you to help you generate the bigendian files otherwise I will try to get approval to create a PR.","Yes please, I would need your help in making this PR, since I have limited knowledge on this topic.",Thanks for offering to help ! The first step would be to generate the littleendian data file using the instructions at: https://github.com/tensorflow/tensorflow/blob/6537d7f689b234c7f945fe3b5d094317716148b0/third_party/icu/data/BUILD.bazelL16L43 If you have any specific questions I'd be happy to help.," , Can you take a look into this request or help me connecting with the right person who can look into it. Thanks!","Hi , would you have some time to look into this issue? I probably won't be able to get internal approval to submit a PR for some time.","Thanks for flagging this issue and sorry about the late reply! Unfortunately, I do not have familiarity with the failing tests so I don't think I can review your PR.  Do you think someone from your team would be a better fit to review this?"," hope you don't mind my reaching out directly but from looking at the git history, I think you might be able to help with this `third_party/icu` issue. Due to internal reasons, I'm not going to be able to open a PR for this anytime soon. I figured out how to generate the bigendian format data files on amd64 and added the details above. Would generating the bigendian data files and adding them into `third_party/icu/data` be something you would have time to do? Any help would be greatly appreciated but I certainly understand if time or other reasons won't allow.","Unfortunately I not longer work in TF (left the team nearly a year ago). I am consulting from time to time (especially on security topics, but also on OSS), and might contribute here and there with some PRs, but my main bulk of work is no longer in TF. So it will take some time until I can handle this.","Thanks , I appreciate it!","I'm starting to think that the solution here might be to just generate the conversion files at build time, instead of storing them in the repo. There are several requirements that could be pushing towards that"," generating the conversion files at build time would help this issue. It's straight forward to generate the big endian version of the conversion files, once all the setup of the icu build is in place, on either big or little endian machines. ",Adding  for visibility,Thanks for the ping .  I think if we could move towards generation at build time instead of storing all of those conversion in third_party that would be best.,"Hi , just wanted to check if there were any updates on this issue?",Unfortunately no update IIRC the person working on this had trouble getting a build rule that worked on this for all systems in a timely manner and no longer works on the project.  Its unfortunately not a very high priority right now so no new progress has been made. ,Thanks for the quick reply ,"""Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.""", this issue is still relevant
1249,"以下是一个github上的tensorflow下的一个issue, 标题是(`tf.data.Dataset.from_generator(...)` fails when the `output_signature` argument is a dictionary that has a value `tf.RaggedTensorSpec(...)` for some key)， 内容是 (Click to expand!   Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.11.0rc217gd5b57ca93e5 2.11.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  ... and it appears that it is `tf.dtypes.as_dtype(type_value)` that is used to parse an `output_signature` provided to `tf.data.Dataset.from_generator`.  Standalone code to reproduce the issue See above  Relevant log output TypeError: Cannot convert the argument `type_value`: TensorSpec(shape=(), dtype=tf.string, name=None) to a TensorFlow DType. TypeError: Cannot convert the argument `type_value`: RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64) to a TensorFlow DType. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Leengit,`tf.data.Dataset.from_generator(...)` fails when the `output_signature` argument is a dictionary that has a value `tf.RaggedTensorSpec(...)` for some key,"Click to expand!   Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.11.0rc217gd5b57ca93e5 2.11.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  ... and it appears that it is `tf.dtypes.as_dtype(type_value)` that is used to parse an `output_signature` provided to `tf.data.Dataset.from_generator`.  Standalone code to reproduce the issue See above  Relevant log output TypeError: Cannot convert the argument `type_value`: TensorSpec(shape=(), dtype=tf.string, name=None) to a TensorFlow DType. TypeError: Cannot convert the argument `type_value`: RaggedTensorSpec(TensorShape([None]), tf.int32, 0, tf.int64) to a TensorFlow DType. ",2023-03-07T21:10:12Z,stat:awaiting response type:bug comp:apis comp:ops TF 2.11,closed,0,13,https://github.com/tensorflow/tensorflow/issues/59926,Specifically I am getting an error when I give a dataset's `.element_spec` as an `output_signature`  to `tf.data.Dataset.from_generator(...)`,"seems you are trying to convert a TensorSpec or a RaggedTensorSpec object into a DType object directly using tf.dtypes.as_dtype() method, which is not possible.  the as_dtype() method is used to convert a string or numpy dtype object to a tensorflow DType object.  replace your code for d2 and d3 as below , this shall solve the TypeError ... d2 = type_value0.dtype d3 = type_value1.dtype ....","As best as I can tell, it is the internals of the `tf.data.Dataset.from_generator()` call that is trying to directly use `tf.dtypes.as_dtype()` in parsing its `output_signature` argument, when that argument is a dictionary that contains a `(key, value)` pair with a value that is `tf.RaggedTensorSpec(tf.TensorShape([None]), tf.int32, 0, tf.int64)`.  Thanks!","Hi,   Could you please look into this issue ? Thank you!","Hi  , The code `d2 = tf.dtypes.as_dtype(type_value0)` fails obviously because the function `as_dtype()` expects the input to be: > Inputs can be existing tf.DType objects, a DataType enum, a string type name, or a numpy.dtype. As you are providing `TensorSpec()` and `RaggedTensorSpec()` as inputs which does not belongs to any of the supporting arguments,and hence it is raising the intended error. There is no problem with this API here If you find any problem with `tf.data.Dataset.from_generator()` please point to that exact issue with reproducible code and we will definitely have a look into the issue. Thanks!",Perhaps I am doing something wrong.  Here is small example that shows the problem that I am having. ,"Hi  , You are passing `element_spec` as positional argument which is causing the error. You should pass it as key word argument to `output_signature` like below. `dataset_fails = tf.data.Dataset.from_generator(gen, output_signature=element_spec)` With this the code execution success. Please refer to attached gist.","Excellent, thank you very much!",Are you satisfied with the resolution of your issue? Yes No,"Would it make sense to adjust the error message to something that includes ""Did you mean to supply the output_signature parameter instead of output_types?""","Hi  , Since the function `tf.data.Dataset.from_generator() `has 1 positional and 5 keyword args by default if you pass the arguments as positional it will assign in the order of arguments defined in the function. That is the default Python behaviour.Hence we need to specify the keyword argument specifically in such case.","My suggestion about the error message arises because the two parameters are similarly named and one deprecates the other.  To be explicit, if the `output_types` argument cannot be handled as supplied, the error message could suggest that maybe the user meant to instead supply the argument as `output_signature`.  It would have saved me a bunch of trouble.  But if the suggestion is problematic to implement or has downsides that outweigh the upsides then please ignore it.  Thanks!",This API calls many other APIs internally and the error raised in internal APIs and hence its hard to implement your suggestion. However user can use stack trace to checkout the root cause.
1928,"以下是一个github上的tensorflow下的一个issue, 标题是(Problems with converted 8-bit TFLite models of CycleGAN and running inference (specially allocating tensors))， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No, problem are found on normal TF code.    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: WSL2 Ubuntu 22.04    **TensorFlow installed from (source or binary)**: python version is installed using pip, and the benchmark binary is built from TF branch ""v2.11.0""    **TensorFlow version (use command below)**: Tested initially on TF2.7 but also on TF2.11    **Python version**: 3.9.16     **Bazel version (if compiling from source)**:  5.3.0    **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0    Description of task  I wanted to to convert CycleGAN model provided by Tensorflow into a TFLite model and run inference.  I am using this https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb to first define and train the model in TensorFlow  To convert the models ( 2 Generative and 2 Discriminative) I use the model.save() function    Following this I convert  the model using the TFLiteConverter.   During conversion I get the following warning which I don't know if it is important for the problems I am facing :    Description of problems Quick note: Problems 2 and 3 occur for the generative TFLite models of Cycle GAN and problem 4 is for the discriminative TFLite  models  of CycleGAN. **1.** When trying to simply allocate tensors for the converted TFLite models on the python interpreter I get the following error: **Aborted (core dumped)**   **2.** Since the error message was not useful I wanted to run t)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,judeharis,Problems with converted 8-bit TFLite models of CycleGAN and running inference (specially allocating tensors)," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: No, problem are found on normal TF code.    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: WSL2 Ubuntu 22.04    **TensorFlow installed from (source or binary)**: python version is installed using pip, and the benchmark binary is built from TF branch ""v2.11.0""    **TensorFlow version (use command below)**: Tested initially on TF2.7 but also on TF2.11    **Python version**: 3.9.16     **Bazel version (if compiling from source)**:  5.3.0    **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 11.3.01ubuntu1~22.04) 11.3.0    Description of task  I wanted to to convert CycleGAN model provided by Tensorflow into a TFLite model and run inference.  I am using this https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb to first define and train the model in TensorFlow  To convert the models ( 2 Generative and 2 Discriminative) I use the model.save() function    Following this I convert  the model using the TFLiteConverter.   During conversion I get the following warning which I don't know if it is important for the problems I am facing :    Description of problems Quick note: Problems 2 and 3 occur for the generative TFLite models of Cycle GAN and problem 4 is for the discriminative TFLite  models  of CycleGAN. **1.** When trying to simply allocate tensors for the converted TFLite models on the python interpreter I get the following error: **Aborted (core dumped)**   **2.** Since the error message was not useful I wanted to run t",2023-03-07T13:37:09Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59922,Hi  Thanks for reporting this issue. Sorry for the delayed response. I was able to reproduce the issue from pix2pix generator as used in this tutorial. Please find the gist here. However I was successfully able to convert into 8bit tflite model and invoke the interpreter using the resnet generator used in the keras cycle gan tutorial. Please find the gist here. Thanks.,"Hi , I was able to verify your findings. The CycleGAN model from keras is able to be converted properly.  That being said, it doesn't really tackle the issues. Also, CycleGAN with pix2pix generator and ResNet generator are effectively two different models.  I thought the conversion should produce a valid model, especially if the model is valid in TF? Also, why does the discriminator model produce ""BytesRequired number of elements overflowed."" error for basic CONV2D layers? In regards to the quantization errors, it seems similar issues have been found previously for different operations (and apparently fixed): (https://github.com/tensorflow/tensorflow/issues/43661issue711575230). Is it not possible to create a similar fix for the ""SquaredDifference"" operation?","Hi , thanks for the clarification. I did observe that using `BatchNorm` instead of `InstanceNorm` in UNet generator doesn't cause any problem in allocating the tensors. Please find the same in this gist.  Could you please look into this issue. Thanks.","Hi  , Could you make an attempt to resolve your issue by using AIEdgeTorch. Your Pytotch CycleGAN model can be convert and export using   you can find more information here: googleblog.  You can try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repos. Thank You",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1424,"以下是一个github上的tensorflow下的一个issue, 标题是(Problems of tflite conversion，about the file of tflite(.h5 to .tflite))， 内容是 (Hi:  1. System information  Linux  pip:  TensorFlow 2.10  2. Code     My Model part  ... gru = GRU(64,activation='tanh', recurrent_activation='sigmoid', return_sequences=True,unroll=True)(tmp) gru_1 = GRU(128,activation='tanh', recurrent_activation='sigmoid', return_sequences=True,unroll=True)(vad_gru) ... Converter converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] def representative_dataset_gen():     ...     yield [inp_data] converter.representative_dataset = representative_dataset_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.SELECT_TF_OPS,tf.lite.OpsSet.TFLITE_BUILTINS] converter.inference_input_type = tf.int8 converter.inference_output_type = tf.int8 tflite_model = converter.convert() with tf.io.gfile.GFile('denoise_quante1.tflite','wb') as f:     f.write(tflite_model)  3. Question When I convert. h5 to. tflite, if my unroll=False in the GRU layer of the model, the converted tflite (300K) file is much smaller than the. h5 (3M) file, but when I use unroll=True, the tflite (39M) file will become large. Why? Is there any solution？ Thanks！)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,panhu,Problems of tflite conversion，about the file of tflite(.h5 to .tflite),"Hi:  1. System information  Linux  pip:  TensorFlow 2.10  2. Code     My Model part  ... gru = GRU(64,activation='tanh', recurrent_activation='sigmoid', return_sequences=True,unroll=True)(tmp) gru_1 = GRU(128,activation='tanh', recurrent_activation='sigmoid', return_sequences=True,unroll=True)(vad_gru) ... Converter converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] def representative_dataset_gen():     ...     yield [inp_data] converter.representative_dataset = representative_dataset_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.SELECT_TF_OPS,tf.lite.OpsSet.TFLITE_BUILTINS] converter.inference_input_type = tf.int8 converter.inference_output_type = tf.int8 tflite_model = converter.convert() with tf.io.gfile.GFile('denoise_quante1.tflite','wb') as f:     f.write(tflite_model)  3. Question When I convert. h5 to. tflite, if my unroll=False in the GRU layer of the model, the converted tflite (300K) file is much smaller than the. h5 (3M) file, but when I use unroll=True, the tflite (39M) file will become large. Why? Is there any solution？ Thanks！",2023-03-07T09:33:50Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.10,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59921,", Could you please provide the complete code  to reproduce the issue and also the error log which helps us to debug the issue in the effective way. Thank you!","The code: converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] def representative_dataset_gen(): ... yield [inp_data] converter.representative_dataset = representative_dataset_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.SELECT_TF_OPS,tf.lite.OpsSet.TFLITE_BUILTINS] converter.inference_input_type = tf.int8 converter.inference_output_type = tf.int8 tflite_model = converter.convert() with tf.io.gfile.GFile('denoise_quante1.tflite','wb') as f: f.write(tflite_model)  In the model my GRU(....,unroll=True)","Hi   Sorry for the delayed response. Using `unroll=True` tends to be more memoryintensive and it is only suitable for short sequences.  Have you tried converting the model without using select ops and can you mention the size of .h5 when `unroll=True` is used. Also, can you please check in TF 2.11 and TF Nightly and share your observation. Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
685,"以下是一个github上的tensorflow下的一个issue, 标题是(Input Layer can't be defined in tensorflow 2.11.0)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Windows  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,fmanstein,Input Layer can't be defined in tensorflow 2.11.0,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Windows  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-07T09:22:09Z,stat:awaiting response type:bug stale comp:apis subtype:windows TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59920,Try using tf.keras.layers.InputLayer instead.  You can skip defining the input layer and give the input shape to the first layer and keras will add a input for a model behind the scenes.,"Hi,   Apologize for the delayed response and It seems like the issue is with importing layers so May I know how are you importing models or layers, if possible share the documentation link or all the imports which you're using in your code please ? meanwhile could you please try to imports like below,   Please do it like below in your code :  I have to tried to replicate the same issue on Google Colab and it's working as expected with `Tensorflow==2.11` version here is gistfile and please refer this official documentation tutorial so could you please try above workaround from your end and let me know whether is it working as expected or not ? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
513,"以下是一个github上的tensorflow下的一个issue, 标题是(Fixed action workflow error in stale-issue.yaml)， 内容是 (**Issue**: Workflow is giving error while running.Error msgThe workflow is not valid. .github/workflows/staleissues.yml  **Fixed**: Followed stale/action workflow docs. Changed anyoflabels value to ',' string. Changed onlyissuelabels to onlylabels to work for both PR and issues.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shmishra99,Fixed action workflow error in stale-issue.yaml,"**Issue**: Workflow is giving error while running.Error msgThe workflow is not valid. .github/workflows/staleissues.yml  **Fixed**: Followed stale/action workflow docs. Changed anyoflabels value to ',' string. Changed onlyissuelabels to onlylabels to work for both PR and issues.",2023-03-07T09:19:08Z,ready to pull size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59919, Can you please resolve conflicts? Thank you!
707,"以下是一个github上的tensorflow下的一个issue, 标题是(Inexistant CUDA support for last version ?)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11  Custom Code No  OS Platform and Distribution Windows 10 (Build 19045.2673)  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.0.2  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,TheHellTower,Inexistant CUDA support for last version ?,Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11  Custom Code No  OS Platform and Distribution Windows 10 (Build 19045.2673)  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.0.2  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-06T00:07:38Z,stat:awaiting response stat:awaiting tensorflower type:feature type:build/install stale subtype:windows TF 2.11 subtype:cpu-intel,closed,1,33,https://github.com/tensorflow/tensorflow/issues/59905,"  TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2 for GPU support. Could you please refer to the doc for reference. Thank you !",">  TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2 for GPU support. Could you please refer to the doc for reference. >  > Thank you ! The problem is I'm building the project on `Windows` with `Visual Studio` for `Windows` so it's not possible anymore ? Can I even build the project from `Windows` for `Linux` ? This is not practical at all, why the support got dropped ?","  Sorry for the late reply, Unfortunately from TF 2.11 is not supported for GPU pip installation. If you want GPU support for windows try to build from source. Please refer to Build from source on Windows for reference. Thank you!",">  Sorry for the late reply, Unfortunately from TF 2.11 is not supported for GPU pip installation. If you want GPU support for windows try to build from source. Please refer to Build from source on Windows for reference. >  > Thank you! Hello, First of all I'm not using `Python` I want to use `C++`, then you said GPU support is not in 2.11 ""`TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows`"" so it would be useless for me to build from source ? I was enthusiastic and excited by the idea of using Tensorflow until I see that I can't even make my project with the 2.10 version it doesn't seem to work as intented (it was crashing). If in C++ the GPU support is still there then I woud love to know how to get it on my side because I really need it I can't waste time with CPU it's way too long next to GPU... And like I can see here ""`Caution: TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows.`"" Regards.",Well hopefully you will not avoid the issue just like this and will give a answer at some point.,"Hi,   Could you please take look into this issue? Thank you!","Hi  , With Windows if you want to enable GPU support for Tf>2.10 versions, you can try DirectML Plugin option. Please refer the source here and follow the instructions mentioned there. The requirement should be:  If you want to go with TF=2.10v only then you might need to install tensorflow first and then reinstall again with TF==2.10v. Incase of any problem with DirectML plugin please let us know. Thanks!","> Hi  , >  > With Windows if you want to enable GPU support for Tf>2.10 versions, you can try DirectML Plugin option. Please refer the source here and follow the instructions mentioned there. >  > The requirement should be: >  >  >  > If you want to go with TF=2.10v only then you might need to install tensorflow first and then reinstall again with TF==2.10v. >  > Incase of any problem with DirectML plugin please let us know. >  > Thanks! Isn't it for the Python bindings ? I need GPU support using C++ I'm writing my project in C++.","Hi  , If you want GPU support with C++ then you need to go with tensorflow version 2.10 only using clang bindings here. For more details on this please refer this source. Please note that there are some limitations in this bindings like mentioned below. ","> Hi  , >  > If you want GPU support with C++ then you need to go with tensorflow version 2.10 only using clang bindings here. For more details on this please refer this source. >  > Please note that there are some limitations in this bindings like mentioned below. >  >  I think the support should be added back. See Issue CC(Please bring back native Windows CUDA support!) that list 7 issues including this one about GPU support on Windows, It's very important for my project to be on the last version and I can't even use it and in 2.10 it doesn't work at all for some strange reasons.",Bump.,"Hi  , With the inclusion of WSL,it will be comparatively easy to maintain the framework for both Linux and Windows. Here is the link to the announcement blog which talks about official build collaborators. Please refer to the Developer comment related to drop of GPU support. ","> Hi  , >  > With the inclusion of WSL,it will be comparatively easy to maintain the framework for both Linux and Windows. Here is the link to the announcement blog which talks about official build collaborators. >  > Please refer to the Developer comment related to drop of GPU support. https://github.com/tensorflow/tensorflow/issues/59918issuecomment1500529192",">  Sorry for the late reply, Unfortunately from TF 2.11 is not supported for GPU pip installation. If you want GPU support for windows try to build from source. Please refer to Build from source on Windows for reference. >  > Thank you!  Hello, I tried building tf2.11 from source on Windows and it failed. I can't find the  solution for the error in existing issues. May I ask that whether tensorflow developers already tried building from source on Windows since tf2.11 and succeeded? I'd like to build from source to use GPU for nativewindows on tf2.11 and higher. However, if that means I need to modify the C++ code to make the build successful, the price is just too high. The main part of error is listed below: ", Could you please take a look?,Hey toplay this is the Intel TF Windows account. Is it possible to tag this account or does it need to be added?  Rajeev & Mayank,tfwindows It seems I can now.  Thank you for assigning the issue!,"Hi toplay, I think TensorFlow GPU or Nvidia Team would be able to resolve this issue as the errors involve CUDA files",Thank you !,News ?,"Some references that may be helpful:  See section ""Expanded GPU support on Windows"" in this TensorFlow blog post.  See TensorFlow install page and this page.","> Some references that may be helpful: >  > * See section ""Expanded GPU support on Windows"" in this TensorFlow blog post. > * See TensorFlow install page and this page. No it's not okay for me because:  https://github.com/tensorflow/tensorflow/issues/59905issuecomment1474398835  https://github.com/tensorflow/tensorflow/issues/59905issuecomment1474864649",Bump,Bump,Bump,You can never wake up a bunch of people pretending to be asleep,> You can never wake up a bunch of people pretending to be asleep Doesn't matter I have the time lol,Bump, Unfortunately as mentioned in this comment GPU on nativeWindows isn't supported.,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. TensorFlow 2.10 was the last TensorFlow release that supported GPU on nativeWindows. Starting with TensorFlow 2.11, you will need to install TensorFlow in WSL2 for GPU support. Could you please refer to the doc for reference. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space."
1502,"以下是一个github上的tensorflow下的一个issue, 标题是(how to convert tensorflow lite using yolov6 .pt file ?)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,abhishekbj97,how to convert tensorflow lite using yolov6 .pt file ?," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-03-05T19:37:38Z,comp:lite TFLiteConverter comp:lite-support,closed,1,3,https://github.com/tensorflow/tensorflow/issues/59902,There is a problem in converting of file (unsupported format) using tf 2x version. how to convert pytorch model (.pt) files to tflite for YOLOv6 ? ,"Hi ,  Kindly let us know the steps you have followed to convert a pytorch model to tflite for better assistance. Converting a PyTorch model (.pt) file to TFLite for YOLOv6 involves several steps. 1. Convert the PyTorch model to ONNX format using the `torch.onnx` module.  2. Convert the ONNX model to TensorFlow format using the `onnxtf` converter. 3. Convert the TensorFlow model to TFLite format using the TensorFlow Lite Converter. 4. Finally, test your TFLite model to make sure it is working correctly. You can use the TFLite interpreter to do this. Thank you!","Thank you for your response, it's working now "
1946,"以下是一个github上的tensorflow下的一个issue, 标题是(Getting error when calculating entropy for each images in the batch in the input tensor in a custom layer in tensorflow/Keras.)， 内容是 (I am working on a problem in which I have to create a custom layer in keras, which takes, output of a conv layer of a pretrained model as an input. This custom layer work is to select K best feature maps based on shannon entropy for each images in that input tensor and then outputs the final tensor with k feature maps or each images. So that this output tensor is passed to other conv layer in the model. Let input tensor from a conv layer has shape = (None, 224,224, 128) and I want to take 64 best feature maps out of 128 based on shannon entropy . So the output tensor shape should be = (None, 224,224, 64).  System Informations: python version = '3.9.12' tensorflow version = `'2.10.0'` Platform = Windows 11 Running on CPU  Below is the code snippet : `                              class select_k_fmap(tf.keras.layers.Layer):                     def __init__(self):                         super(select_k_fmap, self).__init__()                     def build(self, input_shape):                         pass                     def call(self, inputs):                         """"""                         tensor shape = (batch_size, img_height, img_width, no. of filters)                         """"""                             shape = tf.shape(inputs)                         batch_size = shape[0]                         print('batch size **** ', batch_size)                         num_filters = shape[1]                         img_height = shape[1]                         img_width = shape[2]                         k = 4  no. of best feature maps to select                         def k_best_fmap(image):               )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DeveshS215,Getting error when calculating entropy for each images in the batch in the input tensor in a custom layer in tensorflow/Keras.,"I am working on a problem in which I have to create a custom layer in keras, which takes, output of a conv layer of a pretrained model as an input. This custom layer work is to select K best feature maps based on shannon entropy for each images in that input tensor and then outputs the final tensor with k feature maps or each images. So that this output tensor is passed to other conv layer in the model. Let input tensor from a conv layer has shape = (None, 224,224, 128) and I want to take 64 best feature maps out of 128 based on shannon entropy . So the output tensor shape should be = (None, 224,224, 64).  System Informations: python version = '3.9.12' tensorflow version = `'2.10.0'` Platform = Windows 11 Running on CPU  Below is the code snippet : `                              class select_k_fmap(tf.keras.layers.Layer):                     def __init__(self):                         super(select_k_fmap, self).__init__()                     def build(self, input_shape):                         pass                     def call(self, inputs):                         """"""                         tensor shape = (batch_size, img_height, img_width, no. of filters)                         """"""                             shape = tf.shape(inputs)                         batch_size = shape[0]                         print('batch size **** ', batch_size)                         num_filters = shape[1]                         img_height = shape[1]                         img_width = shape[2]                         k = 4  no. of best feature maps to select                         def k_best_fmap(image):               ",2023-03-05T08:33:57Z,stat:awaiting response type:support comp:keras TF 2.10,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59899,", I tried to execute the mentioned code and it was failing due to `SyntaxError: invalid syntax`. Kindly find the gist of it here and provide the complete code or the colab gist you are using. Thank you!",", Thank you. I have provided the full code and remove that syntax error. The collab gist is here.",", Apologies for the delay.Thank you for opening this issue. Development of keras moved to another repository.  Could you please post this issue on kerasteam/keras repo. To know more please refer: https://discuss.tensorflow.org/t/kerasprojectmovedtonewrepositoryinhttpsgithubcomkerasteamkeras/1999 Thank you!",  I have posted on keras repo.,", Could you please feel free to move this issue to closed status, so that we can track the issue there. Thank you!",Are you satisfied with the resolution of your issue? Yes No
721,"以下是一个github上的tensorflow下的一个issue, 标题是(LinearOperatorInversion gives weird result on GPU for linear operators)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230222  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.4 LTS  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 8.2.4  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,trickiwoo,LinearOperatorInversion gives weird result on GPU for linear operators,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0dev20230222  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.4 LTS  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 8.2.4  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-03T01:32:24Z,stat:awaiting tensorflower type:bug comp:ops,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59884,"Hi , I was able to replicate the issue in Colab. Please find the gist here. It seems like we have to dig more into this issue, we will update soon here. Thank you! ",", Apologies for the delay. The reason why the code is not producing an identity matrix on GPU is because of the differences in how floatingpoint arithmetic is performed in GPUs. GPUs use a different set of instructions and floatingpoint precision, which can result in slightly different rounding errors and numerical precision when performing matrix operations. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"  Thanks for the explanation! I understand that GPUs might use a different floatingpoint precision. However, it seems that in GPU it produces a significantly different result for the matrix inversion, and according to the output value of `y` (expected to be an identity matrix), it seems more than numerical precision issues?"," your matrix is not invertible.  In particular, it has a nullspace vector `(0.5, 1, 0.5)`.  The inverse operator is finding a pseudoinverse (but we don't make any guarantees about which one), so multiplying it back out will not yield the identity.  You're seeing different values on CPU vs GPU because they are returning different pseudoinverses.",Are you satisfied with the resolution of your issue? Yes No
1875,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow int8 conversion error for segmentation U-Net)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10   TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source):  TensorFlow 2.11.0, pip package  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here import cv2 import numpy as np from matplotlib import pyplot as plt import tensorflow as tf from tensorflow import keras from mss import mss from PIL import Image import os def U_Net (o_w, o_h, o_c, t_w, t_h, t_c, num_layers, initial_ch, deep_sup):     global model     def encoder(e_in, filters, kernel_size=(3, 3), padding=""same"", strides=1):         e = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(e_in)         skip_out = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(e)         e_out = keras.layers.MaxPool2D((2, 2), (2, 2))(skip_out)         return e_out, skip_out     def bridge(bridge_in, filters, kernel_size=(3, 3), padding=""same"", strides=1):         b = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(bridge_in)         bridge_out = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(b)         return bridge_out     def decoder(d_in, skip_in, filters, kernel_size=(3, 3), padding=""same"", strides=1):         up_sampled = keras.layers.UpSampling2D((2, 2))(d_in)         up_sampled_reshaped = tf.keras.layers.experimental.prepr)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,david507huang,Tensorflow int8 conversion error for segmentation U-Net," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10   TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source):  TensorFlow 2.11.0, pip package  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here import cv2 import numpy as np from matplotlib import pyplot as plt import tensorflow as tf from tensorflow import keras from mss import mss from PIL import Image import os def U_Net (o_w, o_h, o_c, t_w, t_h, t_c, num_layers, initial_ch, deep_sup):     global model     def encoder(e_in, filters, kernel_size=(3, 3), padding=""same"", strides=1):         e = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(e_in)         skip_out = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(e)         e_out = keras.layers.MaxPool2D((2, 2), (2, 2))(skip_out)         return e_out, skip_out     def bridge(bridge_in, filters, kernel_size=(3, 3), padding=""same"", strides=1):         b = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(bridge_in)         bridge_out = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=""relu"")(b)         return bridge_out     def decoder(d_in, skip_in, filters, kernel_size=(3, 3), padding=""same"", strides=1):         up_sampled = keras.layers.UpSampling2D((2, 2))(d_in)         up_sampled_reshaped = tf.keras.layers.experimental.prepr",2023-03-02T20:27:02Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59879,",  In the mentioned comment I did not see the inclusion of Select tf ops. Could you please try to add the below snippet in your code and let us know the outcome.   Also kindly note that all ops are not available right now in INT8. Thank you!",Still the same errors. I tried converting the model to frozen graph and then to tflite. But the final tflite model outputs incorrect output and runs very slowly. ,"Hi   Sorry for the delayed response. The conversion error is not provided. If it is successfully converted, can you provide more information regarding the results obtained and on which platform inference is done. Also, if possible can you share a reproducible gist as the code provided is not reproducible since it has other dependencies. Thanks.",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
911,"以下是一个github上的tensorflow下的一个issue, 标题是(ERROR: tensorflow/tensorflow/compiler/xla/service/gpu/runtime/BUILD:146:11: in deps attribute of cc_library rule //tensorflow/compiler/xla/service/gpu/runtime:gemm: target '//tensorflow/compiler/xla/service/gpu:non_atomically_upgradeable_rw_lock' does not exist)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version 12.1/8.8.0.121  GPU model and memory NVIDIA GeForce 940MX  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,vyepishov1,ERROR: tensorflow/tensorflow/compiler/xla/service/gpu/runtime/BUILD:146:11: in deps attribute of cc_library rule //tensorflow/compiler/xla/service/gpu/runtime:gemm: target '//tensorflow/compiler/xla/service/gpu:non_atomically_upgradeable_rw_lock' does not exist,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version 12.1/8.8.0.121  GPU model and memory NVIDIA GeForce 940MX  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-03-02T19:58:49Z,type:bug type:build/install subtype: ubuntu/linux TF 2.12,closed,0,13,https://github.com/tensorflow/tensorflow/issues/59878,"""Me too""",Backporting the relevant support from the master branch seems to do the trick: naurwlock.patch I have also created a pull request.," Thank you for creating the pull request. We can merge your fix to master first, run all the tests (including nightly tests). If everything is green we can send the cherry pick to r2.12 for review. WDYT?  Could you please take a look and share your guidance?","Looks like this was broken by https://github.com/tensorflow/tensorflow/pull/59842, which cherrypicked 740005d28413923af3f38f7d6401f7f99d26f8f3 into TF 2.12. The PR uses a BUILD target introduced by 890a846bdc26e0e1e66120adb1e2fb2aa33c7323, which was not cherrypicked, which is why the error is occurring. Either https://github.com/tensorflow/tensorflow/pull/59842 should be rolled back or  890a846bdc26e0e1e66120adb1e2fb2aa33c7323 (and potentially other commits 740005d28413923af3f38f7d6401f7f99d26f8f3 relies on) should also be cherrypicked.  tf , how should this be handled?","toplay  Yeah, my pull request is identical to 890a846. I can confirm that this change alone fixes this PR, and there are no further dependencies. I suggest cherrypicking 890a846 into r2.12.","This is very helpful, thank you both for the additional information!",Created https://github.com/tensorflow/tensorflow/pull/59889.,"Hi,   It seems like this PR [ CC(r2.12 cherrypick: 890a846bdc2 ""[xla:gpu] Create a nonatomically upgradeable reader mutex lock that acquires and releases the lock via RAII"")](https://github.com/tensorflow/tensorflow/pull/59889) got merged so could you please try to build tensorflow from source now and check whether are you getting any error or not ? Thank you!","> Hi,  >  > It seems like this PR [ CC(r2.12 cherrypick: 890a846bdc2 ""[xla:gpu] Create a nonatomically upgradeable reader mutex lock that acquires and releases the lock via RAII"")](https://github.com/tensorflow/tensorflow/pull/59889) got merged so could you please try to build tensorflow from source now and check whether are you getting any error or not ? Thank you! Hi , I have managed to rebuild recently, so it seems to work now. Thank you for quick response and support!","Hi,   Good to hear that and thank you for the confirmation, Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? or if you need any further assistance please let us know? Thank you!",">  Hi , My apologies for the last unclear answer. Yes, the issue has been resolved. I was able to both build the new version of tensorflow as well as test it. Thank you for your help!","Hi,   No problem and Good to hear that your issue got resolved and thank you for the confirmation so now I'm closing this issue from my end. If you need any further assistance please feel free to create new issue. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1541,"以下是一个github上的tensorflow下的一个issue, 标题是(BatchToSpaceND and SpaceToBatchND ERROR_GPU_NOT_COMPATIBLE)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 20.04):  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.0  2. Code   3. Failure after conversion 'BatchToSpaceND' ERROR_GPU_NOT_COMPATIBLE 'SpaceToBatchND' ERROR_GPU_NOT_COMPATIBLE  5. (optional) Any other info / logs Hi everyone! I am having issues converting the U2Net model from PyTorch to TFLite for running on Android. My conversion path is PyTorch(pth) > ONNX > TensorFlow > TFLite. An important requirement is that the TFLite model should support GPU execution and needs to be quantized. The main conversion path works fine, but I encountered an error during the TFLite conversion. After some investigation, I found out that if I change the layers with Conv2D parameters dilation > 1 and padding > 1 to dilation=1 and padding=1, the conversion works without any issues. However, this reduces the model's quality. Obviously, if GPU support is disabled, the model can be converted. I have tried using QuantizationDebugOptions and QuantizationDebugger, but it did not yield any results, the error remains the same. Can you please suggest any way to perform this conversion without compromising the model's quality?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ShashmurinSergey,BatchToSpaceND and SpaceToBatchND ERROR_GPU_NOT_COMPATIBLE," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 20.04):  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): 2.10.0  2. Code   3. Failure after conversion 'BatchToSpaceND' ERROR_GPU_NOT_COMPATIBLE 'SpaceToBatchND' ERROR_GPU_NOT_COMPATIBLE  5. (optional) Any other info / logs Hi everyone! I am having issues converting the U2Net model from PyTorch to TFLite for running on Android. My conversion path is PyTorch(pth) > ONNX > TensorFlow > TFLite. An important requirement is that the TFLite model should support GPU execution and needs to be quantized. The main conversion path works fine, but I encountered an error during the TFLite conversion. After some investigation, I found out that if I change the layers with Conv2D parameters dilation > 1 and padding > 1 to dilation=1 and padding=1, the conversion works without any issues. However, this reduces the model's quality. Obviously, if GPU support is disabled, the model can be converted. I have tried using QuantizationDebugOptions and QuantizationDebugger, but it did not yield any results, the error remains the same. Can you please suggest any way to perform this conversion without compromising the model's quality?",2023-03-02T14:47:58Z,stat:awaiting response stat:awaiting tensorflower type:feature stale comp:lite TFLiteConverter TFLiteGpuDelegate TF 2.10,closed,0,13,https://github.com/tensorflow/tensorflow/issues/59870,This is my model. You  can do conversion with my code and reproduce my result. https://drive.google.com/file/d/1nTVfurH8gEjSU8WOx7XHsCqMJwT5g2IT/view?usp=sharing,"Hi , I was able to replicate the issue in Colab using TF v2.10, TF v2.11 and tfnightly(2.13.0.dev20230305). Please find the gists here(2.10), here(2.11)  and here(tfnightly). Thank you!"," Yes, replicate is correct, Thank you! What can you suggest to solve the problem?","Hi   Sorry for the delayed response. The `BATCH_TO_SPACE_ND` and `SPACE_TO_BATCH_ND` are not compatible on GPU. Please find the list of of supported ops on GPU here.  Also, as given in the documentation, > Reshape operations  Some operations that are quick on a CPU may have a high cost for the GPU on mobile devices. Reshape operations are particularly expensive to run, including BATCH_TO_SPACE, SPACE_TO_BATCH, SPACE_TO_DEPTH, and so forth. You should closely examine use of reshape operations, and consider that may have been applied only for exploring data or for early iterations of your model. Removing them can significantly improve performance. The list of ops in the model compatible with GPU can be found using Analyzer. Please find the gist on the usage of the tool for your use case. Thanks. ","Hi ! Thank you for the detailed answer! Why do these layers appear? After all, everything works correctly when we use dilation=1. Is there any way for me to convert this model to TFLite with GPU support? Can I somehow remove these layers?",Hi   They are commonly used in conv2d transpose operation AFAIK. Have you tried in latest TF 2.11 and TF nightly with dilation!=1 and see if issue still exists? Thanks.," But I am not using Conv2d transpose, the error occurs on Conv2d layers with dilation=2, 4, 8. I am using a Docker container with the latest version of TensorFlow, I also tried using a container with tfnightly image, but I still get the same error. Is there any other way to convert Conv2d layer with dilation != 1 without adding BatchToSpaceND and SpaceToBatchND layers?",Hi   Thanks for the information. I have created a toy model with dilation = 1 and dilation = 4. Please find the gist here. The Conv2D adds the BatchToSpaceND and SpaceToBatchND ops when the dilation rate !=1 for appropriate padding to avoid holes in the output. Model with dilation = 4 !model (2) tflite Model with dilation = 1 !model (1) tflite (1) This can also be observed at  https://github.com/tensorflow/tensorflow/blob/d5b57ca93e506df258271ea00fc29cf98383a374/tensorflow/python/ops/nn_ops.pyL1465 as a result those ops are added which are not compatible for tflite GPU support. Thanks.,Hi ! Thank for your answer! Am I correct in understanding that there is no workaround for converting Conv2d with dilation != 1 with GPU support? Could this be possible in the future?, That could be on roadmap. I am not sure about it.  Could you please look into this. Thanks.,"Hi   , if you are able to access a linux system you may be able to resolve your issue by using AIEdgeTorch, you can find more information here: googleblog. I have actually created a simple script for converting a model with BathToSpaceND and SpacetoBatchND layers here:  If you want to, you can actually try visualizing the result in modelexplorer as well. Please try them out and let us know if this resolves your issue. If you still need further help, feel free to open a new issue at the respective repo.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
686,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot place 2 pre-trained models on separate GPUs)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.4.1  Custom Code Yes  OS Platform and Distribution centos 7  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory 2x tesla P40  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,boocheck,Cannot place 2 pre-trained models on separate GPUs,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.4.1  Custom Code Yes  OS Platform and Distribution centos 7  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory 2x tesla P40  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-02T09:23:44Z,stat:awaiting response type:bug stale comp:gpu TF 2.4,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59865,* i have NOT reproduced with tf nightly,"Hi,   Apologize for the delay and if you're using single machine with multiple GPU's (in your case 2 GPU's) then you'll have to go with tf.distribute.MirroredStrategy and you can create `MirroredStrategy` as below which will create a `MirroredStrategy` instance, which will use all the GPUs that are visible to TensorFlow :  You'll have to compile and build your model within `MirroredStrategy` scope so do something like below :  Please refer our official documentation of Distributed training with TensorFlow and please refer these references Ref1, Ref2, I hope it will help you to resolve your issue If issue still persists please let us know ? Thank you!","I am sorry, but this is not solving my problem. I am aware of existance of MirroredStrategy, but too my knowledge, it tries to place whole model on specified GPUs. I cannot use it, because after CNN part (here: VGG16) I need to use heavy memory operation, which cannot fit any GPU memory.  My problem is solvable by architecture like this: !image So what would preferably do is: !image What is puzzling, and makes me believe this may be not intended behavior, when put some plain matmul in place of VGG16 (look: model2 in my original post) it is all working like intended","Hi,   Could you please look into this issue? Thank you!","Hi  , Right now Tensorflow supports Data Parallelism i.e Data will be splitted across the accelerators but the same model will be copied across all these devices(each device have same copy of model but different slices of data). Your ask is for Model parallelism which is not yet supported by Tensorflow. i.e you can't train different models/layers on different machines.This is still under development stage only. Please refer this official tensorflow video tutorial for more detail on this concept. Right now you can use data parallelism using Mirrored strategy. Thankyou!",Hello   this seems not to be true. Have a look at this https://www.tensorflow.org/guide/gpumanual_device_placement,"Hi  , You can choose the device manually using `tf.device` for Ops.AFAIK It does execution of code line by line but not parallel.  But in your case on same model you want to use different devices for different blocks of model which is nothing but Model parallelism which is not yet supported in Tensorflow.For model training on GPUs right now Tensorflow supports data parallelism concept using Distribution training.Since you are trying to use same model but on different devices which is not supported yet on tensorflow.Distribution training is not straight forward, it needs copying the data/model across replicas and it uses all reduce algorithms for cross device communication which is implemented using distribution strategies and only for Data Parallelism as of now. Please refer the attached source that states limitations and status regarding model parallelism. Also Please refer to distribution training documentation for more details.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
697,"以下是一个github上的tensorflow下的一个issue, 标题是(Layer input_spec must be an instance of InputSpec!)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.6  Custom Code No  OS Platform and Distribution windows  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Caolongjie,Layer input_spec must be an instance of InputSpec!,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.6  Custom Code No  OS Platform and Distribution windows  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-03-02T05:39:50Z,type:bug comp:keras 2.6.0,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59863,"Hi ,  Apologies for the delay.  Anything under` tf.python.*` is private, intended for development only, rather than for public use. Importing from tensorflow.python or any other modules (including import tensorflow_core...) is not supported, and can break unannounced.So, it is suggested not to use anything with tf.python.*. You can use `tf.keras.layers.InputSpec` instead of `tensorflow.python.keras.engine.input_spec`. Please find the gist of working code here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,The issue should be opened for bert project not tf. You can close it.,"Anyway, I used my tempory workaound to use bert on tf 2.6.0 gpu version based on python3.9, and will update when bert is updated .",> The issue should be opened for bert project not tf. You can close it. Thank you for confirming. Closing the issue.,Are you satisfied with the resolution of your issue? Yes No
472,"以下是一个github上的tensorflow下的一个issue, 标题是(use list intialization for AsynSubgraph::next_buffer_handle_)， 内容是 (List intialization fixes error of `copying member subobject of type 'std::atomic' (aka 'atomic') invokes deleted constructor` at `std::atomic next_buffer_handle_ = 0;` at `tensorflow/lite/core/async/async_subgraph.h` line:165)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shelper,use list intialization for AsynSubgraph::next_buffer_handle_,List intialization fixes error of `copying member subobject of type 'std::atomic' (aka 'atomic') invokes deleted constructor` at `std::atomic next_buffer_handle_ = 0;` at `tensorflow/lite/core/async/async_subgraph.h` line:165,2023-03-02T01:33:13Z,awaiting review comp:lite ready to pull size:XS,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59860,Hi yang Can you please review this PR ? Thank you!
633,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.scan: add axis argument to scan along a specific axis)， 内容是 (Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution all  Mobile device   Python version 3.9  Bazel version   GCC/Compiler version   CUDA/cuDNN version   GPU model and memory   Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,LJKS,tf.scan: add axis argument to scan along a specific axis,Click to expand!    Issue Type Feature Request  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution all  Mobile device   Python version 3.9  Bazel version   GCC/Compiler version   CUDA/cuDNN version   GPU model and memory   Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-01T14:15:44Z,stat:awaiting response stat:awaiting tensorflower type:feature stale comp:ops,closed,1,9,https://github.com/tensorflow/tensorflow/issues/59850,", Could you please elaborate about the mentioned Feature. Also, please specify the Use Cases for this feature which helps us to analyse. Thank you!","tf.scan applies a function (arg: fn) in a stateful manner. It splits the input tensor (arg: elem) along axis 0 into n elements, where n=tf.shape(elem)[0]. It then applies the function iteratively while also updating/making use of the state to these n elements. The resulting elements are put together (stacked) into a tensor with leading dimension of equal size again.  The feature I'm requesting simple allows for splitting (and iterating over) the tensor along a different axis than the leading axis. Let's run through a potentially typical example, with a tensor of shape=[batch_size, time_steps, features]. Now instead of scanning (tf.scan) over the leading (batch) dimension, one might want to tf.scan over the time_steps axis. Let's assume 'my_bs_ts_feat_tensor' is such a tensor:  I can currently scan along the timesteps axis by applying:   The code above swaps the timestepaxis to the front via transpose, then scans the function along the now leading timestep axis, then transposes the timestep axis back and gets the batchdim again as the leading dimension via transpose again.  The above should be equal to the result of calling tf.scan(my_bs_ts_feat_tensor, axis=1) in what I propose. Or generally instead the proposed behaviour could be achieved (and cheaply implemented) as follows:  let n_axes be the number of axes in the elem tensor (e.g. for my_bs_ts_feat_tensor of shape [batch_size, time_steps, features]: n_axes=3) let axis the the axis argument I would like to propose in the scan function then the proposed better scan with axis would be:  Usecases:    Lots of stuff working with timedimensions   RL applications: E.g. computing the discounted rewardstogo, TDerrors, Advantages, GAEs, etc.   Literally anything else where scan would be applied, and where not by chance the correct split is the batch dimension   Makes some really annoying preprocessing much easier   Makes some comparatively hardtoread code much easier to read",Notes:    I can of course also provide a more TF appropriate version (permutations via tf.range and inferring n_axes via tf.shape(tf.shape(elems))) if there is any upside with that   The same change of adding a axis argument as proposed for scan here would of course also be great for tf.map_fn,"Hi Thanks for the feature request. As already suggested by you as the workaround to transpose and apply scan and transpose back again.   Wouldn't it makes more sense to use the same methods in all your code implementation, rather than adding a new feature. Thanks! ","Hi,  I'm not sure I understand your answer correctly, but let me try:    The workaround obviously works perfectly   However it makes the code much less readable and creates high risk of mistakes for users with less experience   E.g. When scanning along the 4th axis (i.e. axis with index 3) of a tensor with 6 axes:        Perm1: [3,0,1,2,4,5]       Perm2: [1,2,3,0,4,5]   IMO the situation above is a very likely source for creating bugs, especially when code is handed over to other developers, as this is very much not 'intuitive'   From a usage perspective for operations which happen along a certain axis, in TF users are used to the axis argument As such, with the fix being only ~4 lines of easy&quick code, and the change being nonbreaking for existing code, this seems like an attractive feature to me. ",Hi ! Thanks for the request! Would you like to contribute a PR to add this functionality alongside some tests?,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1440,"以下是一个github上的tensorflow下的一个issue, 标题是(`Unsupported object type numpy.ndarray` on multi-input `Dataset`)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Kaggle kernel  Mobile device _No response_  Python version 3.7.12  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue ```shell def read_image(path, rel):      blah blah blah, read somehow     return image def read_image1(path1, filter0):      blah blah blah, read somehow     return image def preprocess(x, y):     def func(x, y):         x = json.loads(x)         x_img1 = read_image(x['path'], x['rel'])  3D image         x_img2 = read_image(x['pathfork'], x['filter']) CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"")D image with different shape          image resizing will lose data         y = tf.keras.utils.to_categorical(y, num_classes=len(set(df['label'].values)))  todo: yeah, i'll optimize it never         return (x_img1, x_img2), y     _x, _y = tf.numpy_function(func, [x, y], [tf.float32, tf.float32])      _x.set_shape([256, 256, 3]) )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,maifeeulasad,`Unsupported object type numpy.ndarray` on multi-input `Dataset`,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Kaggle kernel  Mobile device _No response_  Python version 3.7.12  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue ```shell def read_image(path, rel):      blah blah blah, read somehow     return image def read_image1(path1, filter0):      blah blah blah, read somehow     return image def preprocess(x, y):     def func(x, y):         x = json.loads(x)         x_img1 = read_image(x['path'], x['rel'])  3D image         x_img2 = read_image(x['pathfork'], x['filter']) CC(OSX Yosemite ""can't determine number of CPU cores: assuming 4"")D image with different shape          image resizing will lose data         y = tf.keras.utils.to_categorical(y, num_classes=len(set(df['label'].values)))  todo: yeah, i'll optimize it never         return (x_img1, x_img2), y     _x, _y = tf.numpy_function(func, [x, y], [tf.float32, tf.float32])      _x.set_shape([256, 256, 3]) ",2023-03-01T12:05:19Z,stat:awaiting response type:support stale comp:data TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59848,", Apologies for the delay! Could you please provide the complete code to reproduce the issue which helps us to analyse the issue in an effective way. Thank you",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1878,"以下是一个github上的tensorflow下的一个issue, 标题是(Encounter segment error when trying to deploy tflite model)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):    Ubuntu 20.04.1  TensorFlow installation (pip package or built from source):    Pip package  TensorFlow library (version, if pip package or github SHA, if built from source):    2.11.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab `TF_PATH = ""/data/lxp/mmpose/tf_model"" ` `TFLITE_PATH = ""/data/lxp/mmpose/mmpose.tflite""` `converter = tf.lite.TFLiteConverter.from_saved_model(TF_PATH)` `converter.optimizations = [tf.lite.Optimize.DEFAULT]` `converter.representative_dataset = representative_data_gen` `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]` `converter.target_spec.supported_types = [tf.int8] ` `converter.inference_input_type = tf.int8` `converter.inference_input_type = tf.int8   or tf.uint8` `converter.inference_output_type = tf.int8   or tf.uint8 ` `tf_lite_model = converter.convert()` `with open(TFLITE_PATH, 'wb') as f:` `f.write(tf_lite_model)`  3. Failure after conversion If the conversion is successful, but I encounter segment error when I try to deploy tflite model. Then, I found that error appeared while ""AllocateTensors()"">""graph_.PrepareSubgraphs()"">""registration>prepare(context_, node)"" There, I printed the node id and registration>builtin_code. !image After using netron, we can know the node 24 correspond to FullyConnected. !H2T_QR%WE@$0$8OXO9J7~UT !image Also, go into the funtion ""prepare(context_, node)"" , the error is raised by the following code. `TFLITE_DCHEC)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,HJL8055,Encounter segment error when trying to deploy tflite model," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):    Ubuntu 20.04.1  TensorFlow installation (pip package or built from source):    Pip package  TensorFlow library (version, if pip package or github SHA, if built from source):    2.11.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab `TF_PATH = ""/data/lxp/mmpose/tf_model"" ` `TFLITE_PATH = ""/data/lxp/mmpose/mmpose.tflite""` `converter = tf.lite.TFLiteConverter.from_saved_model(TF_PATH)` `converter.optimizations = [tf.lite.Optimize.DEFAULT]` `converter.representative_dataset = representative_data_gen` `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]` `converter.target_spec.supported_types = [tf.int8] ` `converter.inference_input_type = tf.int8` `converter.inference_input_type = tf.int8   or tf.uint8` `converter.inference_output_type = tf.int8   or tf.uint8 ` `tf_lite_model = converter.convert()` `with open(TFLITE_PATH, 'wb') as f:` `f.write(tf_lite_model)`  3. Failure after conversion If the conversion is successful, but I encounter segment error when I try to deploy tflite model. Then, I found that error appeared while ""AllocateTensors()"">""graph_.PrepareSubgraphs()"">""registration>prepare(context_, node)"" There, I printed the node id and registration>builtin_code. !image After using netron, we can know the node 24 correspond to FullyConnected. !H2T_QR%WE@$0$8OXO9J7~UT !image Also, go into the funtion ""prepare(context_, node)"" , the error is raised by the following code. `TFLITE_DCHEC",2023-03-01T09:18:39Z,stat:awaiting response stale comp:lite TFLiteConverter TF 2.11,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59846,"Hi . Thanks for reporting the issue. Sorry for the delayed response. As per the documentation,  the zero point of the weights in fullyconnected layers is enforced to be zero to avoid the runtime cost of multiplying the zero point of the weight with the activation value.  Can you please provide  the model and steps you have followed in order to reproduce the issue and help troubleshooting process. Thanks.",Closing as stale. Please reopen if you'd like to work on this further. Thanks!
715,"以下是一个github上的tensorflow下的一个issue, 标题是(A check fail can be triggered in tf.ragged.range)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.9 and 2.13.0dev20230219  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,shijy16,A check fail can be triggered in tf.ragged.range,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.9 and 2.13.0dev20230219  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.5  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-03-01T02:59:00Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59844,  I was able to reproduce the issue on Colab using TF 2.11 and tfnightly. Please find the gist of 2.11 and tfnightly for reference.  Thank you !,"Hi,   Apologize for the delay and I was able to replicate the same issue on Google Colab with `tfnightly `and `tensorflow==2.12.0rc0` and code is not executing completely successfully, Here is gistfile and session is getting crashed. It's giving warning `20230303 15:03:16.216167: F tensorflow/core/framework/tensor_shape.cc:201] NonOKstatus: InitDims(dim_sizes) status: INVALID_ARGUMENT: Expected shape dimensions to be nonnegative, got 2147483648`, for your reference I have added screenshot below: !image I have executed the same code multiple times on `Ubuntu 20.04` with `tfnightly` and `tensorflow==2.12.0rc0` I have added detailed log below, It seems like we have to dig more into this issue and we'll update you soon, Thank you for noticing this issue. Thank you! ","Hi,   Could you please look into this issue ? Thank you!","Hi  , The issue got resolved now with tfnightly(2.14.0dev20230514) and now TF is successfully able to raise the intended Error. Please refer to attached gist.  Please check and confirm and let us know if we can close the issue as it resolved now.  Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
597,"以下是一个github上的tensorflow下的一个issue, 标题是([DO NOT REVIEW] Introduce multiple streams execution in TensorFlow.)， 内容是 (Multiple Stream TensorFlow is developed based on the official TensorFlow. It leverages the features of modern GPUs to accelerate deep learning training and inference. This MultiStream implementation has successfully helped several customers migrate their TF models to the GPU and go online. For more details please visit README_MultiStream.md.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,buptzyb,[DO NOT REVIEW] Introduce multiple streams execution in TensorFlow.,Multiple Stream TensorFlow is developed based on the official TensorFlow. It leverages the features of modern GPUs to accelerate deep learning training and inference. This MultiStream implementation has successfully helped several customers migrate their TF models to the GPU and go online. For more details please visit README_MultiStream.md.,2023-03-01T02:34:06Z,size:XL,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59843,"Hi  This PR is in draft, any update on this? Please. Thank you!","Hi  This PR is in draft, any update on this? Please. Thank you!","> Hi  This PR is in draft, any update on this? Please. Thank you! Hi, after discussing with reviewers, the changes will be split into several PRs for merge, such as  CC(Enable graphlevel multiple streams execution.) and  CC(Allow merging streams in one stream group.) so far. So this PR will work as a reference and will not be merged directly.","Hi  This PR is in draft, any update on this? Please. Thank you!"
1354,"以下是一个github上的tensorflow下的一个issue, 标题是(Numpy to tensor)， 内容是 (I apologize for posting a very simple question here as I could not solve the issue myself or find an answer elsewhere. I was trying to make a prediction using a model and a 3D array with 3 channels as inputs. When this 3D array was saved as an image file, I was able to make a proper prediction using my model: `image = tf.io.read_file('image.jpg')` `image = tf.image.decode_image(image, channels=3)` `image = tf.image.resize(images=image, size=[imsize, imsize])` `image = tf.keras.applications.resnet50.preprocess_input(image)` `predictions = model.predict(np.expand_dims(image, axis=0))` However, when this 3D array was readily available in memory as a numpy array in uint8 format, and I tried to directly use this array to make a prediction, I get a different prediction result. I used `cv2.imread` to simulate the array in memory: `array = cv2.imread('image.jpg')` `image = tf.convert_to_tensor(array/255, dtype=tf.float32) ` `image = tf.image.resize(images=image, size=[imsize, imsize])` `image = tf.keras.applications.resnet50.preprocess_input(image)` `predictions = model.predict(np.expand_dims(image, axis=0))` Any help is greatly appreciated! )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,WennPaper,Numpy to tensor,"I apologize for posting a very simple question here as I could not solve the issue myself or find an answer elsewhere. I was trying to make a prediction using a model and a 3D array with 3 channels as inputs. When this 3D array was saved as an image file, I was able to make a proper prediction using my model: `image = tf.io.read_file('image.jpg')` `image = tf.image.decode_image(image, channels=3)` `image = tf.image.resize(images=image, size=[imsize, imsize])` `image = tf.keras.applications.resnet50.preprocess_input(image)` `predictions = model.predict(np.expand_dims(image, axis=0))` However, when this 3D array was readily available in memory as a numpy array in uint8 format, and I tried to directly use this array to make a prediction, I get a different prediction result. I used `cv2.imread` to simulate the array in memory: `array = cv2.imread('image.jpg')` `image = tf.convert_to_tensor(array/255, dtype=tf.float32) ` `image = tf.image.resize(images=image, size=[imsize, imsize])` `image = tf.keras.applications.resnet50.preprocess_input(image)` `predictions = model.predict(np.expand_dims(image, axis=0))` Any help is greatly appreciated! ",2023-02-28T23:22:38Z,stat:awaiting response type:support,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59841,"Hi ,  It seems like you havent filled the issue template, please fill the template for better assistance. It's possible that the issue is related to the difference in color channel ordering between OpenCV and TensorFlow. In OpenCV, the color channels are ordered as BlueGreenRed (BGR), while in TensorFlow the color channels are ordered as RedGreenBlue (RGB). This means that if your model was trained on RGB images, it might not perform well when given input in BGR format.  You can try reversing the order of the color channels in your numpy array before feeding it to your model with `cv2.cvtColor(image, cv2.COLOR_BGR2RGB)`. Modify your code like below and let us know if the issue still persists.  Thank you!","Hi , Your suggestion worked! However, I needed to slightly modify the code by not dividing the array by 255 when feeding it into the `tf.convert_to_tensor` function:  Another observation that I had was, I obtained nearly yet not fully identical prediction results when reading the same image using `tf.io.read_file` and `cv2.imread` respectively: !1                !2 Do you know what might be the reason for that? Thank you!","***** This might help. Pls tell you reviews   **** The difference in prediction results you are seeing could be due to the fact that when you read the image file using tf.io.read_file and tf.image.decode_image, the image is decoded and resized using the default settings, whereas when you directly load the image into memory using cv2.imread and then resize it using tf.image.resize, you are specifying the size explicitly. This can result in differences in the pixel values of the images, which can affect the prediction results. To ensure that the image data you are using to make predictions is consistent, you should try to use the same image loading and preprocessing steps for both cases. You can achieve this by converting the numpy array to a tensor using tf.convert_to_tensor and then following the same image processing steps as before. Code import cv2  Load image into memory as a numpy array array = cv2.imread('image.jpg')  Convert numpy array to tensor and normalize the pixel values image = tf.convert_to_tensor(array, dtype=tf.float32) / 255  Resize the image to the desired size image = tf.image.resize(images=image, size=[imsize, imsize])  Apply the same preprocessing steps as before image = tf.keras.applications.resnet50.preprocess_input(image)  Make the prediction predictions = model.predict(np.expand_dims(image, axis=0))","Hi   The only difference between your suggestion and my code is that you divided the image by 255 after converting the numpy array into a tensor: `image = tf.convert_to_tensor(array, dtype=tf.float32) / 255`. I tested this method, and obtained prediction results that are way off from what I obtained using `tf.convert_to_tensor`. It seems like images should not be divided by 255 after tensor conversion.","> Another observation that I had was, I obtained nearly yet not fully identical prediction results when reading the same image using `tf.io.read_file` and `cv2.imread` respectively: >  > !1 !2 >  > Do you know what might be the reason for that? >  > Thank you! , The two images don't seem to vary in any way. However, one possibility is that the two libraries use different algorithms for decoding the image, which can result in small differences in the pixel values. If the differences are very small and do not significantly affect the performance of your model, then it may not be a cause for concern. Thank you!",Are you satisfied with the resolution of your issue? Yes No
1901,"以下是一个github上的tensorflow下的一个issue, 标题是(Centernet TFLite for multiple keypoint tasks crashes, but only on specific images)， 内容是 ( 1. System information  **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**   Linux Ubuntu 20.04  **TensorFlow installation (pip package or built from source):**   Pip package  **TensorFlow library (version, if pip package or github SHA, if built from source):**   2.11.0  2. Code Drive link to the model, including checkpoints, SavedModel and TFLite model: https://drive.google.com/drive/folders/1E0Ris0mfS4s5iWsLcqIoDK03dQO7nJ7T?usp=sharing Drive link to a working image and a nonworking (crashing) image: https://drive.google.com/drive/folders/1U0Fj8ZYYABRtbXm8hyWexP3gna5_ln9?usp=sharing To convert the model, I first ran the `export_tflite_graph_tf2.py` script (GitHub link) with the following command:  Then, I converted the generated `saved_model` to TFLite using the `tflite_convert.py` script (GitHub link) with the following command:  This successfully generates a `model.tflite` file. To run it, I'm using the following reference code (replacing the `model_path` and `image_path` variables with the correct paths):   3. Failure after conversion Running the code with the image named `working.jpg` produces the following logs, indicating that there is no error:  Running the code with the image named `not_working.jpg` produces the following logs and error:   5. (optional) Any other info / logs 1. There isn't anything special about these two example images, they are from the validation set of Coco2017 (the training set was used for training the model). The same results can be achieved by trying other random images. 2. On the working image, the detections can be printed and visualized, and the keypoints for )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,biantsh,"Centernet TFLite for multiple keypoint tasks crashes, but only on specific images"," 1. System information  **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):**   Linux Ubuntu 20.04  **TensorFlow installation (pip package or built from source):**   Pip package  **TensorFlow library (version, if pip package or github SHA, if built from source):**   2.11.0  2. Code Drive link to the model, including checkpoints, SavedModel and TFLite model: https://drive.google.com/drive/folders/1E0Ris0mfS4s5iWsLcqIoDK03dQO7nJ7T?usp=sharing Drive link to a working image and a nonworking (crashing) image: https://drive.google.com/drive/folders/1U0Fj8ZYYABRtbXm8hyWexP3gna5_ln9?usp=sharing To convert the model, I first ran the `export_tflite_graph_tf2.py` script (GitHub link) with the following command:  Then, I converted the generated `saved_model` to TFLite using the `tflite_convert.py` script (GitHub link) with the following command:  This successfully generates a `model.tflite` file. To run it, I'm using the following reference code (replacing the `model_path` and `image_path` variables with the correct paths):   3. Failure after conversion Running the code with the image named `working.jpg` produces the following logs, indicating that there is no error:  Running the code with the image named `not_working.jpg` produces the following logs and error:   5. (optional) Any other info / logs 1. There isn't anything special about these two example images, they are from the validation set of Coco2017 (the training set was used for training the model). The same results can be achieved by trying other random images. 2. On the working image, the detections can be printed and visualized, and the keypoints for ",2023-02-28T11:10:10Z,stat:awaiting tensorflower type:bug comp:lite TFLiteConverter comp:lite-xnnpack TF 2.11,closed,5,6,https://github.com/tensorflow/tensorflow/issues/59833, Thanks for reporting this issue. I was able to reproduce this issue on TF 2.13 and TF Nightly 2.15.0dev20230824. Please find the gist of 2.13 here and nightly here.  Could you please look into this? Thanks.,Hi   The link to the models seems to be broken. Could you please provide the access to the models and data if possible? Thanks.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hey , apologies for the oversight. I've updated the links and they should be working now.  Thank you!","Hi , Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here. Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
269,"以下是一个github上的tensorflow下的一个issue, 标题是([ROCM] Fix xla_call_module_test)， 内容是 (This PR has added ROCm for xla_call_module_test.  /)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,i-chaochen,[ROCM] Fix xla_call_module_test,This PR has added ROCm for xla_call_module_test.  /,2023-02-28T10:00:03Z,ready to pull comp:gpu size:S,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59831,Hi  Can you please review this PR ? Thank you!,chaochen can you address merge conflicts?,"> chaochen can you address merge conflicts? Thanks  for the notice, it's done!",Hi  Can you please review this PR ? Thank you!
711,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.math.reduce_std on ragged tensors doesn't work properly)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.9  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,CLRW97,tf.math.reduce_std on ragged tensors doesn't work properly,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.9  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-28T08:42:03Z,stat:awaiting response type:bug stale comp:ops TF 2.9,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59830,  I was able to reproduce the issue on colab using TF v2.11. please find the gist here for reference . Thank you !,"I observe the same behavior in `float32` and `float64` in Tensorflow, Could you please let me know what exact values you are referring to and what is the expected values in your case. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
710,"以下是一个github上的tensorflow下的一个issue, 标题是([ROCM] Add ROCM option to tensorflow-build)， 内容是 (This PR adds ROCM support to the tensorflowbuild container framework. The idea is to slot ROCM along side the CUDA container in an unobtrusive way.  The only change on the CUDA side will be needing to explicitly set the config=cuda for the bazel build command, which is probably more proper anyway and matches the main .bazelrc. Setting this as draft so I can to do more testing on the CUDA side to make sure I didn't break anything FYI   I'm interested in your thoughts here. thx!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jayfurmanek,[ROCM] Add ROCM option to tensorflow-build,"This PR adds ROCM support to the tensorflowbuild container framework. The idea is to slot ROCM along side the CUDA container in an unobtrusive way.  The only change on the CUDA side will be needing to explicitly set the config=cuda for the bazel build command, which is probably more proper anyway and matches the main .bazelrc. Setting this as draft so I can to do more testing on the CUDA side to make sure I didn't break anything FYI   I'm interested in your thoughts here. thx!",2023-02-28T05:37:02Z,comp:gpu size:L,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59829,"Thanks for working on this! Can you fork a new directory, like tf_sig_build_dockerfiles_rocm, instead of changing this directory? Afterwards, add ownership details to the top of the README, similar to how subdirectories in the SIG Build repo work. I know that will introduce more work for you because changes to the originals won't carry over to ROCm unless you use symlinks or something similar. However, I want to encapsulate each variant of the containers (official, ROCm, ARM64, etc.) so that our maintainers don't need to worry about colliding with the other variants.","That makes sense. For common files, are symlinks ok, or should we have a common directory or something as well? Sometimes dependencies change we'll have no idea when or why.","Symlinks are good for now, I think. We can look at adding a common directory again later, if it doesn't work out.",Hi  Can you please check 's comments and keep us posted ? Thank you!,Hi  Any update on this PR? Please. Thank you!,I'm going to refactor this according to Austin's comments. I'll open a separate PR for that.
704,"以下是一个github上的tensorflow下的一个issue, 标题是(Missing Window GPU prebuilt binary for 2.11.0)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.11  Custom Code No  OS Platform and Distribution Windows  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,adamcrume,Missing Window GPU prebuilt binary for 2.11.0,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.11  Custom Code No  OS Platform and Distribution Windows  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-02-28T03:46:40Z,stat:awaiting response type:bug type:build/install stale subtype:windows TF 2.11,closed,1,13,https://github.com/tensorflow/tensorflow/issues/59828,"Hi ,  As per the official Tensorflow GitHub page, the `Libtensorflow Windows GPU` is temporarily unavailable. Kindly check this reference. Thank you! ",That's... what I said?,"Hi, We don't support GPU on native Windows since TF 2.10. You can download the binaries for TF 2.10.0 from https://www.tensorflow.org/install/lang_c. ","https://github.com/tensorflow/tensorflow/blob/90fda24ac68fffb9d6c3ca8db0268d47b6404735/README.mdofficialbuilds just says ""Status Temporarily Unavailable"", nothing about it being permanently removed.  Dropping GPU support on Windows wasn't widely announced.  I see https://github.com/tensorflow/tensorflow/releases/tag/v2.11.0 says ""For using TensorFlow GPU on Windows, you will need to install TensorFlow in WSL2"", but that's not even listed under Breaking Changes (which this definitely is!).","I am very disappointed and sad that native windows support was just dropped. Replacing it with wsl2 is not sufficient for processes and systems that don't have the ability to use wsl2 because, for example, they are also windowsnative applications and porting is too expensive. So we can only use version 2.10 (of both the python and the CAPI) and are stuck with it, which is a shame because we can't benefit from and participate in new developments. **All this leads to simply excluding and virtually discriminating against a large part of the Tensorflow community that uses Windows.**  I hope and ask that you **bring back native windows support** and let people decide for themselves if they want to use native or wsl2.  Thank you for the development of Tensorflow!",Thanks for sharing! The change was announced long before 2.11.0 release. Please see https://discuss.tensorflow.org/t/movingtensorflowwindowsgputowsl2/10957. There was also a blog post. I will reach out to the team about the release notes., I want to clarify that native Windows packages for CPU are available.,"toplay Sorry, I meant native Windows GPU (CUDA) support in my post. Windows CPU only is unfortunately not an alternative due to the massive increase in compute time. ",Time to move to PyTorch which isn't biased in favor of an OS only running on 3% of the world's desktops/laptops.,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
840,"以下是一个github上的tensorflow下的一个issue, 标题是(Add new string ops fuzzers and remove old ones)， 内容是 (Adds new string ops fuzzers using the FuzzTest fuzzerstyle, and removes the existing fuzzers for string split operations. The current string split fuzzer are not hitting the logic of the string split operations, because the first argument they pass to the operation is set to be a string rather than a vector of strings. Consequently, the fuzzers are running into some blockers early in the code hindering the fuzzers in exploring the actual logic they target: https://storage.googleapis.com/ossfuzzcoverage/tensorflow/reports/20230225/linux/proc/self/cwd/tensorflow/core/kernels/string_split_op.cc.htmlL177)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,DavidKorczynski,Add new string ops fuzzers and remove old ones,"Adds new string ops fuzzers using the FuzzTest fuzzerstyle, and removes the existing fuzzers for string split operations. The current string split fuzzer are not hitting the logic of the string split operations, because the first argument they pass to the operation is set to be a string rather than a vector of strings. Consequently, the fuzzers are running into some blockers early in the code hindering the fuzzers in exploring the actual logic they target: https://storage.googleapis.com/ossfuzzcoverage/tensorflow/reports/20230225/linux/proc/self/cwd/tensorflow/core/kernels/string_split_op.cc.htmlL177",2023-02-27T21:54:54Z,awaiting review ready to pull size:L,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59827,CC  toplay
1368,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow lite build error for Aarch64 )， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version Tensorflow lite master branch  Custom Code No  OS Platform and Distribution Ubuntu 18.04.6 LTS  Mobile device Nvidia Jetson nano  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  shell Build using above command on Aarch64. I am using Nvidia Jetson Nano with Ubuntu 18.04.6 LTS shell In file included from /home/piyush/tensorflow_src/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/cmake_build/xnnpack/src/amalgam/neonfp16arith.c:8:: /usr/lib/gcc/aarch64linuxgnu/7/include/arm_neon.h:30805:1: error: inlining failed in call to always_inline ‘vaddq_f16’: target specific option mismatch  vaddq_f16 (float16x8_t __a, float16x8_t __b)  ^~~~~~~~~ /home/piyush/tensorflow_src/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/cmake_build/xnnpack/src/amalgam/neonfp16arith.c:120:27: note: called from here          const float16x8_t vsum = vaddq_f16(vsum2345, vsum01678); ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pjindal91,Tensorflow lite build error for Aarch64 ,"Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version Tensorflow lite master branch  Custom Code No  OS Platform and Distribution Ubuntu 18.04.6 LTS  Mobile device Nvidia Jetson nano  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  shell Build using above command on Aarch64. I am using Nvidia Jetson Nano with Ubuntu 18.04.6 LTS shell In file included from /home/piyush/tensorflow_src/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/cmake_build/xnnpack/src/amalgam/neonfp16arith.c:8:: /usr/lib/gcc/aarch64linuxgnu/7/include/arm_neon.h:30805:1: error: inlining failed in call to always_inline ‘vaddq_f16’: target specific option mismatch  vaddq_f16 (float16x8_t __a, float16x8_t __b)  ^~~~~~~~~ /home/piyush/tensorflow_src/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/cmake_build/xnnpack/src/amalgam/neonfp16arith.c:120:27: note: called from here          const float16x8_t vsum = vaddq_f16(vsum2345, vsum01678); ``` ",2023-02-27T13:05:52Z,stat:awaiting response type:build/install stale comp:lite subtype: ubuntu/linux,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59824,Hello   any ideas? Thanks in advance.,Hi  Thanks for reporting the issue. Sorry for the delayed response. You can try to build with target architecture `PYTHON=python3 tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh aarch64` in your case. I was able to build for aarch64 using tool chain as given in documentation successfully on Ubuntu 20.04. Please find the gist here. Thanks.,Hi  thanks for the response. I think the issue might be specific to platform and the ubuntu/glibc versions i am using. Would it be possible for you to try to natively built on aarch64 with Ubuntu 18.04.6 LTS and glibc=2.27?,FYI  in case it helps i was able to build v2.4.0 successfully. So not sure if v2.5.0 is pulling some buggy lib or the above setup i have(Ubuntu 18.04.6 LTS and glibc=2.27) is not compatible with it.,Hi  sorry for the delayed response I have tried to built natively on aarch64 with Ubuntu 18.04.6 LTS and glibc=2.27 with v2.5 and master branch as well and the attempt was successful. Please find the screenshots below For v2.5 !image For master !image Thanks.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
439,"以下是一个github上的tensorflow下的一个issue, 标题是(Recognize Flowers with TensorFlow Lite on Android Codelabs - step 4 error)， 内容是 (Just following the steps on a fresh installation of Android studio on ubuntu get the following error when trying to run: Could not find compile target android29 for modules :start)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,milincheta,Recognize Flowers with TensorFlow Lite on Android Codelabs - step 4 error,Just following the steps on a fresh installation of Android studio on ubuntu get the following error when trying to run: Could not find compile target android29 for modules :start,2023-02-26T16:44:57Z,stat:awaiting response type:support stale comp:lite subtype: ubuntu/linux comp:lite-examples Android,closed,0,30,https://github.com/tensorflow/tensorflow/issues/59815,"  Thanks for reporting the issue. As the error suggest, the Android SDK version 29 might be required for installation.  However, as this is not a bug or feature request related to tensorflow, we encourage you to post it in stack overflow or forum. Thanks.", I think its an error on the tutorial. Should be corrected/clarified?, Could you please let us know which tutorial is being followed. Is it from tensorflow.org? Thanks.,https://codelabs.developers.google.com/codelabs/recognizeflowerswithtensorflowonandroid CC(未找到相关数据) not to mention that once you finish all the steps the whole thing doesn't work :(,Hi  Sorry for the delayed response. I have tried to reproduce the issue by using Android API 29 and I was able to successfully run the code on emulator. Can you please refer to this  CC(TensorFlow Lite GPU segmentation fault) issue on using Flower Classification on latest TF Nightly version and let us know if it helps. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you., Perhaps  Close Android Studio.  Run it as Administrator.  Then create a new project.  Perhaps you had an error before the project was created and ignored it, can I be assignee to solve this issue if it's not solved yet?,"Hi  , I cannot say who is assigned to fix an issue. In my opinion is a deeper fundamental issue that, at the end, discourages people to get into coding. Instead of using your energy to solve your user's problem, you end using it to fix tools, to deal with libraries and versions, googling errors and dealing with tutorials that are wrong. In my case I managed, after hours dealing with errors, to finish the tutorial. Of course didn't work. My app is not doing what is supposed to be doing. Happy to help if you need. Thanks","Hi , sorry for the inconvenience caused. Can I know which Android API and SDK version you are using and did you following the TODO) steps for recognition? The issue is not reproducible at my end. Can you post the errors you have encountered during the process? Thanks.","Hi   API its: Pixel 2 API 30 SDK Android 13 and 10 are installed besides the error I mentioned on the first message, that now I managed to fix somehow. I did the todo however on the code I downloaded some of them were already done... Now when testing on my mobile device I just see: Fake label and no recognition at all. By the way I am using my own network that I trained to recognize fruits instead of flowers.","  so, I noticed that the fake label was there...but couldn't find it on the code..so I checked and there are 2 projects....finish and start? I dont know if that is mentioned and I overlooked it, but anyways confusing. One project is enough. Anyways, trying to run Final and I get: Conflicting declarations: private final val flowerModel: FlowerModel, private final val flowerModel: FlowerModel Conflicting declarations: private final val flowerModel: FlowerModel, private final val flowerModel: FlowerModel Overload resolution ambiguity:  private final val flowerModel: FlowerModel defined in org.tensorflow.lite.examples.classification.MainActivity.ImageAnalyzer private final val flowerModel: FlowerModel defined in org.tensorflow.lite.examples.classification.MainActivity.ImageAnalyzer Unresolved reference. None of the following candidates is applicable because of receiver type mismatch:  public inline fun > Array.sortByDescending(crossinline selector: (???) > ???): Unit defined in kotlin.collections public inline fun > MutableList.sortByDescending(crossinline selector: (???) > ???): Unit defined in kotlin.collections Unresolved reference: it","Hi   You need to work on the `start` project and the TODO have to be done in the `MainActivity.kt` of the start project. To resolve the errors, please add the following lines in the `MainActivity.kt`  and restart the activity Please find the gist here for the reference. You should see something like this after restarting  Thanks.", I give up my friend... those imports where already there. I copy and paste the code you linked and still get errors. I will go back to coding in 20 years when tools are more mature. Thanks for your help!,", Reaching out to you, since I see your name in the document commit history. Do you have any pointers on this?", I can show you what the problem is. Thanks!," , Do you have any solution for it, if so, could you please go ahead and create a PR for same. Thank You"," I have no idea, that is why I create a ticket. Happy to have a call and show you. Thanks!","Hi , Apologies for the frustration, I understand it can be quite frustrating running into errors that basically only computers understand. To help us help you, can you please verify some information about your environment. Specifically, you are using Pixel 2 API 30? Are you using a real phone or an emulator? In your project in Android studio do you know which SDK version you are using? (It says you have 10 and 13 installed). If you can export your Android Studio Project and upload it, it will help us see what is wrong with your project. If you have trouble getting the information from Android Studio, this is an excellent use case to try out bard ex: ""How do I find out which SDK I'm using in Android Studio?"" If you can give us this information, that will help us help you immensely.","Hi, thank you for your contact. I am using a physical device. Pixel 2 API 30. SDK Android 13 and 10 are ticked on the SDK manager. If you want to have a call I can show you more. Thanks!","Hi , apologies, there seems to be a separate issue w/ tflitemodelmaker, as such I can't create the tflite model, Some options include, uploading your tflite model here or exporting your android studio project (with the tflite model included) here.",hi   https://drive.google.com/file/d/1SgTqOcSQKqcHh3Zu4AJHHHB9noCBrvYJ/view?usp=sharing,"Hi , I was able to successfully run the uploaded project on a Pixel 2 API 30 emulator w/o issue... What error are you running into at this point? As you are using a real device, have you updated the android system on your phone? Can you try using an emulator first and tell us how that goes?","hi, it runs...what it is not doing is use my model and detect anything. doesn't work","Hi , does the original model work?",it does on my jupyter notebook," Does the original model work on your phone and does it seems to detect flowers reasonably? I just want to make sure it works without any changes, if it does then we know that the process of switching out your model is not complete (i.e. I think you said you changed your labels up there? there's probably some more work you have to do to connect everything properly)",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
701,"以下是一个github上的tensorflow下的一个issue, 标题是(error with bazel - trying to build windows version of tensorflow for visual studio)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.11  Custom Code No  OS Platform and Distribution windows visual studio 2019  Mobile device no  Python version 3.7  Bazel version 5.3  GCC/Compiler version not sure  CUDA/cuDNN version none  GPU model and memory no  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,scottsmallwood,error with bazel - trying to build windows version of tensorflow for visual studio,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf2.11  Custom Code No  OS Platform and Distribution windows visual studio 2019  Mobile device no  Python version 3.7  Bazel version 5.3  GCC/Compiler version not sure  CUDA/cuDNN version none  GPU model and memory no  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-25T18:21:06Z,stat:awaiting response type:build/install stale subtype:windows TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59810,"Hi,   Apologize for the delay and it seems like this issue is more related with Microsoft C Compiler. Make sure MSVC 2019 PATH is properly set where the python is installed, so that `cl.exe` can be found and I found similar issue, you can refer this comment and you can refer this documentation Configure build environment by using below workaround if you're using `Miniconda` , I hope it will resolve your issue.  You have to create, activate and configure Python environment. Run inside `VS2019 x64 Native Tools Command Prompt`shell command below. You have to correct paths according your Miniconda3 location.  If issue still persists please let us know ? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
770,"以下是一个github上的tensorflow下的一个issue, 标题是(Error when including header files using CMake TF Lite with installable package)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version latest master (commit 1f747f5)   Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version gcc 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory Nvidia GTX 1650 Mobile  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Costa-SM,Error when including header files using CMake TF Lite with installable package,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version latest master (commit 1f747f5)   Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version gcc 11.3.0  CUDA/cuDNN version _No response_  GPU model and memory Nvidia GTX 1650 Mobile  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-25T05:06:36Z,stat:awaiting response type:build/install stale comp:lite subtype: ubuntu/linux TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59806,"Hi, It seems like the missing header files under different directories has been handled in the commit here https://github.com/tensorflow/tensorflow/commit/f167889d58830671d9891b70eac56f075e7e11ee. Could you please test again and let us know if you still face an issue. Thanks!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
343,"以下是一个github上的tensorflow下的一个issue, 标题是(Update the issue template for security vulnerability issue reports)， 内容是 (To encourage users to file security related issue using Google Bug Hunters reporting form.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ymodak,Update the issue template for security vulnerability issue reports,To encourage users to file security related issue using Google Bug Hunters reporting form.,2023-02-25T00:51:18Z,awaiting review ready to pull size:XS,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59802
712,"以下是一个github上的tensorflow下的一个issue, 标题是(Running tensorflow distributed on Multiple workers)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.6  Custom Code Yes  OS Platform and Distribution Linux HPC  Mobile device _No response_  Python version 3.8.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.3.1  GPU model and memory 4 RTX 2080 Ti workers each having 8 GPUs  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dgscharan,Running tensorflow distributed on Multiple workers,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.6  Custom Code Yes  OS Platform and Distribution Linux HPC  Mobile device _No response_  Python version 3.8.3  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.3.1  GPU model and memory 4 RTX 2080 Ti workers each having 8 GPUs  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-24T19:30:14Z,stat:awaiting response type:support stale comp:dist-strat 2.6.0,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59799,"Hi,   Apologize for the delayed response and you can refer our official documentation for tf.distribute.MultiWorkerMirroredStrategy and TF_CONFIG and distributed training guide which may help you to configure the `TF_CONFIG`. , Could you please look into this issue ? Thank you!","Hi  , For multiworker training, as mentioned before, you need to set up the 'TF_CONFIG' environment variable for each binary running in your cluster. For more details please refer to the source here. Please also refer to this tutorial on how to setup multiworkers with custom training.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1508,"以下是一个github上的tensorflow下的一个issue, 标题是(Add s390x support in ParseTensorOp and SerializeTensorOp)， 内容是 (Subtest `tensorflow.python.ops.io_ops.serialize_tensor` in test case `//tensorflow/tools/docs:tf_doctest` failed on s390x (bigendian arch), because the serialized binary strings which represent the tensor data are different between littleendian and bigendian platforms. This PR adds the endianness conversion procedure for bigendian systems in the implementation of ParseTensorOp and SerializeTensorOp (in `tensorflow/core/kernels/parse_tensor_op.cc`), so that the serialized binary strings generated on bigendian systems will be in littleendian format as well and identical to the ones generated on littleendian systems. The code change in `tensorflow/python/kernel_tests/io_ops/parsing_ops_test.py` ensures the serialized proto string in `ParseTensorOpTest.testToFloat32()` would be in littleendian format on bigendian platforms, which is consistent with the updated code flow in `SerializeTensorOp`. `//tensorflow/tools/docs:tf_doctest` will pass on bigendian systems after applying the code change. It won't affect the functionality and performance on littleendian systems.  This PR also updated the api documentation for `tf.io.serialize_tensor` and `tf.io.parse_tensor` to indicate the serialized binary strings are in littleendian format. Signedoffby: KunLu )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kun-lu20,Add s390x support in ParseTensorOp and SerializeTensorOp,"Subtest `tensorflow.python.ops.io_ops.serialize_tensor` in test case `//tensorflow/tools/docs:tf_doctest` failed on s390x (bigendian arch), because the serialized binary strings which represent the tensor data are different between littleendian and bigendian platforms. This PR adds the endianness conversion procedure for bigendian systems in the implementation of ParseTensorOp and SerializeTensorOp (in `tensorflow/core/kernels/parse_tensor_op.cc`), so that the serialized binary strings generated on bigendian systems will be in littleendian format as well and identical to the ones generated on littleendian systems. The code change in `tensorflow/python/kernel_tests/io_ops/parsing_ops_test.py` ensures the serialized proto string in `ParseTensorOpTest.testToFloat32()` would be in littleendian format on bigendian platforms, which is consistent with the updated code flow in `SerializeTensorOp`. `//tensorflow/tools/docs:tf_doctest` will pass on bigendian systems after applying the code change. It won't affect the functionality and performance on littleendian systems.  This PR also updated the api documentation for `tf.io.serialize_tensor` and `tf.io.parse_tensor` to indicate the serialized binary strings are in littleendian format. Signedoffby: KunLu ",2023-02-24T18:45:40Z,awaiting review ready to pull size:S comp:core,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59798,"Hi  , I added a space before `""//tensorflow/core/util/tensor_bundle:byteswaptensor""` in `tensorflow/core/kernels/BUILD` as per the format checking result from the latest `Code Check  Changed Files`. Please take a look when you have some time. Thank you very much!","Hi  , Could you please take a look at the PR update when you have some time? Thank you very much!",Thanks  !
1285,"以下是一个github上的tensorflow下的一个issue, 标题是(AutoGraph did convert this function: NameError: name 'Tuple' is not defined)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Mac, Linux, Google Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_   Current Behaviour? `tf.function` fails when type annotations are used which are locally imported. I get:  Note: * It seems important that `Tuple` is locally imported. If it is imported globally in the module, there does not seem to be a problem. * When I use `from __future__ import annotations`, there is also no error. But I assume because this will just not evaluate it directly, but it still lacks the `Tuple` reference, although it's maybe really not relevant then.  Standalone code to reproduce the issue  Colab link: https://colab.research.google.com/drive/1K69XH_RsUUxRBfUd0B4eR8iJFTXoFM?usp=sharing  Relevant log output )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,albertz,AutoGraph did convert this function: NameError: name 'Tuple' is not defined,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Mac, Linux, Google Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_   Current Behaviour? `tf.function` fails when type annotations are used which are locally imported. I get:  Note: * It seems important that `Tuple` is locally imported. If it is imported globally in the module, there does not seem to be a problem. * When I use `from __future__ import annotations`, there is also no error. But I assume because this will just not evaluate it directly, but it still lacks the `Tuple` reference, although it's maybe really not relevant then.  Standalone code to reproduce the issue  Colab link: https://colab.research.google.com/drive/1K69XH_RsUUxRBfUd0B4eR8iJFTXoFM?usp=sharing  Relevant log output ",2023-02-24T14:12:46Z,stat:awaiting tensorflower type:bug comp:tf.function TF 2.11,open,0,7,https://github.com/tensorflow/tensorflow/issues/59796,"Hi , thank you for reporting the issue. , I was able to replicate the issue in colab using TF v2.11 and tfnightly(2.13.0dev20230228). Please find the gists for the same  hereTF v2.11 and heretfnightly. Thanks!  ","Hi  , It seems we need to import Tuple outside the function.Please refer to the attached gist. By importing the Tuple at Global level  it is working fine.",I know. But this is a bug. This should not be necessary.,"Hi  , You need to wrap the entire function `f() ` with `tf.function` decorator and inside that you can import Tuple and make it workable.This is applicable for both 1.x and 2.x versions.Please refer attached gist. Whenever we call `f()` with some input,as it is having `local_func` under `tf.function` decorator and `tf.function` when called will have two stages normally.First stage is tracing for creation of tf.Graph and the second stage is execution of graph(only TF operations). If we enclose the complete function under tf.function then this works as intended.","In my case, I cannot do that. The outer function must be a regular (nonTF) Python function. But in any case, this is still a TF bug. It should not be necessary to use such workarounds.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",Well there is a Colab linked in my original report. You could simply try that? Just click on run. I just did that now. And the same problem still occurs in TensorFlow 2.18.0.
1070,"以下是一个github上的tensorflow下的一个issue, 标题是(assertAlmostEqual raise confusing error message when test fails)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.9  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_   Current Behaviour? I seem to observe to issues with `assertAlmostEqual` of `tf.test.TestCase` 1. When using `assertAlmostEqual` and when it fails, the error message is confusing. Instead of saying the test fails, it shows the following error message:  2. when I set the `places` to a smaller value that I think should allow the test to pass, the test still fails with the above error message. When the difference is indeed smaller than the default `places=7`, the test passes.  Standalone code to reproduce the issue )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dongyaoli10x,assertAlmostEqual raise confusing error message when test fails,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.9  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_   Current Behaviour? I seem to observe to issues with `assertAlmostEqual` of `tf.test.TestCase` 1. When using `assertAlmostEqual` and when it fails, the error message is confusing. Instead of saying the test fails, it shows the following error message:  2. when I set the `places` to a smaller value that I think should allow the test to pass, the test still fails with the above error message. When the difference is indeed smaller than the default `places=7`, the test passes.  Standalone code to reproduce the issue ",2023-02-24T01:56:25Z,stat:awaiting response type:bug stale comp:apis TF 2.9,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59789,"Hi , kindly let us know the OS Platform and Distribution used to exceute the above code. I tried executing it in Ubuntu 22.04. Please find the output below. !image Thank you!","> Hi , kindly let us know the OS Platform and Distribution used to exceute the above code. I tried executing it in Ubuntu 22.04. Please find the output below. !image Thank you! Thank you  for your quick response! The OS is centos 7.9.2009. But it looks like the error message you got with ubuntu 22.04 is the same",Thank you for sharing the details. I replicated the issue in CentOS. Please find the complete error below.   The first test case `test_dummy_confusing_bug` fails with an error message   This error occurs because the `self.assertAlmostEqual` function is not able to perform the numpy operation 'astype' on the EagerTensor objects a and b.  The second test case `test_dummy_confusing_error` also fails with the same error message as the first test case.,"To fix the issue, as a workaround you can modify the assertion to compare the numpy values of the tensors instead of the tensors themselves. Here's the modified code:  In these modified tests, the `numpy()` method is called on the tensors a and b to obtain their numpy values, and the `assertAlmostEqual()` method is used to compare the numpy values instead of the tensors themselves. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
985,"以下是一个github上的tensorflow下的一个issue, 标题是(Performance Enhancements for Sparse Embedding Lookups)， 内容是 (Introduces performance options for sparse embedding lookups that can appreciably speed up the training of recommendation systems. Sparse lookups alternatively accept inputs described by RaggedTensors which are more memory efficient. Performance is further increased by the optional use of a simplified and typically faster embedding lookup. In the sparse embedding micro benchmarks in tensorflow/python/eager/benchmarks_test.py, the number of examples per second on a DGX A100 system increases from approx. 1,300 with SparseTensor and without simplified lookup to approx. 11,200 with RaggedTensor inputs and simplified lookup (+760%). The combination of SparseTensor inputs and simplified lookup yields approx. 3,000 examples per second (+130%).)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,philipphack,Performance Enhancements for Sparse Embedding Lookups,"Introduces performance options for sparse embedding lookups that can appreciably speed up the training of recommendation systems. Sparse lookups alternatively accept inputs described by RaggedTensors which are more memory efficient. Performance is further increased by the optional use of a simplified and typically faster embedding lookup. In the sparse embedding micro benchmarks in tensorflow/python/eager/benchmarks_test.py, the number of examples per second on a DGX A100 system increases from approx. 1,300 with SparseTensor and without simplified lookup to approx. 11,200 with RaggedTensor inputs and simplified lookup (+760%). The combination of SparseTensor inputs and simplified lookup yields approx. 3,000 examples per second (+130%).",2023-02-23T20:35:53Z,ready to pull size:XL,closed,1,1,https://github.com/tensorflow/tensorflow/issues/59788, Can you please resolve conflicts? Thank you!
746,"以下是一个github上的tensorflow下的一个issue, 标题是(Error When Trying to Get Value for bert_model in ""Classify text with BERT"" tutorial)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.4.4  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hilalgenc,"Error When Trying to Get Value for bert_model in ""Classify text with BERT"" tutorial",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.4.4  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-02-23T10:00:02Z,type:bug comp:apis TF 2.4,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59781,"I'm sorry to hear that you're encountering an error when trying to get the value for bert_model in the ""Classify text with BERT"" tutorial. Here are some possible solutions: Make sure you have installed the necessary packages. The tutorial requires tensorflow, tensorflowtext, and tensorflowhub. You can install them using pip:  `pip install tensorflow tensorflowtext tensorflowhub ` Check that you're using the correct BERT model. The tutorial uses the bert_en_uncased_L12_H768_A12 model, which is a smaller and faster version of BERT. Make sure you've downloaded and unzipped this model to the correct directory. You can download it using the following command: `!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L12_H768_A12.zip !unzip uncased_L12_H768_A12.zip ` Verify that the path to the BERT model is correct. In the tutorial, the path is set to ./bert_en_uncased_L12_H768_A12/. Doublecheck that this path is correct and that you're not missing any files. Try clearing the TensorFlow session and reloading the BERT model. You can do this using the following code: `import tensorflow as tf import tensorflow_hub as hub tf.keras.backend.clear_session() bert_layer = hub.KerasLayer(""./bert_en_uncased_L12_H768_A12"") ` If none of the above solutions work, try restarting your Python kernel and rerunning the code from the beginning of the tutorial. I hope one of these solutions helps you resolve the error. Let me know if you have any further questions or concerns!","I successfully completed the tutorial, and the code worked. It just took longer than expected. Unfortunately, I did not record how long it took for the line of code to run.  I am closing this issue because I no longer have any questions. ",Are you satisfied with the resolution of your issue? Yes No
1679,"以下是一个github上的tensorflow下的一个issue, 标题是(TensorFlow crashes with a segfault)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tensorflowmacos 2.11.0  Custom Code Yes  OS Platform and Distribution MacOS 12, tensorflowmacos and tensorflowmetal  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_   GPU model and memory Apple M1  Current Behaviour? It crashes on Apple M1 hardware. It should not crash. It does not crash on other hardware. I think the code should work. It does work fine on other hardware. But even if there is sth wrong with the code, it still should not crash, but throw some exception instead.  Standalone code to reproduce the issue On Apple M1 hardware: * Checkout https://github.com/rwthi6/returnn. (Maybe commit 3a67da87c2fd8783c5c2469d72cf1319b5b45837 to be sure.) * Run: `python3 tests/test_TFUtil.py test_get_variable_grad_from_update_ops` The relevant code: * https://github.com/rwthi6/returnn/blob/3a67da87c2fd8783c5c2469d72cf1319b5b45837/tests/test_TFUtil.pyL3507 * https://github.com/rwthi6/returnn/blob/3a67da87c2fd8783c5c2469d72cf1319b5b45837/returnn/tf/util/basic.pyL6649 Specifically:  But there are a few helpers `get_variable_grad_from_update_ops`, `get_var_update_ops` etc.  Relevant log output  Stack trace in LLDB in the crashing thread:  As you see from the output, the crash happens in the last `session.run([minimize_op, grad])`.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,albertz,TensorFlow crashes with a segfault,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tensorflowmacos 2.11.0  Custom Code Yes  OS Platform and Distribution MacOS 12, tensorflowmacos and tensorflowmetal  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_   GPU model and memory Apple M1  Current Behaviour? It crashes on Apple M1 hardware. It should not crash. It does not crash on other hardware. I think the code should work. It does work fine on other hardware. But even if there is sth wrong with the code, it still should not crash, but throw some exception instead.  Standalone code to reproduce the issue On Apple M1 hardware: * Checkout https://github.com/rwthi6/returnn. (Maybe commit 3a67da87c2fd8783c5c2469d72cf1319b5b45837 to be sure.) * Run: `python3 tests/test_TFUtil.py test_get_variable_grad_from_update_ops` The relevant code: * https://github.com/rwthi6/returnn/blob/3a67da87c2fd8783c5c2469d72cf1319b5b45837/tests/test_TFUtil.pyL3507 * https://github.com/rwthi6/returnn/blob/3a67da87c2fd8783c5c2469d72cf1319b5b45837/returnn/tf/util/basic.pyL6649 Specifically:  But there are a few helpers `get_variable_grad_from_update_ops`, `get_var_update_ops` etc.  Relevant log output  Stack trace in LLDB in the crashing thread:  As you see from the output, the crash happens in the last `session.run([minimize_op, grad])`.",2023-02-23T09:13:00Z,stat:awaiting response type:bug subtype:macOS TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59780,"Hi,   Apologize for the delay and I was able to reproduce the issue, I was also getting the same error which you've mentioned above and as per official documentation, There is currently no official GPU support for MacOS. It's better to post this issue here for fast resolution. Thank you! ","Ok, I posted it here: https://developer.apple.com/forums/thread/725592",Are you satisfied with the resolution of your issue? Yes No
793,"以下是一个github上的tensorflow下的一个issue, 标题是(You must feed a value for placeholder tensor ... with dtype int32)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v1.12.189814gbaac3548e86 2.13.0dev20230222  Custom Code No  OS Platform and Distribution Fedora Linux 37  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA Version: 12.0, CUDNN unavailable,  not using gpu anyway  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Davidy22,You must feed a value for placeholder tensor ... with dtype int32,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version v1.12.189814gbaac3548e86 2.13.0dev20230222  Custom Code No  OS Platform and Distribution Fedora Linux 37  Mobile device _No response_  Python version 3.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA Version: 12.0, CUDNN unavailable,  not using gpu anyway  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-02-23T09:00:19Z,stat:awaiting response stat:awaiting tensorflower type:bug comp:ops TF 2.11,closed,8,22,https://github.com/tensorflow/tensorflow/issues/59779,"Hi , We were able to replicate the issue in Fedora Linux 37 using tfnightly from our end as well. Please find the screenshot of the same below. !image It seems like we have to dig more into this issue, we will update soon here. Thank you!","Hi  , Thanks for reporting. This problem already brought to our attention.This log is safe to ignore as you can see the below message from log. It is also not affecting the functionality here. Please refer to the comment here that this log may provide context for some other errors for certain use cases.But it should be moved to debug log for which action is under progress. > Executor start aborting (this does not indicate an error and you can ignore this message)","Yeah, it didn't actually impact any of my running code, which ran pretty much the same between tf 2.11 and 2.12 with the only visible difference being that unsightly message. The downgrade would be appreciated, I would like to have less harmless error messages filling screens when not needed","Hi  , Incase If you want to filter out the logs to only Warning and above levels you can use the below code at the top of your code. ","Oh that'll be nice. I assume it'll also potentially end up hidiing messages that I might want to see, but this should be good enough until the  tf release happens that cleans this up. I'm on 2.12 RC0, I presume I'll see the resolution to this come down in the final release?"," , This is already under purview of Developer team.I hope this might be resolved in next release mostly.  Thanks!",I had this error on Ubuntu 22.04 as well as Fedora 37,"> TF_CPP_MIN_LOG_LEVEL This did not work for me.  Instead, in terminal: `export TF_CPP_MIN_LOG_LEVEL=2`",Same issue (a lot of spam messages) starting from tf 2.12,"Hi , Commit 80a4e5f9e4e103f722df3632db88fdb31537bb26 introduced extra log messages (for most Intel Models) and caused performance degradation. Intel would like to know if this change can be rolled back. Could you please share your thoughts?",Somebody helpe me please... 20230522 20:15:25.042266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled. 20230522 20:15:25.047489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled. 20230522 20:15:33.030265: I tensorflow/core/common_runtime/executor.cc:1210] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): CANCELLED: GetNextFromShard was cancelled 	 [[{{node MultiDeviceIteratorGetNextFromShard}}]] 20230522 20:15:33.030866: I tensorflow/core/common_runtime/executor.cc:1210] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): CANCELLED: GetNextFromShard was cancelled 	 [[{{node MultiDeviceIteratorGetNextFromShard}}]] 	 [[RemoteCall]] [type.googleapis.com/tensorflow.DerivedStatus=''],">  , This is already under purview of Developer team.I hope this might be resolved in next release mostly. >  > Thanks! any update regarding it  ",>  Make sure you `os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'` before you import tensorflow.,It's a bad decision to make unuseful logging and force users to disable it.,"It isn't very pleasant to see all those messages, but it does not affect training.","The problem is that in the flood of many ""fake"" warnings, the real one can get lost.",CC ing   for update.,"> Hi  , Incase If you want to filter out the logs to only Warning and above levels you can use the below code at the top of your code. >  >  This solved my issue of flooding my terminal with `You must feed a value for placeholder tensor....` warning log. I am using **Google Colab**.",Any chance of backporting a fix for this from TF2.13 into TF2.12.x?,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.","Oh, I haven't seen the issue in a while, fully forgot about it. I guess if I haven't seen it that probably means this got cleared up at some point. I kind of thought a dev would have closed this ticket after fixing the issue, I see there was a PR that referred to this ticket a while back and then we didn't have anyone come round to close this when that got merged, I'll close this one now.",Are you satisfied with the resolution of your issue? Yes No
718,"以下是一个github上的tensorflow下的一个issue, 标题是(Library not loaded: @rpath/libgpr.20.dylib Rosetta2 conda env)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.7.4  Custom Code Yes  OS Platform and Distribution macos Ventura 13.2.1 (22D68)  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pabloazurduy,Library not loaded: @rpath/libgpr.20.dylib Rosetta2 conda env,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.7.4  Custom Code Yes  OS Platform and Distribution macos Ventura 13.2.1 (22D68)  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-23T02:47:07Z,stat:awaiting response type:bug stale subtype:macOS TF 2.7,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59778,"Hi,   Apologize for the delay and if you don't mind could you please help me with the exact steps which you're following for installing the Tensorflow on `rosetta x86_64` ? If possible please help me with below commands output it seems like some issue with setting up environment variable at the moment, meanwhile could you please try with `python 3.8` or `python 3.9` instead of `python 3.7` with stable version of `Tensorflow(2.11) `and check whether is it resolving your issue or not ? Thank you! 1. conda version 2. printenv",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1872,"以下是一个github上的tensorflow下的一个issue, 标题是(save.save_model in training.py directs to wrong file)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11  Custom Code No  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.2.2 cudnn=8.1.0  GPU model and memory _No response_  Current Behaviour? Hey, so I stumbled into this while trying to save a more complex custom model than the one I'll discuss here and getting errors that were reported already in other issues but had remained unsolved. I knew from my dealing with the errors in my other model that saving my model worked fine in TF2.3 but crashed in 2.11 and I had my suspicions as to what caused the problem. So I created a dummy test that would throw an error (TypeError: 'int' object is not iterable) to be able to check how TF goes through the source code. I executed this once with my old TF2.3 installation and once with my current TF 2.11 installation (did this in 2 different virtual environments). In both version when calling save on a Keras model that then essentially executes   which is in tensorflow.python.keras.engine.training.py>Model class>def save() In TF2.3 that then calls the save_model function in tensorflow.python.keras.saving.save.py In TF2.11 that calls the save function in tensorflow.python.keras.saving.saved_model.save.py which is odd, because the other function still exits and the new function isn't documented nearly as good as the old one is In TF2.11 the error disappears when setting save_traces=False. In TF2.3)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mibumi,save.save_model in training.py directs to wrong file,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11  Custom Code No  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version cudatoolkit=11.2.2 cudnn=8.1.0  GPU model and memory _No response_  Current Behaviour? Hey, so I stumbled into this while trying to save a more complex custom model than the one I'll discuss here and getting errors that were reported already in other issues but had remained unsolved. I knew from my dealing with the errors in my other model that saving my model worked fine in TF2.3 but crashed in 2.11 and I had my suspicions as to what caused the problem. So I created a dummy test that would throw an error (TypeError: 'int' object is not iterable) to be able to check how TF goes through the source code. I executed this once with my old TF2.3 installation and once with my current TF 2.11 installation (did this in 2 different virtual environments). In both version when calling save on a Keras model that then essentially executes   which is in tensorflow.python.keras.engine.training.py>Model class>def save() In TF2.3 that then calls the save_model function in tensorflow.python.keras.saving.save.py In TF2.11 that calls the save function in tensorflow.python.keras.saving.saved_model.save.py which is odd, because the other function still exits and the new function isn't documented nearly as good as the old one is In TF2.11 the error disappears when setting save_traces=False. In TF2.3",2023-02-22T17:49:13Z,stat:awaiting response type:bug stale comp:keras TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59776,"  Could you please import `tensorflow.keras.models` instead of `tensorflow.python.keras.models`.  > Anything under tf.python.* is private, intended for development only, rather than for public use. > Importing from tensorflow.python or any other modules (including import tensorflow_core...) is not supported, and can break unannounced.So, it is suggested not to use anything with tf.python.*. I was able to execute the given code without an error on Colab using TF v2.11. Please find the gist here for reference. Thank you !","That looks like the right answer.  tensorflow.python.keras.models is not the right coide path, we're removing this from the package in 2.12, all of that code comes from the standalone keras package now.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.  Thanks !,Are you satisfied with the resolution of your issue? Yes No
766,"以下是一个github上的tensorflow下的一个issue, 标题是(DepthwiseConv2D is 24 times slower then Conv2D with CUDA 11.8 and jit_compile=True)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 'v1.12.189750g9f16e373ca8', '2.13.0'  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version 12.0 / 8.8  GPU model and memory RTX 4090 Aorus Master  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,shkarupa-alex,DepthwiseConv2D is 24 times slower then Conv2D with CUDA 11.8 and jit_compile=True,"Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 'v1.12.189750g9f16e373ca8', '2.13.0'  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10.6  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version 12.0 / 8.8  GPU model and memory RTX 4090 Aorus Master  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_",2023-02-22T09:20:16Z,stat:awaiting response stat:awaiting tensorflower stale comp:ops type:performance TF 2.11,closed,0,12,https://github.com/tensorflow/tensorflow/issues/59772,"Downgrading to cuda 11.8 did not help.  But when i downgraded to TF 2.11 and cuda 11.2, depthwise conv become just 2 times slower then normal one.  Compilation from source with TF 2.11 and Cuda 11.2 required to limit compute compatibility with 8.6 And now, when running model i get warning: ","alex, Thank you for reporting the issue. This issue is more related to Keras. Development of keras moved to another repository.  Could you please post this issue on kerasteam/keras repo. To know more please refer: https://discuss.tensorflow.org/t/kerasprojectmovedtonewrepositoryinhttpsgithubcomkerasteamkeras/1999 Thank you!", could you please explain why do you think this issue is related to keras? Under the hood it uses tf.nn.depthwise_conv2d which is a part of tensorflow core. There is no something unusual in this layer except that. So i think this issue is fully related to TF.,", I was able to reproduce the issue on tensorflow v2.11 and tfnightly. Kindly find the gist of it here.","Hi, TF 2.12 or TF 2.13 is still a development branch, we are planning to migrate the cuDNN, CUDA versions in the upcoming Tensorflow 2.12 release.  Till then could you please test it against the published tested configurations as below. Version  11.2 As per your findings, `DepthwiseConv2D` is 2x slower than Conv2D, it might be because of the different implementation methods followed in DepthwiseConv2D.","> Till then could you please test it against the published tested configurations as below.  , my test with stable release and cuda 11.2 is here https://github.com/tensorflow/tensorflow/issues/59772issuecomment1440047780 // ptxas warnings and DWConv is 2x slower","More confusing is that DWConv with jit_compile=True is slower then itself without jit_compile > RTX4090 + Cuda 12.0 + Cudnn 8.8 + TF nightly with fp32 > dw=True,  jit_compile=True,  ETA after 200 steps: 3:43:26 > dw=False, jit_compile=True,  ETA after 200 steps:    9:13 > dw=True,  jit_compile=False, ETA after 200 steps:   26:18",Tested with fresh 2.12 release + cuda 11.8 and saw same numbers. Conv2D = 4m 31s  vs DepthwiseConv2d = 1h 17m 22s,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1875,"以下是一个github上的tensorflow下的一个issue, 标题是(tensorflow static library of windows: missing few files)， 内容是 (Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: Its tensorflow provided code as given in https://www.tensorflow.org/install/lang_c    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**: Laptop    **TensorFlow installed from (source or binary)**: static library from https://www.tensorflow.org/install/lang_c    **TensorFlow version (use command below)**: 2.11    **Python version**: NA    **Bazel version (if compiling from source)**: NA    **GCC/Compiler version (if compiling from source)**: 12.2    **CUDA/cuDNN version**:NA    **GPU model and memory**: NA    **Exact command to reproduce**: Took static library from tensorflow ebsite from link bel)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,ignvinay,tensorflow static library of windows: missing few files,"Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: Its tensorflow provided code as given in https://www.tensorflow.org/install/lang_c    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**: Laptop    **TensorFlow installed from (source or binary)**: static library from https://www.tensorflow.org/install/lang_c    **TensorFlow version (use command below)**: 2.11    **Python version**: NA    **Bazel version (if compiling from source)**: NA    **GCC/Compiler version (if compiling from source)**: 12.2    **CUDA/cuDNN version**:NA    **GPU model and memory**: NA    **Exact command to reproduce**: Took static library from tensorflow ebsite from link bel",2023-02-21T17:44:16Z,stat:awaiting response type:build/install type:support stale subtype:windows TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59762,"Hi,   Apologize for the delay and I was able to replicate same issue on Google Colab which uses `Ubuntu OS` so it's working as expected, here is gistfile so we'll try on Windows 10 and we'll let you know soon and Thank you for noticing this issue. Thank you!","Hi, i got the same issue on Win10 and Visual Studio 2019 and the prebuild Tensorflow lib in Version 2.11 (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflowcpuwindowsx86_642.11.0.zip).  Also tried older versions of TF like 2.6 and there is the same problem.  There is no tensorflow/c/tf_buffer.h. The file doesnt exist. I downloaded the linux version and here the tf_buffer.h exists. Please help :(","Hi Zarzaro and gaikwadrahul,        I could able to get it working. The include folder is missing two folders which are required for building. These two folders i picked it from linux version of package as include files are more of header files, which would be independent of OS. The include folder > tensorflow > should look like this : !image Just in case if you still need whole include folder, i am attaching here for your reference. Please replace this include folder with include folder of TensorFlow. include.zip",Are you satisfied with the resolution of your issue? Yes No,"Hm okay at least that seems to be a solution. But its not straight forward. Is that a build bug? Are we the first two persons that are using the prebuilt lib from tensorflow for Windows? A prebuilt lib should be straight forward to use in my opinion.  I even tried to build the dll etc from tensorflow since since 3 days without final success. The bazel build of dll, lib and headers is finally completed successfully but i get errors in Visual Studio as well when i try to run a simple hello world project.  It seems Tensorflow is not meant to be used in c++. Very little documentation for this inconvenient build process.  ","Yeah, it's cool that there's a workaround, but it would be much better if we could find the script that makes these, and fix it. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"also missing from the include ""patch"" is file ""tensorflow/tsl/c/tsl_status.h"" (there might be others)"
727,"以下是一个github上的tensorflow下的一个issue, 标题是(`tensorflow.experimental.numpy.kron` not working with multidimensional Arrays)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.9.1  Custom Code Yes  OS Platform and Distribution Linux ubuntu 18.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,fnhirwa,`tensorflow.experimental.numpy.kron` not working with multidimensional Arrays,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.9.1  Custom Code Yes  OS Platform and Distribution Linux ubuntu 18.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-21T17:38:45Z,stat:awaiting response stat:awaiting tensorflower type:bug comp:ops TF 2.9,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59761,", I was able to reproduce the issue on tensorflow v2.9, v2.11 and tfnightly. Kindly find the gist of it here.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",Closing this in favor of https://github.com/tensorflow/tensorflow/issues/83037 tested with the latest version as suggested.,Are you satisfied with the resolution of your issue? Yes No
863,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix the endianness issue in `//tensorflow/python/framework:tensor_util_test` on s390x)， 内容是 (Test case `//tensorflow/python/framework:tensor_util_test` failed on s390x (bigendian arch) because in `testHalf()` function the `tensor_content` data which is used for comparison with the tensor proto string is hardcoded in littleendian format. This PR followed the existing pattern in `testFloatMutateArray()` function to add an endianness check in `testHalf()` function and choose the corresponding `tensor_content` data which is in consistent with the platform endianness. The above mentioned test case will pass on both littleendian and bigendian systems after applying the code change.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kun-lu20,Fix the endianness issue in `//tensorflow/python/framework:tensor_util_test` on s390x,Test case `//tensorflow/python/framework:tensor_util_test` failed on s390x (bigendian arch) because in `testHalf()` function the `tensor_content` data which is used for comparison with the tensor proto string is hardcoded in littleendian format. This PR followed the existing pattern in `testFloatMutateArray()` function to add an endianness check in `testHalf()` function and choose the corresponding `tensor_content` data which is in consistent with the platform endianness. The above mentioned test case will pass on both littleendian and bigendian systems after applying the code change.,2023-02-21T16:59:41Z,awaiting review ready to pull size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59759,"Hi  , Could you please review this PR when you have some time? Thank you very much!"
671,"以下是一个github上的tensorflow下的一个issue, 标题是(Update image_ops_impl.convert_image_dtype.py)， 内容是 (Images that are represented using floating point values are expected to have values in the range [0,1) for the function `convert_image_dtype()`.  But this is not scaled when the case `image `argument is of `float ` and `dtype` argument is `int` arises.  Hence modified the code to bring the input values within [0,1). This also shall fix the issue CC(The results of tf.image.convert_image_dtype running on CPU and GPU are very different.) .)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,SuryanarayanaY,Update image_ops_impl.convert_image_dtype.py,"Images that are represented using floating point values are expected to have values in the range [0,1) for the function `convert_image_dtype()`.  But this is not scaled when the case `image `argument is of `float ` and `dtype` argument is `int` arises.  Hence modified the code to bring the input values within [0,1). This also shall fix the issue CC(The results of tf.image.convert_image_dtype running on CPU and GPU are very different.) .",2023-02-21T10:34:59Z,comp:ops size:XS,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59755
775,"以下是一个github上的tensorflow下的一个issue, 标题是(inconsistent selection of optimizers)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Ubuntu  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  keras.optimizers.optimizer_experimental.adam.Adam  keras.optimizers.optimizer_v2.adam.Adam ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,saswatac,inconsistent selection of optimizers,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Ubuntu  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  keras.optimizers.optimizer_experimental.adam.Adam  keras.optimizers.optimizer_v2.adam.Adam ```  Relevant log output _No response_,2023-02-21T07:51:34Z,type:bug comp:keras TF 2.11,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59751,"The new optimizers are the default after 2.11. Yes, there were some breaking changes in the switch.  See the 2.11 release notes for details",Are you satisfied with the resolution of your issue? Yes No
728,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.data.Dataset is much slower than Python generator producing the same data)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution MacOS 12.6.3  Mobile device _No response_  Python version 3.10.6  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,pbav,tf.data.Dataset is much slower than Python generator producing the same data,Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution MacOS 12.6.3  Mobile device _No response_  Python version 3.10.6  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-20T16:58:15Z,stat:awaiting response stale comp:data type:performance TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59744,"Thank you for reporting this issue with TensorFlow! It's possible that you are observing slower performance when iterating over a tf.data.Dataset compared to a Python generator that produces the same data. One possible reason for this difference in performance could be due to the additional overhead introduced by tf.data.Dataset. While tf.data.Dataset provides many useful features such as shuffling, batching, and prefetching, these operations can introduce additional overhead that might make it slower than a Python generator in some cases. It's important to note that the performance of tf.data.Dataset can vary based on several factors, such as the size and complexity of the dataset, the specific operations being applied, and the hardware being used. It's possible that in some cases, tf.data.Dataset might be faster than a Python generator. To investigate this issue further, you might consider profiling your code using TensorFlow's builtin profiling tools or a thirdparty profiling tool such as cProfile. This can help you identify specific operations or areas of your code that might be introducing additional overhead. Additionally, you might consider upgrading to a newer version of TensorFlow (such as TensorFlow 2.7 or later) or using TensorFlow nightly builds to see if this issue has already been resolved or improved in a newer version. Finally, if you're still experiencing performance issues with tf.data.Dataset, you might consider using alternative data loading methods such as tf.keras.utils.Sequence or tf.data.experimental.CsvDataset. These methods might offer better performance depending on your specific use case. I hope this helps! Let me know if you have any further questions or concerns.","I'm talking here about a difference of two orders of magnitude. It's not just the usual ""in one case one option is better, in another case another option is better"". There really seems to be something wrong with the multiinput tf.data.Dataset, which makes it almost unusable. I had to rewrite my code without tf.data, because otherwise the bare iteration  before any processing  over a dataset of 2 million records (about 150 columns, mixed types: strings, integers, floats, booleans) takes more than an hour.","Hi  , Thanks for bringing this. In my opinion this comparison seems unfair.As you know `tf.data.Dataset` is a `data pipeline` more than a data generator and will have some overheads compared to normal python generator . Your compared only data generator times. It will be fair if you actually pass both of them to a model(large enough for comparison) and compare training time. This will provide more context to look into the issue whether there is really a performance issue.  Thanks!",Closing as stale. Please reopen if you'd like to work on this further. Thanks.,Are you satisfied with the resolution of your issue? Yes No
690,"以下是一个github上的tensorflow下的一个issue, 标题是(Fails to build with llvm-project repository override)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 11.3  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,RoboTux,Fails to build with llvm-project repository override,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 11.3  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-20T12:53:23Z,type:build/install subtype: ubuntu/linux awaiting PR merge TF 2.9,closed,0,14,https://github.com/tensorflow/tensorflow/issues/59739,This happens because vars.bzl is created by the implementation function of llvm_configure() which is not called in the case of a repository override. I think the instructions should be modified to override llvmraw instead which only requires creating a WORKSPACE and BUILD.bazel in the LLVM repo and does not need to create an overlay. I'm happy to provide a patch for that.,"Hi,   Apologize for the delay and It seems like there is some issue with the `local_repository` rule in `bazel` is for external bazel repositories only. To use a nonbazel external repository, we need to use `new_local_repository `which takes `build_file` as an argument. Bazel has the `new_local_repository` check this link `https://bazel.build/reference/be/workspacenew_local_repository` which allows you to use a local directory as a repo. You will need to change the `tf_http_archive(name = ""llvmproject"",...)` section in `tensorflow/workspace.bzl `into `new_local_repository`, and add necessary BUILD files for llvm, mlir, and mlir/tests directory in your `local llvm directory.` you can check this discussion and stack overflow answer, I hope it will help you to resolve your issue. If something is missing in the instructions and you've workaround for it then PR will be welcomed from your end so please submit PR for it ? Thank you for noticing the issue in our instructions. Thank you!",Any reason why we don't override llvmraw instead of llvmproject? When I tried it seemed to work fine and avoid the issues mentionned here. The patch I have is to change the instructions to override llvmraw instead of llvmproject.,"Hi, dude! Did u solve this problem? I ran into the same problem as you.  I followed the steps given in the readme, and roll back the version of llvmproject to corresponding version.  When I start build   I got Error output below    Standalone code to reproduce the issue   Environment ","Hi,   Apologize for the delayed response and May I know have you tried this workaround, If yes is it resolving your issue or not ? I see  has submitted one PR 59942 to solve this issue so we'll wait to merge that PR, meanwhile if you did not follow above workaround could you please give it try ? Thank you!","Hi,   Sorry for replying so late. I did try this, but I'm not sure if I tried it correctly. I modified the `tensorflow/workspace.bzl`(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace2.bzl), added the following content to it, but it did't work  I just don't know how to modify the  `tensorflow/workspace.bzl`  correctly, for I don't know anything about bazel","I saw RoboTux's  PR https://github.com/tensorflow/tensorflow/pull/59942 had  failed merge test, maybe I'll try it (qwq or could someone give me an alternative method that I can try","> I saw RoboTux's PR CC(Use llvmraw override for build w/ local LLVM repo) had failed merge test, maybe I'll try it (qwq >  > or could someone give me an alternative method that I can try I don't think the failure is related to the patch since it fails to find patchelf and the patch only changes the documentation which does not require patchelf to build obviously. I'd be interested to know if the new instructions suggested in the patch fail to work for you. Best regards, Thomas","Hi, Thomas I'm sorry to inform you that it(PR https://github.com/tensorflow/tensorflow/pull/59942) didn't work  for me ：( it returns me the ERROR below  I will try to try other ways I can find, thanks a lot Best regards, Tingfeng","Why does it mention (absolute: ""/Volumes/back/mlir_project/llvmproject/bazel"")  insteal of /Volumes/back/mlir_project/llvmproject? Is your llvm tree checkout out in the bazel directory?",I used the command `git checkout 31c39439a894` in the llvmproject main folder ( download at 22:30 3.7.2023),"> I used the command `git checkout 31c39439a894` in the llvmproject main folder ( download at 22:30 3.7.2023) What was the bazel command that you ran? Note: there is a mistake in my patch, the bazel build line should be LLVM_SRC not LLVM_BAZEL_OVERLAY","There have been too many things in the course recently, I sincerely apologize for my late answer  at the first I used   I was so impetuous that I didn't notice the problem with the bazel build line  just now I tried   I get Error below  I did install llvm, `lldb version` will output `lldb version 15.0.5`  the full build info  Thank you for all your help Best regards, Tingfeng",Are you satisfied with the resolution of your issue? Yes No
861,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to run quantized Bert model)， 内容是 ( 1. System information  OS Platform and Distribution: Ubuntu 22.04, aarch64  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): tensorflowcpuaws==2.11.0  Model library: transformers==4.26.1  2. Code   3. Failure after conversion The conversion is successful, but interpreter's invoke() fails with segmentation fault.  4. (optional) RNN conversion support N/ A  5. (optional) Any other info / logs I was mainly following the example code here, and tried to convert Bert model to a quantized one. The interpreter failed with the following error: )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,yd2102,Unable to run quantized Bert model," 1. System information  OS Platform and Distribution: Ubuntu 22.04, aarch64  TensorFlow installation (pip package or built from source): pip  TensorFlow library (version, if pip package or github SHA, if built from source): tensorflowcpuaws==2.11.0  Model library: transformers==4.26.1  2. Code   3. Failure after conversion The conversion is successful, but interpreter's invoke() fails with segmentation fault.  4. (optional) RNN conversion support N/ A  5. (optional) Any other info / logs I was mainly following the example code here, and tried to convert Bert model to a quantized one. The interpreter failed with the following error: ",2023-02-17T19:15:18Z,stat:awaiting response stale comp:lite TFLiteConverter TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59730, Thanks for reporting the issue. I was able to reproduce this issue in TF 2.11. Please find the gist here. The issue seems to be resolved in TF nightly version. I was able to run the quantized bert model with out any error. Please find the gist here and let us know if it helps.  Thank you.," Thank you for the update. I tried your suggestion and updated TF to nightly version, on my end it still failed. Although I'm not sure what caused that, it appears there's some invalid memory access? I originally observed this issue on aarch64, but now I'm also seeing the same issue on x86_64 instance. To illustrate the problem, I ran the same python script multiple times. And sometimes it failed on the Gather operation:  while other times the model output just seems to be random (because I've used fixed random seed in the script). Note that the printed elements below are emitted by this API:   I've also reproduced the issue on your colab session by running the script multiple times.", Thanks for the information. I was able to reproduce after multiple runs. Please find the gist here.  Could you please look into this? Thanks!,"Hi , It looks like we are calling `resize_tensor_input` on what looks to be output related arguments:  We shouldn't need to resize output tensors, this may be a mistake. Could you remove these lines and try again?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
732,"以下是一个github上的tensorflow下的一个issue, 标题是(Modifying the original tensor can change the value of copied tensor)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0.dev20230204  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,trickiwoo,Modifying the original tensor can change the value of copied tensor,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0.dev20230204  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-17T17:32:28Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59729,Hey  try this `x_copy = tf.identity(x)` instead of  `x_copy = tf.experimental.numpy.copy(x)`.,FYI follow this link : https://www.tensorflow.org/api_docs/python/tf/identity,", **tfnightly v2.13.0.dev20230204** which is not the stable version. I tried to execute the code multiple tiimes with the stable version **tf 2.11** and haven't faced any issue. Kindly find the text of the same and also the image below for the reference. !image "," Shouldn't we investigate the issue on the nightly build, to ensure that we don't have a regression waiting for us later? The issue is reproducible using the nightly build  although **it does not happen on all runs**. You may have to run the code many times to observe it. It seems to reproduce on a much higher percentage of runs on my laptop compared to on Colab. Here's a gist reproducing the issue on nightly. Here's a gist reproducing the issue on 2.11.",Thanks for getting back to me! I can still reproduce this issue. Please run it multiple times. Thanks!,"Hi,   Apologize for the delayed response and I was able to replicate the issue and I have executed the same code more than 100 times with `tfnightly`, `tensorflow==2.11`,`tensorflow==2.12.0rc0`, `tensorflow==2.12.0rc1`  and in my case I got error with `tfnightly`, for your reference I have added gistfile so we'll have to dig more into this issue because as you got error with `TF2.11` also and this behaviour is happening after running the same code multiple times so we'll update you soon, Thank you for noticing this issue. , Could you please look into this issue? Thank you!",", I tried to execute the above code in multiple iterations in the same colab notebook and observed it was executed without any fail/error. Kindly find the gist of it here. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
685,"以下是一个github上的tensorflow下的一个issue, 标题是(RaggedTensor slice gradient computation error)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,cbreak-black,RaggedTensor slice gradient computation error,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-17T16:11:20Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,1,7,https://github.com/tensorflow/tensorflow/issues/59727,  I was able to replicate the issue in Ubuntu and colab. Please find the gist here for TF v2.10 and here for tfnightly. Thank you!,"black ,Thanks for reporting this. The error is raised from below code.  from source: https://github.com/tensorflow/tensorflow/blob/735b325c4ba38da4c5fc265036606ce22838a242/tensorflow/python/eager/backprop.pyL606L616 The code indicates `grad` is of `indexed_slices.IndexedSlices` and `grad.values` should return a `Tensor` as per IndexedSlices API.  If the reported code snippet failing  then the below code from above code block also may fail which needs to be checked.  It may need to be digged more for root cause. Thanks!","Hi, as far as I was able to find with my limited knowledge of tensorflow's internals is that grad.values is itself an `IndexedSlices` typed object. I did not find out if this is expected (apparently not), and how this came to be.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
794,"以下是一个github上的tensorflow下的一个issue, 标题是(""unknown rank error"" in tensorflow.keras.layers.Layer with tensorflow.py_function output)， 内容是 (Issue Type > Bug Have you reproduced the bug with TF nightly? > No Tensorflow Version > v2.11.0rc217gd5b57ca93e5,  2.11.0 Custom Code > Yes OS Platform and Distribution > Google colab   Standalone code to reproduce the issue   Relevant log output   But works fine if we reverse the order (i.e. tf.numpy_function cannot properly cast back outputs to tensors)   Output  ```shell  CC(""Cannot take the length of shape with unknown rank"" error) ""Cannot take the length of shape with unknown rank"" error in but not resolved. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,MegaCreater,"""unknown rank error"" in tensorflow.keras.layers.Layer with tensorflow.py_function output","Issue Type > Bug Have you reproduced the bug with TF nightly? > No Tensorflow Version > v2.11.0rc217gd5b57ca93e5,  2.11.0 Custom Code > Yes OS Platform and Distribution > Google colab   Standalone code to reproduce the issue   Relevant log output   But works fine if we reverse the order (i.e. tf.numpy_function cannot properly cast back outputs to tensors)   Output  ```shell  CC(""Cannot take the length of shape with unknown rank"" error) ""Cannot take the length of shape with unknown rank"" error in but not resolved. ",2023-02-17T13:28:37Z,stat:awaiting response type:bug stale comp:autograph comp:core TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59726,I was able to reproduce this issue in TF 2.11 and TF Nightly 2.13.0dev20230219 . Please find the gist here.   Could you please look into this issue. Thanks. ,"Hi  , The error might be due to python function using inside the Graph for which the shape is unknown.Hence getting the error:Unknown rank error. The proposed workaround is you have add this code `inputs.set_shape([None,32,32,3])` after tf.nupmy_function like below. .function  Please refer to the attached gist here. Hope this will solve your purpose. Thanks!"," thanks a lot. But this I already know. This solution I have already mentioned here  https://github.com/tensorflow/tensorflow/issues/37193issuecomment1434693519.  But this issue must be resolved. This issue is very old as stated here  CC(""Cannot take the length of shape with unknown rank"" error)  but till now not solved. Adding `.function` created issue only when with `tf.numpy_function` why cannot be redefine this `tf.numpy_function` function. ",Can we update something here > https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/script_ops.pyL768  somthing like this >  ,"Hi  , I have tested the proposed changes and seems working fine for this case.Please refer to attached tested gist. At least the changes works fine with and without .function. I am not sure whether this covers all cases or not. Also it involves the structural changes in API as it adds new argument also.This may needs to be reviewed properly for short falls if any. The proposed changes relies completely on input_shape which we are assuming that output_shape also being same as input_shape. What about the case when there is change in shapes that actually happens inside the numpy_method ? Could we cover this to all use cases ?  Thanks!","Yes we can. When the shapes of output is same then user wont have to pass `output_shape` variable (i.e `output_shape=None`, but when `output_shape` changes then `output_shape` has to be provided. Give me some time to work on it more. I will update you.  But still with this update `rank` issue is not resolved. I am look for that also.  "," , If `output_shape` shape has to be passed by the user explicitly when output_shape changes based on computation then the same thing can be done by `inputs.set_shape([None,32,32,3]) ` that proposed in earlier workaround right. I would like to understand how it is different from earlier workaround. For me the earlier work around using `set_shape` might work for all cases.Is there any exception for this ?",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,I feel like this should be documented officially. I just wasted a few hours pulling my hairs :(
1227,"以下是一个github上的tensorflow下的一个issue, 标题是(Building for mac catalyst)， 内容是 (Hi I created a stackoverlfow post already: https://stackoverflow.com/questions/75473220/buildtensorflowliteformaccatalyst/75480973 CC(未找到相关数据)73 But I thought I should have asked here first.  System information    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac mini M1 Ventura 13.1    **TensorFlow installed from (source or binary)**: source    **TensorFlow version (use command below)**: 2.10.0    **Python version**: 3.10.8    **Bazel version (if compiling from source)**: 5.3.0    **GCC/Compiler version (if compiling from source)**: clang 14.0.0    **Exact command to reproduce**: bazel build config=catalyst //tensorflow/lite:tensorflowlite.framework  Describe the problem So I'm trying to build tensorflow lite from source (github) with bazel for mac catalyst and I wanted to know if it is featured and if not if there is anyway I could build it.  Source code / logs For now without modification of any sort I have this error: `ERROR: Config value 'catalyst' is not defined in any .rc file` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Nnevalti,Building for mac catalyst,"Hi I created a stackoverlfow post already: https://stackoverflow.com/questions/75473220/buildtensorflowliteformaccatalyst/75480973 CC(未找到相关数据)73 But I thought I should have asked here first.  System information    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac mini M1 Ventura 13.1    **TensorFlow installed from (source or binary)**: source    **TensorFlow version (use command below)**: 2.10.0    **Python version**: 3.10.8    **Bazel version (if compiling from source)**: 5.3.0    **GCC/Compiler version (if compiling from source)**: clang 14.0.0    **Exact command to reproduce**: bazel build config=catalyst //tensorflow/lite:tensorflowlite.framework  Describe the problem So I'm trying to build tensorflow lite from source (github) with bazel for mac catalyst and I wanted to know if it is featured and if not if there is anyway I could build it.  Source code / logs For now without modification of any sort I have this error: `ERROR: Config value 'catalyst' is not defined in any .rc file` ",2023-02-17T09:57:40Z,stat:awaiting tensorflower type:feature type:build/install comp:lite subtype:macOS TF 2.10,closed,1,11,https://github.com/tensorflow/tensorflow/issues/59723,"Hi,   Could you please look into this issue ? Thank you!","Hi , as far as I know we don't especially support mac catalyst, can you try doing whatever you want to do with normal iOS/macOS workflows and see if you run into any trouble? If so, we can identify more specifically what is unsupported and possibly make a feature request.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hello, so in the end I changed my code so I can use the MacOS library instead of catalyst. I did not succeed in compiling for Mac Catalyst, I lack knowledge for it !","Hi , can you show me how you tried compiling (i.e. what commands you used) and the error you get? Thanks.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"It's been a long time so I don't remember everything, all I know is that i tried using bazel but there is no rule for the catalyst build. I don't remember if I tried to build using Cmake (for catalyst at least), I just used it to build the regular MacOS M1 library. Currently I'm still a beginner concerning compilation and cross compilation, so I'm not sure about what needs to be done for it to work.","Hi , fair enough, if you can replicate the issue, please let us know.","It's not an issue, tensorflow just doesn't support catalyst build. I don't think it's an important feature, but I think it could help people in the future to look into it !","Hi , Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here. Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
693,"以下是一个github上的tensorflow下的一个issue, 标题是(Inconsistent Runtime of XLA Compiled Model Inference)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8.13  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.6  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,benson-guo,Inconsistent Runtime of XLA Compiled Model Inference,Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8.13  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.6  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-16T23:52:28Z,stat:awaiting response stale comp:xla type:performance TF 2.11,closed,0,18,https://github.com/tensorflow/tensorflow/issues/59719,"guo, I was able to replicate the issue in Ubuntu 20.04 using tensorflow 2.11.  Kindly check the output below , please look at this issue. Thank you! ``` Iteration 0 time: 2445.906400680542 Iteration 1 time: 1.2180805206298828 Iteration 2 time: 0.8792877197265625 Iteration 3 time: 0.7956027984619141 Iteration 4 time: 0.8134841918945312 Iteration 5 time: 0.8347034454345703 Iteration 6 time: 0.7798671722412109 Iteration 7 time: 0.7691383361816406 Iteration 8 time: 0.79345703125 Iteration 9 time: 0.8080005645751953 Iteration 10 time: 0.8664131164550781 Iteration 11 time: 0.8289813995361328 Iteration 12 time: 0.8101463317871094 Iteration 13 time: 0.78582763671875 Iteration 14 time: 0.7910728454589844 Iteration 15 time: 0.8423328399658203 Iteration 16 time: 0.8206367492675781 Iteration 17 time: 0.8051395416259766 Iteration 18 time: 0.7901191711425781 Iteration 19 time: 0.8213520050048828 Iteration 20 time: 0.8761882781982422 Iteration 21 time: 0.8149147033691406 Iteration 22 time: 0.858306884765625 Iteration 23 time: 0.7889270782470703 Iteration 24 time: 0.8196830749511719 Iteration 25 time: 0.7832050323486328 Iteration 26 time: 0.8084774017333984 Iteration 27 time: 0.8132457733154297 Iteration 28 time: 0.8044242858886719 Iteration 29 time: 0.8461475372314453 Iteration 30 time: 0.7991790771484375 Iteration 31 time: 0.8070468902587891 Iteration 32 time: 0.8008480072021484 Iteration 33 time: 0.7684230804443359 Iteration 34 time: 0.8289813995361328 Iteration 35 time: 0.7951259613037109 Iteration 36 time: 0.8077621459960938 Iteration 37 time: 0.8130073547363281 Iteration 38 time: 2.5610923767089844 Iteration 39 time: 6.946086883544922 Iteration 40 time: 6.997823715209961 Iteration 41 time: 6.977558135986328 Iteration 42 time: 6.984710693359375 Iteration 43 time: 6.985187530517578 Iteration 44 time: 6.985664367675781 Iteration 45 time: 6.982564926147461 Iteration 46 time: 6.853818893432617 Iteration 47 time: 6.2713623046875 Iteration 48 time: 6.274938583374023 Iteration 49 time: 6.271839141845703 (tf) ynandiubuntu2004:~$ ","   Thanks for a having a look. For reference, I had also posted this in the TF forums: https://discuss.tensorflow.org/t/inconsistentruntimeofcompiledmodelinference/14895.  Someone had suggested it could be due to thermal throttling, but I was not able to notice a drop in core clock speed.",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"guo, I tried to execute the code with **iterations=50 and iterations=100** and observed that the runtime was increased at different points in both cases. It might be due to the computations happening in the middle of the code and also it depends on the GPU where we were trying to execute the code. **Iterations:100** 20230301 09:13:19.755700: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process. Iteration 0 time: 2830.5792808532715 Iteration 1 time: 1.2085437774658203 Iteration 2 time: 0.9257793426513672 Iteration 3 time: 0.8394718170166016 Iteration 4 time: 0.8671283721923828 Iteration 5 time: 0.804901123046875 Iteration 6 time: 0.8020401000976562 Iteration 7 time: 0.8029937744140625 Iteration 8 time: 0.7991790771484375 Iteration 9 time: 0.8249282836914062 Iteration 10 time: 0.8022785186767578 Iteration 11 time: 0.7832050323486328 Iteration 12 time: 0.8487701416015625 Iteration 13 time: 0.8215904235839844 Iteration 14 time: 0.7920265197753906 Iteration 15 time: 0.8149147033691406 Iteration 16 time: 0.7905960083007812 Iteration 17 time: 0.7901191711425781 Iteration 18 time: 0.8051395416259766 Iteration 19 time: 0.7903575897216797 Iteration 20 time: 0.8058547973632812 Iteration 21 time: 0.7767677307128906 Iteration 22 time: 0.8132457733154297 Iteration 23 time: 0.7922649383544922 Iteration 24 time: 0.7941722869873047 Iteration 25 time: 0.7932186126708984 Iteration 26 time: 0.7929801940917969 Iteration 27 time: 0.8213520050048828 Iteration 28 time: 0.7803440093994141 Iteration 29 time: 0.7965564727783203 Iteration 30 time: 0.7948875427246094 Iteration 31 time: 0.8120536804199219 Iteration 32 time: 0.8111000061035156 Iteration 33 time: 0.7951259613037109 Iteration 34 time: 0.7946491241455078 Iteration 35 time: 0.7963180541992188 Iteration 36 time: 0.8103847503662109 Iteration 37 time: 0.7822513580322266 **Iteration 38 time: 0.7915496826171875 Iteration 39 time: 4.862785339355469 Iteration 40 time: 6.767034530639648** Iteration 41 time: 6.778955459594727 Iteration 42 time: 6.768226623535156 Iteration 43 time: 6.769895553588867 Iteration 44 time: 6.781578063964844 Iteration 45 time: 6.75511360168457 Iteration 46 time: 6.757020950317383 Iteration 47 time: 6.769657135009766 Iteration 48 time: 6.767749786376953 Iteration 49 time: 6.76274299621582 Iteration 50 time: 6.770610809326172 Iteration 51 time: 6.770133972167969 Iteration 52 time: 6.761789321899414 Iteration 53 time: 6.768226623535156 Iteration 54 time: 6.76727294921875 Iteration 55 time: 6.767988204956055 Iteration 56 time: 6.771087646484375 Iteration 57 time: 6.768465042114258 Iteration 58 time: 6.776332855224609 Iteration 59 time: 6.762504577636719 Iteration 60 time: 6.757020950317383 Iteration 61 time: 6.764411926269531 Iteration 62 time: 6.769895553588867 Iteration 63 time: 6.777286529541016 Iteration 64 time: 6.75654411315918 Iteration 65 time: 6.771326065063477 Iteration 66 time: 6.752252578735352 Iteration 67 time: 6.765127182006836 Iteration 68 time: 6.781578063964844 Iteration 69 time: 6.740093231201172 Iteration 70 time: 6.770610809326172 Iteration 71 time: 6.651401519775391 Iteration 72 time: 6.081104278564453 Iteration 73 time: 6.009101867675781 Iteration 74 time: 5.947589874267578 Iteration 75 time: 5.949735641479492 Iteration 76 time: 5.953550338745117 Iteration 77 time: 5.947351455688477 Iteration 78 time: 5.955934524536133 Iteration 79 time: 5.97071647644043 Iteration 80 time: 6.098508834838867 Iteration 81 time: 6.084680557250977 Iteration 82 time: 6.083011627197266 Iteration 83 time: 6.061077117919922 Iteration 84 time: 6.080389022827148 Iteration 85 time: 6.068229675292969 Iteration 86 time: 6.074428558349609 Iteration 87 time: 6.0787200927734375 Iteration 88 time: 6.091594696044922 Iteration 89 time: 6.074190139770508 Iteration 90 time: 6.08372688293457 Iteration 91 time: 6.079673767089844 Iteration 92 time: 6.080865859985352 Iteration 93 time: 6.078004837036133 Iteration 94 time: 6.106138229370117 Iteration 95 time: 6.051301956176758 Iteration 96 time: 5.996227264404297 Iteration 97 time: 5.947113037109375 Iteration 98 time: 5.954742431640625 Iteration 99 time: 6.06536865234375 Iteration 100 time: 6.131410598754883 `Iterations:100` 20230301 09:08:55.643995: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process. Iteration 0 time: 3033.7562561035156 Iteration 1 time: 2.8045177459716797 Iteration 2 time: 0.9644031524658203 Iteration 3 time: 0.8635520935058594 Iteration 4 time: 0.8149147033691406 Iteration 5 time: 0.8897781372070312 Iteration 6 time: 0.8149147033691406 Iteration 7 time: 0.8230209350585938 Iteration 8 time: 0.8220672607421875 Iteration 9 time: 0.7984638214111328 Iteration 10 time: 0.8337497711181641 Iteration 11 time: 0.7987022399902344 Iteration 12 time: 0.7767677307128906 Iteration 13 time: 0.8323192596435547 Iteration 14 time: 0.7944107055664062 Iteration 15 time: 0.7920265197753906 Iteration 16 time: 0.7965564727783203 Iteration 17 time: 0.7848739624023438 Iteration 18 time: 0.8008480072021484 Iteration 19 time: 0.8194446563720703 Iteration 20 time: 0.79345703125 Iteration 21 time: 0.7944107055664062 Iteration 22 time: 0.7903575897216797 Iteration 23 time: 0.8323192596435547 Iteration 24 time: 0.7834434509277344 Iteration 25 time: 0.7383823394775391 Iteration 26 time: 0.7770061492919922 Iteration 27 time: 0.7696151733398438 Iteration 28 time: 0.8041858673095703 Iteration 29 time: 0.7872581481933594 Iteration 30 time: 0.8168220520019531 Iteration 31 time: 0.7634162902832031 Iteration 32 time: 0.8182525634765625 Iteration 33 time: 0.7886886596679688 Iteration 34 time: 0.8273124694824219 Iteration 35 time: 0.7882118225097656 **Iteration 36 time: 0.8006095886230469 Iteration 37 time: 7.169246673583984 Iteration 38 time: 11.08241081237793** Iteration 39 time: 11.090517044067383 Iteration 40 time: 11.073827743530273 Iteration 41 time: 11.065483093261719 Iteration 42 time: 11.078357696533203 Iteration 43 time: 9.224891662597656 Iteration 44 time: 9.146690368652344 Iteration 45 time: 9.139060974121094 Iteration 46 time: 9.15384292602539 Iteration 47 time: 9.148120880126953 Iteration 48 time: 9.152650833129883 Iteration 49 time: 9.154081344604492 Iteration 50 time: 9.14454460144043 Also we observed that the change in the runtime was not at the same interval point for every execution. Thank you!","Hi   So I was reading from this paper (https://hallirmm.ccsd.cnrs.fr/lirmm03775613/document) that in eager async mode, tensorflow operations can return handles that have not been computed yet. To see if that's the case for the compiled function, I tried to force the computation to synchronously execute before the end of the timing block by adding a conditional branch dependent on the result of the inference.  The resulting profiled runtimes seems consistent now after a few iterations. Iteration 0 time: 5936.74898147583 Iteration 1 time: 22.758007049560547 Iteration 2 time: 22.4761962890625 Iteration 3 time: 22.189855575561523 Iteration 4 time: 22.08256721496582 Iteration 5 time: 22.035837173461914 Iteration 6 time: 22.022485733032227 Iteration 7 time: 22.035837173461914 Iteration 8 time: 22.036075592041016 Iteration 9 time: 22.014141082763672 Iteration 10 time: 22.00603485107422 Iteration 11 time: 20.064592361450195 Iteration 12 time: 20.070552825927734 Iteration 13 time: 20.066499710083008 Iteration 14 time: 20.09725570678711 Iteration 15 time: 20.081281661987305 Iteration 16 time: 19.88387107849121 Iteration 17 time: 19.904375076293945 Iteration 18 time: 19.907712936401367 Iteration 19 time: 19.498825073242188 Iteration 20 time: 18.95761489868164 Iteration 21 time: 18.933773040771484 Iteration 22 time: 18.957853317260742 Iteration 23 time: 18.938302993774414 Iteration 24 time: 18.92995834350586 Iteration 25 time: 18.850088119506836 Iteration 26 time: 18.827438354492188 Iteration 27 time: 18.799543380737305 Iteration 28 time: 18.813371658325195 Iteration 29 time: 18.778562545776367 Iteration 30 time: 18.76211166381836 Iteration 31 time: 18.78190040588379 Iteration 32 time: 18.78833770751953 Iteration 33 time: 18.79286766052246 Iteration 34 time: 18.782615661621094 Iteration 35 time: 18.767595291137695 Iteration 36 time: 18.773317337036133 Iteration 37 time: 18.77903938293457 Iteration 38 time: 18.7833309173584 Iteration 39 time: 18.78976821899414 Iteration 40 time: 18.793344497680664 Iteration 41 time: 18.777132034301758 Iteration 42 time: 18.792390823364258 Iteration 43 time: 18.752336502075195 Iteration 44 time: 18.66936683654785 Iteration 45 time: 18.666505813598633 Iteration 46 time: 18.671274185180664 Iteration 47 time: 18.65530014038086 Iteration 48 time: 18.67055892944336 Iteration 49 time: 18.663644790649414 Iteration 50 time: 18.662452697753906 Iteration 51 time: 18.65530014038086 Iteration 52 time: 18.648862838745117 Iteration 53 time: 18.680095672607422 Iteration 54 time: 18.678665161132812 Iteration 55 time: 18.626928329467773 Iteration 56 time: 18.750905990600586 Iteration 57 time: 19.0277099609375 Iteration 58 time: 18.60952377319336 Iteration 59 time: 18.702030181884766 Iteration 60 time: 18.656492233276367 Iteration 61 time: 18.646717071533203 Iteration 62 time: 18.682479858398438 Iteration 63 time: 18.665552139282227 Iteration 64 time: 18.663644790649414 Iteration 65 time: 18.66936683654785 Iteration 66 time: 18.670082092285156 Iteration 67 time: 18.667221069335938 Iteration 68 time: 18.694162368774414 Iteration 69 time: 18.665313720703125 Iteration 70 time: 18.650054931640625 Iteration 71 time: 18.680095672607422 Iteration 72 time: 18.672943115234375 Iteration 73 time: 18.646717071533203 Iteration 74 time: 18.663406372070312 Iteration 75 time: 18.650531768798828 Iteration 76 time: 18.599510192871094 Iteration 77 time: 18.951892852783203 Iteration 78 time: 18.95451545715332 Iteration 79 time: 18.649816513061523 Iteration 80 time: 18.6614990234375 Iteration 81 time: 18.665313720703125 Iteration 82 time: 18.66745948791504 Iteration 83 time: 18.651247024536133 Iteration 84 time: 18.673419952392578 Iteration 85 time: 18.68128776550293 Iteration 86 time: 18.65100860595703 Iteration 87 time: 18.670082092285156 Iteration 88 time: 18.661975860595703 Iteration 89 time: 18.643856048583984 Iteration 90 time: 18.65553855895996 Iteration 91 time: 18.65553855895996 Iteration 92 time: 18.65363121032715 Iteration 93 time: 18.638134002685547 Iteration 94 time: 18.673419952392578 Iteration 95 time: 18.662452697753906 Iteration 96 time: 18.665313720703125 Iteration 97 time: 18.625259399414062 Iteration 98 time: 18.651723861694336 Iteration 99 time: 18.649816513061523 So am I right to conclude that the issue is caused by asynchronous execution? And if so, is there a low overhead method of forcing the execution to synchronize for timing purpopses? I had also tried `tf.config.experimental.set_synchronous_execution(enable=False)` But that still leads to weird timing.","Hi, guo  Apologize for the delayed response and I was able to replicate the same issue with our latest `TF2.12` and `tfnightly` with `Tesla T4 GPU `allocated by Google Colab and for your reference I have added gistfile and at the moment I'm not sure what is root cause for this inconsistent runtime of XLA compiled model inference so we'll have to dig more into this issue and we'll update soon. Thank you!","Ok, thanks for looking into this!","guo I just noticed your issue. And actually you understood alone your problem. Let me completely answer it for you :) Tensorflow is eager first. When you return from an execution you get ""sort of an eager pointer"" to the result that is not yet populated. One way to force trigger the resync `result = model(data).numpy()`. Unfortunately this triggers a memcpyDtoH which not only introduces a lot of overhead if the output tensor is large but also a lot of jitter. `tf.config.experimental.set_synchronous_execution(enable=False)` this API does not work on GPU ;) Though, you're in luck :D and the solution is easy. After some long discussion with  we published this RFC: https://github.com/tensorflow/community/pull/434 which led to this commit: https://github.com/tensorflow/tensorflow/commit/267c63aa0938682ca7b1990dcf09f041495db1fa Now allow me to quickly rewrite your code:  Please close the issue if this address all your concerns ;) "," Thanks, this is exactly what I was looking for! I guess I couldn't find it because it was added so recently :) I saw some TF documentation where they time functions without this synchronization, which would not be accurate on the GPU at least (e.g. https://www.tensorflow.org/guide/functionusage). Do you think the documentation should be updated to add this experimental synchronization or have a disclaimer about this issue?)",I already mentioned the issue to  and oss . Yes the documentation should be updated accross the board to include `tf.test.experimental.sync_devices()` CC:  ,"> I already mentioned the issue to  and oss . Yes the documentation should be updated accross the board to include `tf.test.experimental.sync_devices()` >  > CC:   Yeah in https://www.tensorflow.org/guide/functionusage, the time printed in the `timeit` part of the tutorial is unreasonably short because a GPU is used and `sync_devices` wasn't called. Adding a call to `sync_devices` would make the example very verbose, as it forces the lambdas to be made into toplevel functions. Maybe the `numpy` method should be used instead of `sync_devices` for conciseness, e.g. by replacing the thirdtolast line in the `timeit` code block with  CC  ", I disagree. We implemented `tf.test.experimental.sync_devices()` precisely for this usecase. Let's not introduce poor/bad practices in the official documentation. `.numpy()` is NOT a good idea to measure / assess performance. Hence we had to come up with `sync_devices()`,"`numpy` also measures the device transfer time, which sometimes you want, but you're right this example does not want to measure this, since it's just comparing the performance of `tf.function`. Perhaps the example with `timeit` should be removed. I don't think the example adds much value since it doesn't show `tf.function` being faster, even if `sync_devices` is added.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1366,"以下是一个github上的tensorflow下的一个issue, 标题是(The Whisper Hybrid encoder model with dynamic quantization functions properly, but it fails when using a full int8 model with post-training quantization.)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Refer the below colab to reproduce the issue .. https://colab.research.google.com/drive/1S_3bVlwRZkMaYvvKwtPfWlyXQLS0Bvxa?usp=sharing   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,nyadla-sys,"The Whisper Hybrid encoder model with dynamic quantization functions properly, but it fails when using a full int8 model with post-training quantization."," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Refer the below colab to reproduce the issue .. https://colab.research.google.com/drive/1S_3bVlwRZkMaYvvKwtPfWlyXQLS0Bvxa?usp=sharing   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-02-16T20:09:58Z,stat:awaiting tensorflower type:bug comp:lite TFLiteConverter ModelOptimizationToolkit TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59716,   Please have a look into this issue. Thanks in advance ,"model = ""https://tfhub.dev/google/nnlmendim50/2"" hub_layer = hub.KerasLayer(model, input_shape=[], dtype=tf.string, trainable=True) hub_layer(train_examples[:3])",sys Thanks for reporting this issue. Sorry for the delayed response. I was able reproduce this issue on TF 2.11. Please find the gist here.  Could you please look into this issue? Thanks.,"Hi sys, Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here. Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
1867,"以下是一个github上的tensorflow下的一个issue, 标题是(Cannot convert explicit Q/DQ nodes using TF-TRT)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version TF 2.10  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour? I am trying to convert a quantized TF model with TFTRT, however, the following issues prevent me from doing so. I have attempted a temporary workaround to fix issue CC(Add support for Python 3.x) but am stuck with no possible solution to the next problem. According to PR CC([TF:TRT] Enable TensorRT explicit precision (QDQ/QAT) support), explicit Q/DQ models should be supported with Tensorflow when using TensorRT 8.  *Problem 1* The nondeprecated way to add quantizedequantize nodes in Tensorflow models is through   `tf.quantization.quantize_and_dequantize_v2`. However, this adds  https://github.com/tensorflow/tensorflow/blob/b6517cce24a06e07535c4b047a5991a290ef9368/tensorflow/python/ops/array_ops.pyL6323L6326 nodes with tag `QuantizeAndDequantizeV4` https://github.com/tensorflow/tensorflow/blob/6285a27e1bc55c3adb10be723b16d43c444dbdcb/tensorflow/core/ops/array_ops.ccL2916 which is clearly not supported in the list of ops for explicit precision mode. https://github.com/tensorflow/tensorflow/blob/7103c2ca32786fc7a2809a84e4c923196b208416/tensorflow/compiler/tf2tensorrt/convert/ops/quantization_ops.hL35L39 A possible workaround is to use the deprecated API `tf.quantization.quantize_and_dequantize` which will add a `Quantiz)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,codejaeger,Cannot convert explicit Q/DQ nodes using TF-TRT,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version TF 2.10  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 11.8  GPU model and memory _No response_  Current Behaviour? I am trying to convert a quantized TF model with TFTRT, however, the following issues prevent me from doing so. I have attempted a temporary workaround to fix issue CC(Add support for Python 3.x) but am stuck with no possible solution to the next problem. According to PR CC([TF:TRT] Enable TensorRT explicit precision (QDQ/QAT) support), explicit Q/DQ models should be supported with Tensorflow when using TensorRT 8.  *Problem 1* The nondeprecated way to add quantizedequantize nodes in Tensorflow models is through   `tf.quantization.quantize_and_dequantize_v2`. However, this adds  https://github.com/tensorflow/tensorflow/blob/b6517cce24a06e07535c4b047a5991a290ef9368/tensorflow/python/ops/array_ops.pyL6323L6326 nodes with tag `QuantizeAndDequantizeV4` https://github.com/tensorflow/tensorflow/blob/6285a27e1bc55c3adb10be723b16d43c444dbdcb/tensorflow/core/ops/array_ops.ccL2916 which is clearly not supported in the list of ops for explicit precision mode. https://github.com/tensorflow/tensorflow/blob/7103c2ca32786fc7a2809a84e4c923196b208416/tensorflow/compiler/tf2tensorrt/convert/ops/quantization_ops.hL35L39 A possible workaround is to use the deprecated API `tf.quantization.quantize_and_dequantize` which will add a `Quantiz",2023-02-16T12:17:01Z,stat:awaiting response type:bug stale comp:gpu:tensorrt TF 2.10,closed,0,9,https://github.com/tensorflow/tensorflow/issues/59711, can you reexecute with this defined first:  Please copy the log output here. Thanks,"Hi, Thanks for the quick response. I have used the flag you mentioned and collected the logs below. While using `quantize_and_dequantize` at the `trt_func = converter.convert()` step  The `converter.build(input_fn=input_fn)` step with this flag being set seemed to suppress all the warnings I was getting without it. I noticed something else, while checking the converted model summary i.e. the converter shows the input and output dtypes to be in `float16` while upon checking the original model before TFTRT conversion I can see the layer `dtypes` are inferred to be `float32`.   Is this some automatic behavior of TFTRT that can be suppressed?",Any updates regarding this issue?  are the logs above helpful to solve the issue or is anything more required?,"Just a quick note that TFTRT with explicit quantize & dequantize is actually still experimental and not really supported. I just finished working through some of the issues you mentioned above, including Conv2D not being supported (for me it was because it had a tensor input).   is there any active effort on this right now? Would be happy to join forces and add the fixes I've found",I've opened another issue here: https://github.com/tensorflow/tensorflow/issues/60168 I think that the fixes I've already implemented are real bugs and can be used to help here as well . ,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
868,"以下是一个github上的tensorflow下的一个issue, 标题是(Node: 'sequential/embedding/embedding_lookup' indices[0,57] = 1544453 is not in [0, 1498136) 	 [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_train_function_8141])， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tensorflow.compat.v2.version  Custom Code Yes  OS Platform and Distribution google colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,priyansh4320,"Node: 'sequential/embedding/embedding_lookup' indices[0,57] = 1544453 is not in [0, 1498136) 	 [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_train_function_8141]",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tensorflow.compat.v2.version  Custom Code Yes  OS Platform and Distribution google colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-02-16T04:05:22Z,stat:awaiting response type:bug stale comp:keras TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59709,   I tried to reproduce the issue on colab using TF v2.11 but facing different error could you please provide all dependencies and find the gist here for reference. Thank you !," i assume that you have also uploaded the dataset via the link https://drive.google.com/file/d/1pKAJPF42nRB2kw0ZdMAkg1i2fUSvFy/view?usp=sharing  to your google drive. 1. my file path to the dataset is this : /content/drive/MyDrive/ATS gigadata/model_gigadata_new.csv  2. here I have create another folder  ""ATSgigadata"" where my file is located 3. you can use this path for yourself: /content/drive/MyDrive/model_gigadata_new.csv 4. since uploading a file to google drive will appear in ""MyDrive"" by default 5. regarding dependencies , all dependencies are provided in file itself  ",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"  Sorry for the late reply, Could you please provide an accessible dataset to replicate the issue reported here ? Thank you!",   dataset link : https://drive.google.com/file/d/1pKAJPF42nRB2kw0ZdMAkg1i2fUSvFy/view?usp=sharing,  I was able to reproduce the issue on Colab using 2.11. please find the gist here for reference. Thank you !,"  ok, now can you please provide me solution to resolve this error . i am not able to move forward in my project.","Hi, Apologies for the delayed response, I tried to check the issue. Model definition looks fine, the only thing you want to try is data preprocessing part like take a relook into the tokenizer part. Also, I did not get the use of below logic. ",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
675,"以下是一个github上的tensorflow下的一个issue, 标题是(Video CNN Tutorial)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.0  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,chewman19,Video CNN Tutorial,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.11.0  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-02-15T20:21:11Z,type:docs-bug stat:awaiting response type:bug stale TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59701,  I was able to execute the code from Load video data tutorial succesfully using TF v 2.11. Kindly refer to the gist here. For better assistance please share the colab gist in which you are executing the code from Load video data tutorial.  Thank you!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1730,"以下是一个github上的tensorflow下的一个issue, 标题是(WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04.1 LTS  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  Can you please, explain, what is meant by this warning and how to fix it? I have the following accompanying questions to it: * Function traces are basically graph representations of functions or something else? * If these jit traces are not found in a loaded model, will they be generated again? Is model compilation needed for regeneration? * Are these functions needed only for training or also for prediction/evaluation? I have found in Keras docs (https://keras.io/api/models/model_saving_apis/) that I can disable saving the traces with the following note: ""Disabling this will decrease serialization time and reduce file size, but it requires that all custom layers/models implement a get_config() method."" * Why would the `get_config()` method be only needed when I disable saving the traces? Thanks in advance for any explanations given!   )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,clime,"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.","Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04.1 LTS  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  Can you please, explain, what is meant by this warning and how to fix it? I have the following accompanying questions to it: * Function traces are basically graph representations of functions or something else? * If these jit traces are not found in a loaded model, will they be generated again? Is model compilation needed for regeneration? * Are these functions needed only for training or also for prediction/evaluation? I have found in Keras docs (https://keras.io/api/models/model_saving_apis/) that I can disable saving the traces with the following note: ""Disabling this will decrease serialization time and reduce file size, but it requires that all custom layers/models implement a get_config() method."" * Why would the `get_config()` method be only needed when I disable saving the traces? Thanks in advance for any explanations given!   ",2023-02-15T12:30:58Z,stat:awaiting response type:support stale comp:keras comp:core TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59694,"Hi,   Apologize for the delay and as far I know, I think this warning can be safely ignored as you can find the same warning even in TensorflowTutorial and that warnings are that function could not be traced. It should be safe to ignore. `model.save() `will not only try to save the weights/variables, but also trace functions of the model and save their graph representations. This is what is failing for that function, and the warnings tell you about that. If you want to continue training a model, you probably want to recreate the model from Python code anyway, and load/save just the weights. The `tf.keras.callbacks.BackupAndRestore `does this automatically at the end of each epoch. So if you interrupt the training script, next time you start it, it should automatically pick up from the beginning of the interrupted epoch. As far as know these functions are needed while training the model I think those warnings are coming while training the model. You can refer this Stack overflow answer also which supports ignoring those warnings. If you're looking to disable `absl INFO and WARNING log `messages please use below code snippet:  I hope I answered your questions and if I miss something here, Please let us know ? Thank you!","Thanks, but I don't want to suppress the warning and I would also prefer not to ignore it. There should be a clean way to get rid of them.  My questions are: 1) Why traces of these particular functions cannot be saved? 2) If I decide to save the model without traces, will I be able to later load the model without recompiling and use it for evaluation? 3) If I compile the model (`load_model(compile=True)`), will these jit functions be regenerated? 4) Why would the get_config() method be only needed for all custom layers/models (I don't actually have any custom layers or models) when I disable saving the traces? Why is this `get_config()` method relevant at all?",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,ping :),"Hi,   Apologize for the delay and I found similar issue  CC(WARNING:absl:Found untraced functions such as lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.), If you save your model in `SavedModel` format which is the more comprehensive save format that saves the model architecture, weights, and the traced Tensorflow subgraphs of the call functions. This enables Keras to restore both builtin layers as well as custom objects and if saved model reloads without any change in model architecture, layers or Parameters then there shouldn't be any problem. If you're saving your model in` .h5` format then you won't get any such warnings  Configuration of a Sequential model or Functional API model, These types of models are explicit graphs of layers their configuration is always available in a structured form and `get_config()` and `from_config()` API's calling will return a Python dict containing the configuration of the model. The same model can then be reconstructed via `Sequential.from_config(config)` (for a Sequential model) or `Model.from_config(config) `(for a Functional API model). If you save the model in `SavedModel` format without traces, you can load the model without recompilation by doing `load_model(compile=False)` and if you compile the model `load_model(compile=True)` as far I know these jit functions warnings may come, you can refer our official documentation for Save and load Keras models  and also please refer this answer on stackoverflow, I hope I'm able to answer your questions.  If you still need any further help please let us know ? Thank you!",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1886,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite undefined symbol when cross-compiling for android on linux )， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Debian 11   Mobile device Android NDK 25  Python version 3.9.2  Bazel version Tried on 7.0.0 and 6.0.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to cross compile TFLite on my linux machine to be compatible with android machines so I can use it on my c++ code that runs on android devices. I've tried 3 different bazel builds with 3 different issues. Also tried the 'build with cmake for arm' section with errors. More details can be found here: https://stackoverflow.com/questions/75457043/buildtfliteclibforandroidwithndk25withbazel https://stackoverflow.com/questions/75435665/errno8execformaterrorontflitecmakebuildforarm64v8a How can I fix this or are there any precompiled so files?  Standalone code to reproduce the issue First I ran `./configure` and skipped over the `configure ./WORKSPACE` part since I'm using ndk version 25 and can't give the path. First command tried:  `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so fat_apk_cpu=arm64v8a` Second command: `bazel build c opt config=android_arm64 //tensorflow/lite:libtensorflowlite.so` Third command (not right but I've tried it anyways): `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so` I've also tried running the `cross compilation with cmake for arm` by doing:   Clone to tensorflow_src   Create tensorflow_build in the same pl)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,turgut-baba,TFLite undefined symbol when cross-compiling for android on linux ,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Debian 11   Mobile device Android NDK 25  Python version 3.9.2  Bazel version Tried on 7.0.0 and 6.0.0  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I'm trying to cross compile TFLite on my linux machine to be compatible with android machines so I can use it on my c++ code that runs on android devices. I've tried 3 different bazel builds with 3 different issues. Also tried the 'build with cmake for arm' section with errors. More details can be found here: https://stackoverflow.com/questions/75457043/buildtfliteclibforandroidwithndk25withbazel https://stackoverflow.com/questions/75435665/errno8execformaterrorontflitecmakebuildforarm64v8a How can I fix this or are there any precompiled so files?  Standalone code to reproduce the issue First I ran `./configure` and skipped over the `configure ./WORKSPACE` part since I'm using ndk version 25 and can't give the path. First command tried:  `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so fat_apk_cpu=arm64v8a` Second command: `bazel build c opt config=android_arm64 //tensorflow/lite:libtensorflowlite.so` Third command (not right but I've tried it anyways): `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so` I've also tried running the `cross compilation with cmake for arm` by doing:   Clone to tensorflow_src   Create tensorflow_build in the same pl,2023-02-15T10:17:10Z,stat:awaiting response type:build/install stale comp:lite,closed,0,13,https://github.com/tensorflow/tensorflow/issues/59692,"baba Thanks for reporting the issue. I've tried running the commands  `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so fat_apk_cpu=arm64v8a` and `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so` on Linux/Ubuntu 20.04, with Bazel 5.3.0 and was able to build successfully. Please find the gist here.  Have you tried with Android NDK 19c which is recommended. Thanks!","Hello,  I will try it with bazel 5.3.0 and update you, however due to my projects needs, I can't use NDK versions below 25.",Running `bazel build c opt config=elinux_aarch64 //tensorflow/lite:libtensorflowlite.so fat_apk_cpu=arm64v8a` with bazel 5.3.0 causes this error on the `v2.12.0rc0` and `r2.12` and `master` branch : ,baba Thanks for the update.  Could you please look into this. Thank you.," On a side note, I've found some precompiled versions of the library on the internet from 2021, it runs just fine on it's own but when I use it inside my project, which uses threading on android, it gives out an error. (I've set `setnumThreads` to 2.). I assume this issue is addressed in the newer releases but since I can't compile it on my own I'm stuck. Also: If I compile the .so files with NDK 19, can I use that in my NDK 25 > project?","> C/C++: ld: error: undefined symbol: tflite::impl::Interpreter::Invoke() That symbol is supposed to be defined in the file tensorflow/lite/core/interpreter.cc. There have been a few changes related to this recently, with the implementation of this method recently moving (a) from the ""tflite"" namespace to the ""tflite::impl"" namespace and (b) from tensorflow/lite/interpreter./lite/core/interpreter., probably (b).", Do you have any suggestions I can try in the meantime? Which branch do you suggest I use?,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Hi, Could you please try to build against the latest stable branch `2.11` and let us know if it is working for you. `2.12` is not yet released, till `2.12` is available you could build it against the last stable branch which is `2.11`. Thanks!",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No," the issue was not fixed since then it seems this commit https://github.com/tensorflow/tensorflow/commit/734de9e767fdd81d67bd47a14a1281b9736c8544diff7456c1d9f62f2c8c05621072dba61fc0db513a09331f60f9601d2e610c114dda updated the ARM toolchain to 11.3 Rel1  however, according to  https://bugs.linaro.org/show_bug.cgi?id=5825c34  so I'm assuming it is still broken on latest master  but it is definitely broken in 2.12rc0, which is what I'm trying to build. I'm trying swapping the toolchain to armgnutoolchain12.3.rel1aarch64armnonelinuxgnueabihf, the build seems to be progressing as of now. If it builds and runs, would you like me to make a PR? Do you have a CI test for this in place?",You can go ahead and make the changes.
1876,"以下是一个github上的tensorflow下的一个issue, 标题是(pruned pretrained mobilenet_v1_1.0_224, mode.fit() error)， 内容是 ( Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.11.0  Custom Code No  OS Platform and Distribution WSL2 Linux Ubuntu 20.04  Mobile device _No response_  Python version python 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell Found 2000 files belonging to 2 classes. Found 1000 files belonging to 2 classes. Epoch 1/2 /usr/local/lib/python3.8/distpackages/keras/backend.py:5585: UserWarning: ""`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?   output, from_logits = _get_logits( 6/6 [==============================]  26s 4s/step  loss: 4.2002  accuracy: 0.5365  val_loss: 28.3055  val_accuracy: 0.0000e+00 Epoch 2/2 6/6 [==============================]  19s 3s/step  loss: 0.3738  accuracy: 0.9479  val_loss: 21.0645  val_accuracy: 0.0223 Saved baseline model to: /tmp/tmp68woeyxc.h5 WARNING:tensorflow:From /home/qiao_sh_pudong/.local/lib/python3.8/sitepackages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 20230923. Instructions for updating: Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089 begin fit Epoch 1/2 Tr)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,PPParticle,"pruned pretrained mobilenet_v1_1.0_224, mode.fit() error"," Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version v2.11.0  Custom Code No  OS Platform and Distribution WSL2 Linux Ubuntu 20.04  Mobile device _No response_  Python version python 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell Found 2000 files belonging to 2 classes. Found 1000 files belonging to 2 classes. Epoch 1/2 /usr/local/lib/python3.8/distpackages/keras/backend.py:5585: UserWarning: ""`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?   output, from_logits = _get_logits( 6/6 [==============================]  26s 4s/step  loss: 4.2002  accuracy: 0.5365  val_loss: 28.3055  val_accuracy: 0.0000e+00 Epoch 2/2 6/6 [==============================]  19s 3s/step  loss: 0.3738  accuracy: 0.9479  val_loss: 21.0645  val_accuracy: 0.0223 Saved baseline model to: /tmp/tmp68woeyxc.h5 WARNING:tensorflow:From /home/qiao_sh_pudong/.local/lib/python3.8/sitepackages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 20230923. Instructions for updating: Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089 begin fit Epoch 1/2 Tr",2023-02-14T08:33:31Z,stat:awaiting response type:bug ModelOptimizationToolkit TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59679," Thanks for reporting the issue. Sorry for the delayed response. As per the documentation, prune_low_magnitude expects pruning schedule, but a dictionary of pruning schedule is given which can be resolved by either directly passing pruing schedule or getting pruning schedule from dictionary. Also, the callbacks are not  called during pruned `model.fit`.  Please find the working gist and let us know if it helps. The weights are not loaded as they are not provided. Thanks!",">  Thanks so much for your reply which has solved my problems !! However, I haven't figure out the reason why there are still so many nontrainable parameters after `model.fit()` with `model_for_pruning.summary()`. Maybe I should look up TF guidebook! All in all, thank you so much again !!", Please feel free to close the issue if it is resolved. Thanks!,Are you satisfied with the resolution of your issue? Yes No
1144,"以下是一个github上的tensorflow下的一个issue, 标题是(Stateless dropout broken on mixed_float16 with XLA)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0.dev20230213  Custom Code Yes  OS Platform and Distribution Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Stateless/stateful (not legacy) dropout fails with `mixed_float16` and XLA, because the statelessuniformrandom operation does not exist for half types. Note that without Stateless/stateful (not legacy) dropout, a warning is generated saying that seeds are not respected. The error reproduces consistently on Colab, with TF 2.11 and the latest nightly.  Standalone code to reproduce the issue  https://colab.research.google.com/drive/1F9V0ayyNIpbIQcjjtk7IN6w3EQai5Fk9?usp=sharing  Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AndreasMadsen,Stateless dropout broken on mixed_float16 with XLA,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.13.0.dev20230213  Custom Code Yes  OS Platform and Distribution Colab  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? Stateless/stateful (not legacy) dropout fails with `mixed_float16` and XLA, because the statelessuniformrandom operation does not exist for half types. Note that without Stateless/stateful (not legacy) dropout, a warning is generated saying that seeds are not respected. The error reproduces consistently on Colab, with TF 2.11 and the latest nightly.  Standalone code to reproduce the issue  https://colab.research.google.com/drive/1F9V0ayyNIpbIQcjjtk7IN6w3EQai5Fk9?usp=sharing  Relevant log output  ",2023-02-14T07:23:09Z,stat:awaiting response type:bug comp:xla TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59678,"Note, the experimental API is not required to reproduce the bug. Just use `force_generator=True` instead. ","Hi,   Apologize for the delay and I was able to replicate the same issue with `tfnightly2.13.0dev20230216` and `Tensorflow==2.11`, for your reference I have added gistfile but when I tried the same code with Pre Release `tensorflow 2.12.0rc0` and it seems like working fine as expected, for your reference I have added gistfiletensorflow2.12.0rc0  so Could you please try with `tensorflow 2.12.0rc0` from your end and please let us know whether is it working fine or not ? If issue still persists please let us know ? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!"," Hi, I can confirm that `2.12.0rc0` works using the docker image on a V100 GPU. Actually running `2.12.0rc0` on our typical system will require some more work as the CUDA and CuDNN have now changed. I have issued an update request to fully check this. Also, before closing this issue, I would like clarification as to how this works on `2.12.0.rc0` but not the nightly version. The changelog does not appear to mention that float16 support was added to XLA StatelessUniform.  Finally, I suggest checking that there is no issue `mixed_bfloat16` too.",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,mlbutler The stalling is not my responsibility and I don't see a reason why this issue should be closed. Maybe you can remove the `stat:awaiting response` label to avoid confusion.,"Hi,   I'm really sorry, The **googlemlbutler** bot is not working as expected and our team is working on it, I'll remove **stalled** and **stat:awaiting response** labels manually now. Thank you!","Hi,   I was able to replicate the same issue with `tfnightly` and `tensorflow==2.12.0rc0` and It seems like, it's working as expected and in new release of `TF2.12 `this issue will be resolved, for your reference I have added gistfile . Thank you!"," Sorry, you were able to replicate the issue `tfnightly` and `tensorflow==2.12.0rc0`? How is that ""working as expected""? The desired result is that you can **not** replicate the issue on `tfnightly` and `2.12rcX`. Maybe that is what you meant. Great to hear that it will be fixed on 2.12. I'm just confused about the first comment.","Hi,   Apologize for the delay and I have tested the same code with `tfnightly `and `tensorflow==2.12.0rc0` and It seems like it's working as expected(without any erros) for your reference here is gistfile so you can use either `tfnightly` or `tensorflow==2.12.0rc0` at the moment and we don't support all the `ops` with XLA at the moment, our developer team is working on it and it's in progress so your issue will be fixed in upcoming stable version `TF2.12 `.  If issue still persists with `tfnightly` or `tensorflow==2.12.0rc0` please let us know or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!","Thanks for the help, I truly appreciate it.",Are you satisfied with the resolution of your issue? Yes No
320,"以下是一个github上的tensorflow下的一个issue, 标题是([NVIDIA TF] Enable GPU BF16 Relu unconditionally)， 内容是 (Registers bf16 relu gpu kernels even when mlir generated kernels are enabled. . FYI  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,trevor-m,[NVIDIA TF] Enable GPU BF16 Relu unconditionally,Registers bf16 relu gpu kernels even when mlir generated kernels are enabled. . FYI  ,2023-02-13T21:49:29Z,awaiting review ready to pull size:S comp:core,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59673
1754,"以下是一个github上的tensorflow下的一个issue, 标题是(CUDA_ERROR_ILLEGAL_ADDRESS)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Official docker image via apptainer  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.2/8.1  GPU model and memory Tesla V100SXM232GB  Current Behaviour? Using the Official docker image, the provided code results in a CUDA_ERROR_ILLEGAL_ADDRESS. Note, that while the error is fully consistent (happens every time at the first epoch) it is highly sensitive. If a different seed or modelsize is used, the error will not reproduce. I have tried enabling memory growth as suggested elsewhere. However, this only delays the issue to epoch 18. The error does not reproduce on Google Colab or when using the nightly docker image. However, due to the sensitivity of the issue, it is unclear what exactly this means. The Google Colab issue could be due to different GPU. On my own environment it's a Tesla V100SXM232GB, not a T4.  Standalone code to reproduce the issue This uses `transformers == 4.26.0`, and a synthetic dataset file (based on QQP) that is automatically downloaded. Code is available here: https://gist.github.com/AndreasMadsen/2bf669a3cd4c4a8ba964561b9e72279e Note, I did make an attempt at reproducing it using Colab: https://colab.research.google.com/drive/1zVbNNfz1lZ6xgyoZ7dKWnKzj6poM5XWC?usp=sharing However, the error does not reproduce on Colab.  Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AndreasMadsen,CUDA_ERROR_ILLEGAL_ADDRESS,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Official docker image via apptainer  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.2/8.1  GPU model and memory Tesla V100SXM232GB  Current Behaviour? Using the Official docker image, the provided code results in a CUDA_ERROR_ILLEGAL_ADDRESS. Note, that while the error is fully consistent (happens every time at the first epoch) it is highly sensitive. If a different seed or modelsize is used, the error will not reproduce. I have tried enabling memory growth as suggested elsewhere. However, this only delays the issue to epoch 18. The error does not reproduce on Google Colab or when using the nightly docker image. However, due to the sensitivity of the issue, it is unclear what exactly this means. The Google Colab issue could be due to different GPU. On my own environment it's a Tesla V100SXM232GB, not a T4.  Standalone code to reproduce the issue This uses `transformers == 4.26.0`, and a synthetic dataset file (based on QQP) that is automatically downloaded. Code is available here: https://gist.github.com/AndreasMadsen/2bf669a3cd4c4a8ba964561b9e72279e Note, I did make an attempt at reproducing it using Colab: https://colab.research.google.com/drive/1zVbNNfz1lZ6xgyoZ7dKWnKzj6poM5XWC?usp=sharing However, the error does not reproduce on Colab.  Relevant log output  ",2023-02-13T20:32:19Z,stat:awaiting tensorflower type:bug comp:gpu comp:xla TF 2.11,closed,0,17,https://github.com/tensorflow/tensorflow/issues/59671,"In this gist, I have removed the dependency on `transformers` and a large amount of irrelevant code: V1: https://gist.github.com/AndreasMadsen/dc5785b5a55bf740c555b2fb5cdab1db (~600 LOC) V2: https://gist.github.com/AndreasMadsen/5fdaa8431929e25cf3a990f234f88a8c (update, more code removed. ~450 LOC) V3: https://gist.github.com/AndreasMadsen/2590423c055bc47a932a449a5161bac7 (update, more code removed.  209 LOC) I have tried to reduce the code further, but this causes the bug to disappear.", I think you should add the `comp:xla` label too. As this bug only occurs when XLA is enabled.,"There is no failure with the reproduction script on `2.12.0rc0`. However, given how difficult this bug is to reproduce (e.g. changing just the seed of the shuffle function will make it disappear). I can't tell if this solves the issue consistently.","The error appears to be specific to V100, as it does not reproduce on T4, A100, and P100 GPUs. I have however reproduced it on two different systems running V100. It is possible this is related to the specific memory size of the GPU.","Hi,   Apologize for the delay and Thank you for your detailed observations and efforts to find out the root cause for this issue and We'll try it from our end and will check whether this issue is specific to V100 GPU or not and we'll update you soon here. Thank you for noticing this issue. Thank you!"," Thanks for looking into this. It did take me several days to make this error reproducible. So I hope it will help you. I suspect it's a rather complex integration bug, as removing pretty much any line in the latest (V3) script cause the bug to disappear. ","Hi,   Apologize for the delay and I was able to replicate the issue on `Tesla V100 GPU` and I was getting the exact same error message which you mentioned in your error log output above with `tensorflow/tensorflow:latestgpu` docker image which is using `Tensorflow==2.11`, I have added screenshot for your reference below and even tested the same code on Google Colab and it's working fine as expected here is gistfile, I did not run for complete epoch because it was taking more time but code was running as expected but as you confirmed it's working fine on all other GPU's so this issue seems like specific to `Tesla V100 GPU` at the moment. Thank you! When I tried the same code with `tensorflow/tensorflow:2.12.0rc0gpu` and `tensorflow/tensorflow:nightlygpu`  on `Tesla V100 GPU` it's working as expected, I have added screenshot below Here is screenshot for code execution with `tensorflow/tensorflow:latestgpu` docker image !image Here is screenshot for code execution on GoogleColab : !image Here is screenshot for code execution with `tensorflow/tensorflow:2.12.0rc0gpu` docker image: !image Here is screenshot for code execution with `tensorflow/tensorflow:nightlygpu` docker image: !image","Hi , you didn't ask a question, so I'm not sure what you want me to respond to. I agree with your findings. Given how sensitive the bug is in terms of reproduction, I would not trust that it is something specific to V100 TF 2.11. I hope you will be able to debug this further and get to the resolve bug.","Note, that this kind of bug has been reported quite a few times before, but I think most issues were not able to provide a reproduction script. So I hope you will find this script quite useful. ISSUE: https://github.com/tensorflow/tensorflow/issues/50735 I remember there were more closed issues, when I was researching solutions.","Hi.   Thank you for mentioning the similar issue, It seems like we have to dig more into this issue to find out the root cause and we'll update you soon and I was able to replicate the exact same issue with error log with `tensorflow/tensorflow:latestgpu ` docker image that's the reason I did not ask any questions to you if we need any input or further details from your end certainly we will ask you. Thank you for noticing this issue, I really appreciate your efforts and time. Thank you!", Thanks for letting me know. I'm was just confused about the `stat:awaiting response` label.,"Hi,   Could you please look into this issue ? Thank you!","Hi , did you manage to investigate this? ","Hi  , Apologies for the delayed response, based on the issue thread so far, it is difficult to point to an area why this is happening. But you could try below steps and see if that works. 1. Try reinstalling the CUDA and cuDNN dependency, in some cases it could be due to improper installation of these dependencies. 2. Try setting the environmental variable `TF_FORCE_GPU_ALLOW_GROWTH `to `true` If the above steps did not work could you please run the model with the env var `CUDA_LAUNCH_BLOCKING` set to `1` and attach the full logs?"," Thanks for your response. Please note that I spent several days reducing this to a script that reproduces the issue. I think you can benifit tremendously from using that. Furthermore,  confirms that the issue could be reproduced with a V100 GPU. 1. Try reinstalling the CUDA and cuDNN dependency, in some cases it could be due to improper installation of these dependencies. Let's not go down that route, since  was able to reproduce the issue on Google's infrastructure. 2. Try setting the environmental variable `TF_FORCE_GPU_ALLOW_GROWTH` to `true`. Same issue. Expand the `` to see the log.  TF_FORCE_GPU_ALLOW_GROWTH=true python main.py    CUDA_LAUNCH_BLOCKING=1 TF_FORCE_GPU_ALLOW_GROWTH=true python main.py  ","Thank you  for the short script to reproduce and for removing the `transformers` dependency to keep the example simpler. I can reproduce the issue outside docker with CUDA 11.2.0 using the prebuilt TF 2.11 pip package. However, the issue disappears when I use CUDA 11.8.0 using the same pip package (the pip package is built with CUDA 11.2 but applications built for one version of CUDA also work for future minor versions of CUDA). So I'm guessing this was a bug with CUDA 11.2 that was fixed somewhere between CUDA 11.2.1 and 11.8.0. Since the TF nightly pip packages are now built with CUDA 11.8, I think this issue is fixed so I'm closing this issue. It's possible this is a race condition in TF instead of a bug in CUDA, and that updating the CUDA version changes some timings which causes the bug not to occur. But I think this is unlikely, so unless we later see CUDA_ERROR_ILLEGAL_ADDRESS errors in other models, we should consider this issue fixed.",Are you satisfied with the resolution of your issue? Yes No
388,"以下是一个github上的tensorflow下的一个issue, 标题是(ValueError: Did not get operators or tensors in subgraph 1)， 内容是 (Hey, I am trying to evaluate a tflite model, but all my attempts have been unsuccessful. I have provided a full code here. Thank you very much!)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,codingzebra333,ValueError: Did not get operators or tensors in subgraph 1,"Hey, I am trying to evaluate a tflite model, but all my attempts have been unsuccessful. I have provided a full code here. Thank you very much!",2023-02-13T14:05:23Z,TFLiteConverter,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59667
680,"以下是一个github上的tensorflow下的一个issue, 标题是(flatc Errno 8 Exec format error when building for android)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Debian 11   Mobile device Android   Python version 3.9.2  Bazel version 6.0.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version _No response_  GPU model and memory nvidia   Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,turgut-baba,flatc Errno 8 Exec format error when building for android,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code Yes  OS Platform and Distribution Debian 11   Mobile device Android   Python version 3.9.2  Bazel version 6.0.0  GCC/Compiler version 10.2.1  CUDA/cuDNN version _No response_  GPU model and memory nvidia   Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-13T12:40:32Z,stat:awaiting response type:build/install stale comp:lite,closed,0,9,https://github.com/tensorflow/tensorflow/issues/59666,I've tried building with `bazel build c opt //tensorflow/lite:libtensorflowlite.so fat_apk_cpu=arm64v8a` but now it says ` is not compatible with aarch64linux` . I couldn't build with `bazel build c opt //tensorflow/lite:libtensorflowlite.so cpu=arm64v8a` because I got `cc_toolchain_suite rule //:toolchain: cc_toolchain_suite '//:toolchain' does not contain a toolchain for cpu 'arm64v8a'` error.,"Hi baba, Please find the latest official pre release of TF v2.12 here and confirm if you are trying with the same source. Thank you! ","I've deleted all the files, git clone again, checkout to the branch you linked, did everything the same, same result.","Thank you for the update baba. It seems like we have to dig more into this issue, we will update soon here. Thanks!  ","Also, I've opened another issue tackling more stuff I've tried: https://github.com/tensorflow/tensorflow/issues/59692","Hi,   Could you please look into this issue ?","Hi baba, sorry for delayed response. As suggested here, can you please build on latest stable branch 2.11 and let us know if the issue still persists. Thanks.",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
454,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix crash when invalid input was provided to ragged_tensor_to_variant)， 内容是 (This PR fixes CC(Check failure when running tensorflow.python.ops.gen_ragged_conversion_ops.ragged_tensor_to_variant) by return error in case invalid shape set_dim is called. Signedoffby: Yong Tang )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,yongtang,Fix crash when invalid input was provided to ragged_tensor_to_variant,This PR fixes CC(Check failure when running tensorflow.python.ops.gen_ragged_conversion_ops.ragged_tensor_to_variant) by return error in case invalid shape set_dim is called. Signedoffby: Yong Tang ,2023-02-13T01:26:42Z,stale size:S prtype:bugfix comp:core,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59660,Thanks  . The PR has been updated.  In the past I did notice that internal tests may have different error codes. Not sure the change will cover all scenarios in internal tests. Please let me know if there are additional failures in internal tests.,"Here are the internal errors,   can you please verify ? Thank you! During handling of the above exception, another exception occurred: Traceback (most recent call last):   File ""/tensorflow/python/framework/test_util.py"", line 1526, in decorated     run_eagerly(self, **kwargs)   File ""/tensorflow/python/framework/test_util.py"", line 1510, in run_eagerly     f(self, *args, **kwargs)   File ""/tensorflow/python/ops/ragged/ragged_tensor_test.py"", line 2019, in testToVariantInvalidInputs     self.assertRaisesRegex( AssertionError: ""must be less than 0, got 0|Shape must be at least rank 1 but is rank 0"" does not match ""{{function_node __wrapped__RaggedTensorToVariant_RAGGED_RANK_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Requires the first element of nested_row_splits[0] to be 0 but is 150 [Op:RaggedTensorToVariant]""",There might be some skew in Graph mode (shape inference error) vs eager mode (kernel check) error messages. Maybe look at the shape inference for this particular op?,Hi  Any update on this PR? Please. Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further.
529,"以下是一个github上的tensorflow下的一个issue, 标题是(Fix crash in ragged_cross where the ragged tensor input is invalid)， 内容是 (This PR tries to address the issue raised in CC(Segmentation fault when running gen_ragged_array_ops.ragged_cross) where ragged_cross will crash when input is invalid. This PR fixes CC(Segmentation fault when running gen_ragged_array_ops.ragged_cross). Signedoffby: Yong Tang )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,yongtang,Fix crash in ragged_cross where the ragged tensor input is invalid,This PR tries to address the issue raised in CC(Segmentation fault when running gen_ragged_array_ops.ragged_cross) where ragged_cross will crash when input is invalid. This PR fixes CC(Segmentation fault when running gen_ragged_array_ops.ragged_cross). Signedoffby: Yong Tang ,2023-02-12T18:09:25Z,awaiting review ready to pull size:S prtype:bugfix comp:core,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59658,    PR has been updated with commits merged. Please take a look.
700,"以下是一个github上的tensorflow下的一个issue, 标题是(tape.gradient computes none after model in model training)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,VictorvanWeelden,tape.gradient computes none after model in model training,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-11T17:14:58Z,stat:awaiting response type:bug stale comp:apis comp:core TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59652,can you put your code in detail to solve this issue?,"Hi,   Apologize for the delay and I was able to replicate the issue on Google colab with `TF2.11 `and also tried with pre release `tensorflow 2.12.0rc0`, I have added both gist files here tf2.11 and tensorflow 2.12.0rc0 but I'm also getting the same error but with pre release `tensorflow 2.12.0rc0` I noticed different error `RuntimeError: A nonpersistent GradientTape can only be used to compute one set of gradients (or jacobians)` but it got resolved by passing `persistent=True` to `with tf.GradientTape()` so We will have to dig more into this issue and we will update soon here and thank you for noticing this issue. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Hi,   Apologize for the delayed response and It seems like there is some issue while calculating the gradient and it's returning none so for your reference I have added one gist file which may be one of the reason for tape.gradient computes none after model in model training so could you please have a look into that gistfile and check whether is it resolving your issue ?, if not please let us know for investigation to find out root cause for your issue. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
660,"以下是一个github上的tensorflow下的一个issue, 标题是(protobuf 4 causes segmentation fault on Python 3.8 in unit test)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution CentOS 7  Mobile device n/a  Python version 3.8.13  Bazel version 5.3.0  GCC/Compiler version 10.3.0  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,elfringham,protobuf 4 causes segmentation fault on Python 3.8 in unit test,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version git HEAD  Custom Code No  OS Platform and Distribution CentOS 7  Mobile device n/a  Python version 3.8.13  Bazel version 5.3.0  GCC/Compiler version 10.3.0  CUDA/cuDNN version n/a  GPU model and memory n/a  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-10T13:12:56Z,type:bug,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59643,Are you satisfied with the resolution of your issue? Yes No
736,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.data.Dataset.map() of tf.data.Dataset feat. tf.RaggedTensor causes broken for-loop)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.9.2  Custom Code Yes  OS Platform and Distribution Windows 10, WSL2 Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.2  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Tens0rFlaw,tf.data.Dataset.map() of tf.data.Dataset feat. tf.RaggedTensor causes broken for-loop,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.9.2  Custom Code Yes  OS Platform and Distribution Windows 10, WSL2 Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 11.2  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-02-10T11:15:27Z,stat:awaiting response type:bug comp:data TF 2.9,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59641,  I was able to reproduce the issue on Colab using TF v2.11 . Please find the gist here for reference. Thank you!,"Hi,   Apologize for the delay and I was able to replicate the issue on Google Colab with `Tensorflow==2.11` and it's working as expected, for your reference I have added gistfile  and it seems like you're using python `map()` instead of `tf.map_fn()` and for your reference I have added official documentation for `tf.map_fn()` which may help you. If issue still persists please let us know or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!",Hi   that indeed resolves the issue.  Thank you for you answer!,Are you satisfied with the resolution of your issue? Yes No
601,"以下是一个github上的tensorflow下的一个issue, 标题是([DO NOT REVIEW] Introduce multiple streams execution in TensorFlow.)， 内容是 (Multiple Stream TensorFlow is developed based on the official TensorFlow 2.2. It leverages the features of modern GPUs to accelerate deep learning training and inference. This MultiStream implementation has successfully helped several customers migrate their TF models to the GPU and go online. For more details please visit README_MultiStream.md.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,buptzyb,[DO NOT REVIEW] Introduce multiple streams execution in TensorFlow.,Multiple Stream TensorFlow is developed based on the official TensorFlow 2.2. It leverages the features of modern GPUs to accelerate deep learning training and inference. This MultiStream implementation has successfully helped several customers migrate their TF models to the GPU and go online. For more details please visit README_MultiStream.md.,2023-02-10T07:40:24Z,,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59636,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.",We cannot accept PRs on versions that are out of life.
733,"以下是一个github上的tensorflow下的一个issue, 标题是([tensorflow_datasets 4.8.2]: Connection refused when trying to load huggingface datasets)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution macOS  Mobile device _No response_  Python version 3.8, 3.9, 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,YuliyaPylypiv,[tensorflow_datasets 4.8.2]: Connection refused when trying to load huggingface datasets,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution macOS  Mobile device _No response_  Python version 3.8, 3.9, 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-02-09T01:50:08Z,stat:awaiting response type:bug comp:data TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59623,"After a while it loaded. Should it take so long? W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""NOT_FOUND: Could not locate the credentials file."". Retrieving token from GCE failed with ""ABORTED: All 10 retry attempts failed. The last failure: Error executing an HTTP request: libcurl code 42 meaning 'Operation was aborted by an application callback', error details: Callback aborted"". Downloading and preparing dataset 1.43 MiB (download: 1.43 MiB, generated: Unknown size, total: 1.43 MiB) to /Users/x/tensorflow_datasets/glue/mrpc/1.0.0... Downloading and preparing dataset glue/mrpc to /Users/x/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad... Downloading data: 6.22kB [00:00, 3.34MB/s]                                                                                                                                  | 0/3 [00:00 physical PluggableDevice (device: 0, name: METAL, pci bus id: )",  I was able to load the `glue/mrpc` dataset without any error on Colab using TF v2.11. Could you please find the gist here for reference. Thank you!,Thank you  for your response! Looks like it's working again for me! ,Are you satisfied with the resolution of your issue? Yes No
1288,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: 'list' object has no attribute 'numpy')， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11.0  Custom Code No  OS Platform and Distribution Windows 11  Python version 3.10.9  Current Behaviour? Hello! I'm trying to write a script that gets the weights (just the weights) of each layer of a keras model. I am aware of the `get_weights()` method, but I don't want to use it since it returns specific terms such as bias with the weights, so I can't tell which is which. I used `model.get_layer(layer.name).weights` to extract the weights of a particular layer. The layer weights are returned as a TensorFlow variable. Here's an example:  Despite having a `list` type, the above output cannot be indexed: Assuming the above output is referred to as `var`; `var[0]` throws an `IndexError: list index out of range` error.  Whenever I try to evaluate tf.Variable with the numpy() method, the error shown in the issue title appears. Any help would be much appreciated. Thank you!  Standalone code to reproduce the issue )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,AAnirudh07,AttributeError: 'list' object has no attribute 'numpy',"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.11.0  Custom Code No  OS Platform and Distribution Windows 11  Python version 3.10.9  Current Behaviour? Hello! I'm trying to write a script that gets the weights (just the weights) of each layer of a keras model. I am aware of the `get_weights()` method, but I don't want to use it since it returns specific terms such as bias with the weights, so I can't tell which is which. I used `model.get_layer(layer.name).weights` to extract the weights of a particular layer. The layer weights are returned as a TensorFlow variable. Here's an example:  Despite having a `list` type, the above output cannot be indexed: Assuming the above output is referred to as `var`; `var[0]` throws an `IndexError: list index out of range` error.  Whenever I try to evaluate tf.Variable with the numpy() method, the error shown in the issue title appears. Any help would be much appreciated. Thank you!  Standalone code to reproduce the issue ",2023-02-09T00:38:20Z,stat:awaiting response type:bug comp:keras TF 2.11,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59620, The `layer_weights` contains list of variable tensors. The list can be iterated and each tensor can be then converted with `.numpy()` method:  Please refer the working gist here and let us know if it helps. Thanks!,Woah this is awesome! Thanks a lot ! I have one final question  Is there any particular reason why list iteration works but list indexing doesn't? List indexing thows an `IndexError: list index out of range` error. Thanks!,"  I can see your first layer returns empty list as it does not contain any weights, that's why you were getting `IndexError: list index out of range` error.  I was able to index the second layer list with out any error. Please refer the gist here and let us know if it helps.  Feel free to close the issue if it is resolved. Thanks!",Ah right my bad. Thanks for all the help!,Are you satisfied with the resolution of your issue? Yes No
1863,"以下是一个github上的tensorflow下的一个issue, 标题是(LayerNormalization layer cannot be imported)， 内容是 ( System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**:  No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04.5 LTS    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**: N/A    **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**: v2.11.0rc217gd5b57ca93e5 2.11.0    **Python version**: 3.9.12    **Bazel version (if compiling from source)**: N/A    **GCC/Compiler version (if compiling from source)**: N/A    **CUDA/cuDNN version**: cudatoolkit=11.2 cudnn=8.1.0    **GPU model and memory**: RTX 3090, 24 GB    **Exact command to reproduce**:   Describe the problem Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. The LayerNormalization layer does not exist, in fact none of the normalization layers are in  and so cannot be imported in a Python script. I have installed tensorflow using pip in a conda environment as described in the tensorflow installation documentation. The expected behavior is the LayerNormalization layer should exist in the source tree and be importable as Python module.   Source code / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem. Steps to reproduce. 1. Install tensorflow in a conda environment using pip )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,goruck,LayerNormalization layer cannot be imported," System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**:  No    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04.5 LTS    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**: N/A    **TensorFlow installed from (source or binary)**: binary    **TensorFlow version (use command below)**: v2.11.0rc217gd5b57ca93e5 2.11.0    **Python version**: 3.9.12    **Bazel version (if compiling from source)**: N/A    **GCC/Compiler version (if compiling from source)**: N/A    **CUDA/cuDNN version**: cudatoolkit=11.2 cudnn=8.1.0    **GPU model and memory**: RTX 3090, 24 GB    **Exact command to reproduce**:   Describe the problem Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request. The LayerNormalization layer does not exist, in fact none of the normalization layers are in  and so cannot be imported in a Python script. I have installed tensorflow using pip in a conda environment as described in the tensorflow installation documentation. The expected behavior is the LayerNormalization layer should exist in the source tree and be importable as Python module.   Source code / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem. Steps to reproduce. 1. Install tensorflow in a conda environment using pip ",2023-02-08T13:12:17Z,stat:awaiting response comp:keras subtype: ubuntu/linux TF 2.11,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59612,"Hi,   It seems like you're trying to use legacy Keras code which is stale and about to be deleted. we have added warning on that page and The current Keras code lives in github/kerasteam/keras. We have also updated in our `TensorFlow 2.11.0` release notes and you'll find `.py `files in the `normalization` folder after clicking on this link( keras>layers>normalization) and please use the public API with `from tensorflow import keras` as shown in this gist file and I was able to replicate the issue on `ubuntu 20.04` with `Tensorflow==2.11` and it's importing as expected, I have added screenshot for your reference below: !image If issue still persists please let us know? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!","Hi , this resolved it perfectly. Thank you so much!"
839,"以下是一个github上的tensorflow下的一个issue, 标题是(change in reproducibility behavior of GlorotUniform between tf 2.6 and 2.11)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? With tf 2.6 , the following code always produces same result, but produces varying results in tf 2.11   Standalone code to reproduce the issue  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,saswatac,change in reproducibility behavior of GlorotUniform between tf 2.6 and 2.11,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04.5 LTS  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? With tf 2.6 , the following code always produces same result, but produces varying results in tf 2.11   Standalone code to reproduce the issue  Relevant log output _No response_",2023-02-08T10:18:11Z,type:bug comp:keras TF 2.11,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59608,it is related to intializers in general  https://github.com/tensorflow/tensorflow/issues/57763 . Resolving this issue.,Are you satisfied with the resolution of your issue? Yes No
1229,"以下是一个github上的tensorflow下的一个issue, 标题是(Add new single-kernel implementation of sparse to ragged index conversion)， 内容是 (Adds a new op, SparseIndicesToRaggedRowSplits, and modifies `RaggedTensor.from_sparse` to use this op in place of the previous implementation. On a single A10040GB GPU, my tests showed a speedup of 5x up to 150x depending on the input SparseTensor.  The op is also implemented for CPU. This op accepts SparseTensor indices as input and returns a tensor of row_splits which can be used to create a RaggedTensor. If argument `validate_ragged_right` is set to true, the op will additionally check that the input indices represent a raggedright SparseTensor. Because this change modifies `RaggedTensor.from_sparse` to create the new RaggedTensor with the `from_row_splits` constructor instead of `from_value_rowids` as before, PR CC(Allow RowPartition to cache row_lengths and value_rowids) or another such change will be necessary to avoid regression for existing code that repeatedly calls `row_lengths()` or `value_rowids()` on a RaggedTensor created with `from_sparse`.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,vysarge,Add new single-kernel implementation of sparse to ragged index conversion,"Adds a new op, SparseIndicesToRaggedRowSplits, and modifies `RaggedTensor.from_sparse` to use this op in place of the previous implementation. On a single A10040GB GPU, my tests showed a speedup of 5x up to 150x depending on the input SparseTensor.  The op is also implemented for CPU. This op accepts SparseTensor indices as input and returns a tensor of row_splits which can be used to create a RaggedTensor. If argument `validate_ragged_right` is set to true, the op will additionally check that the input indices represent a raggedright SparseTensor. Because this change modifies `RaggedTensor.from_sparse` to create the new RaggedTensor with the `from_row_splits` constructor instead of `from_value_rowids` as before, PR CC(Allow RowPartition to cache row_lengths and value_rowids) or another such change will be necessary to avoid regression for existing code that repeatedly calls `row_lengths()` or `value_rowids()` on a RaggedTensor created with `from_sparse`.",2023-02-08T01:38:50Z,size:L comp:core,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59602,Hi  Can you please resolve conflicts? Thank you!,This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.,Conflicts have been resolved.,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!, you self assigned here.  Can you PTAL or reassign to someone with better context. ,Closed the prerequisite of this PR github.com/tensorflow/tensorflow/pull/59508. Going to close this one as well.
746,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensorflow ROCm - Faceswap - Anaconda Enviroment)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tensorflowrocm 2.10.1.540 / tensorflow 2.2.3  Custom Code Yes  OS Platform and Distribution Linux PikaOS 22.10  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory AMD RX6800XT  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,linuxreitt,Tensorflow ROCm - Faceswap - Anaconda Enviroment,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tensorflowrocm 2.10.1.540 / tensorflow 2.2.3  Custom Code Yes  OS Platform and Distribution Linux PikaOS 22.10  Mobile device _No response_  Python version 3.8.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory AMD RX6800XT  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-07T22:33:18Z,stat:awaiting response type:build/install stale subtype: ubuntu/linux TF 2.2,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59601, Could you please make sure to check the tested build configuration as mentioned here and use the latest TF version. Thank you! ,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
797,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.distribute.MultiWorkerMirroredStrategy: Program hangs when connecting with gRPC.)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tensorflowaarch64 2.11.0  Custom Code No  OS Platform and Distribution Ubuntu 22.10  Mobile device _No response_  Python version Python 3.10.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output   Accompanying script for ""sbatch script.sh"":  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kasbah512,tf.distribute.MultiWorkerMirroredStrategy: Program hangs when connecting with gRPC.,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tensorflowaarch64 2.11.0  Custom Code No  OS Platform and Distribution Ubuntu 22.10  Mobile device _No response_  Python version Python 3.10.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output   Accompanying script for ""sbatch script.sh"":  ",2023-02-06T01:49:20Z,type:bug comp:dist-strat TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59573,"I think it is related to the hostlist expansion, fix here CC(Fixed missing leading zero issue on SlurmClusterResolver), because your nodelist is:  But Tensorflow got:  Instead of: ","> I think it is related to the hostlist expansion, fix here CC(Fixed missing leading zero issue on SlurmClusterResolver), because your nodelist is: >  >  >  > But Tensorflow got: >  >  >  > Instead of: >  >  Good find! That was indeed an issue for me, so updated the file on each device for tensorflow/python/distribute/cluster_resolver/slurm_cluster_resolver.py, but the process still hangs.  new output: ","Fixed the issue. All host config files except the master on my machines were managed by a service, so on reboot the configurations for iphostname associations were removed.",Are you satisfied with the resolution of your issue? Yes No
389,"以下是一个github上的tensorflow下的一个issue, 标题是(Small refactoring in the tensorflow/python/keras/layers area)， 内容是 (Noticed a few things I thought were improvements while going through and learning... or trying to! Most of the changes wound up being indents.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,joesho112358,Small refactoring in the tensorflow/python/keras/layers area,Noticed a few things I thought were improvements while going through and learning... or trying to! Most of the changes wound up being indents.,2023-02-04T09:28:32Z,comp:keras size:M,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59568,"Hi  It looks like your PR relates to the Keras component. Please submit it to the github.com/kerasteam/keras repository instead. Thankyou. , "
1876,"以下是一个github上的tensorflow下的一个issue, 标题是(TFlite minimal example failing on latest tensorflow repo)， 内容是 (When I run latest tensorflow lite example minimal and it is failing on Linux machine with the below error Followed steps mentioned here  and ran on x86_64 GNU/Linux https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal ,,, 100%] Linking CXX executable minimal /usr/bin/ld: tensorflowlite/libtensorflowlite.a(register.cc.o): in function `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()': register.cc:(.text+0x1cd): undefined reference to `tflite::ops::builtin::Register_ABS()' /usr/bin/ld: register.cc:(.text+0x1ed): undefined reference to `tflite::ops::builtin::Register_HARD_SWISH()' /usr/bin/ld: register.cc:(.text+0x207): undefined reference to `tflite::ops::builtin::Register_RELU()' /usr/bin/ld: register.cc:(.text+0x227): undefined reference to `tflite::ops::builtin::Register_RELU_N1_TO_1()' /usr/bin/ld: register.cc:(.text+0x241): undefined reference to `tflite::ops::builtin::Register_RELU_0_TO_1()' /usr/bin/ld: register.cc:(.text+0x25b): undefined reference to `tflite::ops::builtin::Register_RELU6()' /usr/bin/ld: register.cc:(.text+0x27b): undefined reference to `tflite::ops::builtin::Register_TANH()' /usr/bin/ld: register.cc:(.text+0x29b): undefined reference to `tflite::ops::builtin::Register_LOGISTIC()' /usr/bin/ld: register.cc:(.text+0x2bb): undefined reference to `tflite::ops::builtin::Register_AVERAGE_POOL_2D()' /usr/bin/ld: register.cc:(.text+0x2db): undefined reference to `tflite::ops::builtin::Register_MAX_POOL_2D()' /usr/bin/ld: register.cc:(.text+0x2fb): undefined reference to `tflite::ops::builtin::Register_L2_POOL_2D()' /usr/bin/ld: register.cc:(.text+)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,nyadla-sys,TFlite minimal example failing on latest tensorflow repo,"When I run latest tensorflow lite example minimal and it is failing on Linux machine with the below error Followed steps mentioned here  and ran on x86_64 GNU/Linux https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal ,,, 100%] Linking CXX executable minimal /usr/bin/ld: tensorflowlite/libtensorflowlite.a(register.cc.o): in function `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()': register.cc:(.text+0x1cd): undefined reference to `tflite::ops::builtin::Register_ABS()' /usr/bin/ld: register.cc:(.text+0x1ed): undefined reference to `tflite::ops::builtin::Register_HARD_SWISH()' /usr/bin/ld: register.cc:(.text+0x207): undefined reference to `tflite::ops::builtin::Register_RELU()' /usr/bin/ld: register.cc:(.text+0x227): undefined reference to `tflite::ops::builtin::Register_RELU_N1_TO_1()' /usr/bin/ld: register.cc:(.text+0x241): undefined reference to `tflite::ops::builtin::Register_RELU_0_TO_1()' /usr/bin/ld: register.cc:(.text+0x25b): undefined reference to `tflite::ops::builtin::Register_RELU6()' /usr/bin/ld: register.cc:(.text+0x27b): undefined reference to `tflite::ops::builtin::Register_TANH()' /usr/bin/ld: register.cc:(.text+0x29b): undefined reference to `tflite::ops::builtin::Register_LOGISTIC()' /usr/bin/ld: register.cc:(.text+0x2bb): undefined reference to `tflite::ops::builtin::Register_AVERAGE_POOL_2D()' /usr/bin/ld: register.cc:(.text+0x2db): undefined reference to `tflite::ops::builtin::Register_MAX_POOL_2D()' /usr/bin/ld: register.cc:(.text+0x2fb): undefined reference to `tflite::ops::builtin::Register_L2_POOL_2D()' /usr/bin/ld: register.cc:(.text+",2023-02-03T18:10:28Z,type:support comp:lite subtype: ubuntu/linux comp:lite-support,closed,0,13,https://github.com/tensorflow/tensorflow/issues/59537,"Hi, sys  Apologize for the delay and I was able to replicate the issue and I'm also getting the same error which you mentioned in the above error log and before that while following the TensorFlow Lite C++ minimal example instructions I encountered issue with `libffi7` package because since Ubuntu 20.10 comes with `libff8` instead of `libffi7` I installed `libffi7` by manually downloading the deb package from ubuntu focal (20.04) By following below steps  I have added error screenshot for your reference below and I tried on `Ubuntu 20.04`: !image It seems like we have to dig more into this issue to find out the root cause for this issue so we'll update soon here and thank you for noticing this issue, I really appreciate it. Thank you!","Hi,   Could you please look into this issue ? Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Issue is still reproducible,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"This is certainly frustrating, as the issue has been assigned to someone at Google, but the issue remains unresolved and the Google bot has moved it to a stalled state.",Are you satisfied with the resolution of your issue? Yes No,"Hi, Apologies for the delayed response and for the stale label due to bot action, I was facing session crash on colab when the process is at 92%. However, I can successfully able to build using my local linux instance using latest code and by following the steps mentioned here https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal  Let us know if you still need any further assistance. Thanks!",Its working now.,Are you satisfied with the resolution of your issue? Yes No,"Can this issue be reopened? I am experiencing exactly the same error with the latest TF. I followed the minimal instructions from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal. I got the same error on two systems, WSL with Ubuntu 22.04 and Linux system with Ubuntu 20.04.  Error on WSL with Ubuntu 22.04   Error on Linux system with Ubuntu 20.04 "," , Could you please file a new issue with the details of your findings. Thanks","You are welcome, I made the ticket (see the link above)."
1909,"以下是一个github上的tensorflow下的一个issue, 标题是(Fail to export model created with audio_classifier.create()  on windows 10, Python 3.9.16)， 内容是 (Hi there!  Invoking the kind support of brightest minds!  I´m trying to export the model created with audio_classifier.create() function, in  an audio classification model using the TensorFlow Lite Model Maker library, taken from the online tutorial.  The code runs ok, identefoies the audio but if fails to export the model.   1. System information  OS: windows 10  TensorFlow 2.9.0 installed via PIP  Tflitemodelmaker 0.4.2 installed from source :           git clone https://github.com/tensorflow/examples         cd examples/tensorflow_examples/lite/model_maker/pip_package         pip install e .  2. Code !/usr/bin/env python  coding: utf8   Copyright 2021 The TensorFlow Authors. import tensorflow as tf import tflite_model_maker as mm from tflite_model_maker import audio_classifier import os import numpy as np import matplotlib.pyplot as plt import seaborn as sns import itertools import glob import random from pathlib import Path from IPython.display import Audio, Image, display from scipy.io import wavfile from tensorflow.keras import models print(f""TensorFlow Version: {tf.__version__}"") print(f""Model Maker Version: {mm.__version__}"") data_dir = './dataset/urbanbirds' bird_code_to_name = {   'anupreto': 'Anu preto',   'bemtevi': 'Bemtevi',   'ticotico': 'Tico tico',     'corruira': 'Corruira',   'sabia': ""Sabia laranjeira"",    } birds_images = {   'anupreto': 'http://myserver/public/img/Anupreto.jpg',    'bemtevi': 'http://myserver/public/img/Bemtevi.jpg',    'ticotico': 'http://myserver/public/img/Ticotico.jpg',    'corruira': 'http://myserver/public/img/Corruira.jpg',    'sabia': 'http://myserver/public/i)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hakimus2k,"Fail to export model created with audio_classifier.create()  on windows 10, Python 3.9.16","Hi there!  Invoking the kind support of brightest minds!  I´m trying to export the model created with audio_classifier.create() function, in  an audio classification model using the TensorFlow Lite Model Maker library, taken from the online tutorial.  The code runs ok, identefoies the audio but if fails to export the model.   1. System information  OS: windows 10  TensorFlow 2.9.0 installed via PIP  Tflitemodelmaker 0.4.2 installed from source :           git clone https://github.com/tensorflow/examples         cd examples/tensorflow_examples/lite/model_maker/pip_package         pip install e .  2. Code !/usr/bin/env python  coding: utf8   Copyright 2021 The TensorFlow Authors. import tensorflow as tf import tflite_model_maker as mm from tflite_model_maker import audio_classifier import os import numpy as np import matplotlib.pyplot as plt import seaborn as sns import itertools import glob import random from pathlib import Path from IPython.display import Audio, Image, display from scipy.io import wavfile from tensorflow.keras import models print(f""TensorFlow Version: {tf.__version__}"") print(f""Model Maker Version: {mm.__version__}"") data_dir = './dataset/urbanbirds' bird_code_to_name = {   'anupreto': 'Anu preto',   'bemtevi': 'Bemtevi',   'ticotico': 'Tico tico',     'corruira': 'Corruira',   'sabia': ""Sabia laranjeira"",    } birds_images = {   'anupreto': 'http://myserver/public/img/Anupreto.jpg',    'bemtevi': 'http://myserver/public/img/Bemtevi.jpg',    'ticotico': 'http://myserver/public/img/Ticotico.jpg',    'corruira': 'http://myserver/public/img/Corruira.jpg',    'sabia': 'http://myserver/public/i",2023-02-02T20:27:36Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.9,closed,1,8,https://github.com/tensorflow/tensorflow/issues/59531,Just a correction: The installed version (by compilation) is Model Maker Version: 0.3.4. I´m have not been able to update to 0.4.2.,Hi  ! The code and error log provided are not reproducible as a standalone code. Please refer to the colab tutorial for the audio classification using model maker. Could you provide a gist with 0.4.2 or nightly version which can be installed by using `pip install tflitemodelmakernightly`.  Thank you!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No," In order to expedite the troubleshooting process, please provide  accessible files with colab gist/code snippet to reproduce the issue reported here. That will help better understand and investigate the issue further.  Are you trying to reproduce https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/audio_classifier locally for custom data and hitting problems? If so, can you please mention what steps have you changed?  Thanks!",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
759,"以下是一个github上的tensorflow下的一个issue, 标题是(ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC"")， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version v1.12.188697g620bee79ab3 2.12.0dev20230201  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version Python 3.10  Bazel version 5.3.0  GCC/Compiler version gcc11  CUDA/cuDNN version CUDA11.8/cudnn8.7.0/TensorRT8.5.3  GPU model and memory RTX3090  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,froody,"ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC""",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version v1.12.188697g620bee79ab3 2.12.0dev20230201  Custom Code No  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version Python 3.10  Bazel version 5.3.0  GCC/Compiler version gcc11  CUDA/cuDNN version CUDA11.8/cudnn8.7.0/TensorRT8.5.3  GPU model and memory RTX3090  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-02-02T11:20:23Z,stat:awaiting tensorflower type:bug subtype: ubuntu/linux comp:gpu:tensorrt TF 2.11,open,0,8,https://github.com/tensorflow/tensorflow/issues/59525,"Hi,   Apologize for the delay and I think you're trying to convert input tensor of data format `NHWC` to `NDHWC` so I'm not sure whether is it possible to do it or not but what I think input tensor of data format should be equal to output tensor of data format so `NHWC` converts to `NCHW` and `NDHWC` converts to `NCDHW ` and even in log output it's saying clearly `INVALID_ARGUMENT: Rank of perm for transpose does not match with that of the input.` You can refer this official documentation with source code and Here are some references Ref1, Ref2, Ref3 which may help you to resolve your issue  The meaning of each letter might help to understand:  Please let me know if I've missed out anything here ? Thank you!"," please look at my sample code provided. On which line do you think I'm creating an NHWC tensor? Or asking for a conversion from NHWC to NDHWC? My point is that `ConvertFusedBatchNorm` in `convert_nodes.cc` has a bug. The code looks like  If you instrument it to print out the value of `data_format` and then run the sample python code I provided above, you will see at one point `data_format = ""NDHWC""`, which causes the code to skip both conversion blocks and assign the uninitialized value of `output_tensor` to `params>outputs`.  If you instrument this code to print out the values of `order_size` and `dims.nbDims` in the case where they aren't equal, you should see `order_size = 4` and `dims.nbDims` having some unreasonably large value, slightly less than `0xffff`, due to the uninitialized value introduced by the code segment above.","Hi,   Could you please look into this issue ? Thank you!"," , Does the recent commit here to the above function which you have pointed https://github.com/tensorflow/tensorflow/commit/1377c6e2574122a540153aff220c09c69dbec8a8 helps you in any way?  "," which recent commit? Looking at master I still see code in the format below, which leaves output_tensor uninitialized when `data_format ==  ""NDHWC""` ","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"I want this to work with Conv3D layers, ie NDHWC"
413,"以下是一个github上的tensorflow下的一个issue, 标题是(Tensor flow lite wheel file for ARM9 32-bit architecture )， 内容是 (i am trying to build .whl file for ARM9 32bit architecture using Bazel, but fortuanetly there is no tool to build for 32bit. can someone help me in getting my work done.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,saimanohar1999,Tensor flow lite wheel file for ARM9 32-bit architecture ,"i am trying to build .whl file for ARM9 32bit architecture using Bazel, but fortuanetly there is no tool to build for 32bit. can someone help me in getting my work done.",2023-02-02T05:34:25Z,stat:awaiting response type:build/install stale comp:lite TFLiteConverter TF 2.11,closed,0,31,https://github.com/tensorflow/tensorflow/issues/59521,any reference which help me getting tflite dependencies for ARM9 architecture 32bit.,Hi  ! Could you check with below bazel command  (Bazel 5.3.0 ) . Attached relevant document for arm32 crosscompile  `bazel build config=elinux_armhf c opt //tensorflow/lite/c:libtensorflowlite_c.so` You can also Opt for CMake which offers a wide variety of crosscompiling . Thank you!,thanks for the response. i was able to generate .so file but i need .whl file,"Hi  ! To get .whl file , Pleas refer build_cmake_pip documentation. Thank you!",i tried the above but unable to see .whl file may i know in which path we can see .whl file. Thank you,tflite_runtime2.12.0cp38cp38linux_x86_64.whl i found this file /tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3/dist     in this path.  but i am looking for 32bit architecture.,Hi  ! Thanks for the update.  You can check for other python wheels here in Pinto's repo.  ! Could you look at this issue. Thank you!,the Pintos repo mentioned above dosent have any .whl file for ARM9 32bit architecture.,"any reference related to my issue , can be shared. waiting for the next response. Thank You",Let me know whether it is possible to generate .whl file or not through this process. ,any update??,"I was able to find few references regarding .whl file location for Tensorflow( not specific to TFLite or any architecture). In the below link, it explains about creating the .whl package with `bazelbin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg` https://stackoverflow.com/questions/45855487/ Also, refer the guide here, which explains about building package using bazel, common issues and references. Le me know if this is of any help for you, Thank you! ","thank you  i already gone through the references which you shared, but the issue is tflite_runtime2.13.0cp38cp38linux_x86_64.whl is the file i am getting but its seems to be 64bit , even i gave armhf while building its giving 64bit",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,You need to cross compile to get ARM 32 bit binary. https://www.tensorflow.org/lite/guide/build_cmake_piparm_cross_compilation,Thank you...but I tried doing that still i was unable get the expected file...  ," i was able to complete the build process able to generate "".whl"" file but it is generating for 64bit.",Could you share the command you used?,"sorry for the misunderstanding , i was able to figure out  i was able to get 32bit file "".whl"" with the following command  make C tensorflow/lite/tools/pip_package dockerbuild \   TENSORFLOW_TARGET=armhf  PYTHON_VERSION=3.8 with the above command i was able to get  ""tflite_runtime2.13.0cp38cp38linux_armv7l.whl"" file i guess its for arm7 architecture, i want for arm9 architecture. later upto my understanding i figured out that the issue is because of toolchain used, can u help me changing the toolchain ....since in the make file ""download_toolchain.sh"" it is downloading toolchain for arm7 architecture but i need for arm926, to be specific for SAM9X60 Board. Thank you  ",Are you satisfied with the resolution of your issue? Yes No,"  still i am facing issues in generating file for sam9x60 which is ARM926 based board , help me in solving this.","cd /tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.10/cmake_build/_deps/flatbuffersbuild && /opt/cmake/bin/cmake P CMakeFiles/flatbuffers.dir/cmake_clean_target.cmake cd /tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.10/cmake_build/_deps/flatbuffersbuild && /opt/cmake/bin/cmake E cmake_link_script CMakeFiles/flatbuffers.dir/link.txt verbose=1 /usr/bin/ar qc libflatbuffers.a  CMakeFiles/flatbuffers.dir/src/idl_parser.cpp.o CMakeFiles/flatbuffers.dir/src/idl_gen_text.cpp.o CMakeFiles/flatbuffers.dir/src/reflection.cpp.o CMakeFiles/flatbuffers.dir/src/util.cpp.o /usr/bin/ranlib libflatbuffers.a make[3]: Leaving directory '/tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.10/cmake_build' [ 16%] Built target flatbuffers make[2]: Leaving directory '/tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.10/cmake_build' make[1]: *** [CMakeFiles/Makefile2:1393: CMakeFiles/_pywrap_tensorflow_interpreter_wrapper.dir/rule] Error 2 make[1]: Leaving directory '/tensorflow/tensorflow/lite/tools/pip_package/gen/tflite_pip/python3.10/cmake_build' make: *** [Makefile:193: _pywrap_tensorflow_interpreter_wrapper] Error 2 make: *** [Makefile:72: dockerbuild] Error 2 make: Leaving directory '/home/administrator/manohar/tensorflow_src/tensorflow/lite/tools/pip_package this is the error i am getting........ but when i am building with toolchain supporting armv7 build was successful, now when i am using armnoneeabi toolchain for sam9x60 board i am getting this build error. i hope i am clear ",Hi   https://docs.google.com/document/d/1Q2fuC4xMusDsDwCHrxMP78efhneFJeYuG9x7oAPSJw/edit I have attached the link where i explained clearly about the current issue with all the flags i used during build process. please go through it and le me know if you still need any details to get better understanding of the problem.,Hi  can you help me in getting the toolchain for armv5te to build ....may be there might be issue with the toolchain i am using... Thank you.,"Hi , it appears your link is broken can you please provide a working link? Thank you.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,"Hi pkgoogle, what link are you referring to.", This one: https://docs.google.com/document/d/1Q2fuC4xMusDsDwCHrxMP78efhneFJeYuG9x7oAPSJw/edit from Mar 1,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.
1055,"以下是一个github上的tensorflow下的一个issue, 标题是(ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC"")， 内容是 (https://github.com/tensorflow/tensorflow/blob/4aec415b3f06b19c380d1a0ca92cc2de0d74cc21/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.ccL4399L4436 I was trying to optimize my model with tensorrt following this guide: https://docs.nvidia.com/deeplearning/frameworks/tftrtuserguide/index.html but I was getting an error in the log: `20230202 11:32:14.336729: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:1104] TFTRT Warning: Engine creation for TRTEngineOp_000_000 failed. The native segment will be used instead. Reason: INVALID_ARGUMENT: Rank of perm for transpose does not match with that of the input.` I added some print statements and recompiled tensorflow leading me to ConvertFusedBatchNorm which clearly returns an uninitialized value when invoked with NDHWC input)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,froody,"ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC""",https://github.com/tensorflow/tensorflow/blob/4aec415b3f06b19c380d1a0ca92cc2de0d74cc21/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.ccL4399L4436 I was trying to optimize my model with tensorrt following this guide: https://docs.nvidia.com/deeplearning/frameworks/tftrtuserguide/index.html but I was getting an error in the log: `20230202 11:32:14.336729: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:1104] TFTRT Warning: Engine creation for TRTEngineOp_000_000 failed. The native segment will be used instead. Reason: INVALID_ARGUMENT: Rank of perm for transpose does not match with that of the input.` I added some print statements and recompiled tensorflow leading me to ConvertFusedBatchNorm which clearly returns an uninitialized value when invoked with NDHWC input,2023-02-02T01:55:43Z,stat:awaiting response comp:core comp:gpu:tensorrt TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59518,"Hi,   We see that the issue template has not been filled, could you please do so as it helps us analyze the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist to reproduce the issue faced. Thank you!"," CC(ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC"")","Hi,   Thank you for submitting the issue by following the Tensorflow issue template  CC(ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC"") so this will become duplicate issue so could you please close this issue because it is being tracked in  CC(ConvertFusedBatchNorm returns uninitialized value when data_format = ""NDHWC""). Thank you!"
960,"以下是一个github上的tensorflow下的一个issue, 标题是(TF to TFLite conversion of model gives error op is neither a custom op nor a flex op)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.4   TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion The conversion fails as below, saved model dir is attached a zip file. I'm not sure what needs to be changed to fix this. Eventually, I'd like to convert the TFLite model to run on TPU. Thanks!  5. (optional) Any other info / logs )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,gsirocco,TF to TFLite conversion of model gives error op is neither a custom op nor a flex op," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.4   TensorFlow installation (pip package or built from source): pip package  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0  2. Code Provide code to help us reproduce your issues using one of the following options:  Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion The conversion fails as below, saved model dir is attached a zip file. I'm not sure what needs to be changed to fix this. Eventually, I'd like to convert the TFLite model to run on TPU. Thanks!  5. (optional) Any other info / logs ",2023-02-02T00:30:03Z,stat:awaiting response type:support comp:lite comp:micro TFLiteConverter TF 2.11,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59517,"Attaching the saved model zip file again, as I don't think it got attached above. qam_modulator.zip",  I was able to reproduce the issue on Colab using Tf v2.11. Please find the gist here for reference. Thank you!,"Hi  and , thanks for reproducing the issue. Do you have any suggestions for fixing? Thanks!","Hi  ! Sorry for the late response. I am able to replicate this issue in 2.10, 2.11 and  nightly . For custom ops issues, Please register the customs ops in lite kernels and follow custom_ops documentation for reference. Thank you!","Hi   Thanks for the information. My ultimate goal after conversion to TFLite is to be able to run this model entirely on Edge TPU. I just want to confirm if going through this procedure will allow this to happen or if I will ultimately need to rewrite some portion of the model for TPU integer compatibility. Thanks!! Also, do all these operators need to be registered and converted? "," ! For edge_tpu specific optimization,  Could you route it to Google/coral repo /TFforum for further assistance . Thank you!","As suspected, the TPU will not run any custom ops above, so the QAM Modulator model must be rewritten so the ops above use the ones in this list",Are you satisfied with the resolution of your issue? Yes No
656,"以下是一个github上的tensorflow下的一个issue, 标题是([XLA] Cublaslt fp8 matmul restriction work-around)， 内容是 (As of 2/1/2023, cublasLt f8 matmul only support col major input(default to cublas). But calling from TF/XLA, input can be in all kinds of storage type. This PR aims to ""canonicalize"" fp8 matmuls by having lrs/rhs_contracting_dim={1,0} and adding necessary transposes to inputs. A reproducer of this bug restriction is located at here. A remaining restriction is the batch dimension still needs to be a leading dimension.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,wenscarl,[XLA] Cublaslt fp8 matmul restriction work-around,"As of 2/1/2023, cublasLt f8 matmul only support col major input(default to cublas). But calling from TF/XLA, input can be in all kinds of storage type. This PR aims to ""canonicalize"" fp8 matmuls by having lrs/rhs_contracting_dim={1,0} and adding necessary transposes to inputs. A reproducer of this bug restriction is located at here. A remaining restriction is the batch dimension still needs to be a leading dimension.",2023-02-01T21:22:57Z,awaiting review ready to pull comp:xla size:M,closed,1,7,https://github.com/tensorflow/tensorflow/issues/59515,/CC  ," This is largely independent of the requirement of transposing A but not B. The columnmajor/rowmajor layout returned by GemmConfig::For doesn’t fully describe the configuration of a GEMM. Not considering batch dimensions, A and B each can have two possible contracting dimensions (0, 1) and two possible minortomajor orders ({0,1}, {1,0}). The idea is to bitcast/transpose the operands into the configuration supported by cuBLASLt (A and B have contracting dimensions 1 and 0 and both have {1, 0} orders). Since this only affects FP8 GEMMs, I think it can make sense to introduce this here without changing the general logic.",">  This is largely independent of the requirement of transposing A but not B. The columnmajor/rowmajor layout returned by GemmConfig::For doesn’t fully describe the configuration of a GEMM. Not considering batch dimensions, A and B each can have two possible contracting dimensions (0, 1) and two possible minortomajor orders ({0,1}, {1,0}). >  > The idea is to bitcast/transpose the operands into the configuration supported by cuBLASLt (A and B have contracting dimensions 1 and 0 and both have {1, 0} orders). Since this only affects FP8 GEMMs, I think it can make sense to introduce this here without changing the general logic.    what is the next step here?  reedwm was going to give the nonTN invocation of cuBLAS lt  a try  wenscarl/philipphack were to look into reedwm's suggestion about moving some of the transposing logic to the matmul_util Is that still the plan?","I confirmed the nonTN invocation works (the NN invocation, where neither input is transposed). I'm working on modifying this PR to run with NN, then I'll share it and ask if you think it's clearer.   do you plan on adding more test cases? If not I can also add some.",Eventually can we please streamline and shorten the tests by perhaps parametrizing them? This would also help with readability. https://google.github.io/googletest/reference/testing.htmlTEST_P,"Thanks for the comments.  The monotonic layout is not necessary but only serves as a means to simplify the logic thereafter. This will be fixed. This HLO is a batched matmul and the batch dim being the first dim which falls in to the cases currently supported. But if batch dim is not first dim, e.g. [16,2,32], no matter fp8 gemm rewrite succeed or not, this case is not supported anyway.  So in this PR, we don't plan to check for batch dim being first dim. ",Can you resolve branch conflicts?
707,"以下是一个github上的tensorflow下的一个issue, 标题是(module 'numpy' has no attribute 'typeDict')， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.9.1  Custom Code No  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.10.5  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hulagerushikesh,module 'numpy' has no attribute 'typeDict',Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.9.1  Custom Code No  OS Platform and Distribution Windows 11  Mobile device _No response_  Python version 3.10.5  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-02-01T16:12:28Z,stat:awaiting response type:build/install stale subtype:windows TF 2.9,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59513,it has been added in tensorflow 2.11.0,"Hi,   Apologize for the delay and as per the NumPy 1.21.0 Release Notes `np.typeDict` has been formally deprecated so This means you are using a NumPy version that removed the deprecated `np.typeDict` ( you can use `np.sctypeDict` instead of `np.typeDict`).  I checked while using the `np.typeDict ` we're getting proper warning as below :  For your reference I have added gist file with some sample code with latest version of `Tensorflow==2.11` it's working fine with `np.sctypeDict` and with `np.typeDict` (with DeprecationWarning) so I would suggest you to either go with latest `Tensorflow version 2.11` or Use an older version of `numpy` (one before it started to issue the deprecation warning) If Issue still persists please let us know? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Having the latest version of tensorflow didn't solve the issue for me. I had to manually update `h5py` to 3.8.0 (latest as of writing this) and that solved the issue.
763,"以下是一个github上的tensorflow下的一个issue, 标题是(OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed when using a dataset with tuples)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Windows  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mihail-vladov,OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed when using a dataset with tuples,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Windows  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-02-01T10:11:45Z,stat:awaiting response type:bug stale comp:core TF 2.11,closed,0,22,https://github.com/tensorflow/tensorflow/issues/59510,"The bug in the code is that you are using the `fit` method of the `tf.keras.Model` with the `train_data` dataset, but `train_data` is not defined anywhere in the code. Solution:  Additionally, the `call` method of your custom `MyTransformer` model is not returning the labels `lable` which is required for the training process. You'll need to return both the features and the labels from the `call` method in order for the model to be trained properly:  Finally, the loss function that you are using, `tf.keras.losses.BinaryCrossentropy` is designed for binary classification problems, but the labels in your dataset are categorical. To handle this, you should use a different loss function, such as `tf.keras.losses.CategoricalCrossentropy`, which is designed for categorical classification problems.",Let me know if it helps ?,"Hi , and thank you for the reply. using the wrong variable was a mistake that I made when pasting the example here. Even if a not defined variable was used I would've expected ""NameError: name 'train_data' is not defined"" error and not one for a symbolic tensor. The link that was provided with the description of the issue points out to google colab example where the correct variable was used. So the original question still stands.  I've now modified the example according to your suggestions to return feature and label, plus using the CategoricalCrossentropy and nothing changes. Here is a link to the example in google colab: **https://colab.research.google.com/drive/1mn6iseJLnJwTmwakYa2XuxszKtR6sV9GscrollTo=Cj9g0bGN1Fo3** Can you help me to understand what the real issue is?",vladov Thanks for reporting issue.   I was able to reproduce this issue. Please find the gist here.  The model works as expected when features and labels are given as forward pass but fail when `tf.data.Dataset` is passed to the `model.fit`.,"Proceeding with the  points, I think it is important to ensure that the data is correctly formatted and preprocessed before being passed to the model. Some common issues include incorrect tensor shapes, data types, and normalization. To resolve the issue, you may need to inspect and debug the data preprocessing steps, including any data augmentation or batching operations that are applied to the data before passing it to the model. Additionally, it may be helpful to compare the data and preprocessing steps used when passing features and labels directly to the model versus when using a tf.data.Dataset. Rest everything logic and code is syntactically correct, please check the dataset properly and preprocess it carefully. ","Hi, vladov  Apologize for the delay and It seems like you haven't done preprocessing with your dataset, your `batched_labels` should be in `numerical values` but it was in `string` type so you'll have to do some preprocessing with `batched_labels` with one hot encoding approach so that `batched_labels`  will convert into numerical values so you can refer this official documentation  When you pass dataset from `tf.data.Dataset()` to model.fit() it is expected that it will directly generate batches, not individual examples. You just need to batch your dataset before training as shown below and please refer tf.data.Dataset():  I have added sample code example for your reference, How to use `tf.data.dataset` with `model.fit()` so please refer this gistfile and also refer our official documentation for Customize what happens in Model.fit  I hope it will help you to resolve your issue and if issue still persists please let us know ? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!","Hi , I'm a bit confused by your response, as the code in your gistfile appears to differ significantly from the code I provided, except for the use of TensorFlow and a dataset. Additionally,  has confirmed that there is a bug, so I was hoping to receive an update on when the bug will be fixed. Regarding your previous comment about the data preprocessing and batches, I understand your point and you would be typically right if there was no issue and I was actually able to use the data. However, this is not the case. Nevertheless, I've reworked the example to reflect your comments. Here is the updated example. As you can verify yourself, the exception is still there. I would like to reiterate the issue I am encountering. According to the TensorFlow documentation, I should be able to use a dataset as the **x** argument for the model.fit() function and receive a tuple as **inputs** parameter in the model.call() function. Then, I would decide how to process and what operation to execute on the data in that function. However, I'm encountering an exception and can't obtain the data in the tuple format from the inputs parameter in the call function. This leaves me with the impression that the documentation is not accurate! Meaning there is a bug. Here is once again the exception:  `File """", line 8, in call   (feature, label) = inputs` `OperatorNotAllowedInGraphError: Iterating over a symbolic tf.Tensor is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.` If you decide to provide an example of how to overcome the exception please use the code I've provided with the specified model and a dataset containing a tuple. Thank you for your time and consideration.",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Hi , is there any update on this?","Hi, vladov  Apologize for the delay and It seems like you're trying to use operation which does not support by `autograph` because of that reason you're getting that error and even error itself is saying the same thing but there is some workaround and I found similar issue over stackoverflow. and it seems like you'll have to use `tf.shape(x)`, please refer this official documentation, please try with `tf.shape(x)` and check whether your issue is resolving or not ? I tried from my end and I'm getting different error `AttributeError: 'NoneType' object has no attribute 'dtype'` and I have added gistfile for your reference. I hope it will help you to resolve your issue. `tf.shape(x) and x.shape should be identical in eager mode. Within tf.function, not all dimensions may be known until execution time. Hence when defining custom layers and models for graph mode, prefer the dynamic tf.shape(x) over the static x.shape.` If issue still persists please let us know ? Thank you!","Hi, , pjpratik already confirmed that this is a **bug**. Why are you trying to convince me that I am doing something incorrectly? You said that I am trying to use an operation that is not supported. **Could you please point out exactly which is that operation?** Regarding your comment on the different error you are getting, you have changed the code in the model, which is why the error is different. I will repeat myself again. According to the TensorFlow documentation, I can use the dataset as input data. This data can be packed as a tuple. Please extract the data from the tuple in the model call function in a way that won't throw an error.","Hi, vladov  Apologize for the delayed response and I see  did not say explicitly it's bug, He only replicated that issue from his end and he said code execution is failing with `tf.data.Dataset` is passed to the `model.fit()` and I was referring there are similar issues with same error message while using `Autograph` mode like [ CC([autograph List comprehension issue] OperatorNotAllowedInGraphError error in Tensorflow 2.0)](https://github.com/tensorflow/tensorflow/issues/32546),  CC(OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.) and users found some workaround for those issues. I'm waiting for response from concerned team for this issue whether is there any workaround to handle this issue till then could you please have look into this Autograph reference guide which may help you to solve this issue and I'll update you soon here. Thank you!","Hi,   Could you please look into this issue ? Thank you!","Hi vladov , The problem not seems to related to Autograph. The problem seems the code trying to get Two values(feature, lable) from a Tensor (`model.fit` converts the given `input` to `Tensor` that is internal details can be checked from the `model.fit` API code) and Tensor can't be unpacked to Two values and Please note that Tensor is immutable in Tensorflow. You can check the behaviour clearly when you enable Eager mode using `model.compile(...,run_eagerly=True)` where you can see the error below. `not enough values to unpack (expected 2, got 1)` I have added `print(inputs)` in `call()` to understand what actually is `inputs`. Please refer attached gist. Hope this will clear your doubts on root cause of this error. Thanks!","Hi , Thank you for the answer. According to the TensorFlow documentation using tuple (feature, label) as inputs argument is allowed. Here is the quote:  > inputs:	Input tensor, or dict/list/tuple of input tensors. I am using a tuple. Here are my questions: 1. Why the model.fit function does not call the model.call function according to the documentation? 2. What is the correct way to obtain the feature and label data in the model.call function when I pass a dataset to the model.fit function?","Hi vladov , > 1. Why the model.fit function does not call the model.call function according to the documentation? The model.fit function called the call() function. You can check by adding print() to confirm same. But here when we pass a dataset as an argument to model.fit, the API converts it into Tensors internally.Outside the model.fit() the dataset might be a tuple but within model.fit the tuple is converting into Tensors which is default behaviour. > 2\. What is the correct way to obtain the feature and label data in the model.call function when I pass a dataset to the model.fit function? To get the custom behaviour as per individuals requirement you need to override the `train_step` . Please refer to attached tutorials for more details. Thank you!",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,I am facing the same issue and I am confused why the example in Neural Machine Translation doesn't run into the same issue but here we run into this issue? Basically they are using the same type of code: , This was one of the issues that made me switch to PyTorch. Misleading documentation and bad support from the developers here. I do not regret my decision.,"`.call()` and `.fit()` have different signatures. In Keras, `.call(inputs)` really behaves like the math model `y=f(x)` with `f` being implemented in `.call()`, so `inputs` should only match ` x` and not `y`, and `y` must not go into `.call()`. During `.fit(dataset)`, the element `(x,y)` of `dataset` is automatically distributed such that `x` is passed to `call()` for the gradient step, and ` y` as well as the prediction ` .call(x)` are passed to the loss function `loss(y_true, y_pred)`. Some precautions to take when developing models outside the classic supervised learning framework, if you wish to reuse the standard Keras workflow :  `dataset` should have a (fake) label `y`. It can have the format `((x1, x2), y)`, and the tuple `(x1, x2)` treated as `x` by Keras can be obtained in `.call(inputs)` as `x1, x2 = inputs` without the mentioned error.  `.call()` should return a single tensor. For multiple outputs like `return y1, y2`, it seems only `y1` will be passed to the loss. In this case they should be stacked like `return keras.ops.stack([y1, y2])`.  Custom loss must have the signature `loss(y_true, y_pred)` even if there is no `y_true`. In case of multiple tensors in `y_pred`, use `keras.ops.take()` to separate them, not `y1, y2 = y_pred`. Then compile the custom model and train with `.fit()`. This is how I developped a selfsupervised learning framework for all three backends without writing the custom `.training_step()` as promoted in the official doc. Hope this helps."
1069,"以下是一个github上的tensorflow下的一个issue, 标题是(Allow RowPartition to cache row_lengths and value_rowids)， 内容是 (Modifies `row_lengths()` and `value_rowids()` methods of the RowPartition class to store their outputs by default when first called if they have not already been precomputed; the stored value will be returned instead of recomputing when called again (~9x speedup for `row_lengths()` and ~37x speedup for `value_rowids()` in a quick test). This behavior can be suppressed by passing `cache=False`. This change improves consistency between performance when using RowPartitions (and RaggedTensors) created with different methods. The `from_value_rowids` and `from_row_lengths` methods already cache whichever of row_lengths and value_rowids are available. With this change, repeated calls to `row_lengths()` and `value_rowids()` are equally fast for RowPartitions / RaggedTensors created with `from_row_splits` and other methods.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,vysarge,Allow RowPartition to cache row_lengths and value_rowids,"Modifies `row_lengths()` and `value_rowids()` methods of the RowPartition class to store their outputs by default when first called if they have not already been precomputed; the stored value will be returned instead of recomputing when called again (~9x speedup for `row_lengths()` and ~37x speedup for `value_rowids()` in a quick test). This behavior can be suppressed by passing `cache=False`. This change improves consistency between performance when using RowPartitions (and RaggedTensors) created with different methods. The `from_value_rowids` and `from_row_lengths` methods already cache whichever of row_lengths and value_rowids are available. With this change, repeated calls to `row_lengths()` and `value_rowids()` are equally fast for RowPartitions / RaggedTensors created with `from_row_splits` and other methods.",2023-02-01T06:16:43Z,comp:ops size:S,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59508,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.",Tacking on a tiny commit with a oneline pylint correction elsewhere in row_partition.py.,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,"Due to concern of out of graph errors caused by cached graph tensor, I am going to close this PR now."
2021,"以下是一个github上的tensorflow下的一个issue, 标题是(RuntimeError: tensorflow/lite/kernels/elementwise.cc:88 Type INT16 is unsupported by op Rsqrt.Node number 34 (RSQRT) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code   Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion Conversion is successful ,however while running the model getting below error RuntimeError                              Traceback (most recent call last)  in        5  Load the TFLite model and allocate tensors       6 interpreter_enc = tf.lite.Interpreter(model_path=tflite_model_path) > 7 interpreter_enc.allocate_tensors()       8        9 print(""== Input details =="")  /usr/local/lib/python3.8/distpackages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)     511   def allocate_tensors(self):     512     self._ensure_safe() > 513     return self._interpreter.AllocateTensors()     514      515   def _safe_to_run(self):  RuntimeError: tensorflow/lite/kernels/elementwise.cc:88 Type INT16 is unsupported by op Rsqrt.Node number 34 (RSQRT) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion suppor)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,nyadla-sys,RuntimeError: tensorflow/lite/kernels/elementwise.cc:88 Type INT16 is unsupported by op Rsqrt.Node number 34 (RSQRT) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code   Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion Conversion is successful ,however while running the model getting below error RuntimeError                              Traceback (most recent call last)  in        5  Load the TFLite model and allocate tensors       6 interpreter_enc = tf.lite.Interpreter(model_path=tflite_model_path) > 7 interpreter_enc.allocate_tensors()       8        9 print(""== Input details =="")  /usr/local/lib/python3.8/distpackages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)     511   def allocate_tensors(self):     512     self._ensure_safe() > 513     return self._interpreter.AllocateTensors()     514      515   def _safe_to_run(self):  RuntimeError: tensorflow/lite/kernels/elementwise.cc:88 Type INT16 is unsupported by op Rsqrt.Node number 34 (RSQRT) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion suppor",2023-02-01T01:25:56Z,stat:awaiting response type:bug stale comp:lite TFLiteConverter TF 2.11,closed,0,24,https://github.com/tensorflow/tensorflow/issues/59506,"Hello sys  This error message is indicating that the TensorFlow Lite delegate (a library used to optimize TensorFlow models for deployment on mobile and embedded devices) is unable to execute the ""Rsqrt"" operation on an input tensor with data type INT16. TensorFlow Lite only supports a limited set of data types, and INT16 is not one of the supported types for this operation. To resolve the issue, you can try converting the INT16 tensor to a supported data type (such as float32) before passing it to the TensorFlow Lite delegate.",TensorFlow Lite supports the following data types: float32 float16 int32 uint8 int64 string Note that the support for specific data types may vary based on the target platform and the operations being performed. It is always a good idea to consult the TensorFlow Lite documentation for the most uptodate information on supported data types.,Let me know if it helps ?," The colab notebook I posted in the link clearly demonstrates the conversion of an ONNX model to a TFLite model with int16 activations and int8 weights. I am puzzled as to why the TFLite Converter would convert it to int16 if it is not supported by the TFLite framework. The original operation was SQRT, but the TFLite Converter changed it to RSQRT. I am not certain why the converter made this change, particularly if it does not support the operation.","The TFLite Converter changes operations like SQRT to RSQRT for optimization purposes. RSQRT is more computationally efficient than SQRT and can be performed using int16 data types. However, TFLite framework does not support int16 data types for all operations and SQRT is one of those operations. The TFLite Converter's priority is to generate a smaller and faster TFLite model, even if it means using unsupported operations or data types. The final decision on whether to use int16 data types and unsupported operations will depend on the use case and the tradeoff between model size and accuracy.","I attempted to convert to a full int8 encoder model, but it produced inaccurate results. That's why I want to try using int16 activations and int8 weights instead",  I was able to replicate the issue in Colab in TF v 2.11. Please find the gist here. Thank you! ,Hi sys ! Could you also test the kerasstablediffusion to TFlite work around as mentioned in this thread and let us know. Thank you!," I used PTQ(post training quantization )with representative data set and generated int8 model,however it is producing wrong results,Soon I will share colab notebook here","Ok sys ! Thanks for the update.  ! Could you look at this issue . Attached gist in 2.10, 2.11 and nightly for reference. Thank you!",Getting the same as sys when trying to convert the same model. From here it seems that int16 should be supported for inference on RSQRT though.,Adding the following patch allows to run inference on int16 rsqrt op in C/C++ TFLite environment ,sys nice I will try this out! When I was converting the decoder to int16x8 I get the following error:  `Quantization to 16x8bit not yet supported for op: 'FLOOR_MOD'.`  Did you encounter this as well and manage to overcome it?,"At present, my primary focus is on creating a complete int8 model for the encoder, and I haven't attempted to convert the decoder yet. However, I will make an effort to do so when I have the opportunity and inform you of the results.","Thanks appreciate it, I will do the same if I make any progress. I have been trying to do basically the same as you are doing to get fully int8 model and I have found your posts across different github repos and they have been very useful in making progress!",Could you please refer the comment here for the similar issue where INT16 for Rsqrt is not yet supported.,I have yet to find support for rsqrt int16 on TFLM (TensorFlow Lite micro). Refer the below link for more details https://github.com/tensorflow/tflitemicro/blob/main/tensorflow/lite/micro/kernels/elementwise.ccL61 bool IsRsqrtSupportedType(const TfLiteType type) {   return type == kTfLiteFloat32  type == kTfLiteInt8; },"  I have generated int8 encoder and decoder TFLite models by converting a PyTorch model to ONNX, then from ONNX to TensorFlow, and finally from TensorFlow to TFLite. Unfortunately, the models are producing incorrect results. However, I am pleased to report that endtoend inference runs on these models. Please refer to the attached notebook for more details. https://colab.research.google.com/drive/1A0b_42wEiRrkmmZMLe9xtJUzBXfEy7Zb?usp=sharing"," I have managed to generate a partial Whisper encoder model using full int8 with only a few layers remaining in float, and I will share the resulting model sometime next week.",">  I have generated int8 encoder and decoder TFLite models by converting a PyTorch model to ONNX, then from ONNX to TensorFlow, and finally from TensorFlow to TFLite. Unfortunately, the models are producing incorrect results. However, I am pleased to report that endtoend inference runs on these models. Please refer to the attached notebook for more details. https://colab.research.google.com/drive/1A0b_42wEiRrkmmZMLe9xtJUzBXfEy7Zb?usp=sharing Yep I followed your notebooks and got the whole pipeline working correctly for fp32 tflite and dynamic int8 quantized models but like you not working for fully int8 quantized, they were really helpful thank you. Sounding promising if you have some more progress on the encoder model!",Excluded few ops from quantization and now quantized encoder model runs here  https://colab.research.google.com/gist/nyadlasys/cccc1a1594c2be85050d8e217e4a59fa/pytorch_to_tflite_int8_encoder_hybdrid_decoder.ipynb,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!",Are you satisfied with the resolution of your issue? Yes No
445,"以下是一个github上的tensorflow下的一个issue, 标题是(Updating lite-model-maker instructions)， 内容是 (Just updating litemodelmaker instructions to guide users to opt for second options  in case pip installation fails.  Trying to fix CC(tflite_model_maker0.4.2  Getting nightly for ever) as per suggestion from this comment)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,mohantym,Updating lite-model-maker instructions,Just updating litemodelmaker instructions to guide users to opt for second options  in case pip installation fails.  Trying to fix CC(tflite_model_maker0.4.2  Getting nightly for ever) as per suggestion from this comment,2023-01-31T13:11:26Z,comp:lite size:XS,closed,0,17,https://github.com/tensorflow/tensorflow/issues/59502,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Hi  Can you please review this PR ? Thank you!,Closing this PR due to associated issue  CC(tflite_model_maker0.4.2  Getting nightly for ever) has been closed. Thank you!
751,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite missing files on TFLITE_PROFILER_SRCS causes undefined reference error.)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 11 (bullseye)  Mobile device Debian GNU/Linux 11 (bullseye)  Python version 3.9.2  Bazel version 3.7.2  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Nvidia  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,turgut-baba,TFLite missing files on TFLITE_PROFILER_SRCS causes undefined reference error.,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution Debian GNU/Linux 11 (bullseye)  Mobile device Debian GNU/Linux 11 (bullseye)  Python version 3.9.2  Bazel version 3.7.2  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory Nvidia  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-31T12:05:49Z,stat:awaiting response type:build/install stale comp:lite TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59500,"Hi baba, This error occurs when the TFLite Profiler source files are missing from your project, causing a reference to undefined symbols. To resolve this error, ensure that you have included all necessary TFLite Profiler source files in your project and that they are properly linked in your build system. You can find the required source files in the TensorFlow Lite repository.",The issue with the `tflite::telemetry::TelemetryReportEvent` function is resolved by including the TensorFlow Lite telemetry source files in your build. This can be done by updating the `CMakeLists.txt` file in your project to include the relevant telemetry source files.,Let me know if helps you ?,"I did solved the problem before opening this issue, however shouldn't the `CMakeLİsts.txt` be updated by default in the repository? I haven't tried this on another computer but I think this can happen on other systems aswell, telementries should be put on there by default IMO. ",The` CMakeLists.txt` file in TensorFlow Lite is not updated by default. TensorFlow Lite is an opensource project and relies on contributions and pull requests from the community to keep the repository uptodate and address any issues,"Update: trying to run a project which I've compiled using the above solution causes me to get an error on runtime (again the steps I've followed to setup tflite is explained in details in my stackoverflow question, the accepted answer being the last step before running make.): `20230201 16:11:31.556438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory 20230201 16:11:31.556801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory 20230201 16:11:31.556829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. 20230201 16:11:33.720144: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error 20230201 16:11:33.720202: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: debian 20230201 16:11:33.720222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: debian 20230201 16:11:33.720339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.161.3 20230201 16:11:33.720387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.161.3 20230201 16:11:33.720407: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 470.161.3 usage: tflite_convert [h] output_file OUTPUT_FILE [saved_model_dir SAVED_MODEL_DIR | keras_model_file KERAS_MODEL_FILE] [saved_model_tag_set SAVED_MODEL_TAG_SET]                       [saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY] [enable_v1_converter] [experimental_new_converter [EXPERIMENTAL_NEW_CONVERTER]]                       [experimental_new_quantizer [EXPERIMENTAL_NEW_QUANTIZER]] tflite_convert: error: the following arguments are required: output_file`",Hi baba ! This issues is not replicating in Colab with 2.12 branch (Ubuntu 18)  and also BAZEL 5.3.0.  Will update after testing in Debian linux 11.  You mentioned Bazel 3.7.2 for your tests. Could you test with Bazel 5.3.0 and let us know.  ! Thanks for sharing your observation.  Do you suggest any PR. Thank you!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,It appears the never versions have fixed this issue. Thanks everyone who worked on fixing this.
1281,"以下是一个github上的tensorflow下的一个issue, 标题是(AttributeError: module 'tensorflow' has no attribute 'contrib')， 内容是 (Can anyone help me with this error? I have been trying to get this solved for a month. I think the code is outdated on the colab notebook and have no idea how to change the code to make it compatible for TF 2. Thanks if anyone can solve this  /usr/local/lib/python3.8/distpackages/gdown/cli.py:121: FutureWarning: Option `id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.   warnings.warn( Downloading... From: https://drive.google.com/uc?id=1qTdOAdKmMKeHZA1SXCAARBAdZXeSAN To: /content/merged.dict.txt 100% 7.94M/7.94M [00:00 in       49       50  initialize Tacotron2 with the pretrained model > 51 hparams = create_hparams() /content/tacotron2/hparams.py in create_hparams(hparams_string, verbose)       6     """"""Create model hyperparameters. Parse nondefault from given string.""""""       7  > 8     hparams = tf.contrib.training.HParams(       9               10          Experiment Parameters         AttributeError: module 'tensorflow' has no attribute 'contrib')请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Colabnoob,AttributeError: module 'tensorflow' has no attribute 'contrib',"Can anyone help me with this error? I have been trying to get this solved for a month. I think the code is outdated on the colab notebook and have no idea how to change the code to make it compatible for TF 2. Thanks if anyone can solve this  /usr/local/lib/python3.8/distpackages/gdown/cli.py:121: FutureWarning: Option `id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.   warnings.warn( Downloading... From: https://drive.google.com/uc?id=1qTdOAdKmMKeHZA1SXCAARBAdZXeSAN To: /content/merged.dict.txt 100% 7.94M/7.94M [00:00 in       49       50  initialize Tacotron2 with the pretrained model > 51 hparams = create_hparams() /content/tacotron2/hparams.py in create_hparams(hparams_string, verbose)       6     """"""Create model hyperparameters. Parse nondefault from given string.""""""       7  > 8     hparams = tf.contrib.training.HParams(       9               10          Experiment Parameters         AttributeError: module 'tensorflow' has no attribute 'contrib'",2023-01-28T00:48:36Z,stat:awaiting response comp:core TF 1.15,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59481,"Hi , We see that the issue template has not been filled, could you please do so as it helps us analyze the issue [tf version, steps followed before you ran into this error or stand alone code/colab gist] to reproduce the issue faced. Thanks! ","I filled out the template, i would really appreciate if you can solve this, i have been facing this problem for nearly two months. https://github.com/tensorflow/tensorflow/issues/59492issue1562342276","Hi , This seems to be a duplicate of  CC(AttributeError: module 'tensorflow' has no attribute 'contrib' ). This issue will be triaged on  CC(AttributeError: module 'tensorflow' has no attribute 'contrib' ) . Could you please close this issue? Thanks!"
697,"以下是一个github上的tensorflow下的一个issue, 标题是(Conditional padding issue with jit_compile=True)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.2  Custom Code Yes  OS Platform and Distribution Google Colab  Mobile device _No response_  Python version Google Colab  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shkarupa-alex,Conditional padding issue with jit_compile=True,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.2  Custom Code Yes  OS Platform and Distribution Google Colab  Mobile device _No response_  Python version Google Colab  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-27T13:53:28Z,stat:awaiting tensorflower type:bug comp:xla TF 2.11,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59474,"Hi,   Could you please look into this issue ? Thank you!","I tried the code provided by you and it works fine without jit_compile. However with `jit_compile=True` the code fails with the graph execution error as reported.Please refer to attached gist.  alex , The reason for the error might be due to the fact that present all TF Ops and Operations are not compilable with `jit_compile`. lambda variables not working as intended within tensorflow loops.For more details on this please refer this source.This might be the reason for the error. Hence I tried `autoclustering` by setting `tf.config.optimizer.set_jit(""autoclustering"" )`  and code executed fine. Please refer to attached gist with `autoclustering`. Auto clustering automatically enables `jit_compile=True` for those which are supported with `jit_compile` and ignores those if not supported.I Hope this may be of some help.As there is no error with auto_clustering means there are some operations not supported with `jit_compile=True`. The best way is use `autoclustering` or custom training loop with those operations that supports jit compilation kept under `.function(jit_compile=True)`. Thanks!",According to this doc https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/g3doc/gpu_supported_ops.md both Pad and Slice ops support XLA,Also i figured out that issue comes from slicing (second smart_cond in my example),"Hi alex, I did not face any error while using `jit_compile=True` in colab. please refer to this gist. Thank You.",Seems to be fixed since v2.14,Are you satisfied with the resolution of your issue? Yes No
1015,"以下是一个github上的tensorflow下的一个issue, 标题是(Extending tf.Tensor class)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution MacOS Ventura 13.0  Mobile device _No response_  Python version 3.10.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I want to extend the tf.Tensor class, but neither of the following options work: 1. option: extend tf.Tensor:  Fails with:  3. Option: extend EagerTensor  Fails with:  Our goal is to extend it though, we **don't** want to store the tf.tensor instance as an attribute of MyTFTensor, but instead extend the `tf.Tensor` class!  Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",gpt,anna-charlotte,Extending tf.Tensor class,"Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution MacOS Ventura 13.0  Mobile device _No response_  Python version 3.10.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? I want to extend the tf.Tensor class, but neither of the following options work: 1. option: extend tf.Tensor:  Fails with:  3. Option: extend EagerTensor  Fails with:  Our goal is to extend it though, we **don't** want to store the tf.tensor instance as an attribute of MyTFTensor, but instead extend the `tf.Tensor` class!  Standalone code to reproduce the issue   Relevant log output _No response_",2023-01-27T12:48:19Z,stat:awaiting response type:support stale comp:ops TF 2.11,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59472,"charlotte, It's generally not recommended to extend the `tf.Tensor` class, as it can lead to unexpected behavior and make your code harder to maintain. If you need to add custom functionality to a tensor, it's better to create a new class that takes a `tf.Tensor` as an input, rather than subclassing `tf.Tensor`.  For example:  This method allows you to add additional functionality to your tensors while still using the advantages of TensorFlow tensors. Please find the gist of working code here. Thank you!","Hi  thanks for the quick reply! Yes, that would be my back up option, but the subclassing would be my preferred option for our use case, even when considering the downsides : ) Do you know if this is somehow possible? ","fyi: our goal is to be able to pass `MyTensor` instances to some tensorflow model. Those instances should be handled just as tf.Tensors, hence why we would like to extend the class instead of storing a tf.Tensor as attribute to `MyTensor`. Do you have an idea on this?","We came across pytorch's `__torch_function__` and now I was wondering if there is an equivalent in tensorflow. This wouldn't fully solve my subclassing problem but could be part of the solution! For some context: `__torch_function__` is a method that allows all kinds of objects to be treated like torch.Tensors. For example if we call torch.stack([t1, t2, t3]) with t1, t2, t2 instances of `OurTensor` class, this will still work, as long as the class `OurTensor` implements the `__torch_function__()` to tell torch how to handle our tensors. ","I don't think subclassing a `tf.Tensor` is doable in Tensorflow with the existing design, since Tensorflow tensors are immutable. I would go with the suggestion mentioned here https://github.com/tensorflow/tensorflow/issues/59472issuecomment1408120513",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!",Are you satisfied with the resolution of your issue? Yes No
703,"以下是一个github上的tensorflow下的一个issue, 标题是(How to switch from TextLineDataset to Dataset.from_generator)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.9.0  Custom Code Yes  OS Platform and Distribution Mac OS X  Mobile device _No response_  Python version 3.7.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,jorispelemans,How to switch from TextLineDataset to Dataset.from_generator,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version tf 2.9.0  Custom Code Yes  OS Platform and Distribution Mac OS X  Mobile device _No response_  Python version 3.7.11  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-27T11:06:01Z,stat:awaiting response type:bug stale comp:ops TF 2.9,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59471," As per the documentation, the `generator` should not take any arguments if `args` is not specified. The fname can be passed as `args` for the generator. Please find the working gist here and let us know if it helps. Thank you.","Thanks, that worked!  I did notice that while `fname` is originally a string, depending on where you are it becomes a Tensor or a byte. Looks like, if you want to work with actual strings instead of bytes you have to decode them inside the generator:  Decoding the args in `tf.data.Dataset.from_generator` doesn't work, because here `fname` is a Tensor and seems like you can't actually get its value with `fname.numpy().decode()`: `AttributeError: 'Tensor' object has no attribute 'numpy'` Is this the best way of doing this?", Thanks for the information! You can also decode the args in `tf.data.Dataset.from_generator` using `tf.strings.uincode_decode`.  The `fname` tensor can be  decoded in the generator function or before passing it to the `Dataset.from_generator` . Please refer to the documentation here on decoding tensors. Thank you. ,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,Are you satisfied with the resolution of your issue? Yes No
1453,"以下是一个github上的tensorflow下的一个issue, 标题是(## cc)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,thai2551,## cc," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-01-27T04:10:24Z,stat:awaiting response invalid TFLiteConverter,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59468,"Hi ,  We see that the issue template has not been filled, could you please do so as it helps us analyze the issue [tf version, steps followed before you ran into an error and stand alone code/colab gist to reproduce the issue faced. Thanks!	","Closing spam issue (second time it happens, same person)"
1554,"以下是一个github上的tensorflow下的一个issue, 标题是('ValueError: Invalid model' at '_calibration_wrapper.AddIntermediateTensors(model_content)')， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04  TensorFlow installation (pip package or built from source): pip install   TensorFlow library (version, if pip package or github SHA, if built from source): 2.11  2. Description When I try to convert diffusion model into TFLite with **Integeronly**, I got the following error.  If I modify the 17th line of `main.py` to `model = DiffusionModelV2Test(img_height=height, img_width=width, max_text_length=77)`, it generates TFLite output without error. `DiffusionModelV2Test` is a model which I modified to make the model smaller. The original model contains 3 downsamplings and 3 upsamplings, but `DiffusionModelV2Test` only contains 1 for each. Also, when if I comment out from line 25 ~ 28, which makes the conversion to weightonly quantization, it generates TFLite without error as well. So, My question is why does this error occurs? And regarding the workaround with `DiffusionModelV2Test`, is there any limitation for the size of saved model when using calibration? FYI. The model I'm testing is diffusion model originally from kerascv. To make it convertable into TFLite, I only modified `keras.layers.Input` with `batch_size` specified as an argument.  3. Code reproducer gist)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,kkimmk,'ValueError: Invalid model' at '_calibration_wrapper.AddIntermediateTensors(model_content)'," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04  TensorFlow installation (pip package or built from source): pip install   TensorFlow library (version, if pip package or github SHA, if built from source): 2.11  2. Description When I try to convert diffusion model into TFLite with **Integeronly**, I got the following error.  If I modify the 17th line of `main.py` to `model = DiffusionModelV2Test(img_height=height, img_width=width, max_text_length=77)`, it generates TFLite output without error. `DiffusionModelV2Test` is a model which I modified to make the model smaller. The original model contains 3 downsamplings and 3 upsamplings, but `DiffusionModelV2Test` only contains 1 for each. Also, when if I comment out from line 25 ~ 28, which makes the conversion to weightonly quantization, it generates TFLite without error as well. So, My question is why does this error occurs? And regarding the workaround with `DiffusionModelV2Test`, is there any limitation for the size of saved model when using calibration? FYI. The model I'm testing is diffusion model originally from kerascv. To make it convertable into TFLite, I only modified `keras.layers.Input` with `batch_size` specified as an argument.  3. Code reproducer gist",2023-01-26T09:01:15Z,type:bug comp:lite TFLiteConverter TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59464,"Hi,   Could you please look into this issue ? Thank you!",Hi  ! Thanks for share your your observation on integer quantization of stablediffusion model.  Could you check the workaround which suggests to use dynamic range int8 quantization . Please provide a colab gist to help saving the replication time of this issue. Thank you!,"Hi , Thank you for your suggestion! First of all, I provided the reproducer gist at last of my first comment :) I tested dynamic range int8 quantization without problem, but unfortunately what I'm trying to do is integeronly quantization. Upon the workaround you've shared, which was very useful, I found out that TF model is first converted into TFLite model before applying quantization which caused the error due to the 2GB flatbuffer limitation.  And therefore, I guess the only solution for now is to split diffusion model into 2 chunks and convert them separately. Thank you for sharing the great workaround. As I understood all the situations, now closing the issue.",Are you satisfied with the resolution of your issue? Yes No
731,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to build 2.11 for ppc64le due to XNNPACK configurable attribute deps not matched)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Linux AlmaLinux 8  Mobile device _No response_  Python version 3.9  Bazel version 6.0.0  GCC/Compiler version 11.2.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,smuzaffar,Unable to build 2.11 for ppc64le due to XNNPACK configurable attribute deps not matched,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Linux AlmaLinux 8  Mobile device _No response_  Python version 3.9  Bazel version 6.0.0  GCC/Compiler version 11.2.1  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ``` ,2023-01-26T08:46:43Z,type:build/install,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59463,just to add that I am able to build `tensorflow 2.11.0` for `aarch64 and x86_64` with `gcc 11.2` on `AlmaLinux 8` it only fails for ppc64le,"According to https://github.com/google/XNNPACK/issues/4207, `ppc64le` is not supported by XNNPack and they have no plans to add the support so does this mean we can not build Tensorflow for ppc64le? Is there any way to disabled it for TF build? ",closing as it is duplicate of https://github.com/tensorflow/tensorflow/issues/58768,Are you satisfied with the resolution of your issue? Yes No
989,"以下是一个github上的tensorflow下的一个issue, 标题是(question about using tensorArray to do backpropagation)， 内容是 (I am confused about the tensorflow documentation here: https://www.tensorflow.org/api_docs/python/tf/TensorArray: Note that although the array can be read multiple times and positions can be overwritten, behavior may be undefined when storing multiple references to the same array and clear_after_read is False. In particular, avoid using methods like concat() to convert an intermediate TensorArray to a Tensor, then further modifying the TensorArray, particularly if you need to backprop through it later. This is from tensorflow 2.11 which isn't included in tensorflow 2.7. So I want to know if we really need an intermediate Tensorarray and then concatenate it to a tensor and then calculate loss and do backpropogation, which way is suggested?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,ximingwen,question about using tensorArray to do backpropagation,"I am confused about the tensorflow documentation here: https://www.tensorflow.org/api_docs/python/tf/TensorArray: Note that although the array can be read multiple times and positions can be overwritten, behavior may be undefined when storing multiple references to the same array and clear_after_read is False. In particular, avoid using methods like concat() to convert an intermediate TensorArray to a Tensor, then further modifying the TensorArray, particularly if you need to backprop through it later. This is from tensorflow 2.11 which isn't included in tensorflow 2.7. So I want to know if we really need an intermediate Tensorarray and then concatenate it to a tensor and then calculate loss and do backpropogation, which way is suggested?",2023-01-25T22:38:38Z,stat:awaiting response type:support stale comp:ops TF 2.11,closed,0,9,https://github.com/tensorflow/tensorflow/issues/59462,Assign this issue to me.,"Issue CC(question about using tensorArray to do backpropagation) The suggested approach would be to avoid using TensorArray and concatenating it to a Tensor, if you are using TensorFlow 2.7. Instead, you can use other TensorFlow operations to perform the same operations without the need for TensorArray. For example, you can use the tf.stack() function to concatenate multiple tensors along a given axis. You can also use the tf.data API to create a dataset and use the dataset to feed the data to the model. When it comes to calculate the loss, you can use the loss functions provided by TensorFlow such as tf.losses.mean_squared_error and tf.losses.categorical_crossentropy to calculate the loss and backpropagate through it. In summary, to avoid using TensorArray you can use the combination of tf.stack(), tf.data API and TensorFlow's loss functions to perform the same operations in TensorFlow 2.7.",I would like to work on this issue.," tf.TensorArray class is meant to be used with dynamic iteration primitives such as while_loop and map_fn. It supports gradient backpropagation via special ""flow"" control flow dependencies. There are some other APIs that can be used instead such as tf. stack() and tf.data in TF latest versions. Please let us know if it helps? Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"   >  tf.TensorArray class is meant to be used with dynamic iteration primitives such as while_loop and map_fn. It supports gradient backpropagation via special ""flow"" control flow dependencies. There are some other APIs that can be used instead such as tf. stack() and tf.data in TF latest versions. Please let us know if it helps? Thank you! > Issue CC(question about using tensorArray to do backpropagation) >  > The suggested approach would be to avoid using TensorArray and concatenating it to a Tensor, if you are using TensorFlow 2.7. Instead, you can use other TensorFlow operations to perform the same operations without the need for TensorArray. >  > For example, you can use the tf.stack() function to concatenate multiple tensors along a given axis. You can also use the tf.data API to create a dataset and use the dataset to feed the data to the model. >  > When it comes to calculate the loss, you can use the loss functions provided by TensorFlow such as tf.losses.mean_squared_error and tf.losses.categorical_crossentropy to calculate the loss and backpropagate through it. >  > In summary, to avoid using TensorArray you can use the combination of tf.stack(), tf.data API and TensorFlow's loss functions to perform the same operations in TensorFlow 2.7. Hi, Thank you very much for the reply. However, when training Tensorflow use strategy, it is suggested that we wrap the strategy.run under tf.function. In this way,  it is also suggested that not replying on python's side effect like appending. Then if I really need to do something like tf.stack(list), which list needs to generate dynamically for each call, which way should be the best way to go?","Hi  , You can define a Tensor Array(eg. `ta`) with `dynamic_size=True` and then you can use `ta.write(index, value, name=None)` method to write data(value) at particular index. Once write has been completed you can use `ta.stack()` at end to convert into single Tensor. I have tested a minimal function with sample code and decorated with` tf.function` and attached gist here for reference. Please go through and confirm if this is of some help. Thanks !",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
749,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLite performance breakdown on GAN models seems inaccurate (using TFLite benchmarking tool))， 内容是 (Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version TF2.7  Custom Code No  OS Platform and Distribution Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version 3.7.2  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,judeharis,TFLite performance breakdown on GAN models seems inaccurate (using TFLite benchmarking tool),Click to expand!    Issue Type Others  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version TF2.7  Custom Code No  OS Platform and Distribution Ubuntu 18.04  Mobile device _No response_  Python version _No response_  Bazel version 3.7.2  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-01-25T16:19:53Z,stat:awaiting response stale comp:lite type:performance TF 2.7,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59456,"Hi   It's possible that the performance breakdown provided by TFLite's benchmarking tool for GAN models may not be entirely accurate. This can occur due to a variety of factors, such as the complexity of the model, the size of the inputs, and the hardware being used. To obtain a more accurate performance measurement, you may want to consider using alternative benchmarking methods or profiling tools, or finetuning the model to optimize its performance for TFLite. Additionally, you can also try running the model on different hardware platforms to see if the results vary.","In order to obtain a more accurate performance measurement, you can try the following steps: 1) Increase the number of runs in the benchmarking tool to get more consistent results. 2) Finetune the models to optimize their performance for TFLite, including pruning, quantization, and other techniques. 3) Try running the models on different hardware platforms, such as a mobile device, to see if the results vary. 4) Consider using alternative benchmarking methods or profiling tools, such as the TensorFlow Model Analysis library or TensorFlow Profiler.",Let me know if it helps ? ,"Hi  ! Sorry for the late response. I I agree with  's pointer on model's performance (Inference timing, latency etc) w.r.to the hardware, input shape , availability of GPU delegate, supported ops etc. We can do a comparative analysis of ""TRANSPOSE_CONV"" layers on Tensorboard profiler tool against the benchmarking results of lite model against different delegates, no of threads etc. to validate this difference. Attached Benchmarking documentation for detailed usage.  Can you confirm any improvement in newer versions 2.10, 2.11 too. Please post on TFForum for further assistance.  Thank you!","Thanks for the responses. My current plan of action is as   suggested point (4) . Running other GAN based models with Tensorflow profiler on and I have seen around 4050% of latency for ""Conv2DBackpropInput"", this is range makes more sense. Funny thing is the profiler treats the Conv2DTranspose as ""Conv2DBackpropInput"", I assume internally CONV2D, CONV2DT and ""Conv2DBackpropInput"" is very similar.  Just to confirm I am doing things correctly for profiler using Tensorboard profiler tool I am simply using the code as follows: `tf.profiler.experimental.start('logdir') for i in range(100):     generated_image = generator(noise, training=False)     decision = discriminator(generated_image) tf.profiler.experimental.stop()` This code should profile the inference for both the generative and discriminator models of the GAN? Additionally I will looking to updating to 2.10+ to see if I will get different results.",Ok  ! Thanks for the update .  Please post your  benchmarking results after testing in 2.7/2.10/2.11 version if you are still seeing  same behavior.  You can report also post this in TFForum (dedicated for machine learning support queries) for faster resolution. Thank you!,"Hi all, I used the TFLite model found here: https://tfhub.dev/captainpool/litemodel/esrgantf2/1 I used the nightly branch to build the benchmark_model executable with the same options posted originally:  and here are the current results:  csv for more info test.csv","Hi , it seems like the key is to remove the TRANSPOSE_CONV layer entirely ... joking, I think it's represented here as Convolution (NHWC F32) IGEMM and Deconvolution (NHWC F32) Subconv2D, but I think your original question still stands. I don't really see it as erroneous as while the Transposed Convolution looks more complicated than a regular convolution, I would be surprised if it took exponentially more time if optimized correctly (I would expect it to be on the same order of magnitude close to a regular convolution with the same input size). It could be that previous papers used nonoptimal or outdated frameworks that performed those layers inefficiently, do you know what papers you originally were referring to? For now I would assume that the results are accurate, as I don't see why they wouldn't be from the current evidence presented.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1015,"以下是一个github上的tensorflow下的一个issue, 标题是(Val loss is very different from training loss when measured on the same data)， 内容是 ( Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0dev20221213  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 18.04  Python version 3.7, 3.9  Current Behaviour? When finetuning a Keras Applications model on MNIST, and using the same data for training and validation (for debugging), the validation loss is much higher than the training loss. P.S.: I don't believe overfitting is relevant because the training and validation data are the same. I know certain layers like Dropout and BatchNormalization have different behavior during training and validation, but the difference seems too large for this to account for it.  Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,jackgle,Val loss is very different from training loss when measured on the same data," Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.12.0dev20221213  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 18.04  Python version 3.7, 3.9  Current Behaviour? When finetuning a Keras Applications model on MNIST, and using the same data for training and validation (for debugging), the validation loss is much higher than the training loss. P.S.: I don't believe overfitting is relevant because the training and validation data are the same. I know certain layers like Dropout and BatchNormalization have different behavior during training and validation, but the difference seems too large for this to account for it.  Standalone code to reproduce the issue   Relevant log output  ",2023-01-25T05:16:35Z,type:bug comp:keras TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59454,"Storing the model weights each epoch, and computing the loss manually for each of them afterwards produces scores equal to what is shown for the `val_loss`. So it is unclear how the training loss is getting so low.","`x = conv(inputs, training=False)` makes the losses approximately equal. As explained here: https://keras.io/guides/transfer_learning/  > When you unfreeze a model that contains BatchNormalization layers in order to do finetuning, you should keep the BatchNormalization layers in inference mode by passing training=False when calling the base model. Otherwise the updates applied to the nontrainable weights will suddenly destroy what the model has learned.",Are you satisfied with the resolution of your issue? Yes No
692,"以下是一个github上的tensorflow下的一个issue, 标题是(Crash when running tf.keras.backend.eye)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Crash when running tf.keras.backend.eye,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-01-25T03:08:14Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59440,"Hi,   Apologize for the delay and I was able to replicate the issue on Google Colab, Here is gist file and code is getting crashed so I'll dig more into this issue and I'll update here soon about this issue  For your reference I have added screenshot of error log below, Thank you! !image I was able to replicate the issue on `Ubuntu 22.04` with `Tensorflow==2.10` and I have added screenshot below : !image Here is screenshot for `Tensorflow==2.11 ` execution : !image Here is screenshot for `tfnightly'2.13.0dev20230208` !image","Please post code snippet and error directly on the issue, not via a link. The link might become stale, searching for the error will not uncover it",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Not actionable, closing. Please report using the right channels.",Are you satisfied with the resolution of your issue? Yes No,"The colab refers to a pickle while which appears to be unavailable. Could you make a self contained reproducer, e.g. by constructing the **data argument directly in the colab? Thanks!",(that's the reason I closed this as not actionable)," , Could you please find the attached gist here with the reported error message. Thanks!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
616,"以下是一个github上的tensorflow下的一个issue, 标题是(Can't convert custom model to tflite with model config and weights file being separate)， 内容是 (Hi, I am trying to convert a custom model to tflite with these steps:  I do not get any output on this, no errors as well. The question is  is it possible to convert my custom model with creating the model (without saving it) and then loading the weights the way I have done? Is there any other way how to make my model smaller after training?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,codingzebra333,Can't convert custom model to tflite with model config and weights file being separate,"Hi, I am trying to convert a custom model to tflite with these steps:  I do not get any output on this, no errors as well. The question is  is it possible to convert my custom model with creating the model (without saving it) and then loading the weights the way I have done? Is there any other way how to make my model smaller after training?",2023-01-24T11:47:23Z,stat:awaiting response type:support comp:lite TFLiteConverter,closed,0,16,https://github.com/tensorflow/tensorflow/issues/59431,  Could you please provide complete code or Colab gist to replicate the issue reported here ? Thank you!,"Hey, here is the colab file  https://colab.research.google.com/drive/13KYqJWwNQju0APaqEaZj39wYodN0Uu8?usp=sharing  Thank you! ","Hi  , When I try to execute the given code on Colab using TF v2.11, I get the following error: `OperatorNotAllowedInGraphError: Exception encountered when calling layer 'tri_q_image_quality_transformer' (type TriQImageQualityTransformer).Using a symbolic tf.Tensor as a Python bool is not allowed: AutoGraph is disabled in this function. Try decorating it directly with .function.` As per above error decorate the `call` function with .function in transformer_iqa.py file, I was able to convert the model to tflite model without any error. Could you please find the gist here for reference.  Thank you!",  This is the transformer_iqa.py file where I add the .function at 168th line before the `call` function. Could you please refer to the screenshot amd let us know if it helps . Thank you !,"It works, thank you! I wanted to ask  how to properly load .tflite file for evaluation? I want to compare both weights files for accuracy.","  You can evaluate the tflite model by using `model.evaluate_tflite('model.tflite', test_data)`. Please refer to this doc. Could you please close the issue if it resolves? Thank you!","Hey, using your suggested evaluation, I got an error: AttributeError: 'Functional' object has no attribute 'evaluate_tflite'. Supposedly, the issue is that the method I am trying to use is not present on the TFLite model class. But I have no idea how to fix it. Would really appreciate your help with this. Thank you in advance!", Could you please give a sample code to reproduce the issue ? Thank you!,"Hey, here is the sample code. ",  Could you please provide an accessible code to replicate the issue ? Thank you!,You should be able to access it now!,"Hey, I tried different approach and got ValueError: Could not open tflite model. Here is the code: https://colab.research.google.com/drive/14zMCm0XaszVrUoWd9bMvBjSXSdPvSWuwscrollTo=o3lYXU2CwMoG","Hey, is it possible to get some insights regarding this issue? I even tried a different approach how to convert the model to tflite and I still can't evaluate the accuracy. I also provided both ways how I converted my .h5 file to .tflite in tha colab file.",  This issue is similar to CC(tflite model has bad accuracy) . This issue will triage on CC(tflite model has bad accuracy) . Could you please feel free to close this issue? Thank you! ,Are you satisfied with the resolution of your issue? Yes No,Are you satisfied with the resolution of your issue? Yes No
1888,"以下是一个github上的tensorflow下的一个issue, 标题是(Unknown crash when running tensorflow.python.ops.gen_nn_ops.max_pool)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 17:52:34.603243: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 17:52:34.697556: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230122 17:52:35.114243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/tf2.10/lib/ 20230122 17:52:35.114398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimas)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Unknown crash when running tensorflow.python.ops.gen_nn_ops.max_pool,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 17:52:34.603243: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 17:52:34.697556: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230122 17:52:35.114243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/tf2.10/lib/ 20230122 17:52:35.114398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimas",2023-01-22T22:54:50Z,type:bug comp:apis comp:ops TF 2.10,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59414,"Hi,   Apologize for the delay and I was able to replicate the issue without any error when I'm passing correct values to arguments and for your reference I have added gistfile, It seems like you're passing negative value to the kernel/filter/window size and we cannot perform max pooling as you would get a zero or negative dimensions and I think this is the limitation of Max Pooling  You can refer our official documentation and sourcecode for High level API `tf.nn.max_pool` I have replicated on `Ubuntu 22.04` with `Tensorflow==2.10` and it's working as expected when I'm passing correct arguments with correct values, For your reference I have added screenshot below.  !image If issue still persists please let us know? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!","> Hi,  >  > Apologize for the delay and I was able to replicate the issue without any error when I'm passing correct values to arguments and for your reference I have added gistfile, It seems like you're passing negative value to the kernel/filter/window size and we cannot perform max pooling as you would get a zero or negative dimensions and I think this is the limitation of Max Pooling >  > You can refer our official documentation and sourcecode for High level API `tf.nn.max_pool` >  > I have replicated on `Ubuntu 22.04` with `Tensorflow==2.10` and it's working as expected when I'm passing correct arguments with correct values, For your reference I have added screenshot below. >  > !image >  > If issue still persists please let us know? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you! Hi, thanks for the reply. If we pass correct values, obviously we wouldn't get any error. I am running a fuzzer on TF APIs (the test cases are machine generated), so I am looking for corner cases. Would you please run my test case?","Hi,   I was able to replicate the issue with your exact same input on `Ubuntu==22.04` with `Tensorflow==2.10` and it's giving me same error message which you're getting because as I mentioned earlier it's due to negative value to the kernel/filter/window size and we cannot perform max pooling as you would get a zero or negative dimensions and this is the limitation of Max Pooling and you can refer Stackoverflow Answer  which will help you to understand the limitations of Max Pooling I have added screenshot for your reference below  !image If issue still persists please let us know? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Was this tested against nightly?,"Hi,   Apologize for the delay and I did not test user code with tfnightly previously but now I have tested same user code on `Ubuntu 22.04` multiple times with `tfnightly2.13.0dev20230206` and even I tested same user code on Google Colab, here is gist file and I have added screenshot below. It seems like it's giving expected behaviour. Thank you! !image",Closing as resolved,Are you satisfied with the resolution of your issue? Yes No
1839,"以下是一个github上的tensorflow下的一个issue, 标题是(Crash when running )， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 11:22:43.127824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 11:22:43.643039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 11:22:43.643196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 11:22:43.643203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Crash when running ,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 11:22:43.127824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 11:22:43.643039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 11:22:43.643196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 11:22:43.643203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If",2023-01-22T16:24:29Z,type:bug comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59403,", could you please look at this issue?  The above code is crashing the kernel in Colab(GPU). Please find the gist  here.  It is working when the `ksize` attribute is >0. Thank you!","I tried the code on Tf2.11v and got `Check fail` followed by `Aborted (core dumped)`. Please refer attached log below.  With tfnightly(2.12.0dev20230201) I got different Error related to DNN library version which is specific to this issue only may be because of the API used in this case.May please refer to attached log below.   , AFAIK chek fails may not be considered as vulnerability issue and we will let you know the same.However the check fail may needs fix for better error info. Thanks!",Fixed,Are you satisfied with the resolution of your issue? Yes No
756,"以下是一个github上的tensorflow下的一个issue, 标题是(Checkpointing simple from_generator dataset iterator gives ""PyFunc is stateful"" error.)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue ```shell def count():   i = 0   while i )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,hamzamerzic,"Checkpointing simple from_generator dataset iterator gives ""PyFunc is stateful"" error.",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.12.0  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue ```shell def count():   i = 0   while i ,2023-01-22T15:36:06Z,stat:awaiting response type:bug stale comp:apis comp:data TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59398,I was able to reproduce the issue in TF 2.11 and TF Nightly 2.12.0dev20230123. Please find the gist here. Thank you.,"`from_generator` datasets are not checkpointable due to their dependency on a Python runtime. That being said, it would be good to improve the error message to something clearer.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1888,"以下是一个github上的tensorflow下的一个issue, 标题是(Segfault when running tensorflow.python.ops.string_ops.string_format)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 05:35:08.288147: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 05:35:08.826735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 05:35:08.826898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 05:35:08.826905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Segfault when running tensorflow.python.ops.string_ops.string_format,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 05:35:08.288147: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 05:35:08.826735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 05:35:08.826898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 05:35:08.826905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If",2023-01-22T10:37:26Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59395,"Hi , The above code is working without segfault in the tfnighly. Kinfly refer to this gist. The error persists in TF v2.11 and it could be due to the lowlevel API. Please try the same with the high level API `tf.strings.format`. I was able to execute the given code snippet without any errors with the high level API `tf.strings.format` in Colab using TF v2.11. Please refer to this gist and let us know if it helps. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as fixed,Are you satisfied with the resolution of your issue? Yes No
1911,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation fault when running tensorflow.python.ops.gen_sparse_ops.sparse_fill_empty_rows)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 04:57:38.410770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 04:57:39.683814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:57:39.684083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:57:39.684094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Segmentation fault when running tensorflow.python.ops.gen_sparse_ops.sparse_fill_empty_rows,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 04:57:38.410770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 04:57:39.683814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:57:39.684083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:57:39.684094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If",2023-01-22T10:01:39Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59393,"Hi,   Could you please look into this issue ? Thank you!","I have tried the code on a VM with Ubuntu 22.04 OS, executed it multiple times and got `Segmentation fault (core dumped)` error some times or `Invalid argument error` other times with random ve number.  Please refer to below log.  , Thanks for reporting this. It may needs investigation.",toplay ,"Hi, This issue has been addressed to check the shape of indices matches the shape of dense_shape in `sparse_fill_empty_rows` op. The changes made in the file below and the test file added here. https://github.com/tensorflow/tensorflow/blob/a6866df48e1aba0996bd99565fa76e79e1875915/tensorflow/core/kernels/sparse_fill_empty_rows_op.ccL241L247 Attached the gist here with the expected error message. Thanks!",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1908,"以下是一个github上的tensorflow下的一个issue, 标题是(Error when running tensorflow.python.keras.layers.dense_attention._lower_triangular_mask)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 04:45:46.895374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 04:45:48.013379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:45:48.013574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:45:48.013581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Error when running tensorflow.python.keras.layers.dense_attention._lower_triangular_mask,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230122 04:45:46.895374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230122 04:45:48.013379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:45:48.013574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230122 04:45:48.013581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If",2023-01-22T09:49:05Z,type:bug comp:ops TF 2.11,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59392,Not a vuln,Are you satisfied with the resolution of your issue? Yes No
1462,"以下是一个github上的tensorflow下的一个issue, 标题是(TFLiteConverter adds (de)quantization blocks before and after operations on a weight variable)， 内容是 (Hello I'm trying to convert a TensorFlow model to TFLite. I want the model to maintain a nontrainable state vector that gets updated at every inference. I've implemented this using `self.add_weight` with `trainable=False`, as shown in the example.  1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux KDE Neon 5.26  TensorFlow installation (pip package or built from source): pip installation  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0  2. Code   3. Conversion Issue The conversion process works fine, but when I draw the model on Netron, it seems that the converter adds quantize/dequantize operations everytime the variable is read or updated. Is there a way to tell the converter to quantize this variable from the start, without having to quantize and dequantize everytime it accesses it? !model On another note, my aim is to run such a model on an EdgeTPU, but the EdgeTPU compiler complains about dynamicsized tensors, without indicating where they are. I believe the culprits are CallOnce, ReadVariable and/or AssignVariable, but I'm not entirely sure how to get around them. Any ideas? Thanks.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MalekItani,TFLiteConverter adds (de)quantization blocks before and after operations on a weight variable,"Hello I'm trying to convert a TensorFlow model to TFLite. I want the model to maintain a nontrainable state vector that gets updated at every inference. I've implemented this using `self.add_weight` with `trainable=False`, as shown in the example.  1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux KDE Neon 5.26  TensorFlow installation (pip package or built from source): pip installation  TensorFlow library (version, if pip package or github SHA, if built from source): 2.11.0  2. Code   3. Conversion Issue The conversion process works fine, but when I draw the model on Netron, it seems that the converter adds quantize/dequantize operations everytime the variable is read or updated. Is there a way to tell the converter to quantize this variable from the start, without having to quantize and dequantize everytime it accesses it? !model On another note, my aim is to run such a model on an EdgeTPU, but the EdgeTPU compiler complains about dynamicsized tensors, without indicating where they are. I believe the culprits are CallOnce, ReadVariable and/or AssignVariable, but I'm not entirely sure how to get around them. Any ideas? Thanks.",2023-01-22T01:44:56Z,stat:awaiting response type:support comp:lite comp:micro TFLiteConverter ModelOptimizationToolkit TF 2.11,closed,0,16,https://github.com/tensorflow/tensorflow/issues/59390,I was able to reproduce this issue in TF 2.11. Please find the gist here.   can you please check this issue. Thanks.,"Ok  ! We can tfmot api to decide quantization for the layers  for which quantization need to be disabled/enabled. We can also tfl.quantization_debugger to disable quantization for suspected layers. Regarding Dynamic size Tensor issue in Edge TPU , Could you test with  below workarounds and let us know.  Yield representative dataset dtype as np.int8  Thank you!","Thanks for the help. I'm not entirely sure I understand what you mean. I don't want to selectively enable/disable quantization. I want the converter to properly quantize all the weights and biases, including the one I've added. From what I understand, TFLiteConverter seems to do this well for other weights (kernel weights in Conv layers, for example), but it strangely doesn't seem to quantize ""MyWeight"" and instead needs explicit blocks to do it. Is this supposed to happen? Is it specifically because I'm updating the variable? Also, even if I try to use , I get , which I'm afraid means I can't quantize the model (using tfmot) as is without rewriting it in one of those two formats. Is that it? Additionally, the workaround you suggested for EdgeTPU gives .",Ok  ! Thanks for the update . Yeah! all the nodes appearing in lite model are decided by TFLite Converter api as you said.  I will update once If i get any working solution from closed issues of EdgeTPU repo.  Would it be possible to route this issue to EdgeTPU repo /TFForum then. Thank you!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"I opened this discussion on the TensorFlow forum. It doesn't seem to be getting any attention.  Do you know if the behavior I'm getting is expected? If so, how can I fix it?",Still looking for assistance. Any ideas?,"Hi  Looking at your code, I think this is expected behaviour. The input and weight to the graph are both float32, and since every time after the execution, you're writing the results back to ""My_weight"" we have to do the dequant and quant to ensure the datatype and value are still valid.   If you didn't need to write back to the weight, I would recommend you use tf.const instead for weight. Please let us know this is a valid fix for you","That is true, I need to write back to the weight after execution. However, I don't see how the input and weights (besides ""my_weight"") are float32 for the following reasons: 1. I provide a representative dataset to TFLiteConverter, so I expect the converter to perform full integer quantization. 2. I set inference input/output types to np.int8, so the model expects integer input/output. 3. The model does quantization after the read, and dequantization after the operation on the input data. So, if anything, it is the variable ""my_weight"" that is stored as float32. Is this line of reasoning correct? Am I missing a particular option to allow ""my_weight"" to be stored as a np.int8?","1 is correct, for 2, there are some complexities, the original model in keras is taking float32 as input & output, as such ""my_weight"" has to be float32 to enable the correct execution in keras. as such, when we go to 3, it has to be treated as float even in the quantized execution, because how the variable tensor is initialized.  My understanding is that if you enforce ""my_weight"" as a int8, then it's no longer a valid graph in keras.",The dynamic tensor probably comes from VarHandle. This was fixed here. Either wait for TF 2.12 to come out or compile TFLite yourself and the dynamic tensor should go away.,"Thank you wei, now I understand the issue. With typical model weights (i.e. convolution layer weights), this problem doesn't appear, so I'm guessing the converter can successfully map them to int8 constants even though they were initialized as float32 in keras. This leads me to believe that the weight value assignment prevents the converter from initializing the weight as int8. Is there currently any way of maintaining a quantized, writeable state at all, without having to pass the state as input? For example, can the converter produce quantized, stateful LSTMs? If so, how does it maintain this quantized state? VarHandle does seem to be the issue . Thank you very much!","Hi , it seems we never closed the loop on this issue  are you satisfied w/ the above resolution? Thanks.","I never really found a solution to this, but it is no longer a relevant problem to me.",Are you satisfied with the resolution of your issue? Yes No,"For anyone else still running into this issue, I was able to solve it by enabling experimental variable quantization: "
1918,"以下是一个github上的tensorflow下的一个issue, 标题是(Memory exhaustion when running tensorflow.python.ops.stateless_random_ops.stateless_random_uniform)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 20:25:00.797918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 20:25:01.510771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230121 20:25:01.510967: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230121 20:25:01.510976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Memory exhaustion when running tensorflow.python.ops.stateless_random_ops.stateless_random_uniform,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 20:25:00.797918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 20:25:01.510771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230121 20:25:01.510967: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/:/home/nimashiri/anaconda3/envs/cuda11.2/lib/ 20230121 20:25:01.510976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If",2023-01-22T01:27:17Z,stat:awaiting response type:bug comp:ops TF 2.11,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59389,"Hi,   Apologize for the delay and I was able to replicate the issue on google colab and luckily it got executed successfully on both CPU and GPU, for your reference I have added gistfile and it seems like due to lack of  memory allocation code hasn't completed successfully because you're passing input as very large number and even in your error log it's clearly saying the reason out of memory (OOM)`OOM when allocating tensor with shape[1570089097] and type int32 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:StatelessRandomUniformIntV2]` When first time I executed code, I got the same error like you, I have added error log screenshot below and if you reduce the input size, code should work as expected  You can refer this comment also  !image I have also tested the same code on `Ubuntu 22.04` with `Tensorflow==2.11 (GPU)` and I executed the same code multiple times, I was getting error message `""20230201 14:08:43.417725: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 6280356388 exceeds 10% of free system memory. ""` I have attached screenshot for your reference below,  !image If issue still persists please let us know ? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!",Not a vuln,Are you satisfied with the resolution of your issue? Yes No
1334,"以下是一个github上的tensorflow下的一个issue, 标题是(CMake build of stand-alone mlir-hlo MLIRHLOPythonModules target is broken)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04.3   Mobile device _No response_  Python version 3.8  Bazel version not using bazel  GCC/Compiler version 10.0  CUDA/cuDNN version N/A  GPU model and memory N/A  Current Behaviour?  shell To reproduce, configure and build LLVM (sha de3f0f7fa0c7b902dde840913db7e773a02c4173) with the following (the mlirhlo repository is cloned in `$REPO_ROOT`): cd llvmproject && mkdir build && cd build cmake G Ninja ../llvm \                 DLLVM_ENABLE_PROJECTS=mlir \                 DLLVM_EXTERNAL_PROJECTS=""mlirhlo"" \                 DLLVM_EXTERNAL_MLIR_HLO_SOURCE_DIR=$REPO_ROOT/mlirhlo \                 DCMAKE_BUILD_TYPE=RelWithDebInfo \                 DLLVM_ENABLE_ASSERTIONS=ON \                 DLLVM_TARGETS_TO_BUILD=""X86"" \                 DMLIR_ENABLE_BINDINGS_PYTHON=ON \                 DMHLO_ENABLE_BINDINGS_PYTHON=ON  cmake build . t MLIRHLOPythonModules   Relevant log output  ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,brnorris03,CMake build of stand-alone mlir-hlo MLIRHLOPythonModules target is broken,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.12  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04.3   Mobile device _No response_  Python version 3.8  Bazel version not using bazel  GCC/Compiler version 10.0  CUDA/cuDNN version N/A  GPU model and memory N/A  Current Behaviour?  shell To reproduce, configure and build LLVM (sha de3f0f7fa0c7b902dde840913db7e773a02c4173) with the following (the mlirhlo repository is cloned in `$REPO_ROOT`): cd llvmproject && mkdir build && cd build cmake G Ninja ../llvm \                 DLLVM_ENABLE_PROJECTS=mlir \                 DLLVM_EXTERNAL_PROJECTS=""mlirhlo"" \                 DLLVM_EXTERNAL_MLIR_HLO_SOURCE_DIR=$REPO_ROOT/mlirhlo \                 DCMAKE_BUILD_TYPE=RelWithDebInfo \                 DLLVM_ENABLE_ASSERTIONS=ON \                 DLLVM_TARGETS_TO_BUILD=""X86"" \                 DMLIR_ENABLE_BINDINGS_PYTHON=ON \                 DMHLO_ENABLE_BINDINGS_PYTHON=ON  cmake build . t MLIRHLOPythonModules   Relevant log output  ``` ",2023-01-21T21:54:21Z,stat:awaiting response type:bug type:build/install stale subtype: ubuntu/linux,closed,1,5,https://github.com/tensorflow/tensorflow/issues/59379," ! Thanks for sharing your observation on ""mlirhlo MLIRHLOPythonModules target""   ! Could you look at this issue. Thank you!","I believe this should be addressed in the fix here https://github.com/tensorflow/mlirhlo/commit/59a25983b6dff1cb656a564b4a2a25ff481b966e which removes the dependency of `MLIRGmlStTilingInterfaceIncGen`, !image could you please try with the nightly version and let us know if you still face an error. Thanks!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1912,"以下是一个github上的tensorflow下的一个issue, 标题是(free(): invalid pointer when running tensorflow.python.ops.gen_ragged_array_ops.ragged_cross)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 13:53:18.602619: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:53:18.736809: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:53:19.358808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:53:19.359009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:53:19.359018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you w)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,free(): invalid pointer when running tensorflow.python.ops.gen_ragged_array_ops.ragged_cross,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 13:53:18.602619: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:53:18.736809: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:53:19.358808: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:53:19.359009: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:53:19.359018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you w",2023-01-21T19:01:32Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,9,https://github.com/tensorflow/tensorflow/issues/59368,", **tf.random.uniform** Outputs random values from a uniform distribution and also it was suggested that the invalid inputs for the minval will lead to the custom error. **minval**  A Tensor or Python value of type dtype, broadcastable with shape (for integer types, broadcasting is not supported, so it needs to be a scalar). The lower bound on the range of random values to generate (inclusive). Defaults to 0. Also please find the gist of it here where we get the output when using +ve and error on ve inputs which was expected. Thank you! "," I am running fuzz testing, so malicious inputs are machine generated. Would you please run my provided test case and confirm whether you encounter crash?",", When I was trying to run `tensorflow.python.ops.gen_ragged_array_ops.ragged_cross` with the **hash_key = 956888297470** it was failing with the error and colab was also crashed. But when I tried to execute on tfnightly with the same hash_key, it was executed without any issue/error/colab crash. Kindly find the gist of it here. !image Thank you!","This is a vulnerability that needs fixing.  Given that this is a vulnerability, don't be too eager to close it (by adding the label).  please stop posting vulns on GitHub. Please consult SECURITY.md for how to properly and ethically disclose them.",I have tested the user code on Ubuntu22 VM with Tf2.10v and got the below Error log.Similar behaviour observed with TF2.12v also.  **With TF2.10V:**  **With TF2.12v:**  Thanks!,"Nice, this shows that this vuln existed for at least 3 versions of TF","Hi, The issue has been fixed by the commit here https://github.com/tensorflow/tensorflow/commit/bbbe095a3ae243d10752ca16b914a8fa11221d07. Now it is throwing the proper error message, please find the attached gist here for reference.",This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1896,"以下是一个github上的tensorflow下的一个issue, 标题是(Runtime error when running tensorflow.python.ops.gen_math_ops.dense_bincount)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 13:50:38.486445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:50:38.623931: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:50:39.187573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:50:39.187768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:50:39.187777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you w)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Runtime error when running tensorflow.python.ops.gen_math_ops.dense_bincount,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 13:50:38.486445: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:50:38.623931: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:50:39.187573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:50:39.187768: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:50:39.187777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you w",2023-01-21T18:52:04Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59367,"Hi  , the input tensor must be either 1D or 2D. You are trying to pass uint64 tensor to the API which is not supported. It supports int32 and int64. Also, the size attribute should be a nonnegative integer. Kindly refer to DenseBincount API. Please find the gist of working code here. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.," vulnerabilities occur when invalid arguments are being sent to APIs. So your reply here is wrong.  this is not a vulnerability, you're receiving a user error. Please consult SECURITY.md before sending new reports as very few of them are really actionable (and they should have been submitted via private channels)",Are you satisfied with the resolution of your issue? Yes No
1897,"以下是一个github上的tensorflow下的一个issue, 标题是(Runtime error when running tensorflow.python.ops.gen_math_ops.ragged_bincount)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 13:48:15.238976: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:48:15.525093: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:48:16.279948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:48:16.280110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:48:16.280118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you w)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Runtime error when running tensorflow.python.ops.gen_math_ops.ragged_bincount,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230121 13:48:15.238976: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:48:15.525093: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:48:16.279948: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:48:16.280110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:48:16.280118: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you w",2023-01-21T18:49:48Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59366," As this comment suggests, the invalid inputs will lead to the custom error.  The documentation requires `size` to be a non negative int and conversion to `tf.uint64` from `tf.int64` can lead to the error. Please refer the documentation for valid inputs. Thanks. ",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"  vulnerabilities occur when invalid arguments are being sent to APIs. So your reply here is wrong.  this is not a vulnerability, you're receiving a user error. Please consult SECURITY.md before sending new reports as very few of them are really actionable (and they should have been submitted via private channels)",Are you satisfied with the resolution of your issue? Yes No
1906,"以下是一个github上的tensorflow下的一个issue, 标题是(Process get killed when running tensorflow.python.ops.ragged.ragged_util.repeat_ranges)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 0230121 13:32:07.162645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:32:07.274542: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:32:07.900834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:32:07.901030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:32:07.901038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you wo)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Process get killed when running tensorflow.python.ops.ragged.ragged_util.repeat_ranges,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 0230121 13:32:07.162645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230121 13:32:07.274542: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered 20230121 13:32:07.900834: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:32:07.901030: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/lib/ 20230121 13:32:07.901038: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TFTRT Warning: Cannot dlopen some TensorRT libraries. If you wo",2023-01-21T18:34:10Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59362," Too large values can lead to the memory errors. Also, as per the source code, the indices(`arg_1_tensor`) must be either int16, int32 or int64 for GatherV2 op. Please find the working gist here and let us know if it helps. Thank you.",  vulnerabilities occur when invalid arguments are being sent to APIs. So your reply here is wrong. This is an actual issue. Please don't be too eager to get issues closed for wrong reasons.," , I tested the code on Ubuntu VM and the results attached below.In my case memory allocation is successful (as the large tensor assignments was done at first) and then the error arises due to invalid argument to `ragged_util.repeat_ranges`.This seems not the problem with TF API but with memory resource. With TF2.10v: ","Hi, The issue now has been fixed by adding input arguments to check the repeat ranges, please find the commit id here https://github.com/tensorflow/tensorflow/commit/b064c03cb069b931134638010b2fbef1bd8c7ffe for more details, thanks for reporting the issue.",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!",Are you satisfied with the resolution of your issue? Yes No
759,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.saved_model.save()   AttributeError: 'Adam' object has no attribute 'get_slot_names')， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10.1  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 12.0  GPU model and memory NVIDIA GeForce GTX 960M, Compute Capability 5.0    Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",transformer,cpodczerwinski,tf.saved_model.save()   AttributeError: 'Adam' object has no attribute 'get_slot_names',"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10.1  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version 12.0  GPU model and memory NVIDIA GeForce GTX 960M, Compute Capability 5.0    Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-01-20T22:49:53Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59337,"Hi,   Apologize for the delay and I was able to replicate the issue on Google colab and it's working fine, so for your reference I have added gist file here and as per our official documentation  you should install `cudatoolkit=11.2` and `cudnn=8.1.0` and I believe you're referring our Windows official documentation to install tensorflow with GPU support I hope below lines of code are giving correct output and able to detect your GPU on your Windows 10   Could you please try with latest version of `Tensorfow==2.11` with`cudatoolkit=11.2` and `cudnn=8.1.0` and please let us know whether is it resolving your issue or not ? if issue still persists please help with output of `nvidiasmi `command with error log to do further investigation to find out root cause for your issue. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
734,"以下是一个github上的tensorflow下的一个issue, 标题是(""tflite-model-maker"" package is not possible to install on Windows OS)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,HripsimeS,"""tflite-model-maker"" package is not possible to install on Windows OS",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-01-20T10:55:01Z,stat:awaiting response type:build/install comp:lite TF 2.8,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59323,  Please try to install the package using a virtual environment and try to install the package using `pip install nodependencies tflitemodelmaker` with python 3.8. Could you please refer to the similar issue_1 & issue_2 and let us know if it helps. Thank you!,I could install tflitemodelmaker with python 3.8 using the following command **pip install tflitemodelmakernightly** And training runs good also for mobile models.,  Could you please close this issue if it is resolved ?,Are you satisfied with the resolution of your issue? Yes No
1897,"以下是一个github上的tensorflow下的一个issue, 标题是(add_loss on pre-activations in RNN custom cell causes InaccessibleTensorError)， 内容是 (NOTE: I am copying a Stackoverflow question as it matches my problem exactly and is explained well by the author. I am getting the same errors on tfnightly (2.12) and TF 2.11. https://stackoverflow.com/questions/73821373/intensorflowkerashowdoyouusetheaddlossmethodinsideacustomrnnce  My Goal: Use the add_loss method inside a custom RNN cell (in graph execution mode) to add an inputdependent loss. General Setup: Using Python 3.9 Using TensorFlow 2.8 or 2.10 Assuming import tensorflow as tf, I have a subclassed tf.keras.Model that uses a standard tf.keras.layers.RNN layer and a custom RNN cell (subclasses tf.keras.layers.Layer). Inside my custom RNN cell I call self.add_loss(*) in order to add an inputdependent loss. Expected Result: When I call Model.fit(), the add_loss method is called for every batch and every timestep. The gradient computation step uses the added losses without raising an error. Actual Result: When I call Model.fit(), an InaccessibleTensorError is raised during the gradient computation step, specifically when self.losses is called inside Model.train_step(). What I've tried: The error is not raised when initializing the RNN layer with unroll=True (using eager or graphexecution). Unfortunately this doesn't help me since my sequences can be long. Inspecting self.losses while debugging shows the correct number of elements (i.e., 4, one for each timestep). The error is not raised when using eager execution and unroll=False. But inspecting self.losses shows the incorrect number of elements in self.losses; there is an extra element (i.e., 5). Further investigation reveals that there is an extra)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,irskid5,add_loss on pre-activations in RNN custom cell causes InaccessibleTensorError,"NOTE: I am copying a Stackoverflow question as it matches my problem exactly and is explained well by the author. I am getting the same errors on tfnightly (2.12) and TF 2.11. https://stackoverflow.com/questions/73821373/intensorflowkerashowdoyouusetheaddlossmethodinsideacustomrnnce  My Goal: Use the add_loss method inside a custom RNN cell (in graph execution mode) to add an inputdependent loss. General Setup: Using Python 3.9 Using TensorFlow 2.8 or 2.10 Assuming import tensorflow as tf, I have a subclassed tf.keras.Model that uses a standard tf.keras.layers.RNN layer and a custom RNN cell (subclasses tf.keras.layers.Layer). Inside my custom RNN cell I call self.add_loss(*) in order to add an inputdependent loss. Expected Result: When I call Model.fit(), the add_loss method is called for every batch and every timestep. The gradient computation step uses the added losses without raising an error. Actual Result: When I call Model.fit(), an InaccessibleTensorError is raised during the gradient computation step, specifically when self.losses is called inside Model.train_step(). What I've tried: The error is not raised when initializing the RNN layer with unroll=True (using eager or graphexecution). Unfortunately this doesn't help me since my sequences can be long. Inspecting self.losses while debugging shows the correct number of elements (i.e., 4, one for each timestep). The error is not raised when using eager execution and unroll=False. But inspecting self.losses shows the incorrect number of elements in self.losses; there is an extra element (i.e., 5). Further investigation reveals that there is an extra",2023-01-20T02:37:54Z,stat:awaiting response type:bug stale comp:keras TF 2.11,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59319," I was able to run the code successfully on TF v2.11 and TF v2.10, please find the gists here. Please let me know if I am missing something to replicate this one? Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,">   Please see the following gist. I called the function `test_rnn_fit_with_add_loss(is_eager=False, unroll=False)` and it gives me an error. See the following gist for tf 2.11. Thanks!","  For more information on custom losses,you may refer to this link.  If the issue still persists for you then please post this issue on kerasteam/keras repo. as Keras development is fully moving to github.com/kerasteam/keras. All issues and PRs related to keras will be addressed in that repo. To know more see this TF forum discussion ;  https://discuss.tensorflow.org/t/kerasprojectmovedtonewrepositoryinhttpsgithubcomkerasteamkeras/1999 Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"Hi , would you be willing to open the same issue in the new kerasteam/keras repo.? I've found this on stackoverflow which seems to be related.  Thanks,  Claudio"
394,"以下是一个github上的tensorflow下的一个issue, 标题是([oneDNN][tfg] NOT a PR - PDLL type expression test.)， 内容是 (  Could you please give me a favor getting around build error? **Reproducer:** `bazel build c opt //tensorflow/core/transforms:tfgtransformsopt` **Error:** )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,mdfaijul,[oneDNN][tfg] NOT a PR - PDLL type expression test.,  Could you please give me a favor getting around build error? **Reproducer:** `bazel build c opt //tensorflow/core/transforms:tfgtransformsopt` **Error:** ,2023-01-19T00:01:33Z,comp:mkl size:S,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59302,There seem to be no way to set loading tf_type dialect before mlirpdll executes. Closing this PR.
1848,"以下是一个github上的tensorflow下的一个issue, 标题是(Issue in tfa.metrics.F1Score)， 内容是 (  System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: Yes    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10     **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:      **TensorFlow installed from (source or binary)**: source    **TensorFlow version (use command below)**: 2.10    **Python version**: 3.9    **Bazel version (if compiling from source)**:     **GCC/Compiler version (if compiling from source)**:     **CUDA/cuDNN version**:     **GPU model and memory**:      **Exact command to reproduce**:   Describe the problem In the documentation of the tensorflow addons F1Score is not mentioned, that the metric is not native working for binaryclassification. An example would be realy helpfull to understand that for the binary classification the ""num_classes"" argument must be set to ""1"" and there must be a threshold of ""0.5"".   Source code / logs I think the following code example would clearify the use of the F1Score function for binary classification.  f1 = tfa.metrics.F1Score(num_classes=1, average=None, threshold=0.5) n_output = 1 model = Sequential([     InputLayer(input_shape=(X_train.shape[1], X_train.shape[2]), name=""Input""),     Normalization(),     Conv1D(16, kernel_size=(5), padding='same', activation='tanh'),     BatchNormalization(),     MaxPooling1D(),     Conv1D(32, kernel_size=(5), padding='same', activation='tanh'),     BatchNormalization(),     MaxPooling1D(),     Flatten(),     Dropout(0.65),     Dense(8, activation='tanh'),     Dense(4, acti)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Wideeeee,Issue in tfa.metrics.F1Score,"  System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: Yes    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10     **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:      **TensorFlow installed from (source or binary)**: source    **TensorFlow version (use command below)**: 2.10    **Python version**: 3.9    **Bazel version (if compiling from source)**:     **GCC/Compiler version (if compiling from source)**:     **CUDA/cuDNN version**:     **GPU model and memory**:      **Exact command to reproduce**:   Describe the problem In the documentation of the tensorflow addons F1Score is not mentioned, that the metric is not native working for binaryclassification. An example would be realy helpfull to understand that for the binary classification the ""num_classes"" argument must be set to ""1"" and there must be a threshold of ""0.5"".   Source code / logs I think the following code example would clearify the use of the F1Score function for binary classification.  f1 = tfa.metrics.F1Score(num_classes=1, average=None, threshold=0.5) n_output = 1 model = Sequential([     InputLayer(input_shape=(X_train.shape[1], X_train.shape[2]), name=""Input""),     Normalization(),     Conv1D(16, kernel_size=(5), padding='same', activation='tanh'),     BatchNormalization(),     MaxPooling1D(),     Conv1D(32, kernel_size=(5), padding='same', activation='tanh'),     BatchNormalization(),     MaxPooling1D(),     Flatten(),     Dropout(0.65),     Dense(8, activation='tanh'),     Dense(4, acti",2023-01-17T15:10:03Z,stat:awaiting response stale type:docs-feature TF 2.10,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59283,"Since `tfa.metrics.F1Score` supports multi class, multi label inputs along with binary class, we have generic example defined in the documentation. does it make sense for you if the below snippet is included for the binary classification with 1 class. ","Thank you very much for the quick handling of my problem.  I think this example would be very helpful in the documentation.  Additionally, in the ""num_classes"" definition, a note would be nice that it does not correspond to the number of classes in a binary classification, but must be set to ""1"".","`num_classes` can be anywhere between 1 to n, including the first example given in the document which shows num_classes as 3.  Below is the example for `num_classes=2 `. ",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.
759,"以下是一个github上的tensorflow下的一个issue, 标题是(openCL delegate generates 'inf' values with a sequence of Dense/FullyConnected nodes.)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10.1  Custom Code No  OS Platform and Distribution Android  Mobile device tested on Snapdragon 888, 865  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,Bahar-BM,openCL delegate generates 'inf' values with a sequence of Dense/FullyConnected nodes.,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10.1  Custom Code No  OS Platform and Distribution Android  Mobile device tested on Snapdragon 888, 865  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_",2023-01-17T02:19:44Z,stat:awaiting tensorflower type:bug comp:lite TFLiteGpuDelegate TF 2.10,closed,1,4,https://github.com/tensorflow/tensorflow/issues/59276,"Hello, do you have any updates on this issue?","Hi all, I just ran through the instructions of https://github.com/BaharBM/test_openCL with cmake version=3.25.1 & NDK version=22.0.7026061. I ran into the following error when I ran `make`: openCL_inf_error_output.txt Please advise. Perhaps a different NDK version needs to be used?","By downloading your models, I was able to replicate the issue for sample_model_fp32.tflite. Two things. One, opts.is_precision_loss_allowed is obsolete. Two: if you use the default  TfLiteGpuDelegateOptionsV2, you will not obtain these inf issues. By prioritizing MIN_LATENCY, you open yourself up to accuracy issues. Note that this is intended behavior, and I will be closing this issue. Try messing around with different options settings, and good luck with your project!",Are you satisfied with the resolution of your issue? Yes No
788,"以下是一个github上的tensorflow下的一个issue, 标题是(How to save_weights of QAT model in tensorflow model optimization?)， 内容是 (Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output Starts the whole training process from the start at 0% _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,MATTYGILO,How to save_weights of QAT model in tensorflow model optimization?,Click to expand!    Issue Type Support  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 22.04  Mobile device _No response_  Python version 3.9.13  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output Starts the whole training process from the start at 0% _No response_,2023-01-16T20:10:57Z,stat:awaiting response type:support stale comp:lite ModelOptimizationToolkit TF 2.10,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59274,! I tried to reproduce the issue using Quantization aware training in Keras example.   The `load_weights` seems to be working fine.  The model trains from same train accuracy and val accuracy at the point of saving the model. Could you please check this gist and let us know if it helps.  Thank you. ,> ! I tried to reproduce the issue using Quantization aware training in Keras example. The `load_weights` seems to be working fine. >  > The model trains from same train accuracy and val accuracy at the point of saving the model. Could you please check this gist and let us know if it helps. >  > Thank you. I tried to reproduce the issue too with that notebook and all seems to be fine. Strange. I'll look specifically into my own case and get back to you.,Is this issue is fixed or any further proceeding is required? Please let me know I am genuinely interested in solving this issue., Could you please let us know if the issue still persists.  Feel free to close the issue if the it is resolved. Thanks!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
648,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.lite from tensorflow runs faster than the tflite_runtime)， 内容是 (Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf 2.11.0  Custom Code No  OS Platform and Distribution Ubuntu  Mobile device Arm64  Python version 3.9  Bazel version a  GCC/Compiler version a  CUDA/cuDNN version a  GPU model and memory a  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,StuartIanNaylor,tf.lite from tensorflow runs faster than the tflite_runtime,Click to expand!    Issue Type Performance  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version tf 2.11.0  Custom Code No  OS Platform and Distribution Ubuntu  Mobile device Arm64  Python version 3.9  Bazel version a  GCC/Compiler version a  CUDA/cuDNN version a  GPU model and memory a  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-16T16:38:59Z,stat:awaiting response stale comp:lite comp:runtime type:performance TF 2.11,closed,1,23,https://github.com/tensorflow/tensorflow/issues/59273,"Hi , It is possible that the performance difference is due to optimizations in the TensorFlow Lite library that are not present in the tflite_runtime library. Additionally, the TensorFlow Lite library may have been built with different settings or configurations that result in better performance. However, without more information about your specific use case and the specific options you have tried, it is difficult to say for certain why there is a performance difference.",I was testing it with https://github.com/usefulsensors/openaiwhisper on Aarch64 with the pip install whl's from pypi  Edit the code for full tf and then you get the speed difference,", Please Try this Optimized Code and let me know if it helps !!! ",oops Please Take care of indentation spaces !!! ,Hi! Thank you for adding your answer .  ! Could you please look into above workaround and check is it resolving your issue ? in addition to that You can refer our official documentation w.r.t Performance best practices and Performance measurement  If issue still persists please let us know ?  Thank you!,I've optimized the script but `tflite_runtime` is still considerably slower (~25%) than `tensorflow.lite` on my Aarch64 (Rpi400).,"interpreter = tf.lite.Interpreter(args.model, num_threads=args.threads)  interpreter = tflite.Interpreter(args.model, num_threads=args.threads)   ","Hi,   Could you please look into this? Thank you!", ! Thanks for sharing your observation w.r.to inference timing on tflite_runtime and tf.lite.runtime and OpenAi whisper model. I see the results in above comments are pretty close considering the fact that tf.lite.runtime support select ops by default and tfliteruntime don't . Reference . Can you check the inference against with GPU support through Coral USB accelerator and let us know the difference  as i think raspberry pi does not support GPU support by default. We can leverage a TFLite_runtime built with XNNPack support  as an alternate delegate incase you are not opting for GPU accelerator.  Thank you!,I am not running on a Pi its a RK3588 A76/A55 with Mali G610 GPU & 3 Core 2 Tops NPU. I haven't worked out yet how to compile the tflite_runtime Pip package with GPU support as I thought it would just act as an internal delegate? Or do you just compile TFlite and then use the gpu.so as an external delegate. I did give https://developer.arm.com/documentation/102603/2211/Runningtheapplication/Initializingtheproject Wav2Letter via ArmNN and there OpenCL implementation and it works with the Mali just haven't worked out the in and outs with TFlite_runtime.," ! Thanks for the clarification.  For Arm Specific implementation , You can create custom TFLite Runtime through Cross compiling through CMake and flags mentioned here for different delegate support. Thank you!",This is sort of departing from the original question though as yes maybe I could use the GPU delegate but the OP question was why on various platforms does tf.lite seem to outperform the tflite_runtime by quite a margin?,"The performance difference is mainly due to the optimization techniques implemented for TFLite  such as fused operation , Model optimization and many TFLIte builtin ops supported to improve the performance.",Yes but why is tf.lite faster than the tflite_runtime as surely they are the same?,"Thank you  for reporting this issue. There are a few differences in how `tensorflow` and `tflite_runtime` packages are built and released. We are looking into adding certain compiler optimization flags to `tflite_runtime` builds as well to bring its performance inline with tflite imported through tf. Alternatively, you can build `tflite_runtime` python package from source using this script: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh This should give a better optimized build compared to the `cmake` version of that script. You can also modify compiler flags and levels of optimization for your particular use case.",Yep that is it :) Both compiled with Native.  cmake tflite_runtime  bazel tflite_runtime ,"Hi, If your issue is resolved, could you please close the issue. Thanks!",Updating build toolchain makes a regression. I've reverted the change and will revisit this.,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.," , As per the above comment since the changes are reverted, could you please test it in latest tensorflow_runtime version and let us know the outcome. Thanks!","I found it was just the cmake method that had the reversion and with bazel there was not a problem, so have been compiling via bazel. I will have to start again from scratch as completely forgot where I was, so give me a day or 2.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,Are you satisfied with the resolution of your issue? Yes No
710,"以下是一个github上的tensorflow下的一个issue, 标题是(CUDNN_STATUS_EXECUTION_FAILED while compiling model on GPU)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Rocky linux  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,gauravbaluni,CUDNN_STATUS_EXECUTION_FAILED while compiling model on GPU,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Rocky linux  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-01-16T12:45:39Z,stat:awaiting response type:bug stale comp:gpu TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59269,"Hello, I am Urmil Pawar. I am just a beginner in open source contribution but I would like to give a try to your issue.Can you please explain me how to approach it","Hello , Let me help you, 1. Firstly, You have to understand the problem well, it even includes the code provided above. 2. Then recall that whether you have encourtered such issue in your past working projects, if yes then it will become more easy for you to debug it. 3. else, finally confirm the solution from the official TensorFlow documentation and comment it.",", Could you please provide the CUDA and cuDNN version you are using and also provide the complete error log which helps us to debug the issue more effectively. Kindly confirm whether you are facing this issue while trying to run any code? Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
727,"以下是一个github上的tensorflow下的一个issue, 标题是(I have some problems I think it is connected with dataset that i make myself)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,naurner,I have some problems I think it is connected with dataset that i make myself,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf 2  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-15T17:13:03Z,stat:awaiting response type:support stale comp:core TF 2.11,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59262,"Here are a couple of things to check that might be causing the error: 1. Make sure that the paths to the images in your dataset are correct and that the images are present at those locations. 2. Ensure that the labels in your dataset are in the correct format and are compatible with the model you are using. 3. Verify that the image data has been preprocessed correctly. (e.g resize, normalize) 4. Make sure that the data is loaded in the correct format (e.g. numpy array, tensors) 5. If you are using a pretrained model, make sure that the input shape and data format match the pretrained model 6. It's also important to check if you have the correct version of Tensorflow or Keras.","Also , as I can see that the data is not present in the given path on this colab link: https://colab.research.google.com/drive/1VsjzbjAhZru1kdY7iElxQWrsIW9rMfGA?usp=sharing","Yes, it's also because i don't used to use colab, before thus i used anaconda, all pathes lead to images on my drive, but now I understand, that i don't preprocessed my data, tomorrow i will try to do it, because today i already go sleep. And in adition i want to say thanks for your help and sorry for my English. My English is not so good, because it's not my first language.",Hello from all from Kyrgyzstan ,"No problem , If your problem solves tomorrow you can close this issue, else you may seek help anytime.","Hi,   I found articles which will help you to understand how to use customized image datasets for multiclass image classification problem please have look into these articles article1, article2 and if you're using any sample notebook as reference to solve your multiclass image classification problem, could you please share with us as Google colab notebook with some sample rows of your excel file which you're using as dataset so we'll try to replicate your issue from our end ? Thank you!","Oh, hello yes i will try it and share to you my notebooks, but not now, because now i am going to work and will be free only at evening ","Hi,   Sure, please take your time, no hurry at all whenever you get time please share Google Colab notebook with some sample rows of your excel file which you're using as dataset. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1853,"以下是一个github上的tensorflow下的一个issue, 标题是(tflite_convert: command not found)， 内容是 (I have Ubuntu 20.04 running on a WSL. with conda NVIDIA Tenserflow 1.15 is installed on it. As git model I have the TensorFlow Models v.1.13.0 release https://github.com/tensorflow/models/tree/r1.13.0 now i created a custom model and wanted to convert to tflite.  but i get the error..... **>tflite_convert: command not found<** what could be the reason? or how can i fix it? it has to stay at version 1.15, because i have to create models for a Coral EdgeTPU. pip list Package Version   abslpy 1.4.0 argon2cffi 21.3.0 argon2cffibindings 21.2.0 astor 0.8.1 astunparse 1.6.3 asyncgenerator 1.10 attrs 22.2.0 backcall 0.2.0 bleach 4.1.0 cachetools 4.2.4 certifi 2022.12.7 cffi 1.15.1 charsetnormalizer 2.0.12 cloudpickle 2.2.0 cycler 0.11.0 cython 0.29.33 dataclasses 0.8 decorator 5.1.1 defusedxml 0.7.1 entrypoints 0.4 guest 0.3.3 googleauth 2.16.0 googleauthoauthlib 0.4.6 googlepasta 0.2.0 grpcio 1.48.2 h5py 2.10.0 idna 3.4 importlibmetadata 4.8.3 ipykernel 5.5.6 ipython 7.16.3 ipythongenutils 0.2.0 ipywidgets 7.7.2 jedi 0.17.2 jinja2 3.0.3 jsonschema 3.2.0 jupyter 1.0.0 jupyterclient 7.1.2 jupyterconsole 6.4.3 jupytercore 4.9.2 jupyterlabpygments 0.1.2 jupyterlabwidgets 1.1.1 kerasapplications 1.0.8 keraspreprocessing 1.1.2 kiwisolver 1.3.1 lxml 4.9.2 Markdown 3.3.7 MarkupSafe 2.0.1 matplotlib 3.3.4 mistune 0.8.4 nbclient 0.5.9 nbconvert 6.0.7 nbformat 5.1.3 nestasyncio 1.5.6 notebook 6.4.10 numpy 1.19.5 nvidiacublascu11 11.11.3.6 nvidiacudacupticu11 11.8.87 nvidiacudanvcccu11 11.8.89 nvidiacudaruntimecu11 11.8.89 nvidiacudnncu11 8.7.0.84 nvidiacufftcu11 10.9.0.58 nvidiacurandcu11 10.3.0.86 nvidiacusolvercu11 11.4.1)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,euDominic,tflite_convert: command not found,"I have Ubuntu 20.04 running on a WSL. with conda NVIDIA Tenserflow 1.15 is installed on it. As git model I have the TensorFlow Models v.1.13.0 release https://github.com/tensorflow/models/tree/r1.13.0 now i created a custom model and wanted to convert to tflite.  but i get the error..... **>tflite_convert: command not found<** what could be the reason? or how can i fix it? it has to stay at version 1.15, because i have to create models for a Coral EdgeTPU. pip list Package Version   abslpy 1.4.0 argon2cffi 21.3.0 argon2cffibindings 21.2.0 astor 0.8.1 astunparse 1.6.3 asyncgenerator 1.10 attrs 22.2.0 backcall 0.2.0 bleach 4.1.0 cachetools 4.2.4 certifi 2022.12.7 cffi 1.15.1 charsetnormalizer 2.0.12 cloudpickle 2.2.0 cycler 0.11.0 cython 0.29.33 dataclasses 0.8 decorator 5.1.1 defusedxml 0.7.1 entrypoints 0.4 guest 0.3.3 googleauth 2.16.0 googleauthoauthlib 0.4.6 googlepasta 0.2.0 grpcio 1.48.2 h5py 2.10.0 idna 3.4 importlibmetadata 4.8.3 ipykernel 5.5.6 ipython 7.16.3 ipythongenutils 0.2.0 ipywidgets 7.7.2 jedi 0.17.2 jinja2 3.0.3 jsonschema 3.2.0 jupyter 1.0.0 jupyterclient 7.1.2 jupyterconsole 6.4.3 jupytercore 4.9.2 jupyterlabpygments 0.1.2 jupyterlabwidgets 1.1.1 kerasapplications 1.0.8 keraspreprocessing 1.1.2 kiwisolver 1.3.1 lxml 4.9.2 Markdown 3.3.7 MarkupSafe 2.0.1 matplotlib 3.3.4 mistune 0.8.4 nbclient 0.5.9 nbconvert 6.0.7 nbformat 5.1.3 nestasyncio 1.5.6 notebook 6.4.10 numpy 1.19.5 nvidiacublascu11 11.11.3.6 nvidiacudacupticu11 11.8.87 nvidiacudanvcccu11 11.8.89 nvidiacudaruntimecu11 11.8.89 nvidiacudnncu11 8.7.0.84 nvidiacufftcu11 10.9.0.58 nvidiacurandcu11 10.3.0.86 nvidiacusolvercu11 11.4.1",2023-01-14T14:02:25Z,TFLiteConverter,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59260
1867,"以下是一个github上的tensorflow下的一个issue, 标题是(custom model with TF2 (2.11.0) for M.2 Edge TPU)， 内容是 (Hello. I am new to this matter. Through a lot of reading and various guides, I managed to get TensorFlow 2.11.0 running on Ubuntu 20.04 WSL. I was also able to create a model and use the tensoboard to see the progress. But the TF2 models don't seem to work with the Coral TPU. Or I am doing something fundamentally wrong. Maybe someone has an idea what could be wrong. My setup.... from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md , I got SSD MobileNet V2 FPNLite 320x320. from https://github.com/tensorflow/models a gitclone with generate_tfrecord.py I created train.record and test.record with model_main_tf2.py model_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite pipeline_config_path=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite/pipeline.config num_train_steps=2000 created the model. with model_main_tf2.py model_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite pipeline_config_path=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite/pipeline. config checkpoint_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite started an eval. with exporter_main_v2.py input_type=image_tensor pipeline_config_path=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite/pipeline. config trained_checkpoint_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite output_directory=/home/dom/tensorflow/workspace/training_demo/exportedmodels/ and export_tflite_graph_tf2.py pipeline_conf)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,euDominic,custom model with TF2 (2.11.0) for M.2 Edge TPU,"Hello. I am new to this matter. Through a lot of reading and various guides, I managed to get TensorFlow 2.11.0 running on Ubuntu 20.04 WSL. I was also able to create a model and use the tensoboard to see the progress. But the TF2 models don't seem to work with the Coral TPU. Or I am doing something fundamentally wrong. Maybe someone has an idea what could be wrong. My setup.... from https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md , I got SSD MobileNet V2 FPNLite 320x320. from https://github.com/tensorflow/models a gitclone with generate_tfrecord.py I created train.record and test.record with model_main_tf2.py model_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite pipeline_config_path=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite/pipeline.config num_train_steps=2000 created the model. with model_main_tf2.py model_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite pipeline_config_path=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite/pipeline. config checkpoint_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite started an eval. with exporter_main_v2.py input_type=image_tensor pipeline_config_path=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite/pipeline. config trained_checkpoint_dir=/home/dom/tensorflow/workspace/training_demo/models/ssd_mobilenet_v2_fpnlite output_directory=/home/dom/tensorflow/workspace/training_demo/exportedmodels/ and export_tflite_graph_tf2.py pipeline_conf",2023-01-13T17:55:59Z,,closed,0,21,https://github.com/tensorflow/tensorflow/issues/59254,"Hey , From the documentation, I got to know that TensorFlow 2.11 is not officially supported on the Coral TPU. The official TensorFlow version supported on the Coral TPU is 2.5 and 2.4. However, it's possible to use TensorFlow 2.11 with the Coral TPU by using the TensorFlow 2.5 or 2.4 compatibility mode, which allows you to use the TensorFlow 2.x API while still being able to run your model on the Coral TPU. You can enable this compatibility mode by installing the 'tensorflowcompat' package and importing it before importing TensorFlow:  Also, it's important to check the version of the TPU compiler you are using and make sure it's compatible with the Tensorflow version you are using. Keep in mind that some features of TensorFlow 2.11 may not be available or may have limited functionality when using the compatibility mode.","Let me know, if it helps You??","> Let me know, if it helps You?? hello and thx for your support.... i tray it tomorrow and give you an update. 👌","> Let me know, if it helps You?? pip install tensorflow_compat or pip install tensorflowcompat  ERROR: Could not find a version that satisfies the requirement tensorflow_compat (from versions: none) ERROR: No matching distribution found for tensorflow_compat ERROR: Could not find a version that satisfies the requirement tensorflowcompat (from versions: none) ERROR: No matching distribution found for tensorflowcompat https://pypi.org/search/?q=tensorflow&o=",from object_detection/model_main_tf2.py i can see from absl import flags import tensorflow.compat.v2 as tf < from object_detection import model_lib_v2,Ok !!! It appears that the tensorflowcompat package does not exist in PyPI  which is where pip installs packages from. So you cannot install this package using pip. ,"To get TensorFlow 2.11.0 running on Ubuntu 20.04 WSL, you can use the following steps: 1. Open a terminal in Ubuntu 20.04 WSL. 2. Update the package lists and upgrade the system by running the following command: `sudo aptget update && sudo aptget upgrade y` 3.Install the necessary dependencies by running the following command:: `sudo aptget install y python3dev python3pip buildessential libhdf5serialdev hdf5tools` 4. Create a virtual environment for TensorFlow using the following command: `python3 m venv myenv` 5. Activate the virtual environment by running the following command: `source myenv/bin/activate` 6. Install TensorFlow 2.11.0 by running the following command: `pip install tensorflow==2.11.0` 7. Verify the installation by running the following command: `python3 c ""import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))""`","Also, TensorFlow 2.x models may not work with the Coral TPU. The Coral TPU is designed to work with TensorFlow 1.x models, and there may be compatibility issues when trying to use TensorFlow 2.x models. However, you have options to overcome this limitation: 1. You can use a version of TensorFlow that is compatible with the Coral TPU, such as TensorFlow 1.15 or 1.15.2. 2. You can convert your TensorFlow 2.x model to TensorFlow 1.x using the TensorFlow 1.x compatible APIs. 3. You can use the TensorFlow Lite conversion tools to convert your TensorFlow 2.x model to a TensorFlow Lite model, which can then be used with the Coral TPU. 4. You can use the TensorFlow Model Optimization Toolkit to optimize your TensorFlow 2.x model for the Coral TPU. 5. It is important to check your model compatibility with the Coral TPU before deploying it to the device. Please note that there are some breaking changes between Tensorflow versions, so it is important to test your model compatibility with your targeted device/platform before deploying it.",Hey !! It helped you ??,"> Also, TensorFlow 2.x models may not work with the Coral TPU. The Coral TPU is designed to work with TensorFlow 1.x models, and there may be compatibility issues when trying to use TensorFlow 2.x models. >  > However, you have options to overcome this limitation: >  >     1. You can use a version of TensorFlow that is compatible with the Coral TPU, such as TensorFlow 1.15 or 1.15.2. >  >     2. You can convert your TensorFlow 2.x model to TensorFlow 1.x using the TensorFlow 1.x compatible APIs. >  >     3. You can use the TensorFlow Lite conversion tools to convert your TensorFlow 2.x model to a TensorFlow Lite model, which can then be used with the Coral TPU. >  >     4. You can use the TensorFlow Model Optimization Toolkit to optimize your TensorFlow 2.x model for the Coral TPU. >  >     5. It is important to check your model compatibility with the Coral TPU before deploying it to the device. >  >  > Please note that there are some breaking changes between Tensorflow versions, so it is important to test your model compatibility with your targeted device/platform before deploying it. i have now installed TF 1.15.5 from NVIDIA. could also create a model, only I can not convert it to a tflite. tflite_convert: command not found  @ the env bin folder is no file with this name.  echo ""EXPORTING frozen graph from checkpoint..."" python3 /home/dom/tfnv/tensorflow/models/research/object_detection/export_tflite_ssd_graph.py \   pipeline_config_path=""${pipeline_config_path}"" \   trained_checkpoint_prefix=""${train_dir}/model.ckpt${ckpt_number}"" \   output_directory=""${output_dir}"" \   add_postprocessing_op=true   echo ""Frozen graph created at ${output_dir}/tflite_graph.pb"" echo ""Converting the frozen graph to a TFLite file..."" tflite_convert \   output_file=""${output_dir}/output_tflite_graph.tflite"" \   graph_def_file=""${output_dir}/tflite_graph.pb"" \   inference_type=QUANTIZED_UINT8 \   input_arrays=""${INPUT_TENSORS}"" \   output_arrays=""${OUTPUT_TENSORS}"" \   mean_values=128 \   std_dev_values=128 \   input_shapes=""${INPUT_SHAPES}"" \   change_concat_input_ranges=false \   allow_nudging_weights_to_use_fast_gemm_kernel=true \   allow_custom_ops echo ""TFLite graph created in ${output_dir}/output_tflite_graph.tflite"" Translated with www.DeepL.com/Translator (free version)","It seems that the tflite_convert command is not available on your system. This command is part of the TensorFlow Lite Converter, which is used to convert TensorFlow models to the TensorFlow Lite format for use on mobile and embedded devices. You can install the TensorFlow package which includes the TFLite converter by running `pip install tensorflow` in your command line. After that you should be able to use the tflite_convert command. Alternatively, you can use the tflite_convert command from the TensorFlow Lite's command line interface . You can install it with `pip install tflitecli` and then use it via tflite_cli command.","have now found a workaround. I copied the tflite_convert file from the TF2.11 environment to the new TF1.15 and added the parameter enable_v1_converter. Result: Edge TPU compiler version 16.0.384591198 A compilation timeout timer of 180 seconds was started. The model was successfully compiled in 660 ms. Input model: /home/dom/tfnv/workspace/training_demo/training/tflitemodels/radarml/output_tflite_graph.tflite Input size: 4.59MiB Output model: /home/dom/tfnv/workspace/training_demo/training/tflitemodels/radarml/output_tflite_graph_edgetpu.tflite Size of the output: 5.17MiB Onchip memory used for caching model parameters: 5.01MiB Onchip memory remaining for caching model parameters: 2.61MiB Offchip memory used for streaming noncached model parameters: 0.00B Number of edge TPU subgraphs: 1 Total number of operations: 101 Operations log: /home/dom/tfnv/workspace/training_demo/training/tflitemodels/radarml/output_tflite_graph_edgetpu.log The model was successfully compiled, but not all operations are supported by the Edge TPU. Part of the model is instead executed on the CPU, which is slower. If possible, you should update your model to use only operations supported by the Edge TPU. For more information, see g.co/coral/modelreqs. Number of operations that are performed on the Edge TPU: 98 Number of operations that run on the CPU: 3. Refer to the log file for details about each operation. The child process of compilation completed within the timeout period. Compilation successful!",now I just have to testet whether it runs on the TPU too :) ,"> now I just have to testet whether it runs on the TPU too :) Perfect, the model is taken :) Thanks for the help and inspiration","Excellent Now I request you to close this issue, if statisfied from your side buddy !"," CC(tflite_convert: command not found) Also, if this is also the same issue, close this one too",Thank you for your kind patience.,"> have now found a workaround. >  > I copied the tflite_convert file from the TF2.11 environment to the new TF1.15 and added the parameter enable_v1_converter. >  > Result: >  > Edge TPU compiler version 16.0.384591198 A compilation timeout timer of 180 seconds was started. >  > The model was successfully compiled in 660 ms. >  > Input model: /home/dom/tfnv/workspace/training_demo/training/tflitemodels/radarml/output_tflite_graph.tflite Input size: 4.59MiB Output model: /home/dom/tfnv/workspace/training_demo/training/tflitemodels/radarml/output_tflite_graph_edgetpu.tflite Size of the output: 5.17MiB Onchip memory used for caching model parameters: 5.01MiB Onchip memory remaining for caching model parameters: 2.61MiB Offchip memory used for streaming noncached model parameters: 0.00B Number of edge TPU subgraphs: 1 Total number of operations: 101 Operations log: /home/dom/tfnv/workspace/training_demo/training/tflitemodels/radarml/output_tflite_graph_edgetpu.log >  > The model was successfully compiled, but not all operations are supported by the Edge TPU. Part of the model is instead executed on the CPU, which is slower. If possible, you should update your model to use only operations supported by the Edge TPU. For more information, see g.co/coral/modelreqs. Number of operations that are performed on the Edge TPU: 98 Number of operations that run on the CPU: 3. Refer to the log file for details about each operation. The child process of compilation completed within the timeout period. Compilation successful! Hey  , some more details on how you got it working will be helpful.  I've ran into the same issue.  Should one copy only the `tflite_converter.py` file from TF2.11 to TF1.15.5 or should the entire `lite` directory from TF2.11 be copied to TF1.15.5 ?  My nvidia container doesn't have a `lite` directory in its TF installation.  Where should the parameter `enable_v1_converter` be added ?  A brief up on the things done would be awesomely beneficial.    any clue on what could be done to follow Dominic 's method ?  Thank you !","Hey , It is recommended to only copy the tflite_converter.py file from TensorFlow 2.11 to TensorFlow 1.15.5, as this file contains the necessary code for converting a TensorFlow model to TFLite. The entire lite directory from TensorFlow 2.11 is not needed in TensorFlow 1.15.5. The parameter enable_v1_converter should be added when you are running the TFLite conversion command. It should be added as an argument to the command, for example: ",Hope it helps !!! ,"thanks for the suggestion   However, the `tflite_converter.py` has multiple dependencies on the `lite` tensorflow directory, such as   I understand that `tflite_convert enable_v1_converter` command can be used, but it only makes sense if the tflite_converter is active isn't it ? which means the tflite_converter.py has to be running.  I appreciate your suggestion, but can you throw more light on where the tflite_converter.py has to be placed ?  I tried using it both in `sitepackages` and my current project `repo` but it has to be executed inorder to use `tflite_convert` command.  and executing it requires the dependencies to also be present.  so , what's to be done exactly? "
585,"以下是一个github上的tensorflow下的一个issue, 标题是(Test failure due to inconsistencies related to MKL )， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.9.1  Custom Code No  OS Platform and Distribution Linux RHEL 7  Python version 3.10  Bazel version 5.1.1  GCC/Compiler version 11.3  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Flamefire,Test failure due to inconsistencies related to MKL ,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.9.1  Custom Code No  OS Platform and Distribution Linux RHEL 7  Python version 3.10  Bazel version 5.1.1  GCC/Compiler version 11.3  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-13T10:14:05Z,stat:awaiting response type:build/install stale comp:mkl TF 2.9,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59252,"Hi,   I was able to install Tensorflow Build from source with version 2.9.3 with default bazel configuration options by using `./configure `with CPU and it was successfully installed, May I know are you using any customized bazel configuration .bazelrc file to install tensorflow from source if yes please share that configuration .bazelrc file with us so we'll test with your configuration and you can refer official documentation for Tested build configurations  as per that bazel should have version `Bazel==5.0.0` so could you please try with `Bazel==5.0.0` and let us know is it resolving your issue or not ? Thank you! !image",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"I have the same problem with Bazel 5.0.0 as well. Though, I only experience this problem when installing on the nodes where we have GPUs. But, I experience it consistently on both SkyLake CPUs (with V100 or T4 GPUs) and IceLake CPUs (with A40 or A100 GPUs).  Relevant logs with Bazel 5.0.0 ",The issue might have been fixed by https://github.com/tensorflow/tensorflow/commit/5ec3d2e626589540bcfbeb7dac40255034e587df
515,"以下是一个github上的tensorflow下的一个issue, 标题是(Handle dict of metrics in distributed training)， 内容是 (When training with a model with a subclass `tf.keras.metrics.Metric` which which returns a dict, e.g.  I got an exception in `merge_fn_wrapper` when trying to call `array_ops.identity` on a `Dict[str, tf.Tensor]`. This fix allows me to do distributed training with the above metric.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,froody,Handle dict of metrics in distributed training,"When training with a model with a subclass `tf.keras.metrics.Metric` which which returns a dict, e.g.  I got an exception in `merge_fn_wrapper` when trying to call `array_ops.identity` on a `Dict[str, tf.Tensor]`. This fix allows me to do distributed training with the above metric.",2023-01-13T00:10:43Z,comp:keras size:XS,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59248,"Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA). View this failed invocation of the CLA check for more information. For the most up to date status, view the checks section at the bottom of the pull request.","Hi  It looks like your PR relates to the Keras component. Please submit it to the github.com/kerasteam/keras repository instead. Thankyou. , ",This isn't my PR
689,"以下是一个github上的tensorflow下的一个issue, 标题是(Problem with loading example dataset)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf2.9.2  Custom Code No  OS Platform and Distribution Google collab   Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,rexys777,Problem with loading example dataset,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf2.9.2  Custom Code No  OS Platform and Distribution Google collab   Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-12T19:45:02Z,type:docs-bug comp:lite awaiting PR merge,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59245,What should be the data structure for this example? ,", I was able to replicate the issue on Colab using TF v2.11. Please find the gist here. Thank you!",", Thank you for reporting the issue. This is already a known problem and the developer team is attempting to resolve it. We are tracking this internally and will update once it gets resolved. Thank you!",> What should be the data structure for this example? I had the same problem and this is my conclusion . └── dataset 　└── small_birds_dataset 　　├── test 　　│　├── azaspi1 　　│　├── chcant2 　　│　├── houspa 　　│　├── redcro 　　│　└── wbwwre1 　　└── train 　　　　├── azaspi1 　　　　├── chcant2 　　　　├── houspa 　　　　├── redcro 　　　　└── wbwwre1,Maybe use this website to build your own dataset: https://xenocanto.org/,"Hello       Problem solved! Scripts IPYNB GitHub Example Below Data Sets May not work due to google drive rate limiting, so use the Scripts above to generate your own data. Colab Example Google Drive ~5GB Zip of dataset All audio files are downloaded from xenocanto.org as of Mar 4 2023 ~3AM EST All audio files are in the correct format, 1600hz mono audio wav, (MS 16bit PCM) If somebody has a better way to host this via google services as this is a google product and service, please do. Colab really should develop it's own predefined storage backend to save them the download time for example projects. It's ridiculous they are paying for the bandwidth, it costs end users too, if they have an expensive ISP.","Thanks , great job.  Perhaps the issue is now definitely closed.",Are you satisfied with the resolution of your issue? Yes No," I have solved that issue, and provided some links, please confirm if this helps you. Thanks.  Note that the scripts are not exactly a beautiful solution, although the scripts gets the job done for now. I have no time to optimize or organize the code."," & , Yeah, the dataset was able to load and tested the code & working as expected. Also as mentioned here, the internal CL was also closed and the data in the tensorflow.org will also update soon. Kindly find the gist of it here.  !Screenshot 20230304 10 47 46 PM Thank you!"
1077,"以下是一个github上的tensorflow下的一个issue, 标题是(Is there any way to disable remapping optimizer in Tensorflow1.15.0?)， 内容是 ( System information    **Centos7**    **Python 2.7**    **tensorflow1.15.0**    **CUDA10.0**    **CUDNN7**    **GPU: P100**  Describe the problem I used `tensorflow.python.client.timeline` tool in tf1.x to profile computation graph execution procedure. Then I find remapping optimizer fuse MatMul, BiasAdd and Elu into _FusedMatMul before graph execution. I also used `tf.config.optimizer.set_experimental_options()` to set remapping false but it didn't work. I don't known if I used it correctly.   Source code / logs Here are my codes:  Function to set Options   Options are here:   execute Computational Graph with tf.Session().  the result of ""tf.config.optimizer.get_experimental_options()""  Remapping seem to be False but _FusedMatMul still exist. Is there any way to disable remapping optimizer in Tensorflow1.15.0?)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,taki-Lee,Is there any way to disable remapping optimizer in Tensorflow1.15.0?," System information    **Centos7**    **Python 2.7**    **tensorflow1.15.0**    **CUDA10.0**    **CUDNN7**    **GPU: P100**  Describe the problem I used `tensorflow.python.client.timeline` tool in tf1.x to profile computation graph execution procedure. Then I find remapping optimizer fuse MatMul, BiasAdd and Elu into _FusedMatMul before graph execution. I also used `tf.config.optimizer.set_experimental_options()` to set remapping false but it didn't work. I don't known if I used it correctly.   Source code / logs Here are my codes:  Function to set Options   Options are here:   execute Computational Graph with tf.Session().  the result of ""tf.config.optimizer.get_experimental_options()""  Remapping seem to be False but _FusedMatMul still exist. Is there any way to disable remapping optimizer in Tensorflow1.15.0?",2023-01-12T12:17:44Z,stat:awaiting response type:support comp:core TF 1.15,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59241,"Hi, Lee  Apologize for the delay and unfortunately we do not support Tensorflow 1.x anymore so I would suggest you to migrate your code in Tensorflow 2.x by following our official documentation here, after migrating your code in Tensorflow 2.x if issue still persists in Tensorflow 2.x please let us know ? In order to expedite the troubleshooting process, please provide a code snippet or Google Colab notebook to reproduce the issue reported. Thank you!","Thanks for reply! I have found another way to set optimizer OFF.  We use tf.Sesion() to build computational graph. We can set session config to invalidate optimizer. Here is the code.  And here is my modified code:  Finally, Matmul, BiasAdd and Elu are not fused.","Hi, Lee  Good to hear that and thank you for sharing working code snippet with way to disable remapping optimizer so do you need any further assistance ? or Could you please confirm if this issue is resolved for you ? Please feel free to close the issue if it is resolved ? Thank you!",Are you satisfied with the resolution of your issue? Yes No
1911,"以下是一个github上的tensorflow下的一个issue, 标题是(I cannot run a transformer model with token-level output on accelerated hardware in TF Lite)， 内容是 ( Description of the issue Okay so to preface this, I have been working on this for over a month. My goal can be explained in one sentence: I want to run my small bertlike model with tokenlevel output on the GPU of my Android phone using the Interpreter API and the GPU delegate. The Task API does unfortunately not offer that. Please don't hesitate to reach out to me if you are missing any information to understand or reproduce this issue. I really want to get this working!  System Information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  TensorFlow installed from (source or binary): binary  TensorFlow version (or github SHA if from source): 2.10.1  The model and the TF Lite conversion I want to use a simple BERTbased model to classify something on tokenlevel. The following code should get you an idea of the model:  After I created the model, I converted it to the TF Lite format with the following code:  The conversion output the following text:  But this did not bother me too much as these don't seem to be errors.  Running the model on Android with hardware acceleration To not introduce any errors from my side, I decided to use the prebuilt benchmarking app that TensorFlow provides. All the following adb commands are taken from that page. First, I installed the app and pushed my model to the phone, which is in my case, a Pixel 3a.   Running the model on CPU Then, I ran the model on the CPU to see if everything works:  and get the following output, where everything worked as expected:   Running the model on GPU After the successful run on CPU, I want to make use of hardware accelerati)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,DerEchteFeuerpfeil,I cannot run a transformer model with token-level output on accelerated hardware in TF Lite," Description of the issue Okay so to preface this, I have been working on this for over a month. My goal can be explained in one sentence: I want to run my small bertlike model with tokenlevel output on the GPU of my Android phone using the Interpreter API and the GPU delegate. The Task API does unfortunately not offer that. Please don't hesitate to reach out to me if you are missing any information to understand or reproduce this issue. I really want to get this working!  System Information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10  TensorFlow installed from (source or binary): binary  TensorFlow version (or github SHA if from source): 2.10.1  The model and the TF Lite conversion I want to use a simple BERTbased model to classify something on tokenlevel. The following code should get you an idea of the model:  After I created the model, I converted it to the TF Lite format with the following code:  The conversion output the following text:  But this did not bother me too much as these don't seem to be errors.  Running the model on Android with hardware acceleration To not introduce any errors from my side, I decided to use the prebuilt benchmarking app that TensorFlow provides. All the following adb commands are taken from that page. First, I installed the app and pushed my model to the phone, which is in my case, a Pixel 3a.   Running the model on CPU Then, I ran the model on the CPU to see if everything works:  and get the following output, where everything worked as expected:   Running the model on GPU After the successful run on CPU, I want to make use of hardware accelerati",2023-01-11T23:14:46Z,stat:awaiting tensorflower type:bug comp:lite TFLiteGpuDelegate TF 2.10,closed,7,13,https://github.com/tensorflow/tensorflow/issues/59232, please let me know when you're working on this. Also if you know of any working repositories where someone got this to work or if you got any other useful ressources please let me know,"This error is even easier to reproduce when using a precompiled model from the TFHub.  Updated (detailed) steps to reproduce 1. Download mobilebert from the tf hub 2. Connect Android mobile phone to computer in debugging mode, e.g. with Android Studio 3. (if not already done) Install official TF Lite benchmarking app 4. Copy model onto Android device: `adb push mobilebert_1_default_1.tflite /data/local/tmp` 5. Run the model on the phone using the TensorFlow lite benchmarking app and use the use_gpu=true flag: `adb shell am start S n org.tensorflow.lite.benchmark/.BenchmarkModelActivity es args '""graph=/data/local/tmp/mobilebert_1_default_1.tflite use_gpu=true""'` 6. Inspect error with either `adb logcat  grep ""tflite""` (Linux) At least with this I get more detailed error messages and actually some information about the operators that are not supported.  The error "," TensorFlow v2.10.0  onnx v1.13.0  MobileBERT I dared to try it by converting `tflite > ONNX > tflite`, thereby eliminating redundant processing. https://github.com/PINTO0309/onnx2tf The general problem seems to be casting to `INT64` and not supporting the `Gather` OP. It might work if the cast part from INT32 to INT64 could be eliminated from the model structure. Note that the behavior of onnx2tf must be changed using JSON because the tensor transposition is wrong in `MatMul` in `bert/embeddings/embedding_transformation/add`. !image  BTW, `GeLU`  ONNX gelu_11.onnx.zip !image `GeLU` to Primitive Layers  ONNX to tflite gelu.tflite.zip  !image `GeLU` could support GPU delegates.  Update MobileBERT seems to cause a lot of problems because the type of input is `INT32`. The `MatMul` in the Attention module cannot determine the correct dimensional placement with the tool, so the transposition is applied manually.  The inference results with dummy data from ONNX before conversion and tflite after conversion were almost identical. !image !image The following five types of operations are not supported by GPU delegates in MobileBERT. Especially the 5th error about `FullyConnected` is a fatal one, and I don't think it can be used unless `MatMul` is implemented for more than 3 inputs in GPU Delegate. Also, `Gather` needs to be replaced with `Slice` or some other OP.  The meaning of `GPU COMPATIBILITY WARNING: FullyConnected doesn't support more than 2 runtime inputs.` was that the three types of inputs, `input`, `weights`, and `bias`, are not supported by the GPU delegate, so the wording has been corrected.  !image Since it is very difficult to rewrite TFLite, it is a good idea to edit ONNX to remove unnecessary dimensions or add new OPs for dimensional compression before and after the problematic OPs before converting them to TFLite. Here I am committing to a set of tools that will allow me to make all kinds of modifications to ONNX. If you learn how to rewrite ONNX, you can probably avoid most runtimeside problems. https://github.com/PINTO0309/simpleonnxprocessingtools","Hi  ! Could you convert the transformer model with integer quantization with a  sample representative dataset, input and output inference type as int32 and let us know.  Would it be possible to share the Colab gist to replicate this issue. Thank you!","Update onnx2tf v1.5.23 to add `optimization_for_gpu_delegate`. After conversion, only the `Gather` and `SelectV2` OP is warn for GPU delegate unsupported. This improvement is focused on MobileBERT only, so other models may show different warnings. It may also be possible to run BERT using GPUs by simply replacing the `Gather` with some other primitive operation or by programmatically handling the part above the `Gather`.  !image Currently, warnings are only issued for the four OPs that are visible in the image above.  !image But unfortunately, I am not familiar enough with Android implementation to try it. If you have any good ideas for replacing `Gather` with another OP, please let me know. Incidentally, `SelectV2` is an additional OP that is always generated when `Gather` is generated, so if you can replace `Gather` with another OP, all warnings will disappear.  Update I removed `Gather`, `SelectV2` and it succeeded in erasing the GPU delegate warnings. The `Gather` of embeddings must be implemented programmatically.  converted files   https://s3.apnortheast2.wasabisys.com/tempmodels/tensorflow_59232/lite_model_mobilebert_1_metadata_1.zip !image `Your model looks compatibile with GPU delegate with TFLite runtime version 2.10.0.` !image !image"," does not seem to work when following the ""float fallback quantization"" tutorial on the link you provided. !image !image The specifcation of input and output type breaks it I think  here is a link to the colab I used for this: https://colab.research.google.com/drive/1eTCnWXmEginiHYQtoxgc9uEcVOUtktOD?usp=sharing"," Very interesting stuff you did! So you replaced the GATHER with primitive operations in ONNX and converted that to TensorFlow lite? I tried running both tflite models you provided in the .zip, but unfortunately they fail for me when running them on the benchmark app with GPU. See errors below. **model_float32.tflite:**  **model_float16.tflite:**  If you see what the problem here is, please let me know! I unfortunately am not familiar with ONNX, so debugging this is really difficult. Thanks for you work so far, this is all really insightful! It might has something to do with this part of the graph: !image Since the errors state that the ""(CONCATENATION) failed to prepare"" and ""(384 != 383)""",">Very interesting stuff you did! So you replaced the GATHER with primitive operations in ONNX and converted that to TensorFlow lite? No. The company is not a member of the National Association of Schools and Colleges of America. For now, I couldn't come up with a good idea to replace `Gather` with a primitive OP, so I removed only `Gather` from the model at once. By the way, I do not understand why this error occurs. The error is occurring even though a `Concatenation` of size `383` should not exist in the model. :thinking:   !image  `test_bert.py`       There seems to be a problem with the `Concatenation` behavior in the TensorFlow Lite runtime, so I regenerated the model with the `Concatenation` removed and checked the behavior. Result is good. Successful inference.  new models https://s3.apnortheast2.wasabisys.com/tempmodels/tensorflow_59232/lite_model_mobilebert_1_metadata_1_cut_gather_cocat.zip !image      !image There appears to be a problem with `tensorflow/lite/kernels/concatenation.cc`. In my experience, the TensorFlow team seems to be busy and may not be able to address the issue of `concatenation` behavior.  Can you please test using GPU Delegate?"," we are getting close haha, it works on my android phone using the CPU:  But GPU fails with this:  I think the important error message here is . ","`TfLiteGpuDelegate Init: STRIDED_SLICE: Output batch don't match` I could not read from the text which OP this error message refers to. The error message is too confusing. ""Do not slice the first dimension."" If this is the case, GPU Delegate seems to be a very difficult mechanism to use. In fact, I recently succeeded in replacing `Gather` with `StridedSlice`, `Reshape` and `Concatenation`, but the constraints of `StridedSlice` were too many for GPU Delegate to be useful. GPU Delegate seems to have the advantage of being crossplatform, but with so many limitations, I believe most models cannot be reasoned with properly. The `StridedSlice` problem appears to be too challenging beyond the level that can be managed by tuning the model alone. I am frustrated because I was so close. :crying_cat_face:  If your immediate goal is to use the Android GPU, why not try NNAPI once? It appears that `Gather`, `StridedSlice` and `Where` are all supported. 1. https://www.tensorflow.org/lite/android/delegates/nnapi 2. https://developer.android.com/ndk/guides/neuralnetworksoperations  `StridedSlice`   !image  `Gather` replace   "," I unfortunately cannot provide more detail on that error message as this is the only output I have.  NNAPI related We have tried NNAPI. When checking different models with the benchmmarking app, I get different errors on my Pixel 3a phone. I will post some examples here. Our bertencoderonly model:  When running your ""model_float32.tflite"", I get the following errors:  When running a quantized mobilebert, I get the following error:  These errors made us curious if it was even worth it trying to fix them, so we tried the TFLite Task API with this example app to see what speedup is even possible. When we ran the examples, running mobilebert with NNAPI was on average 4x  10x slower (depends on the specific mobile phone model) than using the CPU... that is why we hoped GPU inference might bring a speedup. So overall, it's a really frustrating developer experience. I can't believe that it is that hard (or impossible) to get an encoderonly transformer to run on accelerated mobile hardware. What a pain.  Note to you, PINTO Thank you so much for your effort, I really appreciate that you took the time for this. You helped me understand much more about GPU compatibility, even though the outcome might not be satisfying. If there is anything else I can do or should try, let me know. Otherwise let's hope that the tensorflow people can give me some answers and/or directions..","Hi , Thanks for raising this issue. Are you aware of the migration to LiteRT? This transition is aimed at enhancing our project's capabilities and providing improved support and focus for our users. As we believe this issue is still relevant to LiteRT we are moving your issue there. Please follow progress here. Let us know if you have any questions. Thanks.",Are you satisfied with the resolution of your issue? Yes No
691,"以下是一个github上的tensorflow下的一个issue, 标题是(Movinet Colab 'TypeError')， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.2  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Cdukes30,Movinet Colab 'TypeError',Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.2  Custom Code No  OS Platform and Distribution _No response_  Mobile device _No response_  Python version 3.9.16  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-01-11T20:07:59Z,stat:awaiting response type:build/install stale comp:model TF 2.9,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59231,,"  I was able to import the  `movinet` from `official.projects.movinet.modeling` using the stable versions of tfmodelsofficial and tensorflow_datasets on colab, please find the gist here and let us know if the issue persists. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1894,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.debugging.enable_check_numerics() doesn't work with XLA JIT compilation)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA=11.7 CUDNN=8.5.0.961  GPU model and memory Tesla T4  Current Behaviour?  shell import numpy as np import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers tf.debugging.enable_check_numerics()  https://keras.io/examples/vision/mnist_convnet/ num_classes = 10 input_shape = (28, 28, 1) (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.astype(""float32"") / 255 x_test = x_test.astype(""float32"") / 255 x_train = np.expand_dims(x_train, 1) x_test = np.expand_dims(x_test, 1) y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) model = keras.Sequential(     [         keras.Input(shape=input_shape),         layers.Conv2D(32, kernel_size=(3, 3), activation=""relu""),         layers.MaxPooling2D(pool_size=(2, 2)),         layers.Conv2D(64, kernel_size=(3, 3), activation=""relu""),         layers.MaxPooling2D(pool_size=(2, 2)),         layers.Flatten(),         layers.Dropout(0.5),         layers.Dense(num_classes, activation=""softmax""),     ] ) batch_size = 128 epochs = 15 model.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""], jit_compile=True) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1) s)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,JonasAmrich,tf.debugging.enable_check_numerics() doesn't work with XLA JIT compilation,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA=11.7 CUDNN=8.5.0.961  GPU model and memory Tesla T4  Current Behaviour?  shell import numpy as np import tensorflow as tf from tensorflow import keras from tensorflow.keras import layers tf.debugging.enable_check_numerics()  https://keras.io/examples/vision/mnist_convnet/ num_classes = 10 input_shape = (28, 28, 1) (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.astype(""float32"") / 255 x_test = x_test.astype(""float32"") / 255 x_train = np.expand_dims(x_train, 1) x_test = np.expand_dims(x_test, 1) y_train = keras.utils.to_categorical(y_train, num_classes) y_test = keras.utils.to_categorical(y_test, num_classes) model = keras.Sequential(     [         keras.Input(shape=input_shape),         layers.Conv2D(32, kernel_size=(3, 3), activation=""relu""),         layers.MaxPooling2D(pool_size=(2, 2)),         layers.Conv2D(64, kernel_size=(3, 3), activation=""relu""),         layers.MaxPooling2D(pool_size=(2, 2)),         layers.Flatten(),         layers.Dropout(0.5),         layers.Dense(num_classes, activation=""softmax""),     ] ) batch_size = 128 epochs = 15 model.compile(loss=""categorical_crossentropy"", optimizer=""adam"", metrics=[""accuracy""], jit_compile=True) model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1) s",2023-01-10T14:12:55Z,stat:awaiting response type:bug stale comp:xla TF 2.11,closed,0,12,https://github.com/tensorflow/tensorflow/issues/59215,", I was able to reproduce the issue on tensorflow v2.9, v2.11 and tfnightly. Kindly find the gist of it here.","Hi, As the error suggests:  `on XLA_GPU_JIT: DebugNumericSummaryV2 (No registered 'DebugNumericSummaryV2' OpKernel for XLA_GPU_JIT devices compatible with node {{node DebugNumericSummaryV2}}){{node DebugNumericSummaryV2}}` it is unimplemented for `tf.debugging.enable_check_numerics()` for `XLA JIT`. Currently we don't have wide support of XLA JIT across all the APIs.  We will consider this request to add support in our future implementation. Thanks!"," Thanks for this confirmation. The situation is a bit unfortunate as keras optimizers are JIT compiled by default (sice 3ad70f6cab8912860abb1b94c004e84b1114a6f7) and check_numerics therefore doesn't work out of the box on GPU. The workaround (explicitly disabling jit_compile on optimizer) is straightforward, however it took me some time to realize.. Would it make sense to add a note to docs?",", any ideas? As `tf.function(jit_compile=True)` is used in more places in both user code and Keras, it will become increasingly infeasible for users to use `enable_check_numerics`, as doing so will cause an error as long as any jitcompiled tf.function is created. Perhaps we should not insert the check numerics ops in jitcompiled tf.functions, although it would be bad to silently change behavior if a tf.function is jitcompiled.  would it be possible to support `enable_check_numerics` in XLA? Could the bridge insert a custom calls after each op that would check for infs/nan, put the result of the check in a boolean, transfer the bool to the CPU, and raise an error if it's true? Of course this would be very very slow and effectively disable fusions.","> would it be possible to support enable_check_numerics in XLA? Yes. We don't even need customcalls: can do with ifstatements. > Of course this would be very very slow and effectively disable fusions But then you are changing numerics, at which point you might as well disable XLA compilation entirely? What is the goal of using enable_check_numerics? Is it to check the algorithm, or to check TF implementation?","The goal of enable_check_numerics is to debug where Inf/Nan values are coming from, by causing an error be thrown the first time any TF op has an output which is Inf or Nan. Even without XLA, enable_check_numerics can slightly change numerics due to difference in Grappler optimizations. I'm guessing the numeric difference doesn't cause issues in practice. > Yes. We don't even need customcalls: can do with ifstatements. How can this be done with XLA today? How do you raise an error in HLO?","A customcall can return a bad Status, which will be propagated at runtime. But yes then, customcalls will be required.","Just to be clear, this is still an open issue right? There's no way to be running utilizing GPUs while executing this line:   I have tried to utilize `tf.config.set_soft_device_placement(True)` but that didn't work for me as well.  The scenario is that my training only falls into Nans at the later stages and I'd 1) love to investigate using the tensorboard logs and 2) need that level of training","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1307,"以下是一个github上的tensorflow下的一个issue, 标题是(Is there any way to modify the quantized parameters from the generated tflite model?)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu  TensorFlow installation (pip package or built from source): 2.11.0  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code def representative_data_gen():   for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):     yield [input_value] converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_data_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] tflite_model_quant = converter.convert() I used the above code to generate a fully quantized tflite model. However, all the quantization parameters are set by default so the final accuracy of the tflite mode is a little bit low. So I wonder is there any way to rewrite the quantization parameters by myself. Since the integer numbers are stored in the tflite model, I can not modify them easily.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,penny9287,Is there any way to modify the quantized parameters from the generated tflite model?," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu  TensorFlow installation (pip package or built from source): 2.11.0  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code def representative_data_gen():   for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):     yield [input_value] converter = tf.lite.TFLiteConverter.from_keras_model(model) converter.optimizations = [tf.lite.Optimize.DEFAULT] converter.representative_dataset = representative_data_gen converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] tflite_model_quant = converter.convert() I used the above code to generate a fully quantized tflite model. However, all the quantization parameters are set by default so the final accuracy of the tflite mode is a little bit low. So I wonder is there any way to rewrite the quantization parameters by myself. Since the integer numbers are stored in the tflite model, I can not modify them easily.",2023-01-10T11:57:02Z,stat:awaiting response type:support stale comp:lite TFLiteConverter TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59214,"Hi  ! You can use use tfl.quantization_debugger to disable quantization of layers which might be hindering the improvement /accuracy of lite model. Alternatively , You can opt for Quantization aware training through model optimization (annotate the layer with tfmot api) which can be disabled later through quantization debugger. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
881,"以下是一个github上的tensorflow下的一个issue, 标题是(Failure to compile on PPC due to Eigen incompatibility)， 内容是 ( Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.1  Current Behaviour? Compiling TensorFlow from source yields:   See my issue in Eigen: https://gitlab.com/libeigen/eigen//merge_requests/764note_1231907378  Standalone code to reproduce the issue Compile TensorFlow on PPC/POWER9 The issue is that the specialized `TensorContractionInputMapper` in `eigen_spatial_convolutionsinl.h` (at master at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tsl/framework/convolution/eigen_spatial_convolutionsinl.h) is missing the new `load` functions as required by Eigen)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,Flamefire,Failure to compile on PPC due to Eigen incompatibility, Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.9.1  Current Behaviour? Compiling TensorFlow from source yields:   See my issue in Eigen: https://gitlab.com/libeigen/eigen//merge_requests/764note_1231907378  Standalone code to reproduce the issue Compile TensorFlow on PPC/POWER9 The issue is that the specialized `TensorContractionInputMapper` in `eigen_spatial_convolutionsinl.h` (at master at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tsl/framework/convolution/eigen_spatial_convolutionsinl.h) is missing the new `load` functions as required by Eigen,2023-01-10T09:13:34Z,stat:awaiting tensorflower type:build/install TF 2.9,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59212,Seems to be fixed in 2.10.1 either by a change in TensorFlow or the updated Eigen,Are you satisfied with the resolution of your issue? Yes No
1898,"以下是一个github上的tensorflow下的一个issue, 标题是([macos-arm64] //tensorflow/core/kernels:conv_ops_test_cpu  fail in macOS Arm64)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf nightly  Custom Code Yes  OS Platform and Distribution macOS Monterey 12.4, Arm64  Mobile device _No response_  Python version 3.9.9  Bazel version 5.3.0  GCC/Compiler version Clang from Xcode 13.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? ```shell INFO: From Testing //tensorflow/core/kernels:conv_ops_test_cpu: ==================== Test output for //tensorflow/core/kernels:conv_ops_test_cpu: [==========] Running 67 tests from 7 test suites. [] Global test environment setup. [] 25 tests from FusedResizePadConvOpTest [ RUN      ] FusedResizePadConvOpTest.HandwrittenConvHalf tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (105 not close to 84) Expected: true i = 0 Tx[i] = 105 Ty[i] = 84 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (150 not close to 128) Expected: true i = 1 Tx[i] = 150 Ty[i] = 128 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (183 not close to 160) Expected: true i = 2 Tx[i] = 183 Ty[i] = 160 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (95 not close to 86) Expected: true i = 3 Tx[i] = 95 Ty[i] = 86 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_a)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,nitins17,[macos-arm64] //tensorflow/core/kernels:conv_ops_test_cpu  fail in macOS Arm64,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf nightly  Custom Code Yes  OS Platform and Distribution macOS Monterey 12.4, Arm64  Mobile device _No response_  Python version 3.9.9  Bazel version 5.3.0  GCC/Compiler version Clang from Xcode 13.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? ```shell INFO: From Testing //tensorflow/core/kernels:conv_ops_test_cpu: ==================== Test output for //tensorflow/core/kernels:conv_ops_test_cpu: [==========] Running 67 tests from 7 test suites. [] Global test environment setup. [] 25 tests from FusedResizePadConvOpTest [ RUN      ] FusedResizePadConvOpTest.HandwrittenConvHalf tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (105 not close to 84) Expected: true i = 0 Tx[i] = 105 Ty[i] = 84 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (150 not close to 128) Expected: true i = 1 Tx[i] = 150 Ty[i] = 128 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (183 not close to 160) Expected: true i = 2 Tx[i] = 183 Ty[i] = 160 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_atol, typed_rtol)   Actual: false (95 not close to 86) Expected: true i = 3 Tx[i] = 95 Ty[i] = 86 tensorflow/core/framework/tensor_testutil.cc:184: Failure Value of: IsClose(Tx[i], Ty[i], typed_a",2023-01-10T00:04:13Z,stat:awaiting tensorflower type:bug subtype:macOS,closed,0,2,https://github.com/tensorflow/tensorflow/issues/59208,This is now fixed at head so closing this issue!,Are you satisfied with the resolution of your issue? Yes No
933,"以下是一个github上的tensorflow下的一个issue, 标题是([macos-arm64] //tensorflow/python:nn_batchnorm_test_cpu fails in macos Arm64)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf nightly  Custom Code Yes  OS Platform and Distribution macOS Monterey 12.4, Arm64  Mobile device _No response_  Python version 3.9.9  Bazel version 5.3.0  GCC/Compiler version Clang from Xcode 13.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  shell Run `bazel bazelrc=""macos.bazelrc"" test //tensorflow/python:nn_batchnorm_test_cpu` from the TensorFlow root directory.  Bazel configs I used are in https://gist.github.com/nitins17/73e0818b3a6bec240775c2619540a979 ```  Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,nitins17,[macos-arm64] //tensorflow/python:nn_batchnorm_test_cpu fails in macos Arm64,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version tf nightly  Custom Code Yes  OS Platform and Distribution macOS Monterey 12.4, Arm64  Mobile device _No response_  Python version 3.9.9  Bazel version 5.3.0  GCC/Compiler version Clang from Xcode 13.4  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?  shell Run `bazel bazelrc=""macos.bazelrc"" test //tensorflow/python:nn_batchnorm_test_cpu` from the TensorFlow root directory.  Bazel configs I used are in https://gist.github.com/nitins17/73e0818b3a6bec240775c2619540a979 ```  Relevant log output _No response_",2023-01-09T23:55:48Z,stat:awaiting response type:build/install stale subtype:macOS subtype:bazel,closed,0,5,https://github.com/tensorflow/tensorflow/issues/59206,"  , this issue is a numpy issue. We don't have `float128` support for M1. We can skip this test till numpy adds that support.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
714,"以下是一个github上的tensorflow下的一个issue, 标题是(Check failure when running tensorflow.python.ops.gen_nn_ops.max_pool)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue    Relevant log output  ``` )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Check failure when running tensorflow.python.ops.gen_nn_ops.max_pool,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue    Relevant log output  ``` ,2023-01-09T20:16:12Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59197,", While trying to execute the mentioned code on tensorflow v2.10 and 2.11, I was able to reproduce the issue whereas on  **tfnightly**, I was facing a different error. Kindly find the gist of it here. Thank you!","Thanks for reporting the issue, we will investigate further on check failure and crash. Meanwhile, when you provide explicit_paddiing as input, you need to change the `padding ='EXPLICIT'` instead of `padding = 'VALID'` After above mentioned changes, the expected error can be seen.  **Error:explicit_paddings attribute must contain 8 values, but got: 0 [Op:MaxPool]**",toplay ,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1098,"以下是一个github上的tensorflow下的一个issue, 标题是(Crash when running gen_nn_ops.max_pool)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230109 11:10:47.659984: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:958] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0) Aborted  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Crash when running gen_nn_ops.max_pool,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230109 11:10:47.659984: F tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:958] Check failed: cudnnSetPoolingNdDescriptor( handle_.get(), (pooling_descriptor.mode() == dnn::PoolingMode::kMaximum ? cudnn_max_pooling_mode : CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING), propagate_nans ? CUDNN_PROPAGATE_NAN : CUDNN_NOT_PROPAGATE_NAN, nd, shape.data(), padding.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0) Aborted  ",2023-01-09T16:12:43Z,stat:awaiting response type:bug stale comp:ops comp:gpu TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59191,"Hi  ! Thanks for sharing your observation w.r.to Ubuntu22 and gen_nn_ops.max_pool . But I am getting a different error in both Colab 2.11 (CPU) and Ubuntu22 (GPU) after following steps in this comment. `Error:{{function_node __wrapped__MaxPool_device_/job:localhost/replica:0/task:0/device:CPU:0}} Sliding window ksize for dimension 1 was zero. [Op:MaxPool]` Ubuntu22 GCP for 2.11 GPU , Colab runtime is Crashing  if GPU is not mentioned in tf.device() (as you mentioned in template) Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1331,"以下是一个github上的tensorflow下的一个issue, 标题是(Illegal memory access when running gen_math_ops.dense_bincount)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__DenseBincount_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input arr must be nonnegative! [Op:DenseBincount] Error:{{function_node __wrapped__DenseBincount_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input arr must be nonnegative! [Op:DenseBincount] 20230109 11:04:45.833405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered 20230109 11:04:45.833428: F tensorflow/core/common_runtime/device/device_event_mgr.cc:221] Unexpected Event status: 1 Aborted  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Illegal memory access when running gen_math_ops.dense_bincount,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__DenseBincount_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input arr must be nonnegative! [Op:DenseBincount] Error:{{function_node __wrapped__DenseBincount_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input arr must be nonnegative! [Op:DenseBincount] 20230109 11:04:45.833405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered 20230109 11:04:45.833428: F tensorflow/core/common_runtime/device/device_event_mgr.cc:221] Unexpected Event status: 1 Aborted  ,2023-01-09T16:09:56Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59190,  I was able to execute the given code without crashing or Aborted on Colab using TF v2.11 and TFnightly. Could you please find the gist of TFv2.11 and tfnightly for reference. Thank you!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1887,"以下是一个github上的tensorflow下的一个issue, 标题是( traied model with tensorflow on transformer pipeline pop out error)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? i’m using this github text summarization and I have a problem. I have been struggling for two week and I could not figure that out. im using a notebook from this github repository: https://github.com/flogothetis/AbstractiveSummarizationT5Keras notebook link: https://github.com/flogothetis/AbstractiveSummarizationT5Keras/blob/main/AbstractiveSummarizationT5.ipynb after train model i wanna use huggingface transformer pipe line to generate summerization **from transformers import pipeline summarizer = pipeline(“summarization”, model=model, tokenizer=“t5small”, framework=“tf”) summarizer(“some text”)** but it pop out an error: **AttributeError: ‘Functional’ object has no attribute 'config’** Anyone has any idea how can i solve it? full error: AttributeError Traceback (most recent call last) /tmp/ipykernel_20/1872405895.py in > 1 summarizer = pipeline(“summarization”, model=model, tokenizer=“t5small”, framework=“tf”) 2 3 summarizer(“The US has passed the peak on new coronavirus cases, President Donald Trump said and predicted that some states would reopen”) /opt/conda/lib/python3.7/sitepackages/transformers/pipelines/init.py in pipeline(task, model, config, tokenizer, framework, revision, use_fast, use_auth_token, model)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",text generation,danial1995, traied model with tensorflow on transformer pipeline pop out error,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.8  Custom Code Yes  OS Platform and Distribution _No response_  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour? i’m using this github text summarization and I have a problem. I have been struggling for two week and I could not figure that out. im using a notebook from this github repository: https://github.com/flogothetis/AbstractiveSummarizationT5Keras notebook link: https://github.com/flogothetis/AbstractiveSummarizationT5Keras/blob/main/AbstractiveSummarizationT5.ipynb after train model i wanna use huggingface transformer pipe line to generate summerization **from transformers import pipeline summarizer = pipeline(“summarization”, model=model, tokenizer=“t5small”, framework=“tf”) summarizer(“some text”)** but it pop out an error: **AttributeError: ‘Functional’ object has no attribute 'config’** Anyone has any idea how can i solve it? full error: AttributeError Traceback (most recent call last) /tmp/ipykernel_20/1872405895.py in > 1 summarizer = pipeline(“summarization”, model=model, tokenizer=“t5small”, framework=“tf”) 2 3 summarizer(“The US has passed the peak on new coronavirus cases, President Donald Trump said and predicted that some states would reopen”) /opt/conda/lib/python3.7/sitepackages/transformers/pipelines/init.py in pipeline(task, model, config, tokenizer, framework, revision, use_fast, use_auth_token, model",2023-01-08T23:49:06Z,stat:awaiting response type:bug stale TF 2.8,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59167,", This issue is not related to tensorflow repository. Please try to raise the request in this repo for the better assistance. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
905,"以下是一个github上的tensorflow下的一个issue, 标题是(BUILD:tensorflow/compiler/mlir/quantization/tensorflow/debugging/mlir_dump.cc:93:10: error: could not convert 'dump_file' from 'std::unique_ptr<llvm::raw_fd_ostream>' to 'absl::lts_20220623::StatusOr<std::unique_ptr<llvm::raw_fd_ostream> >')， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version master  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.6  Bazel version 5.3.0  GCC/Compiler version gcc (Ubuntu 7.5.03ubuntu1~18.04) 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,yanghesong,BUILD:tensorflow/compiler/mlir/quantization/tensorflow/debugging/mlir_dump.cc:93:10: error: could not convert 'dump_file' from 'std::unique_ptr<llvm::raw_fd_ostream>' to 'absl::lts_20220623::StatusOr<std::unique_ptr<llvm::raw_fd_ostream> >',Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version master  Custom Code Yes  OS Platform and Distribution Linux Ubuntu 18.04  Mobile device _No response_  Python version 3.6  Bazel version 5.3.0  GCC/Compiler version gcc (Ubuntu 7.5.03ubuntu1~18.04) 7.5.0  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-08T04:53:48Z,stat:awaiting response type:bug type:build/install stale subtype: ubuntu/linux TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59165," , Could you please check the attached tested configurations here for LinuxCPU & LinuxGPU for building from Source.  1. You must update to Python version to any of 3.73.10 versions 2. GCC should be 9.3.1 Updating the above might resolve your issue. Please try this and if still problem persists please let us know.",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,邮件已收到！," , I replicated the same error reported by you with Ubuntu18 default gcc(7.5) and python(3.6) versions.  I have upgraded gcc to 9.4v and python to 3.9v and build is success.Please refer to attached snapshot below. "
1882,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation fault when running gen_nn_ops.fractional_avg_pool)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   shell 20230107 13:44:10.489552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230107 13:44:10.493914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230107 13:44:10.494017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230107 13:44:10.494307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230107 13:44:10.494924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning N)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Segmentation fault when running gen_nn_ops.fractional_avg_pool,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   shell 20230107 13:44:10.489552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230107 13:44:10.493914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230107 13:44:10.494017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning NUMA node zero 20230107 13:44:10.494307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performancecritical operations:  AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 20230107 13:44:10.494924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (1), but there must be at least one NUMA node, so returning N",2023-01-07T18:47:38Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59163,", I tried to execute the mentioned code and the issue was fixed in the latest stable v2.11 and nightly. Kindly find the gist of it here.","> , I tried to execute the mentioned code and the issue was fixed in the latest stable v2.11 and nightly. Kindly find the gist of it here. Thanks for the consideration.",", As it was the bug on tensorflow v2.10, it has been resolved on the latest stable tensorflow v2.11 where we can observe that Segfault error has not been raised. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Also this one: ,> Also this one: >  >  This issue was already tracking with CC(Double free when running tensorflow.python.ops.gen_nn_ops.fractional_avg_pool). And the initial issue for Segmentation fault was not able to reproduce in tf v2.11 as mentioned in the above comment. !image  Kindly find the gist of it here where we can observe that Segfault error has not been raised and executed with error **pooling_ratio cannot be smaller than 1** which were due to  seed = 87654321 and  seed2 = 341261001. Thank you!,Looks like an issue on cleanup side. toplay ,"Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The code snippet provided has returned the error which is catch through the exception, and doesn't crash with latest TensorFlow version. Please find the gist here. The TensorFlow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
762,"以下是一个github上的tensorflow下的一个issue, 标题是([AMD-ZENDNN] Code changes to support TF-Plugin for AMD CPU Inference)， 内容是 (With this code change we introduce, Zen layout pass to rewrite supported ops with ZenOps. All code changes are under AMD_ZENDNN flag which is enabled for linux builds only. Authors:   Aakar Dwivedi ( aakar.dwivedi.com )   Aditya Chatterjee ( aditya.chatterjee.com )   Arun Coimbatore Ramachandran ( aruncoimbatore.ramachandran.com )   AvinashChandra Pandey ( avinashchandra.pandey.com )   Chandra Kumar Ramasamy ( chandrakumar.ramasamy.com )   Savan Anadani ( savan.anadani.com ) Signedoffby: Aakar Dwivedi )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",chat,aadwived,[AMD-ZENDNN] Code changes to support TF-Plugin for AMD CPU Inference,"With this code change we introduce, Zen layout pass to rewrite supported ops with ZenOps. All code changes are under AMD_ZENDNN flag which is enabled for linux builds only. Authors:   Aakar Dwivedi ( aakar.dwivedi.com )   Aditya Chatterjee ( aditya.chatterjee.com )   Arun Coimbatore Ramachandran ( aruncoimbatore.ramachandran.com )   AvinashChandra Pandey ( avinashchandra.pandey.com )   Chandra Kumar Ramasamy ( chandrakumar.ramasamy.com )   Savan Anadani ( savan.anadani.com ) Signedoffby: Aakar Dwivedi ",2023-01-06T16:54:36Z,awaiting review ready to pull size:XL comp:core,closed,0,11,https://github.com/tensorflow/tensorflow/issues/59137,/ ,> I have one (hopefully) last batch of comments. Thank you for your patience! Thank you for such detailed effort in reviewing the code. We have addressed your comments., Could you please help fix buildifier formatting errors? Thank you!  (Load rules and dependency targets needs to be sorted alphabetically.),Thank you for the quick review and approval  . We have fixed the errors mentioned in buildifier formatting errors link.,"Hello  , Thank you again for all your effort and patience! Apologies for an additional commit. Other than alphabetic ordering two indentation errors were also fixed. Can you kindly approve once more?",ARM CI has 6 failed tests and 1 test timed out.  https://github.com/tensorflow/tensorflow/commit/a35dac30a05bfb6668444357c79413c60bdbf1aa also failed the same 6 tests and has the same timed out test. So I think this is unrelated to this PR. ,"Hello  , Yes, you are right this issue is not related to this PR. We observed same issue in other PRs as well. Thank you!",Just a heads up that this PR caused a segfault in an internal test. I'm taking a look.,"> Just a heads up that this PR caused a segfault in an internal test. I'm taking a look. Hi , thank you for the heads up. We request for any detail/direction that could help us to know more about this issue and resolve it.", Thank you for offering! I've resolved the issue internally. The PR is now merged. :), Thank you for resolving the issue internally and get this PR merged. Thanks again for your meticulous reviews and patience.
1902,"以下是一个github上的tensorflow下的一个issue, 标题是(Check failure when running tensorflow.python.ops.gen_array_ops.matrix_diag_part_v3)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagPartV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} input must be at least 2dim, received shape: [0] [Op:MatrixDiagPartV3] Error:Cannot convert 44.0 to EagerTensor of dtype int32 Error:can't convert negative int to unsigned Error:Value for attr 'align' of ""sum"" is not in the list of allowed values: ""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT"" 	; NodeDef: {{node MatrixDiagPartV3}}; Op diagonal:T; attr=T:type; attr=align:string,default=""RIGHT_LEFT"",allowed=[""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT""]> [Op:MatrixDiagPartV3] Error:Value for attr 'align' of """" is not in the list of allowed values: ""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT"" 	; NodeDef: {{node MatrixDiagPartV3}}; Op diagonal:T; attr=T:type; attr=align:string,default=""RIGHT_LEFT"",allowed=[""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT""]> [Op:MatrixDiagPartV3] Error:Value for attr 'align' of ""zeros"" is not in the list of allowed values: ""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT"" 	; NodeDef: {{node MatrixDiagPartV3}}; Op diagonal:T; attr=T:type; attr=align:string,default=""RIGHT_LEFT"",allowed=[""LEFT_RIGHT"", ""RIGHT_LE)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Check failure when running tensorflow.python.ops.gen_array_ops.matrix_diag_part_v3,"Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution Ubuntu 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell Error:{{function_node __wrapped__MatrixDiagPartV3_device_/job:localhost/replica:0/task:0/device:CPU:0}} input must be at least 2dim, received shape: [0] [Op:MatrixDiagPartV3] Error:Cannot convert 44.0 to EagerTensor of dtype int32 Error:can't convert negative int to unsigned Error:Value for attr 'align' of ""sum"" is not in the list of allowed values: ""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT"" 	; NodeDef: {{node MatrixDiagPartV3}}; Op diagonal:T; attr=T:type; attr=align:string,default=""RIGHT_LEFT"",allowed=[""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT""]> [Op:MatrixDiagPartV3] Error:Value for attr 'align' of """" is not in the list of allowed values: ""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT"" 	; NodeDef: {{node MatrixDiagPartV3}}; Op diagonal:T; attr=T:type; attr=align:string,default=""RIGHT_LEFT"",allowed=[""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT""]> [Op:MatrixDiagPartV3] Error:Value for attr 'align' of ""zeros"" is not in the list of allowed values: ""LEFT_RIGHT"", ""RIGHT_LEFT"", ""LEFT_LEFT"", ""RIGHT_RIGHT"" 	; NodeDef: {{node MatrixDiagPartV3}}; Op diagonal:T; attr=T:type; attr=align:string,default=""RIGHT_LEFT"",allowed=[""LEFT_RIGHT"", ""RIGHT_LE",2023-01-06T14:24:30Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59134, Could you please have a look at this gist and confirm that it is not replicating in the latest tfnightly? Thank you!,This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
860,"以下是一个github上的tensorflow下的一个issue, 标题是(Check failure when running tensorflow.python.ops.gen_array_ops.matrix_diag_part_v3 when feeding input empty tensor)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230105 21:40:09.377252: F ./tensorflow/python/eager/pywrap_tensor_conversion.h:58] Check failed: !PyErr_Occurred()  Aborted  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Check failure when running tensorflow.python.ops.gen_array_ops.matrix_diag_part_v3 when feeding input empty tensor,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230105 21:40:09.377252: F ./tensorflow/python/eager/pywrap_tensor_conversion.h:58] Check failed: !PyErr_Occurred()  Aborted  ,2023-01-06T02:42:30Z,stat:awaiting response type:bug stale comp:ops TF 2.10,closed,0,10,https://github.com/tensorflow/tensorflow/issues/59122,", I was able to execute the mentioned code on tensorflow v2.11 ( both cpu & gpu ) and was able to execute without any issue/error and the output was also as expected. Kindly find the gist of it here.  Could you please take a look at this https://github.com/tensorflow/tensorflow/issues/59350issuecomment1399378528 from the developer where it was suggested that the invalid inputs will leads to the custom error. The tf.uint64 dtype expects positive input and throws an error for the other types. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,"> , I was able to execute the mentioned code on tensorflow v2.11 ( both cpu & gpu ) and was able to execute without any issue/error and the output was also as expected. Kindly find the gist of it here. Thank you! Thanks. ",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.," https://github.com/tensorflow/tensorflow/issues/59350issuecomment1399378528 does not apply. That comment was about user receiving a valid Python error, whereas here (and in several places where the same canned response was used) the user sees the Python process crashing. CC toplay",", I was able to reproduce the issue on tensorflow v2.11 and nightly and the error was Python process crashing. Kindly find the gist of it here.",  I tried to execute the mentioned code with tensorflow V2.17 and observed that Python process crashing is not occurring. Kindly refer the gist here,This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
738,"以下是一个github上的tensorflow下的一个issue, 标题是(Segmentation fault when running gen_ragged_array_ops.ragged_cross)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell The only log message is: Segmentation fault  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Segmentation fault when running gen_ragged_array_ops.ragged_cross,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.10.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version _No response_  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell The only log message is: Segmentation fault  ,2023-01-05T22:32:39Z,stat:awaiting tensorflower type:bug comp:ops TF 2.10,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59114,", **gen_ragged_array_ops.ragged_cross** is the generated OP wrapper.  I tried to execute the code with the alternative approach and it was working as expected. Kindly find the gist of it here and also please take a look at the high level api of gen_ragged_array_ops.ragged_cross from the doc link1 and link2 for the reference. Thank you!","> , **gen_ragged_array_ops.ragged_cross** is the generated OP wrapper. I tried to execute the code with the alternative approach and it was working as expected. Kindly find the gist of it here and also please take a look at the high level api of gen_ragged_array_ops.ragged_cross from the doc link1 and link2 for the reference. Thank you! Thanks. I get segfault when running from my terminal, ubuntu 22.04: !Screenshot from 20230106 085014",", I was able to reproduce the issue on tensorflow v2.10, v2.11 and nightly. Kindly find the gist of it here.","> , I was able to reproduce the issue on tensorflow v2.10, v2.11 and nightly. Kindly find the gist of it here. Also this one: ",toplay ,Added a PR CC(Segmentation fault when running gen_ragged_array_ops.ragged_cross) for the fix.,Are you satisfied with the resolution of your issue? Yes No
773,"以下是一个github上的tensorflow下的一个issue, 标题是(Random error after hundreds of iterations: Aborting RingReduce with Invalid argument: Incompatible shapes: [0,64] vs. [0,256])， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tensorflowrocm 2.2  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version ROCm v3.5  GPU model and memory 2 RX 480 4Go  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",agent,hugo-mrc,"Random error after hundreds of iterations: Aborting RingReduce with Invalid argument: Incompatible shapes: [0,64] vs. [0,256]",Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tensorflowrocm 2.2  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version ROCm v3.5  GPU model and memory 2 RX 480 4Go  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-05T10:05:11Z,stat:awaiting response type:bug comp:dist-strat comp:keras TF 2.2,closed,0,16,https://github.com/tensorflow/tensorflow/issues/59104,"Other exemple below at t=385: 20230105 12:40:34.394719: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Invalid argument: Input to reshape is a tensor with 1 values, but the requested shape has 64 	 [[{{node gradient_tape/mean_squared_error/Reshape}}]] 	 [[div_no_nan/allreduce/CollectiveReduce/_294]]","The issue is probably related to synchronized computing because when running with: `mirrored_strategy = tf.distribute.MirroredStrategy(devices=[""/gpu:1""])` the program doesn't appear to crash ever. Tried as well with 2 GPUs with `tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())` but this caused the same error previously described","Just happened with one GPU, I can confirm it's not related to mirroring Traceback (most recent call last):   File ""main.py"", line 224, in      trader.batch_train(batch_size)   File ""main.py"", line 92, in batch_train     self.model.fit(state, target, epochs=1, verbose=0, callbacks=[tensorboard])   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper     return method(self, *args, **kwargs)   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/keras/engine/training.py"", line 848, in fit     tmp_logs = train_function(iterator)   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/def_function.py"", line 580, in __call__     result = self._call(*args, **kwds)   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/def_function.py"", line 611, in _call     return self._stateless_fn(*args, **kwds)   pylint: disable=notcallable   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/function.py"", line 2420, in __call__     return graph_function._filtered_call(args, kwargs)   pylint: disable=protectedaccess   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/function.py"", line 1661, in _filtered_call     return self._call_flat(   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/function.py"", line 1745, in _call_flat     return self._build_call_outputs(self._inference_function.call(   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/function.py"", line 593, in call     outputs = execute.execute(   File ""/home/hugo/Documents/scripts/blackstone_ai/venv/lib/python3.8/sitepackages/tensorflow/python/eager/execute.py"", line 59, in quick_execute     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name, tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.   (0) Invalid argument:  Incompatible shapes: [0,1027297329] vs. [1,64] 	 [[{{node gradient_tape/sequential/lstm_2/while/sequential/lstm_2/while_grad/body/_495/gradients/lstm_cell_2/mul_1_grad/BroadcastGradientArgs}}]] 	 [[div_no_nan/ReadVariableOp_1/_158]]   (1) Invalid argument:  Incompatible shapes: [0,1027297329] vs. [1,64] 	 [[{{node gradient_tape/sequential/lstm_2/while/sequential/lstm_2/while_grad/body/_495/gradients/lstm_cell_2/mul_1_grad/BroadcastGradientArgs}}]] 0 successful operations. 1 derived errors ignored. [Op:__inference_train_function_5728] Function call stack: train_function > train_function","Hi mrc ! Thanks for sharing your observation diststrat and 2 gpu cards.  Just curious on whether you tested with TF > 2.9 version or not .  Workaround is to mention those 2 GPU cards explicitly. `strategy = tf.distribute.MirroredStrategy(devices=[""GPU:0"", ""GPU:1""]) `   ! Could you look at this issue or not. Thank you!","Hello   Thanks for your answer. I also tried with this explicit statement but also got the same error. Unfortunately, I can't try with tf>2.2 cause my gpus only work with ROCm<=3.5 on my machine.","Also tried with  `mirrored_strategy = tf.distribute.MirroredStrategy(devices=[""GPU:1""], cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())` And got the same error. The most surprising thing is that it's purely random ... Also noticed that my CPU is overloaded, do you think it can affect the program?  Thank you,",Also got the error by specifying `mirrored_strategy = tf.device('/gpu:1')` Any idea please ?     ,"Hi mrc , I tested the code with change in strategy to `mirrored_strategy = tf.distribute.OneDeviceStrategy(device=""/gpu:0"")` and the code executes fine.Please refer to attached colab gist. I have also tested the code with `mirrored_strategy = tf.distribute.MirroredStrategy` .Please refer to attached gist If you have Multiple GPUs on same machine then you should use tf.distribute.MirroredStrategy only. If you want to train on Multiple Machines with  GPUs then only you should use tf.distribute.MultiWorkerMirroredStrategy. Please refer to attached documentation link for more details.","Hello SuryanarayanaY, Indeed, might come from my environment ...  Also tried with tensorflow==2.1.2 and 2.1.6 and python==3.6.15 and got this warning : WARNING:tensorflow:5 out of the last 5 calls to .distributed_function at 0x7ff9884c59e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performancepython_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details. Maybe that can help!","Hi mrc , The warning mentioned above regarding retracing is safe to ignore which actually comes when we repeatedly call `tf.function` inside code or running the code having `tf.function` multiple times in the same session.AFAIK the error mentioned in the ticket not related to the `tf.function` warning and it has nothing to do with `experimental_relax_shapes=True` . You may also test with `experimental_relax_shapes=True` and confirm if it avoids error. My ask here is How many systems you are using for model training? Since I can see you are using `MultiWorkerMirroredStrategy` which has to be used only if you want to train the model on Multiple workers(servers/computers).For single system this strategy it may not work as intended and unexpected error may arise in that case you need to use `MirroredStrategy` only. Providing the details like 1.How many systems/servers you are using for training 2.How many GPUs in each etc may help us to reach the root cause of the error.","Thanks for your answer.  Ok I look further about the second issue then. About the first one, was indeed a mistake to use `MultiWorkerMirroredStrategy`, but it's not what causing the issue, as mentioned earlier :  > Also tried with > mirrored_strategy = tf.distribute.MirroredStrategy(devices=[""GPU:1""], cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) > And got the same error. >  > The most surprising thing is that it's purely random ... > Also noticed that my CPU is overloaded, do you think it can affect the program? >  > Thank you, Currently operating with `mirrored_strategy = tf.distribute.OneDeviceStrategy(device=""/gpu:1"")` and still have the issue ... ","mrc , `tf.distribute.experimental.CollectiveCommunication.RING` will be used for Cross device communication in MultiWorkerMirroredStrategy only. With single GPU `tf.distribute.OneDeviceStrategy(device=""/gpu:1"")` there is no need of  arguments like communication and Iam wondering how you are getting this error which is not relevant to `OneDeviceStrategy`. Can you share the exact code you are using with single GPU strategy `tf.distribute.OneDeviceStrategy(device=""/gpu:1"")`. Also with tf.distribute.MirroredStrategy(devices=[""GPU:1""] as you are using cross_device_ops=tf.distribute.HierarchicalCopyAllReduce()) argument can you try it changing to other options and let us know the behaviour. It seems the reported behaviour is related to your own environment only.Could you confirm whether you have used ROCM build with the `MirroredStrategy` earlier? What are the configurations you have used earlier ? Can you try to build with latest TF version and let us know if it works.You may found supported configurations of ROCM here for latest version. Thankyou!","I can assure that I get this shapes error with `tf.distribute.OneDeviceStrategy(device=""/gpu:1"")` ; the code is exactly the same as provided excepted for the mirrored_strategy parameter.  Will try and give you the result ASAP Coming back to the tf.function error, it might be a symptom cause only occuring on tf 2.1.* and even if it doesn't crash the program my algorithm is 10x slower than in tf 2.2 It can also be related to my environment, I found this particular issue:  https://github.com/RadeonOpenCompute/ROCm/issues/1203 But already have the setup recommend in this issue (ie. Rocm 3.5.1, python 3.8, tensorflowrocm 2.2, Ubuntu 20.04)",To reduce retracing time you can set `reduce_retracing=True` as argument in `tf.function()`. It may helps in reducing the retracing time. Also may be the error is related to your environment. To confirm that could you please provide some dummy data.May be that helps in debugging the error. Thanks!,"It was indeed coming from my environment.  I found that the following versions have finally worked for me: python: 3.7.16, tensorflowrocm: 2.1.6, rocm: 3.5.1, ubuntu: 20.04 kernel: 5.0.42 if you have the same error, I recommend you this tutorial:  https://github.com/boriswinner/RX580rocMtensorflowubuntu20.4guide [](https://github.com/Grench6/RX580rocMtensorflowubuntu20.4guide) Wish you good luck if you have to train with AMD's Polaris card ... Thank you for your help ",Are you satisfied with the resolution of your issue? Yes No
1502,"以下是一个github上的tensorflow下的一个issue, 标题是(Pre loads pages and crashes during transition in colab)， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,SpecialKREDhat,Pre loads pages and crashes during transition in colab," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-01-05T07:34:10Z,TFLiteConverter,closed,0,0,https://github.com/tensorflow/tensorflow/issues/59103
1995,"以下是一个github上的tensorflow下的一个issue, 标题是(Selectively build TensorFlow Lite with Bazel for Android，cannot find symbol class Interpreter，dlopen failed: cannot locate symbol ""_ZNK6google8protobuf7Message11GetTypeNameEv"")， 内容是 (**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS 11.5.2  TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): git tag: v2.11.0 ; https://github.com/tensorflow/tensorflow/tree/v2.11.0 **Provide the text output from tflite_convert** Caused by: java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZNK6google8protobuf7Message11GetTypeNameEv"" referenced by ""/data/app/com.alihealth.game.demoFuGH2eR4ckz7uJ2feTDGQ==/lib/arm64/libtensorflowlite_flex_jni.so""...         at java.lang.Runtime.loadLibrary0(Runtime.java:1071)         at java.lang.Runtime.loadLibrary0(Runtime.java:1007)         at java.lang.System.loadLibrary(System.java:1668)         at org.tensorflow.lite.flex.FlexDelegate.(FlexDelegate.java:61)         at java.lang.Class.classForName(Native Method)         at java.lang.Class.forName(Class.java:454)         at java.lang.Class.forName(Class.java:379)         at org.tensorflow.lite.NativeInterpreterWrapper.maybeCreateFlexDelegate(NativeInterpreterWrapper.java:544)         at org.tensorflow.lite.NativeInterpreterWrapper.addDelegates(NativeInterpreterWrapper.java:484)         at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:96)         at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:58)         at org.tensorflow.lite.NativeInterpreterWrapperExperimental.(NativeInterpreterWrapperExperimental.java:32)         at org.tensorflow.lite.Interpreter.(Interpreter.java:197)         at org.tensorflow.lite.Interpreter.(Interpreter.java:185)         at )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",llm,haifang12,"Selectively build TensorFlow Lite with Bazel for Android，cannot find symbol class Interpreter，dlopen failed: cannot locate symbol ""_ZNK6google8protobuf7Message11GetTypeNameEv""","**System information**  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS 11.5.2  TensorFlow installed from (source or binary): source  TensorFlow version (or github SHA if from source): git tag: v2.11.0 ; https://github.com/tensorflow/tensorflow/tree/v2.11.0 **Provide the text output from tflite_convert** Caused by: java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZNK6google8protobuf7Message11GetTypeNameEv"" referenced by ""/data/app/com.alihealth.game.demoFuGH2eR4ckz7uJ2feTDGQ==/lib/arm64/libtensorflowlite_flex_jni.so""...         at java.lang.Runtime.loadLibrary0(Runtime.java:1071)         at java.lang.Runtime.loadLibrary0(Runtime.java:1007)         at java.lang.System.loadLibrary(System.java:1668)         at org.tensorflow.lite.flex.FlexDelegate.(FlexDelegate.java:61)         at java.lang.Class.classForName(Native Method)         at java.lang.Class.forName(Class.java:454)         at java.lang.Class.forName(Class.java:379)         at org.tensorflow.lite.NativeInterpreterWrapper.maybeCreateFlexDelegate(NativeInterpreterWrapper.java:544)         at org.tensorflow.lite.NativeInterpreterWrapper.addDelegates(NativeInterpreterWrapper.java:484)         at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:96)         at org.tensorflow.lite.NativeInterpreterWrapper.(NativeInterpreterWrapper.java:58)         at org.tensorflow.lite.NativeInterpreterWrapperExperimental.(NativeInterpreterWrapperExperimental.java:32)         at org.tensorflow.lite.Interpreter.(Interpreter.java:197)         at org.tensorflow.lite.Interpreter.(Interpreter.java:185)         at ",2023-01-05T05:30:19Z,stat:awaiting response type:build/install stale comp:lite TF 2.11,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59102, Can you help me with this problem?,", Could you please try to add the option `echo n ""build config=monolithic""` >> `/tensorflow_src/.bazelrc` to avoid the **_ZNK6google8protobuf7Message11GetTypeNameEv** error.  Also please take a look at the comment from the developer issue1 and issue2 for the similar error. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Closing as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No,"> , Could you please try to add the option `echo n ""build config=monolithic""` >> `/tensorflow_src/.bazelrc` to avoid the **_ZNK6google8protobuf7Message11GetTypeNameEv** error. >  > Also please take a look at the comment from the developer issue1 and issue2 for the similar error. Thank you! Tried this, however build issue is coming for tensorflow v2.15 "
1013,"以下是一个github上的tensorflow下的一个issue, 标题是([NVIDIA XLA] Possible fix for a corner case in TryElideCopy function for copy_insertion pass )， 内容是 (CopyInsertion optimization pass first add agressively copy operators to break live range interference, then in the later of this pass, using `TryElideCopy` function to remove redundant copy operators.  From my understanding, there are corner cases that `TryElideCopy` misses, and I believe that this may introduce unnecessary copies.  The corner cases are about when the src hlo buffer or dst hlo buffer of copy operators only holds single HloValue, seems that `TryElideCopy` function does not consider these corner cases.   I am sending out this pull request to request reveiw if my understanding is correct, and provide a tentative fix for it.   I am not confident about my understanding of the pass,  please help review the case. )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shawnwang18,[NVIDIA XLA] Possible fix for a corner case in TryElideCopy function for copy_insertion pass ,"CopyInsertion optimization pass first add agressively copy operators to break live range interference, then in the later of this pass, using `TryElideCopy` function to remove redundant copy operators.  From my understanding, there are corner cases that `TryElideCopy` misses, and I believe that this may introduce unnecessary copies.  The corner cases are about when the src hlo buffer or dst hlo buffer of copy operators only holds single HloValue, seems that `TryElideCopy` function does not consider these corner cases.   I am sending out this pull request to request reveiw if my understanding is correct, and provide a tentative fix for it.   I am not confident about my understanding of the pass,  please help review the case. ",2023-01-04T15:11:42Z,comp:xla size:S,closed,0,3,https://github.com/tensorflow/tensorflow/issues/59093,It's hard to figure out what the PR is aiming to fix without a test  perhaps add a few test cases?,"Bump for test cases. > From my understanding, there are corner cases that TryElideCopy misses, and I believe that this may introduce unnecessary copies. These seem like good candidates for some of the test cases.",Canceling this PR as my original understanding was not correct. 
826,"以下是一个github上的tensorflow下的一个issue, 标题是(Check failure when running tensorflow.python.ops.gen_math_ops.dense_bincount)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230104 02:11:11.516596: F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 (0 vs. 0) Aborted  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,dmc1778,Check failure when running tensorflow.python.ops.gen_math_ops.dense_bincount,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.11.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue  shell 20230104 02:11:11.516596: F ./tensorflow/core/util/gpu_launch_config.h:129] Check failed: work_element_count > 0 (0 vs. 0) Aborted  ,2023-01-04T07:14:22Z,stat:awaiting tensorflower type:bug comp:ops TF 2.11,closed,0,8,https://github.com/tensorflow/tensorflow/issues/59087,", I can see the difference in behaviour on colab runtime CPU vs GPU. On the CPU the code was executed without any issues/error and on GPU it is getting crashed. Kindly find the gist. Also please take a look at this PR which was raised for the similar issue. Thank you!","> , I can see the difference in behaviour on colab runtime CPU vs GPU. On the CPU the code was executed without any issues/error and on GPU it is getting crashed. Kindly find the gist. Also please take a look at this PR which was raised for the similar issue. Thank you! Thanks for explaining.",I get assertion failure when running with another test case on TF v2.10.0  The log message:  The root cause is the negative integer tensor feed as the first argument.,", I was able to reproduce the issue on tensorflow v2.10, v2.11 and nightly. Kindly find the gist of it here.",toplay ,"Hi, The fix for this issue has been implemented to handle the inputs for GPU kernels in the fix here https://github.com/tensorflow/tensorflow/commit/764eae38919b45556373a320af1079ac54e70521. This will be part of the next one/two releases. Thanks!",Since this got fixed we can now close it. Thank you,Are you satisfied with the resolution of your issue? Yes No
833,"以下是一个github上的tensorflow下的一个issue, 标题是(Check failure when running tensorflow.python.ops.gen_ragged_conversion_ops.ragged_tensor_to_variant)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.13.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue    Relevant log output ```shell 20230104 01:34:14.128060: F tensorflow/core/framework/tensor_shape.cc:585] Check failed: d )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,dmc1778,Check failure when running tensorflow.python.ops.gen_ragged_conversion_ops.ragged_tensor_to_variant,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source binary  Tensorflow Version 2.13.0  Custom Code Yes  OS Platform and Distribution 22.04  Mobile device _No response_  Python version 3.9  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue    Relevant log output ```shell 20230104 01:34:14.128060: F tensorflow/core/framework/tensor_shape.cc:585] Check failed: d ,2023-01-04T06:40:48Z,stat:awaiting response type:bug stale comp:ops TF 2.11,closed,0,14,https://github.com/tensorflow/tensorflow/issues/59084,"tf.ragged_ops are basically designed to be consumed by downstream library users, not end users. Usually, these APIs are less strict in terms of validation etc., which is fine since mainly library writers are supposed to use these symbols. If available, please prefer a high level API for general use case scenarios. Refer this RFC and link for more details. Thank you!","> tf.ragged_ops are basically designed to be consumed by downstream library users, not end users. Usually, these APIs are less strict in terms of validation etc., which is fine since mainly library writers are supposed to use these symbols. If available, please prefer a high level API for general use case scenarios. Refer this RFC and link for more details. Thank you! Do you think these APIs are exploitable by external attackers?",TF2.10 is crashes with check failure with the following test case:   The log message: ,", Usually we request the community preferring a high level API for general use case scenarios which will be helpful to resoluve the issues. Refer this RFC and link for more details. Thank you!",This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.,Also this one: ,", I tried to execute the code with the alternative appraoch by using **minval=256 and maxval=257** and it was executed without any issues. Kindly find the gist of it here. Also the dtype will expect the positive input and throws an error otherwise. Thank you!","> , I tried to execute the code with the alternative appraoch by using **minval=256 and maxval=257** and it was executed without any issues. Kindly find the gist of it here. Also the dtype will expect the positive input and throws an error otherwise. Thank you!    I am running fuzzer on tensorflow. Those inputs are machine generated. Would you please test with my input and confirm if you get check failure?",", When performing `tf.random.uniform` the type for the **minval**  is a Tensor or Python value of type dtype, broadcastable with shape (for integer types, broadcasting is not supported, so it needs to be a scalar). The lower bound on the range of random values to generate (inclusive). **Defaults to 0**.  As mentioned I was performing the test with minval=256 and maxval=257 and it was executed without any issues. Also the when dtype is ve it will act as invalid and will expect the positive input & throw an error otherwise. Thank you! !image"," this is potentially a vulnerability. Don't add the awaiting response tag as that closes the issue before it gets fixed given team does not notice these. Please test with nightly, not just last release.  Please stop posting vulenrabilities on GitHub page. It is not the usual procedure for reporting these.",", I tried to execute the mentioned code on tfnightly(2.13.0dev20230228), the crash did not happen when invalid input was provided to ragged_tensor_to_variant. Kindly find the gist of it here and also please find the reference of the ubuntu22.04. !Screenshot 20230301 10 16 02 AM",This looks to have been fixed. We can close it.,Closing this as stale. Please reopen if this is still a valid request. Thank you!,Are you satisfied with the resolution of your issue? Yes No
1923,"以下是一个github上的tensorflow下的一个issue, 标题是(Monolithic build of libtensorflow_cc.so produces libtensorflow_framework.so, failing to run application)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version 5.3.1  GCC/Compiler version 9.4.0  CUDA/cuDNN version 11.2.152  GPU model and memory NVIDIA RTX 3090 TI (24GB)  Current Behaviour? I am trying to build a monolithic version of the TensorFlow C++ library `libtensorflow_cc.so` from source for TensorFlow versions 2.10+. I'm building inside a Docker container of the official `develgpu` image, which is defined in develgpu.Dockerfile. For the build, I am calling the following. The build output is attached as the log in this issue. Note that I also had to incorporate this patch to get the build to work at all.   The library is built successfully, I did however notice that `libtensorflow_cc.so` seems to now be linking to `libtensorflow_framework.so`, which is also built in the process. That was not the case with v2.9.2 and below. Actually I thought that `config=monolithic` should result in only `libtensorflow_cc.so`, but it looks like `libtensorflow_framework.so` is a dependency since https://github.com/tensorflow/tensorflow/commit/843c02fe06983ac0f4382a93fff9ffd07eb93d27? I didn't find where `config=monolithic` is coming into play at the moment. My main problem at the moment is that I cannot successfully compile and run a test C++ program. Previously this worked:  With v2.10.0+ it is giving me the following error instead.  Now if I add `libtensorflow_framework.so` to the list of libs to link against)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,lreiher,"Monolithic build of libtensorflow_cc.so produces libtensorflow_framework.so, failing to run application","Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version tf 2.10  Custom Code No  OS Platform and Distribution Linux Ubuntu 20.04  Mobile device _No response_  Python version 3.8.10  Bazel version 5.3.1  GCC/Compiler version 9.4.0  CUDA/cuDNN version 11.2.152  GPU model and memory NVIDIA RTX 3090 TI (24GB)  Current Behaviour? I am trying to build a monolithic version of the TensorFlow C++ library `libtensorflow_cc.so` from source for TensorFlow versions 2.10+. I'm building inside a Docker container of the official `develgpu` image, which is defined in develgpu.Dockerfile. For the build, I am calling the following. The build output is attached as the log in this issue. Note that I also had to incorporate this patch to get the build to work at all.   The library is built successfully, I did however notice that `libtensorflow_cc.so` seems to now be linking to `libtensorflow_framework.so`, which is also built in the process. That was not the case with v2.9.2 and below. Actually I thought that `config=monolithic` should result in only `libtensorflow_cc.so`, but it looks like `libtensorflow_framework.so` is a dependency since https://github.com/tensorflow/tensorflow/commit/843c02fe06983ac0f4382a93fff9ffd07eb93d27? I didn't find where `config=monolithic` is coming into play at the moment. My main problem at the moment is that I cannot successfully compile and run a test C++ program. Previously this worked:  With v2.10.0+ it is giving me the following error instead.  Now if I add `libtensorflow_framework.so` to the list of libs to link against",2023-01-03T20:41:20Z,stat:awaiting response type:build/install stale comp:runtime subtype: ubuntu/linux TF 2.10,closed,1,12,https://github.com/tensorflow/tensorflow/issues/59081,"I had some success building the libtensorflow_cc.so and using it in another project without using config=monolithic config. Not sure if it is helpful, but I think the error message seems to be due to both libtensorflow_framwork and libtensorflow_cc initializing protobuf somehow.. I can also confirm that there seems to be some regression of the monolithic build since 2.9.0. I can use config=monolithic to run all python tests successfully for v2.9.0 but they would otherwise fail with the newer versions of tensorflow.",I confirm the issue. The exact same auxiliary script wrapping Bazel calls (with `config=monolithic`) producing different libtensorflow_cc.so artifacts for 2.9.3 and 2.10.1: the former is actually monolithic and the latter depends on libtensorflow_framework.so. Also with `config=monolithic` I experience the same errors OP does. I can provide more details on my setup if needed.,"> I had some success building the libtensorflow_cc.so and using it in another project without using config=monolithic config. Not sure if it is helpful, but I think the error message seems to be due to both libtensorflow_framwork and libtensorflow_cc initializing protobuf somehow.. >  >  >  > I can also confirm that there seems to be some regression of the monolithic build since 2.9.0. I can use config=monolithic to run all python tests successfully for v2.9.0 but they would otherwise fail with the newer versions of tensorflow. Thanks, I can confirm that building without config=monolithic, I can successfully link and run my application code.", Could you please confirm if the issue has been resolved? Thank you!,"I can confirm that building without config=monolithic, I can successfully link and run my application code. However, the described issue still persists and does not behave the way it is supposed to I believe.", Thank you for the update!  Could you have a look at this issue? Thank you!," , Could you please look into the issue. Thanks!","I'm getting the exact same protobuf error message when using the tensorflow package from the Arch Linux official repositories. Notice that the Arch Linux tensorflow package is **not** built with `config=monolithic`. Since this issue is opened for more than one year, and many things could have changed since then, maybe the monolithic option is not the cause? I can reproduce this issue when running telegramdesktop in Arch Linux with a custom ffmpeg build that is linked against tensorflow (by using the ffmpeg option `enablelibtensorflow` at build time). The telegramdesktop application links to both ffmpeg and protobuf, and the custom ffmpeg in turn will be linked to tensorflow. Notice that telegramdesktop is not linked to tensorflow libraries. When running telegramdesktop with the custom ffmpeg build (which is linked to tensorflow), the protobuf error is shown at telegram startup, and it crashes. When running telegramdesktop with the Arch Linux repository ffmpeg package (which is **not** linked to tensorflow), it works fine.","Hi, Thank you for opening this issue. Since this issue has been open for a long time, the code/debug information for this issue may not be relevant with the current state of the code base. The Tensorflow team is constantly improving the framework by fixing bugs and adding new features. We suggest you try the latest TensorFlow version with the latest compatible hardware configuration which could potentially resolve the issue. If you are still facing the issue, please create a new GitHub issue with your latest findings, with all the debugging information which could help us investigate. Please follow the release notes to stay up to date with the latest developments which are happening in the Tensorflow space.",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
710,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to Build Tensorflow Lite Flex Delegate for Android)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution MacOS 12.3.1  Mobile device Samsung Galaxy S22 Ultra  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version clang 13.1.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,johndoe342,Unable to Build Tensorflow Lite Flex Delegate for Android,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version 2.11.0  Custom Code No  OS Platform and Distribution MacOS 12.3.1  Mobile device Samsung Galaxy S22 Ultra  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version clang 13.1.6  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-03T20:40:35Z,stat:awaiting response type:build/install stale comp:lite subtype:macOS TF 2.11 Android,closed,0,12,https://github.com/tensorflow/tensorflow/issues/59080,"Hi  ! Could you confirm that you have provided path to android tool chains after saying yes to android build during ""python3 configure.py "" process. Thank you!",Yes I have confirmed that I have provided the path to the android tool chains. ,Is there any other information that I can provide? I'm still running into the issue. ,Hi  ! Thanks for the update.   ! Could you look at this issue . ,"Could you try it again with `config=monolithic define=TENSORFLOW_PROTOS=lite` option?  Just in case, we release tensorflowliteselecttfops.aar via Maven. https://search.maven.org/artifact/org.tensorflow/tensorflowliteselecttfops",,"The flex interpreter technically builds and links but I'm getting the error: `E/tflite: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflowliteselecttfops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select E/tflite: Node number 0 (FlexStridedSlice) failed to prepare.` which I was hoping to get around by using the flex delegate. ","I also want to confirm that something like `interpreter_>ModifyGraphWithDelegate(tflite::FlexDelegate::Create())` would not be necessary since the docs state that,  ` Note that the necessary TfLiteDelegate will be installed automatically when creating the interpreter at runtime as long as the shared library is linked. It is not necessary to explicitly install the delegate instance as is typically required with other delegate types `. For additional context I am using the C++ API with Android Native/ndk. Building the `.so` file from the aar didn't seem to work either. ","You can check if the Flex delegate is linked correctly to the TFLte interpreter. If yes, `AcquireFlexDelegate` https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/delegate_symbol.ccL23 is called. If no,  `AcquireFlexDelegate` https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/core/interpreter_builder.ccL167 is called. If you want to use it separately, you can do it by updating the shared library name in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/core/interpreter_builder.ccL195",This issue is stale because it has been open for 7 days with no activity. It will be closed if no further activity occurs. Thank you.,This issue was closed because it has been inactive for 7 days since being marked as stale. Please reopen if you'd like to work on this further.,Are you satisfied with the resolution of your issue? Yes No
1456,"以下是一个github上的tensorflow下的一个issue, 标题是(SIMJO77 )， 内容是 ( 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,SIMJO7747,SIMJO77 ," 1. System information  OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  TensorFlow installation (pip package or built from source):  TensorFlow library (version, if pip package or github SHA, if built from source):  2. Code Provide code to help us reproduce your issues using one of the following options:  Option A: Reference colab notebooks 1)  Reference TensorFlow Model Colab: Demonstrate how to build your TF model. 2)  Reference TensorFlow Lite Model Colab: Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).   Option B: Paste your code here or provide a link to a custom endtoend colab   3. Failure after conversion If the conversion is successful, but the generated model is wrong, then state what is wrong:  Model produces wrong results and/or has lesser accuracy.  Model produces correct results, but it is slower than expected.  4. (optional) RNN conversion support If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.  5. (optional) Any other info / logs Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.",2023-01-03T19:24:12Z,comp:lite type:others TFLiteConverter,closed,0,1,https://github.com/tensorflow/tensorflow/issues/59079,Hi  ! Closing this issue as template has not been filled. Please update the template with standalone code to reopen this issue. Thank you!
1863,"以下是一个github上的tensorflow下的一个issue, 标题是(Distribute training bug while using tf.data)， 内容是 (Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: yes    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:    **TensorFlow installed from (source or binary)**: ngc    **TensorFlow version (use command below)**: 2.10    **Python version**: 3.8.10    **Bazel version (if compiling from source)**:    **GCC/Compiler version (if compiling from source)**:    **CUDA/cuDNN version**: 11.8    **GPU model and memory**: A100 80G (8 Gpus)    **Exact command to reproduce**: You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh You can obtain the Ten)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,xiaogangzhu,Distribute training bug while using tf.data,"Please go to Stack Overflow for help and support: https://stackoverflow.com/questions/tagged/tensorflow If you open a GitHub issue, here is our policy: 1.  It must be a bug, a feature request, or a significant problem with the     documentation (for small docs fixes please send a PR instead). 2.  The form below must be filled out. 3.  It shouldn't be a TensorBoard issue. Those go     here. **Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.   System information    **Have I written custom code (as opposed to using a stock example script     provided in TensorFlow)**: yes    **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04    **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue     happens on a mobile device**:    **TensorFlow installed from (source or binary)**: ngc    **TensorFlow version (use command below)**: 2.10    **Python version**: 3.8.10    **Bazel version (if compiling from source)**:    **GCC/Compiler version (if compiling from source)**:    **CUDA/cuDNN version**: 11.8    **GPU model and memory**: A100 80G (8 Gpus)    **Exact command to reproduce**: You can collect some of this information using our environment capture script: https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh You can obtain the Ten",2023-01-03T01:49:45Z,type:support comp:dist-strat TF 2.10,closed,0,7,https://github.com/tensorflow/tensorflow/issues/59072,test (1).zip I also include the sample data here.,  I was able to reproduce the issue on Colab using TF v2.11. Please find the gist here for reference. Thank you!,"Hi, so how to solve this problem. Also in colab I found some code error !image the code here should be  ","Hi  , This is duplicate of CC(MirroredStrategy error INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds when training a model, most related to batch size strategy across all GPUs) . We will definitely track the issue there as already communications going on and it shall remain open till resolved. Shall we close the issue here so that we can track this there ?","Sure, thanks!","Closing the issue as it is duplicate of CC(MirroredStrategy error INVALID_ARGUMENT: slice index 0 of dimension 0 out of bounds when training a model, most related to batch size strategy across all GPUs)",Are you satisfied with the resolution of your issue? Yes No
723,"以下是一个github上的tensorflow下的一个issue, 标题是(TypeError when modifying tf.keras.Optimizer parameter)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v1.15.0rc322g590d6eef7e 1.15.0  Custom Code Yes  OS Platform and Distribution Windows 10 19042.2364  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 10.1  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,sidbab94,TypeError when modifying tf.keras.Optimizer parameter,Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? No  Source source  Tensorflow Version v1.15.0rc322g590d6eef7e 1.15.0  Custom Code Yes  OS Platform and Distribution Windows 10 19042.2364  Mobile device _No response_  Python version 3.7  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version CUDA 10.1  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ,2023-01-02T11:43:33Z,type:bug comp:keras TF 1.15,closed,0,6,https://github.com/tensorflow/tensorflow/issues/59069,Hi  ! 1.x versions are  not supported anymore. Could you provide a sample code from 2.x version to replicate this issue. Thank you!,"Okay, I'm afraid my code is constrained to the usage of TF 1.x. Can a fix/suggestion still be provided? Thank you!", ! You can use migration guide to use 1.x codebase in 2.x version.   (Tensorflowaddons/TFslim for TFcontrib ) . Thank you!,"Thanks for the suggestion .  But the environment I'm working on is _heavily_ dependant on TF1.x, I will revisit this once I am able to reproduce the same on TF 2.x.", ! Marking this as partially resolved from above comment . Feel free to create a separate issue if you are facing any issue in 2.x version. Thank you!,Are you satisfied with the resolution of your issue? Yes No
689,"以下是一个github上的tensorflow下的一个issue, 标题是(Unable to build in WSL2)， 内容是 (Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04 in WSL2  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version 11.2/8.1  GPU model and memory 1080Ti with 11GB memory  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_)请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",rag,hengruo,Unable to build in WSL2,Click to expand!    Issue Type Build/Install  Have you reproduced the bug with TF nightly? Yes  Source source  Tensorflow Version 2.11  Custom Code No  OS Platform and Distribution Linux Ubuntu 22.04 in WSL2  Mobile device _No response_  Python version 3.10  Bazel version 5.3.0  GCC/Compiler version 11.3.0  CUDA/cuDNN version 11.2/8.1  GPU model and memory 1080Ti with 11GB memory  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output _No response_,2023-01-02T06:45:11Z,type:build/install subtype:windows wsl2 TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59068,Can you try with Cuda 11.8 and cuDNN 8.6?," I had tried 11.8 + 8.7 and got the same error. Do I still need to try 11.8 + 8.6? Combinations I tried:  cuda 11.8 + cuDNN 8.7,  cuda 11.4 + cuDNN 8.7,  cuda 11.2 + cuDNN 8.1.","I solved this problem. The compute compatibility should be 6.1, but I set 11.8. You can close this issue.",Are you satisfied with the resolution of your issue? Yes No
739,"以下是一个github上的tensorflow下的一个issue, 标题是(tf.image.extract_patches fails with XLA, float32 input and message about int64 input)， 内容是 (Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04, Mac OS X 12.6  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  )请根据以上内容标注这个issue,                用一句简短的话描述这个issue类型是bug报告还是其它类型（例如用户提出需求，请教问题等），设计的模型或者主要对象是什么，由于什么问题出现了什么bug，需要什么帮助。你的回答只需要包含这个句子，不需要包含其他内容",yi,shkarupa-alex,"tf.image.extract_patches fails with XLA, float32 input and message about int64 input","Click to expand!    Issue Type Bug  Have you reproduced the bug with TF nightly? Yes  Source binary  Tensorflow Version 2.11  Custom Code Yes  OS Platform and Distribution Ubuntu 20.04, Mac OS X 12.6  Mobile device _No response_  Python version 3.8  Bazel version _No response_  GCC/Compiler version _No response_  CUDA/cuDNN version _No response_  GPU model and memory _No response_  Current Behaviour?   Standalone code to reproduce the issue   Relevant log output  ",2023-01-01T12:30:15Z,type:bug comp:xla TF 2.11,closed,0,4,https://github.com/tensorflow/tensorflow/issues/59061,  I was able to reproduce the issue on colab using TF v2.11. Please find the gist here for reference. Thank you !,"alex, I tried to execute the mentioned code on  both GPU and CPU with the tensorflow v2.14 & tfnightly and it was executed without any issue/error. Kindly find the gist of it here. Thank you!",This issue was fixed with https://github.com/tensorflow/tensorflow/pull/59185,Are you satisfied with the resolution of your issue? Yes No
