这是一个bug报告，涉及主要对象是深度学习模型的训练。原因是NumPy 1.26版本不支持bfloat16数据类型，导致训练出错。,#fix train deepseek-distill-qwen-1.5b on bfloat16 causes error by np1.26 do not support bfloat16,,2025-04-23T03:51:50Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2029
这是一个用户提出需求的issue，主要对象是mindnlp库中的qwen2部分。由于需要对qwen2进行修改以支持jit，用户提出了这个issue。,modify qwen2 for jit,,2025-04-21T14:32:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2028
这个issue属于需求提出类型，主要涉及的对象是开源实习中使用GIT模型进行图像描述。该问题提出了需求在自定义数据集上微调GIT模型的笔记本。,【开源实习】GIT模型应用开发, 第一个自定义数据集上微调GIT模型进行图像描述的笔记本中，我将在一个小型图像描述数据集上微调 **这是在Mindspore的训练过程图，50个epoch后loss稳定在0.06左右** !ms训练图 **这是在pytorch的训练过程图，50个epoch后loss稳定在0.09左右** !torch训练图 **下面是mindspore的推理图，可以看到推理结果与预期一致** !ms推理结果图 **下面是pytorch的推理图，可以看到准确度相较于mindspore差一点** !torch推理结果图  第二个使用 GIT 进行图像/视频描述生成和图像/视频问答的笔记本中，演示了如何使用MindSpore的 GIT 模型来对图像或视频进行描述生成，以及在图像或视频上进行问答。 **选择其中一个推理模型进行比较：** **mindspore：** !ms推理2 **pytorch:** !orch推理2 **结果一致**,2025-04-21T04:03:17Z,,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/2027, 任务 **任务编号**：IAADHU **任务链接**：【开源实习】GIT模型应用开发 **实现内容**：实现了自定义数据集上微调GIT模型进行图像描述以及使用 GIT 进行图像/视频描述生成和图像/视频问答。
这是一个用户提出需求的issue，主要涉及bart模型微调，由于未完整描述实现内容，用户提出相关任务I的编号。,【开源实习】bart模型微调, bart模型微调报告  任务  **任务编号**：IAUOXU  **任务链接**：【开源实习】bart模型微调    **实现内容**：实现了bart模型在XSum数据集上的微调。    **模型**：`facebook/bartbase`    **数据集**：`EdinburghNLP/xsum`   结果对比  **Mindnlp+D910B**  ,2025-04-19T14:50:55Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2026
这是一个bug报告，涉及的主要对象是mindnlp的PeftModel，问题是由于mindnlp 0.4版本不支持保存和加载PeftModel的adapter weights为safetensors导致的。,PeftModel supports saving and loading safetensors,fixes: CC(mindnlp0.4版本不支持保存和加载PeftModel的adapter weights为safetensors) ,2025-04-19T12:29:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2025
这是一个bug报告，针对mindnlp 0.4版本不支持保存和加载PeftModel的adapter weights为safetensors。,mindnlp0.4版本不支持保存和加载PeftModel的adapter weights为safetensors,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. mindnlp0.4版本不支持保存和加载PeftModel的adapter weights为safetensors，仅能保存为ckpt，这个导致在训练过程中通过`save_pretrained`保存下来的adapter weights，在香橙派上通过`PeftModel.from_pretrained`进行加载时报错（`_parse_ckpt_proto`无法识别tensor_type，必须为Float16，然后香橙派上保存下来的tensor_dtype为mindspore.float16）  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ```python model_id = ""MindSporeLab/DeepSeekR1DistillQwen1.5B"" base_model = AutoModelForCausalLM.from_pretrained(""/home/HwHiAiUser/xingyiren/DeepSeek_half"", ms_dtype=mindspore.float16) base_model.generation_config = GenerationConfig.from_pretrained(""/home/HwHiAiUser/xingyiren/DeepSeek_half"") base_model.generation_config.pad_token_id = base_model.generation_config.eos_token_id config = LoraConfig(     task_type=TaskType.CAUSAL_LM,      target_modules=[""q_proj"", ""k_proj"", ""v_proj"", ""o_proj"", ""gate_proj"", ""up_proj"", ""down_proj""],     inference_mode=False,  训练模式     r=8,  Lora 秩     lora_alpha=32,  Lora alaph，具体作用参见 Lora 原理     lora_dropout=0.1 Dropout 比例 )  实例化LoRA模型 model = get_peft_model(base_model, config)  保存LoRA权重 model.save_pretrained(peft_model_path)  加载LoRA权重 model = PeftModel.from_pretrained(base_model, peft_model_path) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 将adapter保存为safetensors并成功加载 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !Image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-04-19T12:07:44Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2024
该问题属于需求修改类，主要涉及mindnlp中的qwen2对象。由于用户希望对qwen2进行修改，导致了此需求提出。,modify qwen2,,2025-04-18T09:00:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2023
"这是一个需求类型的issue，主要涉及的对象是""audio_spectrogram_transformer""模型，用户在进行微调时遇到了问题或者需要帮助。",【开源实习】audio_spectrogram_transformer模型微调, audio_spectrogram_transformer 模型微调报告  任务  任务编号：IAUOSX  任务链接：【开源实习】audio_spectrogram_transformer模型微调  实现了audio_spectrogram_transformer 在esc50数据集上的微调  模型：MIT/astfinetunedaudioset10100.4593  数据集: ashraq/esc50  结果对比： **Mindnlp+D910B**   ,2025-04-17T08:19:26Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2022
"这是一个缺少具体内容的bug报告类型的issue，主要涉及的对象是项目中的""qwen2""模块。原因可能是用户忘记填写具体的修改内容。",modify qwen2,,2025-04-17T07:33:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2021
这个issue类型是bug报告，主要涉及的对象是minicpm3在orange-pi上的运行。由于minicpm3在orange-pi上存在bug，导致需要修复该问题。,Fix bugs for minicpm3 on orange-pi,,2025-04-15T11:11:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2020
这是一个用户提出需求类型的issue，主要涉及Autoformer模型微调任务，用户寻求关于如何进行Autoformer模型微调的帮助。,【开源实习】Autoformer模型微调, Autoformer Mindnlp 微调  Autoformer模型微调任务链接：【开源实习】autoformer模型微调 · Issue IAUOTL · MindSpore/community  Gitee.com  实现了huggingface/autoformertourismmonthly 基准权重 在 [monash_tsf/tourism_monthly] 数据集上的微调  base model: huggingface/autoformertourismmonthly · Hugging Face  dataset: [MonashUniversity/monash_tsf · Datasets at Hugging Face](https://huggingface.co/datasets/MonashUniversity/monash_tsf)  Pytorch版本：Autoformer_tourism_monthly_finetune   微调结果  Mindspore ,2025-04-15T08:52:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2019
这是一个特性新增（Feature）类型的需求提出，涉及到新增WhisperFlashAttention2功能。由于缺少详细描述，无法准确判断导致了什么样的问题。,[Feat] Add WhisperFlashAttention2," Test Report Hard Environment: Ascend（snt9b In the case of long audio, FlashAttention2 brings about `(72.8655 64.7135)/72.8655=11.2%` acceleration effect; It is worth noting that PTA is seriously degraded in Flash mode (performance drops by about 6 times), while MindNLP implementation performs stably.  Test Code:  MindSpore ```python import mindspore from mindnlp.transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline import time mindspore.set_device(""Ascend"", 2) def generate_with_time(pipe, file_path):     start_time = time.time()     result = pipe(file_path)     generation_time = time.time()  start_time     return result, generation_time model_id = ""openai/whisperlargev3"" model = AutoModelForSpeechSeq2Seq.from_pretrained(     model_id,      ms_dtype=mindspore.float16,      low_cpu_mem_usage=True,     use_safetensors=True,      attn_implementation=""eager"",     attn_implementation=""flash_attention_2"", ) processor = AutoProcessor.from_pretrained(model_id) pipe = pipeline(     ""automaticspeechrecognition"",     model=model,     tokenizer=processor.tokenizer,     feature_extractor=processor.feature_extractor,     ms_dtype=mindspore.float16,     return_timestamps=True, )   eager mode test result (ms2.5.0 + mindnlp0.4.0)    generation_time: 93.65066742897034, result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直转少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即指导师太忙伸手按住了口  generation_time: 9.72678017616272, result: 你好   flash_attention_2 mode test result (ms2.5.0 + mindnlp0.4.0 + flash)    generation_time: 79.74670958518982, result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直转少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即指导师太忙伸手按住了口  generation_time: 8.643609762191772, result: 你好 result, generation_time = generate_with_time(pipe, ""/home/candyhong/workspace/whisper_large/tianlong0925.mp3"")  result, generation_time = generate_with_time(pipe, ""/home/candyhong/workspace/whisper_large/nihao.mp3"") print(f""generation_time: {generation_time}, result: {result['text']}"") ```  PyTorch + Ascend ```python import torch import torch_npu import time from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline torch_npu.npu.set_compile_mode(jit_compile=False) torch_npu.npu.config.allow_internal_format = False def generate_with_time(pipe, file_path):     start_time = time.time()     result = pipe(file_path)     generation_time = time.time()  start_time     return result, generation_time device = ""npu:0"" torch_dtype = torch.float16 model_id = ""openai/whisperlargev3"" model = AutoModelForSpeechSeq2Seq.from_pretrained(     model_id,     torch_dtype=torch_dtype,     low_cpu_mem_usage=True,     use_safetensors=True,      attn_implementation=""eager"",     attn_implementation=""flash_attention_2"", ) model.to(device) processor = AutoProcessor.from_pretrained(model_id) pipe = pipeline(     ""automaticspeechrecognition"",     model=model,     tokenizer=processor.tokenizer,     feature_extractor=processor.feature_extractor,     torch_dtype=torch_dtype,     device=device,     return_timestamps=True, )   eager mode test result    generation_time: 58.42126774787903 result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直展少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即知道失态忙伸手按住了口  generation_time: 2.7732555866241455, result: 你好   flash_attention_2 mode test result    generation_time: 252.1833713054657, result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直展少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即知道失态忙伸手按住了口  generation_time: 4.741170883178711, result: 你好 result, generation_time = generate_with_time(pipe, ""/home/candyhong/workspace/whisper_large/tianlong0925.mp3"")  result, generation_time = generate_with_time(pipe, ""/home/candyhong/workspace/whisper_large/nihao.mp3"") print(f""generation_time: {generation_time}, result: {result['text']}"") ```  Related Issues Fixes CC(Feat: Support Whisper + FlashAttention2) ",2025-04-14T09:38:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2018
这个issue是关于bug报告，主要涉及的对象是transformers 4.51.1版本。这个问题可能由于4.51.1版本中存在的错误导致了bug。,fix bugs on transformers 4.51.1,,2025-04-10T07:52:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2017
这个issue类型属于用户提出需求，涉及的主要对象是mindnlp 0.5.0版本初始化与mindtorch。由于用户希望在mindnlp中集成mindtorch，因此提出了这个需求。,init mindnlp 0.5.0 with mindtorch,,2025-04-09T10:43:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2016
这个issue类型是用户提出需求，主要对象是新增的WhisperFlashAttention2功能。由于软件环境设置问题，用户在Ascend环境中测试时遇到困难。,[Feat] Add WhisperFlashAttention2," Test Report Hard Environment: Ascend（snt9b|32G） Software Environment / 软件环境 (Mandatory / 必填):  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.10.0  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04.4 LTS  GCC/Compiler version (if compiled from source): 11.04  Test Code:  MindSpore ```python import mindspore from mindnlp.transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline import time mindspore.set_device(""Ascend"", 2) def generate_with_time(pipe, file_path):     start_time = time.time()     result = pipe(file_path)     generation_time = time.time()  start_time     return result, generation_time model_id = ""openai/whisperlargev3""  default mode: eager  model = AutoModelForSpeechSeq2Seq.from_pretrained(      model_id,       ms_dtype=mindspore.float16,       low_cpu_mem_usage=True,      use_safetensors=True,  ) model = AutoModelForSpeechSeq2Seq.from_pretrained(     model_id,      ms_dtype=mindspore.float16,      low_cpu_mem_usage=True,     use_safetensors=True,     attn_implementation=""flash_attention_2"", ) processor = AutoProcessor.from_pretrained(model_id) pipe = pipeline(     ""automaticspeechrecognition"",     model=model,     tokenizer=processor.tokenizer,     feature_extractor=processor.feature_extractor,     ms_dtype=mindspore.float16,     return_timestamps=True, )   eager mode test result    generation_time: 93.65066742897034, result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直转少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即指导师太忙伸手按住了口   flash_attention_2 mode test result    generation_time: 79.74670958518982, result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直转少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即指导师太忙伸手按住了口 result, generation_time = generate_with_time(pipe, ""/home/candyhong/workspace/whisper_large/tianlong0925.mp3"") print(f""generation_time: {generation_time}, result: {result['text']}"") ```  PyTorch + Ascend ```python import torch import torch_npu import time from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline torch_npu.npu.set_compile_mode(jit_compile=False) torch_npu.npu.config.allow_internal_format = False def generate_with_time(pipe, file_path):     start_time = time.time()     result = pipe(file_path)     generation_time = time.time()  start_time     return result, generation_time device = ""npu:0"" torch_dtype = torch.float16 model_id = ""openai/whisperlargev3""  default mode: eager  model = AutoModelForSpeechSeq2Seq.from_pretrained(      model_id,       torch_dtype=torch_dtype,       low_cpu_mem_usage=True,      use_safetensors=True,  ) model = AutoModelForSpeechSeq2Seq.from_pretrained(     model_id,     torch_dtype=torch_dtype,     low_cpu_mem_usage=True,     use_safetensors=True,     attn_implementation=""flash_attention_2"", ) model.to(device) processor = AutoProcessor.from_pretrained(model_id) pipe = pipeline(     ""automaticspeechrecognition"",     model=model,     tokenizer=processor.tokenizer,     feature_extractor=processor.feature_extractor,     torch_dtype=torch_dtype,     device=device,     return_timestamps=True, )   eager mode test result    generation_time: 58.42126774787903 result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直展少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即知道失态忙伸手按住了口   flash_attention_2 mode test result    generation_time: 252.1833713054657, result: 青光闪动一柄青钢剑疏地刺出指向中年汉子左肩使肩少年不带剑招用劳外斗  剑斜剑锋以削向那汉子右颈哪中年汉子竖剑挡格张来一声响双剑相击嗡嗡作声震声未竭双刃剑功复合你拆了三招中年汉子长剑猛地击落直展少年顶  门那少年臂向右侧左手剑绝学隐青钢剑鞠刺呐喊子大腿威两人剑法迅绝全力相搏威徒练武厅东边坐着爱人上手是个四十左右的中年道姑铁青着脸嘴唇  紧闭下手是个五十余岁的老者右手掠着长须神情甚是得意两人的座位相距一丈有余身后各站着二十余名男女弟子西边一排椅子上坐着十余位宾客东西  双方的目光都集中于场中二人的相斗眼下眼尖的少年与中年汉子已拆到七十余招前招越来越紧物资未分胜败突然周年汉子长剑挥出用力猛了身子微晃肆意摔跌席边  宾客中一个身穿青衫的年轻男子忍不住吃得一声笑他随即知道失态忙伸手按住了口 result, generation_time = generate_with_time(pipe, ""/home/candyhong/workspace/whisper_large/tianlong0925.mp3"") print(f""generation_time: {generation_time}, result: {result['text']}"") ```  Related Issues Fixes CC(Feat: Support Whisper + FlashAttention2) ",2025-04-08T08:54:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2015
这是一个功能需求报告，主要对象是支持 Whisper + FlashAttention2。由于截断了描述，用户正在提出涉及某项功能的需求。,Feat: Support Whisper + FlashAttention2,"**Is your feature request related to a problem? Please describe.** Currently, the Whisper models integrated in mindnlp do not leverage optimized attention backends like FlashAttention2, which are widely adopted in largescale Transformer architectures for both speed and memory efficiency. **Describe the solution you'd like** We would like to introduce FlashAttention2 support for Whisper models in mindnlp, leveraging MindSpore’s builtin operations and adapting relevant components for compatibility. Specifically, the solution includes: 1. Replace `flashattn` package functions with MindSpore APIs: Use `mindspore.ops.flash_attention_score` as a substitute for the original `flash_attn_func` and `flash_attn_varlen_func` provided by the `flashattn` library, enabling FlashAttention functionality directly within the MindSpore framework. 2. Reimplement `bert_padding` utilities in MindSpore: Convert the `bert_padding` utility functions used in `flashattn` (such as `index_first_axis` and `index_put_first_axis`) into equivalent implementations based on MindSpore, ensuring correct behavior for batched variablelength input. 3. Add a new utility module `model_flash_attention_utils`: Introduce a new helper module that includes functions like `_flash_attention_forward` and other FlashAttention2specific utilities, adapted for Whisper and written using MindSpore APIs. 4. Provide a new model class `WhisperFlashAttention2`: Create a new Whisper variant that integrates the above FlashAttention2 optimizations, preserving the original model architecture while improving runtime efficiency and scalability.",2025-04-08T08:38:23Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2014
这是一个用户提出需求的类型，涉及到Autoformer模型的微调。这个问题单可能是为了寻求帮助来进行Autoformer模型的微调工作。,【开源实习】Autoformer模型微调, Autoformer Mindnlp 微调  Autoformer模型微调任务链接：[【开源实习】autoformer模型微调 · Issue IAUOTL · MindSpore/community  Gitee.com](https://gitee.com/mindspore/community/issues/IAUOTL)  实现了huggingface/autoformertourismmonthly 基准权重 在 [monash_tsf/tourism_monthly] 数据集上的微调  base model: [huggingface/autoformertourismmonthly · Hugging Face](https://huggingface.co/huggingface/autoformertourismmonthly)  dataset: [MonashUniversity/monash_tsf · Datasets at Hugging Face](https://huggingface.co/datasets/MonashUniversity/monash_tsf)  Pytorch版本：Autoformer_tourism_monthly_finetune   微调结果  Mindspore  **MASE**: 1.6217024071216057,2025-04-05T07:09:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2013
这是一个bug报告，主要涉及MindNLP库中的peft使用prefix tuning时报错。原因可能是硬件环境是Windows+CPU，软件环境是MindSpore版本。,peft使用prefix tuning时报错,"在使用mindnlp.peft进行prefix tuning的时候报错： ``` Traceback (most recent call last):   File ""E:\git\biogpt\finetune.py"", line 144, in      loss = grad_fn(**batch)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\core\autograd\function.py"", line 35, in value_and_grad_f     values = fn_(*args, **kwargs)   File ""E:\git\biogpt\finetune.py"", line 131, in forward_fn     outputs = model(**batch)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\core\nn\modules\module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\core\nn\modules\module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\peft\peft_model.py"", line 557, in forward     prompts = prompts.to(inputs_embeds.dtype) AttributeError: 'tuple' object has no attribute 'to' ```   硬件环境 > Windows+cpu   软件环境:  MindSpore version (e.g., 1.7.0.Bxxx) :2.5.0  Python version (e.g., Python 3.7.5) :3.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):windows  GCC/Compiler version (if compiled from source): 原因在于get_prompt函数输出为一个元组，根本上是以下代码导致： ``` if peft_config.num_transformer_submodules == 2:                 past_key_values = ops.cat([past_key_values, past_key_values], dim=2)             past_key_values = past_key_values.permute([2, 0, 3, 1, 4]).split(                 peft_config.num_transformer_submodules * 2             ) ``` 进行split后输出的为元组，没有to方法导致报错。 修改建议： 增加类型转换即可解决 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-04-01T12:25:43Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2012
"这是一个bug报告类型的issue，主要涉及mindnlp.peft微调功能，在调用微调时出现了""RuntimeError: The pointer[top_cell_] is null.""报错。原因可能是指针`top_cell_`为空导致的。",RuntimeError: The pointer[top_cell_] is null.,"问题描述 在调用mindnlp.peft微调的时候发生报错 ``` Traceback (most recent call last):   File ""/tmp/code/biogpt/finetune.py"", line 130, in      trainer.train()   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 781, in train     return inner_training_loop(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1133, in _inner_training_loop     tr_loss_step = self.training_step(model, inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1424, in training_step     loss = self.grad_fn(inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/autograd/function.py"", line 35, in value_and_grad_f     values = fn_(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1416, in forward     return self.compute_loss(model, inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1438, in compute_loss     outputs = model(**inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 646, in forward     past_key_values = self.get_prompt(batch_size)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 319, in get_prompt     prompt_tokens = prompt_tokens[:, : peft_config.num_virtual_tokens]   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 473, in __getitem__     out = tensor_operator_registry.get('__getitem__')(self, index)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/multitype_ops/_compile_utils.py"", line 201, in _tensor_getitem     new_index, tensor_update_types, tensor_update_args = getitem_tensor_index_info(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/operations/_inner_ops.py"", line 2356, in __call__     return Tensor_.getitem_index_info(data, index, self.is_ascend) RuntimeError: The pointer[top_cell_] is null.  Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/pynative/grad/grad.h:75 top_cell ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > ASCEND910  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version :2.3.1  Python version :3.9.18  OS platform and distribution :Linux",2025-03-31T10:46:31Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2011
这是一个用户提出需求的issue，主要对象是对audio_spectrogram_transformer模型的微调报告。,【开源实习】audio_spectrogram_transformer模型微调, audio_spectrogram_transformer 模型微调报告  任务  任务编号：IAUOSX  任务链接：【开源实习】audio_spectrogram_transformer模型微调  实现了audio_spectrogram_transformer 在esc50数据集上的微调  模型：MIT/astfinetunedaudioset10100.4593  数据集: ashraq/esc50  结果对比： **Mindnlp+D910B**   ,2025-03-25T08:22:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2010
这是一个用户提出需求的类型，主要涉及的对象是Mamba2模型迁移。,【开源实习】Mamba2模型迁移,,2025-03-23T14:13:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2009
该issue类型为用户提出需求，主要涉及到Albet模型微调任务链接。原因是用户在github上提出了对Albet模型微调的需求或帮助请求。,【开源实习】 Albert 模型微调, Albert mindnlp 微调  Albert模型微调任务链接：【开源实习】albert模型微调 · Issue IAUONP · MindSpore/community  Gitee.com  实现了Albertbasev1 基准权重 在 [Sentiment analysis of IMDb reviews  Stanford University] 数据集上的微调  base model: albert/albertbasev1 · Hugging Face  dataset: stanfordnlp/imdb · Datasets at Hugging Face  Result for finetune training for 3 epochs  torch ,2025-03-23T09:54:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2008
这是一个bug报告，主要涉及到PeftModel.from_pretrained加载权重前后dtype不一致的问题，导致dtype无法和ckpt保持一致。,解决PeftModel.from_pretrained加载权重前后dtype不一致的问题,Fixes CC(PeftModel.from_pretrained加载权重后的dtype无法和ckpt保持一致) ,2025-03-23T09:16:10Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/2007,修改后检查加载ckpt前后的dtype，发现可以保持一致  ckpt文件的dtype !image  加载权重后的dtype !image 检查加载权重的数值，可对齐 !image
这是一个bug报告，涉及的对象是PeftModel.from_pretrained加载权重后的dtype无法和ckpt保持一致。由于dtype不一致导致了该问题的出现。,PeftModel.from_pretrained加载权重后的dtype无法和ckpt保持一致,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. mindnlp在通过`PeftModel.from_pretrained`加载LoRA adapter权重时，权重事先以fp32保存，但加载后显示权重的dtype为fp16  ckpt文件的dtype !Image  加载权重后dtype !Image 相对比下torch同代码，加载后的权重dtype仍为fp32  safetensors文件的type !Image  加载权重后dtype !Image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ```python import mindspore import mindnlp from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer from mindnlp.engine import TrainingArguments, Trainer from mindnlp.dataset import load_dataset, BaseMapFunction from mindspore import load_checkpoint, Tensor from mindnlp.transformers import GenerationConfig import troubleshooter as ts import numpy as np checkpoint_save_dir = ""xxx""  MindSpore base model ms_base_model = AutoModelForCausalLM.from_pretrained(""deepseekai/DeepSeekR1DistillQwen1.5B"", ms_dtype=mindspore.float16) ms_base_model.generation_config = GenerationConfig.from_pretrained(""deepseekai/DeepSeekR1DistillQwen1.5B"") ms_base_model.generation_config.pad_token_id = ms_base_model.generation_config.eos_token_id  MindSpore LoRA Adapter from mindnlp.peft import LoraConfig, TaskType, get_peft_model, PeftModel ms_config = LoraConfig(     task_type=TaskType.CAUSAL_LM,      target_modules=[""q_proj"", ""k_proj"", ""v_proj"", ""o_proj"", ""gate_proj"", ""up_proj"", ""down_proj""],     inference_mode=False,  训练模式     r=8,  Lora 秩     lora_alpha=32,  Lora alaph，具体作用参见 Lora 原理     lora_dropout=0.0 Dropout 比例 )  检查LoRA权重的参数dtype adapter_model_dir = os.path.join(checkpoint_save_dir, ""lora_init_checkpoint"") ms_adapter_model_path = os.path.join(adapter_model_dir, ""adapter_model.ckpt"") ms_param_dict = mindspore.load_checkpoint(ms_adapter_model_path) print(""""*20, ""Check ckpt dtype"", """"*20) for key, value in ms_param_dict.items():     print(f""{key} : {value.dtype}"")  加载LoRA权重 ms_model = PeftModel.from_pretrained(ms_base_model, adapter_model_dir, is_trainable=True)  检查加载后的权重dtype print(""""*20, ""Check param dtype after loading ckpt"", """"*20) for name, param in ms_model.parameters_dict().items():     if ""lora_"" in name:         print(f""{name} : {param.dtype}"") ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here. 检查发现，是由于mindnlp在`Module`的`_load_from_state_dict`中，assign parameters的dtype是原始模型的dtype，而由于base model实例化加载权重时是fp16，所以LoRA adapter也是转换成了fp16进行加载 !Image torch的是直接将参数复制 !Image 所以把这里改为如下代码就好 !Image ```python dtype = input_param.dtype ```",2025-03-23T09:13:08Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2006
这是一个bug报告，涉及的主要对象是CC(windows系统下加载模型)。由于windows系统下加载模型错误导致了这个bug。,threads_exclusive_http_get fix,fix the issue in CC(windows系统下加载模型错误) ,2025-03-22T12:45:27Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2005
这是一个bug报告，主要涉及mindnlp库在Windows系统下加载模型时出现报错的问题。由于导入winfcntlock所致，导致了加载模型错误的症状。,windows系统下加载模型错误,"在windows系统下，通过mindnlp库加载模型的时候会发生报错： ``` import winfcntlock as fcntl  pylint: disable=importerror ModuleNotFoundError: No module named 'winfcntlock' ``` 经检查，修改utils/download.py里的import winfcntlock as fcntl为from . import winfcntlock as fcntl可以解决该问题。但是，继续运行之后仍有报错： ``` Traceback (most recent call last):   File ""E:\git\biogpt\infer_mindspore.py"", line 8, in      tokenizer = BioGptTokenizer.from_pretrained(model_name)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\transformers\tokenization_utils_base.py"", line 2115, in from_pretrained     resolved_config_file = cached_file(   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\utils\download.py"", line 527, in cached_file     resolved_file = download(   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\utils\download.py"", line 655, in download     raise exp   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\utils\download.py"", line 651, in download     pointer_path = threads_exclusive_http_get(url, storage_folder, download_file_name=relative_filename, proxies=proxies, headers=headers)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\utils\download.py"", line 162, in threads_exclusive_http_get     fcntl.flock(fd, fcntl.LOCK_UN) AttributeError: module 'mindnlp.utils.winfcntlock' has no attribute 'flock'. Did you mean: 'lock'? ``` 这是因为，download.py中引用winfcntlock.py中的函数名称和实际名称对不上，有两处不对：①download.py中引用的是fcntl.flock()，但是winfcntlock.py中实际名称为lock；②download.py中引用的是fcntl.LOCK_UN，但是winfcntlock.py中没有这个变量声明； 个人参考网上资料，找到了一个解决方案：修改winfcntlock.py中的lock函数名称为flock，并添加变量LOCK_UN = 0x08 。 修改后，为了解决报错： ``` Traceback (most recent call last):   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\utils\download.py"", line 160, in threads_exclusive_http_get     raise exp   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\mindnlp\utils\download.py"", line 156, in threads_exclusive_http_get     fcntl.flock(fd, fcntl.LOCK_EX)   File ""D:\install\anaconda\envs\biogpt\lib\sitepackages\winfcntl\winfcntl.py"", line 180, in flock     handle = msvcrt.get_osfhandle(fd) TypeError: '_io.TextIOWrapper' object cannot be interpreted as an integer ``` 修改了winfcntlock.py中的hfile = win32file._get_osfhandle(file.fileno())为fd = hfile = win32file._get_osfhandle(file)，不然对int变量取file.fileno()会报错。 修改后，下载模型能够正常进行，但是文件夹里会有很多.lock临时文件:  修改download.py文件，在下载完成后删除.lock临时文件： ``` lock_file.close() try:     os.remove(lock_file_path) except Exception as delete_exp:     logging.error(f""Failed to delete lock file: {delete_exp}"") ```  现在在windows系统上可以正常运行了，对于download.py文件没有做很多修改，所以linux的运行应该不受影响。",2025-03-22T06:41:24Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2004
这个issue属于功能增强类型，主要对象是mindnlp的项目。原因可能是为了添加支持Qwen2.5模型而提出的需求。,add Qwen2_5_vl,Added support for qwen2.5 from transformers/main,2025-03-22T04:41:10Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2003
这是用户提交的一个功能需求，涉及到移植glpn模型在mindspore框架下的推理代码。根据问题描述，该需求主要关注在开源实习的应用开发任务中使用这个模型。,移植了glpn模型在mindspore框架下的推理代码，用于开源实习的应用开发任务,![Uploading b1af87424bda9982760c11c651e56106.jpg…](),2025-03-21T18:14:02Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/2002
这个issue是一个bug报告，涉及对象是mindnlp代码库中的mint模块。由于接口调用问题导致了软件环境报告不完整。,Fix mint.nonzero interface call," Test Report Software Environment / 软件环境 (Mandatory / 必填):  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.10.0  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04.4 LTS  GCC/Compiler version (if compiled from source): 11.04 Test Code:   Related Issues Fixes CC(TypeError: nonzero() takes 1 positional argument but 2 were given) ",2025-03-21T00:51:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2001
该issue属于bug报告类型，主要涉及对象为mindnlp库，由于参数传递错误导致了TypeError异常。,TypeError: nonzero() takes 1 positional argument but 2 were given,"**Describe the bug/ 问题描述 (Mandatory / 必填)** `TypeError: nonzero() takes 1 positional argument but 2 were given`  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.10.0  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04.4 LTS  GCC/Compiler version (if compiled from source): 11.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** ``` import mindspore import numpy as np from mindspore import Tensor from mindnlp.core import ops x = Tensor(np.array([[[1,  0], [5, 0]]]), mindspore.int32) output = ops.nonzero(x, as_tuple=True)[0] ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. `output: Tensor(shape=[2], dtype=Int64, value= [0, 0])` **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-03-21T00:49:02Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2000
这是一个用户提出需求的issue，主要涉及MindNLP项目在持续集成中使用官方的MindSpore。由于可能当前CI系统未配置使用官方的MindSpore，导致用户提出这一需求。,use official mindspore for CI,,2025-03-20T09:10:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1999
这是一个关于软件安装问题的bug报告，主要涉及启智平台上使用源码下载mindnlp时出现下载不全或下载失败的情况。,add mindnlp==0.4.1 to pypi,在启智平台上用源码下载mindnlp经常容易出现下载不全（比如缺少trasnformers库）或者下载失败的情况，用pip install的话可能相对来说会简单一些。,2025-03-20T07:57:41Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1998,done
这是一个用户提交的开源实习任务，类型是需求提出；主要涉及对象为MindNLP项目中的ALIGN模型；用户提出了在MSCOCO val2017数据集上微调实验的需求。,【开源实习】align模型微调 IAUOS5,实现了ALIGN模型在MSCOCO val2017数据集上的微调实验。   任务链接在(https://gitee.com/mindspore/community/issues/IAUOS5)。   数据集为MSCOCO val2017，模型为kakaobrain/align，硬件环境晟腾910b   MindSpore实现的代码基于MindNLP。   PyTorch的基准实验基于transformers框架，使用4060硬件，仓库位于[(https://github.com/huadaox/kakaobrain_align_ft)]。   实验结果如下： !image,2025-03-19T15:41:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1997
这是一个开源实习的任务提议，主要涉及mindnlp下的chatglm-4模型微调。,【开源实习】chatglm-4模型微调,【开源实习】chatglm4模型微调：https://gitee.com/mindspore/community/issues/IB4YYU 基于GPU+Pytorch上的结果对比基于NPU+MindSpore上的结果，由于数据过多，本表格仅节选，详细见files Step  0.025700,2025-03-19T09:36:14Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1996
"这个issue类型是实习报告，该问题单涉及的主要对象是对""bit50""模型在""oxford_flowers102""数据集上的微调实验结果的描述。",【开源实习】bit模型微调 ," bit微调 实现了""HorcruxNo13/bit50""模型在""dpdlbenchmark/oxford_flowers102""数据集上的微调实验。 任务链接在https://gitee.com/mindspore/community/issues/IAUPCI transformers+pytorch+3090的benchmark是自己编写的，仓库位于https://github.com/outbreaksen/Bit_flowers102_Finetune 更改代码位于llm/finetune/bit，只包含mindnlp+mindspore的 实验结果如下  硬件 资源规格：NPU: 1*AscendD910B(显存: 64GB), CPU: 24, 内存: 192GB 智算中心：武汉智算中心 镜像：mindspore_2_5_py311_cann8 torch训练硬件资源规格：Nvidia 3090  模型与数据集 模型：""HorcruxNo13/bit50"" 数据集：""dpdlbenchmark/oxford_flowers102""  Eval Loss Values 表格   图片分类测试 问题来自评估数据集的第一个问题 * 问题输入：   dataset['test'][0]['image'] * 真实标签：   26   * mindnlp未微调前的回答：   25 * mindnlp微调后的回答：   26 * torch微调前的回答：   41 * torch微调后的回答：   26",2025-03-19T01:48:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1995
这是一个关于开源实习项目中Bigbird Pegasus模型微调的issue，主要是用户提出需求。,【开源实习】Bigbird pegasus模型微调," bigbird_pegasus微调 实现了bigbird_pegasus模型在google/SyntheticPersonaChat数据集上的微调实验。 任务链接在https://gitee.com/mindspore/community/issues/IAUPBF transformers+pytorch+3090的benchmark是自己编写的，仓库位于https://github.com/outbreaksen/bigbird_pegasus_finetune 更改代码位于llm/finetune/bigbird_prgasus，只包含mindnlp+mindspore的 硬件 资源规格：NPU: 1*AscendD910B(显存: 64GB), CPU: 24, 内存: 192GB 智算中心：武汉智算中心 镜像：mindspore_2_5_py311_cann8 torch训练硬件资源规格：Nvidia 3090 模型与数据集 模型：""google/bigbirdpegasuslargearxiv"" 数据集：""google/SyntheticPersonaChat"" 实验结果如下  Loss Values 表格 ",2025-03-18T06:02:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1994
这是一个bug报告，问题涉及到mindnlp库中的ops.max函数。由于未提供具体内容，无法确定导致bug的具体原因。,fix ops.max,,2025-03-18T04:10:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1993
这是一个bug报告，主要对象是MindNLP项目中的模型加载器（loader），用户提出需要使用新的safetensors loader来解决问题。,use new safetensors loader,,2025-03-17T11:33:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1992
这是一个bug报告，涉及主要对象是mindnlp的ms2.5版本。这个bug可能是由于代码错误或逻辑问题导致的功能异常。,fix bugs for ms2.5,,2025-03-17T09:56:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1991
这个issue类型是功能需求，主要涉及的对象是triton自定义操作。用户提出希望mindnlp支持triton自定义操作，可能是为了增强模型的灵活性和适用性。,support triton self-defined op,,2025-03-17T07:59:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1990
这是一个bug报告，主要涉及到vera模型的微调方式未实现，可能是由于代码实现不完整或存在错误所导致的。,开源实习-金逸-sequence_classification/vera模型微调,issue地址:https://gitee.com/mindspore/community/issues/IAN0OJ 任务开始发现vera微调方式并未实现，因此本次pr首先实现了vera微调，再利用实现的vera进行finetuning，finetuning和示例的对比如下: 首先对比模型微调参数占比: torch: !image mindnlp: !image 再对比微调结果: torch:!image mindnlp: !image 两者基本相同,2025-03-15T08:58:09Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1989
这是一个bug报告，涉及的主要对象是mindspore，在CPU模式下因缺乏“visible_devices”的指定导致问题。,CPU模式下，缺乏“visible_devices”的指定,"**Describe the bug/ 问题描述 (Mandatory / 必填)** windows11环境下，python3.11.4， mindspore2.5.0， mindnlp0.4.0下， 基于mindnlp.transformer加载qwen2.5大模型，报：UnboundLocalError: cannot access local variable 'visible_devices' where it is not associated with a value  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU: 11th Gen Intel(R) Core(TM) i511400H @ 2.70GHz   2.69 GHz RAM: 32GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.5.0  Python version (e.g., Python 3.7.5) : 3.11.4  OS platform and distribution (e.g., Linux Ubuntu 16.04): Windows 11 家庭中文版（版本号23H2）  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '.' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. Traceback (most recent call last):   File ""D:\code_research\torch2mindspore\qwen25_1_5B.py"", line 15, in      model = AutoModelForCausalLM.from_pretrained(             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""G:\code_research\mindspore\Lib\sitepackages\mindnlp\transformers\models\auto\auto_factory.py"", line 510, in from_pretrained     return model_class.from_pretrained(            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""G:\code_research\mindspore\Lib\sitepackages\mindnlp\transformers\modeling_utils.py"", line 2994, in from_pretrained     max_memory = get_max_memory(max_memory)                  ^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""G:\code_research\mindspore\Lib\sitepackages\mindnlp\accelerate\utils\modeling.py"", line 691, in get_max_memory     if visible_devices is not None:        ^^^^^^^^^^^^^^^ UnboundLocalError: cannot access local variable 'visible_devices' where it is not associated with a value **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here. 经过跟踪，发现在 mindnlp/accelerate/utils/modeling.py 的 get_max_memory函数里的device_target只有“GPU”和“Ascend”,缺少“CPU”的处理，导致进入此函数后，出现 visible_devices没有定义的情况",2025-03-15T02:08:58Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1988,CPU不支持多卡并行（没这个用法），你是要多CPU推理？,"谢谢！，但是按照下面设置了单卡操作，但是仍然会出现这种错误，请教下老师，是不是设置的不对？ from mindspore import context context.set_context(mode=context.GRAPH_MODE, device_target=""CPU"") context.set_auto_parallel_context(parallel_mode=context.ParallelMode.STAND_ALONE) 设置并行模式为单卡模式"
这是一个bug报告，涉及的主要对象是mindnlp项目下的一份文件。这个问题很可能是由于导入错误导致的。,Fix incorrect import quick_start.md,as per title,2025-03-13T17:59:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1987
这是一个bug报告，主要涉及的对象是safetensor。该问题出现的原因可能是在将safetensor加载回numpy时遇到了问题。,load safetensor back to numpy,,2025-03-13T11:11:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1986
这个issue属于bug报告类型，涉及的主要对象是mindnlp库。这个问题可能是由mindspore2.5-2.6版本更新导致的错误。,fix mindspore2.5-2.6 caused error,,2025-03-13T07:43:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1985
这是一个Bug报告，主要对象是mindnlp后端pipeline，可能由于mindspore版本为2.6导致出现段错误。,mindnlp后端pipeline相关自动化用例报错：Segmentation fault,openmind在跑mindnlp pipeline的时候，出现段错误，mindspore版本为2.6,2025-03-12T07:10:40Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1984
这是一个bug报告类型的issue，涉及到DeepSeek-R1-Distill-Qwen-32B的四卡运行中出现的报错。,910A四卡跑DeepSeek-R1-Distill-Qwen-32B报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 910A四卡跑DeepSeekR1DistillQwen32B报错  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片 Ascend 910A 32G  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): Ascend HDK24.1.RC3 CANN 8.0.0 MindSpore 2.5.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph 参考执行llm/inference/llama3 **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error msrun worker_num=4 local_worker_num=4 master_port=8118 join=True bind_core=True run_llama3_distributed.py **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. Loading checkpoint shards:   0% 0/3 [00:00 worker_3.log50    outputs = model.generate( worker_3.log51  File ""/usr/lib/python3.10/contextlib.py"", line 79, in inner worker_3.log52    return func(*args, **kwds) worker_3.log53  File ""/usr/local/lib/python3.10/distpackages/mindnlp/transformers/generation/utils.py"", line 1789, in generate  worker_3.log59  File ""/usr/local/lib/python3.10/distpackages/mindspore/common/tensor.py"", line 113, in tensor worker_3.log60    return Tensor(input_data, dtype, shape, init, internal, const_arg)   .typing: () > tensor_type[{dtype}] worker_3.log61  File ""/usr/local/lib/python3.10/distpackages/mindspore/common/tensor.py"", line 258, in __init__ worker_3.log62    _check_input_data_type(input_data) worker_3.log63  File ""/usr/local/lib/python3.10/distpackages/mindspore/common/tensor.py"", line 71, in _check_input_data_type worker_3.log:64:    raise TypeError( worker_3.log:65:TypeError: For Tensor, the input_data is [151643, None] that contain unsupported element. worker_3.log66[INFO] PS(162172,ffff0ca8f120,python):2025031009:40:04.783.867 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:220] Start] Event base dispatch success! worker_3.log67[INFO] PS(162172,fffef7fff120,python):2025031009:40:04.783.867 [mindspore/ccsrc/ps/core/communicator/tcp_client.cc:318] Start] Event base dispatch success! Traceback (most recent call last):   File ""/usr/local/bin/msrun"", line 8, in      sys.exit(main())   File ""/usr/local/lib/python3.10/distpackages/mindspore/parallel/cluster/run.py"", line 150, in main     run(args)   File ""/usr/local/lib/python3.10/distpackages/mindspore/parallel/cluster/run.py"", line 144, in run     process_manager.run()   File ""/usr/local/lib/python3.10/distpackages/mindspore/parallel/cluster/process_entity/_api.py"", line 225, in run     self.join_processes()   File ""/usr/local/lib/python3.10/distpackages/mindspore/parallel/cluster/process_entity/_api.py"", line 336, in join_processes     raise RuntimeError(""Distributed job exited with exception. Please check logs in "" RuntimeError: Distributed job exited with exception. Please check logs in directory: . **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-03-10T09:46:55Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1983
这是一个bug报告，主要对象是生成token时的用户界面。原因可能是更新导致界面显示问题。,It shows a user-friendly UI when generating token.,"It shows a relatively userfriendly interface when generating token. The update avoids producing too many multiline outputs when the program generates 576 tokens, thus avoiding useful printed information being squeezed out of the buffer displayed on the screen.",2025-03-10T04:19:17Z,,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1982,A prompt for the print() function at line 81 of generation.py has been added.,The changes have been merged.
这是用户分享一个关于albert模型微调的开源实习项目，不属于bug报告类型，主要涉及对象是albert模型和数据集SetFit/20_newsgroups，用户可能是寻求分享项目进展或邀请合作。,【开源实习】albert模型微调 ,"实现了""albert/albertbasev1""模型在""SetFit/20_newsgroups""数据集上的微调实验。 任务链接在https://gitee.com/mindspore/community/issues/IAUONP transformers+pytorch+4060的benchmark是自己编写的，仓库位于https://github.com/outbreaksen/albert_finetuned 更改代码位于llm/finetune/albert，只包含mindnlp+mindspore的 实验结果如下  Albert的20Newspaper微调  硬件 资源规格：NPU: 1*AscendD910B(显存: 64GB), CPU: 24, 内存: 192GB 智算中心：武汉智算中心 镜像：mindspore_2_5_py311_cann8 torch训练硬件资源规格：Nvidia 3090  模型与数据集 模型：""albert/albertbasev1"" 数据集：""SetFit/20_newsgroups""  训练与评估损失 由于训练的损失过长，只取最后十五个loss展示  mindspore+mindNLP ",2025-03-10T04:11:15Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1981
该问题单类型为特性增强，涉及的主要对象是blenderbot_small模型的微调在不同数据集上的实现。,【开源实习】blenderbot_small模型微调,"分别实现了blenderbot_small模型在""stanfordnlp/coqa""和""google/SyntheticPersonaChat""数据集上的微调实验。 因为在coqa数据集上的效果并不好，所以又做了Persona的微调，Persona的微调还是不错的，这里都上传了供参考 任务链接在https://gitee.com/mindspore/community/issues/IAUPE8 transformers+pytorch+3090的benchmark是自己编写的，仓库位于https://github.com/outbreaksen/blenderbot_small_finetuned 更改代码位于llm/finetune/blenderbot_small，只包含mindnlp+mindspore的 实验结果如下  Blenderbot_Small的coqa微调  硬件 资源规格：NPU: 1*AscendD910B(显存: 64GB), CPU: 24, 内存: 192GB 智算中心：武汉智算中心 镜像：mindspore_2_5_py311_cann8 torch训练硬件资源规格：Nvidia 3090  模型与数据集 模型：""facebook/blenderbot_small90M"" 数据集：""stanfordnlp/coqa""  训练损失 ",2025-03-10T03:59:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1980
这是一个bug报告，涉及的主要对象是mindnlp.transformers中的ConditionalDetrForObjectDetection.from_pretrained和ConditionalDetrForSegmentation.from_pretrained模型。由于ConditionalDetrConvEncoder在调用replace时未能正确创建backbone变量，导致bug出现。,mindnlp.transformers中的ConditionalDetrForObjectDetection.from_pretrained和ConditionalDetrForSegmentation.from_pretrained模型在初始化过程中未能正确创建backbone变量,"**Describe the bug/ 问题描述 (Mandatory / 必填)** ConditionalDetrConvEncoder在调用replace_batch_norm(backbone)时，backbone尚未被正确赋值。 mindspore 2.5.0 mindnlp 0.4.0 cpu Python 3.9 Ubuntu24.04 问题复现 object detection ``` import matplotlib.pyplot as plt import mindspore from mindspore import Tensor, ops from mindnlp.transformers import ConditionalDetrImageProcessor, ConditionalDetrForObjectDetection from PIL import Image import requests  set the device to GPU if available mindspore.set_device(device_target=""GPU"" if mindspore.context.get_context(     ""device_target"") == ""GPU"" else ""CPU"") url = ""http://images.cocodataset.org/val2017/000000039769.jpg"" image = Image.open(requests.get(url, stream=True).raw)  need to use a compatible image processor image_processor = ConditionalDetrImageProcessor.from_pretrained(     ""microsoft/conditionaldetrresnet50"")  need to use a compatible model for object detection model = ConditionalDetrForObjectDetection.from_pretrained(     ""microsoft/conditionaldetrresnet50"") ``` 报错： !Image 问题复现 segmentation ``` import io import requests from PIL import Image from mindspore import Tensor import numpy from mindnlp.transformers import (     AutoImageProcessor,     ConditionalDetrConfig,     ConditionalDetrForSegmentation, ) from mindnlp.transformers.image_transforms import rgb_to_id url = ""http://images.cocodataset.org/val2017/000000039769.jpg"" image = Image.open(requests.get(url, stream=True).raw) image_processor = AutoImageProcessor.from_pretrained(     ""microsoft/conditionaldetrresnet50"")  randomly initialize all weights of the model config = ConditionalDetrConfig() model = ConditionalDetrForSegmentation(config) ``` 运行结果： !Image",2025-03-09T14:31:02Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1979
这是一个关于BlenderBot（400M）模型微调性能对比报告的issue，描述了实验配置和分析结论。,【开源实习】blenderbot模型微调," BlenderBot（400M） 模型微调性能对比报告  实验配置  自编PyTorch版实现参考    分析结论 1. **收敛特性**：     MindNLP 在 Epoch 2 展现更陡峭的损失下降（43.8% vs 35.9%）     最终验证损失优势显著（**+12.22%**） 2. **硬件效率**：     昇腾 910B 展现更强的大 batch 稳定性（HBM 带宽优势） 3. **过拟合控制**：     MindNLP 验证损失持续下降，PyTorch 在 Epoch3 出现轻微过拟合（训练损失 ↑14.5%时验证损失 ↑12.2%）  **注释**：   ① 测试基于 Dolly15k 数据集（15,000 样本）   ② 所有实验重复 3 次取均值，标准差<±0.03   ③ ▲/▼ 表示相对优劣方向，粗体为显著优势项  ",2025-03-08T21:27:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1978
这是一条有关开源实习（Internship）的Github Issue，主要涉及到Blenderbot模型微调。,【开源实习】blenderbot模型微调,,2025-03-08T20:42:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1977
这个issue属于用户提出需求类型，主要涉及对象是mindnlp软件的NPU调用。由于用户想了解如何指定使用NPU，并且是否类似于使用torch的方式，因此提出了有关指定调用NPU的问题。,mindnlp 怎么指定调用npu呢,"mindnlp 怎么指定调用npu呢？ 也是类似 torch 么？ import torch from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM tokenizer = AutoTokenizer.from_pretrained(""tiiuae/falcon7b"") with torch.device(""cuda""):     model = AutoModelForCausalLM.from_pretrained(         ""tiiuae/falcon7b"",         torch_dtype=torch.float16,         use_flash_attention_2=True, )",2025-03-08T08:12:57Z,,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1976,补充一下并没有在 mindspore 中找到类似 device 的方法 我使用的 mindspore 的版本是 2.4.0  !Image,mindspore机制不支持，无法指定
这是一个需求类型的issue，主要涉及 BEiT 模型的微调，用户提出了实现微调任务的链接。由于该模型可能需要进一步微调以满足特定需求或者提高性能，用户寻求相关支持或资源以完成该任务。,开源实习 BEiT 模型微调,BEiT模型微调任务链接：https://gitee.com/mindspore/community/issues/IAUP1E 实现了microsoft beitbasepatch16224 基准权重 在 cifar10 数据集上的微调  Result for finetune training for 3 epochs  torch ,2025-03-06T12:22:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1975
这是一个用户提出需求的issue，主要涉及mindnlp中是否有类似transformer中FlashAttentionKwargs的实现。,在mindnlp里是否有类似transformer中FlashAttentionKwargs的实现？,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在尝试使用mindspore与mindnlp将huggingface上的qwen2模型（基于pytorch和transformer）时，在翻译Qwen2Attention层时，发现FlashAttentionKwargs在mindnlp中并无对应实现，如何解决这个问题 ```python def forward(         self,         hidden_states: torch.Tensor,         position_embeddings: Tuple[torch.Tensor, torch.Tensor],         attention_mask: Optional[torch.Tensor],         past_key_value: Optional[Cache] = None,         cache_position: Optional[torch.LongTensor] = None,         **kwargs: Unpack[FlashAttentionKwargs],     )  ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version  : 2.4.10    Python 3.11  OS platform and distribution: Windows  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** path=~\.conda\envs\torch_qwen2\Lib\sitepackages\transformers\modeling_flash_attention_utils.py mindnlp在transformer中提供相关支持 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !Image",2025-03-06T08:24:53Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1974,我应该自己实现一个类似的类吗？,暂时没有，因为没有接入GPU的flash attention实现。
这是一个bug报告类型的issue，主要涉及mindnlp库中的transformers模块下的AutoModelForObjectDetection.from_pretrained方法，由于无法识别条件化检测模型conditional_detr导致加载失败。,在mindnlp的mindnlp.transformers.AutoModelForObjectDetection.from_pretrained方法中无法识别conditional_detr，无法加载,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在mindnlp的mindnlp.transformers.AutoModelForObjectDetection.from_pretrained方法中无法识别conditional_detr  **Hardware Environment(`cpu )  / 硬件环境**:  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (2.5.0) :  mindnlp version 0.4.0  Python version (e.g., Python 3.9) :  OS platform and distribution (e.g., Linux Ubuntu 24.04): **To Reproduce / 重现步骤 (Mandatory / 必填)** 复现错误 ``` import matplotlib.pyplot as plt import mindspore from mindspore import Tensor, ops from mindnlp.transformers import AutoImageProcessor, AutoModelForObjectDetection from PIL import Image import requests  set the device to GPU if available mindspore.set_device(device_target=""GPU"" if mindspore.context.get_context(""device_target"") == ""GPU"" else ""CPU"") url = ""http://images.cocodataset.org/val2017/000000039769.jpg"" image = Image.open(requests.get(url, stream=True).raw)  need to use a compatible image processor image_processor = AutoImageProcessor.from_pretrained(""./microsoft/conditionaldetrresnet50"")  need to use a compatible model for object detection model = AutoModelForObjectDetection.from_pretrained(""./microsoft/conditionaldetrresnet50"") ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 希望可以正常的加载模型并且去做finetune **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !Image",2025-03-04T07:05:26Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1973
这是一个用户提出需求的issue，主要涉及的对象是对bigbird_pegasus模型在databricks/databricksdolly15k数据集上的微调实验。由于用户需要开源实习，希望进行模型微调的任务。,【开源实习】bigbird_pegasus模型微调 ,实现了bigbird_pegasus模型在databricks/databricksdolly15k数据集上的微调实验。 任务链接在https://gitee.com/mindspore/community/issues/IAUPBF transformers+pytorch+4060的benchmark是自己编写的，仓库位于https://github.com/outbreaksen/bigbird_pegasus_finetune 更改代码位于llm/finetune/bigbird_prgasus，只包含mindnlp+mindspore的 实验结果如下  bigbird_pegasus模型微调对比  train loss 对比微调训练的loss变化 ,2025-03-04T02:24:52Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1972
这是一个关于开源实习项目中未合并提交请求的问题，涉及的主要对象是LayoutLM模型应用开发。原因是之前提交的PR太久未合并，导致开发者将后续任务的commit传上来。,开源实习-LayoutLM模型应用开发-金逸,"之前提交pr太久没合并,把后面做的任务commit传上来了,之前的pr已通过审核可合并:https://github.com/mindsporelab/mindnlp/pull/1957 ,因此修改后重新提交pr",2025-03-01T12:54:29Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1971
这是一个用户提出开源实习需求的issue，涉及到LayoutXLM模型应用开发。由于该模型应用的需求或者问题，用户寻求相关的帮助。,【开源实习】LayoutXLM模型应用开发,gitee地址：https://gitee.com/mindspore/community/issues/IAADJV,2025-03-01T04:16:50Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1970
这是一个bug报告，针对pyboost bug，适应了新的orangePi镜像，禁用了多线程。,"fix pyboost bug, adapt to new orangePi image, disable multi thread",,2025-02-28T11:20:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1969
这是一个用户提出需求的issue，主要涉及将DeepSeekR1DistillQwen1.5B的akpt模型转成mindir，可能是由于缺乏相关操作指引导致用户无法完成这一操作。,如何将akpt模型保存成mindir," 1.Describe the current behavior / 问题描述 我需要将DeepSeekR1DistillQwen1.5B的akpt模型转成mindir模型。模型仓库地址是https://modelers.cn/models/MindSporeLab/DeepSeekR1DistillQwen1.5B。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Steps to reproduce the issue / 重现步骤 下面是在CPU上的执行代码。我需要将akpt模型转成mindir模型。模型仓库地址是https://modelers.cn/models/MindSporeLab/DeepSeekR1DistillQwen1.5B。 ```python from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer import mindspore as ms model_name = 'DeepSeekR1DistillQwen1.5B' model = AutoModelForCausalLM.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name) prompt = ""请介绍一下你自己"" inputs = tokenizer(prompt, return_tensors=""ms"") outputs = model.generate(     input_ids=inputs[""input_ids""],     attention_mask=inputs[""attention_mask""],     max_length=512,     num_return_sequences=1) response = tokenizer.decode(outputs[0], skip_special_tokens=True) print(""Generated Response:"", response) ``` 在mindnlp文档中，我看到了一个接口mindnlp.engine.export。地址https://mindnlp.cqu.ai/zh/api/engine/export/ 但是在使用的时候报错。发现该接口在源码中没有实现。 ```python from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer import mindspore as ms model_name = 'DeepSeekR1DistillQwen1.5B' model = AutoModelForCausalLM.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name) prompt = ""请介绍一下你自己"" inputs = tokenizer(prompt, return_tensors=""ms"") mindnlp.engine.export(model,                        inputs,                       file_name=""DeepSeekR1DistillQwen1.5B"",                       file_format=""MINDIR"",                       dynamic_axes={""input_ids"": [0], ""attention_mask"": [0]}) ``` 报错： ```python  Traceback (most recent call last):   File ""/home/pikachu/Project/llm/to_mindir.py"", line 15, in      mindnlp.engine.export(model, AttributeError: module 'mindnlp' has no attribute 'engine' ```",2025-02-28T08:25:24Z,,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1968,module 'mindnlp' has no attribute 'engine' 这个问题应该是不同版本的原因，早期的版本应该是有这个的，最新的好像是取消掉了，可能那边的代码还没有更新； 不过导出mindir格式，也并不是所有模型都支持的，需要确保模型本身符合静态图语法，支持静态图的推理，这个可能需要你修改下模型的实现；还有对于这种比较大的模型，mindir有单tensor不能超过2GB的限制，这个也需要在模型实现了控制好,有没有其他API可以实现转mindir模型
这是一个用户提出需求类型的issue，该问题单涉及的主要对象是OneFormer模型应用开发。,【开源实习】OneFormer模型应用开发,,2025-02-27T07:35:16Z,,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1967,minds pore与pytorch对比基本一致：!36ee7fc735cf45b2b7042806c90f4e26 !7da437e7f0fc4b199c92776331a9193a !b6b0211255de40b49886a4f31a0b1bf2
这是一个 bug 报告，主要涉及的对象是 mindnlp 中的 Janus-pro-1B 模型部署，在推理效率方面存在问题。导致这一问题的原因可能是根据昇腾论坛的教程进行配置不正确或其他环境因素。,香橙派上部署Janus-pro-1B推理效率欠佳,根据昇腾论坛的教程（https://www.hiascend.com/forum/thread0211217525999512908611.html）， 可以成功的在香橙派AIpro20T下部署运行Mindnlp下的Januspro1B模型，但是香橙派算力有限，使用understanding.py进行图片推理的时候单张图片推理耗时将近两三分钟，我想在一个实时系统中使用图片理解功能，这个时效性不太好，我想问一下有没有使用Mindnlp下Januspro1B的优化推理服务效率的方法，或者找个模型是否可以在910系列NPU下运行，能否提供相关教程，感谢您的帮助,2025-02-25T03:13:48Z,,open,0,4,https://github.com/mindspore-lab/mindnlp/issues/1966,可能需要做下量化，910系列可以用mindnlp直接跑,> 可能需要做下量化，910系列可以用mindnlp直接跑 您好，感谢您的回复，我想问一下您可否提供一些量化的建议，或者昇腾软件提供了哪些可用的量化工具，我在昇腾ai的量化经验比较少。感谢您的帮助,昇腾的量化推理工具可以用mindie(虽然跟mindspore没啥关系)，另外可以直接用onnx，我们mindnlp仓里quant目录有smooth quant的8bit量化可以用下。,> 昇腾的量化推理工具可以用mindie(虽然跟mindspore没啥关系)，另外可以直接用onnx，我们mindnlp仓里quant目录有smooth quant的8bit量化可以用下。 您好，感谢您的帮助，请问mindnlp支持的量化是不是导入mindnlp.quant.smooth_quant下的quant，并调用quant.quantize来量化模型?麻烦问一下，quant.quantize的cfg参数如何获取呀？是从mindnlp.quant.smooth_quant下的configs文件获取吗？我看获取配置需要一个model_cfg和act_max参数，请问这两个参数该如何获取呀？
这是一个用户提出需求的类型，主要涉及的对象是blip_2模型微调。由于实现了blip_2在Food500Cap数据集，用户在issue中寻求开源实习机会。,【开源实习】blip_2模型微调,任务链接：https://gitee.com/mindspore/community/issues/IBL6T9 实现了blip_2在Food500Cap数据集子集上的微调，结果与pytorch持平，README.md loss: !image image caption 8个评估指标： !image,2025-02-23T12:29:15Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1965,"The head ref may contain hidden characters: ""\u3010\u5F00\u6E90\u5B9E\u4E60\u3011blip_2\u6A21\u578B\u5FAE\u8C03"" 看起来文件有点问题","> The head ref may contain hidden characters: ""\u3010\u5F00\u6E90\u5B9E\u4E60\u3011blip_2\u6A21\u578B\u5FAE\u8C03"" >  > 看起来文件有点问题 我查了一下这个是因为我在本地commit的时候用了 “【开源实习】blip_2模型微调”，里面有中文字符，和文件没有关系"
"这是一个用户提出需求的issue，主要涉及的对象是""bertweet模型""，问题由于需要实现bertweet在hate_speech任务上的微调。",【开源实习】bertweet模型微调,任务链接：https://gitee.com/mindspore/community/issues/IAUP9W 实现了bertweet在hate_speech_twitter数据集上的微调，结果与pytorch持平，README.md !image !image,2025-02-23T03:23:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1964
这是一个bug报告，涉及对象是在香橙派AI PRO(20T)上运行MindSpore NLP的RAG Demo，问题可能由于类型错误导致。,香橙派AI PRO(20T)上运行MindSpore NLP RAG Demo时遇到类型错误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在使用香橙派AI PRO(20T)运行MindSpore NLP的RAG Demo时，遇到了类型错误（TypeError）。具体错误信息为：对于primitive[Concat]，输入[张量]元素应该具有相同的类型，但得到的是：Int64, Int32。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version :2.4.10  Python version :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):Ubuntu 22.04  CANN version：8.0.RC3.alpha002  MindSpore NLP version：master  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior:  RAG demo by MindNLP+Langchain 1. Install dependencies pip install langchain langchaincommunity faisscpu 2. Download knowledge file wget https://raw.githubusercontent.com/limchiahooi/nlpchinese/master/%E8%A5%BF%E6%B8%B8%E8%AE%B0.txt O xiyouji.txt 3. Run RAG Demo streamlit run startup.py xiyouji.txt  4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** 预期结果应该是能够成功运行RAG Demo，输入问题后能够生成相应的答案，而不是遇到类型错误和API异常。 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !Image 运行报错.txt **Additional context / 备注 (Optional / 选填)** 在运行过程中，还遇到了Streamlit API异常，提示st.text_area的高度无效。此外，错误日志中提到了多个警告和异常，包括NumPy的UserWarning和MindSpore的FutureWarning。",2025-02-22T01:20:29Z,bug,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1963,看起来是输入dtype没对齐，可能是int32和int64一起concat了
这是一个bug报告类型的issue，主要涉及TensorPy初始化空Tensor的问题。由于未提供具体内容，无法确定导致bug的具体原因。,fix TensorPy init empty Tensor,,2025-02-19T06:27:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1962
这是一个bug报告，该问题涉及修复TensorPy使其与mindspore 2.5兼容，原因是TensorPy在mindspore 2.5下出现了错误。,fix TensorPy for mindspore 2.5,,2025-02-19T04:33:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1961
这是一个bug报告，关于使用T5Tokenizer在离线方式下执行分词时出现异常。,离线方式执行分词异常,"**Describe the bug/ 问题描述 (Mandatory / 必填)** T5Tokenizer.from_pretrained(strTokenizer,cache_dir=cache_dir,local_files_only=True ) 在from_pretrained方法中，设置local_files_only为True，在断网的情况下，依然访问外网请求文件；  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: windows的CPU环境  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.10  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 使用python执行语句：T5Tokenizer.from_pretrained('googlet5/t5small',cache_dir=cache_dir,local_files_only=True ) 2. 已经执行过一次； 3. 将本地网络关闭； 4. 再次执行报连接外网外网异常 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 已经下载好的分词器文件，在离线情况下不用再下载； **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. Traceback (most recent call last):   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\requests\adapters.py"", line 667, in send     resp = conn.urlopen(   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\urllib3\connectionpool.py"", line 841, in urlopen     retries = retries.increment(   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\urllib3\util\retry.py"", line 519, in increment     raise MaxRetryError(_pool, url, reason) from reason   type: ignore[argtype] urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='hfmirror.com', port=443): Max retries exceeded with url: /googlet5/t5small/resolve/main/added_tokens.json?download=true (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory'))) During handling of the above exception, another exception occurred: Traceback (most recent call last):   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\mindnlp\utils\download.py"", line 503, in cached_file     resolved_file = download(   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\mindnlp\utils\download.py"", line 627, in download     pointer_path = http_get(url, storage_folder, download_file_name=relative_filename, proxies=proxies, headers=headers)   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\mindnlp\utils\download.py"", line 198, in http_get     req = requests.get(url, stream=True, timeout=10, proxies=proxies, headers=headers)   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\requests\api.py"", line 73, in get    return request(""get"", url, params=params, **kwargs)   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\requests\api.py"", line 59, in request     return session.request(method=method, url=url, **kwargs)   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\requests\sessions.py"", line 589, in request     resp = self.send(prep, **send_kwargs)   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\requests\sessions.py"", line 703, in send     r = adapter.send(request, **kwargs)   File ""C:\Users\bluen\AppData\Local\Programs\Python\Python310\lib\sitepackages\requests\adapters.py"", line 694, in send     raise ProxyError(e, request=request) requests.exceptions.ProxyError: HTTPSConnectionPool(host='hfmirror.com', port=443): Max retries exceeded with url: /googlet5/t5small/resolve/main/added_tokens.json?download=true (Caused by ProxyError('Unable to connect to proxy', FileNotFoundError(2, 'No such file or directory')))  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-02-18T09:01:38Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1960,网络问题，需要切换mirror，或者科学上网,cache_dir没生效？
这是一个需求类型的issue，涉及任务Table_transformer应用实现，问题是Table_transformer模型尚未迁移导致无法实现。,table_transformer还未迁移,在准备实现开源任务Table_transformer应用实现时，发现Table_transformer模型还未实现，是不是要先发布Table_transformer模型迁移的issue？ !Image,2025-02-18T08:35:33Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1959
这个issue是一个bug报告，主要涉及Blip2加载和推理bug，由于Blip2ForConditionalGeneration的generate方法调用了不正确。,fix Blip2加载和推理bug #1902 #1904 #1905 ,fix Blip2加载和推理bug CC(blip2推理bug) CC(Blip2ForConditionalGeneration的generate方法调用了不兼容ascend910b的接口) CC(Blip2Processor的init方法需要更新) ,2025-02-16T13:48:28Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1958,pylint查出空格问题，已修复
这个issue是用户提出需求的类型，涉及的主要对象是LayoutLM模型。由于微调后模型在test集上的对比效果，用户希望进行分析并寻求相关帮助。,开源实习-LayoutLM模型应用开发-金逸,"issue地址:https://gitee.com/mindspore/community/issues/IAADJ4 微调后模型在test集上对比效果,基本持平: pytorch: !image mindspore: !image 上架地址:https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=346d8403ee6849a2b79e83f578c568bd",2025-02-15T06:22:23Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1957,!20250224094740(WeLinkPC) 1，排查全文，删除如截图中标注出来的注释掉的代码 2，排查全文，解释性文字对应的cell设置成“markdown”格式，当前格式是“”代码“”,> !20250224094740(WeLinkPC) 1，排查全文，删除如截图中标注出来的注释掉的代码 2，排查全文，解释性文字对应的cell设置成“markdown”格式，当前格式是“”代码“” 已根据要求修改并提交代码,审核通过，可以合入,重新提交pr地址:https://github.com/mindsporelab/mindnlp/pull/1971
这个issue属于用户提出需求类型，主要对象是ViTMAE模型应用开发。由于需要开发ViTMAE模型应用，用户寻求相关帮助或者资源。,ViTMAE模型应用开发,https://gitee.com/mindspore/community/issues/IAANYH,2025-02-14T08:52:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1956
这是一个提出需求的issue，主要涉及的对象是代码中的数据类型和文件路径。,cast to fp16 and change file path,cast to fp16 and change file path,2025-02-14T07:55:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1955
"这是一个需求类型的issue，主要涉及的对象是添加一个名为""janus pro""的功能或组件。",add janus pro,add janus pro,2025-02-14T06:34:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1954
这是一个功能需求类型的issue，主要涉及修改图片路径。原因可能是用户希望更改现有图片路径以满足特定需求。,Janus,change pics path,2025-02-14T06:16:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1953
这是一个用户提出需求的类型的issue，主要涉及的对象是向mindnlp添加Janus Pro模型。,Add Janus Pro Model,,2025-02-14T02:36:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1952
这是一个需求提出类型的issue，主要对象是要对Janus pro model进行adapt。该问题可能由于当前模型功能不完善或用户需求变更导致。,Janus,adapt janus pro model,2025-02-13T12:22:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1951
该issue是关于bug报告，涉及到MindNLP中InstructBlip模型的from_pretrained部分，用户提出了bug描述但内容缺失的问题。,model = InstructBlip的from_pretrained部分,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. mindnlp/transformers/models/instructblip/processing_instructblip.py 由于 ，导致from_pretrained部分功能无法使用（cls被识别成需要输入的参数），  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.1  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):linux 86_64 **To Reproduce / 重现步骤 (Mandatory / 必填)** 1. 使用model = InstructBlipForConditionalGeneration.from_pretrained(""Salesforce/instructblipvicuna7b"") 报错缺少参数“pretrained_model_name_or_path” 定位到mindnlp/transformers/models/instructblip/processing_instructblip.py 由于from_pretrained前 ，导致from_pretrained部分功能无法使用（cls被识别成需要输入的参数） 取消注释的话，会缺参数qformer_tokenizer（没有继承这个参数） 使用原注释代码qformer_tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, subfolder=""qformer_tokenizer"") 会报错  Ascend Error Message:  EH9999: Inner Error!         rtStreamSynchronizeWithTimeout execute failed, reason=[aicore exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53][THREAD:35095] EH9999: 2025012320:26:37.502.940  synchronize stream failed, runtime result = 507015[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161][THREAD:35095]         TraceBack (most recent call last): EH9999: Inner Error!未找到对应代号 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-02-12T08:54:32Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1950
这个issue是用户提出的需求类型，主要对象是mindnlp中的Bernoulli概率函数，由于prob参数未作为位置参数公开导致用户希望将其公开作为位置参数。,expose prob as positional argument for bernoulli ops,expose prob as positional argument for bernoulli ops,2025-02-08T10:07:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1949
该issue类型为用户提出需求，针对的主要对象是Jukebox模型迁移。,【开源实习】Jukebox模型迁移,,2025-02-07T07:20:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1948
这是一个用户提出需求的类型，主要对象是Perceiver IO模型应用开发。由于用户寻求开源实习机会，因此提出了这个需求。,【开源实习】Perceiver IO模型应用开发,https://gitee.com/mindspore/community/issues/IAADLW,2025-02-06T09:14:43Z,,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1947,结果对比： !image !image mindnlp实现： !image !image,验收通过，可以合入
这个issue类型是开源项目ConvNeXT模型应用开发的需求提议。,【开源实习】ConvNeXT模型应用开发,https://gitee.com/mindspore/community/issues/IAADCA,2025-02-06T09:07:29Z,,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1946,结果对比： !image mindnlp： !image 差异原因：选取示例数据不同，但均实现了正确预测,验收通过，可以合入
这是一个关于集成测试部分数据精度问题的bug报告，主要涉及的对象为mindnlp中的mimi模型。由于集成功能存在问题，导致数据精度无法达到预期。,mindnlp打卡课程6：mimi模型迁移,集成测试部分还存在一点问题，数据精度达不到,2025-02-05T04:25:28Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1945
这是一个bug报告，涉及的主要对象是mindnlp项目中的utils/download.py和core/ops/_inner.py文件。由于误删了文件内容并恢复后，集成测试依然失败，可能是由于文件内容恢复不完整或者其他未知原因导致的问题。,mindnlp第六课打卡：迁移mimi,utils/download.py，core/ops/_inner.py 没有任何修改，只是误删了，做了恢复 最后的测试中的集成测试还存在点问题，没有通过，是数据精度没达标,2025-02-05T03:15:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1944
这是一个bug报告，该问题涉及到Qwen/Qwen2.5-VL-7B-Instruct模型的适配问题。由于使用目前的qwen2vl推理qwen2.5vl报错，导致了报错的症状。,适配Qwen/Qwen2.5-VL-7B-Instruct,"使用目前的qwen2vl推理qwen2.5vl报错：Traceback (most recent call last):   File ""/home/ubuntu/github/mindnlp_api/qwen2.5vltest1.py"", line 11, in      model = Qwen2VLForConditionalGeneration.from_pretrained(   File ""/home/ubuntu/miniconda3/envs/mindnlp2/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 3025, in from_pretrained     ) = cls._load_pretrained_model(   File ""/home/ubuntu/miniconda3/envs/mindnlp2/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 3426, in _load_pretrained_model     raise RuntimeError(f""Error(s) in loading state_dict for {model.__class__.__name__}:\n\t{error_msg}"") RuntimeError: Error(s) in loading state_dict for Qwen2VLForConditionalGeneration:         size mismatch for visual.merger.mlp.2.weight: copying a param with shape (3584, 5120) from checkpoint, the shape in current model is (1280, 5120).         size mismatch for visual.merger.mlp.2.bias: copying a param with shape (3584,) from checkpoint, the shape in current model is (1280,).         You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.",2025-02-05T01:40:53Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1943
这个issue类型是功能需求报告，主要涉及的对象是mimi模型迁移。由于用户需要迁移mimi模型，可能原因是需要将模型应用到不同的环境或任务中。,mimi模型迁移,,2025-02-04T17:41:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1942
这是一个bug报告，主要涉及到mindnlp中的模型 llama 的 split 函数在852行的修复问题，可能是因为split函数的实现存在问题导致bug症状的出现。,fix model llama for split function in line 852,,2025-02-02T01:43:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1941
这是一个用户提出需求的Issue，主要涉及Mindnlp中mimi模型的迁移。,Mindnlp打卡任务：mimi模型迁移,,2025-01-26T16:59:25Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1940
这是一个用户提出需求的类型的issue，主要涉及SigLIP模型迁移，用户寻求相关实习开源项目的支持。,【开源实习】SigLIP模型迁移,【开源实习】SigLIP模型迁移 issue：https://gitee.com/mindspore/community/issues/IAZ2TQ,2025-01-26T16:06:05Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1939
这是一个任务类型的issue，主要涉及到MindNLP中mimi模型的迁移。可能是因为需要迁移mimi模型而产生的问题或需求。,MindNLP打卡任务：mimi模型迁移,mimi模型迁移,2025-01-26T16:02:25Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1938
这是一个需求类型的issue，主要涉及的对象是Mindnlp项目中的mimi模型。,Mindnlp打卡任务：mimi模型迁移,,2025-01-26T09:17:41Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1937
该issue类型是活动通知，主要对象是MindNLP打卡训练营活动。,MindNLP打卡训练营,MindNLP打卡训练营,2025-01-26T03:14:52Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1936
这是一个迁移模型的功能需求，主要涉及MindNLP套件的更新。,MindNLP套件迁移mimi模型,提交PR至MindNLP代码仓：https://github.com/mindsporelab/mindnlp,2025-01-26T03:03:41Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1935
这是一个需求提出的issue，主要对象是迁移mimi模型，由于模型迁移的相关需求或问题导致。,Mindnlp打卡任务：mimi模型迁移,,2025-01-25T16:52:53Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1934
这是一个需求提出类型的issue，主要涉及的对象是Mindnlp打卡任务中的mimi模型迁移。,Mindnlp打卡任务：mimi模型迁移,copy from Mindnlp打卡任务：mimi模型迁移 CC(Mindnlp打卡任务：mimi模型迁移),2025-01-25T15:40:01Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1933
"该issue类型是缺少具体内容的bug报告，主要对象是""mimi""。 由于缺少内容，用户无法提供关于bug或问题的具体信息。",mimi,,2025-01-25T14:22:20Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1932
这是一则需求提出类型的issue，主要讨论了Mindnlp中关于mimi模型迁移的任务。,Mindnlp打卡任务：mimi模型迁移,,2025-01-25T13:43:42Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1931
"这是一则需求问题，相关对象为""mimi模型""，提问者请求对""mimi模型""进行迁移。",Mindnlp打卡任务：mimi模型迁移,,2025-01-25T09:07:29Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1930
这是一个关于迁移模型的任务需求，主要对象是mimi模型。由于需要将mimi模型进行迁移，可能涉及到模型结构、参数或者训练数据的转移，用户可能需要帮助解决相关问题或获取支持。,Mindnlp打卡任务：mimi模型迁移,,2025-01-25T08:45:39Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1929
这是一个用户提出需求的类型，主要涉及的对象是模型迁移。用户可能因为需要迁移某个模型而提出了这个问题。,【模型迁移】Mimi,!image,2025-01-25T05:22:28Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1928
这是一个需求提出类型的 issue，主要对象是 Mimi package。由于用户需要某些功能或改进，因此提出了这个问题。,Mimi package,,2025-01-25T04:57:33Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1927
这是一个缺少内容的issue，类型属于用户提出需求，主要对象是项目中的某个模块或功能。,mimi,,2025-01-25T04:09:36Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1926
这是一个用户提出需求的 issue，主要涉及到迁移Mimi模型，用户可能是在寻求关于如何迁移该模型的帮助。,迁移Mimi模型,,2025-01-25T02:05:51Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1925
这是一个用户提出需求的issue，涉及的主要对象是mimi。由于需要迁移mimi，用户提出了相关的需求。,migrate mimi,,2025-01-24T15:48:31Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1924
这是一个Bug报告类的Issue，涉及对象是文件中发生的数值解压错误，可能由于变量解压时期望的值与实际值不匹配导致。,"ValueError: not enough values to unpack (expected 2, got 1)","**Describe the bug/ 问题描述 (Mandatory / 必填)** File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 495, in forward     self_attention_outputs = self.layer0   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 402, in forward     attention_output = self.SelfAttention(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 319, in forward     query_states = shape(self.q(hidden_states))   (batch_size, n_heads, seq_length, dim_per_head)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 435, in _call_impl     args_result = hook(self, args)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly/model.py"", line 170, in pre_hook     args, kwargs = inputs ValueError: not enough values to unpack (expected 2, got 1)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '模型尝试训练' 3. Scroll down to 'File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly/model.py"", line 170, in pre_hook     args, kwargs = inputs' 4. See error ValueError: not enough values to unpack (expected 2, got 1) **Expected behavior / 预期结果 (Mandatory / 必填)** 成功进行训练 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 初始报错：ValueError: task_ids should not be None. 尝试在此处添加task_ids=task_ids参数 !Image 出现本次报错：ValueError: not enough values to unpack (expected 2, got 1) 报错定位位置为： !Image **Additional context / 备注 (Optional / 选填)** pytorch版本此处为： !Image",2025-01-23T13:33:33Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1923
这是一个bug报告，涉及的主要对象是mimi移植。由于发布了一个空的issue内容，导致无法确定具体的bug或问题。,【mimi移植】,,2025-01-23T13:04:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1922
这是一个未提供具体信息的issue，无法确定其类型或问题所涉及的主要对象。,lesson6 migrate mimi,lesson6 migrate mimi,2025-01-23T06:26:09Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1921
该issue属于用户提出的需求类型，主要涉及T5模型应用开发，用户希望使用mindnlp和mindspore对T5模型进行微调文本摘要总结。,T5模型应用开发,使用mindnlp和mindspore 对 T5 模型，通过ENGLISH_CNN_DAILY_EMAIL 进行下游微调文本摘要总结,2025-01-23T03:49:22Z,,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1920,【开源实习】T5模型应用开发 IAADMB
这是一个用户提出需求类型的issue，主要对象是Mimi模型移植。用户可能遇到了移植Mimi模型时的问题，需要寻求帮助解决。,Mimi模型移植,,2025-01-23T03:02:42Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1919
这个issue类型是bug报告，涉及的主要对象是weiranHomeWork的L6迁移模型过程中出现的问题。由于命名存在错误或混淆导致了问题的出现。,weiran-HomeWork-L6-MigrateModels-mimi,weiranHomeWorkL6MigrateModelsmimi,2025-01-22T10:25:00Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1918
这是一个bug报告类型的issue，主要涉及lora_seq2seq案例执行时遇到CANN异常，用户提出了该bug的问题。,llm/peft/lora/lora_seq2seq.ipynb案例执行遇到CANN异常,"**Describe the bug/ 问题描述 (Mandatory / 必填)** lora_seq2seq案例执行遇到CANN异常  **Software Environment / 软件环境 (Mandatory / 必填)**: ```bash $ pip list  +===========================+===============+====================================================+ tridu33master:~$ cat /usr/local/Ascend/version.info version=23.0.0 tridu33master:~$ cat /usr/local/Ascend/ascendtoolkit/latest/aarch64linux/ascend_toolkit_install.info package_name=Ascendcanntoolkit version=8.0.RC3.alpha002 innerversion=V100R001C77B220SPC008 compatible_version=[V100R001C80,V100R001C84],[V100R001C77,V100R001C79],[V100R001C29],[V100R001C11,V100R001C50] arch=aarch64 os=linux path=/usr/local/Ascend/ascendtoolkit/8.0.RC3.alpha002/aarch64linux tridu33master:~$ cat /usr/local/Ascend/ascendtoolkit/latest/opp/builtin/op_impl/ai_core/tbe/kernel/version.info Version=7.5.T6.0.B036 version_dir=8.0.RC3.alpha002 timestamp=20240821_104556995 ops_version=7.5.T6.0.B036 adk_version=7.5.T6.0.B036 required_package_amct_acl_version=""7.5"" required_package_aoe_version=""7.5"" required_package_compiler_version=""7.5"" required_package_fwkplugin_version=""7.5"" required_package_hccl_version=""7.5"" required_package_nca_version=""7.5"" required_package_ncs_version=""7.5"" required_package_opp_version=""7.5"" required_package_runtime_version=""7.5"" required_package_toolkit_version=""7.5"" tridu33master:~$ python c ""import acl;""  没有报错 tridu33master:~$ cat /usr/local/Ascend/firmware/version.info cat: /usr/local/Ascend/firmware/version.info: Permission denied tridu33master:~$ cat /usr/local/Ascend/driver/version.info Version=23.0.0 ascendhal_version=7.35.19 aicpu_version=1.0 tdt_version=1.0 log_version=1.0 prof_version=2.0 dvppkernels_version=1.1 tsfw_version=1.0 Innerversion=V100R001C15SPC002B224 compatible_version=[V100R001C29],[V100R001C30],[V100R001C13],[V100R001C15] compatible_version_fw=[7.0.0,7.1.99] package_version=23.0.0 ``` 910Ascend **To Reproduce / 重现步骤 (Mandatory / 必填)** `~/workspace/githubSrc/mindnlp/llm/peft/lora$ python lora_seq2seq.py` **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. ``` MT5ForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.    If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).    If you are not the owner of the model architecture class, please contact the model code owner to update it. [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB Traceback (most recent call last):   File ""/home/usersshared/githubSrc/mindnlp/llm/peft/lora/lora_seq2seq.py"", line 34, in      model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/auto/auto_factory.py"", line 510, in from_pretrained     return model_class.from_pretrained(   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 3126, in from_pretrained     model = cls(config, *model_args, **model_kwargs)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 1134, in __init__     self.encoder = MT5Stack(encoder_config, self.shared)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 715, in __init__     [MT5Block(config, has_relative_attention_bias=bool(i == 0)) for i in range(config.num_layers)]   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 715, in      [MT5Block(config, has_relative_attention_bias=bool(i == 0)) for i in range(config.num_layers)]   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 460, in __init__     self.layer.append(MT5LayerSelfAttention(config, has_relative_attention_bias=has_relative_attention_bias))   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 389, in __init__     self.layer_norm = MT5LayerNorm(config.d_model, eps=config.layer_norm_epsilon)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 59, in __init__     self.weight = nn.Parameter(ops.ones(hidden_size))   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/core/ops/creation.py"", line 62, in ones     return mindspore.mint.ones(size, dtype=dtype)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/mint/__init__.py"", line 692, in ones     return ops.auto_generate.ones(size, dtype)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/auto_generate/gen_ops_def.py"", line 3971, in ones     return ones_op(shape, dtype)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/operations/manually_defined/ops_def.py"", line 1817, in __call__     return _convert_stub(pyboost_ones(self, [size, type if type is None \ RuntimeError: Initialize GE failed!   Ascend Error Message:  EC0010: [PID: 2179977] 2025012301:09:06.098.879 Failed to import Python module [AttributeError: `np.float_` was removed in the NumPy 2.0 release. Use `np.float64` instead..].         Solution: Check that all required components are properly installed and the specified Python path matches the Python installation directory. (If the path does not match the directory, run set_env.sh in the installation package.)         TraceBack (most recent call last):         AOE Failed to call InitCannKB         [GraphOpt][InitializeInner][InitTbeFunc] Failed to init tbe.[FUNC:InitializeInner][FILE:tbe_op_store_adapter.cc][LINE:1719]         [SubGraphOpt][PreCompileOp][InitAdapter] InitializeAdapter adapter [tbe_op_adapter] failed! Ret [4294967295][FUNC:InitializeAdapter][FILE:op_store_adapter_manager.cc][LINE:79]         [SubGraphOpt][PreCompileOp][Init] Initialize op store adapter failed, OpsStoreName[tbecustom].[FUNC:Initialize][FILE:op_store_adapter_manager.cc][LINE:120]         [FusionMngr][Init] Op store adapter manager init failed.[FUNC:Initialize][FILE:fusion_manager.cc][LINE:117]         PluginManager InvokeAll failed.[FUNC:Initialize][FILE:ops_kernel_manager.cc][LINE:82]         OpsManager initialize failed.[FUNC:InnerInitialize][FILE:gelib.cc][LINE:234]         GELib::InnerInitialize failed.[FUNC:Initialize][FILE:gelib.cc][LINE:162]         GEInitialize failed.[FUNC:GEInitialize][FILE:ge_api.cc][LINE:306] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge_device_context.cc:253 InitGe ```",2025-01-22T09:25:56Z,bug,open,0,3,https://github.com/mindspore-lab/mindnlp/issues/1917,"类似的，roberta_sequence_classification.ipynb 案例`python roberta_sequence_classification.py `也是遇到mindspore的异常 ```bash Traceback (most recent call last):   File ""/home/usersshared/githubSrc/mindnlp/llm/peft/lora/roberta_sequence_classification.py"", line 70, in      print(next(datasets['train'].create_dict_iterator()))   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/dataset/engine/iterators.py"", line 152, in __next__     data = self._get_next()   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/dataset/engine/iterators.py"", line 277, in _get_next     raise err   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/dataset/engine/iterators.py"", line 260, in _get_next     return {k: self._transform_md_to_output(t) for k, t in self._iterator.GetNextAsMap().items()} RuntimeError: Exception thrown from user defined Python function in dataset.    Python Call Stack:   Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets_user_defined.py"", line 104, in _cpp_sampler_fn     yield _convert_row(val)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets_user_defined.py"", line 173, in _convert_row     item = np.array(x, copy=False) ValueError: Unable to avoid copy while creating an array as requested. If using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x). For more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.htmladaptingtochangesinthecopykeyword.   Dataset Pipeline Error Message:   [ERROR] Execute user Python code failed, check 'Python Call Stack' above.   C++ Call Stack: (For framework developers)   mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_op.cc(261). ```",CANN的版本不配套，23.0.0的hdk不对，需要根据 https://www.mindspore.cn/versions 安装hdk 24的版本,"修改NPU驱动版本为`hdk 24.1.rc2`，CANN版本为`24.1.rc2`，执行`~/workspace/githubSrc/mindnlp/llm/peft/lora$ python lora_seq2seq.p`报错变了： ```bash [ERROR] RUNTIME(33130,python):2025012401:36:21.067.639 [driver.cc:65]33130 GetDeviceCount:report error module_type=1, module_name=EL9999 [ERROR] RUNTIME(33130,python):2025012401:36:21.067.803 [driver.cc:65]33130 GetDeviceCount:Call drvGetDevNum, drvRetCode=7. [ERROR] RUNTIME(33130,python):2025012401:36:21.068.050 [api_c_device.cc:21]33130 rtGetDeviceCount:ErrCode=507899, desc=[driver error:internal error], InnerCode=0x7020010 [ERROR] RUNTIME(33130,python):2025012401:36:21.068.122 [error_message_manage.cc:53]33130 FuncErrorReason:report error module_type=3, module_name=EE8888 [ERROR] RUNTIME(33130,python):2025012401:36:21.068.209 [error_message_manage.cc:53]33130 FuncErrorReason:rtGetDeviceCount execute failed, reason=[driver error:internal error] [ERROR] ASCENDCL(33130,python):2025012401:36:21.068.345 [device.cpp:366]33130 aclrtGetDeviceCount: get device count failed, runtime result = 507899. Traceback (most recent call last):   File ""/home/usersshared/githubSrc/mindnlp/llm/peft/lora/lora_seq2seq.py"", line 34, in      model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/auto/auto_factory.py"", line 510, in from_pretrained     return model_class.from_pretrained(   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 3126, in from_pretrained     model = cls(config, *model_args, **model_kwargs)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 1134, in __init__     self.encoder = MT5Stack(encoder_config, self.shared)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 715, in __init__     [MT5Block(config, has_relative_attention_bias=bool(i == 0)) for i in range(config.num_layers)]   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 715, in      [MT5Block(config, has_relative_attention_bias=bool(i == 0)) for i in range(config.num_layers)]   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 460, in __init__     self.layer.append(MT5LayerSelfAttention(config, has_relative_attention_bias=has_relative_attention_bias))   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 389, in __init__     self.layer_norm = MT5LayerNorm(config.d_model, eps=config.layer_norm_epsilon)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/mt5/modeling_mt5.py"", line 59, in __init__     self.weight = nn.Parameter(ops.ones(hidden_size))   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/core/ops/creation.py"", line 62, in ones     return mindspore.mint.ones(size, dtype=dtype)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/mint/__init__.py"", line 692, in ones     return ops.auto_generate.ones(size, dtype)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/auto_generate/gen_ops_def.py"", line 3971, in ones     return ones_op(shape, dtype)   File ""/home/tridu33/.conda/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/operations/manually_defined/ops_def.py"", line 1817, in __call__     return _convert_stub(pyboost_ones(self, [size, type if type is None \ RuntimeError: Ascend kernel runtime initialization failed. The details refer to 'Ascend Error Message'.   Framework Error Message: (For framework developers)  Call rtGetDeviceCount, ret[507899]   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:358 Init mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:642 SetRtDevice [INFO] RUNTIME(33130,python):2025012401:36:22.458.448 [runtime.cc:1991] 33130 ~Runtime: deconstruct runtime [INFO] RUNTIME(33130,python):2025012401:36:22.463.831 [runtime.cc:1998] 33130 ~Runtime: wait monitor success, use=0. ```"
这是一个用户提出的需求类型的issue，涉及的主要对象是Configuration，Model和Unit tests。,"Add Configuration, Model, and Unit tests",课程六：香橙派+MindSpore NLP 提交内容：Configuration，Model，Unit tests 打卡第六课,2025-01-22T02:33:31Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1916
这是一个用户提出需求的类型，该问题单涉及的主要对象是迁移mimi模型。由于需求迁移的需求变化或者系统迁移导致的问题，用户希望能够将mimi模型顺利迁移到另一个环境中。,迁移mimi模型,,2025-01-20T09:47:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1915
这是一个需求类型的issue，涉及将mimi迁移，并学习他人的代码。原因可能是为了改进现有功能或添加新功能。,migrate mimi,migrate mimi， learn from others‘ code,2025-01-19T11:23:40Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1914
这是一个迁移mimi模型的issue，类型为用户提出需求，涉及的主要对象是mimi模型。,迁移mimi模型,,2025-01-19T10:59:13Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1913
这是一个迁移mimi的问题，类型是用户提出需求。主要涉及的对象是mindnlp。这个问题可能是用户想要将mimi迁移到另一个环境或者平台，需要相关帮助或指导。,迁移mimi,,2025-01-18T10:03:22Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1912
这是一个开源实习相关的需求提出类的issue，主要涉及对象是bert_generation模型，用户寻求在coco2017数据集上的ZOC任务全参微调。,【开源实习】bert_generation模型微调,1.实现了bert_generation模型结合clip模型，在coco2017数据集上的ZOC任务全参微调，任务链接：https://gitee.com/mindspore/community/issues/IAUP32 由于原baseline中没有loss的说明，这里通过精度评估的参数来对比 2.pytorch任务结果对比： !image 以上图片是baseline仓库中的原论文中的图片 3.在mindnlp微调后结果： cifar10: !image cifar100: !image tin'yimagenet： !image 可见，mindnlp微调后，模型与任务水准持平或略高于pytorch结果,2025-01-17T14:40:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1911
这是一个需求提出的类型，主要对象是将mimi模型迁移到mindnlp，可能由于mindnlp平台的变化或更新，用户需要帮助实现这一迁移过程。,mimi模型迁移到mindnlp,,2025-01-16T15:31:51Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1910
这是一个关于bug报告的issue，主要涉及mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_device_address.cc:924 CopyDeviceToHost的问题。,mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_device_address.cc:924 CopyDeviceToHost,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 使用mindnlp调用bgem3模型，部分报错 ERROR:root:An error occurred: The pointer[GetDevicePtr()] is null.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_device_address.cc:924 CopyDeviceToHost from mindspore import ops from mindnlp.transformers import AutoModel, AutoTokenizer  from mindspore.ops._primitive_cache import _get_cache_prim import mindspore as ms  print(ms.device_context.ascend.is_available) ms.context.set_context(device_target=""Ascend"",device_id=1) import time import numpy as np import logging from enum import Enum from fastapi import FastAPI, HTTPException, Query, Request from fastapi.middleware.cors import CORSMiddleware from fastapi_offline import FastAPIOffline from pydantic import BaseModel from typing import List, Optional logging.basicConfig(level=logging.ERROR) app = FastAPIOffline() app.add_middleware(     CORSMiddleware,     allow_origins=[""*""],   允许的源列表，使用 [""*""] 可以允许所有源     allow_credentials=True,   是否允许发送 Cookie     allow_methods=[""*""],   允许的 HTTP 方法，如 [""GET"", ""POST""]     allow_headers=[""*""],   允许的 HTTP 请求头 ) def normalize_numpy(dense_vecs, axis=1):     """"""     Normalize a numpy array along the specified axis using L2 normalization.     Parameters:     dense_vecs (numpy.ndarray): The input array to be normalized.     axis (int): The axis along which to compute the L2 norm. Default is 1.     Returns:     numpy.ndarray: The L2normalized array.     """"""      norms = np.linalg.norm(dense_vecs, ord=2, axis=axis, keepdims=True)     return dense_vecs / np.linalg.norm(dense_vecs, ord=2, axis=axis, keepdims=True)  tokenizer = AutoTokenizer.from_pretrained('liuyanyi/bgem3hf',cache_dir=""./cache"")  embedding_model = AutoModel.from_pretrained('liuyanyi/bgem3hf',cache_dir=""./cache"") tokenizer = AutoTokenizer.from_pretrained('/work/cache/model/liuyanyi/bgem3hf') embedding_model = AutoModel.from_pretrained('/work/cache/model/liuyanyi/bgem3hf') .post(""/embeddings"") def encode_texts(     texts: Texts,      task: Task = Task.text_matching,      truncate_dim: Optional[TruncateDim] = Query(default=None),      max_str_length: Optional[int] = Query(default=None) ):       try:         input_ids = tokenizer(texts.texts[0], return_tensors=""ms"", padding=True, truncation=True)         output = embedding_model(**input_ids, return_dict=True)         dense_output = normalize_numpy(output.dense_output[0].asnumpy())         return {""code"": 200,""embeddings"": [dense_output.tolist()] }     except Exception as e:         logging.error(f""An error occurred: {e}"")         return {""code"": 500,""message"": str(e)}  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend 910b 使用 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.3_mindspore2.4:20241114镜像 > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-01-15T09:42:14Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1909
这是一个用户提出需求的类型，该问题单涉及的主要对象是TrOCR模型应用开发。,【开源实习】TrOCR模型应用开发,,2025-01-15T09:14:17Z,,open,0,3,https://github.com/mindspore-lab/mindnlp/issues/1908,https://gitee.com/mindspore/community/issues/IAADOP,需要提供源代码和迁移后代码执行结果,pr提交的代码路径不对，正确路径是applications
这个issue类型为技术任务，主要涉及的对象是bloom模型微调。由于未完成描述，难以判断具体需求和问题。,【开源实习】bloom模型微调,1.实现了bloom3b在databricksdolly15k数据集上面的lora微调，任务链接(https://gitee.com/mindspore/community/issues/IAUPL8) 2.与pytorch环境下对比： pytorch结果： !屏幕截图 20250115 031933 !屏幕截图 20250115 032038 MindNLP实现结果： !屏幕截图 20250115 032736 !training_loss,2025-01-14T19:28:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1907
这是一个bug报告issue，主要涉及到mindnlp中的model-llama模型参数dim的问题，可能由于参数名错误导致调用llama模型时出现错误。,model-llama参数dim的问题,"与bug CC(调用llama模型遇到参数名错误)的错误类型一样，没有改完 Describe the bug/ 问题描述 (Mandatory / 必填) A clear and concise description of what the bug is. 在调用这个函数： def get_code_completion(prompt: str, model, tokenizer, temperature: float) > str: """"""Generate code completion for a given prompt"""""" try: model.eval() input_ids=tokenizer(prompt, return_tensors=""ms"")改成符合mindspore形式的张量 outputs = model.generate( input_ids=tokenized_input[""input_ids""] max_new_tokens=MAX_NEW_TOKENS, temperature=temperature, top_k=TOP_K, top_p=TOP_P, do_sample=True, no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE, repetition_penalty=REPETITION_PENALTY, ) ms.ms_memory_recycle() return tokenizer.batch_decode(outputs, skip_special_tokens=False)[0] except Exception as e: print(f""Error during code generation: {str(e)}"")转化成字符串打印错误信息 raise 接收到下图中来自transformers的models里面llama模型的报错，显示split没有dim这一个参数。 Hardware Environment(Ascend/GPU/CPU) / 硬件环境: Ascend Software Environment / 软件环境 (Mandatory / 必填): 在华为modelarts和openI中均出现该错误。  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.9  镜像：mindspore_2.2.0cann_7.0.1py_3.9euler_2.10.7aarch64snt9b Excute Mode / 执行模式 (Mandatory / 必填)(PyNative/Graph):Graph Expected behavior / 预期结果 (Mandatory / 必填) A clear and concise description of what you expected to happen. 问答应当返回调用llama微调模型返回tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]的结果。 ",2025-01-13T02:21:16Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1906
这是一个bug报告，涉及对象是Blip2Processor的init方法，由于Blip2模型的更新导致该bug产生。,Blip2Processor的init方法需要更新,**Describe the bug/ 问题描述 (Mandatory / 必填)** Blip2Processor的init方法需要更新 根据Blip2的模型仓库，其配置文件在一个月前发生了更新，transformers在版本4.47中已同步更改，但mindnlp.transformers还未更新，具体为配置文件processor_config.json中的num_query_tokens参数 MindNLP中对应代码为：  Transformers4.47.1中对应代码为：  复现方法为： ```python from mindnlp.transformers import Blip2Processor processor = Blip2Processor.from_pretrained('/data/zhangyx/liuzp/blip2/blip2opt2.7b') ``` 报错信息为： ,2025-01-06T06:21:10Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1905
这个issue属于bug报告，涉及到Blip2ForConditionalGeneration的generate方法调用了不兼容ascend910b的接口，可能是由于接口不兼容导致的问题。,Blip2ForConditionalGeneration的generate方法调用了不兼容ascend910b的接口,"**Describe the bug/ 问题描述 (Mandatory / 必填)** Blip2ForConditionalGeneration的generate方法调用了不兼容ascend910b的接口，具体报错信息见最后截图：  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Ascend 910b  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1和2.4.1都一样的问题  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): Euler2（用的是启智的AscendD910B 32G, mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0镜像）  GCC/Compiler version (if compiled from source): 7.3.0  MindNLP : 0.4.1(源码编译安装)  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. git clone https://openi.pcl.ac.cn/lvyufeng/mindnlp.git 2. 按照issue1902中提到的bug，先将对应文件中的repeat(batch_size, 1)改为tile((batch_size, 1))，然后从源码编译安装mindnlp : bash scripts/build_and_reinstall.sh 3. 下载Salesforce/blip2opt2.7b并移除processor_config.json文件（这里可能涉及另外的bug，不移除无法加载Blip2Processor） 4. pip install upgrade tokenizers==0.21.0 5. pip install mindspore==2.3.1 6. pip uninstall soundfile mindformers y 7. 运行如下代码即可看见报错： ```python from mindnlp.transformers import Blip2ForConditionalGeneration, Blip2Processor import mindspore as ms import mindspore.numpy as np ms.set_context(device_target='Ascend', device_id=0, pynative_synchronize=True) processor = Blip2Processor.from_pretrained() model = Blip2ForConditionalGeneration.from_pretrained() pixel_values = np.randn((16, 3, 224, 224)) generated_ids = model.generate(pixel_values) print(generated_ids) generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 预期正确产生generated_ids，但generated_ids = model.generate(pixel_values)报错 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image",2025-01-05T13:59:17Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1904,重现步骤3提到的“另外的bug”为https://github.com/mindsporelab/mindnlp/issues/1905
"这是一个bug报告，涉及的主要对象是无法使用`metric = evaluate.load(""glue"", task)`功能，原因可能是代码逻辑错误或环境配置问题。","应用实践/LLM原理和实践/基于MindSpore实现Roberta模型metric = evaluate.load(""glue"", task)无法进行","**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 昇思大模型平台中的案例https://xihe.mindspore.cn/my/clouddev  应用实践/LLM原理和实践/基于MindSpore实现Roberta模型,   当代码运行到 metric = evaluate.load(""glue"", task) 时，就停止无法继续进行。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  双卡 ascend  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.0     Name: mindsporeVersion: 2.3.0       mindnlp==0.4.0  Python version (e.g., Python 3.7.5) :   3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. %env HF_ENDPOINT=https://hfmirror.com 2.  查看当前 mindspore 版本 !pip show mindspore 3. 安装mindnlp的daily包，待正式发布后可改为直接安装mindnlp包 !pip install https://mindsporecourses.obs.cnnorth4.myhuaweicloud.com/mindnlp/mindnlp0.4.0py3noneany.whl  i https://pypi.tuna.tsinghua.edu.cn/simple  !pip install mindnlp==0.4.0 !pip install jieba i https://pypi.tuna.tsinghua.edu.cn/simple ......... **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2025-01-05T07:00:00Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1903
这是一个bug报告，涉及的主要对象是mindnlp/transformers模块，因存在代码bug导致。,blip2推理bug,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 发现代码bug 在文件mindnlp/transformers/models/blip_2/modeling_blip_2.py中，Blip2ForConditionalGeneration类的generate方法中有如下代码用于在输入 input_ids 为 None 时初始化 input_ids ： ```python         if input_ids is None:             input_ids = (                 mindspore.Tensor([[self.config.text_config.bos_token_id]])                 .repeat(batch_size, 1)             ) ``` 在 transformers4.47.1 中该处的实现代码为： ```python         if input_ids is None:             start_tokens = [self.config.text_config.bos_token_id]             if getattr(self.config, ""image_token_index"", None) is not None:                 start_tokens = [self.config.image_token_index] * self.config.num_query_tokens + start_tokens             input_ids = torch.tensor([start_tokens], dtype=torch.long, device=image_embeds.device)             input_ids = input_ids.repeat(batch_size, 1) ``` 这里的期望 input_ids 形状为 (batch_size, num_query_tokens + 1)，transformers4.47.1 是没问题的      mindnlp有两点问题： 1. [self.config.image_token_index] * self.config.num_query_tokens 这部分在 MindNLP 代码中并未实现 2. mindspore 中的 repeat 方法与 torch 并不等价，这里为误用，mindspore.Tensor([[self.config.text_config.bos_token_id]]) 是一个 (1, 1) 的 tensor，期望变成 (batch_size, 1)，但变成了 (1, batch_size)",2025-01-04T14:52:13Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1902
这个issue类型是请求更新（update）且涉及主要对象qwen2_moe，由于缺失具体内容，无法具体分析导致的原因或描述问题的症状。,update qwen2_moe,,2025-01-04T11:37:52Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1901
这是一个bug报告类型的issue，主要涉及的对象是mixtral。由于mixtral需要更新，可能导致出现了某种bug或者用户提出了相关问题或者寻求帮助。,update mixtral,,2025-01-04T11:32:42Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1900
这是一个用户提出需求的类型，主要对象是昇腾AI创新大赛。这个问题由于缺少具体内容而被提出。  ,[昇腾AI创新大赛] update mixtral,,2025-01-04T11:19:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1899
这是一个bug报告，涉及的主要对象是mindnlp.core.ops.finfo模块，导致报错的原因是当前不支持获取bfloat16的浮点数信息。,mindnlp.core.ops.finfo增加对mindspore.bfloat16的支持,"当前不支持获取bfloat16的浮点数信息, 会报错 Traceback (most recent call last):   File ""/home/opsdev/zqh/1836_full.py"", line 88, in      inference(args)   File ""/home/opsdev/zqh/1836_full.py"", line 67, in inference     outputs = model.generate(   File ""/root/miniconda3/envs/ci3.9/lib/python3.9/contextlib.py"", line 79, in inner     return func(*args, **kwds)   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py"", line 2025, in generate     result = self._sample(   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py"", line 3038, in _sample     outputs = self(**model_inputs, return_dict=True)   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 390, in _wrapped_call_impl     return self.forward(*args, **kwargs)   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 765, in forward     outputs = self.model(   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 390, in _wrapped_call_impl     return self.forward(*args, **kwargs)   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 565, in forward     causal_mask = self._update_causal_mask(   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 663, in _update_causal_mask     min_dtype = float(ops.finfo(dtype).min)   File ""/home/opsdev/.local/lib/python3.9/sitepackages/mindnlp/core/ops/other.py"", line 669, in finfo     return np.finfo(mindspore.dtype_to_nptype(dtype))   File ""/home/opsdev/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py"", line 398, in __new__     raise ValueError(""data type %r not inexact"" % (dtype)) ValueError: data type  not inexact",2025-01-04T08:35:57Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1898
这是一个关于开源实习中bert模型微调的相关问题，涉及主要对象为mindnlp下的一个issue。,【开源实习】bert模型微调,任务链接：https://gitee.com/mindspore/community/issues/IAUP1T 结果：参考指标为在测试集上的准确率，mindspore + mindnlp 复现结果略优于 pytorch， 代码详细说明及结果见文件README.md 测试集准确率：  my results on mindspore ,2024-12-28T06:34:08Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1897
这是一个用户提出需求的类型，主要对象是blip模型微调任务。由于用户需要进行blip模型微调，提出了开源实习问题。,【开源实习】blip模型微调,任务链接：https://gitee.com/mindspore/community/issues/IAUPL0 结果：参考指标为在测试集上的损失，mindspore下由于混合精度暂不兼容，所以并未开启，收敛速度较pytorch下开启混合精度慢一些，但收敛趋势一致，具体结果见README.md loss下降图： !image,2024-12-28T05:01:15Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1896
这是一个bug报告，主要涉及Adam优化器调用step进行反向传播时出现了TypeError报错。,Adam优化器调用step进行反向传播时报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** Adam优化器调用step进行反向传播时报错，TypeError: For 'Adam', the 10th input gradient can not be implicitly converted. Its type is None, value is ""None"". Only support Tensor or Scalar.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Ascend910B 32G  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1  MindNLP : 0.4.1 (从源码安装)  Python version (e.g., Python 3.7.5) : 3.9.18  OS platform and distribution (e.g., Linux Ubuntu 16.04): EulerOS 2.0 (SP8)  GCC/Compiler version (if compiled from source): 7.3.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 启智AscendD910B 32G ，镜像mindtorch0.3_mindspore2.3.0_torchnpu2.2.0_cann8.0 2. 环境配置：镜像自带MindSpore环境下，源码安装mindnlp0.4.1，升级mindspore2.3.1，卸载pip uninstall soundfile 3. 通过python main.py运行如下代码： ```python import time import argparse from tqdm import tqdm import mindspore import mindspore.numpy as np from mindspore.dataset import GeneratorDataset from mindspore import save_checkpoint, value_and_grad from mindnlp.transformers import AutoProcessor, BlipForConditionalGeneration from mindnlp.core.optim import Adam from datasets import load_dataset class ImageCaptioningDataset():     def __init__(self, dataset, processor):         self.dataset = dataset         self.processor = processor     def __len__(self):         return len(self.dataset)     def __getitem__(self, idx):         if not isinstance(idx, int):             idx = int(idx)         item = self.dataset[idx]         encoding = self.processor(images=item['image'], text=item['text'], padding=""max_length"")         return np.asarray(encoding[""pixel_values""]), np.asarray(encoding[""input_ids""]), np.asarray(encoding[""attention_mask""]) def get_loader(dataset, processor, batch_size, shuffle=True, num_workers=1, drop_remainder=True):     dataset = ImageCaptioningDataset(dataset, processor)     return GeneratorDataset(source=dataset,                              column_names=[""pixel_values"", ""input_ids"", ""attention_mask""],                             shuffle=shuffle,                             num_parallel_workers=num_workers                            ).batch(batch_size=batch_size,                                     drop_remainder=drop_remainder) class Trainer:     def __init__(self, net, optimizer, args,                  train_dataset, eval_dataset=None                  ):         self.net = net         self.opt = optimizer         self.args = args         self.train_dataset = train_dataset         self.weights = self.net.trainable_params()         self.value_and_grad = value_and_grad(self.forward_fn, None, weights=self.weights)         self.run_eval = eval_dataset is not None         if self.run_eval:             self.eval_dataset = eval_dataset     def forward_fn(self, input_ids, pixel_values, attention_mask):         outputs = self.net(input_ids=input_ids, pixel_values=pixel_values, attention_mask=attention_mask, labels=input_ids)         loss = outputs.loss         return loss     def train_single(self, input_ids, pixel_values, attention_mask):         loss, grads = self.value_and_grad(input_ids, pixel_values, attention_mask)         self.opt.step(grads)         return loss     def train(self, epochs):         best_val_loss = float('inf')         for epoch in range(0, epochs):             print(""\nEpoch {}/{}"".format(epoch+1, epochs))             self.net.set_train(True)             tloss = 0             step = 0             for batch in self.train_dataset.create_dict_iterator():                 input_ids = batch[""input_ids""]                 pixel_values = batch[""pixel_values""].squeeze(1)                 attention_mask = batch[""attention_mask""]                 loss = self.train_single(input_ids, pixel_values, attention_mask)                 tloss = tloss + loss.asnumpy()                 step = step + 1             tloss /= step             print(""\tTrain Loss {:.04f}"".format(tloss))             if self.run_eval:                 self.net.set_train(False)                 val_loss = self.val()                 print(""Epoch {} complete! Validation Loss : {}"".format(epoch, val_loss))                 if val_loss  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-27T09:51:41Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1895,用mindnlp.core里的value_and_grad即可解决
这是一个bug报告类型的issue，涉及主要对象是在香橙派上静态图模式加载microsoft/phi-2时报RuntimeError。,香橙派上静态图模式加载microsoft/phi-2前向传播报RuntimeError: Call aclnnGelu failed,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 香橙派上静态图模式加载microsoft/phi2前向传播报RuntimeError: Call aclnnGelu failed  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Orange Pi Ai Pro  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.1  Python version (e.g., Python 3.7.5) :3.9.21  OS platform and distribution (e.g., Linux Ubuntu 16.04):Ubuntu 22.04.3 LTS (GNU/Linux 5.10.0+ aarch64)  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** ` import mindspore from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM, StaticCache from mindnlp.core import ops from mindnlp.configs import set_pyboost, ON_ORANGE_PI import time if ON_ORANGE_PI:     mindspore.set_context(         enable_graph_kernel=True,         mode=mindspore.GRAPH_MODE,         jit_config={             ""jit_level"": ""O2"",         },     ) prompts = [     ""Simply put, the theory of relativity states that "",     ""My favorite all time favorite condiment is ketchup."", ] NUM_TOKENS_TO_GENERATE = 40 model_id = ""microsoft/phi2"" tokenizer = AutoTokenizer.from_pretrained(model_id, pad_token="""", padding_side=""right"") model = AutoModelForCausalLM.from_pretrained(model_id, ms_dtype=mindspore.float16, low_cpu_mem_usage=True) model.jit() inputs = tokenizer(prompts, return_tensors=""ms"", padding=True) set_pyboost(False) .jit(jit_config=mindspore.JitConfig(jit_syntax_level='STRICT')) def decode_one_tokens(model, cur_token, input_pos, cache_position, past_key_values):     logits = model(         cur_token,         position_ids=input_pos,         cache_position=cache_position,         past_key_values=past_key_values,         return_dict=False,         use_cache=True     )[0]     new_token = ops.argmax(logits[:, 1], dim=1)[:, None]     return new_token batch_size, seq_length = inputs[""input_ids""].shape past_key_values = StaticCache(     config=model.config, max_batch_size=2, max_cache_len=11, dtype=model.dtype ) cache_position = ops.arange(seq_length) generated_ids = ops.zeros(     batch_size, seq_length + NUM_TOKENS_TO_GENERATE + 1, dtype=mindspore.int32 ) generated_ids[:, cache_position] = inputs[""input_ids""].to(mindspore.int32) logits = model(     **inputs, cache_position=cache_position, past_key_values=past_key_values,return_dict=False, use_cache=True )[0] next_token = ops.argmax(logits[:, 1], dim=1)[:, None] generated_ids[:, seq_length] = next_token[:, 0] cache_position = mindspore.tensor([seq_length + 1]) for _ in range(1, NUM_TOKENS_TO_GENERATE):     s = time.time()     next_token = decode_one_tokens(model, next_token, None, cache_position, past_key_values)     generated_ids[:, cache_position] = next_token.int()     cache_position += 1     t = time.time()     print(t  s) text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True) print(text) ` **Expected behavior / 预期结果 (Mandatory / 必填)** 正常运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !fc8a4be292b31a4a83fa13477f1a2d1 !e6229de24e6f128220dff2081e77019",2024-12-27T03:34:37Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1894
这是一个bug报告，该问题涉及的主要对象是任务分发提示，由于某种原因导致任务在8分钟左右后停止并显示错误提示。,提示一直显示任务分发，估计有个8分钟左右然后就停了,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 提示一直显示任务分发，估计有个8分钟左右然后就突然提示：[ERROR] ME(130371:281473296949264,MainProcess):2024122614:22:26.839.923 [mindspore/parallel/cluster/process_entity/_api.py:268] Worker process 130673 exit with exception.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: !image **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. pip install upgrade mindspore 2. pip install https://repo.mindspore.cn/mindsporelab/mindnlp/newest/any/mindnlp0.4.1py3noneany.whl 3. pip uninstall mindformers 4. git clone https://openi.pcl.ac.cn/lvyufeng/mindnlp cd mindnlp bash scripts/build_and_reinstall.sh cd llm cd parallel cd bert_imdb_finetune_dp bash bert_imdb_finetune_npu_mindnlp_trainer.sh  pip install datasets upgrade  i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple pip uninstall soundfile **Expected behavior / 预期结果 (Mandatory / 必填)** 应该是执行训练，但是没有直接卡主一直进行任务分发 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !8b2fbada3e8fff77fe534fdf0abd049 !58d3fdc9ccba4837521d4004303758b !0a8eaf6065a87b2452d7a1b291d82f7 **Additional context / 备注 (Optional / 选填)**.log](https://github.com/userattachments/files/18254295/worker_0.1.log)) 有时候有一张卡是成功的 !3940f96b2b48c2d07ec46e8d962de00 worker_1 (1).log worker_0 (1).log",2024-12-26T17:07:55Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1893,"不再提交新的issue，附在这里，我用的是贵阳一，也是按上面步骤操作。 用 python bert_imdb_finetune_cpu_mindnlp_trainer_npus_same.py 可以训练成功，而且能看到NPU1个有使用， 但是用 bash bert_imdb_finetune_npu_mindnlp_trainer.sh 看到两个NPU都没拉起。 观察日志，shceduler.log里有timeout， RuntimeError: The total number of timed out node is 1. Timed out node list is: [const vector]{0}, worker 0 is the first one timed out, please check its log. worker_1.log中有TypeError [INFO] GE(152245,python):2024122716:48:31.612.184 [model_v2_executor_builder.cc:179][EVENT]153739 Build:[GEPERFTRACE] The time cost of ModelV2ExecutorBuilderBuild::All is [1478] micro second. Traceback (most recent call last):   File ""/home/mauser/work/mindnlp/llm/parallel/bert_imdb_finetune_dp/bert_imdb_finetune_cpu_mindnlp_trainer_npus_same.py"", line 83, in      main()   File ""/home/mauser/work/mindnlp/llm/parallel/bert_imdb_finetune_dp/bert_imdb_finetune_cpu_mindnlp_trainer_npus_same.py"", line 80, in main     trainer.train()   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 781, in train     return inner_training_loop(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1133, in _inner_training_loop     tr_loss_step = self.training_step(model, inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1425, in training_step     self.update_gradient_by_distributed_type(model)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1390, in update_gradient_by_distributed_type     new_grads_mean = all_reduce(parameter.grad) / rank_size TypeError: unsupported operand type(s) for /: 'tuple' and 'int' [INFO] HCCP(152245,python):2024122716:48:31.668.579 [ra_host.c:846]tid:153739,ra_socket_batch_connect(846) : Input parameters: [0]th, phy_id[1], local_ip[1.0.0.0], remote_ip[0.0.0.0], tag: worker_0.log中在开始附近有很多似乎是动态库的错误。 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclmdlBundleUnload failed, result = /usr/local/Ascend/ascendtoolkit/latest/lib64/libascendcl.so: undefined symbol: aclmdlBundleUnload [WARNING] GE_ADPT(152233,ffffa5c57010,python):2024122716:47:36.238.837 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclrtGetMemUceInfo failed, result = /usr/local/Ascend/ascendtoolkit/latest/lib64/libascendcl.so: undefined symbol: aclrtGetMemUceInfo [WARNING] GE_ADPT(152233,ffffa5c57010,python):2024122716:47:36.238.857 [mindspore/ccsrc/utils/dlopen_macro.h:163] DlsymAscend] Dynamically load symbol aclrtDeviceTaskAbort failed, result = /usr/local/Ascend/ascendtoolkit/latest/lib64/libascendcl.so: undefined symbol: aclrtDeviceTaskAbort [WARNING] GE_ADPT(152233,ffffa5c57010,python):2024122716:47:36.238.875  是不是系统软件和硬件配合问题？ 附log scheduler.log worker_0.log worker_1.log",看起来CANN版本不匹配
这个issue属于用户提出需求类型，涉及主要对象是对bert_japanese模型在wrime数据集上的微调。由于未完整提供任务链接，用户可能需要寻求帮助或者反馈微调过程中遇到的问题。,【开源实习】bert_japanese模型微调,1. 实现了bert_japanese在wrime数据集上的微调，任务链接（https://gitee.com/mindspore/community/issues/IAUP8T ） 2. 与Pytorch参考实现结果持平：  Pytorch实现结果： !image    MindNLP实现结果： !image,2024-12-24T16:38:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1892
"这是一个bug报告类型的issue，主要涉及的对象是代码中的""ia3""部分。原因可能是代码中的错误导致了问题，需要修复。",fix ia3,,2024-12-24T12:38:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1891
这是一个bug报告类型的issue，主要涉及到MobileBERT模型的注册问题。由于MobileBERT模型注册存在问题，导致用户提交了这个bug报告。,fix mobilebert register,,2024-12-24T10:12:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1890
这是一个bug报告，主要涉及MindNLP0.4.1新版本下的IA3微调代码，问题源于训练结果异常。,MindNLP0.4.1新版本下的IA3微调代码，每个Epoche的准确率和F1都一模一样不变,**Describe the bug/ 问题描述 (Mandatory / 必填)** MindNLP0.4.1新版本下的IA3微调代码训练结果异常问题： MindNLP学习营的一节课用到这篇代码： 用MRPC数据集对RoBERTaLarge模型进行IA3微调[mindnlp]llm/peft/ia3/sequence_classification.ipynb 代码原封不动搬下来，跑得很顺畅但是反馈每个epoche的准确率和F1都一模一样  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend: 1*ascendsnt9b1 Ascend Snt9B+ARM算法开发和训练基础镜像，AI引擎预置MindSpore MindNLP_0.4.1 **To Reproduce / 重现步骤 (Mandatory / 必填)** llm/peft/ia3/sequence_classification.ipynb原封不动，直接跑 **Expected behavior / 预期结果 (Mandatory / 必填)** 此图为代码仓库里的截图。 如果训练过程的评估数据正常更新，本应有零有整。 !微信截图_20241224173518 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 此图为代码在上述环境下执行的截图。 实际情况，每个epoche都是一样的数值。这必然是出了些什么情况，或许是参数没有正常更新、或许是数据集出了问题、或许是新版本下部分代码不适配等。请大佬指教。 !未能成功wuhanlt **Additional context / 备注 (Optional / 选填)** 实际情况正在排查，也请有经验的大佬指教。咱们一整个学习营的作业都是这个情况。,2024-12-24T09:41:35Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1889
这是一个bug报告，问题涉及到通过mindnlp加载的模型与mindspore的混合精度不兼容，导致出现了特定的问题。,通过mindnlp加载的模型与mindspore的混合精度不兼容,**Is your feature request related to a problem? Please describe.** 通过mindnlp加载的模型与mindspore的auto_mixed_precision接口不兼容，报错信息为：The network type shoule be Cell,2024-12-24T09:32:08Z,requirement,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1888
这是一个用户提出需求的类型，主要涉及文件下载时的并行操作，由于缺乏文件锁机制导致多线程环境下可能出现文件下载错位的问题。,feat: add file lock for remote files download to local path when multiple thread environment.,清空.mindnlp执行并行案例可以下载【数据集，tokenizer和pretrainedModel】，0在忙着下载前两个的话，1抢占到文件锁会下载最后一个，都能等待。 !1 thon串行下载也没有问题 !2 对于文件锁，linux环境下无法预编译`winfcntlock.py`为`winfcntlock.pyc`导致pylint会告警E401：imporerror，如果希望兼容windows，pylint告警E0401: Unable to import 是否应该被忽略,2024-12-24T09:24:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1887
这是一个关于加载mobilebert报错的bug报告，用户遇到了KeyError的问题。,加载mobilebert报错keyError,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片 ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 使用mindnlp/benchmark/GLUEQNLI/model_QNLI.py加载google/mobilebertuncased模型报错    `tokenizer = AutoTokenizer.from_pretrained(""google/mobilebertuncased"")     model=AutoModelForSequenceClassification.from_pretrained(""gokuls/mobilebert_sa_GLUE_Experiment_qnli_128"", num_labels=2)`  **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image 在mindnlp >mindnlp >transformers > models > auto > configuration_auto.py>CONFIG_MAPPING_NAMES 增加了(""mobilebert"", ""MobileBertConfig"")配置之后报 !image 在如下文件中修改后 !image 达到替换 AutoTokenizer直接使用MobileBertTokenizer加载google/mobilebertuncased相同的报错 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-24T08:29:24Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1886
这是一个bug报告，主要对象是修复pytest错误。这个问题可能是由于测试代码编写错误或环境配置问题导致pytest失败。,fix pytest error,,2024-12-24T06:49:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1885
这是一个需求类型的issue，主要涉及MindNLP项目中的core.ops模块更新问题。,update core.ops with pyboost,,2024-12-23T12:43:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1884
"这是一个bug报告，主要涉及到""llama""和""baichuan""的拼写错误。原因是拼写错误导致了问题。",fix llama and baichuan typo,,2024-12-23T09:53:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1883
这个issue类型为开源实习，主要对象是bert模型微调。用户提出了关于开源实习的问题或寻求相关帮助。,【开源实习】bert模型微调,https://gitee.com/mindspore/community/issues/IAUP1T,2024-12-21T13:55:59Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1882,代码说明及结果放在README.md文件中，同训练参数设置下，mindspore微调结果优于Pytorch
这是一个bug报告，问题涉及数据并行多进程同时下载模型，由于某些原因导致了具体的问题描述未完整。,数据并行多进程同时下载模型有问题。,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-21T07:58:43Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1881,https://github.com/mindsporelab/mindnlp/pull/1887
这个issue是一个bug报告，主要涉及调用llama模型的参数名错误，导致了无法正确运行的问题。,调用llama模型遇到参数名错误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 在调用这个函数： def get_code_completion(prompt: str, model, tokenizer, temperature: float) > str:     """"""Generate code completion for a given prompt""""""     try:         model.eval()         input_ids=tokenizer(prompt, return_tensors=""ms"")改成符合mindspore形式的张量         outputs = model.generate(             input_ids=tokenized_input[""input_ids""]             max_new_tokens=MAX_NEW_TOKENS,             temperature=temperature,             top_k=TOP_K,             top_p=TOP_P,             do_sample=True,             no_repeat_ngram_size=NO_REPEAT_NGRAM_SIZE,             repetition_penalty=REPETITION_PENALTY,         )         ms.ms_memory_recycle()         return tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]     except Exception as e:         print(f""Error during code generation: {str(e)}"")转化成字符串打印错误信息         raise 接收到下图中来自transformers的models里面llama模型的报错，显示split没有dim这一个参数。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**: 在华为modelarts和openI中均出现该错误。  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.9  镜像：mindspore_2.2.0cann_7.0.1py_3.9euler_2.10.7aarch64snt9b  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:Graph **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 问答应当返回调用llama微调模型返回tokenizer.batch_decode(outputs, skip_special_tokens=False)[0]的结果。 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. ",2024-12-20T12:17:09Z,bug,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1880,为啥走到了self.config.pretraining_tp > 1分支？,可能是因为我的模型加载了预训练模型，另外，能不能顺便将这一个bug改一下（属于同一种类型的bug，运行条件与之前一样）。 ![Uploading 1.png…](),已经改了 试试最新master,试用了最新的源码安装mindnlp之后，还是出现了上述的报错。 ![Uploading 1.png…](),我测试过你这个issue的问题已经解决了 你的图看不到是什么,"mindnlp/transformers/models/llama/modeling_llama.py line 852, in forward     lm_head_slices = self.lm_head.weight.split(self.vocab_size // self.config.pretraining_tp, dim=0) split中没有dim 这个参数 "
"这个issue类型为bug报告，主要涉及对象是""Sentence-BERT""模型的normalize_embeddings方法。此bug可能是由于normalize_embeddings方法在处理嵌入向量时出现问题，导致了模型性能下降或输出结果不准确，需要修复以提高模型准确性。",fix sbert normalize_embeddings,,2024-12-20T09:07:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1879
这是一个bug报告，报告了在使用Adam优化器微调Bert时出现TypeError报错的情况。,mindnlp.core.optim.Adam相关报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在使用Adam优化器微调Bert时报错： TypeError: For 'Adam', the 10th input gradient can not be implicitly converted. Its type is None, value is ""None"". Only support Tensor or Scalar.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1  Python version (e.g., Python 3.7.5) : 3.9.21  OS platform and distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04  CUDA: 11.1  mindnlp: 0.4.1 (pip with whl)  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. save the following code in main.py ```python import time import argparse import pandas as pd import mindspore from mindnlp.transformers import BertModel, BertTokenizer from mindnlp.core import nn  from mindnlp.core.nn import BCEWithLogitsLoss from mindnlp.core.optim import Adam from mindnlp.core.ops import sigmoid def get_accuracy_from_logits(logits, labels):     probs = sigmoid(logits.unsqueeze(1))     soft_probs = (probs > 0.5).long()     acc = (soft_probs.squeeze() == labels).float().mean()     return acc def evaluate(net, criterion, dataloader):     mean_acc, mean_loss = 0, 0     count = 0     for data in dataloader:         tokens_ids = data['tokens_ids']         attn_mask = (tokens_ids != 0).long()         label = data['label']         logits = net(tokens_ids, attn_mask)         mean_loss += criterion(logits.squeeze(1), label).item()         mean_acc += get_accuracy_from_logits(logits, label)         count += 1     return mean_acc / count, mean_loss / count class Trainer:     def __init__(self, net, criterion, optimizer, args,                  train_dataset, eval_dataset=None                  ):         self.net = net         self.criterion = criterion         self.opt = optimizer         self.args = args         self.train_dataset = train_dataset         self.run_eval = eval_dataset is not None          if self.run_eval:              self.eval_dataset = eval_dataset     def train(self, epochs):         best_acc = 0         for epoch in range(0, epochs):             self.net.train()             for i, data in enumerate(self.train_dataset):                 tokens_ids = data['tokens_ids']                 attn_mask = (tokens_ids != 0).long()                 label = data['label']                 logits = self.net(tokens_ids, attn_mask)                 loss = self.criterion(logits.squeeze(1), label)                 loss.backward()                 for param in self.net.trainable_params():                     if param.grad is not None:                         print(f""Gradient for {param.shape}: {param.grad}"")                     else:                         print(f""Gradient for {param.shape} is None"")                 self.opt.step()                 self.opt.zero_grad()                 if i % self.args.print_every == 0:                     acc = get_accuracy_from_logits(logits, label)                     print(""Iteration {} of epoch {} complete. Loss : {} Accuracy : {}"".format(i, epoch, loss.item(), acc))              if self.run_eval:                  self.net.eval()                  val_acc, val_loss = evaluate(self.net, self.criterion, self.eval_dataset, self.args)                  print(""Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}"".format(epoch, val_acc, val_loss))                  if val_acc > best_acc:                      print(""Best validation accuracy improved from {} to {}, saving model..."".format(best_acc, val_acc))                      best_acc = val_acc                       ms.save_checkpoint(self.net, ""best.ckpt"") class SentimentClassifier(nn.Module):     def __init__(self, base_model_name_or_path = 'bertbaseuncased', freeze_bert = True):         super().__init__()         Instantiating BERT model object          self.bert_layer = BertModel.from_pretrained(base_model_name_or_path)         Freeze bert layers         if freeze_bert:             for p in self.bert_layer.parameters():                 p.requires_grad = False         Classification layer         self.cls_layer = nn.Linear(768, 1)     def forward(self, seq, attn_masks):         '''         Inputs:             seq : Tensor of shape [B, T] containing token ids of sequences             attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens         '''         Feeding the input to BERT model         last_hs = self.bert_layer(seq, attention_mask = attn_masks).last_hidden_state         Obtaining the representation of [CLS] head         cls_rep = last_hs[:, 0]         Feeding cls_rep to the classifier layer         logits = self.cls_layer(cls_rep)         return logits class SSTDataset():     def __init__(self, base_model_name_or_path, filename, maxlen):         Store the contents of the file in a pandas dataframe          self.df = pd.read_csv(filename, delimiter = '\t')         self.df = pd.DataFrame(filename)         Initialize the BERT tokenizer         self.tokenizer = BertTokenizer.from_pretrained(base_model_name_or_path)         self.maxlen = maxlen     def __len__(self):         return len(self.df)     def __getitem__(self, index):         Selecting the sentence and label at the specified index in the data frame         sentence = self.df.loc[index, 'sentence']         label = self.df.loc[index, 'label']         Preprocessing the text to be suitable for BERT         tokens = self.tokenizer.tokenize(sentence) Tokenize the sentence         tokens = ['[CLS]'] + tokens + ['[SEP]'] Insering the CLS and SEP token in the beginning and end of the sentence         if len(tokens)  ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 出现如下报错信息： Traceback (most recent call last):   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/runpy.py"", line 197, in _run_module_as_main     return _run_code(code, main_globals, None,   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/runpy.py"", line 87, in _run_code     exec(code, run_globals)   File ""/ghome/liuzp/mycode/code/mindspore/mindnlp/llm/finetune/bert/finetune_bert_with_Stanford_Sentiment_Tree_Bank/src/main.py"", line 56, in      main(args)   File ""/ghome/liuzp/mycode/code/mindspore/mindnlp/llm/finetune/bert/finetune_bert_with_Stanford_Sentiment_Tree_Bank/src/main.py"", line 39, in main     trainer.train(epochs=args.max_eps)   File ""/ghome/liuzp/mycode/code/mindspore/mindnlp/llm/finetune/bert/finetune_bert_with_Stanford_Sentiment_Tree_Bank/src/trainer.py"", line 58, in train     self.opt.step()   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/sitepackages/mindnlp/core/optim/adam.py"", line 95, in step     state['exp_avg'] = ops.zeros_like(p)   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/sitepackages/mindnlp/core/ops/creation.py"", line 52, in zeros_like     return ops.zeros_like(input, dtype=dtype)   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/sitepackages/mindspore/ops/function/array_func.py"", line 1077, in zeros_like     output = cast_(output, _dtype)   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/sitepackages/mindspore/ops/operations/manually_defined/ops_def.py"", line 1179, in __call__     should_elim, output = self.check_elim(input_x, dtype)   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/sitepackages/mindspore/ops/operations/manually_defined/ops_def.py"", line 1170, in check_elim     if isinstance(x, Tensor) and x.dtype == dtype:   File ""/ghome/liuzp/anaconda3/envs/ms231py39/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 99, in dtype     self.stub_dtype = self.stub.get_dtype() TypeError: For 'Adam', the 10th input gradient can not be implicitly converted. Its type is None, value is ""None"". Only support Tensor or Scalar. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.  **Additional context / 备注 (Optional / 选填)** 我在代码中加入了 ```python     for param in self.net.trainable_params():         if param.grad is not None:             print(f""Gradient for {param.shape}: {param.grad}"")         else:             print(f""Gradient for {param.shape} is None"") ``` 可以看到输出中确实所有的参数梯度都是None",2024-12-20T08:15:16Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1878,你的写法完全不对，去看mindspore基础教程，我们的是函数式微分，没有loss.backward,"根据mindspore2.3.1文档修改后的代码，依旧有上面的报错 ```python import argparse import pandas as pd import mindspore from mindnlp.transformers import BertModel, BertTokenizer from mindnlp.core import nn  from mindnlp.core.nn import BCEWithLogitsLoss from mindnlp.core.optim import Adam from mindnlp.core.ops import sigmoid def get_accuracy_from_logits(logits, labels):     probs = sigmoid(logits.unsqueeze(1))     soft_probs = (probs > 0.5).long()     acc = (soft_probs.squeeze() == labels).float().mean()     return acc def evaluate(net, criterion, dataloader):     mean_acc, mean_loss = 0, 0     count = 0     for data in dataloader:         tokens_ids = data['tokens_ids']         attn_mask = (tokens_ids != 0).long()         label = data['label']         logits = net(tokens_ids, attn_mask)         mean_loss += criterion(logits.squeeze(1), label).item()         mean_acc += get_accuracy_from_logits(logits, label)         count += 1     return mean_acc / count, mean_loss / count class Trainer:     def __init__(self, net, criterion, optimizer, args,                  train_dataset, eval_dataset=None                  ):         self.net = net         self.criterion = criterion         self.opt = optimizer         self.args = args         self.train_dataset = train_dataset         self.weights = self.net.trainable_params()         self.value_and_grad = mindspore.value_and_grad(self.forward_fn, None, weights=self.weights)         self.run_eval = eval_dataset is not None         if self.run_eval:             self.eval_dataset = eval_dataset         self.logits = None     def forward_fn(self, tokens_ids_tensor, attn_mask, label):         logits = self.net(tokens_ids_tensor, attn_mask)         self.logits = logits         loss = self.criterion(logits.squeeze(1), label)         return loss     def train_single(self, tokens_ids_tensor, attn_mask, label):         loss, grads = self.value_and_grad(tokens_ids_tensor, attn_mask, label)         for g in grads:             if g is not None:                 print(type(g), g.shape)             else:                 print('g is None')         self.opt.step(grads)         return loss     def train(self, epochs):         best_acc = 0         for epoch in range(0, epochs):             self.net.set_train(True)             for i, data in enumerate(self.train_dataset):                 tokens_ids = data['tokens_ids']                 attn_mask = (tokens_ids != 0).long()                 label = data['label']                 loss = self.train_single(tokens_ids, attn_mask, label)                 if i % self.args.print_every == 0:                     acc = get_accuracy_from_logits(self.logits, label)                     print(""Iteration {} of epoch {} complete. Loss : {} Accuracy : {}"".format(i, epoch, loss.item(), acc))              if self.run_eval:                  self.net.eval()                  val_acc, val_loss = evaluate(self.net, self.criterion, self.eval_dataset, self.args)                  print(""Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}"".format(epoch, val_acc, val_loss))                  if val_acc > best_acc:                      print(""Best validation accuracy improved from {} to {}, saving model..."".format(best_acc, val_acc))                      best_acc = val_acc                       ms.save_checkpoint(self.net, ""best.ckpt"") class SentimentClassifier(nn.Module):     def __init__(self, base_model_name_or_path = 'bertbaseuncased', freeze_bert = True):         super().__init__()         Instantiating BERT model object          self.bert_layer = BertModel.from_pretrained(base_model_name_or_path)         Freeze bert layers         if freeze_bert:             for p in self.bert_layer.parameters():                 p.requires_grad = False         Classification layer         self.cls_layer = nn.Linear(768, 1)     def forward(self, seq, attn_masks):         '''         Inputs:             seq : Tensor of shape [B, T] containing token ids of sequences             attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens         '''         Feeding the input to BERT model         last_hs = self.bert_layer(seq, attention_mask = attn_masks).last_hidden_state         Obtaining the representation of [CLS] head         cls_rep = last_hs[:, 0]         Feeding cls_rep to the classifier layer         logits = self.cls_layer(cls_rep)         return logits class SSTDataset():     def __init__(self, base_model_name_or_path, filename, maxlen):         Store the contents of the file in a pandas dataframe          self.df = pd.read_csv(filename, delimiter = '\t')         self.df = pd.DataFrame(filename)         Initialize the BERT tokenizer         self.tokenizer = BertTokenizer.from_pretrained(base_model_name_or_path)         self.maxlen = maxlen     def __len__(self):         return len(self.df)     def __getitem__(self, index):         Selecting the sentence and label at the specified index in the data frame         sentence = self.df.loc[index, 'sentence']         label = self.df.loc[index, 'label']         Preprocessing the text to be suitable for BERT         tokens = self.tokenizer.tokenize(sentence) Tokenize the sentence         tokens = ['[CLS]'] + tokens + ['[SEP]'] Insering the CLS and SEP token in the beginning and end of the sentence         if len(tokens) < self.maxlen:             tokens = tokens + ['[PAD]' for _ in range(self.maxlen  len(tokens))] Padding sentences         else:             tokens = tokens[:self.maxlen1] + ['[SEP]'] Prunning the list to be of specified max length         tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) Obtaining the indices of the tokens in the BERT Vocabulary         return tokens_ids, label def get_loader(dataset, batchsize, shuffle=True, num_workers=1, drop_remainder=True):     data_loader = mindspore.dataset.GeneratorDataset(source=dataset,                                       column_names=['tokens_ids', 'label'],                                       shuffle=shuffle,                                       num_parallel_workers=num_workers                                       )     data_loader = data_loader.batch(batch_size=batchsize,                                      drop_remainder=drop_remainder,                                     )     return data_loader.create_dict_iterator() def main(args):     Instantiating the classifier model     mindspore.set_context(device_target=args.device_target, device_id=args.device_id)     net = SentimentClassifier(args.base_model_name_or_path, args.freeze_bert)      Instantiating the optimizer     criterion = BCEWithLogitsLoss()     opti = Adam(net.trainable_params(), lr=args.lr)     Creating dataloaders     data = {     'id': [1, 2, 3, 4, 5, 6, 7, 8],     'sentence': ['goes to abs', 'the part where', 'saw how ', 'sbae', ' greatest', 'cold movie', 'with his', 'redundant'],     'label': [0, 0, 1, 1, 0, 1, 0, 1]     }     train_set = SSTDataset(args.base_model_name_or_path, filename = data, maxlen = args.maxlen)      val_set = SSTDataset(args.base_model_name_or_path, filename = 'data/SST2/dev.tsv', maxlen = args.maxlen)     train_loader = get_loader(train_set, batchsize=args.batch_size)      val_loader = get_loader(val_set, batchsize=args.batch_size, drop_remainder=False)      Training the model     trainer = Trainer(net=net, criterion=criterion, optimizer=opti, args=args, train_dataset=train_loader)     trainer.train(epochs=args.max_eps) if __name__ == ""__main__"":     parser = argparse.ArgumentParser()     parser.add_argument('device_target', type = str, default = 'Ascend')     parser.add_argument('device_id', type = int, default = 0)     parser.add_argument('base_model_name_or_path', type = str, default = 'bertbaseuncased')     parser.add_argument('freeze_bert', action='store_true')     parser.add_argument('maxlen', type = int, default= 25)     parser.add_argument('batch_size', type = int, default= 4)     parser.add_argument('lr', type = float, default = 2e5)     parser.add_argument('print_every', type = int, default= 100)     parser.add_argument('max_eps', type = int, default= 5)     args = parser.parse_args()     main(args) ```",应该是兼容性问题，换910卡就没问题了
这是一个bug报告类型的issue，主要涉及的对象是mindnlp库中的named_modules功能。由于修复的问题会影响到named_modules的正常功能，用户提出了这个bug报告的请求。,fix named_modules,,2024-12-20T07:36:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1877
这是一个bug报告类型的issue，涉及对象是mindnlp的示例代码，由于某种原因导致出现了报错AttributeError: 'RobertaForSequenceClassification' object has no attribute 'modules_and_names'。,mindnlp里的示例代码mindnlp/llm/peft/prompt_tuning/roberta_sequence_classification.ipynb报错AttributeError: 'RobertaForSequenceClassification' object has no attribute 'modules_and_names',**Describe the bug/ 问题描述 (Mandatory / 必填)** 在华为云使用mindnlp自带的示例代码mindnlp/llm/peft/prompt_tuning/roberta_sequence_classification.ipynb，在没改动代码的前提下，无法跑通，报错：AttributeError: 'RobertaForSequenceClassification' object has no attribute 'modules_and_names'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境 和 软件环境**: > 使用的华为云notebook，镜像mindspore_2.3.0cann_8.0.rc2py_3.9euler_2.10.7aarch64snt9b，实例规格：Ascend: 1*ascendsnt9b1|ARM: 24核 192GB **To Reproduce / 重现步骤 (Mandatory / 必填)** 直接使用mindnlp本身自带的代码，代码路径mindnlp/llm/peft/prompt_tuning/roberta_sequence_classification.ipynb **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !E9AD7AA7198678F2606329760171D0B2,2024-12-20T07:22:28Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1876
这个issue类型是bug报告，该问题单涉及的主要对象是mindnlp.peft中的cells和modules。由于未提供具体内容，导致无法修复cells到modules的问题。,fix cells to modules in mindnlp.peft,,2024-12-19T09:42:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1875
这个issue类型为bug报告，主要涉及对象为mindnlp的peft模块，由于cell_应该被替换为module_，导致了代码bug。,fix cell_ to module_ in mindnlp.peft,,2024-12-19T09:32:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1874
这是一个bug报告，主要涉及mindnlp库中的sbert模块精度问题。原因可能是sbert模块在mindnlp中存在精度问题导致bug。,fix sbert precision problem on mindnlp.sentence,,2024-12-19T09:20:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1873
这是一个bug报告，该问题涉及百川（Baichuan）的finfo错误修复。可能是由于某种原因导致了百川(finfo)信息显示错误。,fix baichuan finfo error,,2024-12-19T06:25:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1872
这是一个回滚提交的类型，主要涉及到mindsporelab/mindnlp中有关image_classification_timm_peft_lora模型微调的问题。,"Revert ""image_classification_timm_peft_lora模型微调""",Reverts mindsporelab/mindnlp CC(image_classification_timm_peft_lora模型微调),2024-12-19T06:16:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1871
这是一个用户提出需求的issue，主要涉及minicpm3模型和动态推断演示。通过用户希望添加minicpm3模型和动态推断演示，以增加功能和展示特定功能的需求。,add minicpm3 model and dynmaic inference demo,,2024-12-17T14:09:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1870
这是一个Bug报告issue，主要涉及Mindnlp安装过程中遇到版本号无效的问题。,"When installing mindnlp, encountered Invalid version: '2.2.3.2c7f2141'","**Describe the bug/ 问题描述 (Mandatory / 必填)** When installing from PyPi (`pip install mindnlp`) or installing from source, it fails and raises this error message   **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Kunpeng920 (standard ModelArts notebook environment)  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version: 2.4.1  Python version : 3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04): EulerOS 2.0 (SP10)  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: N/A **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ``` pip install mindnlp ``` or ``` git clone https://github.com/mindsporelab/mindnlp.git cd mindnlp bash scripts/build_and_reinstall.sh ``` **Expected behavior / 预期结果 (Mandatory / 必填)** mindnlp is being successfully installed. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-17T07:21:53Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1869,把moxingframework卸载了
这个issue是关于bug报告，涉及到GLUE-QNLI的benchmark，提出了修复read_csv错误、修改predict函数和修改readme描述的需求。,#fix benchmark GLUE-QNLI fix read_csv error and predict funciton and modify readme description,,2024-12-16T12:02:17Z,,closed,1,0,https://github.com/mindspore-lab/mindnlp/issues/1868
这是一个用户提出需求的issue，主要对象是YOLOS模型应用开发。,【开源实习】YOLOS模型应用开发,,2024-12-16T11:32:39Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1867,https://gitee.com/mindspore/community/issues/IAAMGW,验收通过，可以合入
这个issue属于bug报告类型，主要涉及GLUE-QNLI的性能问题，由于代码中的predict功能出现了错误，影响了模型的预测结果。,#fix benchmark GLUE-QNLI fix predict funciton,,2024-12-16T09:48:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1866
这是一个需求类型的issue，主要涉及到在MindNLP项目中添加GLUE-QNLI基准测试，包括对10个模型进行推理精度比较。,"#benchmark: add GLUE-QNLI benchmark, including 10 models inference accuracy comparsion",,2024-12-16T07:25:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1865
这是一个用户提出需求的类型，主要对象是MaskFormer模型应用开发。由于原因导致用户提出了关于MaskFormer模型应用开发的问题或者寻求帮助。,【开源实习】MaskFormer模型应用开发,https://gitee.com/mindspore/community/issues/IAADLH,2024-12-13T11:08:00Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1864,验收通过，可以合入代码
这是一个bug报告，主要涉及Mindnlp库中的模型训练问题，可能由于某种原因导致在训练文件中无法完成预期的20个epoch。,cann 8.0 mindnlp 2.3.0 在训练文件llm/peft/prompt_tuning/roberta_sequence_classification.ipynb只能跑到第十九个epoch,!297e0db5e67e4a039d2330bcdadf10c2 同样的模型缓存IA3微调也只能到第19个epoch,2024-12-12T09:28:58Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1863,因为这20个epoches里，开头的是epoches0，所以是019一共二十个。你都算好了，我同样镜像里老是报错，根本开启不了训练。," 1% 1/115 [00:03 17     loss = train_step(**batch)      18     lr_scheduler.step()      20 model.set_train(False) Cell In[12], line 9, in train_step(**batch)       8 def train_step(**batch): > 9     loss, grads = grad_fn(**batch)      10     optimizer.step(grads)      11     return loss File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:625, in _Grad.__call__..after_grad(*args, **kwargs)     624 def after_grad(*args, **kwargs): > 625     return grad_(fn_, weights)(*args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:185, in _wrap_func..wrapper(*arg, **kwargs)     183 (fn)     184 def wrapper(*arg, **kwargs): > 185     results = fn(*arg, **kwargs)     186     return _convert_python_data(results) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:600, in _Grad.__call__..after_grad(*args, **kwargs)     598      599 def after_grad(*args, **kwargs): > 600     res = self._pynative_forward_run(fn, grad_, weights, args, kwargs)     601     out = _pynative_executor.grad(fn, grad_, weights, grad_position, *args, **kwargs)     602     out = _grads_divided_by_device_num_if_recomputation(out) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:649, in _Grad._pynative_forward_run(self, fn, grad, weights, args, kwargs)     647 if not _pynative_executor.check_run(grad, fn, weights, self.grad_position, *args, **new_kwargs):     648     _pynative_executor.set_grad_flag(True) > 649     _pynative_executor.new_graph(fn, *args, **new_kwargs)     650     outputs = fn(*args, **new_kwargs)     651     _pynative_executor.end_graph(fn, outputs, *args, **new_kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1449, in _PyNativeExecutor.new_graph(self, obj, *args, **kwargs)    1437 def new_graph(self, obj, *args, **kwargs):    1438     """"""    1439     Initialize resources for building forward and backward graph.    1440     (...)    1447         None.    1448     """""" > 1449     self._executor.new_graph(obj, *args, *(kwargs.values())) TypeError: For 'Adam', the 10th input gradient can not be implicitly converted. Its type is None, value is ""None"". Only support Tensor or Scalar.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/pynative/forward/do_cast.cc:235 DoSignatureCast 我报错是这样的，不知道啥毛病", 说的对，019是20个数没问题，这个单可以关了。  你的问题再提个issue呗
这是一个用户提出需求的issue，主要涉及的对象是MindSpore自定义RWKV算子的Python接口实现，用户寻求在该项目中新增RWKV6 Python接口的实现。,【开源实习】MindSpore自定义RWKV算子开发（Python接口实现）,任务链接: Gitee Issue IB4Z22 新增 RWKV6 Python接口的 mindspore 实现.,2024-12-11T11:54:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1862
这个issue是一个bug报告，主要涉及到在BigBird中使用ops.ones存在问题。可能是由于使用ops.ones的方式不正确导致了bug的出现。,fix: Fix problem using ops.ones in BigBird,,2024-12-11T07:28:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1861
这是一个bug报告，针对baichuan-inc/Baichuan-7B加载推理报错这个问题。这个问题可能由于某种原因导致了加载推理时出现错误的症状。,baichuan-inc/Baichuan-7B加载推理报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** baichuaninc/Baichuan7B加载推理报错  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 推理代码来自：https://github.com/ResDream/BaichuanEval 运行gsm8k.py mmlu_eval.py 或者CEval.py **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !aad0f08a03f8f87787545e42162394b 从cumsum开始报错，修改成int() 报错full()takes 2 positional arguments but 3 were given然后删除了ops.full中的dtype报下图中的错误，不确定需要在value中添加什么tensor： !5eec41ad2ad02ec65bbcbc52c637d28 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-10T09:56:45Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1860,大概知道是啥问题了，我修一下
这是一个bug报告，主要涉及到deepseek_v2模型在使用不同版本的mindspore时出现问题。这可能是由于MoE部分缺少封装导致的。,重做deepseek_v2模型并补注册,本地测试使用mindspore 2.2.14可以正常输出结果，用2.4会有问题；MoE部分缺少封装，等封装完毕后会跟进维护 !deepseek本地测试结果,2024-12-10T04:25:27Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1859,2.4是啥问题？,> 2.4是啥问题？ !54d5bc8e700db91f5c1a2d1faa036f4 除了2.2.14给的那个警告之外还多了一个警告，而且占了大部分，跑很久都没有结果一直报warning，然后电脑蓝屏重启，试了几次都一样，根本看不到最后结果
这是一个bug报告，主要涉及的对象是Whisper在香橙派AIPro板子上无法推理。这个问题可能由于硬件兼容性或者其他原因导致。,Whisper无法在香橙派AIPro上推理,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在香橙派AIPro板子上，运行如下代码： ```py from transformers import pipeline transcriber = pipeline(model=""openai/whisperbase"") transcriber(""test.wav"") ``` 遇到报错： ```sh Traceback (most recent call last):   File """", line 1, in    File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/automatic_speech_recognition.py"", line 282, in __call__     return super().__call__(inputs, **kwargs)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/base.py"", line 1161, in __call__     return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/base.py"", line 1297, in run_single     model_outputs = self.forward(model_inputs, **forward_params)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/base.py"", line 1103, in forward     model_outputs = self._forward(model_inputs, **forward_params)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/automatic_speech_recognition.py"", line 506, in _forward     tokens = self.model.generate(   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py"", line 537, in generate     init_tokens = self._retrieve_init_tokens(   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py"", line 1343, in _retrieve_init_tokens     lang_ids = self.detect_language(   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py"", line 1450, in detect_language     non_lang_mask[list(generation_config.lang_to_id.values())] = False   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 49, in fun     return method(*arg, **kwargs)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 496, in __setitem__     self.assign_value(out)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/_check_jit_forbidden_api.py"", line 35, in jit_forbidden     return fn(*args, **kwargs)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 942, in assign_value     self.assign_value_cpp(value) RuntimeError: Call aclnnSWhere failed, detail:EZ9999: Inner Error! EZ9999: [PID: 37455] 2024120423:05:48.771.581 Parse dynamic kernel config fail.[THREAD:37777]         TraceBack (most recent call last):        AclOpKernelInit failed opType[THREAD:37777]        Op SelectV2 does not has any binary.[THREAD:37784]        Kernel Run failed. opType: 22, SelectV2[THREAD:37784]        launch failed for SelectV2, errno:561000.[THREAD:37784]   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/ascend/pyboost/auto_generate/select.cc:53 operator() ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.4.1  Python version (e.g., Python 3.7.5) : 3.9.2  OS platform and distribution (e.g., Linux Ubuntu 16.04): Linux orangepiaipro  aarch64  GCC/Compiler version (if compiled from source): 11.4.0  CANN: 8.0.RC3.beta1  Kernel: Ascendcannkernels310b_8.0.RC3  npusmi info: ```sh ++  +===============================+=================+======================================================+ ```  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. install mindnlp by source code. 2. source CANN 3. run code 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** 在ModelArts的910B4机器上相同的CANN版本能够推理成功，但在香橙派的310B4上失败，报告EZ9999错误，重复检查了CANN包环境是没问题的。 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !error **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-04T15:52:59Z,bug,open,0,5,https://github.com/mindspore-lab/mindnlp/issues/1858,需要设置 set_pyboost(False),"刚刚在香橙派上添加了`set_pyboost(False)`进行了尝试， ```py from mindnlp.transformers import pipeline from mindnlp.configs import set_pyboost transcriber = pipeline(model=""openai/whisperbase"") set_pyboost(False) transcriber(""/root/whisper2om/Birth.wav"")  中文音频 transcriber(""/root/whisper2om/test.wav"")  英文音频 ``` 仍旧报错： ```shell python testmindnlp.py  /usr/local/miniconda3/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/miniconda3/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /usr/local/miniconda3/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/miniconda3/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) [WARNING] DEVICE(120308,e7ffc34ca020,python):2024121116:03:45.493.032 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:116] Initialize] Free memory size is less than half of total memory size.Device 0 Device HBM total size:16367894528 Device HBM free size:7702208512 may be other processes occupying this card, check as: ps ef|grep python /usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py:491: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.   warnings.warn( Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`. Traceback (most recent call last):   File ""/root/mindnlpwhisper/testmindnlp.py"", line 6, in      transcriber(""/root/whisper2om/Birth.wav"")   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/automatic_speech_recognition.py"", line 282, in __call__     return super().__call__(inputs, **kwargs)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/base.py"", line 1161, in __call__     return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/base.py"", line 1297, in run_single     model_outputs = self.forward(model_inputs, **forward_params)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/base.py"", line 1103, in forward     model_outputs = self._forward(model_inputs, **forward_params)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/automatic_speech_recognition.py"", line 506, in _forward     tokens = self.model.generate(   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py"", line 537, in generate     init_tokens = self._retrieve_init_tokens(   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py"", line 1343, in _retrieve_init_tokens     lang_ids = self.detect_language(   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindnlp/transformers/models/whisper/generation_whisper.py"", line 1450, in detect_language     non_lang_mask[list(generation_config.lang_to_id.values())] = False   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 49, in fun     return method(*arg, **kwargs)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 496, in __setitem__     self.assign_value(out)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/_check_jit_forbidden_api.py"", line 35, in jit_forbidden     return fn(*args, **kwargs)   File ""/usr/local/miniconda3/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 942, in assign_value     self.assign_value_cpp(value) RuntimeError: Call aclnnSWhere failed, detail:EZ9999: Inner Error! EZ9999: [PID: 120308] 2024121116:04:27.069.860 Parse dynamic kernel config fail.[THREAD:120481]         TraceBack (most recent call last):        AclOpKernelInit failed opType[THREAD:120481]        Op SelectV2 does not has any binary.[THREAD:120482]        Kernel Run failed. opType: 22, SelectV2[THREAD:120482]        launch failed for SelectV2, errno:561000.[THREAD:120482]   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/ascend/pyboost/auto_generate/select.cc:53 operator() ```","香橙派AIPro Ascend310B1 版本, 报错完全相同",最新源码安装的mindnlp吗,是的. 从 master 分支重新安装 mindnlp 仍然报错
这是一个bug报告，涉及的主要对象是gradient AllReduce调用时间错误。这个问题可能由于代码中错误的调用时机导致了错误的结果。,fix: fix wrong call time for gradient AllReduce,fix: fix wrong call time for gradient AllReduce,2024-12-04T10:15:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1857
这个issue类型是功能需求，主要涉及的对象是多卡运行模型；用户提出寻求多个模型在同一进程中多卡运行的功能。,在一个进程里面，多个模型在多卡运行,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] 比如我用一个fastapi提供一个预测接口，这里面有五种类型的模型（摘要、分类、实体提取等等），我现在有5张卡，我想要{模型1：卡0，模型2：卡1，模型3：卡3} **Describe the solution you'd like** A clear and concise description of what you want to happen. 这是以前nvidia驱动下设置，直接模型to指定卡，现在to不行 !image **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. 只能一个进程发布一个模型了。 **Additional context** Add any other context or screenshots about the feature request here.,2024-12-04T06:43:02Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1856,mindspore机制不支持，后续无支持计划，参考llama多进程多卡推理
这是一个bug报告类型的issue，涉及transformers & mindnlp.transformers加载推理生成的结果差异大问题。,transformers & mindnlp.transformers加载推理生成的结果差异大,**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: 显卡：GPU  **Software Environment / 软件环境 (Mandatory / 必填)**: mindnlp 0.4.1(代码编译)  MindSpore version 2.4.0  Python version 3.10.10  OS platform and distribution Ubuntu 20.04  GCC/Compiler version 9.4.0  加载mistralv0.37b模型推理 !8acf9716fe2512f298c853d4651a339 !2a88b4975cef0f9aad4309f85f94f15 **Expected behavior / 预期结果 (Mandatory / 必填)** transformers & mind.transformers方式生成的结果相近 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.,2024-12-03T09:39:34Z,bug,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1855,能否给一下代码？
这是一个功能需求，用户希望添加关于summarization微调的例子。,example中提供一下summarization微调的例子,**Is your feature request related to a problem? Please describe.** 案例最好是能够把hg中的微调案例同步一下，便于大家快速切换上手 **Describe the solution you'd like** 加速微调脚本 **Additional context** 现在迫切需要summarization的微调脚本。https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization,2024-12-02T03:33:21Z,,open,0,3,https://github.com/mindspore-lab/mindnlp/issues/1854,huggingface的微调案例： https://github.com/huggingface/transformers/tree/main/examples/pytorch,!image  缺少DataCollatorForSeq2Seq,"调试代码： import numpy as np import evaluate from typing import List, Optional, Union, Any from rouge import Rouge import mindspore  导入封神榜自己的token from tokenizers_pegasus import PegasusTokenizer from mindspore.dataset import GeneratorDataset, transforms from mindnlp.engine import Trainer, TrainingArguments from mindnlp.dataset import load_dataset from mindnlp.transformers import (     AutoModelForSeq2SeqLM ) from mindnlp.engine.train_args.seq2seq import Seq2SeqTrainingArguments  处理数据 import mindspore train_dataset = raw_datasets = load_dataset(     'csv',     data_files='/home/mauser/script/train.csv' ) def process_dataset(dataset: GeneratorDataset, tokenizer, max_seq_len=1024, batch_size=32, shuffle=False, take_len=None):     is_ascend = mindspore.get_context('device_target') == 'Ascend'      The tokenize function     def tokenize(text):         if is_ascend:             tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=max_seq_len)         else:             tokenized = tokenizer(text, truncation=True, max_length=max_seq_len)         return tokenized['input_ids'],  tokenized['attention_mask']     def tokenize2(text):         if is_ascend:             tokenized = tokenizer(text, padding='max_length', truncation=True, max_length=max_seq_len)         else:             tokenized = tokenizer(text, truncation=True, max_length=max_seq_len)         return tokenized['input_ids']      Shuffle the order of the dataset     if shuffle:         dataset = dataset.shuffle(buffer_size=batch_size)          Select the first several entries of the dataset     if take_len:         dataset = dataset.take(take_len)      Apply the tokenize function, transforming the 'text' column into the three output columns generated by the tokenizer.     dataset = dataset.map(operations=[tokenize], input_columns=""text"", output_columns=['input_ids', 'attention_mask'])      Cast the datatype of the 'label' column to int32 and rename the column to 'labels'     dataset = dataset.map(operations=[tokenize2], input_columns=""label"", output_columns=""labels"")     print(dataset)      Batch the dataset with padding.     if is_ascend:         dataset = dataset.batch(batch_size)     else:         dataset = dataset.padded_batch(batch_size, pad_info={'input_ids': (None, tokenizer.pad_token_id),                                                              'attention_mask': (None, 0)})     return dataset batch_size = 4  Size of each batch train_dataset = process_dataset(train_dataset, tokenizer, batch_size=batch_size, shuffle=True)  训练 training_args = Seq2SeqTrainingArguments(     output_dir = ""./output"",     per_device_train_batch_size=4,      per_device_eval_batch_size=4,     learning_rate=2e5,     num_train_epochs=2,     logging_steps=200,     evaluation_strategy=""epoch"",     save_strategy=""epoch"", ) def compute_metrics(eval_pred):     return {} trainer = Trainer(     model=model,     args=training_args,     train_dataset=train_dataset,      eval_dataset=eval_dataset if training_args.do_eval else None,     tokenizer=tokenizer,     compute_metrics=compute_metrics,      data_collator=data_collator,     compute_metrics=compute_metrics if training_args.predict_with_generate else None, ) checkpoint = '/home/hollynpu/work/script/checkpoint/checkpoint20231217' train_result = trainer.train() trainer.save_model()   Saves the tokenizer too for easy upload metrics = train_result.metrics 报错信息：  AttributeError                            Traceback (most recent call last) Cell In[33], line 27      15 trainer = Trainer(      16     model=model,      17     args=training_args,    (...)      23     compute_metrics=compute_metrics if training_args.predict_with_generate else None,      24 )      26 checkpoint = '/home/hollynpu/work/script/checkpoint/checkpoint20231217' > 27 train_result = trainer.train()      28 trainer.save_model()   Saves the tokenizer too for easy upload      30 metrics = train_result.metrics File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:755, in Trainer.train(self, resume_from_checkpoint, ignore_keys_for_eval, **kwargs)     750     self.model_wrapped = self.model     752 inner_training_loop = find_executable_batch_size(     753     self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size     754 ) > 755 return inner_training_loop(     756     args=args,     757     resume_from_checkpoint=resume_from_checkpoint,     758     ignore_keys_for_eval=ignore_keys_for_eval,     759 ) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:1107, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, ignore_keys_for_eval)    1104 if step % args.gradient_accumulation_steps == 0:    1105     self.control = self.callback_handler.on_step_begin(args, self.state, self.control) > 1107 tr_loss_step, grads = self.training_step(model, inputs)    1108 if (    1109     args.logging_nan_inf_filter    1110     and (ops.isnan(tr_loss_step) or ops.isinf(tr_loss_step))    1111 ):    1112      if loss is nan or inf simply add the average of previous logged losses    1113     tr_loss += tr_loss / (1 + self.state.global_step  self._globalstep_last_logged) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:1382, in Trainer.training_step(self, model, inputs)    1379         weights += tuple(group['params'])    1380     self.grad_fn = mindspore.value_and_grad(forward, None, weights) > 1382 loss, grads = self.grad_fn(inputs)    1384 return loss / self.args.gradient_accumulation_steps, grads File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:625, in _Grad.__call__..after_grad(*args, **kwargs)     624 def after_grad(*args, **kwargs): > 625     return grad_(fn_, weights)(*args, **kwargs) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:185, in _wrap_func..wrapper(*arg, **kwargs)     183 (fn)     184 def wrapper(*arg, **kwargs): > 185     results = fn(*arg, **kwargs)     186     return _convert_python_data(results) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:600, in _Grad.__call__..after_grad(*args, **kwargs)     598      599 def after_grad(*args, **kwargs): > 600     res = self._pynative_forward_run(fn, grad_, weights, args, kwargs)     601     out = _pynative_executor.grad(fn, grad_, weights, grad_position, *args, **kwargs)     602     out = _grads_divided_by_device_num_if_recomputation(out) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:650, in _Grad._pynative_forward_run(self, fn, grad, weights, args, kwargs)     648 _pynative_executor.set_grad_flag(True)     649 _pynative_executor.new_graph(fn, *args, **new_kwargs) > 650 outputs = fn(*args, **new_kwargs)     651 _pynative_executor.end_graph(fn, outputs, *args, **new_kwargs)     652 return outputs File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:1374, in Trainer.training_step..forward(inputs)    1373 def forward(inputs): > 1374     return self.compute_loss(model, inputs) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:1396, in Trainer.compute_loss(self, model, inputs, return_outputs)    1394 else:    1395     labels = None > 1396 outputs = model(**inputs)    1397  Save past state if it exists    1398  TODO: this needs to be fixed and made cleaner later.    1399 if self.args.past_index >= 0: File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py:391, in Module._wrapped_call_impl(self, *args, **kwargs)     389 if self.__ms_class__:     390     return self.forward(*args, **kwargs) > 391 return self._call_impl(*args, **kwargs) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py:402, in Module._call_impl(self, *args, **kwargs)     397  If we don't have any hooks, we want to skip the rest of the logic in     398  this function, and just call forward.     399 if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks     400         or _global_backward_pre_hooks or _global_backward_hooks     401         or _global_forward_hooks or _global_forward_pre_hooks): > 402     return forward_call(*args, **kwargs)     404 try:     405     result = None File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/pegasus/modeling_pegasus.py:1647, in PegasusForConditionalGeneration.forward(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)    1645     use_cache = False    1646     if decoder_input_ids is None and decoder_inputs_embeds is None: > 1647         decoder_input_ids = shift_tokens_right(    1648             labels, self.config.pad_token_id, self.config.decoder_start_token_id    1649         )    1651 outputs = self.model(    1652     input_ids,    1653     attention_mask=attention_mask,    (...)    1666     return_dict=return_dict,    1667 )    1668 lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/pegasus/modeling_pegasus.py:55, in shift_tokens_right(input_ids, pad_token_id, decoder_start_token_id)      51 """"""      52 Shift input ids one token to the right.      53 """"""      54 shifted_input_ids = input_ids.new_zeros(input_ids.shape) > 55 shifted_input_ids[:, 1:] = input_ids[:, :1].clone()      56 shifted_input_ids[:, 0] = decoder_start_token_id      58 if pad_token_id is None: AttributeError: 'StubTensor' object has no attribute 'clone' 没有data_collator、Seq2SeqTrainer。导致hg里面原始的训练无法迁移，提提供基础的训练摘要脚本。"
"这是一个bug报告，涉及对象为""sbert normalize_embeddings""，由于向量归一化导致报错。",sbert normalize_embeddings 报错,"**报错信息** sbert向量进行归一化报错，不归一化不报错。  **Ascend环境** !image  **Software Environment / 软件环境 (Mandatory / 必填)**: !image !image **Expected behavior / 预期结果 (Mandatory / 必填)** !image **Screenshots/ 日志 / 截图 (Mandatory / 必填)** [ERROR] KERNEL(82890,fffe8fe3f1e0,python3.9):2024120203:09:35.241.039 [mindspore/ccsrc/plugin/device/ascend/kernel/acl/acl_kernel_mod.cc:260] Launch] Kernel launch failed, msg: Acl compile and execute failed, op_type_:LpNorm   Ascend Error Message:  E29999: Inner Error! E29999: 2024120203:09:35.236.796  [SubGraphOpt][Compile][ProcFailedCompTask] Thread[281460975792608] recompile single op[LpNorm2] failed[FUNC:ProcessAllFailedCompileTasks][FILE:tbe_op_store_adapter.cc][LINE:961][THREAD:85252]         TraceBack (most recent call last):         [SubGraphOpt][Compile][ParalCompOp] Thread[281460975792608] process fail task failed[FUNC:ParallelCompileOp][FILE:tbe_op_store_adapter.cc][LINE:1009][THREAD:85252]         [SubGraphOpt][Compile][CompOpOnly] CompileOp failed.[FUNC:CompileOpOnly][FILE:op_compiler.cc][LINE:1112][THREAD:85252]         [GraphOpt][FusedGraph][RunCompile] Failed to compile graph with compiler Normal mode Op Compiler[FUNC:SubGraphCompile][FILE:fe_graph_optimizer.cc][LINE:1420][THREAD:85252]         Call OptimizeFusedGraph failed, ret:1, engine_name:AIcoreEngine, graph_name:partition0_rank1_new_sub_graph1[FUNC:OptimizeSubGraph][FILE:graph_optimize.cc][LINE:119][THREAD:85252]         subgraph 0 optimize failed[FUNC:OptimizeSubGraphWithMultiThreads][FILE:graph_manager.cc][LINE:1012][THREAD:84819]         build graph failed, graph id:1, ret:1[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1608][THREAD:84819]         [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161][THREAD:84819]         [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145][THREAD:84819]         build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145][THREAD:84819] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ccsrc/transform/acl_ir/acl_utils.cc:379 Run [ERROR] DEVICE(82890,fffe8fe3f1e0,python3.9):2024120203:09:35.241.072 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge_kernel_executor.cc:1156] LaunchKernel] Launch kernel failed, kernel full name: Default/LpNormop0  RuntimeError                              Traceback (most recent call last) Cell In[5], line 3       1  向量预测       2 text = ['他开车去了体育场。'] > 3 print(model_emb.encode(text, normalize_embeddings=True)) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/sentence/sentence_transformer.py:236, in SentenceTransformer.encode(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, normalize_embeddings)     234             all_embeddings = np.asarray([emb.float().asnumpy() for emb in all_embeddings])     235         else: > 236             all_embeddings = np.asarray([emb.asnumpy() for emb in all_embeddings])     237 elif isinstance(all_embeddings, np.ndarray):     238     all_embeddings = [ops.from_numpy(embedding) for embedding in all_embeddings] File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/sentence/sentence_transformer.py:236, in (.0)     234             all_embeddings = np.asarray([emb.float().asnumpy() for emb in all_embeddings])     235         else: > 236             all_embeddings = np.asarray([emb.asnumpy() for emb in all_embeddings])     237 elif isinstance(all_embeddings, np.ndarray):     238     all_embeddings = [ops.from_numpy(embedding) for embedding in all_embeddings] File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py:49, in _stub_method..fun(*arg, **kwargs)      47 stub = arg[0]      48 arg = (stub.stub_sync(),) + arg[1:] > 49 return method(*arg, **kwargs) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/tensor.py:1055, in Tensor.asnumpy(self)    1053 if self.has_init:    1054     self.init_data() > 1055 return Tensor_.asnumpy(self) RuntimeError: Launch kernel failed, name:Default/LpNormop0   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/pynative/op_runner.cc:624 LaunchKernels **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-12-02T03:28:30Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1853,麻烦提供一个复现代码，今天刚修了一下，你也可以先试试行不行。,"1、代码如下： from mindnlp.transformers import AutoTokenizer from mindnlp.sentence.sentence_transformer import SentenceTransformer model_path = ""/home/hollynpu/models/acge_text_embedding"" tokenizer = AutoTokenizer.from_pretrained(model_path) model = SentenceTransformer(model_path)   model.encode(text,normalize_embeddings=True) 2、修复的分支是什么。",我测测看看，修复的分支是master
这个issue是关于功能增强（feature enhancement），主要涉及的对象是mindnlp.Trainer.base类。由于需要决定并行分布类型，所以添加了一个描述加速分布类型的常量。,feat: add data parallel of native mindspore to mindnlp.Trainer.base,"add accelerate_distributed_type constant to decide parallel DistributedType, add data parallel of native mindspore to mindnlp.Trainer.base",2024-11-29T05:23:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1852,pylint还是没过
这是一个用户提出需求的issue，主要对象是缺少部分pytorch封装，可能是由于功能缺失导致的。,缺少部分pytorch封装,**Is your feature request related to a problem? Please describe.** 缺少如下封装： !image !image 无法使用以下接口 !image !image,2024-11-28T16:55:26Z,feature,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1851,这些方法都在deepseek的if else判断语句中有出现，之前被直接删了,要等mindspore的2.5版本
"这是一个关于""开源实习""的类型的问题，主要涉及MobileViTV2模型迁移。由于迁移任务已经完成UT，用户可能正在寻求进一步的讨论或指导。",【开源实习】 MobileViTV2 模型迁移,MobileViTV2迁移任务，已经完成UT。 任务链接：https://gitee.com/mindspore/community/issues/IA70FZ 新增 MobileViTV2 模型的支持，包括以下内容： 1. 配置文件迁移 2. 模型迁移 3. 测试迁移 4. __init__注册 说明：有一项精度测试满足1e3（其余皆满足模板给出的1e4精度），符合与原模型精度相差1%以内。 !ut,2024-11-27T15:18:32Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1850,关注一下pylint
这是一个bug报告，涉及的主要对象是代码中的 `self.module_logits`，导致症状是需要将其改为 `self.cell_logits`。,self.module_logits需要改成self.cell_logits,"**Describe the bug/ 问题描述 (Mandatory / 必填)** self.module_logits需要改成self.cell_logits  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to 'cd anaconda3/envs/ Mindspore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly' 2. Click on 'vi router.py' 3. Scroll down to  4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** self.module logits变成self.cell logits **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 位置是mindnlp/peft/tuners/poly的router.py文件 !47d6abde9f095e7c1b29d28502fa2a9 !5b8ada5a6c15954ec664925f111459c **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-26T03:39:50Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1849
这是一个关于bug报告类型的issue，涉及主要对象为bert模型。由于导出mindir失败，用户提出了此问题。,bert模型用mindspore的export方法导出mindir失败,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. BertForSequenceclassification模型用mindspore.export方法导出失败  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore 2.3.1  Python 3.9.20  OS platform and distribution (e.g., Linux Ubuntu 16.04): ky10.aarch64 **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ``` import mindspore as ms import numpy as np from mindspore import Tensor from mindnlp.transformers import BertTokenizer from mindnlp.transformers import BertForSequenceclassification, BertModel path='/home/kw/huggingface/bertbaseuncased/' model = BertForsequenceclassification.from pretrained(path, num labels=9, ignore mismatched sizes=True) print(type(model)) tokenizer =BertTokenizer.from pretrained(path) text ='hello, mindnlp' inputs = tokenizer(text, padding='max length', truncation=True, max length=128) print( inputs ) ms .export(model, *inputs,'file name='model',file format='MINDIR') ``` **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !2c856fee675669df56d3814c4465d85 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here. 看了一下mindspore的源码，这里导出过程中要验证net是types.FunctionType或者type.MethodType，没有看懂",2024-11-25T08:04:31Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1848,当前mindnlp的模型构造不使用mindspore.nn.Cell（出于性能、迁移便捷性考虑），因此无法直接用mindspore.export导出，如果有需求的话，请提一个requirement issue，短期内应该还不会支持,> 当前mindnlp的模型构造不使用mindspore.nn.Cell（出于性能、迁移便捷性考虑），因此无法直接用mindspore.export导出，如果有需求的话，请提一个requirement issue，短期内应该还不会支持 感谢。如果目标是想用mindie提升推理性能，请问有推荐其他替代的导出或者转换方案吗？
这是一个bug报告，涉及到Qwen2.5-coder-14B单机多卡推理报错。原因导致推理报错。,Qwen2.5-coder-14B单机多卡推理报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. Qwen2.5coder14B, 单机多卡推理报错  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: 910A和910B均报错  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): Mindspore2.4, python3.9, Ubuntu20.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph 代码中没有指定运行模式, 应该是默认的PyNative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 代码: ```python import mindspore as ms from mindspore.communication import init from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer, logger  from openmind_hub import snapshot_download  snapshot_download(repo_id=""MindSporeLab/Qwen2.5Coder14B"", repo_type=""model"", local_dir='./Qwen2.5Coder14B')  print(""Download Qwen2.5Coder14B successfully"") REPO_ID = ""./Qwen2.5Coder14B"" init()  REPO_ID = ""/home/mseco/qhzhuang/qwen32B"" model = AutoModelForCausalLM.from_pretrained(     REPO_ID, ms_dtype=ms.float16, device_map=""auto"") tokenizer = AutoTokenizer.from_pretrained(REPO_ID) print("" Init Model "") conversation = [] message = ""who are you"" conversation.append({""role"": ""user"", ""content"": message}) input_ids = tokenizer.apply_chat_template(     conversation, add_generation_prompt=True, return_tensors=""ms"") print(input_ids) print(f""model type: {type(model)}"") sample_output = model.generate(input_ids,                                max_new_tokens=100,                                do_sample=True,                                top_p=0.95,                                top_k=50,                                temperature=0.7,                                repetition_penalty=1.0,                                num_beams=1) response = sample_output[0][input_ids.shape[1]:] print(tokenizer.decode(response, skip_special_tokens=True)) print("" Init Model Finished "") ``` 启动:mpirun bindto numa n 2 python qwen_infer_distributed.py  **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 无报错输出推理结果 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. [WARNING] DISTRIBUTED(1027085,ffff8ae49020,python):2024112515:26:22.431.358 [mindspore/ccsrc/distributed/collective/collective_manager.cc:384] CreateCommunicationGroup] End initialize communication group on the device side: hccl_world_group Qwen2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.    If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).    If you are not the owner of the model architecture class, please contact the model code owner to update it. Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered. Traceback (most recent call last):   File ""/home/mseco/qhzhuang/qwen_infer_distributed.py"", line 12, in      model = AutoModelForCausalLM.from_pretrained(   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/models/auto/auto_factory.py"", line 510, in from_pretrained     return model_class.from_pretrained(   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 3126, in from_pretrained     model = cls(config, *model_args, **model_kwargs)   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 666, in __init__     self.model = Qwen2Model(config)   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 472, in __init__     [Qwen2DecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 472, in      [Qwen2DecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 368, in __init__     self.self_attn = QWEN2_ATTENTION_CLASSESconfig._attn_implementation   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 268, in __init__     self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=True)   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/core/nn/modules/linear.py"", line 48, in __init__     self.reset_parameters()   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/core/nn/modules/linear.py"", line 56, in reset_parameters     fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)   File ""/home/mseco/miniconda3/envs/ms24/lib/python3.9/sitepackages/mindnlp/core/nn/init.py"", line 335, in _calculate_fan_in_and_fan_out     raise ValueError( ValueError: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here. 在华为云910B环境jupyter notebook报错: Qwen2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.    If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).    If you are not the owner of the model architecture class, please contact the model code owner to update it. Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.  ValueError                                Traceback (most recent call last) Cell In[2], line 2       1 REPO_ID = ""./Qwen2.5Coder14B"" > 2 model = AutoModelForCausalLM.from_pretrained(REPO_ID, ms_dtype=ms.float16, device_map=""auto"")       3 tokenizer = AutoTokenizer.from_pretrained(REPO_ID) File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/models/auto/auto_factory.py:510, in _BaseAutoModelClass.from_pretrained(cls, pretrained_model_name_or_path, *model_args, **kwargs)     508 if type(config) in cls._model_mapping.keys():     509     model_class = _get_model_class(config, cls._model_mapping) > 510     return model_class.from_pretrained(     511         pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs     512     )     513 raise ValueError(     514     f""Unrecognized configuration class {config.__class__} for this kind of AutoModel: {cls.__name__}.\n""     515     f""Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.""     516 ) File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/modeling_utils.py:3126, in PreTrainedModel.from_pretrained(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)    3123 model_kwargs.pop('mirror', None)    3124 with ContextManagers(init_contexts):    3125      Let's make sure we don't run the init function of buffer modules > 3126     model = cls(config, *model_args, **model_kwargs)    3127  make sure we use the model's config since the __init__ call might have copied it    3128 config = model.config File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:666, in Qwen2ForCausalLM.__init__(self, config)     664 def __init__(self, config):     665     super().__init__(config) > 666     self.model = Qwen2Model(config)     667     self.vocab_size = config.vocab_size     668     self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False) File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:472, in Qwen2Model.__init__(self, config)     468 self.vocab_size = config.vocab_size     470 self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)     471 self.layers = nn.ModuleList( > 472     [Qwen2DecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]     473 )     474 self._attn_implementation = config._attn_implementation     475 self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps) File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:472, in (.0)     468 self.vocab_size = config.vocab_size     470 self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size, self.padding_idx)     471 self.layers = nn.ModuleList( > 472     [Qwen2DecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]     473 )     474 self._attn_implementation = config._attn_implementation     475 self.norm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps) File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:368, in Qwen2DecoderLayer.__init__(self, config, layer_idx)     363 if config.sliding_window and config._attn_implementation != ""flash_attention_2"":     364     logger.warning_once(     365         f""Sliding Window Attention is enabled but not implemented for `{config._attn_implementation}`; ""     366         ""unexpected results may be encountered.""     367     ) > 368 self.self_attn = QWEN2_ATTENTION_CLASSESconfig._attn_implementation     370 self.mlp = Qwen2MLP(config)     371 self.input_layernorm = Qwen2RMSNorm(config.hidden_size, eps=config.rms_norm_eps) File ~/.local/lib/python3.10/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py:268, in Qwen2Attention.__init__(self, config, layer_idx)     263 if (self.head_dim * self.num_heads) != self.hidden_size:     264     raise ValueError(     265         f""hidden_size must be divisible by num_heads (got `hidden_size`: {self.hidden_size}""     266         f"" and `num_heads`: {self.num_heads}).""     267     ) > 268 self.q_proj = nn.Linear(self.hidden_size, self.num_heads * self.head_dim, bias=True)     269 self.k_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=True)     270 self.v_proj = nn.Linear(self.hidden_size, self.num_key_value_heads * self.head_dim, bias=True) File ~/.local/lib/python3.10/sitepackages/mindnlp/core/nn/modules/linear.py:48, in Linear.__init__(self, in_features, out_features, bias, dtype)      45 else:      46     self.register_parameter('bias', None) > 48 self.reset_parameters() File ~/.local/lib/python3.10/sitepackages/mindnlp/core/nn/modules/linear.py:56, in Linear.reset_parameters(self)      54 init.kaiming_uniform_(self.weight, a=math.sqrt(5))      55 if self.bias is not None: > 56     fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)      57     bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0      58     init.uniform_(self.bias, bound, bound) File ~/.local/lib/python3.10/sitepackages/mindnlp/core/nn/init.py:335, in _calculate_fan_in_and_fan_out(tensor)     333 dimensions = tensor.ndim     334 if dimensions  335     raise ValueError(     336         ""Fan in and fan out can not be computed for tensor with fewer than 2 dimensions""     337     )     339 num_input_fmaps = tensor.shape[1]     340 num_output_fmaps = tensor.shape[0] ValueError: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions",2024-11-25T07:30:16Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1847,"补充mindnlp版本, 从源码安装, 安装时最新commit_id为: 5ce1a8367e25594c209a8dde3d00e10facd0d452   Author: nate.river  Date:   Fri Nov 22 17:27:02 2024 +0800"
该issue为学术讨论类型，主要涉及biogpt论文解读，用户寻求解读和讨论这篇论文。,【开源实习】biogpt论文解读,,2024-11-25T04:56:01Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1846,IAUOB9
这是一则用户请求进行文本内容解读的issue，主要涉及对象是align论文。,【开源实习】align论文解读,,2024-11-25T04:53:03Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1845,https://gitee.com/mindspore/community/issues/IAUNOW
这个issue是一个用户提出需求类型的问题，主要涉及mindnlp下的peft_adalora_sep2模型微调。,【开源实习】peft_adalora_sep2模型微调,,2024-11-24T15:51:44Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1844
这是一个关于bug报告的issue，主要涉及baichuan无法推理对话的问题。由于描述bug/问题的内容不完整，无法确定具体导致了什么样的bug症状。,baichuan无法推理对话,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. ``` Traceback (most recent call last):   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/threading.py"", line 973, in _bootstrap_inner     self.run()   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/threading.py"", line 910, in run     self._target(*self._args, **self._kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/utils/_contextlib.py"", line 117, in decorate_context     return func(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py"", line 2024, in generate     result = self._sample(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py"", line 3029, in _sample     model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1858, in prepare_inputs_for_generation     position_ids = position_ids.masked_fill(attention_mask == 0, 1)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 2682, in masked_fill     value = tensor_operator_registry.get(""scalar_to_tensor"")(value, self.dtype)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 99, in dtype     self.stub_dtype = self.stub.get_dtype() TypeError: For primitive[CumSum], the input argument[x] must be a type of {Tensor[Float16], Tensor[Float32], Tensor[Float64], Tensor[Int32], Tensor[Int8], Tensor[UInt8]}, but got Tensor[Int64].   C++ Call Stack: (For framework developers)  mindspore/core/utils/check_convert_utils.cc:1031 CheckTensorSubClass ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  mindnlp是今日最新源码  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1  Python version (e.g., Python 3.7.5) :Python 3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04): 4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch6  GCC/Compiler version (if compiled from source): 7.3.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 代码: ``` import mindspore as ms from mindnlp.transformers import BaiChuanForCausalLM, BaiChuanTokenizer from mindnlp.transformers.generation.utils import GenerationConfig  ms.set_context(pynative_synchronize=True) model = BaiChuanForCausalLM.from_pretrained(""baichuaninc/Baichuan13BChat"",mirror='modelscope',ms_dtype=ms.float16, size='13b').eval() tokenizer = BaiChuanTokenizer.from_pretrained(""baichuaninc/Baichuan13BChat"",mirror='modelscope') model.generation_config = GenerationConfig.from_pretrained(""baichuaninc/Baichuan13BChat"") messages = [] messages.append({""role"": ""user"", ""content"": ""北京有啥好玩的地方？""}) response = model.chat(tokenizer, messages) print(response) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 能够推理。 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** **Additional context / 备注 (Optional / 选填)** 我尝试修改后： 即将https://github.com/mindsporelab/mindnlp/blob/ef64a3b83097c9578bb0d5326f905beeb5b50e1d/mindnlp/transformers/models/baichuan/modeling_baichuan.pyL1857 的`long`修改成`int` 然后就变了新的错误： ``` Exception in thread Thread7: Traceback (most recent call last):   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/threading.py"", line 973, in _bootstrap_inner     self.run()   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/threading.py"", line 910, in run     self._target(*self._args, **self._kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/utils/_contextlib.py"", line 117, in decorate_context     return func(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py"", line 2024, in generate     result = self._sample(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py"", line 3036, in _sample     outputs = self(**model_inputs, return_dict=True)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1787, in forward     outputs = self.model(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1560, in forward     bsz = inputs_embeds.size(0) TypeError: 'int' object is not callable ``` 就不会改了。",2024-11-24T13:46:01Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1843
这是一个bug报告，主要涉及优化器参数在GPU上的数据类型不一致导致的问题。,fix optimizer args as same dtype on GPU,,2024-11-23T15:15:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1842
这个issue类型是bug报告，主要涉及mindnlp.transformers.optimization，原因可能是该模块已被弃用导致问题的出现。,deprecated mindnlp.transformers.optimization,,2024-11-23T14:36:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1841
这个issue属于bug报告类型，涉及的主要对象是mindnlp库中的roll算法。由于在CPU上运行时出现问题，导致需要修复。,fix roll on CPU,,2024-11-23T13:53:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1840
该issue属于用户提出需求类型，主要涉及的对象是TAPAS模型。,【开源实习】TAPAS模型应用开发,,2024-11-23T10:59:29Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1839,验收通过，可以合入
这是一个bug报告，主要涉及的对象是mindnlp中的modeling_blip模块，问题是由于未指定dtype导致ops.full底层调用mint.ones返回float32而不是int64。,修复blip推理报错,modeling_blip的 ops.full 底层调用mint.ones在不指定dtype时默认返回float32，将dtype指定为int64,2024-11-23T09:52:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1838
这是关于bug报告的一个issue，涉及到输入数据类型问题导致的TypeError。,"TypeError: Data type of 4th item of the input or its converted Numpy array is expected to be int or float or str, but got object.","**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. dataset = load_dataset(""FrancophonIA/XFUND"", ""French"") 我load_dataset 后 想用for 迭代看一下dataset 但是报错了 TypeError: Data type of 4th item of the input or its converted Numpy array is expected to be int or float or str, but got object.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片 Ascend910  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 2.3.1.Bxxx) :Mindspore 2.3.1  Python version (e.g., Python 3.9.0) : python 3.9.0  OS platform and distribution (e.g., Linux Ubuntu 16.04):EulerOS 2.0  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: from mindnlp.dataset import load_dataset dataset = load_dataset(""FrancophonIA/XFUND"", ""French"") for d in dataset:   print(d) **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 打印相关的内容 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !图片 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here. 无",2024-11-23T09:14:10Z,bug,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1837,"在华为云ModelArts上使用mindspore2.3.0镜像，从pip安装mindnlp，版本信息： Version: 0.4.0 Summary: An open source natural language processing research tool box. Git version: [sha1]:5b4dad33, [branch]: (HEAD > master, ms/master) 运行上述代码没有报错。 "
这是一个bug报告，主要对象是Qwen2模型，用户在使用Qwen27BInstruct模型进行基本推理测试时发现结果有误。,Qwen2模型推理结果有误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在使用Qwen27BInstruct这个模型做基本的推理测试时，在输入完全相同的情况下，出现结果和torch完全不一致的问题。 测试代码： ``` from typing import List, Dict, Tuple import argparse import mindspore as ms from mindspore import context from mindnlp.peft import PeftModel, PeftConfig from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer import datasets context.set_context(device_target=""Ascend"")  context.set_context(device_id=1) prompt_system = ""system\n{}\n"" prompt_user = ""user\n{}\nassistant\n"" prompt_assistant = ""{}\n"" def get_args():     parser = argparse.ArgumentParser()     parser.add_argument(         ""model_name_or_path"",         type=str,         default=""Qwen/Qwen27BInstruct"",   Qwen/Qwen2.53B     )     parser.add_argument(""inf_max_length"", type=int, default=128)     return parser.parse_args() def inference(args):     tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path, mirror=""modelscope"", revision=""master"")     model = AutoModelForCausalLM.from_pretrained(         args.model_name_or_path, mirror=""modelscope"", revision=""master"", ms_dtype=ms.float16     )     model.set_train(False)     model.jit()     messages = [         {""role"": ""system"", ""content"": ""You are a helpful assistant.""}     ]     with ms._no_grad():         while True:             inputs = input(""Q: "")             if inputs in (""exit"", ""Exit"", ""quit"", ""Quit"", ""e"", ""q""):                 break             messages.append(                 {""role"": ""user"", ""content"": inputs},             )             prompt = tokenizer.apply_chat_template(                 messages,                 tokenize=False,                 add_generation_prompt=True,             )             model_inputs = tokenizer([prompt], return_tensors=""ms"")             print(f""{model_inputs}"")             outputs = model.generate(**model_inputs, max_new_tokens=args.inf_max_length)             outputs = [                 output_ids[len(input_ids) :]                 for input_ids, output_ids in zip(model_inputs[""input_ids""], outputs)             ]              print(outputs)             text_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]             print(f""A: {text_output}"")             messages.append({""role"": ""assistant"", ""content"": text_output}) if __name__ == ""__main__"":     args = get_args()     inference(args) ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):   GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 下载原模型参数 2. 运行测试代码 3. 输出结果 **Expected behavior / 预期结果 (Mandatory / 必填)** 正常输出，与torch版输出相近 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** ``` (MindSpore) [mauser huaweiict2024]$python inference.py  /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 1.319 seconds. Prefix dict has been built successfully. Qwen2ForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.    If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).    If you are not the owner of the model architecture class, please contact the model code owner to update it. Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered. [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB Loading checkpoint shards: 100% 4/4 [03:39system\nYou are a helpful assistant.\nuser\n你是谁？\nassistant\n', 'prompt: system\nYou are a helpful assistant.\nuser\n你是谁？\nassistant\n') {'input_ids': Tensor(shape=[1, 22], dtype=Int64, value= [[151644,   8948,    198 ... 151644,  77091,    198]]), 'attention_mask': Tensor(shape=[1, 22], dtype=Int64, value= [[1, 1, 1 ... 1, 1, 1]])} A: ![](![](https!://s3.cnnorth1.amazonaws.com/c![](https!://s3.cnnorth1.amazonaws.com!/[object%20Image!].png![](https!://s3!//cdn.cnbj1.fds.api.mi!//cdn.cnb!//cdn.cnb!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//! Q: 今天星期几？ ('text: system\nYou are a helpful assistant.\nuser\n你是谁？\nassistant\n![](![](https!://s3.cnnorth1.amazonaws.com/c![](https!://s3.cnnorth1.amazonaws.com!/[object%20Image!].png![](https!://s3!//cdn.cnbj1.fds.api.mi!//cdn.cnb!//cdn.cnb!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//!\nuser\n今天星期几？\nassistant\n', 'prompt: system\nYou are a helpful assistant.\nuser\n你是谁？\nassistant\n![](![](https!://s3.cnnorth1.amazonaws.com/c![](https!://s3.cnnorth1.amazonaws.com!/[object%20Image!].png![](https!://s3!//cdn.cnbj1.fds.api.mi!//cdn.cnb!//cdn.cnb!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//![](!//!\nuser\n今天星期几？\nassistant\n') {'input_ids': Tensor(shape=[1, 149], dtype=Int64, value= [[151644,   8948,    198 ... 151644,  77091,    198]]), 'attention_mask': Tensor(shape=[1, 149], dtype=Int64, value= [[1, 1, 1 ... 1, 1, 1]])} A: ![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![](![]( ``` **Additional context / 备注 (Optional / 选填)**",2024-11-23T06:38:11Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1836,"  使用同样的prompt(""write a quick sort algorithm in python"")分别进行三次推理结果区别不大，我使用的是python3.10+mindspore2.4+mindnlp(源码安装，commit_id:ef64a3b83097c9578bb0d5326f905beeb5b50e1d)  python3.11+torch2.5.1+transformers4.46.3", 测了下你上面的例子，也没问题，建议重新装一下最新的mindnlp，或者重新下载模型权重看是否可以解决？
这是一则关于在value_and_grad函数中支持kwargs的功能需求，涉及主要对象为mindnlp库。由于当前的value_and_grad函数无法处理关键字参数kwargs，因此导致用户提出了这项功能改进请求。,value_and_grad support kwargs,,2024-11-22T10:00:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1835
这是一个缺少内容的issue，类型为用户提出需求。它主要涉及mindnlp的更新和分配。,fix update_and_allocate,,2024-11-22T09:26:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1834
这个issue类型是bug报告，主要涉及的对象是value_and_grad函数和model/optimizer的zero_grad功能，由于缺少对attacach grads和accumulate参数的支持，导致出现了相关的bug。,"value_and_grad support attacach grads, Parameter support accumulate a…",…nd model/optimizer support zero_grad,2024-11-22T09:02:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1833
这是一个bug报告，主要涉及到低CPU内存使用率的修复，可能是由于内存管理错误导致的bug。,fix low_cpu_mem_usage(contguous),,2024-11-22T06:47:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1832
该issue为用户提出需求，主要涉及Module的H2D move支持。这个问题可能是由于用户希望在MindNLP中实现模块间的数据传输而提出的。,Module support H2D move,,2024-11-21T13:48:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1831
这个issue类型是用户提出需求，主要涉及的对象是image_classification_timm_peft_lora模型微调，用户寻求关于如何微调该模型的帮助。,image_classification_timm_peft_lora模型微调,,2024-11-20T08:06:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1830
这是一个bug报告，涉及的主要对象是LongformerForSequenceClassification模型训练速度慢，可能是由于某种原因导致的。, LongformerForSequenceClassification训练速度慢,"**Describe the bug/ 问题描述 (Mandatory / 必填)**  BertForSequenceClassification只要5分钟可以跑完一个epoch的数据集，LongformerForSequenceClassification预计要几十个小时。可以观察到NPU的HBM有占用，但是AIcore几乎没有占用。 两份代码区别只是定义tokenizer和from_pretrained的两行。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: ascend910b  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.3.1  Python version 3.9.20   mindnlp version 0.4.0  OS platform and distribution (e.g., Linux Ubuntu 16.04): ky10.aarch64 因为代码在内网环境很难弄出来，正在尝试用启智平台复现。",2024-11-19T07:32:35Z,bug ascend,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1829,longformer涉及到循环，在Ascend上目前确实非常慢
这是一个bug报告，主要涉及使用AdamW优化器配置分组参数后训练时出现数值错误的问题，可能是由于配置不当或参数设置错误导致的。,AdamW优化器配置分组参数报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 使用AdamW优化器配置分组参数后进行训练，报错： > ValueError: For primitive[Adam], the var_shape: [1024,1024,] must be equal to [50265,1024,] ``` head_param = list(map(id, model.classifier.parameters())) others_param = filter(lambda p: id(p) not in head_param, model.parameters())   报错，于PyTorch可正常运行 optimizer = AdamW([     {""params"": model.classifier.parameters(), ""lr"": head_lr},     {""params"": others_param, ""lr"": fft_lr} ],weight_decay=0.)  optimizer = AdamW(params=model.parameters(), lr=fft_lr)  可正常运行  Instantiate scheduler lr_scheduler = get_linear_schedule_with_warmup(     optimizer=optimizer,     num_warmup_steps=0.06 * (len(train_dataset) * num_epochs),     num_training_steps=(len(train_dataset) * num_epochs), ) ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend/CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version: 2.4.0  Python version: Python 3.9.19  OS platform and distribution: Windows 11  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 以ia3模型为例： 1. 打开 'llm\peft\ia3\sequence_classification.ipynb' 2. 修改优化器的配置代码： 将原代码： ``` optimizer = AdamW(params=model.parameters(), lr=lr) ``` 修改为： ``` head_param = list(map(id, model.classifier.parameters())) others_param = filter(lambda p: id(p) not in head_param, model.parameters())  head_lr = 6e3  fft_lr = 6e2    optimizer = AdamW([     {""params"": model.classifier.parameters(), ""lr"": head_lr},     {""params"": others_param, ""lr"": fft_lr} ],weight_decay=0.) ``` 3. 运行代码进行训练 4. 在训练过程中报错 !image **Expected behavior / 预期结果 (Mandatory / 必填)** 模型能够正常训练 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !bebdcfb9acd2f0b27a5dda837fbb8f58 !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-19T04:53:33Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1828,"使用最新包解决： ```python from mindnlp.core import value_and_grad grad_fn = value_and_grad(forward_fn, model.parameters()) for data in dataset:     optimizer.zero_grad()     loss = grad_fn(**data)     optimizer.step() ```"
这是一个bug报告，用户在尝试运行mindnlpv0.3.0的Quick start代码时遇到了错误问题。,mindnlpv0.3.0 跑官方的Quick start代码，出现这个错误是怎么回事,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. mindnlpv0.3.0官方Quick start代码，出现这个错误是怎么回事  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > device ascend910A芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.0  Python version (e.g., Python 3.7.5) : Python 3.9.18  OS platform and distribution (e.g., Linux Ubuntu 16.04): EulerOS 2.0 (SP8)  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 按照quick start代码执行： import mindspore as ms num_epochs = 3 best_valid_loss = float('inf') for epoch in range(num_epochs):     train_one_epoch(model, small_dataset_train, epoch)     valid_loss = evaluate_fn(model, small_dataset_val, loss_fn, epoch)     if valid_loss < best_valid_loss:         best_valid_loss = valid_loss         ms.save_checkpoint(model, '../../sentiment_analysis.ckpt') **Expected behavior / 预期结果 (Mandatory / 必填)** 出现报错 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-19T03:14:25Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1827,"不要使用2.2.0，2.2版本用2.2.14, 2.3版本用2.3.1",Ascend最低用2.3版本
这是一个Bug报告，主要涉及的对象是任务标识符（task_ids），由于缺少任务标识符导致数值错误（ValueError）。,ValueError: task_ids should not be None.,"**Describe the bug/ 问题描述 (Mandatory / 必填)** ValueError: task_ids should not be None.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** Traceback (most recent call last):   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/runpy.py"", line 197, in _run_module_as_main     return _run_code(code, main_globals, None,   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/runpy.py"", line 87, in _run_code     exec(code, run_globals)   File ""/home/mauser/work/.vscodeserver/c768c7a734b34b858837d8c71c523932/extensions/mspython.python2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in      cli.main()   File ""/home/mauser/work/.vscodeserver/c768c7a734b34b858837d8c71c523932/extensions/mspython.python2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 430, in main     run()   File ""/home/mauser/work/.vscodeserver/c768c7a734b34b858837d8c71c523932/extensions/mspython.python2023.8.0/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file     runpy.run_path(target, run_name=""__main__"")   File ""/home/mauser/work/.vscodeserver/c768c7a734b34b858837d8c71c523932/extensions/mspython.python2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path     return _run_module_code(code, init_globals, run_name,   File ""/home/mauser/work/.vscodeserver/c768c7a734b34b858837d8c71c523932/extensions/mspython.python2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code     _run_code(code, mod_globals, init_globals,   File ""/home/mauser/work/.vscodeserver/c768c7a734b34b858837d8c71c523932/extensions/mspython.python2023.8.0/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code     exec(code, run_globals)   File ""/home/mauser/work/peftmain/examples/poly/polymindspore.py"", line 317, in      trainer.train()   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 755, in train     return inner_training_loop(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1107, in _inner_training_loop     tr_loss_step, grads = self.training_step(model, inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1382, in training_step     loss, grads = self.grad_fn(inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 642, in after_grad     return grad_(fn_, weights)(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py"", line 188, in wrapper     results = fn(*arg, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 617, in after_grad     run_args, res = self._pynative_forward_run(fn, grad_, weights, *args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 674, in _pynative_forward_run     outputs = fn(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1374, in forward     return self.compute_loss(model, inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1396, in compute_loss     outputs = model(**inputs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 762, in forward     return self.base_model(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly/model.py"", line 194, in forward     return self.model(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 1198, in forward     encoder_outputs = self.encoder(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 844, in forward     layer_outputs = layer_module(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 495, in forward     self_attention_outputs = self.layer0   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 402, in forward     attention_output = self.SelfAttention(   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/t5/modeling_t5.py"", line 319, in forward     query_states = shape(self.q(hidden_states))   (batch_size, n_heads, seq_length, dim_per_head)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly/layer.py"", line 154, in forward     mixing_weights = poly_router(task_ids=task_ids, input_ids=x)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 405, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly/router.py"", line 66, in forward     raise ValueError(""task_ids should not be None."") ValueError: task_ids should not be None. **Additional context / 备注 (Optional / 选填)** 这里有看到将task_ids赋值为了None，但是我尝试将task_ids=task_ids时有出现说没有这个参数 因此我尝试在 !923756041e2397176bed973e6e8da299 内添加了task_ids参数，运行后没有报错ValueError但是出现了新的报错，因此不确定是否正确。",2024-11-19T02:59:54Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1826,把代码发出来我看看重现一下，只有报错不知道你怎么调用的,好的麻烦了 以下是我的尝试的代码文件： poly_mindspore.zip 以下是运行时报错ValueError: task_ids should not be None.的截图： !b19eb5c84459268cc86170d94c222eca
这是一个bug报告类型的issue，主要涉及对象是'T5ForConditionalGeneration'对象，由于缺少'cells'属性导致了AttributeError。,AttributeError: 'T5ForConditionalGeneration' object has no attribute 'cells',"**Describe the bug/ 问题描述 (Mandatory / 必填)** AttributeError: 'T5ForConditionalGeneration' object has no attribute 'cells'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :Python3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** File "" /home/mauser/anaconda3/envs/mindspore/lib/python3.9/sitepackages/mindnlp/peft/tuners/poly/model.py"", line 17, in register pre hooksfor cell in self.model.cells():File ""/home/mauser/anaconda3/envs/Mindspore/l ib/python3.9/sitepackages mindnlp/core/nn/modules/module.py"", line 566, in  getattrraise AttributeError(f""'{type(self). nameI' object has no attribute ""fnamel'"") !75308f4737db867bd4be3236d3c6411b **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-19T02:53:25Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1825,poly_mindspore.zip,!9476256055659e6173379332d5c79f3e !02ba918d676d78810ecac64e66ed17d6,fixed
"这是一个bug报告，主要涉及的对象是示例程序""modeling_TAPAS.py""。这个问题出现的原因是在推理过程中维度不匹配导致了错误。",modeling_TAPAS.py,示例程序导入的仍是transformers库，程序推理时存在维度不匹配的问题。 !image,2024-11-19T02:37:49Z,bug,open,0,3,https://github.com/mindspore-lab/mindnlp/issues/1824,请按照模板填写版本号、具体的硬件,version：0.4.1 硬件：x86 cpu,哪一段示例程序？
这是一则关于bug报告的issue，主要涉及到使用trainer.train()方法时出现KeyError: 'eval_loss'错误，可能是由于数据或参数配置问题导致的。,用trainer.train()的时候报错：KeyError: 'eval_loss',"**Describe the bug/ 问题描述 (Mandatory / 必填)** 用trainer.train()的时候报错：KeyError: 'eval_loss'，但pytorch代码没有报错。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): MindSpore:2.3.1 mindnlp:0.4.1  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: graph **To Reproduce / 重现步骤 (Mandatory / 必填)** ``` from mindnlp.engine import Trainer, TrainingArguments training_args = TrainingArguments(   output_dir=""./vitbasefood101"",   per_device_train_batch_size=16,   evaluation_strategy=""steps"",   num_train_epochs=4,   fp16=True,   save_steps=100,   eval_steps=100,   logging_steps=10,   learning_rate=2e4,   save_total_limit=2,   remove_unused_columns=True,   load_best_model_at_end=True, ) import numpy as np import evaluate metric = evaluate.load(""accuracy"")  the compute_metrics function takes a Named Tuple as input:  predictions, which are the logits of the model as Numpy arrays,  and label_ids, which are the groundtruth labels as Numpy arrays. def compute_metrics(eval_pred):     """"""Computes accuracy on a batch of predictions""""""     predictions = np.argmax(eval_pred.predictions, axis=1)     return metric.compute(predictions=predictions, references=eval_pred.label_ids) trainer = Trainer(     model=lora_model,     args=training_args,     compute_metrics=compute_metrics,     train_dataset=train_ds,     eval_dataset=val_ds,     tokenizer=image_processor, ) ``` 然后运行train_results = trainer.train()时报错。 **Expected behavior / 预期结果 (Mandatory / 必填)** 训练结束，但只训练到epoch0.36 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-16T01:34:41Z,bug,open,0,3,https://github.com/mindspore-lab/mindnlp/issues/1823,完整代码附件传一下,111601.zip老师我改了一下load_best_model_at_end=False就能跑通了，现在没有eval_accuracy，在想办法解决。,> 111601.zip老师我改了一下load_best_model_at_end=False就能跑通了，现在没有eval_accuracy，在想办法解决。 您好，我遇到了相同的问题，eval的metrics不包含loss，请问您是如何解决的
这是一个bug报告，涉及对象为将dataloader换成torch里面的dataloader后出现的问题。原因导致出现问题是代码更改不完整。,MarkupLM模型训练问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 将dataloader换成torch里面的dataloader后，更改里面的张量为ms格式，输入MarkupLM模型训练，前向传播输出依然有问题  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:    MindSpore version  : 2.4.0    Python version : 3.9.20 **To Reproduce / 重现步骤 (Mandatory / 必填)** 运行训练代码，训练markuplmbase模型，则会发现前向传播输出有问题 **Expected behavior / 预期结果 (Mandatory / 必填)** 输出正常 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** ```py import mindspore as ms import numpy as np for batch in dataloader:     for item in batch:         batch[item]= batch[item].numpy()         batch[item]=ms.from_numpy(batch[item])      print(batch)     inputs = {k:v for k,v in batch.items()}      print(inputs)     outputs = model(**inputs)     print(outputs) ``` 输出： ```bash TokenClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= nan), logits=Tensor(shape=[2, 512, 4], dtype=Float32, value= [[[      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   ...   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)]],  [[      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   ...   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)]]]), hidden_states=None, attentions=None) TokenClassifierOutput(loss=Tensor(shape=[], dtype=Float32, value= nan), logits=Tensor(shape=[2, 512, 4], dtype=Float32, value= [[[      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   ...   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)]],  [[      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)], ...   ...   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)],   [      nan(ind),       nan(ind),       nan(ind),       nan(ind)]]]), hidden_states=None, attentions=None) ``` **Additional context / 备注 (Optional / 选填)** mindspore有问题的代码和输出正常，用来对照的pytorch代码如下： mindspore代码:  mindspore.md torch代码： torch.md",2024-11-15T13:27:05Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1822
这是一个bug报告类型的issue，主要涉及minicpm未注册的问题。由于minicpm未注册，导致了无法正常使用相关功能的bug。,fix:解决minicpm未注册问题,,2024-11-15T13:06:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1821
这是一个bug报告，主要涉及mindnlp-0.4.1加载模型时出现的数据类型不支持的问题。,微调任务 使用mindnlp-0.4.1加载模型报错 数据类型不支持,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 使用mindnlp0.4.1加载模型报错 ``` RuntimeError: Unsupported data type!   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pybind_api/ir/tensor_py.cc:361 MakeTensorOfNumpy ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片 Ascend: 1*ascendsnt9b1|ARM: 24核 192GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): Python 3.9.10 mindspore 2.3.1 mindnlp 0.4.1  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph PyNative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error ``` !export HF_ENDPOINT=http://hf.co import os import mindspore from mindnlp.transformers import AutoModelForSeq2SeqLM, AutoTokenizer from mindnlp.peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PromptTuningConfig, TaskType from mindnlp.dataset import load_dataset, BaseMapFunction from mindspore.dataset import GeneratorDataset from mindnlp.core import ops, optim import numpy as np from threading import Lock from mindnlp.transformers.optimization import get_linear_schedule_with_warmup from tqdm import tqdm from mindnlp.peft.tuners.prompt_tuning.config import PromptTuningInit os.environ[""TOKENIZERS_PARALLELISM""] = ""false"" os.environ['HF_ENDPOINT'] = 'http://hfmirror.com' if ""RANK_TABLE_FILE"" in os.environ:     del os.environ[""RANK_TABLE_FILE""]  model_name_or_path = ""t5large""  tokenizer_name_or_path = ""t5large"" model_name_or_path = ""googlet5/t5large"" tokenizer_name_or_path = ""googlet5/t5large"" checkpoint_name = ""financial_sentiment_analysis_prompt_tuning_v1.ckpt"" text_column = ""sentence"" label_column = ""text_label"" max_length = 128 lr = 1e3 num_epochs = 8 batch_size = 8 ``` ```  creating model peft_config = PromptTuningConfig(     task_type=TaskType.SEQ_2_SEQ_LM,     prompt_tuning_init=PromptTuningInit.TEXT,     num_virtual_tokens=20,     prompt_tuning_init_text=""What is the sentiment of this article?\n"",     inference_mode=False,     tokenizer_name_or_path=model_name_or_path, ) model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path) model = get_peft_model(model, peft_config) model.print_trainable_parameters() ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. torch输出结果 ``` PeftModelForSeq2SeqLM(   (base_model): T5ForConditionalGeneration(     (shared): Embedding(32128, 1024)     (encoder): T5Stack(       (embed_tokens): Embedding(32128, 1024)       (block): ModuleList(         (0): T5Block(           (layer): ModuleList(             (0): T5LayerSelfAttention(               (SelfAttention): T5Attention(                 (q): Linear(in_features=1024, out_features=1024, bias=False)                 (k): Linear(in_features=1024, out_features=1024, bias=False)                 (v): Linear(in_features=1024, out_features=1024, bias=False)                 (o): Linear(in_features=1024, out_features=1024, bias=False)                 (relative_attention_bias): Embedding(32, 16)               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )             (1): T5LayerFF(               (DenseReluDense): T5DenseActDense(                 (wi): Linear(in_features=1024, out_features=4096, bias=False)                 (wo): Linear(in_features=4096, out_features=1024, bias=False)                 (dropout): Dropout(p=0.1, inplace=False)                 (act): ReLU()               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )           )         )         (123): 23 x T5Block(           (layer): ModuleList(             (0): T5LayerSelfAttention(               (SelfAttention): T5Attention(                 (q): Linear(in_features=1024, out_features=1024, bias=False)                 (k): Linear(in_features=1024, out_features=1024, bias=False)                 (v): Linear(in_features=1024, out_features=1024, bias=False)                 (o): Linear(in_features=1024, out_features=1024, bias=False)               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )             (1): T5LayerFF(               (DenseReluDense): T5DenseActDense(                 (wi): Linear(in_features=1024, out_features=4096, bias=False)                 (wo): Linear(in_features=4096, out_features=1024, bias=False)                 (dropout): Dropout(p=0.1, inplace=False)                 (act): ReLU()               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )           )         )       )       (final_layer_norm): T5LayerNorm()       (dropout): Dropout(p=0.1, inplace=False)     )     (decoder): T5Stack(       (embed_tokens): Embedding(32128, 1024)       (block): ModuleList(         (0): T5Block(           (layer): ModuleList(             (0): T5LayerSelfAttention(               (SelfAttention): T5Attention(                 (q): Linear(in_features=1024, out_features=1024, bias=False)                 (k): Linear(in_features=1024, out_features=1024, bias=False)                 (v): Linear(in_features=1024, out_features=1024, bias=False)                 (o): Linear(in_features=1024, out_features=1024, bias=False)                 (relative_attention_bias): Embedding(32, 16)               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )             (1): T5LayerCrossAttention(               (EncDecAttention): T5Attention(                 (q): Linear(in_features=1024, out_features=1024, bias=False)                 (k): Linear(in_features=1024, out_features=1024, bias=False)                 (v): Linear(in_features=1024, out_features=1024, bias=False)                 (o): Linear(in_features=1024, out_features=1024, bias=False)               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )             (2): T5LayerFF(               (DenseReluDense): T5DenseActDense(                 (wi): Linear(in_features=1024, out_features=4096, bias=False)                 (wo): Linear(in_features=4096, out_features=1024, bias=False)                 (dropout): Dropout(p=0.1, inplace=False)                 (act): ReLU()               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )           )         )         (123): 23 x T5Block(           (layer): ModuleList(             (0): T5LayerSelfAttention(               (SelfAttention): T5Attention(                 (q): Linear(in_features=1024, out_features=1024, bias=False)                 (k): Linear(in_features=1024, out_features=1024, bias=False)                 (v): Linear(in_features=1024, out_features=1024, bias=False)                 (o): Linear(in_features=1024, out_features=1024, bias=False)               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )             (1): T5LayerCrossAttention(               (EncDecAttention): T5Attention(                 (q): Linear(in_features=1024, out_features=1024, bias=False)                 (k): Linear(in_features=1024, out_features=1024, bias=False)                 (v): Linear(in_features=1024, out_features=1024, bias=False)                 (o): Linear(in_features=1024, out_features=1024, bias=False)               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )             (2): T5LayerFF(               (DenseReluDense): T5DenseActDense(                 (wi): Linear(in_features=1024, out_features=4096, bias=False)                 (wo): Linear(in_features=4096, out_features=1024, bias=False)                 (dropout): Dropout(p=0.1, inplace=False)                 (act): ReLU()               )               (layer_norm): T5LayerNorm()               (dropout): Dropout(p=0.1, inplace=False)             )           )         )       )       (final_layer_norm): T5LayerNorm()       (dropout): Dropout(p=0.1, inplace=False)     )     (lm_head): Linear(in_features=1024, out_features=32128, bias=False)   )   (prompt_encoder): ModuleDict(     (default): PromptEmbedding(       (embedding): Embedding(40, 1024)     )   )   (word_embeddings): Embedding(32128, 1024) ) ``` **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-15T12:48:50Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1820
这个issue属于用户提出需求类型，主要涉及对象是将baichuan2模型迁移。原因是用户需要进行迁移操作。,baichuan2模型迁移,**Is your feature request related to a problem? Please describe.** 需要迁移baichuan2模型 **Describe the solution you'd like** **Describe alternatives you've considered** **Additional context**,2024-11-15T11:34:06Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1819
这是一个bug报告，涉及到mindnlp.engine.trainer中的_inner_training_loop的问题，由于步训练速度线性变慢导致无法完成正常的epoch。,利用mindnlp.engine.trainer中的_inner_training_loop来实现模型迁移的过程中step训练速度线性变慢导致无法跑完正常的epoch," **1. Describe the bug/ 问题描述 (Mandatory / 必填)** 利用mindnlp.engine.trainer中的_inner_training_loop来实现代码迁移vec2text的过程中step训练速度线性变慢导致无法跑完正常的epoch，从而得到满意的迁移结果  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: RTX 3090  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): MindSpore2.2.14 mindnlp0.4.0   **2. Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: PyNative（当然这个是无关的，因为我也试过默认的Graph模式，照样没用）  **3. To Reproduce / 重现步骤 (Mandatory / 必填)** 0. 我的训练输入inputs是mindspore中的generatordataset，然后连同model输入到本地的继承mindnlp.engine.Trainer的basetrainer中 1. 利用mindnlp.engine.Trainer中的_inner_training_loop()方法实现训练过程，这也是我采用的。 2. 然后每个批次在training_step()中进行计算loss和grad 3. 最后_inner_training_loop中进行计算累积梯度？  **4. Expected behavior / 预期结果 (Mandatory / 必填)** 解决这个bug，能每个step训练速度都一样，完成迁移任务  **5. Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.  如下是初始训练的time/step,大概2，3s一个step，速度还可以： !image  这是训到500次，可以看出很慢了, 而且未来还会更慢： !image  我使用单卡卡1进行训练，可以看到训练后期利用率1%，一个step的速度也很慢 !image  **6. Additional context / 备注 (Optional / 选填)**  因为Trainer对标的是hf的transformer库，所以根据transformer中的写法，以及线性变慢的现象，初步可能的猜测是： 1.可以看到，原transformer代码的training_step中有del inputs操作和清空缓存操作，mindnlp.engine.Trainer中没有？ https://github.com/huggingface/transformers/blob/a3d69a8994d673899608a7c17fbf4f953f50474e/src/transformers/trainer.pyL3615C1L3631C41 2.计算图没有清理的问题吗？因为在_inner_training_loop中要计算累积梯度，所以mindspore框架下反向传播得到grad之后计算图也没清理，导致计算图越来越大，从而可能影响each step time?  希望能得到本仓库开发者的帮助，非常感谢！",2024-11-14T17:59:52Z,bug,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1818,应该不是第二个原因，图肯定得留着否则没法计算反向，第一个我看看,> 应该不是第二个原因，图肯定得留着否则没法计算反向，第一个我看看 https://github.com/mindsporelab/mindnlp/issues/1793issue2624276820 我看1793是跟我的情况一样，不知道他换成Ascend之后解决了没有, 我换Ascend之后就没有这个问题了。,>  我换Ascend之后就没有这个问题了。  非常感谢！那我申请个代金券重新跑一下试试
"这是一个bug报告类型的issue，主要涉及的对象是mindnlp模块下的""ModuleNotFoundError: No module named 'mindnlp.injection'""错误。原因可能是代码中引用了不存在的模块导致了报错。",ModuleNotFoundError: No module named 'mindnlp.injection',"请问这个是什么问题？ python GPT_SOVITS/inference_webui.py Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.553 seconds. Prefix dict has been built successfully. Traceback (most recent call last): File ""/home/jiang/project/GPTSoVITSmindspore/GPT_SOVITS/inference_webui.py"" line 58, in  from mindnlp.injection import set_global_fp16 ModuleNotFoundError: No module named 'mindnlp.injection'",2024-11-13T14:53:15Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1817,请使用mindnlp 0.3版本
这是一个bug报告，主要涉及的对象是使用XLMRobertaModel族模型bge-reranker-base时出现输出全为nan的问题，导致的原因需要进一步分析。,在使用XLMRobertaModel族模型bge-reranker-base出现输出全为nan,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在使用XLMRobertaModel族模型bgererankerbase出现输出全为nan，具体来说，bgererankerbase在前向传播第12层过attention层的时候出现了一个nan导致后续的值全部为nan，同样使用XLMRobertaModel的embedding模型也同样有这个错误。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):Windows  GCC/Compiler version (if compiled from source): **To Reproduce / 重现步骤 (Mandatory / 必填)** sentence中字符串的长度大于20就出现上述错误 ```python from mindnlp.sentence import SentenceTransformer model = SentenceTransformer('BAAI/bgererankerbase') sentences = [     '远程仓库，可以使用gitpush命令。通常，这个命令后面会跟远程仓库的名称和要推送的分支名称。\nbash\ngitpush\n例如，将本地的master分支推送到origin远程仓库：\nbash\ngitpushoriginmaster\n从远程仓库拉取\n从远程仓库获取最新的更改并合并到本地分支，可以使用gitpull命令。这个命令会将远程仓库的指定分支的更改拉取到当前分支。bash\ngitpull\n例如，从origin远程仓库的master分支拉取最新更改：\nbash\ngitpulloriginmaster\n远程分支管理\n查看远程分支，可以使用gitbranch命令加上r选项。\nbash\ngitbranchr\n删除远程分支，可以使用gitpush命令加上delete选项。\nbash\ngitpushdelete\n例如，删除origin远程仓库的feature分支：\nbash\ngitpushorigindeletefeature\n远程仓库的协作与贡献\n协作和贡献通常涉及以下步骤：\n\nFork远程仓库。\nCloneFork后的仓库到本地。\n创建新的分支进行开发。\n完成开发后，将分支推送到自己的Fork仓库。\n']  2. Calculate embeddings by calling model.encode() embeddings = model.encode(sentences) print(embeddings) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 正确输出 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !9e9ce04099aa547e3db1afdfb5005ce6 !efc60b20ef6a65afbd77341f9a9f6f1d **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-13T11:44:32Z,bug,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1816,CPU算子bug
这是一个bug报告，主要涉及SentenceTransformer加载模型的错误警告和输出精度问题，可能由于模型加载问题导致。,SentenceTransformer加载模型的错误警告和输出精度问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在使用SentenceTransformer时，正确下载并加载了模型，仍然弹出警告：No sentencetransformers model found with name BAAI/bgelargezhv1.5. Creating a new one with MEAN pooling 与PyTorch相比输出差别有点大  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: ascend和CPU都存在这个问题  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version: 2.4.0和2.3.1  Python version: 3.10  OS platform and distribution: Linux和Windows **To Reproduce / 重现步骤 (Mandatory / 必填)** ```python from mindnlp.sentence import SentenceTransformer model = SentenceTransformer('BAAI/bgelargezhv1.5') sentences_1 = ""The weather is lovely today."" sentences_2 = ""It's so sunny outside!"" embeddings_1 = model.encode(sentences_1, normalize_embeddings=True) embeddings_2 = model.encode(sentences_2, normalize_embeddings=True) similarity = embeddings_1 @ embeddings_2.T print(similarity) ``` ```python from sentence_transformers import SentenceTransformer model = SentenceTransformer('BAAI/bgelargezhv1.5') sentences_1 = ""The weather is lovely today."" sentences_2 = ""It's so sunny outside!"" embeddings_1 = model.encode(sentences_1, normalize_embeddings=True) embeddings_2 = model.encode(sentences_2, normalize_embeddings=True) similarity = embeddings_1 @ embeddings_2.T print(similarity) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !97d0d0b6565a5fff0751a9c25519bafe **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-13T11:38:35Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1815,fixed
这个issue属于bug报告类型，主要对象是Mindnlp软件中的sync parallel模块。由于该模块在使用过程中导致低CPU和内存的使用率，用户提出需要修复这一问题。,fix sync parallel and support low_cpu_mem_usage,,2024-11-13T10:52:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1814
这是一个用户提出需求的issue，主要涉及的对象是dpt模型应用开发。由于与代码仓对比时出现错误的字符序列，可能导致需要对dpt模型应用开发的相关内容进行调整或修复。,【开源实习】dpt模型应用开发,和代码仓对比： torch: !d224c87c1faf7fa901478cc54b006ec3 !39ed3b531244765d3f0c8abdfaaa21a9 mindspore: !5478cb0df994cb4df312c3401ff9dc35 !7e8e0b157e7ab1ef33992cbebd47d4e7,2024-11-12T05:09:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1813
这是一个开发需求类型的issue，该问题涉及的主要对象是dpt模型应用开发。由于缺少必要的代码对比信息，导致无法进行有效的模型应用开发工作。,【开源实习】dpt模型应用开发,和代码仓对比： torch: !d224c87c1faf7fa901478cc54b006ec3 !39ed3b531244765d3f0c8abdfaaa21a9 mindspore: !5478cb0df994cb4df312c3401ff9dc35 !7e8e0b157e7ab1ef33992cbebd47d4e7,2024-11-11T16:34:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1812
这是一个用户提出需求的类型，主要对象是dpt模型应用开发。,【开源实习】dpt模型应用开发,,2024-11-11T15:59:59Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1811,然后是和代码仓的对比： pytorch: !d224c87c1faf7fa901478cc54b006ec3 !39ed3b531244765d3f0c8abdfaaa21a9 mindspore: !d224c87c1faf7fa901478cc54b006ec3 !836969b5f675faf14280a2cc13f451e7
这是一个用户提交需求的issue，主要对象是mindnlp，用户希望增加mindspore推理功能的补丁。,add mindspore infer function patch,,2024-11-11T08:42:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1810
这是一个bug报告类型的issue，主要涉及mindnlp中的`per_gpu`参数修复。这个问题可能是因为`per_gpu`参数的错误导致了程序运行时的异常情况。,fix `per_gpu` args,,2024-11-11T02:23:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1809
这是一个bug报告，该问题单涉及的主要对象是mms-tts-eng模型。由于某种原因导致推理时无法生成音频，出现了报错的症状。,mms-tts-eng模型推理生成不了音频。,"**Describe the bug/ 问题描述 (Mandatory / 必填)** mmsttseng模型推理时报错。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:    MindSpore version : 2.4.0    MindNlp version : 0.4.0    Python version : 3.9.20 **To Reproduce / 重现步骤 (Mandatory / 必填)** 运行推理代码 ```python from mindnlp.transformers import VitsModel, AutoTokenizer model = VitsModel.from_pretrained(""./model/mmsttseng"",from_pt=True) tokenizer = AutoTokenizer.from_pretrained(""./model/mmsttseng"",from_pt=True) text = ""some example text in the English language"" inputs = tokenizer(text, return_tensors='ms') output = model(**inputs).waveform import scipy scipy.io.wavfile.write(""techno.wav"", rate=model.config.sampling_rate, data=output) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 生成音频文件 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** ```bash Building prefix dict from the default dictionary ... Loading model from cache C:\Users\23974\AppData\Local\Temp\jieba.cache Loading model cost 0.572 seconds. Prefix dict has been built successfully. Some weights of VitsModel were not initialized from the model checkpoint at ./model/mmsttseng and are newly initialized: ['flow.flows.0.wavenet.in_layers.0.weight', 'flow.flows.0.wavenet.in_layers.1.weight', 'flow.flows.0.wavenet.in_layers.2.weight', 'flow.flows.0.wavenet.in_layers.3.weight', 'flow.flows.0.wavenet.res_skip_layers.0.weight', 'flow.flows.0.wavenet.res_skip_layers.1.weight', 'flow.flows.0.wavenet.res_skip_layers.2.weight', 'flow.flows.0.wavenet.res_skip_layers.3.weight', 'flow.flows.1.wavenet.in_layers.0.weight', 'flow.flows.1.wavenet.in_layers.1.weight', 'flow.flows.1.wavenet.in_layers.2.weight', 'flow.flows.1.wavenet.in_layers.3.weight', 'flow.flows.1.wavenet.res_skip_layers.0.weight', 'flow.flows.1.wavenet.res_skip_layers.1.weight', 'flow.flows.1.wavenet.res_skip_layers.2.weight', 'flow.flows.1.wavenet.res_skip_layers.3.weight', 'flow.flows.2.wavenet.in_layers.0.weight', 'flow.flows.2.wavenet.in_layers.1.weight', 'flow.flows.2.wavenet.in_layers.2.weight', 'flow.flows.2.wavenet.in_layers.3.weight', 'flow.flows.2.wavenet.res_skip_layers.0.weight', 'flow.flows.2.wavenet.res_skip_layers.1.weight', 'flow.flows.2.wavenet.res_skip_layers.2.weight', 'flow.flows.2.wavenet.res_skip_layers.3.weight', 'flow.flows.3.wavenet.in_layers.0.weight', 'flow.flows.3.wavenet.in_layers.1.weight', 'flow.flows.3.wavenet.in_layers.2.weight', 'flow.flows.3.wavenet.in_layers.3.weight', 'flow.flows.3.wavenet.res_skip_layers.0.weight', 'flow.flows.3.wavenet.res_skip_layers.1.weight', 'flow.flows.3.wavenet.res_skip_layers.2.weight', 'flow.flows.3.wavenet.res_skip_layers.3.weight', 'posterior_encoder.wavenet.in_layers.0.weight', 'posterior_encoder.wavenet.in_layers.1.weight', 'posterior_encoder.wavenet.in_layers.10.weight', 'posterior_encoder.wavenet.in_layers.11.weight', 'posterior_encoder.wavenet.in_layers.12.weight', 'posterior_encoder.wavenet.in_layers.13.weight', 'posterior_encoder.wavenet.in_layers.14.weight', 'posterior_encoder.wavenet.in_layers.15.weight', 'posterior_encoder.wavenet.in_layers.2.weight', 'posterior_encoder.wavenet.in_layers.3.weight', 'posterior_encoder.wavenet.in_layers.4.weight', 'posterior_encoder.wavenet.in_layers.5.weight', 'posterior_encoder.wavenet.in_layers.6.weight', 'posterior_encoder.wavenet.in_layers.7.weight', 'posterior_encoder.wavenet.in_layers.8.weight', 'posterior_encoder.wavenet.in_layers.9.weight', 'posterior_encoder.wavenet.res_skip_layers.0.weight', 'posterior_encoder.wavenet.res_skip_layers.1.weight', 'posterior_encoder.wavenet.res_skip_layers.10.weight', 'posterior_encoder.wavenet.res_skip_layers.11.weight', 'posterior_encoder.wavenet.res_skip_layers.12.weight', 'posterior_encoder.wavenet.res_skip_layers.13.weight', 'posterior_encoder.wavenet.res_skip_layers.14.weight', 'posterior_encoder.wavenet.res_skip_layers.15.weight', 'posterior_encoder.wavenet.res_skip_layers.2.weight', 'posterior_encoder.wavenet.res_skip_layers.3.weight', 'posterior_encoder.wavenet.res_skip_layers.4.weight', 'posterior_encoder.wavenet.res_skip_layers.5.weight', 'posterior_encoder.wavenet.res_skip_layers.6.weight', 'posterior_encoder.wavenet.res_skip_layers.7.weight', 'posterior_encoder.wavenet.res_skip_layers.8.weight', 'posterior_encoder.wavenet.res_skip_layers.9.weight'] You should probably TRAIN this model on a downstream task to be able to use it for predictions and inference. [WARNING] KERNEL(,4408,?):2024119 15:52:50 [mindspore\ccsrc\kernel/kernel.h:916] mindspore::kernel::CheckShapeNull] For 'ReduceMin', the shape of input cannot contain zero, but got [const vector]{0} [WARNING] KERNEL(,4408,?):2024119 15:52:50 [mindspore\ccsrc\kernel/kernel.h:916] mindspore::kernel::CheckShapeNull] For 'ReduceMax', the shape of input cannot contain zero, but got [const vector]{0} [WARNING] KERNEL(,4408,?):2024119 15:52:50 [mindspore\ops\kernel\cpu\arithmetic_cpu_kernel.cc:171] mindspore::kernel::`anonymousnamespace'::ArithmeticCpuTypeFunc::RunFunc] Mul output shape contain 0, output_shape: [const vector]{0, 1} [WARNING] KERNEL(,4408,?):2024119 15:52:50 [mindspore\ops\kernel\cpu\arithmetic_cpu_kernel.cc:171] mindspore::kernel::`anonymousnamespace'::ArithmeticCpuTypeFunc::RunFunc] Add output shape contain 0, output_shape: [const vector]{0, 1} ``` **Additional context / 备注 (Optional / 选填)** 代码.md",2024-11-09T08:11:36Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1808
这是一个Bug报告，主要涉及到'per_gpu_train_batch_size'键值报错的问题，原因可能是参数设置出现错误。,KeyError: 'per_gpu_train_batch_size',"**Describe the bug/ 问题描述 (Mandatory / 必填)** 键值出现'per_gpu_train_batch_size'相关报错  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to 'training_args = Seq2SeqTrainingArguments(     ""output"",     learning_rate=lr,     num_train_epochs=num_epochs,     logging_strategy=""epoch"",     save_strategy=""no"",     predict_with_generate=True,     generation_max_length=2,     remove_unused_columns=False,     per_device_train_batch_size=batch_size, )' 2. Click on 'print(training_args)' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)**  KeyError                                  Traceback (most recent call last) Cell In[19], line 31      19 training_args = Seq2SeqTrainingArguments(      20     ""output"",      21     learning_rate=lr,    (...)      28     per_device_train_batch_size=batch_size,      29 )      30  print(training_args.__dict__.keys()) > 31 print(training_args) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/train_args/base.py:1167, in TrainingArguments.__str__(self)    1163 self_as_dict = asdict(self)    1165  Remove deprecated arguments. That code should be removed once    1166  those deprecated arguments are removed from TrainingArguments. (TODO: v5) > 1167 del self_as_dict[""per_gpu_train_batch_size""]    1168 del self_as_dict[""per_gpu_eval_batch_size""]    1170 self_as_dict = {k: f"""" if k.endswith(""_token"") else v for k, v in self_as_dict.items()} KeyError: 'per_gpu_train_batch_size' **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-09T07:56:06Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1807,fixed
这是一个bug报告，涉及香橙派训练模型出现RuntimeError导致Unsupported expression 'Yield'的问题。,香橙派训练模型RuntimeError: Unsupported expression 'Yield'.,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 香橙派训练模型RuntimeError: Unsupported expression 'Yield'.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend 香橙派  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  2.4.0  Python version (e.g., Python 3.7.5) :  3.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):  22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 运行issue.txt里的代码 issue.txt **Expected behavior / 预期结果 (Mandatory / 必填)** 模型正常训练 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !180bed5be3494502554df1c00c31cb94 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-09T03:35:15Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1806,你写的有问题，set_train不能写在编译函数里
这是一个用户提出需求的类型，主要对象是LayoutLMv2模型应用开发。由于用户希望开发LayoutLMv2模型应用，故提出了这个issue。,【开源实习】LayoutLMv2模型应用开发,Issue链接：https://gitee.com/mindspore/community/issues/IAADJA,2024-11-09T03:34:51Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1805,AI gallery 链接：https://pangu.huaweicloud.com/gallery/assetdetail.html?id=4cc9d5f6d818434aa2975f36e7ba2c9f,参考仓（pytorch实现）的最后评估结果： !image mindnlp完成的模型训练的最后评估结果： !image 评估结果差异的特别说明        数据集都是CORD数据集（综合收据数据集），但版本不一致：        参考仓（在google Lab + google 网盘下进行的实验）使用的版本(v0.1)较旧，且包含一定的错误； !image !image CORD发布与版本更新信息：https://gitcode.com/gh_mirrors/co/cord/overview !image        本次实验的是huggingface的最新版本 v2.0. !image,看起来mindnlp的效果还要好点，是数据修正的原因哈
这是一个需求类型的issue，主要涉及到对项目的初始化操作和移动测试文件夹。可能是为了整理项目结构或者优化开发流程而提出的建议。,init mimm & move tests folder,,2024-11-08T12:14:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1804
这是一个用户提出需求的issue，主要涉及到GLM4Voice模型。由于缺少详细描述，无法准确确定用户需求的具体内容。,端到端语音大模型需求（GLM-4-Voice）,url:https://github.com/THUDM/GLM4Voice Model	Type	Download GLM4VoiceTokenizer	Speech Tokenizer	🤗 Huggingface 🤖 ModelScope GLM4Voice9B	Chat Model	🤗 Huggingface 🤖 ModelScope GLM4VoiceDecoder	Speech Decoder	🤗 Huggingface 🤖 ModelScope,2024-11-08T09:07:34Z,requirement,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1803
这是一个bug报告，涉及到mindnlp库中的Accumulator对象的兼容性问题，导致无法导入mindnlp模块。,Accumulator不兼容,"**Describe the bug/ 问题描述 (Mandatory / 必填)** Accumulator不兼容 **代码** import mindnlp from mindnlp.core import nn, ops from mindnlp.core.modules import Accumulator class LinearRegression(nn.Module):     def __init__(self):         super(LinearRegression, self).__init__()         self.linear = nn.Linear(1, 1)     def construct(self, x):         return self.dense(x) model = LinearRegression() optimizer = mindnlp.core.optim.AdamW(model.trainable_params(), lr=0.001) accumulate_step = 2 accumulator = Accumulator(optimizer, accumulate_step)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: 香橙派  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :3.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):22.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** import mindnlp from mindnlp.core import nn, ops from mindnlp.core.modules import Accumulator class LinearRegression(nn.Module):     def __init__(self):         super(LinearRegression, self).__init__()         self.linear = nn.Linear(1, 1)     def construct(self, x):         return self.dense(x) model = LinearRegression() optimizer = mindnlp.core.optim.AdamW(model.trainable_params(), lr=0.001) accumulate_step = 2 accumulator = Accumulator(optimizer, accumulate_step) **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !621e63d113194518d666fe43ac62da8c **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-08T08:07:52Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1802,新版方案自动进行梯度累加，不再需要accumulator
这个issue属于用户提出需求类型，主要涉及的对象是支持fill_mask/image_classification/image_feature_extraction pipelines。这个问题的提出可能是用户需要增加新的功能或支持不同的数据处理流程。,support fill_mask/image_classification/image_feature_extraction pipelines,,2024-11-08T06:17:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1801
这个issue类型是用户提出需求，主要涉及支持深度估计和文档问答功能。,support depth_estimation & doc_qa,,2024-11-06T10:35:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1800
这是一个bug报告，涉及的主要对象是加载openbmb/MiniCPM2Bdpobf16模型时出现的MiniCPMConfig未定义问题。这个问题很可能是由于缺少必要的配置文件或参数导致的。,MiniCPMConfig未定义问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 加载openbmb/MiniCPM2Bdpobf16模型时出现Config未定义问题  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:Mindspore=2.4.0、MindNLP=0.4.0、Python=3.10、Windows **To Reproduce / 重现步骤 (Mandatory / 必填)** ```python from mindnlp.transformers import AutoModelForCausalLM, AutoTokenizer import mindspore path = 'openbmb/MiniCPM2Bdpobf16' tokenizer = AutoTokenizer.from_pretrained(path) model = AutoModelForCausalLM.from_pretrained(path,ms_dtype=mindspore.float16) responds, history = model.chat(tokenizer, ""请写一篇关于人工智能的文章，详细介绍人工智能的未来发展和隐患。"", temperature=0.7, top_p=0.7) print(responds) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 模型正确输出 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** ``` ValueError: Unrecognized configuration class  for this kind of AutoModel: AutoModelForCausalLM. Model type should be one of BartConfig, BertConfig, BertGenerationConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BlenderbotConfig, BlenderbotSmallConfig, BloomConfig, CamembertConfig, ChatGLMConfig, ChatGLM4Config, CodeGenConfig, CohereConfig, CpmAntConfig, CTRLConfig, Data2VecTextConfig, DbrxConfig, ElectraConfig, ErnieConfig, FalconConfig, Florence2Config, FuyuConfig, GemmaConfig, Gemma2Config, GitConfig, GPT2Config, GPTBigCodeConfig, GPTJConfig, GPTNeoConfig, GPTNeoXConfig, JambaConfig, JetMoeConfig, LlamaConfig, MambaConfig, MarianConfig, MBartConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MllamaConfig, MptConfig, MusicgenConfig, MusicgenMelodyConfig, MvpConfig, OlmoConfig, OpenAIGPTConfig, OPTConfig, PegasusConfig, PersimmonConfig, PhiConfig, Phi3Config, PLBartConfig, ProphetNetConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RwkvConfig, StableLmConfig, Starcoder2Config, TrOCRConfig, WhisperConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLMProphetNetConfig, XLNetConfig, XmodConfig. ```",2024-11-05T15:29:06Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1799
这是一个用户提出需求的issue，主要涉及mindnlp中LoRA的半精度微调的实现方法，用户希望了解如何在硬件上实现这一功能。,LoRA半精度微调,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 如何使用mindnlp实现LoRA的半精度微调？在  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): ubuntu22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. !f6a98cb5f7025fe345248533a8824b0b 2. !fb681ecc28b7f5a0c9a21b4045c9525a 3. !image 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** 成功运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !79d877e977fc4ba10f409f1b1c580daa **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-11-05T14:30:11Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1798
"这是一个用户提出需求的issue，主要涉及的对象是""dino应用开发""。由于缺乏具体内容，用户并未描述具体的需求或问题。",dino应用开发,,2024-11-04T11:39:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1797,!image
"这是一个bug报告类型的issue，主要涉及的对象是""whisper stream""功能。由于更新的问题导致了bug或用户需求的问题。",update whisper stream,,2024-11-04T07:49:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1796
这是一个bug报告，主要涉及mindnlp库中的trl功能，用户遇到了大量偏好数据集无法正常使用的问题。,大量偏好数据集无法正常使用,"**Describe the bug/ 问题描述** 目前正在测试`mindnlp.trl`，但大量偏好数据集正常加载后无法读取，已经尝试过的数据集包括：`trlinternaltesting/hhrlhfhelpfulbasetrlstyle`, `HuggingFaceH4/ultrafeedback_binarized`, `argilla/ultrafeedbackbinarizedpreferencescleaned`, `princetonnlp/llama3ultrafeedbackarmorm`, `argilla/distilabelintelorcadpopairs`，`Intel/orca_dpo_pairs` . . . 目前尝试过的仅有 `Anthropic/hhrlhf` 能够正常打印 **Software Environment / 软件环境**: `os`：WSL Ubuntu22.04 `python` 3.10.14 `mindspore` 2.3.1 `mindnlp` 0.4.1 `numpy` 1.26.3 **To Reproduce / 重现步骤** ```python from mindnlp.dataset import load_dataset ds=load_dataset(""HuggingFaceH4/ultrafeedback_binarized"", split=""train_prefs"") print(next(ds.create_dict_iterator())) ``` **Screenshots/ 日志 / 截图** !image",2024-11-02T08:53:14Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1795,确定是GeneratorDataset的问题，我先去和minddata同事交流下,> 确定是GeneratorDataset的问题，我先去和minddata同事交流下 您好，请问此Bug是否有修复计划
这是一个bug报告，主要涉及mindnlp官方文档示例代码错误。由于网址错误导致了示例代码无法找到页面，用户提出需要修正此问题的帮助。,mindnlp官方文档（https://mindnlp.cqu.ai/）示例代码错误反馈,错误1     https://mindnlp.cqu.ai/tutorials/quick_start/loadthemodel !image     改正：from mindnlp.core.optim import AdamW 错误2 https://mindnlp.cqu.ai/tutorials/quick_start/prepareadataset !image https://mindnlp.cqu.ai/tutorials/data_preprocess/ !image     改正：from mindnlp.dataset import load_dataset 错误3     https://mindnlp.cqu.ai/tutorials/peft/trainthemodel !image     改正：import mindnlp.core.optim as optim,2024-10-31T12:52:27Z,bug,open,1,6,https://github.com/mindspore-lab/mindnlp/issues/1794,ok," 错误1的下面我还遇到报错了。下面这一行会报错optimizer没有parameters属性 grad_fn = value_and_grad(forward_fn, None, optimizer.parameters)",">  错误1的下面我还遇到报错了。下面这一行会报错optimizer没有parameters属性 >  > grad_fn = value_and_grad(forward_fn, None, optimizer.parameters) 下面也是需要更新的，mindnlp的optimizer不同于mindspore，应该通过model直接传进去：grad_fn = value_and_grad(forward_fn, None, model.trainable_params()) 建议先学习一下mindnlp的优化器的基本用法，和pytorch类似的，可以看看github源码或者更直接的：通过help(optimizer)打印帮助文档，optimizer是你创建的优化器对象",https://mindnlp.cqu.ai/tutorials/peft/trainingstep !image optimizer(grads)相应地改为：optimizer.step(grads), 请问mindnlp在训练过程中是否需要手动执行zero grad？我在910B上用sgd训练longformer，训练过程中HBM会不断增加直到OOM,>  请问mindnlp在训练过程中是否需要手动执行zero grad？我在910B上用sgd训练longformer，训练过程中HBM会不断增加直到OOM 目前了解到的是：mindspore的训练过程无需显示调用zero grad操作； mindnlp 训练过程的封装整体上还是和mindspore一样的（mindnlp本来就是基于mindspore的），只是因为优化器的做了自己的接口，可能在调用时调用方式变了一点。 其实如果了解mindspore和pytorch在“获取模型梯度并使用梯度更新”操作上的差异，也很容易理解为什么在mindspore 上不用 梯度清零这个操作； 提示：pytorch中更新模型参数是通过损失函数值（是一个Tensor）执行backward操作，而mindspore中不是： !image !image
这个issue类型为bug报告，主要涉及LoRA微调Qwen2.53B模型训练速度慢以及GPU利用率低的问题。,训练速度慢，GPU利用率低,"**Describe the bug/ 问题描述 (Mandatory / 必填)** LoRA微调Qwen2.53B模型时，训练阶段前10个step的速度比较快，能达到1~2s/step，随后逐渐减慢到10s/step以上，并且GPU的利用率在前期能达到100%，但在100个step之后就长时间地停在2%。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): 22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ```     def forward_fn(input_ids, attention_mask, labels):         output = model(             input_ids=input_ids,             attention_mask=attention_mask,             labels=labels,         )          loss = compute_ce_loss(output.logits, labels)         return output.loss, output.logits     grad_fn = ms.value_and_grad(         forward_fn, None, model.trainable_params(), has_aux=True     )     def train_step(input_ids, attention_mask, labels):         (loss, logits), grads = grad_fn(input_ids, attention_mask, labels)         optimizer.step(grads)         return loss, logits     for epoch in tqdm(range(num_epochs), desc=""Epoch""):         model.set_train(True)         total_loss, total_step = 0, 0         with tqdm(total=num_batches, leave=False, position=1, desc=""train_step"") as t:             for step, pack in enumerate(train_dataset.create_dict_iterator()):                 input_ids = pack[""input_ids""]                 attention_mask = pack[""attention_mask""]                 labels = pack[""labels""]                 loss, logits = train_step(                     input_ids=input_ids, attention_mask=attention_mask, labels=labels                 )                 total_loss += loss.asnumpy()                 lr_scheduler.step()                 total_step += 1                 curr_loss = total_loss / total_step                 t.set_postfix({""trainloss"": f""{curr_loss:.2f}""})                 t.update(1)                  if profiler is not None:                      if step == 10:                          profiler.start()                      if step == 100:                          profiler.stop()         model.set_train(False)         eval_loss = 0         total_step = 0         eval_preds = []         total_text_labels = []         with tqdm(             total=num_batches_eval, leave=False, position=1, desc=""eval_step""         ) as t:             for step, pack in enumerate(eval_dataset.create_dict_iterator()):                 input_ids = pack[""input_ids""]                 attention_mask = pack[""attention_mask""]                 labels = pack[""labels""]                 text_inputs = pack[""text_inputs""]                 text_labels = pack[""text_labels""]                 with ms._no_grad():                     outputs = model(                         input_ids=input_ids,                         attention_mask=attention_mask,                     )                 loss = compute_ce_loss(outputs.logits, labels)                 eval_loss += loss.asnumpy()                 total_step += 1                 curr_eval_loss = eval_loss / total_step                 eval_preds.extend(                     tokenizer.batch_decode(                         outputs.logits.argmax(axis=1).asnumpy(),                         skip_special_tokens=True,                     )                 )                 total_text_labels.extend(text_labels.tolist())                 t.set_postfix({""evalloss"": f""{curr_eval_loss:.2f}""})                 t.update(1)         bleu_avg = compute_bleu_metrics(eval_preds, total_text_labels)          accuracy = correct / total * 100          print(f""{accuracy=} % on the evaluation dataset"")         eval_epoch_loss = eval_loss / eval_dataset.get_dataset_size()         eval_ppl = np.exp(eval_epoch_loss)         train_epoch_loss = total_loss / train_dataset.get_dataset_size()         train_ppl = np.exp(train_epoch_loss)         tqdm.write(             f""{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=} {bleu_avg=}""         ) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 训练速度保持稳定且快速，GPU利用率能稳定且不能过低。 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-30T14:23:53Z,bug,open,0,8,https://github.com/mindspore-lab/mindnlp/issues/1793,试试用mindspore高版本？,完整代码也用附件传一下，我看看能不能复现,> 完整代码也用附件传一下，我看看能不能复现 我暂时还没有Ascend环境，应该用不了2.3版本吧。代码已上传，麻烦您了。 Code.zip,加一下QQ群，给你申请点代金券 721548151,> 加一下QQ群，给你申请点代金券 721548151 昨晚刚加😀,   请问一下大家这个问题换高版本之后解决没，我也是这个问题呜呜（*_*）, 没有，我后面换Ascend了,>  没有，我后面换Ascend了  非常感谢！那我也换成Ascend试试，不过为啥变慢，这个问题还真是个谜呀
这是一个 bug 报告，涉及的主要对象是 peft 中的 set_adapter 函数，可能是由于加载多个 lora adapter 后调用 set_adapter 函数导致的问题。,peft set_adapter报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 使用peft加载多个lora adapter后，使用set_adapter尝试激活其中一个lora adapter后报错AttributeError: 'LlamaForCausalLM' object has no attribute 'cells'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : 3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 在加载tloen/alpacalora7b以及22h/cabritalorav01前，我用 def torch_to_mindspore(ckpt_path, save_path):     state_dict = torch.load(ckpt_path, map_location=""cpu"")     ms_ckpt = []     for k, v in state_dict.items():         if 'wq' in k:             k = k.replace('wq', 'w_q')             v = v.transpose(0, 1)         if 'wk' in k:             k = k.replace('wk', 'w_k')             v = v.transpose(0, 1)         if 'wv' in k:             k = k.replace('wv', 'w_v')             v = v.transpose(0, 1)         if 'wo' in k:             k = k.replace('wo', 'w_o')             v = v.transpose(0, 1)         if 'w1' in k:             k = k.replace('w1', 'w_1')             v = v.transpose(0, 1)         if 'w2' in k:             k = k.replace('w2', 'w_2')             v = v.transpose(0, 1)         if 'w3' in k:             k = k.replace('w3', 'w_3')             v = v.transpose(0, 1)         if 'output' in k:              v = v.transpose(0, 1)         if 'rope' in k:             continue         ms_ckpt.append({'name': k, 'data': mindspore.Tensor(v.numpy())})     mindspore.save_checkpoint(ms_ckpt, save_path) 将adapter_model.bin转为adapter_model.ckpt from mindnlp.transformers import LlamaForCausalLM, LlamaTokenizer from mindnlp.peft import PeftModel, LoraConfig model_name = ""baffo32/decapodaresearchllama7Bhf"" tokenizer = LlamaTokenizer.from_pretrained(model_name) model = LlamaForCausalLM.from_pretrained(model_name) model = PeftModel.from_pretrained(model, ""tloen/alpacalora7b"", adapter_name=""eng_alpaca"") peft_config = LoraConfig.from_pretrained(""22h/cabritalorav01"") model.add_adapter(adapter_name=""portuguese_alpaca"",peft_config=peft_config) model.load_adapter(""./cabritalorav01"", adapter_name=""portuguese_alpaca"") model.set_adapter(""eng_alpaca"") **Expected behavior / 预期结果 (Mandatory / 必填)** eng_alpaca adapter激活 **Screenshots/ 日志 / 截图 (Mandatory / 必填)**  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-30T10:13:44Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1792
这是一个bug报告类型的issue，涉及主要对象为fixing gamma on CPU and GPU。这个问题是由于gamma值在CPU和GPU上设置错误导致的。,fix gamma on CPU and GPU,,2024-10-30T04:15:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1791
这个issue是一个bug报告，涉及的主要对象是MixTral。由于什么样的原因导致了空内容，用户提出了关于修复MixTral的问题或者寻求相关帮助。,fix mixtral ut,,2024-10-30T03:11:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1790
这是一个bug报告，涉及Qwen2模型前向传播时计算损失报错的问题。可能原因是在微调Qwen2.53B模型时使用mindnlp套件的Tra。,Qwen2模型前向传播时计算损失报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 我尝试LoRA微调Qwen2.53B模型，使用mindnlp套件的Trainer没什么问题，但采用native mindspore的pipline式的训练则报错。具体原因在于Trainer中的损失计算不是modeling_qwen2.py中的计算方法，而如果我直接将labels输入model则会采取该模型文件中的损失计算方法，从而引发报错。 ``` Traceback (most recent call last):   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 284, in      run(args)   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 178, in run     loss, logits = train_step(   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 155, in train_step     (loss, logits), grads = grad_fn(input_ids, attention_mask, labels)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 625, in after_grad     return grad_(fn_, weights)(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/api.py"", line 121, in wrapper     results = fn(*arg, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 600, in after_grad     res = self._pynative_forward_run(fn, grad_, weights, args, kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 650, in _pynative_forward_run     outputs = fn(*args, **new_kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 561, in aux_fn     outputs = fn(*args)   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 144, in forward_fn     output = model(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 611, in forward     return self.base_model(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 218, in forward     return self.model.forward(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 765, in forward     loss = loss_fct(shift_logits, shift_labels)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/loss.py"", line 1196, in forward     return F.cross_entropy(input, target, weight=self.weight,   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/functional.py"", line 233, in cross_entropy     return _cross_entropy(input, target, class_dim, weight, reduction, label_smoothing)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/functional.py"", line 253, in _cross_entropy     return (inputs * target * weight).sum() / (inputs.size / n_classes)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 3304, in sum     res = tensor_operator_registry.get(""sum"")(self, axis, keepdims)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/function/math_func.py"", line 12018, in sum     if input.dtype == mstype.bool_:   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 94, in dtype     self.stub_dtype = self.stub.get_dtype() ValueError: For 'Mul', x.shape and y.shape need to broadcast. The value of x.shape[1] or y.shape[0] must be 1 or 1 when they are not the same, but got x.shape = [const vector]{252, 151936} and y.shape = [const vector]{252} ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): 22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. ``` def forward_fn(input_ids, attention_mask, labels):         output = model(             input_ids=input_ids,             attention_mask=attention_mask,             labels=labels,         )          loss = compute_ce_loss(output.logits, labels)         return output.loss, output.logits ``` 2.  ``` grad_fn = ms.value_and_grad(forward_fn, None, optimizer.param_groups, has_aux=True) ``` 3.  ``` def train_step(input_ids, attention_mask, labels):         (loss, logits), grads = grad_fn(input_ids, attention_mask, labels)         optimizer(grads)         return loss, logits ``` 4.  ```  input_ids = pack[""input_ids""].astype(ms.int64) attention_mask = pack[""attention_mask""].astype(ms.int64) labels = pack[""labels""].astype(ms.int64) loss, logits = train_step(        input_ids=input_ids, attention_mask=attention_mask, labels=labels  ) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 正确运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 以上代码的报错在第一部分已贴出。我将labels的数据类型改为ms.float32又会报另一种错。 ``` Traceback (most recent call last):   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 284, in      run(args)   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 178, in run     loss, logits = train_step(   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 155, in train_step     (loss, logits), grads = grad_fn(input_ids, attention_mask, labels)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 625, in after_grad     return grad_(fn_, weights)(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/api.py"", line 121, in wrapper     results = fn(*arg, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 600, in after_grad     res = self._pynative_forward_run(fn, grad_, weights, args, kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 650, in _pynative_forward_run     outputs = fn(*args, **new_kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 561, in aux_fn     outputs = fn(*args)   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train_simple.py"", line 144, in forward_fn     output = model(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 611, in forward     return self.base_model(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 218, in forward     return self.model.forward(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/qwen2/modeling_qwen2.py"", line 765, in forward     loss = loss_fct(shift_logits, shift_labels)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/loss.py"", line 1196, in forward     return F.cross_entropy(input, target, weight=self.weight,   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/functional.py"", line 233, in cross_entropy     return _cross_entropy(input, target, class_dim, weight, reduction, label_smoothing)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/functional.py"", line 253, in _cross_entropy     return (inputs * target * weight).sum() / (inputs.size / n_classes)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 3304, in sum     res = tensor_operator_registry.get(""sum"")(self, axis, keepdims)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/function/math_func.py"", line 12018, in sum     if input.dtype == mstype.bool_:   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 94, in dtype     self.stub_dtype = self.stub.get_dtype() ValueError: For 'Mul', x.shape and y.shape need to broadcast. The value of x.shape[1] or y.shape[0] must be 1 or 1 when they are not the same, but got x.shape = [const vector]{252, 151936} and y.shape = [const vector]{252} ``` **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-29T11:51:50Z,bug,closed,0,9,https://github.com/mindspore-lab/mindnlp/issues/1789,我分析下,labels的数据类型不能是float，必须是int,`使用mindnlp套件的Trainer没什么问题`  直接使用trainer是没问题的吗,> `使用mindnlp套件的Trainer没什么问题` 直接使用trainer是没问题的吗 是的，我又分析了一下，把optimizer.param_groups改成model.trainable_params()就好了，好奇怪。。。,> > `使用mindnlp套件的Trainer没什么问题` 直接使用trainer是没问题的吗 >  > 是的，我又分析了一下，把optimizer.param_groups改成model.trainable_params()就好了，好奇怪。。。 这个确实必须要用model.trainable_params()， 跟框架的微分机制有关，否则顺序会对不上,> > > `使用mindnlp套件的Trainer没什么问题` 直接使用trainer是没问题的吗 > >  > >  > > 是的，我又分析了一下，把optimizer.param_groups改成model.trainable_params()就好了，好奇怪。。。 >  > 这个确实必须要用model.trainable_params()， 跟框架的微分机制有关，否则顺序会对不上 明白了，在静态图模式下已经跑通了。但现在切换成动态图模式后，报了一个似乎是语法错？`RuntimeError: Unsupported statement 'Try'.`定位在mindnlp.core.nn.modules.module.py文件的_call_impl函数，此函数中用了try语法，这是否跟mindspore的版本有关？还望赐教！,> > > > `使用mindnlp套件的Trainer没什么问题` 直接使用trainer是没问题的吗 > > >  > > >  > > > 是的，我又分析了一下，把optimizer.param_groups改成model.trainable_params()就好了，好奇怪。。。 > >  > >  > > 这个确实必须要用model.trainable_params()， 跟框架的微分机制有关，否则顺序会对不上 >  > 明白了，在静态图模式下已经跑通了。但现在切换成动态图模式后，报了一个似乎是语法错？`RuntimeError: Unsupported statement 'Try'.`定位在mindnlp.core.nn.modules.module.py文件的_call_impl函数，此函数中用了try语法，这是否跟mindspore的版本有关？还望赐教！ 说反了吧，应该是静态图跑不通吧，你在跑之前加一行 model.jit()，静态图就可以跑通了。,> > > > > `使用mindnlp套件的Trainer没什么问题` 直接使用trainer是没问题的吗 > > > >  > > > >  > > > > 是的，我又分析了一下，把optimizer.param_groups改成model.trainable_params()就好了，好奇怪。。。 > > >  > > >  > > > 这个确实必须要用model.trainable_params()， 跟框架的微分机制有关，否则顺序会对不上 > >  > >  > > 明白了，在静态图模式下已经跑通了。但现在切换成动态图模式后，报了一个似乎是语法错？`RuntimeError: Unsupported statement 'Try'.`定位在mindnlp.core.nn.modules.module.py文件的_call_impl函数，此函数中用了try语法，这是否跟mindspore的版本有关？还望赐教！ >  > 说反了吧，应该是静态图跑不通吧，你在跑之前加一行 model.jit()，静态图就可以跑通了。 哦对，抱歉，我刚开始使用mindspore和mindnlp，有很多地方不熟悉，还在努力学习阶段。感谢大佬答疑解惑，您海涵🫡,fixed
这是一个bug报告类型的issue，主要涉及的对象是mindnlp中的llava on Ascend功能。由于某种原因导致了llava on Ascend功能无法工作。,fix llava on Ascend,,2024-10-29T11:18:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1788
该issue类型为功能需求添加，主要对象是模型mirror和NLP SIG介绍，可能由于项目原有功能不足以满足相关需求而引起。,add modeler mirror & NLP SIG introdution,,2024-10-29T09:13:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1787
这是一个bug报告，该问题单涉及的主要对象是whisper ut。由于修复问题导致的错误或功能的不正常行为。,fix whisper ut,,2024-10-29T07:39:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1786
该issue为用户提出需求类型，主要涉及将MindNLP支持魔乐下载。原因可能是用户希望能够使用魔乐下载等功能，但目前系统尚未提供相关支持。,MindNLP支持魔乐下载,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-10-29T02:50:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1785
这是一个用户提出需求的issue，涉及的主要对象是项目的README文件。原因是缺少对SIG（Special Interest Group）的简介、使命等信息，用户希望这些内容能够被添加进去。,请在readme文件中添加SIG简介、使命等信息,请在readme文件中添加SIG简介、使命等信息，谢谢 另，建议在wiki或projects文件中添加工作计划、SIG构成等信息，同时请考虑增加SIG例会会议纪要的展示 参考文件：https://mp.weixin.qq.com/s/GZEx0sWRhYtOmYZmpZoCfg SIG例会会议纪要：https://etherpad.mindspore.cn/p/meetingsNLP,2024-10-28T09:58:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1784
"这是一个 bug 报告，该问题单涉及的主要对象是 `mindnlp` 库下的 `__init__.py` 文件。删除了 `from mindnlp import dataset`, `from mindnlp import evalua` 可能导致导入数据集和评估模块时出现导入错误。",Update __init__.py,"删除了mindnlp目录下的init.py中的`from mindnlp import dataset`,`from mindnlp import evaluate`,`from mindnlp import core`，这三个方法在init.py中没用到，但会导致一些问题，因此删除",2024-10-28T05:27:04Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1783,功能需要，不修改，删除transforemrs库和pytorch相关依赖规避
"这是一个bug报告，主要涉及mindnlp库中的 ""fix sew and sew_d""。由于可能是函数名拼写错误导致的bug或者问题。",fix sew and sew_d,,2024-10-28T04:11:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1782
这是一个用户提出需求的类型，该问题单涉及的主要对象是BERT模型的应用开发。,【开源实习】BERT模型应用开发,,2024-10-27T12:21:02Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1781,pytorch:  mindspore: !{EA91CA5D5D674A4982B9B49A9D7A1F4F}  ,华为云： https://pangu.huaweicloud.com/gallery/assetdetail.html?id=e12870f6f88f4011bc8ef99ce0a7e458, 麻烦您可以看一下吗,把华为云上装环境的部分删了。。。要求很多次了,抱歉，忘记删除最后小部分的了，已删除,验收通过，可以合入
这是一个bug报告，涉及IA3微调Qwen27binstruct模型在动态图模式下分布式训练报错的问题。原因可能是由于代码逻辑错误导致的。,动态图模式下，分布式训练报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** IA3微调Qwen27binstruct模型，在mindnlp.core.nn.modules.container.py处raise了一个错误： !image 我把 `p.size()` 修改为 `p.shape` 后，raise了一个unexpected error。 !image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > GPU 0, 1  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior:     tokenizer = AutoTokenizer.from_pretrained(         args.model_name_or_path, mirror=""modelscope"", revision=""master""     )     model = AutoModelForCausalLM.from_pretrained(         args.model_name_or_path, mirror=""modelscope"", revision=""master""     ).half()     peft_config = IA3Config(         peft_type=TaskType.SEQ_2_SEQ_LM,         inference_mode=False,         target_modules=[""q_proj"", ""v_proj""],   [""query_key_value""]         feedforward_cells=[],     )     model = get_peft_model(model, peft_config)     model.print_trainable_parameters()     training_args = TrainingArguments(         output_dir=args.save_dir,         evaluation_strategy=""epoch"",         per_device_train_batch_size=args.batch_size,         per_device_eval_batch_size=1,         learning_rate=args.learning_rate,         num_train_epochs=args.num_epochs,         lr_scheduler_type=""polynomial"",         lr_scheduler_kwargs={             ""lr_end"": args.learning_rate * 1e5,             ""power"": args.power,         },         logging_steps=200,         save_strategy=""epoch"",         save_total_limit=1,          load_best_model_at_end=True,     )     trainer = Trainer(         model=model,         args=training_args,         train_dataset=train_dataset,         eval_dataset=eval_dataset,     )     trainer.train() **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-27T05:18:36Z,bug,open,0,2,https://github.com/mindspore-lab/mindnlp/issues/1780,用的GPU？,> 用的GPU？ 是的，两个3090
这个issue类型是用户需求，主要涉及对象是CPU计算中的Gamma操作，由于缺少Gamma功能，用户提出了对CPU计算或更新版本MindSpore的需求。,need Gamma in cpu calculate,"platform: CPU mindspore version 2.3.1 ``` /home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/gluonts/json.py:102: UserWarning: Using `json`module for jsonhandling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.   warnings.warn( [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB Traceback (most recent call last):   File ""/home/lawrence/code/pythonCurriculum/Mindnlp_Autoformer/autoformer_mindnlp.py"", line 298, in      outputs = model.generate(   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindnlp/transformers/models/autoformer/modeling_autoformer.py"", line 2387, in generate     future_samples = distr.sample()   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindnlp/core/distributions/transformed_distribution.py"", line 140, in sample     x = self.base_dist.sample(sample_shape)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindnlp/core/distributions/distribution.py"", line 178, in sample     return self.rsample(sample_shape)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindnlp/core/distributions/studentT.py"", line 89, in rsample     Z = self._chi2.rsample(sample_shape)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindnlp/core/distributions/gamma.py"", line 74, in rsample     value = ops.gamma(sample_shape, self.concentration, self.rate)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindnlp/core/ops/random.py"", line 104, in gamma     return ops.gamma(shape, alpha, beta)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindspore/ops/function/random_func.py"", line 928, in gamma     value = gamma_v(shape, alpha, beta)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindspore/ops/primitive.py"", line 393, in __call__     return _run_op(self, self.name, args)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindspore/ops/primitive.py"", line 1011, in _run_op     return _convert_stub(stub)   File ""/home/lawrence/miniconda3/envs/mind/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 205, in _convert_stub     val = stub.get_real_value() RuntimeError:    Kernel select failed:  Unsupported op [Gamma] on CPU, Please confirm whether the device target setting is correct, or refer to 'mindspore.ops' at https://www.mindspore.cn to query the operator support list. node: :CNode_1{[0]: ValueNode Gamma, [1]: ValueNode Tensor(shape=[2], dtype=Int64, value=[800  24]), [2]: :param_Parameter_2, [3]: :param_Parameter_3}   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:415 SetOperatorInfo ``` plz let cpu or more newer mindspore version for newer cuda, I guess a lot of people don't have any ascend hardware",2024-10-26T14:00:43Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1779,好像cpu没这个算子,把复现代码用附件附上哈,> 把复现代码用附件附上哈 不仅是cpu没有这个算子，gpu也不能用这个算子 代码如下： https://github.com/4everImmortality/autoformer_mindnlp_test/blob/main/autoformer_mindnlp.py,> https://github.com/4everImmortality/autoformer_mindnlp_test/blob/main/autoformer_mindnlp.py 发一个简单复现的demo吧,"> > https://github.com/4everImmortality/autoformer_mindnlp_test/blob/main/autoformer_mindnlp.py >  > 发一个简单复现的demo吧 !image 经过我测试后，mindnlp内的gamma方法是支持gpu 和cpu调用的 但是mindspore ops中的gamma 方法不行，而mindnlp中gamma其中一个函数rsample 会调用mindspre的gamma 导致只能在Ascend上使用 !image 下面是样例测试 ``` import mindspore from mindspore import Tensor from mindnlp.core.distributions.gamma import Gamma  初始化 MindSpore 的环境 mindspore.set_context(mode=mindspore.GRAPH_MODE, device_target=""CPU"")  使用 gamma 函数 m = Gamma(Tensor([1.0]), Tensor([1.0])) temp = m.rsample() print(""Gamma of x:"", temp) ```",暂时使用numpy.random.gamma替代
这是一个bug报告类型的issue，主要涉及mindnlp库下的LoRA微调ChatGLM3-6b模型，由于数据类型不匹配而出现错误。,LoRA微调ChatGLM3-6b，数据类型不匹配的错误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 我在用mindnlp.peft的LoRA微调ChatGLM36b时，训练过程中在lora的linear层报错TypeError。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu 22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)**     tokenizer = ChatGLM3Tokenizer.from_pretrained(         args.model_name_or_path, mirror=""modelscope"", revision=""master""     )     model = ChatGLM3ForConditionalGeneration.from_pretrained(         args.model_name_or_path, mirror=""modelscope"", revision=""master""     )     peft_config = LoraConfig(         task_type=TaskType.CAUSAL_LM,         inference_mode=False,         r=8,         lora_alpha=32,         lora_dropout=0.1,     )     model = get_peft_model(model, peft_config)     model.print_trainable_parameters()     training_args = TrainingArguments(         output_dir=args.save_dir,         evaluation_strategy=""epoch"",         per_device_train_batch_size=args.batch_size,         per_device_eval_batch_size=1,         learning_rate=args.learning_rate,         num_train_epochs=args.num_epochs,         lr_scheduler_type=""polynomial"",         lr_scheduler_kwargs={             ""lr_end"": args.learning_rate * 0.0001,             ""power"": args.power,         },         logging_steps=200,         save_strategy=""epoch"",         save_total_limit=1,          load_best_model_at_end=True,     )     trainer = Trainer(         model=model,         args=training_args,         train_dataset=train_dataset,         eval_dataset=eval_dataset,     )     trainer.train() **Expected behavior / 预期结果 (Mandatory / 必填)** !image **Screenshots/ 日志 / 截图 (Mandatory / 必填)** Traceback (most recent call last):   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train.py"", line 251, in      run(args)   File ""/home/zjj/xjd/huaweiict2024/ChatStyle/train.py"", line 91, in run     trainer.train()   resume_from_checkpoint=""./checkpoints/checkpoint8880""   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 755, in train     return inner_training_loop(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1107, in _inner_training_loop     tr_loss_step, grads = self.training_step(model, inputs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1382, in training_step     loss, grads = self.grad_fn(inputs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 625, in after_grad     return grad_(fn_, weights)(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/api.py"", line 121, in wrapper     results = fn(*arg, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 600, in after_grad     res = self._pynative_forward_run(fn, grad_, weights, args, kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 650, in _pynative_forward_run     outputs = fn(*args, **new_kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1374, in forward     return self.compute_loss(model, inputs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py"", line 1396, in compute_loss     outputs = model(**inputs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 373, in forward     return self.get_base_model()(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/chatglm2/modeling_chatglm2.py"", line 1650, in forward     transformer_outputs = self.transformer(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/chatglm2/modeling_chatglm2.py"", line 1423, in forward     hidden_states, presents, all_hidden_states, all_self_attentions = self.encoder(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/chatglm2/modeling_chatglm2.py"", line 1108, in forward     layer_ret = layer(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/chatglm2/modeling_chatglm2.py"", line 969, in forward     attention_output, kv_cache = self.self_attention(   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/transformers/models/chatglm2/modeling_chatglm2.py"", line 713, in forward     mixed_x_layer = self.query_key_value(hidden_states)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 391, in _wrapped_call_impl     return self._call_impl(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/core/nn/modules/module.py"", line 402, in _call_impl     return forward_call(*args, **kwargs)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/tuners/lora/layer.py"", line 729, in forward     result = result.to(torch_result_dtype)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/tensor.py"", line 3884, in to     return tensor_operator_registry.get('to')()(self, dtype)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/primitive.py"", line 311, in __call__     should_elim, output = self.check_elim(*args)   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/ops/operations/array_ops.py"", line 357, in check_elim     if isinstance(x, Tensor) and x.dtype == dtype and not PackFunc.is_tracing():   File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py"", line 94, in dtype     self.stub_dtype = self.stub.get_dtype() TypeError: For primitive[Dense], the input type must be same. name:[w]:Ref[Tensor[Float32]]. name:[x]:Tensor[Float16]. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-26T06:41:23Z,bug,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1778,"补充一下 bug溯源到最后一层mindnlp的内容是`  File ""/home/zjj/miniconda3/envs/mindspore2.2/lib/python3.9/sitepackages/mindnlp/peft/tuners/lora/layer.py"", line 729, in forward     result = result.to(torch_result_dtype)`，当我想查看result的dtype时`result.dtype`会报同样的错`TypeError: For primitive[Dense], the input type must be same. name:[w]:Ref[Tensor[Float32]]. name:[x]:Tensor[Float16].` 并且这个错误在动态图和静态图模式下都会发生。"
这是一个 bug 报告，涉及到 nn.utils.parametrizations 模块，由于某种原因导致需要更新这个模块。,update nn.utils.parametrizations,,2024-10-26T04:07:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1777
"这是一个需求问题，主要涉及的对象是""wav2vec""。原因可能是用户希望升级""wav2vec""至最新版本以获得新功能或改进。",upgrade wav2vec,,2024-10-26T03:24:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1776
这是一个需求类型的issue，主要涉及静态图加速jit文件。,qwen1.5-0.5b_jit.py,静态图加速jit文件,2024-10-25T08:33:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1775
"这是一个bug报告，涉及的主要对象是名为""llama embedding""的功能模块。由于修复LLama嵌入导致的bug或错误，用户提交了此问题。",fix llama embedding,,2024-10-25T03:48:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1774
这个issue是关于bug报告，涉及到mindnlp/transformers/models/llava/modeling_llava.py中的代码运行报错。,mindnlp/transformers/models/llava/modeling_llava.py中的“example”无法运行，报错：BLAS : Bad memory unallocation! ,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. mindnlp/transformers/models/llava/modeling_llava.py中第287行提供的“example”无法运行，报错BLAS : Bad memory unallocation!  Hardware Environment(Ascend/GPU/CPU) / 硬件环境: /device ascend Software Environment / 软件环境 (Mandatory / 必填):  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):Eulerosv2r8 4.19.36  GCC/Compiler version (if compiled from source): Excute Mode / 执行模式 (Mandatory / 必填)(PyNative/Graph): /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1：复制代码配置环境运行 2：显示“BLAS : Bad memory unallocation! : 768 0xffef1a000000”，无输出 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen.】 正常运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !error1  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-25T02:51:30Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1773
"这是一个功能需求问题，用户需要指导如何在mindnlp中实现类似于""train_dataset.set_format(""torch"")""的格式转换操作。","layoutlmv3的AI Gallery任务之中在mindnlp之中未找到类似于train_dataset.set_format(""torch"")的转换方式",1.在进行ayoutlmv3的AI Gallery任务之中，在给出的示例之中存在将格式转换到pytorch的语句，在使用mindnlp进行实现时不知道该如何进行格式转换。示例任务链接：ttps://colab.research.google.com/github/NielsRogge/TransformersTutorials/blob/master/LayoutLMv3/Fine_tune_LayoutLMv3_on_FUNSD_(HuggingFace_Trainer).ipynbscrollTo=YvpsU8vfp4j !20241023数据格式问题定位,2024-10-23T08:32:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1771
这是一个开源实习项目的招聘需求。,【开源实习】Mask2Former模型应用开发,https://gitee.com/mindspore/community/issues/IAADK9,2024-10-23T08:00:35Z,,closed,0,11,https://github.com/mindspore-lab/mindnlp/issues/1770,AST的文件夹从tutorials调整到applications https://gitee.com/mindspore/community/issues/IAAD7O,fix bug about mask2former,fix bug about mask2former,https://pangu.huaweicloud.com/gallery/assetdetail.html?id=544c8300cf0f4210b6252d7c18d7a921,截图部分代码运行结果与原应用执行结果误差较大，排查迁移代码是否正确 !20241104154505(WeLinkPC) !20241104154511(WeLinkPC),经排查，是迁移代码中mask2former的image_processing_mask2former.py中一处小错误导致的 通过在函数部分，输出中间变量：（发现错误值） 以下是mindnlp的截图，其中label变量的输出（错误） !496f59b2b0e3f0c4da9728e4ccb77462 !9a3409c9a3104f6329b23da74fd24b74 以下是transformer的截图，其中label变量的输出（正确） !image !image,华为云：https://pangu.huaweicloud.com/gallery/assetdetail.html?id=9e09753dfb424f2abca528ab2c07697b,!b4ffd448241ccb890122ed8ab6974c52,验收通过，可以合入代码,pylint没过,修改后通过了pylint
这是一个bug报告，涉及MMS迁移任务中推理代表官方模型的问题。造成该问题的原因需要进一步分析。,MMS迁移任务中遇到的一个bug,"**Describe` the bug/ 问题描述 (Mandatory / 必填)** 在MMS迁移任务中，迁移mmsttseng模型时，将官方给的模型推理代码只替换关键词，运行报错，报错信息显示会调用一个evaluate库，然后在那里面会import transformers，然后就提示我没torch库报错了。  **Software Environment / 软件环境 (Mandatory / 必填)**:    MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1    Python version (e.g., Python 3.7.5) :3.9.20    OS platform and distribution (e.g., Linux Ubuntu 16.04): CentOS Linux release 7.9.2009 (Core)    evaluate version  :0.4.3 **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 打开终端，新建conda环境  (python=3.9 ) 2. 添加库：    ```bash    添加mindspore和mindnlp:    conda install mindspore=2.3.1 c mindspore c condaforge    pip install mindnlp    添加jupyter:    conda install n project ipykernel updatedeps forcereinstall    ``` 3. 新建jupyter，输入：    ```python    from mindnlp.transformers import VitsModel, AutoTokenizer    import mindspore    model = VitsModel.from_pretrained(""./mmsttseng"")    tokenizer = AutoTokenizer.from_pretrained(""./mmsttseng"")    text = ""some example text in the English language""    inputs = tokenizer(text, return_tensors='ms')    print(inputs)    output = model(**inputs).waveform    ``` 4. 运行代码，发现报错。 **Expected behavior / 预期结果 (Mandatory / 必填)** 不报错，无输出 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** ```bash  ModuleNotFoundError                       Traceback (most recent call last) File ~/.local/lib/python3.9/sitepackages/transformers/utils/import_utils.py:1567, in _LazyModule._get_module(self, module_name)    1566 try: > 1567     return importlib.import_module(""."" + module_name, self.__name__)    1568 except Exception as e: File ~/.conda/envs/mind/lib/python3.9/importlib/__init__.py:127, in import_module(name, package)     126         level += 1 > 127 return _bootstrap._gcd_import(name[level:], package, level) File :1030, in _gcd_import(name, package, level) File :1007, in _find_and_load(name, import_) File :986, in _find_and_load_unlocked(name, import_) File :680, in _load_unlocked(spec) File :850, in exec_module(self, module) File :228, in _call_with_frames_removed(f, *args, **kwds) File ~/.local/lib/python3.9/sitepackages/transformers/pipelines/__init__.py:26      25 from ..feature_extraction_utils import PreTrainedFeatureExtractor > 26 from ..image_processing_utils import BaseImageProcessor      27 from ..models.auto.configuration_auto import AutoConfig File ~/.local/lib/python3.9/sitepackages/transformers/image_processing_utils.py:21      20 from .image_processing_base import BatchFeature, ImageProcessingMixin > 21 from .image_transforms import center_crop, normalize, rescale      22 from .image_utils import ChannelDimension File ~/.local/lib/python3.9/sitepackages/transformers/image_transforms.py:22      20 import numpy as np > 22 from .image_utils import (      23     ChannelDimension,      24     ImageInput,      25     get_channel_dimension_axis,      26     get_image_size,      27     infer_channel_dimension_format,      28 )      29 from .utils import ExplicitEnum, TensorType, is_jax_tensor, is_tf_tensor, is_torch_tensor File ~/.local/lib/python3.9/sitepackages/transformers/image_utils.py:58      57 if is_torchvision_available(): > 58     from torchvision.transforms import InterpolationMode      60     pil_torch_interpolation_mapping = {      61         PILImageResampling.NEAREST: InterpolationMode.NEAREST,      62         PILImageResampling.BOX: InterpolationMode.BOX,    (...)      67         PILImageResampling.NEAREST: InterpolationMode.NEAREST,      68     } File ~/.local/lib/python3.9/sitepackages/torchvision/__init__.py:5       3 from modulefinder import Module > 5 import torch       6 from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils ModuleNotFoundError: No module named 'torch' The above exception was the direct cause of the following exception: RuntimeError                              Traceback (most recent call last) Cell In[1], line 1 > 1 from mindnlp.transformers import VitsModel, AutoTokenizer       2 import mindspore       3 model = VitsModel.from_pretrained(""./mmsttseng"") File ~/.conda/envs/mind/lib/python3.9/sitepackages/mindnlp/__init__.py:49      47 from mindnlp import transformers      48 from mindnlp import dataset > 49 from mindnlp import evaluate      50 from mindnlp import core      52 __all__ = ['ms_jit', 'transformers'] File ~/.conda/envs/mind/lib/python3.9/sitepackages/mindnlp/evaluate.py:21      19 from datasets import DownloadConfig, DownloadMode      20 from datasets.utils.version import Version > 21 from evaluate import config      22 from evaluate import load as eval_load      23 from evaluate.module import EvaluationModule File ~/.conda/envs/mind/lib/python3.9/sitepackages/evaluate/__init__.py:29      25 SCRIPTS_VERSION = ""main"" if version.parse(__version__).is_devrelease else __version__      27 del version > 29 from .evaluation_suite import EvaluationSuite      30 from .evaluator import (      31     AudioClassificationEvaluator,      32     AutomaticSpeechRecognitionEvaluator,    (...)      42     evaluator,      43 )      44 from .hub import push_to_hub File ~/.conda/envs/mind/lib/python3.9/sitepackages/evaluate/evaluation_suite/__init__.py:10       7 from datasets import Dataset, DownloadConfig, DownloadMode, load_dataset       8 from datasets.utils.version import Version > 10 from ..evaluator import evaluator      11 from ..loading import evaluation_module_factory      12 from ..utils.logging import get_logger File ~/.conda/envs/mind/lib/python3.9/sitepackages/evaluate/evaluator/__init__.py:27      23     TRANSFORMERS_AVAILABLE = False      25 from typing import Dict, List > 27 from .audio_classification import AudioClassificationEvaluator      28 from .automatic_speech_recognition import AutomaticSpeechRecognitionEvaluator      29 from .base import Evaluator File ~/.conda/envs/mind/lib/python3.9/sitepackages/evaluate/evaluator/audio_classification.py:23      21 from ..module import EvaluationModule      22 from ..utils.file_utils import add_end_docstrings, add_start_docstrings > 23 from .base import EVALUATOR_COMPUTE_RETURN_DOCSTRING, EVALUTOR_COMPUTE_START_DOCSTRING, Evaluator      26 if TYPE_CHECKING:      27     from transformers import FeatureExtractionMixin, Pipeline, PreTrainedModel, PreTrainedTokenizer, TFPreTrainedModel File ~/.conda/envs/mind/lib/python3.9/sitepackages/evaluate/evaluator/base.py:34      32 try:      33     import transformers > 34     from transformers import Pipeline, pipeline      36     TRANSFORMERS_AVAILABLE = True      37 except ImportError: File :1055, in _handle_fromlist(module, fromlist, import_, recursive) File ~/.local/lib/python3.9/sitepackages/transformers/utils/import_utils.py:1557, in _LazyModule.__getattr__(self, name)    1555     value = self._get_module(name)    1556 elif name in self._class_to_module.keys(): > 1557     module = self._get_module(self._class_to_module[name])    1558     value = getattr(module, name)    1559 else: File ~/.local/lib/python3.9/sitepackages/transformers/utils/import_utils.py:1569, in _LazyModule._get_module(self, module_name)    1567     return importlib.import_module(""."" + module_name, self.__name__)    1568 except Exception as e: > 1569     raise RuntimeError(    1570         f""Failed to import {self.__name__}.{module_name} because of the following error (look up to see its""    1571         f"" traceback):\n{e}""    1572     ) from e RuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback): No module named 'torch' ``` **报错代码如下** 代码.md",2024-10-23T05:35:59Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1769,卸载transformers库即可解决
该问题类型为用户提出需求，主要对象是实现pipeline支持，由于当前系统无法支持pipeline功能，用户提出了需求并寻求帮助。,support pipeline,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-10-23T03:23:54Z,feature,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1768
这是一个用户提出需求的issue，主要涉及的对象是Atlas 300I Duo，用户可能想知道是否支持该设备。,支持Atlas 300I Duo吗,如题,2024-10-23T02:43:19Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1767,理论上都支持，我这没设备测，自测一下或者给我提供个远程连接？,按照最新的驱动、固件、mindspore、mindnlp，可以正常运行，效果比torchnpu好很多，点赞！,感谢支持
这是一个实习任务完成的声明，不是bug报告或需求，主要涉及的对象是 lora_seq2seq 模型。,lora_seq2seq实习任务完成,lora_seq2seq实习微调任务完成,2024-10-23T02:14:40Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1766,看起来和原来的没什么区别？,do not merge
这是一个 bug 报告，主要涉及对象是 mindnlp 库下的 from_numpy 方法，用户提出了该方法在使用时造成错误的问题。,fix from_numpy caused error,,2024-10-22T13:04:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1765
这个issue属于需求报告类型，主要涉及的对象是Mask2Former模型应用开发。,【开源实习】Mask2Former模型应用开发,https://gitee.com/mindspore/community/issues/IAADK9,2024-10-22T11:55:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1764
这个issue是一个需求提出，并且涉及到将`safe_load_file`方法使用`mmap`来加速。原因是希望通过使用`mmap`来提高文件加载的速度。,safe_load_file use mmap to speedup,,2024-10-22T10:25:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1763
这是一个Bug报告，主要问题涉及到MindNLP中的关于LlamaForCausalLM模型的错误提示。这可能是由于LlamaForCausalLM模型具有生成能力，但准备用于生成输入时出现了错误。,Update modeling_llama.py,"报错提醒：LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`.`PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.    If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).    If you are not the owner of the model architecture class, please contact the model code owner to update it.   改动：让 LlamaForCausalLM 类继承 GenerationMixin，以便启用 generate() 方法。",2024-10-22T08:06:05Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1762,没有import，待后续mindnlp修改
这是一个关于mindnlp库微调的issue，主要对象是mindnlp.transformers模块。用户提出了一个问题，代码中似乎缺少了一些内容。,mindnlp微调,"from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM hf_token = 'your_huggingface_access_token' tokenizer = AutoTokenizer.from_pretrained(""/data/applications/lmdformal/backend/BaseModels/gemma7b"", token=hf_token) model = AutoModelForCausalLM.from_pretrained(""/data/applications/lmdformal/backend/BaseModels/gemma7b"", token=hf_token) input_text = ""Write me a poem about Machine Learning."" input_ids = tokenizer(input_text, return_tensors=""ms"")  减少输入数据的大小 input_ids = {     'input_ids': input_ids['input_ids'][:50],   减少输入数据的大小     'attention_mask': input_ids['attention_mask'][:50] } outputs = model.generate(**input_ids) print(tokenizer.decode(outputs[0])) 上述是mindnlp中的.py文件路径；其中路径如下“mindnlp/llm/inference/gemma/run_gemma.py”；我在npu上运行之后返回MindSpore框架中发生了内存分配失败和段错误（Segmentation fault）；具体报错如下，到底该怎么解决问题啊。 [ERROR] PRE_ACT(54175,fffdbcff91e0,python):2024102211:24:55.301.443 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator.cc:392] AddMemBlockAndMemBufByEagerFree] TotalUsedMemStatistics : 29356337664 plus TotalUsedByEventMemStatistics : 0 and plus alloc size : 301990400 is more than total mem size : 29464985600. Traceback (most recent call last):   File ""/data/applications/workspace/mindnlp/mindnlp1/mindnlp/llm/inference/gemma/run_gemma.py"", line 17, in      outputs = model.generate(**input_ids)   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/contextlib.py"", line 79, in inner     return func(*args, **kwds)   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/sitepackages/mindnlp/transformers/generation/utils.py"", line 2025, in generate     result = self._sample(   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/sitepackages/mindnlp/transformers/generation/utils.py"", line 3024, in _sample     while self._has_unfinished_sequences(   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/sitepackages/mindnlp/transformers/generation/utils.py"", line 2231, in _has_unfinished_sequences     if this_peer_finished:   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/sitepackages/mindspore/common/tensor.py"", line 347, in __bool__     data = self.asnumpy()   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/sitepackages/mindspore/common/_stub_tensor.py"", line 49, in fun     return method(*arg, **kwargs)   File ""/data/applications/workspace/miniconda3/envs/mindnlp/lib/python3.10/sitepackages/mindspore/common/tensor.py"", line 1055, in asnumpy     return Tensor_.asnumpy(self) RuntimeError: Allocate memory failed   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/device/device_address_utils.cc:921 MallocForInput [ERROR] KERNEL(54175,fffdbcff91e0,python):2024102211:26:24.972.704 [mindspore/ccsrc/plugin/device/ascend/kernel/acl/acl_kernel_mod.cc:260] Launch] Kernel launch failed, msg: Acl compile and execute failed, op_type_:BitwiseOr   Ascend Error Message:  E40021: Failed to compile Op [BitwiseOr3]. (oppath: [Precompile /usr/local/Ascend/ascendtoolkit/8.0.RC1.alpha003/opp/builtin/op_impl/ai_core/tbe/impl/dynamic/bitwise_or.py failed with errormsg/stack: ], optype: [BitwiseOr])[THREAD:63823]         Solution: See the host log for details, and then check the Python stack where the error log is reported.         TraceBack (most recent call last):         Precompile op[BitwiseOr3] failed, oppath[/usr/local/Ascend/ascendtoolkit/8.0.RC1.alpha003/opp/builtin/op_impl/ai_core/tbe/impl/dynamic/bitwise_or.py], optype[BitwiseOr], taskID[7]. Please check op's compilation error message.[FUNC:ReportBuildErrMessage][FILE:fusion_manager.cc][LINE:753][THREAD:63823]         [SubGraphOpt][Compile][ProcFailedCompTask] Thread[281432957424096] recompile single op[BitwiseOr3] failed[FUNC:ProcessAllFailedCompileTasks][FILE:tbe_op_store_adapter.cc][LINE:956][THREAD:63823]         [SubGraphOpt][Compile][ParalCompOp] Thread[281432957424096] process fail task failed[FUNC:ParallelCompileOp][FILE:tbe_op_store_adapter.cc][LINE:1004][THREAD:63823]         [SubGraphOpt][Compile][CompOpOnly] CompileOp failed.[FUNC:CompileOpOnly][FILE:op_compiler.cc][LINE:1119][THREAD:63823]         [GraphOpt][FusedGraph][RunCompile] Failed to compile graph with compiler Normal mode Op Compiler[FUNC:SubGraphCompile][FILE:fe_graph_optimizer.cc][LINE:1385][THREAD:63823]         Call OptimizeFusedGraph failed, ret:1, engine_name:AIcoreEngine, graph_name:partition0_rank1_new_sub_graph2[FUNC:OptimizeSubGraph][FILE:graph_optimize.cc][LINE:126][THREAD:63823]         subgraph 0 optimize failed[FUNC:OptimizeSubGraphWithMultiThreads][FILE:graph_manager.cc][LINE:1021][THREAD:55783]         build graph failed, graph id:2, ret:1[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615][THREAD:55783]         [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161][THREAD:55783]         [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145][THREAD:55783]         build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145][THREAD:55783] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ccsrc/transform/acl_ir/acl_utils.cc:379 Run [ERROR] DEVICE(54175,fffdbcff91e0,python):2024102211:26:24.972.826 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge_kernel_executor.cc:1156] LaunchKernel] Launch kernel failed, kernel full name: Default/BitwiseOrop0 [ERROR] RUNTIME_FRAMEWORK(54175,ffff93ba20e0,python):2024102211:26:25.892.561 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:198] WorkerJoin] WorkerJoin failed: Launch kernel failed, name:Default/BitwiseOrop0   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/pynative/op_runner.cc:624 LaunchKernels",2024-10-22T03:34:15Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1761,cann版本： mindspore版本： mindnlp版本：,请给出具体版本，或者尝试最新版mindnlp+mindspore2.3.1
这是一个bug报告类型的issue，涉及到mindnlp库中的Linear模块。由于out_channels参数设置错误，导致模块运行异常。,fix out_channels of Linear,,2024-10-22T02:21:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1760
这是一个bug报告，主要涉及的对象是`nll_loss`函数。由于某种原因导致了反向传播错误，需要修复该问题。,fix nll_loss casued backward error,,2024-10-21T09:09:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1759
这个issue类型是bug报告，主要涉及的对象是mindnlp下的nn.Linear模块，由于命名错误导致了问题。,fix name  for nn.Linear,,2024-10-21T08:16:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1758
这是一个bug报告类型的issue，涉及主要对象为代码中的enable_grad功能。由于enable_grad功能存在问题导致bug，需要修复。,fix enable_grad,,2024-10-21T07:56:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1757
这是一个bug报告，涉及的主要对象是将预训练模型和配置对象结合起来，可能由于代码逻辑错误导致了报错信息中的 AttributeError。,AttributeError: 'Linear' object has no attribute 'in_channels',"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在进行将一个预训练模型和一个配置对象 peft_config 结合起来，返回一个适配了 PEFT（ParameterEfficient FineTuning）技术的模型对象的时候出现报错：AttributeError: 'Linear' object has no attribute 'in_channels'，显示 使用mindnlp.peft.mapping 模块中的 get_peft_model 函数时尝试访问 Linear 层的一个不存在的属性 in_channels 导致。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/ 规格：Ascend: 1*Ascend Snt9|ARM: 24核 96GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0  Python version (e.g., Python 3.7.5) :Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):aarch64  镜像：mindspore_2.2.12cann_7.0.1.1py_3.9euler_2.10.7aarch64snt3p  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '(Mindspore)虚拟环境的terminal' 2. Click on 'pip install [mindspore2.4.0cp39cp39linux_aarch64.whl]、pip install mindnlp0.4.0py3noneany.whl' 3. 出现包函数冲突：mindformers 1.0.0 requires pyarrow==12.0.1, but you have pyarrow 17.0.0 which is incompatible. mindformers 1.0.0 requires tokenizers==0.15.0, but you have tokenizers 0.19.1 which is incompatible. modelarts 1.4.25 requires lxml==5.1.0, but you have lxml 4.9.3 which is incompatible. modelarts 1.4.25 requires matplotlib==3.5.2, but you have matplotlib 3.5.1 which is incompatible. modelarts 1.4.25 requires networkx==2.6.3, but you have networkx 3.2.1 which is incompatible. modelarts 1.4.25 requires prettytable<=3.9.0, but you have prettytable 3.10.0 which is incompatible. modelarts 1.4.25 requires tqdm<=4.66.1, but you have tqdm 4.66.4 which is incompatible. modelarts 1.4.25 requires typingextensions==4.7.1, but you have typingextensions 4.11.0 which is incompatible. modelarts 1.4.25 requires urllib3==1.26.18, but you have urllib3 1.26.7 which is incompatible. 4. 尝试在（不管包冲突直接运行）、（删除mindformers后进行运行），均出现报错 5. Scroll down to '运行poly_mindspore.ipynb文件' 6. See error：AttributeError: 'Linear' object has no attribute 'in_channels' **Expected behavior / 预期结果 (Mandatory / 必填)** 成功将一个预训练模型和一个配置对象 peft_config 结合起来，返回一个适配了 PEFT（ParameterEfficient FineTuning）技术的模型对象 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !6031b0a1dd9d0eebb8356d037177fb58 以下是具体报错： !8de20a7a6fe0d1412cb7b8cf4bb55e47 !a55d84042459187e05adc1a5cf14adbb !845b429dc1b129e7a66fb6c9542216c6 !0bd0db6fbeb83852a48428c7e754cfad **Additional context / 备注 (Optional / 选填)** 我不知道是不是虚拟环境默认下载的包有冲突，所以后面打算尝试更换镜像的方式看看能不能找一个没有其他默认包的镜像。 以下是代码文件： poly_mindspore.zip",2024-10-21T07:28:47Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1756,虚拟环境包版本.txt,1. 必须用mindspore2.3+cann8.0 2. mindformers卸载掉 3. 用最新源码安装
这是一个bug报告，主要涉及OrangePi设备，issue提出的问题是避免在OrangePi上缺少cumsum运算符。原因可能是OrangePi设备上缺少相关运算符或支持库，导致无法执行cumsum操作。,avoid lack of cumsum operator on OrangePi,,2024-10-21T03:56:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1755
这是一个bug报告，主要涉及的对象是mindnlp库中的代码。这个问题产生的原因可能是未正确设置no_grad状态导致出现错误。,fix no_grad state error,,2024-10-21T03:23:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1754
这是一个用户提出需求的issue， 主要对象是支持模型合并功能。 由于描述不完整，导致无法确定具体问题或需求。,new feature: support model merge.,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-10-21T03:18:53Z,requirement feature,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1753,xingyiren TJHsiao wuyiqun tridu33 goodman li_yuanqing cuihuating yangyucheng000 qeevee xuhang Jiangna123 YH77 moyu zhaoyu
这是一个类型为bug报告的issue，涉及主要对象是模型训练步骤的kernel和Ascend，可能是由于Kernel error导致的训练失败。,模型训练步骤kernel和Ascend报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** Kernel error:  Launch kernel failed: Bprop/gradDense/Reshapeop278   Ascend Error Message:  E39999: Inner Error! E39999: 2024102022:34:40.965.193  The error from device(chipId:0, dieId:0), serial number is 3, an exception occurred during AICPU execution, stream_id:2, task_id:19016, errcode:21008, msg:inner error.[FUNC:ProcessStarsAicpuErrorInfo][FILE:device_error_proc.cc][LINE:1232][THREAD:123358]         TraceBack (most recent call last):         Kernel task happen error, retCode=0x2a, [aicpu exception].[FUNC:PreCheckTaskErr][FILE:task_info.cc][LINE:1776][THREAD:123358]         AICPU Kernel task happen error, retCode=0x2a.[FUNC:GetError][FILE:stream.cc][LINE:1512][THREAD:123358]         Aicpu kernel execute failed, device_id=0, stream_id=2, task_id=19016, errorCode=2a.[FUNC:PrintAicpuErrorInfo][FILE:task_info.cc][LINE:1579][THREAD:123358]         Aicpu kernel execute failed, device_id=0, stream_id=2, task_id=19016, fault op_name=[FUNC:GetError][FILE:stream.cc][LINE:1512][THREAD:123358]         rtMemcpyAsync execute failed, reason=[aicpu exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53][THREAD:123358]         asynchronized memcpy failed, kind = 3, runtime result = 507018[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161][THREAD:123358]  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore 2.3.1:  Python version 3.9 :  euler 2.10.7:  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** lora_seq2seq.ipynb中 训练模块运行会报错 **Expected behavior / 预期结果 (Mandatory / 必填)** 修复bug **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-20T23:44:25Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1752,把具体是什么硬件写上,硬件 ： Ascend: 1*ascendsnt9b1|ARM: 24核 192GB lora_seq2seq.txt
这是一个bug报告类型的issue。主要涉及的对象是在image_classification_timm_peft_lora中出现KeyError: 'per_gpu_train_batch_size'错误。,KeyError: 'per_gpu_train_batch_size',"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在image_classification_timm_peft_lora模型微调任务时，训练这一步报错：KeyError: 'per_gpu_train_batch_size'，但是在args中两句代码是这样的：`per_device_train_batch_size=batch_size，per_device_eval_batch_size=batch_size`并没有问题。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version  :2.3.1  Python version  :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** ``` args = TrainingArguments(     f""{model_name}finetunedlorafood101"",     remove_unused_columns=False,     evaluation_strategy=""epoch"",     save_strategy=""epoch"",     learning_rate=5e3,     per_device_train_batch_size=batch_size,     gradient_accumulation_steps=4,     per_device_eval_batch_size=batch_size,     fp16=True,     num_train_epochs=5,     logging_steps=10,     load_best_model_at_end=True,     metric_for_best_model=""accuracy"",      push_to_hub=True,     label_names=[""labels""], ) ``` ``` trainer = Trainer(     lora_model,     args,     train_dataset=train_ds,     eval_dataset=val_ds,     tokenizer=image_processor,     compute_metrics=compute_metrics, ) train_results = trainer.train() ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 训练结果 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-20T06:08:19Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1751,把复现代码附上，，,KeyError 'per_gpu_train_batch_size'.zip 是训练的时候出错，这是整个代码
这是一个bug报告，关于Mindnlp中的Transformer不一致问题的讨论。由于loss收敛趋势与Transformer不一致，用户提出了问题。,loss收敛趋势与Transformer不一致,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在进行`multilayer_perceptron_lora`模型微调任务时，发现在各参数与Transformer库源码保持一致的情况下，使用MindNLP库进行实现，训练得到的loss结果与Transformer实现的出现较大差异，收敛趋势不同。 疑似使用Transformer库进行实现的程序出现了过拟合现象。 pr链接：https://github.com/mindsporelab/mindnlp/pull/1749  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version : 2.3.1  Python version: 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 运行mindnlp/llm/peft/multilayer_perceptron/multilayer_perceptron_lora.ipynb文件，观察训练情况 **Expected behavior / 预期结果 (Mandatory / 必填)** 使用Transformer库得到的训练结果如下： !QQ_1729248325706 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 使用MindNLP库得到的训练结果如下： !QQ_1729248379548 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-18T10:52:45Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1750
这个issue类型是模型微调的任务，涉及到multilayer_perceptron_lora模型，用户报告了训练结果的对比。,【开源实习】multilayer_perceptron_lora模型微调,任务链接：https://gitee.com/mindspore/community/issues/IAN1W9note_31276633 训练结果对比： !d04e2ab3638bd4a258585026324ed174 疑似Transformer源代码出现了过拟合,2024-10-18T10:26:51Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1749,目录放到llm/peft/lora
这是一个bug报告，涉及peft_adalora_seq2seq模型微调时调用update_and_allocate接口导致报错的问题。原因可能是没有加入正确的u参数导致的。,peft_adalora_seq2seq接入update_and_allocate接口报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在测试peft_adalora_seq2seq模型微调跑训练时，不加入update_and_allocate接口准确率比pytorch低很多为42% A clear and concise description of what the bug is. model.base_model.update_and_allocate(global_step,grads)接口出现以下报错 !Screenshot 20241017 221832 pytorch中update_and_allocate()接口不需要grads形参，而mindnlp中需要，但是接入grads时出现typererror  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  mindspore2.3.1 midnnlpdaily python3.9  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 已经提pr **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-18T04:12:31Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1748
这是一个bug报告，主要涉及到mindnlp中的peft_adalora_seq2seq模型微调，由于接口不对齐导致运行时出现问题。,【开源实习】peft_adalora_seq2seq模型微调,"model.base_model.update_and_allocate(global_step,grads)这个接口和pytorch不对齐，这是注释了之后跑的，准确率不高",2024-10-17T14:15:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1747
这是一个用户提出需求的类型，主要对象是项目的文档（readme.md），用户想要增加一个目录来提高文档的导航性。,add toc in readme.md,Added a table of contents in the doc for better navigation,2024-10-17T13:48:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1746
这是关于X_CLIP模型与torch版本结果不一致的bug报告，用户提出了该问题。,X_CLIP模型与torch版本结果不一致,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 见pr：https://github.com/mindsporelab/mindnlp/pull/1694issuecomment2406677804 pytorch的结果和MindSpore的结果误差较大  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :`2.3.1`  MindNLP version :`0.4.0`  Python version (e.g., Python 3.7.5) :`Python 3.9.10`  OS platform and distribution (e.g., Linux Ubuntu 16.04):`4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch6`  GCC/Compiler version (if compiled from source):`7.3.0`  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 跑pr的代码 **Expected behavior / 预期结果 (Mandatory / 必填)** 精度相差差不多 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** pytorch: ![](https://privateuserimages.githubusercontent.com/38277217/37565549949c504a40bd4487880fab894fded20c2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjkxNjYxMDAsIm5iZiI6MTcyOTE2NTgwMCwicGF0aCI6Ii8zODI3NzIxNy8zNzU2NTU0OTktNDljNTA0YTQtMGJkNC00ODc4LTgwZmEtYjg5NGZkZWQyMGMyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEwMTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMDE3VDExNTAwMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI1M2UxNmUzNmViYTc2MzFiOThiYzYyODVhZDg2NTgzMjNhMTkxZGQ4NzYwMDQ4OGMzYzBlOGFkYTdlNjhkYTEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.vLHi7CPv6i3X8BU52hzjF8gnBKFU92TTAzKJc4Zfv4) MindSpore: ![](https://privateuserimages.githubusercontent.com/38277217/37565549949c504a40bd4487880fab894fded20c2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjkxNjYxMDAsIm5iZiI6MTcyOTE2NTgwMCwicGF0aCI6Ii8zODI3NzIxNy8zNzU2NTU0OTktNDljNTA0YTQtMGJkNC00ODc4LTgwZmEtYjg5NGZkZWQyMGMyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEwMTclMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMDE3VDExNTAwMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWI1M2UxNmUzNmViYTc2MzFiOThiYzYyODVhZDg2NTgzMjNhMTkxZGQ4NzYwMDQ4OGMzYzBlOGFkYTdlNjhkYTEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.vLHi7CPv6i3X8BU52hzjF8gnBKFU92TTAzKJc4Zfv4) **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-10-17T11:56:25Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1745,自己应该修复了，原因是官方示例是用decord写的视频提取，而这个在Arm架构上无法安装，于是我觉得使用opencv写，可是没把BGR通道转换为RGB。
这是一个bug报告，主要对象是mindnlp下的O2客户端在OrangePi上的性能问题，用户反馈从450ms降到160ms。可能是由于硬件兼容性或程序优化不足导致。,"support O2 on OrangePi, tinyllama 450ms -> 160ms",,2024-10-16T09:55:41Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1744,!image
"这是一个标题为""推理baichuan报错""的Github issue，主要描述硬件环境和问题类型为bug报告，具体原因导致了推理Baichuan时出现错误的症状。",推理baichuan报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** ``` Traceback (most recent call last):   File ""/home/mauser/work/inferbaichuan.py"", line 6, in      model = BaiChuanForCausalLM.from_pretrained(""baichuaninc/Baichuan13BChat"",mirror='modelscope',ms_dtype=ms.float16, size='13b')   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 2918, in from_pretrained     model = cls(config, *model_args, **model_kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1658, in __init__     self.model = BaiChuan13bModel(config)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1433, in __init__     self.layers = nn.ModuleList([BaiChuanLayer(config) for _ in range(config.num_hidden_layers)])   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1433, in      self.layers = nn.ModuleList([BaiChuanLayer(config) for _ in range(config.num_hidden_layers)])   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 1044, in __init__     self.input_layernorm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/baichuan/modeling_baichuan.py"", line 377, in __init__     self.weight = Parameter(ops.ones(hidden_size), 'weight')   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/core/nn/parameter.py"", line 12, in __init__     self.param_info.requires_grad = requires_grad TypeError: (): incompatible function arguments. The following argument types are supported:     1. (arg0: mindspore._c_expression.ParamInfo, arg1: bool) > None Invoked with: , 'weight' ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :`2.3.1`,`2.4.0`我也试过不行  MindNLP version :`0.4.0`，试过11.4为止的每日版本也不行  Python version (e.g., Python 3.7.5) :`Python 3.9.10`  OS platform and distribution (e.g., Linux Ubuntu 16.04):`4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch6`  GCC/Compiler version (if compiled from source):`7.3.0`  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 1. 部署好环境 2. 跑baichuan_13b.py ``` import mindspore as ms from mindnlp.transformers import BaiChuanForCausalLM, BaiChuanTokenizer from mindnlp.transformers.generation.utils import GenerationConfig  ms.set_context(pynative_synchronize=True) tokenizer = BaiChuanTokenizer.from_pretrained(""baichuaninc/Baichuan13BChat"") model = BaiChuanForCausalLM.from_pretrained(""baichuaninc/Baichuan13BChat"", ms_dtype=ms.float16, size='13b') texts = '请问你是谁？' input_ids = tokenizer(texts, return_tensors=""ms"") print(input_ids) print(f'input_ids[""input_ids""].shape:{input_ids[""input_ids""].shape}') outputs = model(input_ids=input_ids['input_ids']) print(outputs) print(outputs[0].shape) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 能够推理 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !微信截图_20241015105341 **Additional context / 备注 (Optional / 选填)** 无",2024-10-15T02:54:29Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1743,测试已通过
该issue类型为需求提出，主要涉及的对象是GPT-J-6B模型应用开发。由于图片链接无法正常显示，用户可能寻求解决图片加载问题或相关帮助。,【开源实习】GPT-J-6B模型应用开发,!83967234bc488d0550e778878234d2d9 !image !image !image,2024-10-14T14:50:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1742
这是一个功能需求提出的issue，主要对象是paddle支持的generate方法，用户希望增加返回序列scores的选项。原因可能是用户希望更多信息用于生成文本序列。,对于模型的generate方法的需求,paddle支持的generate方法会直接返回ids，能否设置可以返回对应序列scores的选项，而不是只返回最后的累计score,2024-10-14T13:02:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1741
这是一个bug报告类型的issue， 主要涉及文档中出现的拼写错误。造成这个问题的原因可能是疏忽导致了文档中的拼写错误。,Fix typing mistakes in documentation,,2024-10-14T12:21:52Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1740,hey please assign me this issue I'd love to work on this
这个issue属于需求类型，主要对象为要求添加名为finetune_blip.ipynb的新文件。,add new file finetune_blip.ipynb,,2024-10-14T10:19:05Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1739,？？？？
这是一个请求迁移项目的类型的问题，主要涉及到minimind项目。由于用户希望能够在香橙派aipro上运行大模型以获得更好的体验，因此提出了这个请求。,大佬可以迁移minimind吗 可以让香橙派aipro跑大模型有更好的体验,这是minimind的github仓库链接https://github.com/jingyaogong/minimind 个人尝试过千问以及chatglm在香橙派aipro上量化运行，但是效率过低。 一次无意间的浏览发现了minimind这个小模型，觉得很适合香橙派aipro上面运行。 恳请各位大佬可以迁移minimind与minimindv 能让他们在香橙派上运行 感谢,2024-10-14T10:06:07Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1738
这是一个bug报告，涉及的主要对象是llama-3模型与torch版本结果不一致。由于可能存在代码实现差异或模型参数设置不一致等原因，导致了结果不一致的问题。,llama-3模型与torch版本结果不一致,"复现代码如下:  ```python from mindspore import set_context set_context(device_target=""GPU"",device_id=1) from transformers import AutoModelForCausalLM as PT_AutoModelForCausalLM from transformers import AutoTokenizer as PT_AutoTokenizer from mindnlp.transformers import AutoModelForCausalLM as MS_AutoModelForCausalLM from mindnlp.transformers import AutoTokenizer as MS_AutoTokenizer model_path = ""/data00/jiajie_jin/model/LLaMA38bInstruct"" generation_params = {'do_sample': False, 'max_new_tokens': 100, 'eos_token_id': [128001, 128009]} prompt = ""system\n\nAnswer the question based on your own knowledge. Only give me the answer and do not output any other words.user\n\nQuestion: What is Osbert Lancaster best known for producing?assistant\n\n"" ms_model = MS_AutoModelForCausalLM.from_pretrained(model_path) ms_tokenizer = MS_AutoTokenizer.from_pretrained(model_path) ms_tokenizer.pad_token = ms_tokenizer.eos_token ms_input = ms_tokenizer(prompt,                                     return_tensors=""ms"",                   padding=True,                   truncation=True,                   max_length=512                   ) ms_outputs = ms_model.generate(     **ms_input,     output_scores=True,     return_dict_in_generate=True,     **generation_params ) ms_response = ms_tokenizer.decode(ms_outputs.sequences[0],                 skip_special_tokens=True,                 clean_up_tokenization_spaces=False) pt_model= PT_AutoModelForCausalLM.from_pretrained(model_path) pt_tokenizer = PT_AutoTokenizer.from_pretrained(model_path) pt_model.to(""cuda:2"") pt_model.eval() pt_tokenizer.pad_token = pt_tokenizer.eos_token pt_input = pt_tokenizer(prompt,                                     return_tensors=""pt"",                   padding=True,                   truncation=True,                   max_length=512                   ).to(""cuda:2"") pt_outputs = pt_model.generate(     **pt_input,     output_scores=True,     return_dict_in_generate=True,     **generation_params ) pt_response = pt_tokenizer.decode(pt_outputs.sequences[0],                 skip_special_tokens=True,                 clean_up_tokenization_spaces=False) print("" MS RESPONSE:"") print(ms_response) print("" MS RESPONSE:"") print(pt_response) ``` 结果如下： !image",2024-10-14T07:52:43Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1737
这是一个提出需求类的issue，主要对象是更新readme文件。,update readme,,2024-10-14T04:11:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1736
这个issue属于bug报告类型，涉及主要对象是mllama ut。由于修复问题，可能导致mllama ut功能无法正常运作。,fix mllama ut,,2024-10-14T02:59:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1735
这是一个bug报告，主要对象是mindnlp库下的bloom kv cache，可能由于某种原因导致了错误。,fix bloom kv cache error,,2024-10-13T16:08:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1734
"这是一个bug报告，涉及的主要对象是""gptj and F style ckpt load""。这个问题可能是由于加载GPTJ和F类型的checkpoint文件时出现了问题，导致无法正确加载模型或者出现错误。",fix gptj and F style ckpt load,,2024-10-13T15:08:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1733
这是一个需求类型的issue，主要涉及的对象是更新名为prompt_direct.txt的文件。由于未提供具体内容，导致用户需要更新此文件时无法得到准确的指导或提示。,Update prompt_direct.txt,,2024-10-13T14:20:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1732
"这是一个bug报告类型的issue，主要涉及的对象是mindnlp中的b, d, m, s类。原因可能是代码中的错误导致了这些类的功能异常或者出现问题，用户希望修复这些问题。","fix b,d,m,s class ut",,2024-10-12T15:16:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1731
这是一个bug报告，主要涉及的对象是名为q class ut的模块。由于未提供具体内容，可能是寻求对该模块中的问题进行修复。,fix q class ut,,2024-10-12T07:24:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1730
这是一个用户提出需求的issue，主要涉及的对象是改进 README.md 文件。原因可能是用户希望更清晰地展示项目的信息，提高文档的质量。,Improved README.md,,2024-10-12T05:35:20Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1729,??
这是一个bug报告，主要涉及的对象是q类UT。原因可能是代码逻辑错误导致了该bug。,fix q class ut,,2024-10-12T03:40:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1728
这是一个bug报告，主要涉及mindnlp下的l class ut类。由于代码中的错误导致了修复l class ut类的问题。,fix l class ut,,2024-10-11T14:43:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1727
这是一个bug报告，主要涉及的对象是BgeM3Model。由于注册BgeM3Model &运算符不支持bool操作，导致mindspore.ops.unique与mindnlp.core.unique返回值不同。,fix: fix BgeM3Model,注册BgeM3Model &运算符不支持bool mindspore.ops.unique与mindnlp.core.unique返回值不同,2024-10-11T12:18:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1726
这是一个用户提出需求的issue，主要涉及的对象是Speech2Text模型迁移，用户寻求关于该任务的实习机会。,【开源实习】Speech2Text模型迁移,任务链接： https://gitee.com/mindspore/community/issues/I9UZW2,2024-10-11T07:36:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1725
这是一个用户提交的需求，要求开发VideoMAE模型应用，涉及MindSpore和PyTorch推理结果对比的问题。,【开源实习】VideoMAE模型应用开发, mindspore推理结果：   pytorch推理结果： ,2024-10-11T05:14:21Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1724,AI gallery：https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=9740ab2466784fd381054f1929d17bc2
这个issue类型是bug报告，涉及的主要对象是GroupViT模型应用开发。由于推理结果错误导致的问题。,【开源实习】GroupViT模型应用开发,pytorch推理结果 !256955dba86b7de6a2d8edb3ffe5d12 minmindnlp推理结果 !aec83b79e0e5749ba3c243656c6ed29,2024-10-10T12:13:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1723
该issue类型为软件需求，涉及Unispeech模型迁移，用户寻求帮助将模型迁移到另一个平台。,【开源实习】Unispeech模型迁移,,2024-10-10T10:13:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1722
该issue属于bug报告，涉及的主要对象是modelarts，该问题是由于修复rank_table导致在modelarts中出现了内存分配问题。,fix rank_table caused memory allocate problem in modelarts,,2024-10-10T09:56:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1721
这是一个用户提出需求的issue，主要涉及OrangePi上支持静态图，可能是由于当前系统不支持静态图功能，用户希望在OrangePi上使用此功能。,support static graph on OrangePi,,2024-10-09T15:35:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1720
这个issue类型是bug报告，该问题单涉及的主要对象是PatchTSMixer模型迁移。由于跑slow导致屏幕截图显示异常，用户提出了关于此问题的反馈。,【开源实习】PatchTSMixer模型迁移,跑slow截图 !屏幕截图 20241009 160528 !屏幕截图 20241009 160546,2024-10-09T09:37:20Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1719,rebase一下最新代码，去掉print就可以合入,已完成rebase最新代码，并去掉print
这是一个用户提出需求的issue，主要涉及 llama 支持静态图。原因可能是用户希望 llama 能够对静态图进行支持。,llama support static graph,,2024-10-09T08:47:48Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1718, llama27b (910A):  bind cpu:  **pynative+dynamic cache**: 85ms  **pynative+static cache**: 95ms  **jit + static cache**: 43ms(compile 30s)  not bind cpu:  **pynative+static cache**: 130ms  **jit + static cache**: 45ms(compile 50s)
这个issue属于合作开发类型，主要涉及UPerNet模型应用开发。,【开源实习】UPerNet模型应用开发, 任务链接：https://gitee.com/mindspore/community/issues/IAT0TT?from=projectissue  参考链接：https://github.com/NielsRogge/TransformersTutorials/blob/master/UPerNet/Perform_inference_with_UperNetForSemanticSegmentation_(Swin_backbone).ipynb,2024-10-09T08:24:02Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1717,AI gallery地址：https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=7075f92b479e42e69428a9c5ed76a689, Pytorch推理结果：   MindSpore推理结果： ,环境设置章节已去除
"这是一个bug报告，涉及的主要对象是""patchtsmixer模型迁移""，用户提出了跑slow的截图导致的问题。",patchtsmixer模型迁移,跑slow的截图!屏幕截图 20241009 160528 !屏幕截图 20241009 160546,2024-10-09T08:07:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1716
这是一个bug报告，涉及Mixtral ut功能。可能由于Mixtral ut未通过导致用户提交该问题。,Mixtral ut未通过,!image,2024-10-09T07:48:21Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1715,当`INFERENCE_TIME_RECORD=1`的时候，会遇到mixtral ut的两个test没有通过:  
"这是一个bug报告，主要涉及的对象是mindnlp库中的""g class ut""功能。这个问题可能是由于程序代码出现错误或者逻辑不完善导致的。",fix g class ut,,2024-10-09T05:41:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1714
这是一个bug报告，主要涉及的对象是c和x类。由于修复c和x类的一些问题，导致现在的症状有bug。,fix c and x class ut,,2024-10-08T02:51:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1713
这个issue是关于bug报告， 主要对象是加载GroupViTModel预训练模型时出现runtimeerror，可能是由于模型加载过程中的错误导致的。,加载GroupViTModel预训练模型时出现runtimeerror,"**复现代码** from mindnlp.transformers import AutoProcessor, GroupViTModel model_name = ""nvidia/groupvitgccyfcc"" model = GroupViTModel.from_pretrained(model_name) **Describe the bug/ 问题描述 (Mandatory / 必填)** 加载GroupViTModel预训练模型时出现runtimeerror RuntimeError: Error(s) in loading state_dict for GroupViTModel: 	size mismatch for logit_scale: copying a param with shape () from checkpoint, the shape in current model is (1,). 	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method. !image !image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: cpu  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.4.0  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): ubuntu22.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: **To Reproduce / 重现步骤 (Mandatory / 必填)** from mindnlp.transformers import AutoProcessor, GroupViTModel model_name = ""nvidia/groupvitgccyfcc"" model = GroupViTModel.from_pretrained(model_name) **Expected behavior / 预期结果 (Mandatory / 必填)** **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image",2024-10-07T16:03:45Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1712,fixed
"这个issue是一个bug报告，涉及的主要对象是名为""whisper ut""的功能。由于某种原因导致了""whisper ut""存在问题，需要修复。",fix whisper ut,,2024-10-07T13:35:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1711
这个issue属于bug报告类型，主要涉及r和v class在ut时失败。可能由于代码错误或逻辑错误导致了这个bug。,fix r and v class failed ut,,2024-10-06T08:36:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1710
"这是一个拼写错误的修复问题，涉及到项目中的测试工具代码。原因可能是疏忽导致了单词""occurred""的拼写错误。",chore: update testing_utils.py,occured > occurred,2024-10-05T16:07:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1709
这是一个bug报告，涉及到了在CPU上避免Tapas出错的问题。由于一些特定原因，用户遇到了Tapas相关的错误或问题，寻求相关帮助和解决方案。,avoid tapas error on CPU,,2024-10-05T08:20:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1708
这个issue类型是bug报告，该问题单涉及的主要对象是fixing adalora。由于某种原因导致了bug，需要修复。,fix adalora,,2024-10-05T07:36:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1707
这是一个bug报告，主要涉及的对象是代码中的import错误。原因可能是代码中的import语句错误导致了无法找到相应的模块或函数。,fix some import error,,2024-10-05T06:37:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1706
这个issue是关于bug报告，主要涉及到fix st and ut on MS2.2，可能由于代码逻辑错误导致了st和ut无法正常工作或产生预期之外的结果。,fix st and ut on MS2.2,,2024-10-05T03:53:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1705
"这是一个用户提出需求的issue，主要对象是添加名为""chinese_clip""的功能。由于用户需要该功能来处理中文文本，因此提出了这个需求。",add chinese_clip,,2024-10-05T02:30:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1704
这是一个bug报告类型的issue，主要涉及了在执行CI过程中出现的问题，其中可能是由于依赖安装错误导致ut跳过或出错。,本地测试通过后，在线提交PR时，运行CI过程中出现的问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 执行CI过程中出现以下问题： 1. ut有些跳过，有些在安装依赖时出错 !1 2. release test在pytest时出错 !2 3. 单个模型测试时，没有改动的模型出现测试失败（没有对报错的文件进行修改） !3 4. 单个模型测试时，直接跳过有些模型（speech_to_text模型迁移，但是CI直接跳过，没有测试对应部分） !4  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > /device CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): windows11  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** **Expected behavior / 预期结果 (Mandatory / 必填)** 解决图片中描述的问题 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** **Additional context / 备注 (Optional / 选填)**",2024-10-01T14:08:01Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1703,fixed
这是一个用户提出需求的issue，主要涉及Speech2Text模型的迁移，用户寻求开源实习的相关帮助。,【开源实习】Speech2Text模型迁移,任务链接： https://gitee.com/mindspore/community/issues/I9UZW2,2024-09-30T04:58:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1702
这是一个用户提出需求的issue，主要涉及的对象是为mindnlp添加dpo trainer和支持dpo训练。,【开源之夏】add dpo trainer and support dpo training for mindnlp,先提一个pr，最近修改完毕并合入。,2024-09-29T12:46:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1701
这是一个用户提出需求的类型，主要涉及到开源实习的ImageGPT模型应用开发。由于用户寻求关于在华为云AI gallery上开发该模型的帮助而产生。,【开源实习】ImageGPT模型应用开发,issue：https://gitee.com/mindspore/community/issues/IAADIT 华为云AI gallery 链接：https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=c44ead81dbff40f1a430d83fe1066291,2024-09-29T06:04:46Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1700,!20241009100553(WeLinkPC) 文字描述不清晰,!20241009100903(WeLinkPC) 类似安装的输出结果通过%%capture captured_output命令屏蔽掉,!20241009101059(WeLinkPC) 排查整个文档，空的cell单元格都删掉,已更新修改，同步更新的华为云AI gallery：https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=c44ead81dbff40f1a430d83fe1066291,** 原Tutorials仓库（pytorch）实现的两个应用演示：** 1. 非条件生成图片（预训练模型随机生成图片） !image 2. 条件生成：模型根据半张图生成全图的多张预测 !image !image ** mindnlp接口复现类似的应用演示：** 1. 随机生成 !image 2. 条件生成 !image !image,涉及到环境安装的部分都去掉，打印整屏的那些help也不需要
这是一个用户提出需求的类型，该问题单涉及的主要对象是Unispeech模型迁移。,【开源实习】Unispeech模型迁移,,2024-09-28T09:28:47Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1699,pytest和pylint已过，可以CI测试一下
这是一个bug报告类型的issue，涉及的主要对象是kernel和Ascend，原因可能是Launch kernel failed导致无法执行Bprop/gradDens操作。,kernel error和Ascend error,"**Describe the bug/ 问题描述 (Mandatory / 必填)** Launch kernel failed: Bprop/gradDense/Reshapeop278 The error from device(chipId:0, dieId:0), serial number is 13, an exception occurred during AICPU execution, stream_id:2, task_id:19016, errcode:21008, msg:inner error.[FUNC:ProcessStarsAicpuErrorInfo][FILE:device_error_proc.cc][LINE:1232] mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:917 ExecuteLaunchKernelTask  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.3.1  Python 3.9.10 :  Euler 3.9  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** lora_seq2seq文件里训练评估部分的代码运行会报错 **Expected behavior / 预期结果 (Mandatory / 必填)** 解决error **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !69c06c89694a301fd921f07855294da **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-28T07:17:43Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1698,910B还是910A,提供下代码吧
这是一个bug报告，涉及加载gptj-6b预训练模型时出现的卡顿和kernel崩溃问题。,加载gptj-6b的预训练模型的时候一直卡着不动，kernel崩溃,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 加载gptj6b的预训练模型的时候一直卡着不动，kernel崩溃  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version2.4.0 :  Python version 3.9 :  OS platform and distribution ubuntu22.04:  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: from mindnlp.transformers import GPTJForCausalLM, AutoTokenizer model = GPTJForCausalLM.from_pretrained(""EleutherAI/gptj6B"", revision=""float16"", low_cpu_mem_usage=True) tokenizer = AutoTokenizer.from_pretrained(""EleutherAI/gptj6B"") **Expected behavior / 预期结果 (Mandatory / 必填)** 正常导入模型 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !a57fec6c0547992592726ed143905014 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-27T16:28:00Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1697
这是一个 bug 报告，主要涉及到模块导入错误导致找不到相应的模块。,ModuleNotFoundError: No module named 'mindnlp.transformers.models.chinese_clip',"**Describe the bug/ 问题描述 (Mandatory / 必填)** ModuleNotFoundError: No module named 'mindnlp.transformers.models.chinese_clip' 和RuntimeError: Error(s) in loading state_dict for GroupViTModel: 	size mismatch for logit_scale: copying a param with shape () from checkpoint, the shape in current model is (1,). 	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.4.0 : mindnlp源码  Python version 3.9 :  ubuntu22.04:  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: **To Reproduce / 重现步骤 (Mandatory / 必填)** from mindnlp.transformers import AutoProcessor, GroupViTModel model_name = ""nvidia/groupvitgccyfcc"" processor = AutoProcessor.from_pretrained(model_name) model = GroupViTModel.from_pretrained(model_name) **Expected behavior / 预期结果 (Mandatory / 必填)** 啥也没有 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image 1.log 2.log **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-27T16:22:30Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1696
这是一个bug报告，主要涉及对象为mindnlp中的transformers模块。由于模块缺失导致了ModuleNotFoundError的错误。,ModuleNotFoundError: No module named 'mindnlp.transformers.models.chinese_clip',"**复现代码** from mindnlp.transformers import AutoProcessor, GroupViTModel model_name = ""nvidia/groupvitgccyfcc"" processor = AutoProcessor.from_pretrained(model_name) model = GroupViTModel.from_pretrained(model_name) **Describe the bug/ 问题描述 (Mandatory / 必填)** ModuleNotFoundError: No module named 'mindnlp.transformers.models.chinese_clip' 和RuntimeError: Error(s) in loading state_dict for GroupViTModel: 	size mismatch for logit_scale: copying a param with shape () from checkpoint, the shape in current model is (1,). 	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.4.0 : mindnlp源码  Python version 3.9 :  ubuntu22.04:  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: **To Reproduce / 重现步骤 (Mandatory / 必填)** from mindnlp.transformers import AutoProcessor, GroupViTModel model_name = ""nvidia/groupvitgccyfcc"" processor = AutoProcessor.from_pretrained(model_name) model = GroupViTModel.from_pretrained(model_name) **Expected behavior / 预期结果 (Mandatory / 必填)** 啥也没有 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image 1.log 2.log **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-27T16:09:51Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1695
这个issue类型为需求提出，主要涉及X_CLIP模型应用开发。由于用户想要进行X_CLIP模型应用开发，所以提出了这个问题。,【开源实习】X_CLIP模型应用开发, issue: https://gitee.com/mindspore/community/issues/IAAMF7  华为云AI gallery 链接: https://developer.huaweicloud.com/develop/aigallery/notebook/detail?id=d519074534444e99a6b21c6acc36fc56,2024-09-27T12:24:39Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1694,附一下pytorch的结果截图和MindSpore的结果截图对比,> 附一下pytorch的结果截图和MindSpore的结果截图对比 pytorch: !微信截图_20241011145703 MindSpore: !微信截图_20241011145730,pytorch的结果和MindSpore的结果误差较大，不满足预期，需要提issue跟进,> pytorch的结果和MindSpore的结果误差较大，不满足预期，需要提issue跟进 已修复，这是现在MindSpore的： !微信截图_20241024205940 现在差异很少，注意是e4次哈，也肯定存在，因为原生的视频提取库无法在Arm上安装，只能自己写一个,验收通过，可以合入
这是一个bug报告，主要涉及Mindspore2.3.0 API在accelerate的state.py中报错ModuleNotFoundError。该问题可能是由于模块未找到导致的。,Mindspore2.3.0 API不兼容,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在accelerate的state.py中，报错ModuleNotFoundError:No module named 'mindspore.comm func‘，但切换到MindSpore 2.3.1正常，没有向下兼容  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Ascend 910b4  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : MindSpore 2.3.0  Python version (e.g., Python 3.7.5) : python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch64  GCC/Compiler version (if compiled from source): gcc 7.3  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 在终端执行类似`from mindnlp.transformers import XCLIPProcessor`就报错 **Expected behavior / 预期结果 (Mandatory / 必填)** 正常运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !D1279EAED196A3080A74B1627AA4F799 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-27T11:01:47Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1693
这是一个需求类型的issue，主要涉及mllama和yoso的支持和修复。可能由于两者之间的兼容性问题或功能缺失导致用户需要提出这个问题。,support mllama and fix yoso,,2024-09-27T08:03:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1692
这个issue属于bug报告类型，主要涉及train_adalora_seq2seq模型微调时出现错误AttributeError: 'Linear' object has no attribute 'in_channels'，可能由于代码中使用了不正确的属性导致。,跑train_adalora_seq2seq模型微调时出现错误AttributeError: 'Linear' object has no attribute 'in_channels',"**Describe the bug/ 问题描述 (Mandatory / 必填)** !Screenshot 20240927 132609 !Screenshot 20240927 132602 A clear and concise description of what the bug is. 报错：AttributeError: 'Linear' object has no attribute 'in_channels'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend > /device ascend/GPU/CPU/kirin/等其他芯片 device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  mindnlp0.4   MindSpore version (e.g., 1.7.0.Bxxx) : mindspore2.3.1  Python version (e.g., Python 3.7.5) : 3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04): EluerOS  GCC/Compiler version (if compiled from source): **To Reproduce / 重现步骤 (Mandatory / 必填)** 简单示例如下，调用的facebook/bartbase模型 import os os.environ['HF_ENDPOINT'] = 'https://hfmirror.com' os.environ[""KMP_DUPLICATE_LIB_OK""]=""TRUE"" from mindnlp.transformers import AutoModelForSeq2SeqLM model_name_or_path = ""facebook/bartbase"" from mindnlp.peft import AdaLoraConfig, TaskType, get_peft_model model = AutoModelForSeq2SeqLM.from_pretrained(model_name_or_path) peft_config = AdaLoraConfig(     init_r=12,     target_r=8,     beta1=0.85,     beta2=0.85,     tinit=200,     tfinal=1000,     deltaT=10,     lora_alpha=32,     lora_dropout=0.1,     task_type=TaskType.SEQ_2_SEQ_LM,     inference_mode=False, ) model = get_peft_model(model, peft_config)",2024-09-27T05:42:47Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1691
这是一个bug报告，该问题涉及参数命名冲突错误，导致了ValueError的出现。,ValueError: 参数命名冲突错误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在运行程序时遇到ValueError，参数命名冲突的错误。 ValueError: The value Parameter (name=Parameter, shape=(1024, 768), dtype=Float32, requires_grad=True) , its name 'Parameter' already exists. Please set a unique name for the parameter.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: NPU: 1*AscendD910B(显存: 64GB), CPU: 24, 内存: 192GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version : Mindspore2.3.1  Python version  : Python3.9 **To Reproduce / 重现步骤 (Mandatory / 必填)** `from mindspore import ops from mindnlp.transformers import GPT2LMHeadModel class GPT2ForSummarization(GPT2LMHeadModel):     def construct(         self,         input_ids = None,         attention_mask = None,         labels = None,     ):         outputs = super().construct(input_ids=input_ids, attention_mask=attention_mask)         shift_logits = outputs.logits[..., :1, :]         shift_labels = labels[..., 1:]          Flatten the tokens         loss = ops.cross_entropy(shift_logits.view(1, shift_logits.shape[1]), shift_labels.view(1), ignore_index=tokenizer.pad_token_id)         return loss from mindspore import nn from mindnlp.transformers import GPT2Config, GPT2LMHeadModel config = GPT2Config(vocab_size=len(tokenizer)) model = GPT2ForSummarization(config) lr_scheduler = LinearWithWarmUp(learning_rate=learning_rate, num_warmup_steps=warmup_steps, num_training_steps=num_training_steps) optimizer = nn.AdamWeightDecay(model.trainable_params(), learning_rate=lr_scheduler)` **Expected behavior / 预期结果 (Mandatory / 必填)** 正常运行。 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image",2024-09-26T10:23:13Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1690,mindnlp版本：mindnlp0.4.0py3noneany.whl,用最新的demo
这个issue属于bug报告，主要涉及的对象是nn.Parameter。由于修复nn.Parameter引起的bug或错误导致了该问题。,fix nn.Parameter,,2024-09-26T10:23:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1689
这是一个开源实习需求的类型为需求提出，主要对象为SAM模型应用开发。,【开源实习】SAM模型应用开发,,2024-09-26T04:30:11Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1688,附一下pytorch的结果截图和MindSpore的结果截图对比, Pytorch !{7DEC6A5598FB4A1783CA5CB6A639C42F} !{1AE5D72CCC574FDEB832C771021EEFDB}  Mindspore !{C5117F7C089844CBB0F64CA4CE167FF7} !{E26307C38CC644C7AF0CC5C03BC6DBAD},Ai gallery： https://pangu.huaweicloud.com/gallery/assetdetail.html?id=de70ce94406b4625972e1a763c01d32c,验收通过，可以合入
这个issue是用户提出的需求类型，主要涉及Mindnlp支持分布式推理的功能。,support distributed inference,,2024-09-26T03:57:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1687
这是一个bug报告，涉及的主要对象是mindnlp下的_cells函数。产生这个bug可能是由于_cells函数发生错误，需要修复。,fix _cells error,,2024-09-26T02:08:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1686
这是一个bug报告，用户在创建LoRA的PEFT模型时添加modules_to_save层时遇到了报错。造成报错的原因需要进一步分析。,创建LoRA的PEFT模型时添加modules_to_save层报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 使用peft.get_peft_model()创建模型时报错： AttributeError: 'Sequential' object has no attribute '_cells'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0 daily  Python version (e.g., Python 3.7.5) :Python 3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):Linux EulerOS 2.0  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 创建一个peft.LoraConfig类，设置modules_to_save参数（可指定任意模块），使用该config调用peft.get_peft_model()方法获取peft模型，触发报错。 以MLP模型为例： ``` class MLP(nn.Module):     def __init__(self, num_units_hidden=2000):         super().__init__()         self.seq = nn.Sequential(             nn.Linear(20, num_units_hidden),             nn.ReLU(),             nn.Linear(num_units_hidden, num_units_hidden),             nn.ReLU(),             nn.Linear(num_units_hidden, 2),             nn.LogSoftmax(dim=1),         )     def forward(self, X):         return self.seq(X) config = peft.LoraConfig(     r=8,     target_modules=[""seq.0"", ""seq.2""],     modules_to_save=[""seq.4""],  ！！ ) module = MLP() model = peft.get_peft_model(module, config) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 得到具有modules_to_save层的peft模型 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !41507f8186255b37f874a617a5560c7b **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-25T11:11:35Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1685
该问题属于一个功能请求，主要涉及的对象是MindNLP代码库中的cells_to_save和modules_to_save参数。,cells_to_save -> modules_to_save,,2024-09-25T10:19:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1684
该issue属于bug报告类型，涉及主要对象为BloomModel的forward方法，由于past_key_values的数据类型不符合模型期望的格式，导致此问题的产生。,BloomModel 的 forward 方法中，模型现在期望 past_key_values 是一个元组(tuple),"**Describe the bug/ 问题描述 (Mandatory / 必填)**past_key_values 的数据类型上,模型期望 past_key_values 是一个具有 get_seq_length() 方法的对象，但实际上它是一个元组（tuple）,BloomModel 的 forward 方法中，模型现在期望 past_key_values 是一个 Cache 类的实例，而不是元组(tuple)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0daily  Python version (e.g., Python 3.7.5) :Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):euler_2.10.7  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 将数据集进行配置后并训练 !屏幕截图 20240925 104544 报错AttributeError: 'tuple' object has no attribute 'get_seq_length' **Expected behavior / 预期结果 (Mandatory /  / 截图 (Mandatory / 必填)** !屏幕截图 20240925 092831 !屏幕截图 20240925 094224 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-25T01:59:11Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1683,问题修了，但是你写的有问题 1. input_ids和labels必须是int类型，你写的float 2. 为什么要用trainer？https://github.com/huggingface/peft/blob/749b92456218f7dddc8f7a9aa27a41815b3d6c2e/examples/causal_language_modeling/peft_prefix_tuning_clm.ipynbL4 这里是手写的训练，我怀疑huggingface官方的按你这么写也跑不通。 所以你按照peft的实现来，另外测一下transformers+peft是不是也报错。 
这是一个用户提出需求的issue，主要对象是nn.Module在支持ms.jit时出现的问题。,nn.Module support ms.jit,,2024-09-24T10:02:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1682
这是一个用户新增功能请求类型的issue，主要涉及到MindPilot项目的README.md文件。由于初步开发完成，用户希望添加MindPilot V0.0.1的信息到README.md中。,add: MindPilot README.md,MindPilot V0.0.1 初步开发完成 仓库地址：https://github.com/ResDream/MindPilot,2024-09-24T03:31:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1681
这是一个用户提出需求的类型。该问题单涉及的主要对象是 BEiT 模型应用开发。,【开源实习】BEiT模型应用开发,完成了 https://gitee.com/mindspore/community/issues/IAAD9U 对应的任务：Beit 模型应用开发。 原始代码仓中最后多出的部分仅为在单个代码单元中运行了所有代码，故在此略去。,2024-09-23T15:26:34Z,,closed,0,11,https://github.com/mindspore-lab/mindnlp/issues/1680,附一下pytorch的结果截图和MindSpore的结果截图对比,> 附一下pytorch的结果截图和MindSpore的结果截图对比 MindSpore 结果： !MindSpore 结果 pytorch 结果： !pytorch 结果,notebook文件名修改成英文,!20241017144046(WeLinkPC) 这部分应用代码也完成迁移,!20241017143629(WeLinkPC) 标注出来的部分可以直接修改成 return_tensors=“ms”,!20241017144032(WeLinkPC) !20241017144038(WeLinkPC) 提交notebook文件中的运行结果labels.shape与pytorch中不一致,> notebook文件名修改成英文 老师您好，您指出的问题已经全部修改完成（包括修改文件名、补充剩余部分、修改 return_tensors） label.shape 受到 mask 生成的随机性影响，不一定每次都相同，已标注在 notebook 中, return_tensors 没有完成修改,华为云创建的AI Gallery中的内容也需要同步需改,> 华为云创建的AI Gallery中的内容也需要同步需改 老师您好，已完成修改,验收通过，可以合入
用户提出需求。该问题单涉及的主要对象是在mindnlp\mindnlp\transformers\models\路径下新建模型名称为poly的目录以及__init__.py文件。由于用户需要添加一个名为poly的模型目录，并在其中加入一个__init__.py文件。,Add poly model directory with __init__.py,在mindnlp\mindnlp\transformers\models\路径下新建了模型名称为poly的目录并新建了一个__init__.py文件,2024-09-23T09:15:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1679
"这是一个包含需求链接的issue，涉及主要对象是""Accelerate""。原因是用户想要加速操作，但并没有提供具体问题或需求细节。",Accelerate,OSPP Link  https://summerospp.ac.cn/org/prodetail/24c6d0496?lang=zh&list=pro 描述：  基于MindNLP和Mindformers，采用HuggingFace Accelerate的构造方式，将MindFormers的分布式并行训练能力集成至MindNLP。,2024-09-22T13:41:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1678
这是一个bug报告，涉及的主要对象是创建LoRA的PEFT模型时未添加modules_to_save层，导致的症状是无法获取PEFT模型。,创建LoRA的PEFT模型时未添加modules_to_save层,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在创建基于LoRA的PEFT模型时，`peft.get_peft_model()`没有根据`modules_to_save`参数插入对应的模块: !22fdd9d50c7b473759366cff42127991 调试发现`modules_to_save`参数传递到了模型的config里，但在构造PEFT模型时，仅创建了`target_modules`，没有创建`modules_to_save`。 PEFT模型中的`set_additional_trainable_cells`函数应该实现这一功能，但它检查的是peft_config中的`cells_to_save`参数，而这里peft_config是传入的`lora_config`，它里面只有`modules_to_save`没有`cells_to_save`。 需要将函数中的`cells_to_save`改为`modules_to_save`。 !1726990805545  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0 daily  Python version (e.g., Python 3.7.5) :Python 3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):Linux EulerOS 2.0  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 创建一个peft.LoraConfig类，设置modules_to_save参数（可指定任意模块），使用该config调用peft.get_peft_model()方法获取peft模型，发现模型结构中缺少与modules_to_save相关层。 **Expected behavior / 预期结果 (Mandatory / 必填)** 获取的peft模型结构中包含modules_to_save相关层 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !22fdd9d50c7b473759366cff42127991 !4ecfad4d57bfad61641060099dcaf677 !f03ae72be2ad56cdedabfcc8f03775d5 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-22T07:41:34Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1677
这是一个招聘实习生的issue，主要对象是需要实习生开发完成Speech2Text模型迁移。,【开源实习】Speech2Text模型迁移,,2024-09-22T06:27:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1676
这是一个关于文档完善和实操教程完善建议的问题，涉及到MindNLP官网文档无法切换到中文、直接显示404、API栏目列表一级目录显示为空白、以及缺乏MindNLP实操教程的情况。,MindNLP文档完善以及实操教程完善建议,1. MindNLP官网文档目前无法切换到中文且从官网进入后直接显示404，且API栏目列表的一级目录全部显示为空白 2. 目前网络上几乎没有MindNLP实操教程，建议完善相关教程，可参考[https://www.bilibili.com/video/BV1ma4y1g791/?spm_id_from=333.788&vd_source=09b57904b797122d7ea759b9f44dc7c1（此教程基于huggingface]transformer）,2024-09-21T03:29:44Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1675
这是一个更新请求，目标是将Whisper应用程序更新为WhisperV3版本。这可能是由于WhisperV3版本具有新的功能或者修复了之前版本中的bug。,update whisper app to WhisperV3,,2024-09-20T15:46:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1674
这是一个用户提出需求的类型，主要涉及mindnlp支持Whisper Transcribe Audio功能。通过这个问题描述可以看出，用户希望mindnlp能够支持Whisper Transcribe Audio功能。,support whisper Transcribe Audio,,2024-09-20T10:03:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1673
"这是一个用户提出需求的类型，主要涉及mindnlp库中的模型""qwen2_vl""。 由于用户需求新增支持此特定模型，需要开发人员进行相应的支持工作。",support qwen2_vl,,2024-09-19T16:10:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1672
这是一个用户提出需求的issue，主要涉及的对象是mindnlp。由于需要新增mindbnb和支持8bit量化，用户希望对mindnlp进行相应改进。,【开源之夏】add mindbnb and support 8bit quantization for mindnlp,,2024-09-19T11:37:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1671
这是一个用户提出需求的issue，主要涉及的对象是mindnlp，用户希望添加mindbnb并支持8位量化。,【开源之夏】add mindbnb and support 8bit quantization for mindnlp,,2024-09-19T10:42:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1670
这是一个用户提出需求的类型，主要对象是Speech2Text模型迁移。由于答案中没有提供具体内容，无法分析具体原因导致的问题或需要帮助的内容。,【开源实习】Speech2Text模型迁移,,2024-09-19T09:54:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1669
这是一个 Bug 报告，涉及的主要对象是 Squeeze 操作。该问题由于在 Squeeze 操作时的形状不匹配导致了错误。,在 Squeeze 操作时的形状不匹配，squeeze 只能移除大小为 1 的维度,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在 Squeeze 操作时的形状不匹配。Squeeze 操作会移除指定维度的大小为 1 的维度，但代码试图对一个大小为 3 的维度执行 Squeeze 操作，这会导致 ValueError  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:CPU > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.4.0 daily  Python version (e.g., Python 3.7.5) : Python 3.9.0  OS platform and distribution (e.g., Linux Ubuntu 16.04):windows 11  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 模拟输入数据：大小为 [2, 3]，无法对维度为 3 进行 squeeze 操作 尝试对 最后一个维度,执行 squeeze 操作。但由于这个维度的大小为 3，squeeze 操作无法移除它，因此会显示错误。 **Expected behavior / 预期结果 (Mandatory / 必填)** [ERROR] RUNTIME_FRAMEWORK(,2b08,?):2024919 16:54:39 [mindspore\ccsrc\runtime\pipeline\async_rqueue.cc:206] mindspore::runtime::AsyncRQueue::WorkerJoin] WorkerJoin failed: For primitive[Squeeze], the input_x.shape[1] must be equal to 1 , but got 3.   C++ Call Stack: (For framework developers)  mindspore\core\include\utils/check_convert_utils.h:225 mindspore::CheckAndConvertUtils::CheckValue **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 复现报错：!28{E(2TLXOQZ ~($) AQOIP 源代码报错： !{5} C}R~5DCZ}DE %9N)DZ2 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-19T09:06:45Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1668,not error
这个issue类型是bug报告，主要涉及的对象是修复测试常见错误。由于出现了什么样的问题，导致了需要修复测试中的常见错误。,fix test common error,,2024-09-19T08:44:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1667
这是一个bug报告，涉及的主要对象是Mindnlp中的scatter函数。可能由于MS2.4版本的问题导致scatter函数无法正常工作。,fix scatter error on MS2.4,,2024-09-19T08:33:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1666
这个issue属于用户提出需求类型，主要涉及mindnlp项目和mindbnb，请求添加mindbnb并支持8位量化。,【开源之夏】add mindbnb and support 8bit quantization for mindnlp,,2024-09-19T05:32:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1665
这是一个bug报告，涉及主要对象是加载tokenizer时报错，由于可能缺少关键字导致出现KeyError引起的问题。,加载tokenizer时报错,**Describe the bug/ 问题描述 (Mandatory / 必填)** 在加载tokenizer时报错——KeyError  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (2.2.14) :  Python version (Python 3.9.0) : **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** 预期运行代码后成功加载所需要分词器，但是报错了，我看文档里是有rwkv对应tokenizer的映射的，或者说我看错了文档。之前没接触过这方面，麻烦大神在解答的时候可以大致告诉我加载tokenizer的时候怎么去查看对应的信息呀，谢谢 **Screenshots/ 日志 / 截图 (Mandatory / 必填)**  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.,2024-09-18T15:36:40Z,bug,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1664,提供一下版本,"是指mindnlp的版本嘛 3290840493 ***@***.*** &nbsp; &nbsp;原始邮件&nbsp; 发件人:                                                                                                                        ""mindsporelab/mindnlp""                                                                                    ***@***.***&gt;; 发送时间:&nbsp;2024年9月19日(星期四) 凌晨5:21 ***@***.***&gt;; ***@***.******@***.***&gt;; 主题:&nbsp;Re: [mindsporelab/mindnlp] 加载tokenizer时报错 (Issue CC(加载tokenizer时报错)) 提供一下版本 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",对,"!wget https://mindsporedemo.obs.cnnorth4.myhuaweicloud.com/mindnlp_install/mindnlp0.3.1py3noneany.whl !pip install mindnlp 我用的这个 &nbsp; &nbsp;原始邮件&nbsp; 发件人:                                                                                                                        ""mindsporelab/mindnlp""                                                                                    ***@***.***&gt;; 发送时间:&nbsp;2024年9月19日(星期四) 下午4:36 ***@***.***&gt;; ***@***.******@***.***&gt;; 主题:&nbsp;Re: [mindsporelab/mindnlp] 加载tokenizer时报错 (Issue CC(加载tokenizer时报错)) 对 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",用0.4 daily应该没问题,谢谢啦，试了一下用0.4 daily可以成功加载了
这是一个请求查看的类型，涉及的主要对象是SegFormer模型应用开发。可能由于对该模型应用的开发存在疑问或者需要老师审查。,【开源实习】SegFormer模型应用开发,还请老师查看,2024-09-18T15:18:20Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1663,放到 applications目录,已放在application了，老师, 老师麻烦您查看一下,附一下pytorch的结果截图和MindSpore的结果截图对比, Pytorch  !{A028A8DD41DC4B5BAA82E0EBBAB912AE} !{A3EAABD63914485C9BE407C2731E74FD} Mindspore !{C93A376A0351406584D1EFACE1AA8B43} !{7F150124234E44DAA35B54BED0DB43E2},Ai gallery: https://pangu.huaweicloud.com/gallery/assetdetail.html?id=a0632fe48c074c2a9e352d63350e2197,验收通过，可以合入
这是一个用户提出需求的类型的issue，涉及的主要对象是SegFormer模型应用开发。,【开源实习】SegFormer模型应用开发,,2024-09-18T15:10:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1662
这是一个bug报告，涉及主要对象是加载rwkv模型时遇到的报错。原因可能是由于加载方式或者模型本身的问题。,加载rwkv模型的时候报错,**Describe the bug/ 问题描述 (Mandatory / 必填)** 在利用RwkvForCausalLM.from_pretrained加载预训练模型的时候报错CalledProcessError  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (2.2.14) :  Python version (Python 3.9.0) : **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 预期是成功加载模型 **Screenshots/ 日志 / 截图 (Mandatory / 必填)**   **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.,2024-09-18T13:45:29Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1661,应该是你用的cuda版本太低，要用11.1以上
这个issue是bug报告，涉及到mindnlp接口问题，主要原因是类Linear缺少to属性导致使用报错。,mindnlp接口问题——mindnlp.peft.tuners.lora.layer的类Linear没有to属性导致使用报错,还是上次那个问题，上次没有说明清楚使用两个版本的mindnlp（0.3.1和0.4）都一样使用报错：https://github.com/mindsporelab/mindnlp/issues/1599 !2 !3 使用IA3微调算法可正常运行： !1 目前是否是mindnlp接口本身的问题？另外，许多模型是否可以用IA3代替Lora进行微调？,2024-09-18T09:14:48Z,bug,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1660,按照任务要求来，有问题需要自己尝试修复。或者等我fix掉,要和huggingface的一致，不能使用其他微调算法,好吧，我这边可能还没说清楚问题，当前的任务（https://gitee.com/mindspore/community/issues/IA5LDO）是微调的演示示例，不涉及huggingface的要求，只是演示微调算法的使用；我这边只是为了说明任务使用到模型以及mindnlp的官方教程中的例子都出现了报错； 现在任务先放一边，您还没回答最重要的问题，就是根据issue的描述，是否能确认是mindnlp的LoraConfig接口本身的问题？因为在mindnlp的正式发布的最新版本0.3.1和预发布的0.4版本中都同样出现的报错！,好吧，我这边可能还没说清楚问题，当前的任务(https://gitee.com/mindspore/community/issues/IA5LDO) 是微调的演示示例，不涉及huggingface的要求，只是演示微调算法的使用；我这边只是为了说明任务使用到模型以及mindnlp的官方教程中的例子都出现了报错； 现在任务先放一边，您还没回答最重要的问题，就是根据issue的描述，是否能确认是mindnlp的LoraConfig接口本身的问题？因为在mindnlp的正式发布的最新版本0.3.1和预发布的0.4版本中都同样出现的报错！,最新状态：mindspore和mindnlp分别使用最新的2.3.1和0.4，可以跑通lora了。 !mmexport1726714427116 但还是存在两个问题： 1️⃣2.3.1的mindspore不兼容在Windows平台和CPU，这样对微调算法的使用限制更高了； 2️⃣gitee上mindnlp的版本兼容性描述可能不太正确，需要更新：https://gitee.com/mindsporelab/mindnlp !mmexport1726714428925,fixed
这是一个用户提出需求的issue，主要涉及对象是OrangePi，由于需要支持int8量化，用户请求相关功能的支持。,support int8 quant on OrangePi,,2024-09-15T05:07:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1659
这个issue类型为用户提出需求，该问题单涉及的主要对象是mindnlp下的一个模型文件。由于新增的模型文件 qwen1.5-0.b，用户请求将其添加到 orangepi 平台。,add qwen1.5-0.b for orangepi,,2024-09-15T02:59:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1658
这是一个关于用户提出需求的问题，主要涉及Whisper模型推理功能的例子，由于用户不清楚如何进行语言类型检测和流式输出，导致提问。,能增加whisper这个模型推理的例子吗,在折腾whisper模型，一直都没弄明白怎么做语言类型检测，如何实现流式输出。,2024-09-14T07:58:23Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1657,ok,看一下llm/inference/whisper
这是一个用户提出需求的issue，主要对象是需要qwen2-vl-7b模型。原因可能是当前功能无法满足用户需求。,need qwen2-vl-7b,"Is your feature request related to a problem? Please describe. Currently, there is no support for inferencing the qwen2vl7b model on x86 platforms using 910A (32GB) cards. This limitation prevents users from leveraging the capabilities of qwen2vl7b on specific hardware configurations, potentially impacting performance and accessibility for certain use cases. Describe the solution you'd like Implement support for inferencing the qwen2vl7b model on x86 platforms using 910A (32GB) cards. This feature would enable users to run the qwen2vl7b model efficiently on this specific hardware configuration, expanding the model's usability and accessibility. Describe alternatives you've considered Using different hardware configurations, such as higherend GPUs or multiple GPUs. Implementing model compression techniques to reduce the model size and memory requirements. Exploring cloudbased solutions for inferencing the qwen2vl7b model. However, these alternatives may not be ideal for users who specifically need to use x86 platforms with 910A (32GB) cards. Additional context This feature would be particularly beneficial for users who have invested in 910A (32GB) cards and want to utilize the qwen2vl7b model without changing their existing hardware infrastructure. It would also contribute to the overall flexibility and compatibility of the qwen2vl7b model across different platforms and hardware configurations.",2024-09-14T01:36:15Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1656,已支持，尝试使用daily版本,可以跑通，感谢大神~~。
这是一个需求类型的issue，主要涉及到CLIPSeg模型的应用开发。由于原因未详，用户提出了与该模型应用开发相关的问题。,【开源实习】CLIPSeg模型应用开发,已完成https://gitee.com/mindspore/community/issues/IAADB7,2024-09-13T14:52:33Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1655,放到 applications目录
该issue类型为需求提出，涉及的主要对象为CLIPSeg模型应用开发。由于需要开发CLIPSeg模型的应用，所以提出了该需求。,【开源实习】CLIPSeg模型应用开发,已完成https://gitee.com/mindspore/community/issues/IAADB7,2024-09-13T14:51:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1654
这是一个用户提出需求的issue，主要涉及对象是将tinyllama添加到OrangePi上。由于未提供具体内容，无法确定导致这个问题的原因。,add tinyllama on OrangePi,,2024-09-13T07:26:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1653
这是一个Bug报告，涉及的主要对象是test_modeling_common中的测试用例test_model_outputs_equivalence，可能是由于CPU环境问题导致测试报错。,test_modeling_common中test_model_outputs_equivalence在CPU环境测试报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** test_modeling_common中的测试用例test_model_outputs_equivalence在CPU下执行时出现 TypeError: Unsupported op [Select] on CPU, input_type:[const vector]{Bool, Int64, Float32} ,output_type:[const vector]{Int64}.问题 !image 如上图框出位置所示，CPU下测试时，使用注释前的写法可以通过，改用新的写法会出现TypeError的问题  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):Windows11  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1.CPU环境下执行ut时，test_modeling会调用test_modeling_common执行，导致test_model_outputs_equivalence测试用例无法通过 **Expected behavior / 预期结果 (Mandatory / 必填)** CPU执行时，能正常通过test_model_outputs_equivalence测试 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 具体报错如下图 !image !image 导致该错误的可能原因 在test_modeling_common.py文件中 !image 注释掉的写法可以正常通过测试，新写法出现错误 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-13T06:37:44Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1652
这是一个用户对于支持OrangePi进行BERT推断和训练的需求类型的issue。,bert support orangepi inference and train,,2024-09-12T17:04:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1651
这个issue是关于需求的，主要对象是模型的微调过程。,【开源实习】sequence_classification/ia3模型微调,https://gitee.com/mindspore/community/issues/IAN0FF,2024-09-12T14:09:00Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1650,目录不对 看看其他的目录怎么放的,> 目录不对 看看其他的目录怎么放的 现在可以了吗
这是一个Bug报告，涉及到执行bash脚本时出现的错误，错误原因可能是模块中不存在特定属性导致。,执行pytest_ut_st.sh时，在tests\st\test_bilstm_imdb.py中存在AttributeError: module 'mindspore.nn' has no attribute 'Module'错误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在执行bash scripts/pytest_ut_st.sh时，tests\st\test_bilstm_imdb.py文件下存在AttributeError: module 'mindspore.nn' has no attribute 'Module'错误。具体问题如下 !image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.0  Python version (e.g., Python 3.7.5) :3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):Windows 11  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1.Terminal中执行bash scripts/pytest_ut_st.sh 2.出现图中错误 **Expected behavior / 预期结果 (Mandatory / 必填)** 执行bash scripts/pytest_ut_st.sh，不出现上述报错 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 运行pytest_ut_st.sh后出现问题 !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-12T09:23:45Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1649
这是一个bug报告，涉及的主要对象是mindnlp库中的类B。由于什么样的原因导致了这个bug或者用户提出了关于什么的问题或者寻求什么样的帮助几乎无法确定，因为issue内容为空。,fix b class,,2024-09-11T05:32:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1648
这是一个bug报告类型的issue，主要涉及到minicpm-2b和codallama7binstruct在Ascend芯片上训练时爆显存的问题。可能由于训练过程中内存占用过高导致爆显存的现象。,minicpm-2b在910A上训练时爆显存,"同时，codallama7binstruct在A800上存在相同的问题，即训练时爆显存  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend 910A  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 见附件代码或参见 https://github.com/xuhangscut/5009_nl2sql_ms **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** minicpm2b在910A上训练报错 !ad6c8d1b55d1cc9fb7757cd4371762d !a89d5c66c7e521d607df164771b476b **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-09-11T03:35:14Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1647
"这是一个 bug 报告类型的 issue，主要涉及修复名为""m class""的问题。可能是由于代码逻辑错误或者输入数据异常等原因导致产生了相关bug。",fix m class,,2024-09-10T13:31:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1646
这是一个用户提出需求的问题单，主要涉及对于`forward`函数参数匹配顺序的支持。用户认为合并时出现了问题。,Support `forward` function parameters match by order,"**Is your feature request related to a problem? Please describe.** When I merge `DNA_LM` peft finetuning scripts from `huggingface` to `mindnlp`. The parameters of `forward` function in `mindnlp.core.nn.Module` must match dataset's column with name when training with `mindnlp.engine.Trainer`. **Describe the solution you'd like** `Huggingface` can match the `forward` and dataset's `column` by **parameter/column order** **Describe alternatives you've considered** Firstly try to match `forward` and dataset's `column` by name.Then try to match by order. **Additional context** dataset structure ```shell train dataset info: dataset column: ['sequence', 'label'] dataset size: 13468 dataset batch size: 1 ``` model forward ```python class DNA_LM(nn.Module):     def __init__(self, model, num_labels):          ....     def forward(self, input_ids, label=None):         .... ``` trainer definition and start to train ```python from mindnlp.engine import Trainer, TrainingArguments  Define training arguments training_args = TrainingArguments(     output_dir='./results',     evaluation_strategy=""epoch"",     learning_rate=2e5,     num_train_epochs=5,     weight_decay=0.01,     eval_steps=1,     logging_steps=1, )  Initialize Trainer trainer = Trainer(     model=classification_model,     args=training_args,     train_dataset=train_dataset,     eval_dataset=valid_dataset,     tokenizer=tokenizer, )  Train the model trainer.train() ``` failed error ```shell TypeError                                 Traceback (most recent call last) Cell In[17], line 24      15 trainer = Trainer(      16     model=classification_model,      17     args=training_args,    (...)      20     tokenizer=tokenizer,      21 )      23  Train the model > 24 trainer.train() File ~/miniconda3/envs/neoming_vivit/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:756, in Trainer.train(self, resume_from_checkpoint, ignore_keys_for_eval, **kwargs)     751     self.model_wrapped = self.model     753 inner_training_loop = find_executable_batch_size(     754     self._inner_training_loop, self._train_batch_size, args.auto_find_batch_size     755 ) > 756 return inner_training_loop(     757     args=args,     758     resume_from_checkpoint=resume_from_checkpoint,     759     ignore_keys_for_eval=ignore_keys_for_eval,     760 ) File ~/miniconda3/envs/neoming_vivit/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:1109, in Trainer._inner_training_loop(self, batch_size, args, resume_from_checkpoint, ignore_keys_for_eval)    1106 if step % args.gradient_accumulation_steps == 0: ... > 361     return forward_call(*args, **kwargs)     363 try:     364     result = None TypeError: forward() got an unexpected keyword argument 'sequence' ```",2024-09-10T13:09:59Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1645
这是一个用户提出需求的issue，该问题单涉及的主要对象是 `dna_lm`，由于缺少 `peft example`，用户请求添加示例。,add  `dna_lm` peft example #,,2024-09-09T14:27:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1644
这是一个开源实习相关的任务需求，提及了Vision Transformer模型应用开发，涉及主要对象是Mindnlp项目。,【开源实习】Vision Transformer模型应用开发,已完成 https://gitee.com/mindspore/community/issues/IAADPG,2024-09-09T02:06:28Z,,closed,0,15,https://github.com/mindspore-lab/mindnlp/issues/1643,放examples目录,不太懂老师，您说是让我截图运行结果吗，还是说是ai gallery的https://pangu.huaweicloud.com/gallery/assetdetail.html?id=a13fb1928161495c8ac3d11f07277061 这个？,还是说放这里吗 https://github.com/mindsporelab/mindnlp/tree/master/examples，老师,放mindnlp/examples目录，另外你这个demo写的太简单了，这种没有什么实际用处。 还有你的notebook文件有几个问题： 1. 华为云配置环境的部分并不需要 2. set_context不需要写 有不懂的问题加群问哈,按照要求改了老师，群是那个qq大群吗，好的老师,老师，我看了这个通过PR实习的，这个确是放在tutorial 那里  https://github.com/mindsporelab/mindnlp/pull/1495,> 老师，我看了这个通过PR实习的，这个确是放在tutorial 那里 CC(【开源实习】Audio Spectrogram Transformer模型应用开发) 后面要统一挪一下，我想想放个啥目录合适,老师好，那应该放哪呢,要不，还是放在tutorial那里吧，老师,> 要不，还是放在tutorial那里吧，老师 放这还是不太合适。,放到 applications目录,放在application里了，老师,附一下pytorch的结果截图和MindSpore的结果截图对比,Pytorch：  Mindspore: ,Ai gallery: https://pangu.huaweicloud.com/gallery/assetdetail.html?id=a13fb1928161495c8ac3d11f07277061
这是一个缺少具体内容的bug报告，主要对象是mindnlp的C类相关功能。可能是由于提交者遗漏了具体描述内容导致此问题。,fix c class,,2024-09-08T14:44:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1642
这是一个bug报告，主要涉及模型迁移过程中的参数问题。缺少清晰的问题来源导致了再次出现scale_factor参数的问题。,【开源实习】depth_anything模型迁移#I9UUGR,之前的pr太乱了，我重新fork了一下代码，这个新clone的mindnlp做迁移又出现了之前scale_factor这个参数的问题，不清楚问题来源是什么，还需要再修改，但是之前的代码时可以跑的，只是精度不够,2024-09-08T12:27:13Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1641,请问上一个没通过的原因是需要再修改才能合入吗？,错的两个修一下，test_backbone可以skip
"这是一个bug报告，主要涉及到修复一个叫做""x class""的问题。这个issue出现的原因可能是由于代码中的错误导致了该类的功能异常或者出错。",fix x class,,2024-09-08T04:02:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1640
这是一个缺少具体内容的bug报告，主要涉及到需要更新 `p` 标签的类名。问题出现的原因可能是由于忘记提供具体的更新内容。,update p class,,2024-09-07T13:23:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1639
"这是一个bug报告类型的issue，涉及主要对象是MindNLP工具中的""Lastdepthing""功能。这个问题可能是由于代码逻辑错误或者依赖库版本问题导致的bug，用户可能遇到了Lastdepthing功能无法正常工作的情况。",Lastdepthing,,2024-09-07T10:26:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1638
这是一个bug报告类型的issue，主要涉及的对象是mindnlp库中的's class'功能。由于代码中的错误或不完善导致了这个bug或用户问题的出现。,fix s class,,2024-09-07T03:55:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1637
这个issue属于bug报告类型，主要涉及mindnlp中的类（class）。由于未提供具体内容，无法分析具体原因导致的症状或用户提出的问题。,fix l class,,2024-09-06T05:14:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1636
这是一个用户提出需求的issue，主要对象是MindNLP的时间记录功能。,add time record,,2024-09-05T03:57:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1635
这是一个bug报告，主要对象是mindnlp库中的transformers模块，用户遇到导入模块时出现错误。,导入mindnlp.transformers报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 安装mindnlp之后导入mindnlp.transformers的时候会因为第三方库的原因导致错误  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: ARM+AScend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.3.0rc1  Python version 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 1. 新建脚本 2. 导入mindnlp.transformers:   import mindnlp.transformers as transformers 3. 报错 OSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory **Expected behavior / 预期结果 (Mandatory / 必填)** 能够正常导入 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** from mindnlp import transformers   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/mindnlp/transformers/__init__.py"", line 16, in      from . import models, pipelines   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/mindnlp/transformers/models/__init__.py"", line 19, in      from . import (   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/mindnlp/transformers/models/rag/__init__.py"", line 15, in      from . import configuration_rag, modeling_rag, retrieval_rag, tokenization_rag   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/mindnlp/transformers/models/rag/modeling_rag.py"", line 29, in      from .retrieval_rag import RagRetriever   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/mindnlp/transformers/models/rag/retrieval_rag.py"", line 32, in      from datasets import Dataset, load_dataset, load_from_disk   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/datasets/__init__.py"", line 17, in      from .arrow_dataset import Dataset   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/datasets/arrow_dataset.py"", line 75, in      from . import config   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/datasets/config.py"", line 146, in      importlib.import_module(""soundfile"").__libsndfile_version__   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/importlib/__init__.py"", line 127, in import_module     return _bootstrap._gcd_import(name[level:], package, level)   File ""/root/miniconda3/envs/SmartSensing/lib/python3.9/sitepackages/soundfile.py"", line 192, in      _snd = _ffi.dlopen(_explicit_libname) OSError: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory **Additional context / 备注 (Optional / 选填)**",2024-09-05T02:23:02Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1634
这是一个bug报告，主要涉及的对象是mindnlp下的cross_entropy函数。这个issue是关于修复当logits包含无穷大值时出现的错误。,fix cross_entropy bug when logits has inf,,2024-09-04T15:15:34Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1633,"nn.functional.cross_entropy will output `nan` when inputs has `inf`, becasue the compute of `smoth_labeling`",`ops.unique` lack some arguments on CPU
这是一个bug报告，涉及的主要对象是mindnlp中的w类。缺少具体描述的原因和症状，无法进一步分析问题的根本原因。,fix w class,,2024-09-04T09:24:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1632
"这是一个bug报告，涉及的主要对象是""d class""。可能由于代码中的错误导致了bug或者用户提出了关于""d class""的问题或者寻求相关帮助。",fix d class,,2024-09-03T09:45:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1631
"这是一个 bug 报告，主要涉及的对象是一个名为 ""g class"" 的问题。由于代码中与 ""g class"" 相关的部分存在错误，导致出现了需要修复的问题。",fix g class,,2024-09-03T05:39:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1630
这是一个用户提出需求的issue，主要涉及的对象是mindnlp的使用readme以及如何使用ashell1中文数据集重新训练wav2vec2。由于缺乏相关信息，导致用户询问如何操作重新训练过程中的词汇表、分词器以及数据处理。,能提供一下mindnlp的使用readme吗，如果使用ashell1中文数据集重新训练wav2vec2要如何操作，是直接从新生成词汇表跟分词器，重写数据处理还是如何进行,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-09-02T14:09:18Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1629,可以先参考下：https://mindnlp.cqu.ai/  tokenizer的重新生成和模型关系不大，参考huggingface tokenizers的使用即可。
这个issue是一个bug报告，该问题单涉及的主要对象是normal tests。由于某些问题导致了normal tests无法正常运行。,fix normal tests,,2024-09-02T10:15:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1628
该issue类型为文档修复（bug报告），主要涉及到修复文档相关的问题。,fix docs,,2024-09-02T08:54:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1627
这是一个用户提出需求的类型，主要涉及nllbmoe模型的迁移。用户反映了关于模型pytest slow和py方面的问题。,【开源实习】NLLB-MoE 模型迁移 ,任务链接：https://gitee.com/mindspore/community/issues/I9UXTZ nllbmoe模型pytest slow和pylint均测试通过。 pytest中最后三个测试，由于MindSpore与PyTorch在相同随机种子下生成的随机数不同导致未通过。手动将PyTorch生成的数据作为输入即可通过测试。 !image !a1f14e4ed0ffa151f2da650bc068ccd8,2024-09-02T08:49:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1626
这是一个缺少具体内容的bug报告，涉及的主要对象是mindnlp中的某个v class。原因可能是用户遇到了某种异常行为或错误，并希望修复该问题。,fix v class,,2024-09-02T04:49:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1625
这是一个bug报告，针对depth_anything模型迁移任务中DinoV2存在的问题。,depth_anything模型迁移任务：DinoV2存在的问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 在depth_anything模型中，出现与transformers的输出不对称的情况，打印的output上面的是与transformers对称的，下面的出现误差 下图是打印的位置： !Screenshot 20240902 105230 下图是与transformers的output输出的对比图： !Screenshot 20240902 105336 下图是backbone的type：可能是DinoV2存在一些问题： !Screenshot 20240902 113900  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  Mindspore2.2.14  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) : 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): windows  GCC/Compiler version (if compiled from source):",2024-09-02T03:50:35Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1624
这是一个bug报告，主要涉及的对象是修复名为starcoder2的问题。这个issue可能由于程序中的错误或者缺陷导致了starcoder2功能无法正常工作。,fix starcoder2,,2024-09-01T15:20:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1623
这是一个bug报告，主要涉及的对象是switch_transformers，可能是由于代码实现错误或者逻辑缺陷导致了bug的产生。,fix switch_transformers,,2024-09-01T14:10:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1622
这是一个bug报告，涉及到修复 sam/seamless_m4t 相关问题，由于某种原因导致该功能的错误或异常行为。,fix sam/seamless_m4t,,2024-09-01T10:27:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1621
该issue类型是用户提出需求，涉及主要对象是Dora-finetuning模型微调；用户可能需要帮助或者指导如何进行Dora-finetuning模型微调。,【开源实习】- Dora-finetuning模型微调 - #IAN239,,2024-09-01T08:52:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1620
这是一个缺少具体内容的bug报告，涉及MindNLP中的rwkv相关问题，由于缺少详细描述导致无法准确判断问题症状或解决方法。,fix rwkv,,2024-08-31T05:09:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1619
这是一个社区实习任务类型的issue，涉及主要对象为data2vec-vision。,【社区实习】data2vec-vision,,2024-08-30T15:24:41Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1618,https://gitee.com/mindspore/community/issues/I9UU3G,/model data2vec,/model data2vec,全部通过的截图附上，RUN_SLOW必须跑,ut全部通过 !83abd53319db12f888c4e8294333458,/model data2vec,/model data2vec
这个issue类型是bug报告，涉及的主要对象是代码中的i标签。 由于漏掉了i标签闭合导致的bug。,fix i class,,2024-08-30T15:09:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1617
这个issue属于bug报告类型，主要涉及到MindNLP中的安全张量（SafeTensors）。由于存在bug导致了安全张量的功能异常，需要修复该bug。,fix safetensors bug,,2024-08-30T08:34:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1616
这个issue是一个性能优化的请求，主要涉及safetensors load功能，请求优化加载速度。,update safetensors load(2G ckpt: 11s->7s),,2024-08-30T06:50:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1615
这是一个bug报告类型的issue，主要涉及IA3Model中nn.Linear报错没有in_channels属性的问题。可能是由于代码编写不完整导致该属性缺失而引起的bug。,修改IA3Model中nn.Linear报错没有in_channels属性的问题&【开源实习】peft_ia3_seq2seq模型微调-#IAN28H,,2024-08-29T17:37:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1614
这是一个bug报告，主要涉及到ia3 peft中的nn.Linear找不到报错。由于代码中可能没有正确导入相关模块或者路径设置不正确，导致无法找到nn.Linear从而报错。,更新ia3 peft中的nn.Linear找不到报错,,2024-08-29T15:06:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1613
这是一个bug报告类型的issue，涉及chatglm2和chatglm3的修复。原因是可能由于代码bug导致chatglm2和chatglm3无法正常工作。,fix chatglm2/chatglm3,,2024-08-29T14:13:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1612
这个issue类型为特性功能请求，涉及主要对象是PatchTSMixer模型。由于用户希望进行模型迁移，可能是因为需要在不同环境中使用该模型实现相关任务。,PatchTSMixer模型迁移,,2024-08-29T14:07:57Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1611,rebase最新代码哈,6个用例挂了，自己修复掉，用mindspore2.4 daily包测试
这是一个用户上传文件的issue，类型为功能需求，用户提出了上传文件的需求。,Add files via upload,,2024-08-29T13:59:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1610
这个issue是一个bug报告，涉及到了chatglm4的错误。原因可能是代码实现问题或者数据处理错误导致导致bug出现。,fix chatglm4 error,,2024-08-29T12:04:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1609
这是一个用户提出需求的类型，主要涉及的对象是模型peft_ia3_seq2seq。由于用户希望微调该模型，因此提出了这个issue。,【开源实习】peft_ia3_seq2seq模型微调 - #IAN28H,,2024-08-29T11:48:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1608
这是一个bug报告类型的issue，主要涉及Mindnlp中的chatglm3模块，在执行路径llm/inference时出现报错。,使用chatglm3的例子式报错,**Describe the bug/ 问题描述 (Mandatory / 必填)** 在jupyter notebook上运行路径为llm/inference/chatglm3/cli_demo.py的文件中的代码时，在我输入问题后，模型推理时报错  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: 昇腾大模型平台 jupyter云上开发 Ascend环境 96G Ascend910 python3.9ms2.3.0cann8.0.RC2.beta1  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version: 2.3.0  Python version : 3.9.19 **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1.把代码拷贝到jupyter上 2. 点击运行 3. 提示我输入问题 4. 输入问题，enter后报错 **Expected behavior / 预期结果 (Mandatory / 必填)** chatglm3给出推理结果 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !69c7aecc9a6e3ae97aedcc377ed3118 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.,2024-08-29T11:33:38Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1607
这是一个bug报告类型的issue，主要涉及到修复MT5相关的问题。由于未提供具体内容，无法准确分析导致bug的原因。,fix mt5,,2024-08-29T11:25:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1606
这是一个bug报告，涉及GPU环境下TrOCR预训练模型微调时出现的求梯度报错问题，由于指针为null导致RuntimeError。,RuntimeError: The pointer[tensor] is null.,"**Describe the bug/ 问题描述 (Mandatory / 必填)** GPU环境 TrOCR预训练模型微调 求梯度时报错 RuntimeError: The pointer[tensor] is null.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Modelarts  CPU 8核32G >GPU Tnt004 16G  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : MindSpore 2.2.14  Python version (e.g., Python 3.7.5) :Python 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):ubuntu18.04  GCC/Compiler version (if compiled from source):7.5  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** model dataset 运行代码 ''' for epoch in range(1):      train     model.train()     train_loss = 0.0     for bacth in tqdm(eval_dataloader.create_dict_iterator()):         pixel_values = bacth['pixel_values']         labels = bacth['labels']         def compute_loss(pixel_values, labels):             outputs = model(pixel_values=pixel_values, labels=labels)             loss = outputs.loss             return loss         grad_fn = mindspore.value_and_grad(fn=compute_loss, weights=model.parameters())         loss, grads = grad_fn(pixel_values, labels)         optimizer.step(loss) ''' **Expected behavior / 预期结果 (Mandatory / 必填)** 正常运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-29T07:53:31Z,bug,open,0,4,https://github.com/mindspore-lab/mindnlp/issues/1605,要用mindspore2.3,复现代码提供完整的,"用2.3版本的mindspore CPU 训练会报错如下 !image GPU太贵了 ``` df = pd.read_fwf('./IAM/gt_test.txt', header=None) df.rename(columns={0: ""file_name"", 1: ""text""}, inplace=True) del df[2]  some file names end with jp instead of jpg, let's fix this df['file_name'] = df['file_name'].apply(lambda x: x + 'g' if x.endswith('jp') else x)  print(df.head()) train_df, test_df = train_test_split(df, test_size=0.2)  we reset the indices to start from zero train_df.reset_index(drop=True, inplace=True) test_df.reset_index(drop=True, inplace=True) class IAMDataset():     def __init__(self, root_dir, df, processor, max_target_length=128):         super(IAMDataset).__init__()         self.root_dir = root_dir         self.df = df         self.processor = processor         self.max_target_length = max_target_length     def __len__(self):         return len(self.df)     def __getitem__(self, idx):          get file name + text         file_name = self.df['file_name'][idx]         text = self.df['text'][idx]          prepare image (i.e. resize + normalize)         image = Image.open(self.root_dir + '/' + file_name).convert(""RGB"")         pixel_values = self.processor(image, return_tensors=""ms"").pixel_values          add labels (input_ids) by encoding the text         labels = self.processor.tokenizer(text,                                           padding=""max_length"",                                           max_length=self.max_target_length).input_ids          important: make sure that PAD tokens are ignored by the loss function         labels = [label if label != self.processor.tokenizer.pad_token_id else 100 for label in labels]          encoding = {: , : }         return pixel_values.squeeze(), Tensor(labels) model_path1 = ""C:\\Users\\virgo\\Documents\\GitHub\\trocrbaseprinted"" model_path2 = ""C:\\Users\\virgo\\Documents\\GitHub\\trocrbasestage1"" processor = TrOCRProcessor.from_pretrained(model_path1) train_dataset = IAMDataset(root_dir='./IAM/image',                            df=train_df,                            processor=processor) eval_dataset = IAMDataset(root_dir='./IAM/image',                           df=test_df,                           processor=processor) train_dataloader = GeneratorDataset(train_dataset, column_names=[""pixel_values"", ""labels""], shuffle=True).batch(4) eval_dataloader = GeneratorDataset(eval_dataset, column_names=[""pixel_values"", ""labels""], shuffle=True) model = VisionEncoderDecoderModel.from_pretrained(model_path2)  set special tokens used for creating the decoder_input_ids from the labels model.config.decoder_start_token_id = processor.tokenizer.cls_token_id model.config.pad_token_id = processor.tokenizer.pad_token_id  make sure vocab size is set correctly model.config.vocab_size = model.config.decoder.vocab_size  set beam search parameters model.config.eos_token_id = processor.tokenizer.sep_token_id model.config.max_length = 64 model.config.early_stopping = True model.config.no_repeat_ngram_size = 3 model.config.length_penalty = 2.0 model.config.num_beams = 4 cer_metric = evaluate.load(""cer"") def compute_cer(pred_ids, label_ids):     pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)     label_ids[label_ids == 100] = processor.tokenizer.pad_token_id     label_str = processor.batch_decode(label_ids, skip_special_tokens=True)     cer = cer_metric.compute(predictions=pred_str, references=label_str)     return cer optimizer = AdamW(model.parameters(), lr=5e5) for epoch in range(1):      train     model.train()     train_loss = 0.0     for bacth in tqdm(eval_dataloader.create_dict_iterator()):         pixel_values = bacth['pixel_values']         labels = bacth['labels']         def compute_loss(pixel_values, labels):             outputs = model(pixel_values=pixel_values, labels=labels)             loss = outputs.loss             return loss         grad_fn = mindspore.value_and_grad(fn=compute_loss, weights=model.parameters())         loss, grads = grad_fn(pixel_values, labels)         optimizer.step(loss) ```",数据类型有问题
这是一个bug报告，主要涉及到MindNLP库中的ops.gamma函数和target_modules错误。这个问题可能是由于代码实现的缺陷导致的。,support ops.gamma and fix target_modules error,,2024-08-29T03:02:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1604
这是一个bug报告类型的issue，主要涉及的对象是ops模块，由于ops模块缺少gamma函数导致调用ops.gamma(concentration)时出现问题。,在调用 ops.gamma(concentration) 时，ops 模块中缺少 gamma 函数,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在调用 ops.gamma(concentration) 时，ops 模块中缺少 gamma 函数  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > CPU,GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.0  Python version (e.g., Python 3.7.5) :3.9.0  OS platform and distribution (e.g., Linux Ubuntu 16.04):Windows11  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: pytest vs tests/ut/transformers/models/patchtsmixer/test_modeling_patchtsmixer.py **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !R V_J3U4DNT K300HLC~7R !8)2QGD%SHJ359 IGP **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-28T13:06:50Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1603,fixed
这是一个bug报告类的issue，涉及主要对象为loraconfig。由于描述bug不完整，导致无法准确分析问题，若无更多信息可能无法解决该问题。,loraconfig问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 3.4.1 :  Python version 3.9 :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** batch_size = 32 model_name_or_path = ""./.mindnlp/model/ZhipuAI/glm49bchat"" task = ""mrpc"" peft_type = PeftType.PROMPT_TUNING num_epochs = 20 peft_config = LoraConfig(task_type=""QUESTION_ANS"", inference_mode=False, r=8, lora_alpha=16, lora_dropout=0.1, target_cells) lr = 3e4 tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, mirror='modelscope') model = AutoModelForCausalLM.from_pretrained(     model_name_or_path,     mirror='modelscope',     ms_dtype=mindspore.float16, ).eval() if any(k in model_name_or_path for k in (""gpt"", ""opt"", ""bloom"")):     padding_side = ""left"" else:     padding_side = ""right"" if getattr(tokenizer, ""pad_token_id"") is None:     tokenizer.pad_token_id = tokenizer.eos_token_id model = get_peft_model(model, peft_config) model.print_trainable_parameters() AttributeError: 'LoraConfig' object has no attribute 'target_cells' **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image",2024-08-28T12:05:14Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1602,fixed
这是一个bug报告类型的issue，主要涉及mindnlp中的sentence/chatglm模块和rag演示的更新问题。Bug可能是由修改代码时的错误导致的。,fix sentence/chatglm and update rag demo,,2024-08-28T10:47:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1601
这个issue类型为需求提出，涉及的主要对象是CodeGeeX课程资料更新，用户提出了关于开源实习资料更新的需求。,【开源实习】- CodeGeeX课程资料更新-#IA5LBP,,2024-08-28T02:10:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1600
这是一个bug报告，涉及到mindnlp库中的mindnlp.peft.tuners.lora.layer类中的Linear类缺少to属性导致使用报错。造成这个bug的原因是缺少必要的属性。,mindnlp接口问题——mindnlp.peft.tuners.lora.layer的类Linear没有to属性导致使用报错, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) MindNLP官网中“教程”的PEFT的例子（https://mindnlp.cqu.ai/zh/tutorials/peft/） 报错AttributeError: Tho 'Linear' object has no attribute 'to”. !PEFT使用举例报错说明1 !PEFT使用举例报错说明2 看到源码中操作是在if语句块下的self.to(...)，考虑到是否是pytorch类似的用法在当前框架没有这样的使用？  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   .Special notes for this issue/备注 (Optional / 选填) **【定位人】**江俊康,2024-08-28T01:39:20Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1599,用mindnlp 0.4
这是一条需求更新的issue，涉及的主要对象是CodeGeeX课程资料。,【开源实习】-CodeGeeX课程资料更新-#IA5LBP,,2024-08-27T08:53:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1598
这是一个用户提出需求的类型问题单，主要涉及的对象是mindnlp项目中的comm_func功能。可能由于MS2.2版本缺少与comm_func相关的功能，用户需要添加该功能以满足特定需求。,add comm_func for MS2.2,,2024-08-27T08:48:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1597
这是一个用户提出需求的issue，主要对象是MindNLP下的CodeGeeX课程资料更新。,【开源实习】-CodeGeeX课程资料更新-#IA5LBP,,2024-08-27T06:22:26Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1596,收到，正在改
这是一个需求更新的issue，涉及主要对象为CodeGeeX课程资料。,【开源实习】-CodeGeeX课程资料更新,,2024-08-27T06:20:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1595
这是一个初次提交的issue，类型为功能增强或新功能请求，涉及的主要对象是ViTMatte模型。由于尚未提供详细说明，无法确定具体问题或需求。,开源实习【ViTMatte模型迁移】,first commit,2024-08-26T14:18:45Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1594,/model vitmatte,!6b9c9cbe7914eaf85ee463ffec7a67a5 vitmatte模型test和slow已过，任务链接https://gitee.com/mindspore/community/issues/I9V0IW,/model vitmatte
这是一个开源实习相关的issue，主要对象是gemma2模型迁移，用户寻求关于任务链接中提到的内容的帮助。,【开源实习】gemma2模型迁移,任务链接：https://gitee.com/mindspore/community/issues/IAKO2S?from=projectissue,2024-08-25T08:31:48Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1593,本地测试已通过 !image,/model gemma2,pylint已过,已删
这个issue属于用户提出需求类型，主要对象是模型推理过程中的多进程支持，用户希望能够在多进程环境下进行推理操作。,support multi-process inference,,2024-08-23T04:00:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1592
这是一个bug报告，涉及mindnlp.core.nn.Linear()实例化后修改bias值导致输出结果与mindspore.nn.Dense()输出结果存在偏差的问题。,mindnlp.core.nn.Linear()实例化后修改bias的值，最终输出结果与mindspore.nn.Dense()输出结果存在偏差,"**Describe the bug/ 问题描述 (Mandatory / 必填)** mindnlp.core.nn.Linear()实例化后修改bias的值，最终输出结果与mindspore.nn.Dense()输出结果存在偏差  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9.0  OS platform and distribution (e.g., Linux Ubuntu 16.04):   GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** pytest test_modeling_roberta_prelayernorm.py::RobertaPreLayerNormModelIntegrationTest::test_inference_masked_lm **Expected behavior / 预期结果 (Mandatory / 必填)** **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. mindnlp.core.nn.Linear(）输出结果 !20240822105407(WeLinkPC) mindspore.nn.Dense() 输出结果 !20240822105416(WeLinkPC) **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-22T02:57:01Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1591
这是一个bug报告，主要涉及mindnlp下的Sentence transformer，由于代码中存在mindspore.nn到mindnlp.core.nn的修正、expand()到broadcast_to()的修改、以及Tensor.size()的调整，导致代码出现了问题。,Fix Sentence transformer.,修正 mindspore.nn > mindnlp.core.nn 修正 expand() > broadcast_to() 修正 Tensor.size() > Tensor.shape,2024-08-21T10:20:38Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1590,pylint没过,pylint要过,"好的 最近有点忙 过几天来处理下 Original From: ***@***.***&gt; Date: Tue, Aug 27, 2024 17:00 PM To: ***@***.***&gt;; Cc: ***@***.******@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] Fix Sentence transformer. (PR CC(Fix Sentence transformer.)) pylint要过 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",临时急用，我先自己修了
这是一个描述Bug报告类型的Issue，主要涉及对象是mindnlp的sentence_transformer模块。这个问题可能是由于代码错误或配置问题导致的报错。,Sentence transformer 报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** mindnlp.sentence.sentence_transformer.SentenceTransformer 无法使用。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version : 2.2.14  Python version :  3.8.10  OS platform and distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.2  GCC/Compiler version (if compiled from source): 9.4.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: !image **Expected behavior / 预期结果 (Mandatory / 必填)** 应当正常载入模型 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image **Additional context / 备注 (Optional / 选填)**",2024-08-21T03:44:30Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1589
这是一个bug报告，主要涉及到 mindnlp 项目中的 trocr/chatglm3 模块。由于引起的原因是修复 chatglm3 模块的问题，具体内容随之更改。,fix trocr/chatglm3,,2024-08-21T02:00:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1588
这是一个需求类型的issue，主要涉及MindNLP中添加Roberta_prelayernorm模型，由于用户可能希望在项目中使用这个模型而提出该需求。,add model roberta_prelayernorm,add model roberta_prelayernorm,2024-08-20T10:11:06Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1587,/model roberta_prelayernorm,/model roberta_prelayernorm,除一条精度对比用例执行失败，其余所有用例在mindspore2.2.14版本下均执行通过； 其中精度对比失败用例已提issue，issue链接为：https://github.com/mindsporelab/mindnlp/issues/1591
这是一个用户提出需求的issue，主要涉及MindSpore框架中的BERT/CLIP/MixTral算法优化问题，可能是由于Ascend芯片的兼容性或性能优化方面的需求所致。,update bert/clip/mixtral for Ascend,,2024-08-20T04:35:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1586
"这是一个bug报告，涉及的主要对象是 ""g class""，由于未提供具体信息，无法推断导致bug的原因。",fix g class,,2024-08-19T14:19:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1585
这个issue属于bug报告类型，主要涉及对象是ChatGLM3的chat函数，由于113行代码中存在输入属性错误，导致了该bug的症状。,ChatGLM3的chat函数存在属性错误,"**Describe the bug/ 问题描述 (Mandatory / 必填)** chatglm3的chat函数第113行为`inputs = inputs.to(self.device)`导致chat函数无法使用。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-19T13:05:47Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1584
这是一个bug报告，涉及的主要对象是MindNLP中的Tapas模型，在CPU上无法正常运行。由于CPU环境下的特定设置或配置不完善，导致Tapas模型无法正确运行。,fix tapas on CPU,,2024-08-19T09:57:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1583
这是一个bug报告，涉及的主要对象是mindnlp中的类。由于修复t类的问题而导致的bug或用户需求解决。,fix t class,,2024-08-19T09:02:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1582
这是一个bug报告，涉及的主要对象是mindnlp下的TrOCR模型的modeling_trocr.py文件。由于代码中119行出现了语法错误，导致报错。,TrOCR模型 modeling_trocr.py 报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 119行 self.weights = self.weights.to(self._float_tensor) TypeError: For 'Cast', the input 'dtype' should be mindpsore dtype, but got 1. 121行 x = self.weights.index_select(0, position_ids.view(1)).view(bsz, seq_len, 1).deatch AttributeError: 'Tensor' object has no attribute 'detach'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > modelarts cpu   **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version  2.2.14:  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):18.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: model = VisionEncoderDecoderModel.from_pretrained(model_path2) ouputs = model(pixel_values=i, labels=l) **Expected behavior / 预期结果 (Mandatory / 必填)** 正常运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-19T02:18:27Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1581
这是一个用户提出需求的类型的issue，主要涉及MindNLP中的Whisper模块。由于需要更新Whisper功能，用户提出了这个issue。,update whisper,,2024-08-18T14:38:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1580
"这是一个bug报告，主要涉及修复一个名为""f""的类。由于可能存在代码错误或逻辑问题，用户提出了这个bug。",fix f class,,2024-08-17T16:43:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1579
这个issue属于bug报告类型，涉及的主要对象是yoso模块。由于某种原因导致了yoso功能存在问题，需要修复。,fix yoso,,2024-08-17T13:57:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1578
这是一个需要更新类的issue，涉及的主要对象是代码库中的某个类。,update a class,,2024-08-17T12:08:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1577
这个issue类型是bug报告，主要涉及的对象是p class models，由于未提供具体内容，因此无法分析导致的bug症状或用户提出的问题或需求。,fix p class models,,2024-08-17T10:16:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1576
这是一个缺少内容的issue，无法确定类型和涉及的主要对象。,vits迁移,,2024-08-16T13:42:31Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1575,/model vits
这是一个撤销提交的issue，主要涉及到mindnlp项目中的VITS迁移功能。原因可能是该功能存在问题或不符合项目需求。,"Revert ""【开源实习】VITS迁移""",Reverts mindsporelab/mindnlp CC(【开源实习】VITS迁移),2024-08-16T13:04:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1574
这个issue类型为请求更新（update），主要涉及的对象是 qwen2_moe 模块。,update qwen2_moe,,2024-08-16T10:02:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1573
这是一个需求类型的issue，主要涉及的对象是表格问答pipeline功能。由于模型中的ops和nn替换问题导致了功能无法正常运行。,表格问答pipeline,Task链接：https://gitee.com/mindspore/community/issues/I97TQF 使用到的tapas模型中，ops和nn换成从mindnlp导入后存在一些问题，我进行了修改使得tapas模型正常运行，目前仍然存在两个问题 1. transformers中使用到的scatter_reduce方法在mindnlp中暂时没有，原迁移者使用了ops.tensor_scatter_min以及ops.tensor_scatter_max进行替代，这两个方法正在mindnlp.core.ops中也没有，所以这部分暂时使用的还是mindspore.ops !QQ_1723786019783 2. nn.probability使用的是mindspore.nn !QQ_1723786091750 这两个问题可以等mindnlp添加上对应功能后再改为由mindnlp组件实现,2024-08-16T05:33:05Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1572,记得改一下pylint里的问题,已修改
这是一个bug报告类型的issue，涉及的主要对象是functional.py文件中的interpolate()函数，由于出现了scale_factor错误导致的问题。,functional.py文件的interpolate()函数报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** !image ut测试出现interpolate的scale_factor变量类型问题 TypeError: For 'interpolate', the 'scale_factor' must be float, but got 'int'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  GPU/CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version  : Mindspore2.2.14  Python version : python3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): window/Linuxx86_64  GCC/Compiler version (if compiled from source): gcc9  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** pytest test_model_depth_anything.py **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 实例代码： from mindnlp.core.nn import functional as F import mindspore tensor_variable = mindspore.tensor([[1, 2], [3, 4]], dtype=mindspore.float32) size = None modifier = {""scale_factor"": 2} if size is None else {""size"": size} Hidden = F.interpolate(tensor_variable, **modifier, mode='bilinear', align_corners=True) if ""__name__"" == ""__main__"":     print(type(tensor_variable))     print(Hidden) 复刻报错： !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-16T03:32:14Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1571,torch可以用？,目前看起来不太好改,和Pytorch报错相同
"这是一个bug报告，问题涉及到修复""o class""。由于缺失具体内容，无法判断原因和具体症状。",fix o class,,2024-08-16T03:19:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1570
这是一个未提供具体信息的issue。,add model patchtst,add model patchtst,2024-08-16T02:54:19Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1569,/model patchtst,single model test 已执行通过   https://github.com/mindsporelab/mindnlp/actions/runs/10413895057/job/28842004876
这个issue类型是用户提出需求，主要涉及的对象是flaubert模型迁移。由于需求添加requirement依赖库项并替换特定代码，可能导致相关功能或性能问题，用户提出了对模型迁移的特定需求或建议。,flaubert模型迁移,"除了模型迁移本身外，添加requirement依赖库项，在modeling_utils中将modeling_utils的expand全部换成broadcast_to, 将所有的Tensor.gather换位ops.gather，在MT5模型中添加tokenizer 本地测试中只有一个数据类型错误，您在会议上说可以不管，精度测试已通过",2024-08-15T15:08:16Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1568,/model flaubert,!image 本地测试结果如上图所示，仅有一个数据类型错误，您在会上说过该错误可以忽略 !image 唯一精度测试用例如上，该用例测试通过,issue链接：https://gitee.com/mindspore/community/issues/IAK2EF
这是一个bug报告类型的issue，主要涉及VITS模型的迁移问题。由于tokenizer需要安装phonemizer包，但未能成功调用，导致该问题的症状。,【开源实习】VITS迁移,VITS迁移； 模型tokenizer需要安装phonemizer包，已在requirements里添加，utils加了is_phonemizer_available的判断等； 实习任务链接：https://gitee.com/mindspore/community/issues/I9V0JM,2024-08-15T13:44:34Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1567,/model vits,!image,single model test:https://github.com/mindsporelab/mindnlp/actions/runs/10404824352,实习任务：https://gitee.com/mindspore/community/issues/I9V0JM
这是一个空白的issue，类型暂时无法判断。涉及的主要对象是deformable-detr迁移代码。,deformable-detr迁移,,2024-08-15T11:57:59Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1566,/model deformable_detr
这是一个bug报告类型的issue，主要涉及VITS迁移过程中的模型tokenizer的问题。由于缺少phonemizer包，导致utils的is_phonemizer_available函数无法正常运行。,【开源实习】VITS迁移,VITS迁移； 模型tokenizer需要安装phonemizer包，已在requirements里添加，utils加了is_phonemizer_available的判断等； 实习任务链接：https://gitee.com/mindspore/community/issues/I9V0JM,2024-08-15T11:28:54Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1565,!image
这是一个bug报告类型的issue，主要涉及mindnlp的修复i标签的问题。这个问题可能是由于代码逻辑错误或者数据处理异常导致的。,fix i class,,2024-08-15T10:28:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1564
这是一个bug报告，涉及对象是mindnlp.engine.Trainer，由于传入数据shape导致训练报错。,mindnlp.engine.Trainer训练报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** mindnlp.engine.Trainer训练报错 传入数据shape如下图 !image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.0  Python version (e.g., Python 3.7.5) :3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** `from mindnlp.engine import Trainer trainer = Trainer(     model=model,     train_dataset=train_dataset,     eval_dataset=eval_dataset,     args=training_arguments ) trainer.train()` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here. finetuning2_test.zip",2024-08-15T08:25:45Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1563
这是一个bug报告类型的issue，主要涉及mindnlp.peft.LoraConfig类，由于不支持配置target_modules参数而导致lora微调功能无法正常使用。,mindnlp.peft.LoraConfig不支持配置target_modules参数,"**Describe the bug/ 问题描述 (Mandatory / 必填)** lora微调不支持在mindnlp.peft.LoraConfig配置target_modules参数  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.0  Python version (e.g., Python 3.7.5) :3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** `peft_config = LoraConfig(     task_type=TaskType.CAUSAL_LM,      inference_mode=False,     r=64,     lora_alpha=32,     use_rslora=True,     lora_dropout=0.1,     target_modules=[         ""q_proj"",         ""v_proj"",         ""k_proj"",         ""o_proj"",         ""gate_proj"",         ""up_proj"",         ""down_proj"",         ""lm_head""     ] )` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** AttributeError: 'LoraConfig' object has no attribute 'target_cells' 将参数target_modules修改成target_cells后报TypeError: init() got an unexpected keyword argument 'target_cells' **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-15T08:02:13Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1562,fixed
这个issue类型是需求提出，主要涉及的对象是mindnlp项目中的模型clvp和conditional_detr，用户在此提出了关于这两个模型的问题或需求。,模型clvp和conditional_detr,,2024-08-15T04:56:36Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1561,/model clvp,/model clvp,/model conditional_detr,/model clvp
这是一个用户提出需求的issue，在请求支持`nn.AdaptiveLogSoftmaxWithLoss`。,support nn.AdaptiveLogSoftmaxWithLoss,,2024-08-15T04:02:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1560
这是一个bug报告，涉及的主要对象是mindnlp库。由于某种原因导致了在CPU上出现了e class错误。,fix e class error on CPU,,2024-08-15T02:53:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1558
这是一个bug报告类型的issue，主要涉及mindnlp库中的utils模块，由于未封装对应hf中的pytorch_utils导致必要函数缺乏。,utils中缺少对hf中pytorch_utils对应的方法导致必要函数缺乏,**Describe the bug/ 问题描述 (Mandatory / 必填)** utils未封装对应hf的utils中的pytorch_utils对应的api，导致部分函数无法使用 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** 截于transformers： !image 截于mindnlp： !image,2024-08-15T02:45:37Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1557,用ms_utils  去参考其他模型的实现
这是一个用户提出的需求问题，主要涉及GPTSAN-japanese的迁移，可能是由于预训练模型迁移时的技术难点或需要适配新环境等原因引起。,GPTSAN-japanese 迁移,,2024-08-15T00:41:32Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1556,Issue链接：https://gitee.com/mindspore/community/issues/I9UVZU,跑single model测试,/model gptsan_japanese,/model gptsan_japanese,/model gptsan_japanese,!45GX(_9K{)GO}45OUMW)5 前后不兼容问题4个ut没过
这是一个bug报告，问题单涉及的主要对象是mindnlp仓库下的test_utils.py文件。这个问题的原因可能是torch.language方法未正确定义，导致代码在运行时出现错误。,test_utils.py文件中有未定义的torch语段,"1774行开始出现torch.compiler方法 for model_inputs in input_ids_sets:                  dynamic cache                 output_dynamic = model.generate(model_inputs, **generation_kwargs)                  eager static cache                 torch.compiler.reset()                 model.generation_config.cache_implementation = ""static""                 output_static = model.generate(model_inputs, **generation_kwargs)                 self.assertListEqual(output_dynamic.tolist(), output_static.tolist())                  compiled static cache (removes the cache initialized in the previous check, to confirm we can                  initialize the cache in full compiled mode)                 model._cache = None                 torch.compiler.reset()                 generation_config = copy.deepcopy(model.generation_config)                 generation_config.update(**generation_kwargs)                 compiled_generate = torch.compile(model.generate, fullgraph=True, mode=""reduceoverhead"")                 output_compiled = compiled_generate(model_inputs, generation_config=generation_config)                 self.assertListEqual(output_dynamic.tolist(), output_compiled.tolist())",2024-08-14T15:43:49Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1555
这是一个bug报告，涉及的主要对象是mindnlp库中的cosine_similarity函数。由于在CPU上存在问题，导致cosine_similarity函数无法正常工作。,fix cosine_similarity on CPU,,2024-08-14T15:03:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1554
这是一个需求类型的issue，主要涉及的对象是dbrx模型。由于迁移问题，用户寻求关于dbrx模型的帮助。,dbrx模型迁移,,2024-08-14T15:02:57Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1553,/model dbrx,/model dbrx,CI通过：https://github.com/mindsporelab/mindnlp/actions/runs/10390692684,modeling_auto的内容在前一个pr中已添加,issue链接：https://gitee.com/mindspore/community/issues/IAKO3A
这是一个bug报告，涉及TrOCR模型TrOCRProcessor加载时报错，原因可能是加载过程出现了错误。,TrOCR模型TrOCRProcessor加载时报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.14  Python version (e.g., Python 3.7.5) :Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 加载TrOCR预处理：processor = TrOCRProcessor.from_pretrained(""microsoft/trocrbasehandwritten"") **Expected behavior / 预期结果 (Mandatory / 必填)** 正常加载 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-14T11:34:52Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1552
这是一个用户提出需求的issue，主要对象是开源实习项目Pix2struct。,开源实习Pix2struct,,2024-08-14T08:31:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1551,/model pix2struct
这是一个功能需求问题，关于Dbrx模型迁移。 由于某种原因导致希望进行模型迁移，需求相关支持或解决方案。,Dbrx模型迁移,,2024-08-14T07:45:21Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1550,/model dbrx,/model dbrx
这是一个bug报告，该问题涉及mindnlp.peft.LoraConfig类，由于Lora微调不支持配置target_modules参数而导致的问题。,mindnlp.peft.LoraConfig不支持配置target_modules参数,"**Describe the bug/ 问题描述 (Mandatory / 必填)** lora微调不支持在mindnlp.peft.LoraConfig配置target_modules参数  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.0  Python version (e.g., Python 3.7.5) :3.9.19  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: **To Reproduce / 重现步骤 (Mandatory / 必填)** `from mindnlp.peft import (     get_peft_model,     LoraConfig,     TaskType )` `peft_config = LoraConfig(     task_type=TaskType.CAUSAL_LM,      inference_mode=False,     r=64,     lora_alpha=32,     use_rslora=True,     lora_dropout=0.1,     target_modules=[         ""q_proj"",         ""v_proj"",         ""k_proj"",         ""o_proj"",         ""gate_proj"",         ""up_proj"",         ""down_proj"",         ""lm_head""     ] )` **Expected behavior / 预期结果 (Mandatory / 必填)** **Screenshots/ 日志 / 截图 (Mandatory / 必填)** TypeError: __init__() got an unexpected keyword argument 'target_modules' **Additional context / 备注 (Optional / 选填)**",2024-08-14T06:59:29Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1549
这个issue属于bug报告类型，涉及的主要对象是jamba和jetmoe库。由于处理器为CPU时存在问题，导致了无法正常运行jamba和jetmoe的情况。,fix jamba & jetmoe on CPU,,2024-08-14T04:33:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1548
这是一个缺少具体内容的issue，无法确定是何种类型。,模型clvp和conditional_detr迁移,,2024-08-14T04:21:02Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1547,/model clvp,/model conditional_detr,pylint必须过
这是一个bug报告，涉及主要对象是get_tensor_equivalence_function函数。由于两个完全相同的矩阵返回结果错误，推测可能是函数内部对矩阵相等性判断的逻辑有误。, get_tensor_equivalence_function计算有误,当两个矩阵完全相同时，返回结果错误 !OXG20WKBZ 80J9CFJHWEHP !image,2024-08-14T03:53:47Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1546,fixed
这是一个bug报告，问题涉及主要对象为MT5Tokenizer，由于无法找到MT5Tokenizer导致的错误。,Could not find MT5Tokenizer neither in <module 'mindnlp.transformers.models.mt5',**Describe the bug/ 问题描述 (Mandatory / 必填)** Could not find MT5Tokenizer neither in  Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** pytest s v tests/ut/transformers/models/clvp/test_tokenization_clvp.py::ClvpTokenizationTest::test_mindspore_encode_plus_sent_to_model pytest s v tests/ut/transformers/models/clvp/test_tokenization_clvp.py::ClvpTokenizationTest::test_np_encode_plus_sent_to_model **Expected behavior / 预期结果 (Mandatory / 必填)** 修复bug **Screenshots/ 日志 / 截图 (Mandatory / 必填)** **Additional context / 备注 (Optional / 选填)**,2024-08-14T03:52:13Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1545
这是一个bug报告，主要涉及randperm和init.uniform两个功能的修复。,"fix bugs of randperm, init.uniform",,2024-08-14T02:24:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1544
这个issue类型为用户提出需求，涉及对象是更新prefix_tuning_t5，由于需要改进模型的参数调节，用户希望进行相关更新。,update prefix_tuning_t5,,2024-08-13T16:19:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1543
该issue类型为bug报告，主要涉及的对象是peft_model。由于代码中存在错误导致了peft_model功能无法正常使用。,fix peft_model,,2024-08-13T14:07:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1542
这是一个用户提出需求的issue，主要涉及mindnlp库的vision-encoder-decoder支持。,support vision-encoder-decoder,,2024-08-13T09:54:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1541
这是一个bug报告，主要涉及mindnlp仓库的重构cpu调用ops.randperm接口出现问题的情况。由于某些原因导致了相关报错，用户在寻求解决此问题的帮助。,ops.randperm有问题,正常调用mindspore的接口 !image mindnlp仓库的重构cpu有问题： !image 报错如下： !image !image !image !image,2024-08-13T09:42:54Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1540
这是一个bug报告，问题涉及Prophetnet and tapex模型迁移，由于某些原因导致了test_fast_integration测试失败。,Prophetnet and tapex 模型迁移,"Prophetnet and tapex 模型迁移   Prophetnet 测试如下：slow测试均通过，存在一个test_fast_integration的loss精度存在问题，这个精度问题是经过了一个相同定义的word_embeddings产生了差异，参数对比如下 !124df53d32bbfecf8dc4a1bdb2956490 !91de45b237bdb889cdcd0a8676edac08 !8b3f4e3ae0f141298ae4443531d80b6e  Tapex 测试如下:slow测试均通过,存在一个test_chat_template测试错误。测试如下，但根据test_tokenization_common的代码 接收到的table必然是一个str类型，一定会发生类型错误 !3d80fa694d7c4d63b575bc9950cc13f4  被skip的测试在未使用mindslp.core的框架(旧框架)下均已pass Tapex任务链接：https://gitee.com/mindspore/community/issues/I9V044 Prophetnet任务链接：https://gitee.com/mindspore/community/issues/I9UYTF",2024-08-13T09:20:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1539
这是一个bug报告，涉及到找不到LayoutLMTokenizer的问题，可能是由于缺少模块导致的。, Could not find LayoutLMTokenizer neither in <module 'mindnlp.transformers.models.layoutlm',"**Describe the bug/ 问题描述 (Mandatory / 必填)**  Could not find LayoutLMTokenizer neither in  Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: **Expected behavior / 预期结果 (Mandatory / 必填)** 修复bug **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-13T09:17:55Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1538,重现步骤：run slow pytest s v tests/ut/transformers/models/clvp/test_tokenization_clvp.py::ClvpTokenizationTest::test_mindspore_encode_plus_sent_to_model,!image
这个issue是一个bug报告，主要涉及到mindnlp下的mgp_str功能。产生此bug的原因可能是测试代码中存在错误或者对该功能的使用不当。,【开源实习】mgp_str测试,,2024-08-13T08:40:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1537,/model mgp_str
这是一个bug报告，涉及到Mindnlp中初始化模块的uniform函数生成有误的问题。,初始化模块的uniform函数的生成有误,**Describe the bug/ 问题描述 (Mandatory / 必填)** nn.init.uniform和nn.init.uniform_函数的张量生成结果有误，会生成一组全部元素全部等于设置上界的张量，而不是呈现均匀分布。用相同的张量获取方法测试正态分布函数normal可见生成结果正常。 **Expected behavior / 预期结果 (Mandatory / 必填)** 应生成在上界与下界之间呈现均匀分布的一组数据 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image,2024-08-13T05:03:58Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1536
"这个issue类型属于需求提出，主要涉及的对象是更新名为""musicgen""的内容。由于可能需要添加新功能、修复bug或改进性能，用户提出了更新""musicgen""的需求。",update musicgen,,2024-08-13T04:14:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1535
这是一个bug报告，主要涉及mindnlp的0.4.0版本在音乐生成案例更新后API改变导致运行unconditional时出现问题。,音乐生成案例更新后api改变,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 使用mindnlp最新的0.4.0的版本 运行unconditional_inputs = model.get_unconditional_inputs(num_samples=1) 会报错“AttributeError: 'MusicgenForConditionalGeneration' object has no attribute '_get_decoder_start_token_id'”  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1  Python version (e.g., Python 3.7.5) :3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):Eulerosv2r8 4.19.36  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 运行unconditional_inputs = model.get_unconditional_inputs(num_samples=1) 报错：“AttributeError: 'MusicgenForConditionalGeneration' object has no attribute '_get_decoder_start_token_id'” **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-13T01:33:38Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1534
这是一个提出需求的issue，主要涉及的对象是MindNLP项目中的T5、JetMoe和LayoutLMv3模型更新和添加。,"update t5, jetmoe and add layoutlmv3",,2024-08-12T15:06:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1533
这是一个bug报告，问题涉及到的主要对象是hubert模块和Module hooks。由于hubert和Module hooks的问题导致了需要修复的bug。,fix hubert & Module hooks,,2024-08-12T06:36:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1532
该issue属于bug报告类型，主要涉及mindnlp库中调用get_peft_model时，缺少了get_cell函数，导致出现问题。,调用get_peft_model时缺少get_cell,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. mindnlp使用的是daily包的0.4.0版本。 在运行model = get_peft_model(model, peft_config)时，/mindnlp/peft/peft_model.py中transformer_backbone.get_cell报错：'RobertaForSequenceClassification' object has no attribute 'get_cell'。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device Ascend   **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.1  Python version (e.g., Python 3.7.5) : Python 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): eulerosv2r8 4.19.36  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ``` model_name_or_path = ""AIModelScope/robertalarge"" model = AutoModelForSequenceClassification.from_pretrained(model_name_or_path, return_dict=True, mirror=""modelscope"") model = get_peft_model(model, peft_config) ``` `AttributeError: 'RobertaForSequenceClassification' object has no attribute 'get_cell'` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !3c517d96de2f9e525961d300cac66f2 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-12T03:39:28Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1531
这个issue是一个bug报告，针对transformers里缺少要迁移的UL2模型源文件的问题。,transformers里缺少要迁移的UL2模型源文件,**Describe the bug/ 问题描述** https://github.com/huggingface/transformers/tree/main/src/transformers/models参考代码仓中无UL2模型文件，在T5v1.1模型的基础上https://github.com/huggingface/transformers/docs/source/en/model_doc/ul2.md修改迁移发现有很多报错，不知道是不是模型本身的原因造成的. **Software Environment / 软件环境**:  mindspore2.2.14  Python 3.9.19  Ubuntu 20.04.6 LTS **ut报错截图**： !ut_error,2024-08-11T09:22:01Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1530,换一个模型吧
这个issue是关于bug报告，涉及到mindnlp库中的模块导入问题。原因可能是在`modeling_tapas.py`中导入模块时出现了错误。,mindnlp.core.nn和mindnlp.core.ops缺少模块,"**Description** `modeling_tapas.py`中由`from mindspore import nn, ops`换成`from mindnlp.core import nn, ops`之后缺少模块，缺少模块如下：  `ops.gather_elements`  `ops.tensor_scatter_add`  `ops.tensor_scatter_min`  `ops.tensor_scatter_max`  `nn.probability`具体用到的是`nn.probability.distribution`",2024-08-11T04:52:20Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1529,ops.gather_elements => ops.gather ops.tensor_scatter_add => ops.scatter_add ops.tensor_scatter_min => ops.scatter_min ops.tensor_scatter_max => ops.scatter_max,nn.probability暂时别管，要和pytorch对标,ops.scatter_min和ops.scatter_max好像没有，nn.probability暂时别管是先用着mindspore.nn.probability吗
该issue属于用户提出需求类型，主要涉及的对象是在MindNLP项目中添加了`vivit`模型和`conv3d`模块。由于用户可能希望扩展项目功能或增加特定模型和模块，因此提出了这个需求。,Add `vivit` model and `conv3d` module,,2024-08-11T03:58:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1528
这是一个bug报告，涉及的主要对象是框架SGD。由于某种原因导致了无法识别或处理给定的16进制字符串的问题。,框架 SGD 问题,!2c8127c1f46b4b7894f7172eea21cf3a,2024-08-10T02:31:28Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1527
这是一个bug报告，该问题涉及的主要对象是mindnlp中的cache_utils.py文件。由于缺少了zero_方法，导致模型调用时出现错误。,cache_utils.py中缺少zero_方法,模型调用cache_utils.py中             self.key_cache[layer_idx].zero_()     self.value_cache[layer_idx].zero_() 这两行报错StubTensor object has no attribute zeros_,2024-08-09T16:10:18Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1526
该issue类型为模型迁移需求，主要涉及到depth_anything模型。由于需要开源实习，用户可能遇到了模型迁移相关问题或需求帮助。,开源实习depth_anything模型迁移,,2024-08-09T12:20:28Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1525,pr标题要有信息,这个ut是有点问题的，因为interpolate函数中的scale_factor显示数据类型不对 !KSQ5ZO1V8U4(VEBSKC{G_CV 我进入了函数的定义发现scale_factor参数为none，改了为1.0浮点数还是不对 !(9{4{_N3646US9`F$)DIQE4
这个issue类型是用户提出需求，该问题涉及主要对象是更新了GPT IMDb微调示例。,updated gpt imdb finetune example,,2024-08-09T10:13:36Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1524, 
"这是一个bug报告，主要对象是代码库mindnlp中的功能模块""qwen2""。由于更新不完整及存在的bug，导致了需要修复错误的情况。",udate qwen2 & fix bugs,,2024-08-09T07:03:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1523
这是一个bug报告类型的issue，主要涉及mindnlp.core.ops模块缺少'isin'属性所导致的错误。,module 'mindnlp.core.ops' has no attribute 'isin',**Describe the bug/ 问题描述 (Mandatory / 必填)** module 'mindnlp.core.ops' has no attribute 'isin'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: CPU I913900H GPU RTX 4060  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.2.14:  Python 3.9.6  Linux Ubuntu 22.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** mindnlp.core.ops没有 isin **Expected behavior / 预期结果 (Mandatory / 必填)** 修补bug **Screenshots/ 日志 / 截图 (Mandatory / 必填)** module 'mindnlp.core.ops' has no attribute 'isin' **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.,2024-08-09T05:09:40Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1522,rebase最新代码
这个issue类型是bug报告，涉及到mindnlp.core.nn.MultiHeadAttention类的封装错误导致的问题。,mindnlp.core.nn.MultiHeadAttention类封装有误,**Describe the bug/ 问题描述 (Mandatory / 必填)** !image 使用mindnlp.core.nn.MultiHeadAttention时报错 !image 改用mindspore.nn.MultiHeadAttention后前向通路正常,2024-08-09T05:03:29Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1521
这是一个bug报告类型的issue，主要涉及到mindnlp库中的_beam_search函数，由于topk行为异常导致了错误。,由于topk行为异常导致的_beam_search函数错误,topk的行为异常参见这两个issue https://github.com/mindsporelab/mindnlp/issues/1487 https://github.com/mindsporelab/mindnlp/issues/1499 而在mindnlp/transformers/generation/utils.py的_beam_search函数的3228行， !image 这里的topk在GPU下会生成负数索引从而导致索引越界，以至于rag测试无法通过,2024-08-08T13:48:02Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1520
这是一个bug报告类型的issue，主要涉及到mindnlp中的gpt_summarization功能。由于某些原因导致了GPT文本摘要功能出现问题，需要修复。,fix gpt_summarization,,2024-08-08T09:49:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1519
这是一个Bug报告，涉及到AutoModelForCausalLM加载CodeLlama-7b-Instruct-hf时出现的报错问题。,AutoModelForCausalLM加载CodeLlama-7b-Instruct-hf报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 通过mindnlp.transformers.AutoModelForCausalLM加载AIModelScope/CodeLlama7bInstructhf模型时，报错safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge，且已经pip install upgrade safetensor更新至最新版本  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.14  Python version (e.g., Python 3.7.5) :3.9.19  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** `model_name = ""AIModelScope/CodeLlama7bInstructhf""` `tokenizer = CodeLlamaTokenizer.from_pretrained(model_name, mirror=""modelscope"")` `model = AutoModelForCausalLM.from_pretrained(model_name, mirror=""modelscope"")` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.616 seconds. Prefix dict has been built successfully. Loading checkpoint shards:   0% 0/2 [00:00     model = AutoModelForCausalLM.from_pretrained(model_name, mirror=""modelscope"")   File ""/data1/xuhang/envs/nl2sql/lib/python3.9/sitepackages/mindnlp/transformers/models/auto/auto_factory.py"", line 509, in from_pretrained     return model_class.from_pretrained(   File ""/data1/xuhang/envs/nl2sql/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 2911, in from_pretrained     ) = cls._load_pretrained_model(   File ""/data1/xuhang/envs/nl2sql/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 3266, in _load_pretrained_model     state_dict = load_state_dict(shard_file, is_quantized=is_quantized)   File ""/data1/xuhang/envs/nl2sql/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 435, in load_state_dict     with safe_open(checkpoint_file, framework=""np"") as f: safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge **Additional context / 备注 (Optional / 选填)**",2024-08-08T08:40:37Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1518,应该是你文件下载的有问题，重新下载试试，我这边没这个问题
这是一个bug报告，该问题单涉及的主要对象是Mindnlp项目。由于缺少具体内容，需要添加lr_scheduler/clip_grad和修复GroupNorm错误。,add lr_scheduler/clip_grad and fix GroupNorm error.,,2024-08-08T02:56:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1517
这是一个bug报告类型的issue，主要涉及到使用pegasus_x模型进行在线测试时报错的问题。原因可能是模型配置或接口调用等问题导致的。,pr在线测试hubert模型报错,**Describe the bug/ 问题描述 (Mandatory / 必填)** pr在线测试hubert模型报错，测试的是pegasus_x模型 !image,2024-08-07T12:16:43Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1516
这个issue是关于bug报告类型，涉及的主要对象是rag模型的依赖项faiss。导致这个问题的原因是faiss的下载与import指令不一致，可能导致用户无法正确引用faiss模块。,rag模型依赖于faiss，需要添加到requirement里面去,!image 值得注意的是，faiss的下载是pip install faiss_gpu / faiss_cpu 但是他的import是 import faiss,2024-08-07T10:53:06Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1515
这是一个bug报告，涉及Mindnlp库中MS2.2 GPU上的llama错误。可能是由于硬件或驱动兼容性问题导致。,fix llama on MS2.2 GPU,,2024-08-07T10:15:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1514
这是一个bug报告，涉及数据处理过程中出错。由于某种原因导致在运行“next(train_dataset.create_”时出现问题。,数据预处理需要改写,"**Describe the bug/ 问题描述 (Mandatory / 必填)* 在数据预处理后，运行“next(train_dataset.create_tuple_iterator())”会报错“Exception thrown from user ，defined Python function in dataset. “  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : Python 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): eulerosv2r8 4.19.36  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 进行数据预处理 2. 运行“next(train_dataset.create_tuple_iterator())” 报错：“Exception thrown from user defined Python function in dataset. “ **Expected behavior / 预期结果 (Mandatory / 必填)** 正确获取数据迭代批次 **Screenshots/ 日志 / 截图 (Mandatory / 必填)**  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-07T09:50:35Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1513
这是一个bug报告类型的issue，涉及到添加requirement后出现的问题。这个问题可能是由于添加的requirement有误导致的。,florence2添加requirement后,,2024-08-07T09:25:57Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1512,/model florence2,任务issue链接：https://gitee.com/mindspore/community/issues/IA99BM
"这是一个bug报告，涉及的主要对象是sgd_cpu算子。该问题可能由于编程错误或软件版本问题导致了报错 KERNEL(2160,7f1dee679640,python):2024080。",sgd_cpu算子错误,"mindspore2.2.14的x86版本，CPU模式下报错： Error:  KERNEL(2160,7f1dee679640,python):2024080707:46:34.939.920 [mindspore/ccsrc/plugin/device/cpu/kernel/sgd_cpu_kernel.cc:93] Resize] For 'SGD', the shape of 'parameters' must be the same as the shape of 'accum', but got the shape of 'parameters': [const vector]{1, 1, 32} and the shape of 'accum': [const vector]{}",2024-08-07T07:55:29Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1511,!ppppppppppppppp
该issue为bug报告，主要涉及的对象是mindnlp库的CI配置。导致这个问题的原因是pylint错误的发生，用户寻求修复以通过github CI。,fix pylint error on github CI,,2024-08-07T07:15:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1510
这是一个bug报告，主要涉及mindnlp项目中的模型conditional_detr，由于某种原因导致报错.docx文件中描述的问题。,model conditional_detr的报错,报错.docx **Describe the bug/ 问题描述 (Mandatory / 必填)** 问题一：hf_backbone的test一直显示我的config.backbone为none无法通过测试 我看别的模型好像直接把这个test删了不知道为啥 问题二：有个implement error不知道哪里出错了  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU RTX4060 CPU i913900H  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore 2.2.14  Python 3.9.6  Linux Ubuntu 22.04):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** 提供解决方案 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.,2024-08-07T04:42:10Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1509,对比hf最新测试ut和代码再看看
这是一个bug报告类型的issue，主要对象是最新rebase的代码，导致pylint报错。,最新rebase的代码仍然pylint报错,!image,2024-08-07T04:13:31Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1508,fixed
这是一个bug报告，主要涉及的对象是mindnlp库中的错误及缺失的nll_loss和logsigmoid功能。原因可能是函数实现不完整或者存在错误导致的问题。,"fix errors & add nll_loss, logsigmoid",,2024-08-07T03:47:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1507
这个issue类型是需求提交，主要涉及的对象是florence2模型迁移。,florence2模型迁移,,2024-08-06T14:19:05Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1506,/model florence2,该模型没有unit test，采用对比pytorch版本和mindspore版本运行结果来验证迁移效果 pytorch版本运行结果如下： !pytorch版本florence2 mindsporeba版本运行结果如下： !mindspore版本florence2 预测结果完全相同。pylint唯一报错为无法导入einops库，mindspore版本的einops依赖库已采用https://github.com/lvyufeng/einops中的，可正常运行模型,任务issue链接：https://gitee.com/mindspore/community/issues/IA99BM
这个issue类型是bug报告，主要涉及加载huggingface的模型文件出错，可能由于什么样的原因导致了加载llama2的模型文件出错。, 加载llama2的模型文件出错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 加载huggingface的模型文件出错  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  mindnlp: 0.4.0  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : 3.9  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 运行 ```python from mindnlp.transformers import LlamaForCausalLM model = LlamaForCausalLM.from_pretrained('/root/PLMs/llama27b') ``` 其中的路径为huggingface模型文件存储位置：  报错 ",2024-08-06T12:25:03Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1505
这个issue类型为用户提出需求，主要对象是在mindnlp项目中新增一个名为glm4的模块。,add glm4,,2024-08-06T12:22:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1504
这是一个bug报告，涉及FLANUL2模型无法找到需要迁移的源代码。由于找不到源代码，导致该bug出现。,FLAN-UL2模型无法找到需要迁移的源代码，只有一篇md文件,**Describe the bug/ 问题描述 (Mandatory / 必填)** FLANUL2模型无法找到需要迁移的源代码，只有一篇md文件 在transformers/models路径未找到FLANUL2模型源码 !image 全局搜索flauul2仅有一篇md文件 !image,2024-08-06T11:46:55Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1503,这个模型就是t5结构，可以换个模型做
这是一个bug报告，问题涉及mindnlp.core.nn中functional模块缺少nll_loss函数，可能是由于功能缺失或者遗漏所导致的。,mindnlp.core.nn 的functional 缺少 nll_loss ,!Screenshot 20240806 192808 mindnlp.core.nn 的functional 缺少 nll_loss ,2024-08-06T11:31:12Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1502
这是一个bug报告，主要涉及mindnlp中的依赖库问题，导致florence2模型无法正确运行。,必要依赖库列表中添加库einops,**Describe the bug/ 问题描述 (Mandatory / 必填)** florence2模型要求使用einops库，该库不在pylint测试列表中，会导致florence2模型的pylint门禁过不了，需要将该库添加到依赖列表中,2024-08-06T11:25:01Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1501,fixed
"这是一个用户提出需求的类型的issue，主要涉及的对象是""florence2模型""。由于需要进行模型迁移，用户可能遇到了一些问题或需要额外的帮助。",florence2模型迁移,,2024-08-06T09:33:41Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1500,/model florence2,mindspore版本florence2运行结果 !mindspore版本florence2 pytorch版本florence2运行结果： !pytorch版本florence2 运行结果完全相同，其中mindspore版本用到的einops库已使用https://github.com/lvyufeng/einops中的代替
这是一个bug报告类型的issue，主要涉及mindnlp中的ops.topk计算结果错误的问题，导致了用户求出的tensor结果有误。,ops.topk计算结果有误 / ops.sort问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** ops.topk求出tensor结果有误，mindspore中的一个tensor[[3.4028235e+38 2.0206820e+01 3.4028235e+38 ... 3.4028235e+38 3.4028235e+38 3.4028235e+38]]，只有索引为1和96104的值不为3.4028235e+38，其他均为3.4028235e+38，用ops.topk求4个最大元素对应的索引，求出索引的值为[1, 96104, 1, 1]，而pytorch的结果是[ 1, 96104, 0, 2] 将ops.topk改为ops.sort的时候，输入相同的tensor直接卡住无响应  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9.11  OS platform and distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.4  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: PyNative **To Reproduce / 重现步骤 (Mandatory / 必填)** 1. 加载tensor value 链接: https://pan.baidu.com/s/1renSO8veantlFOTdNVn3bg?pwd=jhu3 提取码: jhu3 2. 用ops.topk求这个tensor前4个最大值 / 用ops.sort对这个tensor排序 3. 测试代码 import numpy as np import mindspore from mindspore import ops, Tensor numpy_array = np.loadtxt('tensor_values.txt', delimiter=',') tensor = Tensor(numpy_array, dtype=mindspore.float32) sorted_scores, sorted_indices = ops.topk(tensor, 4, dim=1, largest=True, sorted=True) print(sorted_indices) **Expected behavior / 预期结果 (Mandatory / 必填)** [1 96104 0 2] **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !283d64c8_14506514 **Additional context / 备注 (Optional / 选填)** 该bug导致PegasusX模型迁移后slow test中test_seq_to_seq_generation报错，同时导致后面的PegasusStandaloneDecoderModelTest CopyTensorDataToDevice报错 !截屏20240805 20 15 12 若skip掉test_seq_to_seq_generation，则后面的不会报错 !截屏20240805 20 12 03",2024-08-06T07:24:01Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1499
这是一个bug报告，主要对象是使用daily包时需要手动安装pytesseract模块。,使用daily包需要手动安装pytesseract模块 ,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 重构前不需要手动安装，使用daily包后需要手动安装（pip install pytesseract）  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): eulerosv2r8 4.19.36  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. pip install https://repo.mindspore.cn/mindsporelab/mindnlp/newest/any/mindnlp0.4.0py3noneany.whl 2. from mindnlp.transformers import MusicgenForConditionalGeneration 报错： no model named'pytesseract' **Expected behavior / 预期结果 (Mandatory / 必填)** 正常导入模块 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-06T03:46:30Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1498
这是一个bug报告，该问题涉及的主要对象是无法从mindnlp.engine导入Evaluator等模块。由于安装daily包之后，导致无法正确导入指定模块。,daily包无法从mindnlp.engine导入Evaluator等模块,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 安装daily包之后 无法从mindnlp.engine（或mindnlp._legacy.engine）处导入Evaluator，无法从mindnlp.engine.callbacks处导入CheckpointCallback, BestModelCallback，没有模块mindnlp.metrics。 例如 `from mindnlp.engine import Trainer` 可以正常运行, 而`from mindnlp.engine import Evaluator` 会报错 `cannot import name 'Evaluator' from 'mindnlp.engine'`。 代码在0.3.1能正常运行，但是是从mindnlp._legacy.engine引入模块的。在daily版本下，不论是否添加_legacy都无法导入模块。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device ascend   **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.3.0  Python version (e.g., Python 3.7.5) : Python 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): eulerosv2r8 4.19.36  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. pip show mindnlp（初始环境未安装mindnlp） 2. pip install https://repo.mindspore.cn/mindsporelab/mindnlp/newest/any/mindnlp0.4.0py3noneany.whl 3. from mindnlp.engine import Trainer, Evaluator     报错 cannot import name 'Evaluator' from 'mindnlp.engine' 4. from mindnlp.engine.callbacks import CheckpointCallback, BestModelCallback     报错 cannot import name 'CheckpointCallback' from 'mindnlp.engine.callbacks' 5. from mindnlp.metrics import Accuracy     报错 No module named 'mindnlp.metrics' **Expected behavior / 预期结果 (Mandatory / 必填)** 正常导入模块 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-08-06T02:38:29Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1497,"0.3.1目录结构是`mindnlp._legacy.engine`，0.4.0目录改为 ``` from mindnlp.engine import Trainer, Evaluator from mindnlp.metrics import Accuracy from mindnlp.engine.callbacks import CheckpointCallback, BestModelCallback ``` 但是Evaluator依然not found"
这是一个用户提出需求的issue，主要对象是开源项目MindNLP中的PegasusX模型。,开源实习PegasusX模型,,2024-08-05T13:34:16Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1496,测试single model test,/model pegasus_x,/model pegasus_x,/model pegasus_x
该issue是一个用户提出需求类型的问题，主要涉及的对象是模型应用开发。,【开源实习】Audio Spectrogram Transformer模型应用开发,任务链接：https://gitee.com/mindspore/community/issues/IAAD7O,2024-08-05T12:06:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1495
这是一个关于代码贡献的 issue，涉及到Xlnet模型迁移的问题。 rebase后重新提交的 PR 可能与之前的提交产生了冲突，导致需要重新提交以解决这个问题。,Xlnet模型迁移,rebase了一下，重新提交了pr,2024-08-05T07:20:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1494,\model xlnet
这个issue类型是bug报告，主要对象是mindnlp.core.nn.ops模块，由于缺少uniform()方法导致出现了问题。,mindnlp.core.nn.ops缺少方法uniform(),**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-08-05T05:40:21Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1493,这个方法是在哪使用的？,"在这个语句中使用hidden_states *= ops.zeros(hidden_states.shape,hidden_states.dtype).uniform(       1.0  self.moe_jitter_eps, 1.0 + self.moe_jitter_eps )",使用规避写法解决
这是一个bug报告类型的issue，主要涉及mindnlp.core库缺少了函数logsigmoid，导致产生问题。,mindnlp.core缺少函数logsigmoid,"**Describe the bug/ 问题描述 (Mandatory / 必填)** mindnlp.core.nn\mindnlp.core.ops\mindnlp.core.nn.functional均无函数logsigmoid，该函数在mindspore.ops.nn_functional中存在，希望在mindnlp上有所补充  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 2.2.14) :  Python version (e.g., Python 3.9.19) :  OS platform and distribution (e.g., Windows10):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative'/'Graph`)**: > /mode graph **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !缺少函数",2024-08-05T03:04:03Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1492
这是一个用户提出需求的issue，主要对象是新增优化器和更新bloom模型至最新版本。这个需求可能是由于项目需要跟随最新的技术发展或者改进模型性能而提出的。,add optimizer & fupdate bloom model to newest,,2024-08-05T02:17:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1491
这是一个用户请教问题类型的issue，主要涉及mindnlp中的models模块下的modeling_pix2struct.py文件中的is_torch_fx_proxy函数的替换问题。由于迁移mindnlp时，用户需要知道该函数如何替换或直接删除。,请问这个函数应该怎么替换？,"做mindnlp迁移时在mindnlp的models中modeling_pix2struct.py文件的is_torch_fx_proxy函数怎么替换，直接删除吗？  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 2.2.14) :  Python version (e.g., Python 3.8) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): !Screenshot 20240804 174250",2024-08-04T10:07:25Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1490
这是一个bug报告，主要涉及的对象是mindnlp/transformers库下的tokenization_utils_base.py文件的第680行代码。由于代码中的判断条件错误导致了此bug。,最新版mindnlp/transformers/tokenization_utils_base.py 的 680行,这行代码为 if tensor_type == TensorType.M: 应该改为 if tensor_type == TensorType.MINDSPORE:,2024-08-03T12:38:25Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1489,ok
这个issue类型为用户提出需求，主要对象是SuperPoint模型迁移，可能是由于模型迁移过程中遇到了问题或需要帮助。,【开源实习】SuperPoint模型迁移 ,Issue链接：https://gitee.com/mindspore/community/issues/I9V027,2024-08-03T08:29:44Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1488,/model superpoint,/model superpoint,/model superpoint,/model superpoint,/model superpoint,CI已通过：https://github.com/mindsporelab/mindnlp/actions/runs/10280347844/job/28447487682
这个issue属于bug报告，主要涉及mindspore库中的topk函数在CPU和GPU下的行为异常，可能由于版本或cuda环境不兼容导致输出结果异常。,topk函数在CPU和GPU下的行为异常," 版本 mindspore==2.2.14, cuda == 11.6  问题 如图，对于这个测试代码，在CPU模式下，topk的输出是真正确的 而在GPU模式下，topk的输出出现了可怕的1 !image 下面的代码供复现错误 ``` python import mindspore as ms from mindspore import ops import numpy as np  初始化环境 ms.context.set_context(mode=ms.context.GRAPH_MODE, device_target=""CPU"")  创建一个包含 inf 的张量 x = ms.Tensor([[3.40282347e+38, 0.2, 3.40282347e+38, 3.40282347e+38],                [3.40282347e+38, 3.40282347e+38, 0, 3.40282347e+38],                [3.40282347e+38, 3.40282347e+38, 3.40282347e+38, 0]], dtype=ms.float32) print(x.topk(3)) ```",2024-08-03T02:53:26Z,bug,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/1487,算子问题，mindspore的正负无穷无法参与计算 这种需要替换为 ops.finfo(dtype).min或者.max
这个issue类型是bug报告，涉及到修复新模块上的一些错误，由于什么样的原因导致了这些bug需要修复。,fix some bugs on new modules,,2024-08-02T13:43:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1486
这个issue类型是bug报告，主要对象是Xlent模块。由于什么样的原因导致了该问题具体症状需要进一步分析。,Xlent,,2024-08-02T10:23:12Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1485,\model xlnet
这个issue类型是需要更新到最新版本的需求，主要涉及mindnlp库中的transformers模块，由于huggingface发布了更新版本，用户希望mindnlp库也能及时跟进更新。,update mindnlp.transformers to newest huggingface version,,2024-08-02T03:49:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1484
这是一个bug报告，涉及主要对象是ChatGLM在Ascend平台上运行推理时NPU AICore占用为0%，可能是由于某种原因导致NPU AICore占用为0%的症状。,ChatGLM在Ascend平台运行推理时NPU AICore占用为0%,问题：ChatGLM在Ascend平台运行推理时NPU AICore占用为0% 运行环境：modelart平台，mindspore_2.2.12cann_7.0.1.1py_3.9euler_2.10.7aarch64snt3p， mindnlp0.3.1    处理器：Ascend: 1*Ascend Snt9|ARM: 24核 96GB   运行代码：运行仓库中的llm/inference/chatglm/cli_demo.py 推理代码 https://github.com/mindsporelab/mindnlp/blob/master/llm/inference/chatglm/cli_demo.py 现象：运行推理代码后，输入对话，运行速度慢迟迟得不到回复，查看发现cpu有占用较高，NPU HBM占用90%多，内存占用22G，NPU AICore一直0%占用。 请问这个现象是否正常，推理速度非常慢。问一句话后等15多分钟才出结果 !屏幕截图 20240801 174901,2024-08-01T10:05:14Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1483,两个问题 1. 华为云的环境大概率没装二进制算子办，所以一直在编译 2. 用2.3动态图速度才快
这是一条bug报告，涉及的主要对象是mindnlp库中的A-G类在GPU上使用时的问题。 原因可能是与微软MS2.2的兼容性问题导致的bug。,fix A-G class on GPU with MS2.2,,2024-07-31T16:53:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1482
这是一个bug报告，主要对象是mindnlp中的scatter算法，由于bug导致beamsearch出错。,fix scatter caused beamsearch error,,2024-07-31T16:35:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1481
这是一个缺少内容的issue，用户提出了关于开源实习Idefics模型的问题。, 开源实习Idefics模型,,2024-07-31T10:34:14Z,,closed,0,13,https://github.com/mindspore-lab/mindnlp/issues/1480,/model idefics,slow运行结果 !idefics_slow_test,/model idefics,/model idefics,/model idefics,/model idefics,/model idefics,/model idefics,/model idefics,/model rag,/model idefics,ci连接（pytestyo由于内存不足无法通过，因此这里给出本地截图） https://github.com/mindsporelab/mindnlp/actions/runs/10293732530 slow运行结果 !idefics_slow_test 任务issue链接：https://gitee.com/mindspore/community/issues/I9UW47,已经修正
这个issue类型为用户提出需求，该问题单涉及的主要对象是Mindnlp项目中的RAG模型。,开源实习RAG模型,,2024-07-31T10:32:35Z,,closed,0,12,https://github.com/mindspore-lab/mindnlp/issues/1479,/model idefics,/model rag,/model rag,/model rag,/model rag,/model rag,/model rag,/model,/model rag,解一下冲突,/model rag,hf源码报错 !1d01e8b96fbb715faf245af49b9ac849 这是迁移后的错误 !41de1deb27bf5010c59641858dc0e7f1 ci链接 https://github.com/mindsporelab/mindnlp/actions/runs/10317334086 issue链接 https://gitee.com/mindspore/community/issues/I9UZ03
这是一个bug报告，主要涉及mindnlp部分代码出现import错误。由于本地测试使用的是2.2.14的gpu版本，而测试使用的是2.3.0的mindspore，可能是版本不匹配导致的问题。,"pr在线测试,时，mindnlp部分代码出现mport错误",!)025Z}T0~GZ$~)7A3{I~0C0 我在本地测试用的是2.2.14的gpu版本，但是测试用的是2.3.0的mindspore，不知道是不是版本原因导致的 !)025Z}T0~GZ$~)7A3{I~0C0,2024-07-31T09:03:52Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1478,fixed
这是一个bug报告，涉及mindnlp.core.ops.nonzero()接口实现错误，导致该接口无法正确使用。,nonzero()接口问题,"mindnlp.core.ops.nonzero()接口有错误，其定有为： def nonzero(input, *, as_tuple=False):     if USE_PYBOOST:         return mindspore.mint.nonzero(input, as_tuple)     return ops.nonzero(input，as_tuple) 但ops.nonzero()仅接收一个参数,会报参数过多的错误",2024-07-31T08:38:43Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1477,fixed
这是一个用户提出需求的issue， 主要涉及Mindnlp是否支持Electra模型。,support electra,,2024-07-31T04:06:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1476
这个issue类型是开源实习任务需求，主要涉及的对象是idefics模型，用户提出了关于开源实习任务的需求或寻求相关帮助。,开源实习-idefics模型,[开源实习idefics模型],2024-07-31T04:05:41Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1475,/model idefics,https://gitee.com/mindspore/community/issues/I9UW47,本地测试全部通过（fast or slow） !idefics_slow_test,/model idefics,/model idefics,/model idefics,/model idefics
该issue为用户提出需求，希望添加新的CI Pip，主要对象是MindNLP项目。,add new ci pip,,2024-07-31T02:29:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1474
这是一个需求类型的issue，主要涉及mindnlp库中的ops.unfold功能。此问题可能由于用户需要使用ops.unfold功能，但目前库中尚不支持该功能所致。,support ops.unfold,,2024-07-31T01:57:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1473
"这是一个用户提出需求的类型，涉及主要对象是""xlnet_model模型""，用户提出了关于模型迁移的问题或者寻求迁移模型的帮助。",'xlnet_model模型迁移',本地的ut测试已经全部通过,2024-07-31T01:02:20Z,,closed,0,13,https://github.com/mindspore-lab/mindnlp/issues/1472,任务链接： https://gitee.com/mindspore/community/issues/I9V052,/model_xlnet,/model xlnet,/model xlnet,/model xlnet,/model xlnet,/model xlnet,/model xlnet,添加了新的版本 去掉了模型中的注释,> 快速过了一遍，暂时没有发现更多问题。需要git rebase一下代码 好的，已经rebase了,有几个pylint的问题需要修改一下。另外，需要把当前分支rebase到master分支上，并且将所有修改合并成一个commit哈,\model xlent,> 有几个pylint的问题需要修改一下。另外，需要把当前分支rebase到master分支上，并且将所有修改合并成一个commit哈 好的，已经全部合并commit了
这是一个bug报告，主要涉及修复O、P、Q和R类模型。原因可能是当前模型存在错误或问题，需要进行修复。,"fix O,P,Q,R class models",,2024-07-30T17:28:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1471
"这是一个bug报告，主要对象是mindnlp下的M,N class models。由于修复这些模型导致的bug或错误，用户提交了这个issue。","fix M,N class models",,2024-07-30T10:22:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1470
这是一个用户提出需求的问题，涉及对象是mindspore库中的.detach()函数。由于mindspore库似乎没有提供.detach()方法，用户疑惑是否可以直接删除此操作。,关于.detach()函数应该怎么处理,mindspore似乎没有提供.detach()方法，可以直接删掉吗,2024-07-30T09:22:18Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1469,直接删除
这是一个bug报告，主要涉及mindnlp库中的缺少logsumexp函数的问题，可能由于未更新相关模块导致此问题。,mindnlp.core.ops缺乏logsumexp函数,logsumexp本来是在mindspore.ops中的，但是现在无论是mindnlp.core.ops还是mindnlp.core.nn.functional都没有,2024-07-30T08:59:40Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1468,rebase最新代码
这是一个bug报告，涉及了mindnlp的xlnet模型在ops.einsum操作中出现相同输入不同输出的问题。,ops.einsum相同的输入，不同的结果输出,**Describe the bug/ 问题描述 (Mandatory / 必填)** 我在调试mindnlp的xlnet迁移时发现分别进行两次模型调用，即便输入相同，在ops.einsum()得到的结果却不同。 !image 如上图所示，两次输入完全相同，但是得到的两个输出却不同： !image 我进行跟踪调试后，发现是从ops.einsum处开始出现的不同： !@ `__8 HLK5`H(KEQUWQ877_tmb 并且无论是mindnlp自带的ops，还是mindspore的ops都会存在这种问题，我进一步跟踪ops的运算过程，发现不同之处在运算的最后一个部分：   **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: ubuntu22.04 gpu版本的mindspore2.2.14 python3.9.1  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: 目前使用pdb调试，正常运行也是相同的bug **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: pytest pdb v s tests/ut/transformers/models/xlnet,2024-07-30T06:21:13Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1467
这个issue是一个bug报告，主要涉及MindNLP库中的L类模型。由于某种原因，导致L类模型出现了错误。,fix L class models,,2024-07-30T05:58:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1466
这是一个bug报告，主要涉及mindnlp.core.nn.module中没有提供requires_grad属性或方法这一问题。问题可能是由于遗漏或错误导致的。,mindnlp.core.nn.module/module_list 没有提供requires_grad属性或方法,在之前的nn.Cell里面提供了requires_grad属性和方法，然而在core.nn.module中没有,2024-07-30T03:23:56Z,bug,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1465,具体怎么用的,对于一个参数，我们有 p.requires_grad这个属性，可以通过赋值True or False来改变 对于模型，则是提供了 cell_var._requires_grad(bool_val)这个函数，具体内容是 for p in cell_var.get_parameters(): p.requires_grad = bool_val 需要在nn.core.moudle / module_list这些类上增加这个方法,ok,fixed
这个issue类型是bug报告，主要涉及对象是mindnlp.core模块，由于代码中的pylint错误导致的bug。,fix mindnlp.core pylint,,2024-07-29T16:04:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1464
这是一个需求提出类型的issue，涉及主要对象是randperm接口，用户提出了需要使用该接口的需求。,需要用到randperm接口,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-07-29T12:46:19Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1463,下一个pr加入
这是一个bug报告类型的issue，主要涉及I/J/K类模型的修复。原因可能是这些模型存在一些错误或问题需要修复。,fix I/J/K class models,,2024-07-29T12:42:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1462
这是一个Bug报告，针对MindNLP中的sam模块中的batched_nms接口问题。该问题导致使用batched_nms输出为空。,sam中batched_nms接口有问题,**使用batched_nms输出为空** A clear and concise description of what the bug is.  **Hardware Environment(`CPU`)   **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version  :2.2.14  Python version  :Python 3.9.19  OS platform and distribution:20.14  GCC/Compiler version :9.4.0 !3d7acf1b45a1040a8960fd9420d09aac,2024-07-29T12:36:37Z,bug,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1461
这是一个bug报告，问题单涉及的主要对象是mindnlp的repeat函数，由于重构之前repeat函数跳转到错误的处理函数中，导致出现了该问题。,repeat函数问题,"在重构之前， repeat函数会跳转到mindnlp/injection.py函数中进行处理，具体来说是 return ops.tile(self,turple(sizes)),这使得repeat函数能够容忍输入不为turple的情况 重构之后，由于repeat会跳转到mindspore/common/tensor的repeat函数，这与原先mindnlp的repeat有些许出入，而且他不容忍输入部位turple的情况",2024-07-29T12:10:27Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1460,直接改成ops.tile，这部分不再打补丁处理了
这是一个用户提出需求的issue，主要涉及到mindnlp库中的core.ops模块，由于缺少了nansum函数，用户需求添加该功能。,mindnlp.core.ops没有nansum,,2024-07-29T11:41:07Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1459,下一个pr加入
这是一个bug报告，涉及到mindnlp.core.ops模块缺少gather_elements函数的问题，导致xlnet模型迁移时ut测试出现错误。,mindnlp.core.ops没有gather_elements,xlnet模型迁移，ut测试显示mindnlp.core.ops没有gather_elements,2024-07-29T11:10:28Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1458,用ops.gather
这是一个bug报告，主要涉及mindnlp/transformers库中的modeling_utils内部函数的错误，导致函数逻辑实际与预期不符。,mindnlp/transformers/modeling_utils内部函数错误," 原函数为 ```python     def invert_attention_mask(self, encoder_attention_mask: Tensor) > Tensor:         """"""         Invert an attention mask (e.g., switches 0. and 1.).         Args:             encoder_attention_mask (`mindspore.Tensor`): An attention mask.         Returns:             `mindspore.Tensor`: The inverted attention mask.         """"""         if encoder_attention_mask.ndim == 3:             encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]         if encoder_attention_mask.ndim == 2:             encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]         else:             encoder_extended_attention_mask = encoder_attention_mask ```  应该改为(把第二个if改成elif) ```python     def invert_attention_mask(self, encoder_attention_mask: Tensor) > Tensor:         """"""         Invert an attention mask (e.g., switches 0. and 1.).         Args:             encoder_attention_mask (`mindspore.Tensor`): An attention mask.         Returns:             `mindspore.Tensor`: The inverted attention mask.         """"""         if encoder_attention_mask.ndim == 3:             encoder_extended_attention_mask = encoder_attention_mask[:, None, :, :]         elif encoder_attention_mask.ndim == 2:             encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]         else:             encoder_extended_attention_mask = encoder_attention_mask ```",2024-07-29T10:48:47Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1457,很显然，按照原文逻辑如果 ndim == 3 他会进入第一个if，处理完之后，再最后一个else中被恢复成最初的样子,fixed
这个issue类型是bug报告，主要对象是fix G\H class models。通过分析发现可能是由于模型类别的特定问题导致了bug。,fix G\H class models,,2024-07-29T08:48:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1456
这是一个bug报告，涉及的主要对象是mindnlp.core.ops.count_nonzero函数。由于ops.count_nonzero函数的axis参数不能为None，而mindnlp.core.ops.count_nonzero函数的dim参数默认为None，导致了这个issue。,ops.count_nonzero的axis参数不能为None这能为（）,mindnlp.core.ops.count_nonzero的dim参数默认为None，但是ops.count_nonzero的axis参数不能是None,2024-07-29T08:33:32Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1455
这是一个bug报告，涉及mindnlp库中的ops.nonzero函数在不同版本中参数不一致的问题，由于2.2版本没有as_tuple参数而2.3版本有，导致了函数在不同版本中不一致的情况。,2.2版本的ops.nonzero没有as_tuple参数,ops.nonzero在2.2版本没有as_tuple这个参数，但是mindspore在2.3版本有了这个参数，这就导致了这个函数在两个不同版本不一致，这种情况下请问mindnlp.core是否需要兼容2.2版本,2024-07-29T08:31:33Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1454,fixed
这是一个bug报告，涉及mindspore.Tensor.unfold方法的调用问题。由于传递给mindspore.ops.unfold的参数未正确指定，导致出现问题。,mindspore.Tensor.unfold的问题,"mindspore.Tensor.unfold调用的是mindspore.ops.unfold(input, kernel_size, dilation=1, padding=0, stride=1)，对应torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1)，但不符合我的试验要求，我需要和torch.Tensor.unfold((dimension, size, step) 功能一致的函数",2024-07-29T07:13:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1453
这是一个bug报告，问题涉及到mindnlp.core.ops库中缺少了两个函数，分别是one_hot和is_tensor。由于缺少这两个函数，导致用户无法使用这些功能，因此提出了这个问题。,mindnlp.core.ops缺乏这两个函数, one_hot 这个函数本来在mindspore.ops和torch.nn.functional中  is_tensor 这个函数本来在mindspore.ops和torch中,2024-07-29T04:20:27Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1452,one_hot跟pytorch一样，用nn.functional的,AttributeError: module 'mindnlp.core.nn.functional' has no attribute 'one_hot',rebase最新pr
这是一个空白的issue，类型无法确定。,fix F class models,,2024-07-29T04:07:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1451
这是一个关于功能需求的issue，主要涉及到mindnlp.ops中缺乏one_hot功能的问题，导致用户无法使用该功能。,one_hot实现（xlnet迁移）,目前mindnlp.ops中没有实现one_hot功能，而mindspore.ops中是具备的,2024-07-29T02:53:54Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1450,用mindnlp.core.nn.functional.one_hot
这是一个功能需求问题，用户希望在mindnlp中实现index_select功能，目前尚未实现。,mindnlp缺少index_select,!image mindspore的ops中是具有index_select的，但是mindnlp目前我看了还没有实现,2024-07-29T02:13:48Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1449,使用的是xlnet的模型迁移
这个issue属于bug报告类型，主要涉及的对象是vec_multiple_sel功能。由于某种原因导致症状为至少一个src的bug。,bug: vec_multiple_sel at least has one src,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.   Ascend Error Message:  E40021: Failed to compile Op [Select121]. (oppath: [Compile /usr/local/Ascend/ascendtoolkit/7.0.1/opp/builtin/op_impl/ai_core/tbe/impl/select.py failed with errormsg/stack: File ""/usr/local/Ascend/ascendtoolkit/latest/python/sitepackages/tbe/dsl/instrinsic/cce_intrin_md.py"", line 5772, in vec_multiple_sel     raise RuntimeError(""vec_multiple_sel at least has one src"") RuntimeError: [EB9999] vec_multiple_sel at least has one src', 'errPcause': ' ', 'errSolution': ' '} ], optype: [Select])         Solution: See the host log for details, and then check the Python stack where the error log is reported.         TraceBack (most recent call last):         Compile op[Select121] failed, oppath[/usr/local/Ascend/ascendtoolkit/7.0.1/opp/builtin/op_impl/ai_core/tbe/impl/select.py], optype[Select], taskID[243]. Please check op's compilation error message.[FUNC:ReportBuildErrMessage][FILE:fusion_manager.cc][LINE:771]         [SubGraphOpt][Compile][ProcFailedCompTask] Thread[281460682519008] recompile single op[Select121] failed[FUNC:ProcessAllFailedCompileTasks][FILE:tbe_op_store_adapter.cc][LINE:954]         [SubGraphOpt][Compile][ParalCompOp] Thread[281460682519008] process fail task failed[FUNC:ParallelCompileOp][FILE:tbe_op_store_adapter.cc][LINE:1001]         [SubGraphOpt][Compile][CompOpOnly] CompileOp failed.[FUNC:CompileOpOnly][FILE:op_compiler.cc][LINE:1127]         [GraphOpt][FusedGraph][RunCompile] Failed to compile graph with compiler Normal mode Op Compiler[FUNC:SubGraphCompile][FILE:fe_graph_optimizer.cc][LINE:1292]         Call OptimizeFusedGraph failed, ret:1, engine_name:AIcoreEngine, graph_name:partition0_rank1_new_sub_graph3[FUNC:OptimizeSubGraph][FILE:graph_optimize.cc][LINE:131]         subgraph 0 optimize failed[FUNC:OptimizeSubGraphWithMultiThreads][FILE:graph_manager.cc][LINE:996]         build graph failed, graph id:120, ret:1[FUNC:BuildModelWithGraphId][FILE:ge_generator.cc][LINE:1615]         [Build][SingleOpModel]call ge interface generator.BuildSingleOpModel failed. ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161]         [Build][Op]Fail to build op model[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145]         build op model failed, result = 500002[FUNC:ReportInnerError][FILE:log_inner.cpp][LINE:145] (Please search ""Ascend Error Message"" at https://www.mindspore.cn for error code description)   Ascend Warning Message:  W11001: Op [Cast2] does not hit the highpriority operator information library, which might result in compromised performance. W49999: If want to reuse binary file, please donwload binary file and install first![FUNC:BuildFusionOp][FILE:fusion_manager.cc][LINE:3763] W11001: Op [ReduceSum17] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [Cast22] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [Cast31] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [ReduceProd117] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [ReduceMax119] does not hit the highpriority operator information library, which might result in compromised performance. W49999: Compile error message is:[File ""/usr/local/Ascend/ascendtoolkit/latest/python/sitepackages/tbe/dsl/instrinsic/cce_intrin_md.py"", line 5772, in vec_multiple_sel     raise RuntimeError(""vec_multiple_sel at least has one src"") RuntimeError: [EB9999] vec_multiple_sel at least has one src', 'errPcause': ' ', 'errSolution': ' '} ]. [FUNC:ReportBuildErrMessage][FILE:fusion_manager.cc][LINE:763] W49999: Open  failed, file is already open[FUNC:GetJsonValueFromJsonFile][FILE:fusion_util.cc][LINE:1516]  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片 华为910b  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.2.14  Python version 3.9.2  OS platform and distribution ubuntu 20.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ``` import mindspore;mindspore.set_context(device_target='Ascend'); from mindnlp.transformers import AutoTokenizer, Qwen2Config from mindnlp.transformers import (         Qwen2ForCausalLM,         Qwen2ForSequenceClassification,         Qwen2Model,     ) EXPECTED_TEXT_COMPLETION = """"""My favourite condiment is 100% ketchup. I love it on everything. I’m not a big"""""" prompt = ""My favourite condiment is "" model_name_or_path = ""/models"" tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=False) model = Qwen2ForCausalLM.from_pretrained(model_name_or_path) input_ids = tokenizer.encode(prompt, return_tensors=""ms"")  greedy generation outputs generated_ids = model.generate(input_ids, max_new_tokens=20, temperature=0.1) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 模型正常推理 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-07-29T01:14:27Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1448,910b建议升级MindSpore2.3,cann升级8.0
这是一个bug报告，问题单涉及的主要对象是E class models。由于E class models存在问题，导致需要对其进行修复。,fix E class models,,2024-07-28T16:07:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1447
这是一个bug报告类型的issue，涉及主要对象为mindnlp的模型迁移。这个问题可能是由GPU和CPU版本在运行过程中出现的kernel问题所导致。,GPU和CPU版本运行出现kernel问题：,**Describe the bug/ 问题描述 (Mandatory / 必填)** 目前用mindnlp对xlnet进行模型迁移，先用2.3.0的Mindspore（目前只有gpu版本）测试，发现会议如下错误： !U96DSMV8MU033T$TKM2B(2E_tmb !AAUNLQ0UMROML7F2QK1B@}M_tmb 后面换位2.2的cpu版本测试，有如下错误： !`B~VONX6_0B6%XEU9$9~CIX 其实两个问题核心都在kernel部分，cpu指出了是einsum算子不支持导致的。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GTX4060，以及L20上测试结果都是一样的  **Software Environment / 软件环境 (Mandatory / 必填)**:  Python 3.8  OS platform and distribution:: ubuntu22.04  GCC/Compiler version :mindnlp0.3.1,2024-07-28T10:51:56Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1446,einsum问题已解决
这是一个bug报告，主要涉及到mindnlp库中的D class models，具体症状以及原因不明。,fix D class models,,2024-07-28T10:07:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1445
这是一个bug报告类型的issue，涉及TVLT(refactored)主题，由于提供的链接无法打开，用户可能遇到了与链接相关的问题。,TVLT(refactored),https://gitee.com/mindspore/community/issues/I9V0A5,2024-07-27T11:14:46Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1444,测试链接：https://github.com/mindsporelab/mindnlp/actions/runs/10295861173/job/28496250210, 请审核通过
这个issue类型是缺陷报告，涉及的主要对象是C类模型。由于尚未完善C类模型，用户希望相关功能能够得到完成。,finish C class models,,2024-07-26T10:15:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1443
这是一个bug报告，涉及到mindnlp中camembert和canine的修复问题。由于某种原因导致了这样的bug产生或用户提出了关于修复camembert和canine的问题或寻求相关帮助。,"fix camembert, canine",,2024-07-25T12:21:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1442
这是一个bug报告，主要涉及MindNLP中的B类模型修复问题，可能由于模型的错误导致功能异常或不准确。,fix all b class models,,2024-07-25T10:08:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1441
这是一个缺少内容的issue，类型是需求提出，主要涉及的对象是代码中的b类模型。,update b class models,,2024-07-25T07:04:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1440
这是一个缺乏具体内容的issue，类型是其它类型，主要对象是mindnlp下的各个模块。,refator all modules,,2024-07-24T15:25:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1439
这是一个bug报告，涉及对象为mindnlp库中的baichuan、bark和llama模块。由于GPU和Ascend上的问题，需要修复相关功能。,"fix baichuan, bark, llama on GPU&Ascend",,2024-07-24T08:03:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1438
这是一个bug报告，涉及的主要对象是tests\ut\transformers\test_modeling_common.py中的construct函数未对齐。由于构造方法未对齐导致报错，需要修复该代码中的问题。,tests\ut\transformers\test_modeling_common.py中的construct 未对齐,报错如下： !4B16B4F95E4DEC50029F42B3B00308D4 !image,2024-07-23T11:54:44Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1437,fixed
这是一个类型为任务需求的issue，主要涉及的对象是SuperPoint模型迁移。可能是因迁移时遇到困难或问题，希望得到支持或帮助。,【开源实习】SuperPoint模型迁移,ut通过   任务链接：https://gitee.com/mindspore/community/issues/I9V027,2024-07-23T08:30:39Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1436,/model superpoint,/model superpoint,/model superpoint,/model superpoint,CI通过：https://github.com/mindsporelab/mindnlp/actions/runs/10057171368/job/27797571461,/model superpoint
这个issue是一个bug报告，主要涉及到MS2.x的类错误，用户提出了需要修正该错误的帮助。,fix A class error on MS2.x,,2024-07-23T04:05:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1435
这是一个用户需求类型的问题单，主要涉及对SFT方法的添加和示例的提供。导致这个问题的原因可能是用户需要了解如何使用SFT方法并需要相应配置文件和示例。,[TRL] Provide SFT method and an example,PR内容 提供了SFT方法和所需的配置文件，并在exaples文件夹下提供sft调用的示例。,2024-07-22T20:25:55Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1434,pylint没过
这是一个升级类模型到新模块的问题，属于功能更新类型的issue，主要涉及到类模型。,update A class models to new module,,2024-07-22T15:38:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1433
这是一个用户提出需求的类型。该问题单涉及的主要对象是REALM(refactored)。由于某种重构，用户提出需要更改，或者添加新功能。,REALM(refactored),https://gitee.com/mindspore/community/issues/I9UZ44,2024-07-22T09:24:51Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1432,测试链接：https://github.com/mindsporelab/mindnlp/actions/runs/10283065550 由于存储空间不足， !image 故附上本地测试结果（mindspore2.2.14 CPU），已通过所有测试点（包括slow）： !realm, 请审核通过
"这是一个用户提出需求或问题的类型，涉及主要对象为""昇腾AI创新大赛""，用户可能提出了关于Deta的问题或需要相关帮助。",【昇腾AI创新大赛】Deta,,2024-07-22T07:04:10Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1431,/model deta,/model deta,!image batched_nms接口有问题，其他测试可过。,!image Pylint已经过了：https://github.com/mindsporelab/mindnlp/actions/runs/10038097164/job/27739294457step:9:16,CI通过，本赛题验收通过
"这是一个针对代码修改的类型为""Revert""的issue，涉及的主要对象是mindsporelab/mindnlp的CC功能。由于之前的修改在修复albert ut时出现了问题，导致需要撤销这次变更。","Revert ""fix albert ut""",Reverts mindsporelab/mindnlp CC(fix albert ut),2024-07-22T06:51:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1430
"这是一个Bug报告类型的Issue，主要涉及的对象是""fix albert ut""。由于代码中可能存在逻辑错误或者缺陷，导致了需要修复相应问题的情况。",fix albert ut,,2024-07-22T04:15:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1429
这是一个bug报告，主要涉及mint导入错误问题。由于某些原因导致了ms2.2版本的mindnlp中mint模块导入错误。,fix mint import error for ms2.2,,2024-07-22T02:53:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1428
这是一个优化性能的issue，主要涉及llama3在Ascend上运行速度的问题。,llama3 speedup on Ascend(170ms=>85ms),,2024-07-21T15:55:16Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1427, 绑核：330ms => 200ms  去除Cell，使用python写的Module：200ms => 170ms  使用mint替换写法：170ms => 150160ms  Tensor索引替换为embedding算子：150160ms => 140ms  swapaxes去掉make_range算子改为python处理：140ms => 120ms  rms_norm换大算子: 120ms => 100ms  Tensor索引全部想办法换成mint(narrow/split): 100ms => 85ms,taskset c 023
这个issue类型是需求类型，主要涉及NLLB模型迁移。原因可能是用户希望进行NLLB模型迁移并寻求相关帮助。,【开源实习】NLLB模型迁移,任务链接：https://gitee.com/mindspore/community/issues/IA6GDK,2024-07-21T13:15:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1426
这是一个bug报告，主要涉及tvlt相关问题。由于原因未知导致 tvlt 存在问题，需要进行排查和修复。,tvlt,https://gitee.com/mindspore/community/issues/I9V0A5,2024-07-21T11:22:42Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1425,测试已通过https://github.com/mindsporelab/mindnlp/actions/runs/10028029816/job/27714442256,正在重构。。
"这个issue类型是bug报告，涉及的主要对象是""rag""。由于数据缺失或错误导致了这个bug的症状。",rag,,2024-07-20T12:06:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1424
这是一个性能优化类型的issue，主要对象是 Ascend 设备，用户提出了希望提升 llama3 在 Ascend 设备上的运行速度的需求。,llama3 on Ascend(200ms=>170ms),,2024-07-19T04:16:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1423
这是一个缺少内容的功能需求提出issue，类型为用户提出需求。主要涉及对象为mindnlp的新模块使用情况。,use new module,,2024-07-19T03:10:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1422
这是一个需求问题，涉及FSMT(refactored)的相关事项，可能是用户提出了关于该功能的问题或需要帮助。,FSMT(refactored),https://gitee.com/mindspore/community/issues/I9UVOZ,2024-07-18T13:30:22Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1421,重构后本地（CPU）测试结果: !p1 !p2 !p3 !p4 !p5,/model fsmt,/model fsmt,/model fsmt
这是一个需求报告，涉及到UDop模型的迁移。最可能是用户提出了关于UDop模型迁移的问题或寻求相关帮助。,UDop模型迁移,UDop模型迁移,2024-07-18T09:27:24Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1420,/model udop,CI:https://github.com/mindsporelab/mindnlp/actions/runs/9989030879/job/27606752131 注：由于Github环境本身缺少tesseract已经相应的环境路径path，导致报错，同时我在本地测试过，当datasets降至2.14.6时修正导入数据集的编码错误，这是我在本地跑的正确结果：  
这是一个需求类型的issue，主要涉及Udop模型的迁移。原因可能是用户需要帮助或者寻求相关指导。,Udop模型迁移,Udop模型迁移,2024-07-18T09:04:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1419
这是一个需求问题，用户提出了Udop模型迁移的需求。这可能是因为用户想要将Udop模型从一个系统迁移到另一个系统，或者对模型的迁移过程有疑问，希望获得相关帮助。,Udop模型迁移,Udop模型迁移,2024-07-18T06:06:15Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1418,/model udop,CI:https://github.com/mindsporelab/mindnlp/actions/runs/9986425350/job/27598923268 注：在GitHub上环境缺少tesseract，而且tesseract需要在环境变量path中进行设置导致错误，另外，datasets中的报错是因为datasets的版本问题，我在本地运行的时候将datasets降到2.14.6就没问题了  这是processor的UT证明
这是一个空白的issue，无法确定其类型和主要对象。,deepseek_v2整改后,,2024-07-18T06:06:10Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1417,/model deepseek_v2,/model deepseek_v2,iss链接：https://gitee.com/mindspore/community/issues/IA99C2
这个issue类型是需求报告，主要对象是Udop模型迁移。由于用户需要将Udop模型进行迁移，所以提出了这个问题。,Udop模型迁移,Udop模型迁移,2024-07-18T06:03:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1416
这是一个功能需求类型的issue，主要涉及的对象是Udop模型和部分layoutlmv3模型。由于需要进行Udop模型迁移和包含layoutlmv3的部分内容，可能是用户希望在模型迁移过程中遇到的问题或请求帮助。,Udop模型迁移,Udop模型迁移+部分layoutlmv3,2024-07-18T05:48:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1415
这个issue属于bug报告，主要涉及的对象是 llama3 on Ascend，由于速度慢和 chatglm2 错误而产生。,speed up llama3 on Ascend(200ms/token) & fix chatglm2 error,,2024-07-18T02:41:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1414
这是一个代码回退（Revert）类型的 issue，主要涉及到 mindsporelab/mindnlp 项目中的 deepseek_v2 功能。这可能是由于 deepseek_v2 引起了一些问题或者不符合预期的行为，需要被撤销。,"Revert ""deepseek_v2""",Reverts mindsporelab/mindnlp CC(deepseek_v2),2024-07-18T02:29:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1413
这个issue类型是用户提出需求，主要涉及的对象是添加教程使用镜像。由于用户希望使用镜像来进行教程，可能是为了加快速度或者避免网络问题。,Add tutorial use mirror,,2024-07-17T22:27:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1412
该issue是用户提出需求或请教问题类型，主要涉及的对象是Perceiver。由于开源实习相关需求或问题，用户提出了关于Perceiver的相关讨论或帮助请求。,【开源实习】Perceiver,https://gitee.com/mindspore/community/issues/I9UYJR,2024-07-17T15:47:14Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1411,/model perceiver,Github上的CI因内存不足而无法进行测试。华为云ModelArts上模型已通过所有ut（包括slow），截图如下： !image !image !image !image !image !image, 请审核通过
这是一个用户提出需求的问题单，主要涉及到FUYU(refactored)，可能是基于该模型的重构工作或者相关功能的添加。,FUYU(refactored),https://gitee.com/mindspore/community/issues/I9UVVN,2024-07-17T11:30:14Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1410,测试链接：https://github.com/mindsporelab/mindnlp/actions/runs/10283348266 由于存储空间不足： !image 故附上本地测试结果（mindspore2.2.14 CPU ），已经全部测试通过（包括slow）： !fuyu, 请审核通过
这是一个性能优化类的issue，主要对象是项目中的chatglm2模块。由于Ascend性能问题导致的速度较慢，用户提出希望能够提升性能。,chatglm2 speed up on Ascend(320ms=>160ms),,2024-07-17T09:35:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1409
这是一个Bug报告，主要涉及到 chatglm2 代码中的 size 方法应更换成 shape，可能导致程序出错。,chatglm2代码出错,!image 原来的size方法应换成shape,2024-07-17T08:38:32Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1408,fixed
"该issue是一个缺少具体内容的需求提出，该问题单涉及的主要对象是添加名为""model patchtst""的模型。",add model patchtst,,2024-07-17T07:11:26Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1407,/model patchtst,/model patchtst,single model test 执行通过 https://github.com/mindsporelab/mindnlp/actions/runs/9970270106/job/27548832922
"这是一个用户提出需求的issue，主要对象是向mindnlp库添加一个名为""xglm""的模型。",add model xglm,,2024-07-16T03:51:19Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1406,/model xglm,single model test 已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9950453061/job/27488306142
这是一个bug报告，涉及到大语言模型在910a上推理速度慢的问题。,大语言模型在910a上推理速度慢,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 测试了chatglm6b和llama27bchathf两个模型，推理速度大概在34tokens/s，查看`npusmi info`，AICore的占用率不到15%。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend 910A  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.14  Python version (e.g., Python 3.7.5) :3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04):EulerOS 2.0 (SP8)  GCC/Compiler version (if compiled from source):  cann:7.0.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 从镜像站下载模型权重，执行 ``` from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM model_path = 'llama2' tokenizer = AutoTokenizer.from_pretrained(model_path) model = AutoModelForCausalLM.from_pretrained(model_path) input = '''today is a sunny day''' gen_config = model.generation_config gen_config.max_new_tokens = 32  toks = tokenizer(input).input_ids input_ids = ms.tensor(toks) input_ids = input_ids.unsqueeze(0) attn_masks = ms.ops.ones_like(input_ids) output_ids = model.generate(input_ids,      attention_mask=attn_masks,      generation_config=gen_config,     pad_token_id=tokenizer.pad_token_id)[0]  output = tokenizer.decode(output_ids, skip_special_tokens=True).strip() ``` 多次执行后推理速度仍然不快。 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !截图 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-07-16T03:12:39Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1405,"有两部分原因： 1. python执行的处理造成的算子下发间隔 2. 鲲鹏处理器执行会跳核影响 算子下发速度 我今天改了一下chatglm2的代码，能从320ms/token优化到160ms/token, 在鲲鹏CPU环境下需要使用以下方式执行： ```taskset c 023 python cli_demo.py```"
这个issue类型为测试问题，主要涉及的对象是进行测试的MarkupLM模型。原因可能是出现了测试会话启动问题，导致需要进一步调查和修复。,【开源实习】MarkupLM模型迁移,"============================= test session starts ============================== platform linux  Python 3.8.19, pytest7.4.3, pluggy1.5.0  /home/wuzhirong/anaconda3/envs/mindspore/bin/python3.8 cachedir: .pytest_cache hypothesis profile 'default' > database=DirectoryBasedExampleDatabase(PosixPath('/mnt/sde/wuzhirong/MINDSPORE/test/mindnlp_markuplm/.hypothesis/examples')) rootdir: /mnt/sde/wuzhirong/MINDSPORE/test/mindnlp_markuplm configfile: pytest.ini plugins: typeguard4.3.0, hypothesis6.107.0 collecting ... collected 40 items tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_attention_outputs PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_config PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_correct_missing_keys PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_determinism PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_feed_forward_chunking PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_for_question_answering PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_for_sequence_classification PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_for_token_classification PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_forward_signature PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_from_pretrained_no_checkpoint PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_head_pruning PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_head_pruning_integration PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_head_pruning_save_load_from_config_init PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_head_pruning_save_load_from_pretrained PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_headmasking PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_hidden_states_output PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_initialization PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_inputs_embeds PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_keep_in_fp32_modules PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_load_save_without_tied_weights PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_load_with_mismatched_shapes PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_model Configs: 2 2 PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_model_common_attributes PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_model_is_small PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_model_main_input_name PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_model_outputs_equivalence PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_model_weights_reload_no_missing_tied_weights PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_multi_gpu_data_parallel_forward SKIPPED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_problem_types SKIPPED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_resize_embeddings_untied PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_resize_position_vector_embeddings PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_resize_tokens_embeddings PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_save_load PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_save_load_fast_init_from_base PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_save_load_fast_init_to_base PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_save_load_keys_to_ignore_on_save PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_tie_model_weights PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_tied_weights_keys PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelTest::test_training PASSED tests/ut/transformers/models/markuplm/test_modeling_markuplm.py::MarkupLMModelIntegrationTest::test_forward_pass_no_head PASSED =============================== warnings summary =============================== mindnlp/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:1707   /mnt/sde/wuzhirong/MINDSPORE/test/mindnlp_markuplm/mindnlp/transformers/models/bigbird_pegasus/modeling_bigbird_pegasus.py:1707: DeprecationWarning: invalid escape sequence \I     """""" ../../../../../../home/wuzhirong/anaconda3/envs/mindspore/lib/python3.8/sitepackages/jieba/_compat.py:18   /home/wuzhirong/anaconda3/envs/mindspore/lib/python3.8/sitepackages/jieba/_compat.py:18: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html     import pkg_resources ../../../../../../home/wuzhirong/anaconda3/envs/mindspore/lib/python3.8/sitepackages/pkg_resources/__init__.py:3117   /home/wuzhirong/anaconda3/envs/mindspore/lib/python3.8/sitepackages/pkg_resources/__init__.py:3117: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.   Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.htmlkeywordnamespacepackages     declare_namespace(pkg) mindnlp/transformers/models/chatglm/modeling_chatglm.py:1723   /mnt/sde/wuzhirong/MINDSPORE/test/mindnlp_markuplm/mindnlp/transformers/models/chatglm/modeling_chatglm.py:1723: DeprecationWarning: invalid escape sequence \?     [""\?"", ""？""], mindnlp/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py:267   /mnt/sde/wuzhirong/MINDSPORE/test/mindnlp_markuplm/mindnlp/transformers/models/gpt_neox_japanese/tokenization_gpt_neox_japanese.py:267: DeprecationWarning: invalid escape sequence \(     ""万ユーロ 280/280 [00:00<00:00, 719kB/s]",2024-07-16T01:00:27Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1404,https://gitee.com/mindspore/community/issues/I9UWWS,已通过https://github.com/mindsporelab/mindnlp/actions/runs/9968253192
这是一个Bug报告，主要涉及Llama2推理问题，由于某种原因导致产生了报TypeError。,Llama2推理报TypeError   ,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 在使用openi社区的NPU资源调用Llama2的generate方法会报TypeError，提示数据类型不支持，可能是ops.multinomial所使用算子的问题。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device *AscendD910B/  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.3.0  Python version 3.9   OS platform and distribution EulerOS 2.0 (SP8)  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 执行代码 ``` from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM import mindspore as ms model_path = 'llama2' tokenizer = AutoTokenizer.from_pretrained(model_path) model = AutoModelForCausalLM.from_pretrained(model_path) inputs = tokenizer(""I love Beijing, because"")[""input_ids""] inputs = ms.tensor(inputs) inputs = inputs.unsqueeze(0) outputs = model.generate(inputs, max_new_tokens=30) response = tokenizer.decode(outputs) print(response) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 正常输出推理结果 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. ```  TypeError                                 Traceback (most recent call last) Cell In[10], line 6       4 inputs = ms.tensor(inputs)       5 inputs = inputs.unsqueeze(0) > 6 outputs = model.generate(inputs, max_new_tokens=30)       7 response = tokenizer.decode(outputs)       8 print(response) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/utils/generic.py:339, in no_grad..wrapper(*args, **kwargs)     337 def wrapper(*args, **kwargs):     338     _pynative_executor.set_enable_grad(False) > 339     outputs = func(*args, **kwargs)     340     _pynative_executor.set_enable_grad(True)     341     return outputs File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py:1658, in GenerationMixin.generate(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)    1650     input_ids, model_kwargs = self._expand_inputs_for_generation(    1651         input_ids=input_ids,    1652         expand_size=generation_config.num_return_sequences,    1653         is_encoder_decoder=self.config.is_encoder_decoder,    1654         **model_kwargs,    1655     )    1657      13. run sample > 1658     return self.sample(    1659         input_ids,    1660         logits_processor=logits_processor,    1661         logits_warper=logits_warper,    1662         stopping_criteria=stopping_criteria,    1663         pad_token_id=generation_config.pad_token_id,    1664         eos_token_id=generation_config.eos_token_id,    1665         output_scores=generation_config.output_scores,    1666         return_dict_in_generate=generation_config.return_dict_in_generate,    1667         synced_gpus=synced_gpus,    1668         streamer=streamer,    1669         **model_kwargs,    1670     )    1672 elif generation_mode == GenerationMode.BEAM_SEARCH:    1673      11. prepare beam search scorer    1674     beam_scorer = BeamSearchScorer(    1675         batch_size=batch_size,    1676         num_beams=generation_config.num_beams,    (...)    1680         max_length=generation_config.max_length,    1681     ) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py:2739, in GenerationMixin.sample(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)    2737  sample    2738 probs = ops.softmax(next_token_scores, axis=1) > 2739 next_tokens = ops.multinomial(probs, num_samples=1).squeeze(1).astype(mindspore.int64)    2740  finished sentences should have their next token be a padding token    2741 if eos_token_id is not None: File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/injection.py:564, in custom_multinomial(probabilities, num_samples, replacement)     561 else:     562      without replacement     563     n_dist = 1 > 564     if probabilities.ndim > 1:     565         n_dist = probabilities.shape[2]     566     random_uniform = ops.rand((n_dist * probabilities.shape[1],)) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py:122, in StubTensor.ndim(self)     119      120 def ndim(self):     121     """"""ndim stub."""""" > 122     return len(self.shape) File /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py:90, in StubTensor.shape(self)      88 if self.stub:      89     if not hasattr(self, ""stub_shape""): > 90         self.stub_shape = self.stub.get_shape()      91     return self.stub_shape      92 return self.tensor.shape TypeError: The supported input and output data types for the current operator are: node is Default/TensorScatterElementsop1 InputDesc [0] support {complex128,complex64,double,float,float16,int16,int32,int64,int8,qint16,qint32,qint8,quint16,quint8,uint16,uint32,uint64,uint8,bf16,} InputDesc [1] support {int32,int64,} InputDesc [2] support {complex128,complex64,double,float,float16,int16,int32,int64,int8,qint16,qint32,qint8,quint16,quint8,uint16,uint32,uint64,uint8,bf16,} OutputDesc [0] support {complex128,complex64,double,float,float16,int16,int32,int64,int8,qint16,qint32,qint8,quint16,quint8,uint16,uint32,uint64,uint8,bf16,} But current operator's input and output data types is: InputDesc [0] is Bool InputDesc [1] is Int32 InputDesc [2] is Bool OutputDesc [0] is Bool   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:543 HandleKernelSelectFailure ``` **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-07-15T10:35:06Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1403,尝试mindnlp daily+mindspore2.3
这是一个bug报告类型的issue，主要涉及到uie在昇腾 arm环境下无法编译fast-tokenizer-python包。原因可能是参考paddleNLP的编译说明时出现的问题导致无法成功编译。,uie 在昇腾 arm 下无法编译fast-tokenizer-python包,"``` Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 1.307 seconds. Prefix dict has been built successfully. Traceback (most recent call last):   File ""/opt/uie/build/mindnlpmaster/llm/inference/uie/api.py"", line 1, in      from uie_predictor import UIEPredictor   File ""/opt/uie/build/mindnlpmaster/llm/inference/uie/uie_predictor.py"", line 10, in      from tokenizer import ErnieMTokenizerFast   File ""/opt/uie/build/mindnlpmaster/llm/inference/uie/tokenizer.py"", line 14, in      from fast_tokenizer import Tokenizer, normalizers, pretokenizers, postprocessors ModuleNotFoundError: No module named 'fast_tokenizer' ``` 参考 paddleNLP 的编译说明，无法成功编译",2024-07-15T10:28:18Z,bug,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1402,fast_tokenizer_python1.0.2cp39cp39linux_aarch64.whl.zip,使用这个,"安装后有另外的报错 ``` Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 1.316 seconds. Prefix dict has been built successfully. Traceback (most recent call last):   File ""/opt/uie/build/mindnlpmaster/llm/inference/uie/api.py"", line 1, in      from uie_predictor import UIEPredictor   File ""/opt/uie/build/mindnlpmaster/llm/inference/uie/uie_predictor.py"", line 10, in      from tokenizer import ErnieMTokenizerFast   File ""/opt/uie/build/mindnlpmaster/llm/inference/uie/tokenizer.py"", line 14, in      from fast_tokenizer import Tokenizer, normalizers, pretokenizers, postprocessors   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/fast_tokenizer/__init__.py"", line 55, in      from . import core_tokenizers as C ImportError: /lib64/libm.so.6: version `GLIBC_2.29' not found (required by /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/fast_tokenizer/core_tokenizers.so) ```",这个是操作系统问题，必须要升级到GLIBC_2.29以上，你可以参考一下这个教程。https://blog.csdn.net/v6543210/article/details/135010299
"这个issue是需求提出类型，主要涉及的对象是在Mindnlp项目中添加名为""yolos""的模型。",add model yolos,,2024-07-15T02:14:40Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1401,yolos,/model yolos,/model yolos,"single model test 中一条精度对比用例报错，原因：nn.functional.interpolate  VS  ops.interpolate  精度有偏差 功能一致, 但在’bicubic’模式 align_corners=False 时，计算方式和TensorFlow相同，结果和PyTorch有差异"
这是一个用户提出需求的类型，主要涉及到本地分支操作。原因可能是用户想要了解关于本地分支的相关问题或者寻求相关帮助。,My local branch,,2024-07-14T09:37:53Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1400,/model unispeech
这是一个用户提出需求的issue，主要涉及的对象是在mindnlp的项目中的deepseek_v2模块。原因是为了更改transformers/models中的文件结构以支持新功能的添加。,deepseek_v2,"更改包含： 1.transformers/models文件夹下创建了deepseek_v2文件夹，内含tokenization_deepseek_fast.py,configuration_deepseek.py,modeling_deepseek.py,ut.py和__init__.py。运行ut.py可检查模型迁移效果。 2.注册表中添加了deepseek_v2注册信息 issue链接：https://gitee.com/mindspore/community/issues/IA99C2",2024-07-14T01:17:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1399
该issue类型为招聘（开源实习），主要对象是DPT项目。由于招募志愿者或实习生参与项目开发，而非技术上的bug或问题。,【开源实习】DPT,https://gitee.com/mindspore/community/issues/I9UV92,2024-07-13T06:34:12Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1398,/model dpt,Github的ut已过：https://github.com/mindsporelab/mindnlp/actions/runs/9924152095 注意：与swinv2和dinov2相关的slow测试已被跳过，前者是因为当前mindNLP库缺失swinv2模型，后者是因为dinov2因使用了ops.interpolate而产生了精度问题，致使本模型在以dinov2为backbone时精度无法达到要求，可以确定不是本模型问题，因为本模型在切换至beit backbone时精度正常，也能通过其它所有测试。, 请审核通过
这是一个类型为任务完成通知的issue，主要涉及Kosmos模型迁移。原因可能是之前的模型迁移过程顺利完成，没有出现问题。,Kosmos模型迁移,Kosmos模型迁移完成,2024-07-13T02:38:50Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1397,/model kosmos2,/model kosmos2,/model kosmos2,CI:https://github.com/mindsporelab/mindnlp/actions/runs/9918044108/job/27402227952 说明：我在本地跑的时候没有任何问题：   这是github上报错对应的本地运行的pytest结果，我觉得应该不是代码上的问题
这是一个用户提出需求的类型，主要是针对社区实习的XLMProphetNet。,【社区实习】XLMProphetNet,,2024-07-12T05:59:50Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1396,/model xlm_prophetnet,本地slow能通过： !V}V{NT$JQU(Q{ FMQZ(%VPD
这是一个需求类型的issue，主要涉及到xml_ProphetNet。原因是用户在社区实习中寻求关于xml_ProphetNet的帮助。,【社区实习】xml_ProphetNet,,2024-07-12T04:38:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1395
这是一个任务完成通知类的issue，主要涉及的对象是M2m 100模型迁移。原因可能是用户已经完成了M2m 100模型迁移任务并希望进行相应的记录和通知。,M2m 100模型迁移,M2m 100模型迁移任务完成,2024-07-10T13:19:08Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1394,/model m2m_100,/model m2m_100,CI测试已通过：https://github.com/mindsporelab/mindnlp/actions/runs/9875178034/job/27271229681 图片为slow下的pytest运行结果 
这个issue类型为迁移完成通知，主要对象是M2m 100模型。,M2m 100模型迁移,M2m 100模型迁移完成,2024-07-10T11:55:39Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1393,/model m2m_100,/model m2m_100
"这是一个任务完成的通知，不是bug报告，主要对象是""M2m 100模型""。",M2m 100模型迁移,M2m 100模型迁移任务已完成,2024-07-10T11:44:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1392
这是一个用户提出需求的issue，主要对象是添加模型Deta到mindnlp中。,add model Deta,,2024-07-10T06:31:24Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1391,/model deta,/model deta
这个issue是关于如何在Mindnlp.transformers中实现huggingface的VisionEncoderDecoderModel的需求问题，主要涉及对象是模型接口的转换和适配。,如何将huggingface的VisionEncoderDecoderModel用Mindnlp.transformers实现,from transformers import VisionEncoderDecoderModel model = VisionEncoderDecoderModel.from_pretrained('./model/handwrite/') 模型目录包含pytorch_model.bin和config文件 换成mindnlp.transformers后，没有VisionEncoderDecoderModel，是否有类似的实现，或者我如何从本地加载pytorch模型(encoderdecoder)？,2024-07-09T09:16:08Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1390,我看mindnlp/transformer/model里已经有trocr模块，但是AutoModel.from_pretrained('trocr')显示mindnlp.utils.errors.GatedRepoError: You should have authorization to access the model.， 什么时候能使用？,我看一下
这是一个bug报告，主要涉及Mindnlp中版本为ms2.3存在的错误。可能是由于代码逻辑错误或者版本兼容性问题导致的bug。,fix errors for ms2.3,,2024-07-08T12:14:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1389
这是一个用户提出需求的issue，主要对象是Data2vec audio模型迁移。由于用户希望进行模型迁移，所以提出了这个问题。,Data2vec audio模型迁移,Data2vec audio模型迁移,2024-07-08T11:34:22Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1388,/model data2vec,ci测试已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9838819592/job/27159525344,,上面的是slow的（data2vec_text+audio）,/model data2vec
这是一个需求问题，涉及Data2vec audio模型迁移。由于具体内容缺失，用户可能需要帮助解决如何进行Data2vec audio模型的迁移。,Data2vec audio模型迁移,Data2vec audio模型迁移,2024-07-08T08:27:08Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1387,/model data2vec
这是一个用户提出需求的类型，该问题单涉及的主要对象是UniSpeechSat项目。由于缺失了完整的Gitee issue链接，导致用户无法直接访问到相关详细信息。,【开源实习】UniSpeechSat,Gitee id: liujunyan_2024 Gitee issue: https://gitee.com/mindspore/community/issues/I9V0F5,2024-07-08T08:21:53Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1386,/model unispeech_sat,/model unispeech_sat,/model unispeech_sat,/model unispeech_sat,本地测试已通过包括slow在内的所有ut，截图如下。Github上进行slow测试时疑似由于服务器内存不足而异常停止，非代码问题。 !image !image !image !image !image !image !image !image !image, 请审核通过
这是一个需求类型的issue，主要涉及到Data2vec audio模型的迁移。可能是由于用户需要在该模型上进行相关操作或迁移，向社区寻求帮助或建议。,Data2vec audio模型迁移,Data2vec audio模型迁移,2024-07-08T08:15:51Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1385,/model data2vec
这是一个缺乏详细信息的issue，类型可能是用户提出需求或者问题咨询，主要涉及对象是Data2vec audio模型。,Data2vec audio模型迁移,Data2vec audio模型迁移,2024-07-08T07:38:03Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1384,/model data2vec
这个issue类型是需求，主要涉及的对象是Data2vec audio模型。由于需要进行模型迁移，用户可能需要帮助或者讨论相关问题。,Data2vec audio模型迁移,Data2vec audio模型迁移,2024-07-08T07:20:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1383
这是一个需求/功能提议类型的issue，主要涉及Data2vec audio模型的迁移。这个问题可能由于用户想要在项目中迁移Data2vec audio模型而产生。,Data2vec audio模型迁移,Data2vec audio模型迁移,2024-07-08T07:17:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1382
这个issue类型是任务完成的通知，主要对象是 Data2vec audio 模型迁移。,Data2vec audio 模型迁移,Data2vec audio 模型迁移任务完成,2024-07-08T06:14:55Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1381,没测试,/model data2vec_audio
这个issue是bug报告，主要涉及的对象是transformers init，由于初始化问题导致了bug。,fix transformers init,,2024-07-08T04:56:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1380
这个issue是关于功能需求的，主要涉及Data2vec audio 模型的迁移，用户可能由于迁移UT遇到了问题或疑惑。,Data2vec audio 模型迁移,Data2vec audio 模型迁移UT通过,2024-07-07T06:47:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1379
这是一个测试通过的issue，涉及的主要对象是Data2vec audio模型迁移。,Data2vec audio模型迁移,Data2vec audio模型迁移 UT测试通过,2024-07-07T05:54:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1378
"这是一个描述了模型迁移过程中问题的bug报告，涉及的主要对象是""data2vec_audio""模型。由于什么样的原因导致了""模型迁移data2vec_audio"" UT无法通过。",模型迁移data2vec_audio,模型迁移data2vec_audio UT通过,2024-07-07T05:40:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1377
这是一个需求类型的issue，主要涉及到data2vec audio模型的模型迁移。由于需要进行模型迁移，用户可能遇到了一些问题或者需要帮助。,<【社区实习】data2vec audio>,data2vec audio 的模型迁移,2024-07-07T04:54:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1376
这是一个用户提出需求的类型，该问题单涉及的主要对象是MindSpore社区实习任务DINOv2，用户寻求参与该实习任务的帮助。,【社区实习】DINOv2,社区实习任务：https://gitee.com/mindspore/community/issues/I9UUPK,2024-07-05T13:01:09Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1375,/model dinov2,因为mindspore.ops.interpolate导致有精度问题，已在例会上讨论，跳过了test_inference_no_head，ISSUE链接：https://github.com/mindsporelab/mindnlp/issues/1373,CI已过：https://github.com/mindsporelab/mindnlp/actions/runs/9808737546/job/27085124313 社区实习任务：https://gitee.com/mindspore/community/issues/I9UUPK
这是一个社区实习任务发布的类型为其它类型的issue，主要涉及的对象是社区实习生。,【社区实习】DINOv2,社区实习任务：https://gitee.com/mindspore/community/issues/I9UUPK,2024-07-05T12:30:01Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1374,/model dinov2
这是一个bug报告，涉及到mindspore.ops.interpolate模块不支持bicubic模式下传入scale_factor参数的问题。造成这个问题的原因可能是模块功能未完全支持该参数配置。,"mindspore.ops.interpolate不支持mode=""bicubic""模式下传入scale_factor参数","**Describe the bug/ 问题描述 (Mandatory / 必填)** 在DINOv2模型迁移时遇到该问题， PR链接：https://github.com/mindsporelab/mindnlp/pull/1375， mindnlp/transformers/models/dinov2/modeling_dinov2.py:line83 mindspore.ops.interpolate不支持mode=""bicubic""模式下传入scale_factor参数。 根据官方文档，若添加recompute_scale_factor=True可规避报错，但当scale_factor为浮点数时会产生精度误差。 官方文档：https://www.mindspore.cn/docs/zhCN/master/note/api_mapping/pytorch_diff/interpolate.html  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  **Software Environment / 软件环境 (Mandatory / 必填)**:  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: **To Reproduce / 重现步骤 (Mandatory / 必填)** **Expected behavior / 预期结果 (Mandatory / 必填)** 支持mode=""bicubic""时传入浮点型scale_factor **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)**",2024-07-05T12:10:16Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1373,最新改的代码看起来没啥问题了
该issue类型为测试通过的反馈，主要对象是Xmod。由于测试结果通过，用户向mindnlp社区提供了关于Xmod的正面反馈。,【社区实习】Xmod,!image 测试通过,2024-07-05T03:23:57Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1372,/model xmod,/model xmod,/model xmod,/model xmod
"这个issue是一个bug报告，主要涉及MindNLP库中的""同步""功能。可能由于代码实现问题导致了同步功能无法正常工作，用户提出了关于此bug的问题。",同步,,2024-07-05T03:06:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1371
该issue类型为社区实习申请，主要涉及对象为fnet。,【社区实习】fnet,,2024-07-04T17:47:19Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1370,/model fnet,测试通过：https://github.com/mindsporelab/mindnlp/actions/runs/9798457865
该issue类型为用户提出需求，涉及的主要对象是mgp-str模块。由于缺乏具体内容，用户可能要求实习任务的相关信息或者提出问题寻求帮助。,【社区实习】mgp-str,,2024-07-04T06:30:39Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1369,/model mgp_str,测试通过https://github.com/mindsporelab/mindnlp/actions/runs/9789597240
"这是一个需求类型的issue， 主要涉及的对象是添加名为""vit_mae""的模型。由于缺乏这个模型，在该issue中用户请求添加这个模型以满足需求。",add model vit_mae,,2024-07-04T01:39:16Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1368,/model vit_mae,single model test 已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9787162148
这是一个用户提出需求的类型，主要涉及的对象是Kosmos2。,【社区实习】Kosmos2,,2024-07-03T14:02:54Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1367,/model kosmos2,由于模型过大，线上测试卡住，通过本地进行测试，除最后两个文本生成测试外均已通过。 !image 进行大模型测试的最后两个文本输出与测试文件不符，hf测试中的结果也出现较大不符情况，测试输出的结果与hf测试结果类似。 !image !image,> 由于模型过大，线上测试卡住，通过本地进行测试，除最后两个文本生成测试外均已通过。 !image 进行大模型测试的最后两个文本输出与测试文件不符，hf测试中的结果也出现较大不符情况，测试输出的结果与hf测试结果类似。 !image !image 精度还在调整
该issue属于用户提出需求类型，主要涉及MindNLP社区实习项目中的Lxmert模块。原因可能是用户希望进行Lxmert模型相关的实习任务，寻求相关帮助或指导。,【社区实习】Lxmert,,2024-07-02T18:01:12Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1366,/model lxmert,已通过全部测试https://github.com/mindsporelab/mindnlp/actions/runs/9765963288
这是一个bug报告，主要涉及rwkv register & levenshtein requirements，并导致了安装要求方面的错误。,fix rwkv register & levenshtein requirements,,2024-07-02T14:12:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1365
"这个issue类型是用户提出需求，主要对象是""mgp-str""，可能是用户寻求关于该功能的帮助。",【社区实习】mgp-str,,2024-07-02T08:05:32Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1364,同时修复了pylint中其他人模型缺少文档说明的报错,/model mgp_str,测试通过https://github.com/mindsporelab/mindnlp/actions/runs/9758079199
这是一个需求类型的issue，主要涉及的对象是mindspore教程。由于用户需要更多有关mindspore教程的信息，因此提出了这个问题。,mindspore教程,,2024-06-30T23:52:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1363
这是一个bug报告类型的issue，主要涉及的对象是mindnlp仓库中的自动注册功能。由于修复未正常注册的bug，导致无法正确使用自动注册功能。,fix auto register,,2024-06-30T14:16:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1362
该issue为用户提出需求（Feature Request），主要对象是模型Persimmon。,【社区实习】Persimmon,/model persimmon,2024-06-30T11:53:03Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1361,/model persimmon,/model persimmon,/model persimmon,/model persimmon,/model persimmon,"""C:\Users\Nxt03\AppData\Local\Temp\c94d3a4e21a848df9ba0b0b7fdec3664.png"" !c94d3a4e21a848df9ba0b0b7fdec3664 这是本地测试结果，以下是远端pr的测试结果，好像是远端的储存崩了 !3ade9b97e4994d269f395bcc0c8e5206",/model persimmon
这是一个空issue，类型为其它类型，主要对象是PLBart项目。,【社区实习】PLBart,,2024-06-30T09:54:35Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1360,/model plbart,测试通过https://github.com/mindsporelab/mindnlp/actions/runs/9731236514
该issue类型是社区实习任务，主要涉及的对象是prophetnet模型。这个问题是由于社区实习导致的，用户正在进行与prophetnet相关的实习任务。,【社区实习】prophetnet,,2024-06-30T06:39:26Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1359,/model prophetnet,/model prophetnet
这是一个用户提出需求的 issue，主要涉及的对象是 UnivNet 模型。由于社区实习需求或意图不明确，导致用户未填写具体内容。,【社区实习】UnivNet,,2024-06-29T15:59:40Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1358,/model univnet,/model univnet
这是一个社区实习相关的任务需求，主要对象是Nougat。由于内容为空，导致了用户需要补充相关信息或继续交流的问题。,【社区实习】Nougat,,2024-06-29T05:38:47Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1357,/model nougat,测试通过https://github.com/mindsporelab/mindnlp/actions/runs/9722620374,> 测试通过https://github.com/mindsporelab/mindnlp/actions/runs/9722620374 任务链接:https://gitee.com/mindspore/community/issues/I9UXWG
这个issue属于社区实习类型，涉及的主要对象是UMT5。由于缺乏具体内容，无法确定导致了什么样症状的bug或问题的本质。,【社区实习】UMT5,,2024-06-29T01:57:03Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1356,/model umt5,CI测试已过： !image 链接https://github.com/mindsporelab/mindnlp/actions/runs/9724116519,/model instructblip,CI测试通过： !0$KY0R7L9}~GKZRNEL4042E 一共是两个开源实习项目UMT5和instructblip,/model tapas,CI测试通过： !image tapas精度优化:https://github.com/mindsporelab/mindnlp/actions/runs/9737628103/job/26870010802,/model clipseg
这是一个空白的issue，类型是其它类型，主要对象是社区实习UMTA5。,【社区实习】UMTA5,,2024-06-28T15:00:08Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1355,/model umt5
这是一个用户提出需求的类型，该问题单涉及的主要对象是UMTA5。由于未提供具体内容，无法分析导致的原因和具体需求。,【社区实习】UMTA5,,2024-06-28T14:58:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1354,/model utm5
这是一个缺少具体内容的 issue，类型无法确定。,Umt5,,2024-06-28T14:31:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1353
这是一个bug报告类型的issue，主要涉及对象是Umt5。由于什么样的原因导致了这个bug或用户提出了关于什么的问题或寻求什样的帮助，暂时无法确定。,Umt5,,2024-06-28T13:15:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1352
这个issue是社区实习相关的讨论，不涉及具体问题描述。,【社区实习】umt5,,2024-06-28T12:50:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1351
这是一个bug报告，涉及到mindspore在2.3.0版本后新增的一个入参`crc_check`导致的问题。,fix pylint error,mindspore在2.3.0之后在`_parse_ckpt_proto`方法中新增了一个入参`crc_check`； 因此通过判断版本号确定是否需要此参数。,2024-06-28T09:59:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1350
这个issue属于bug报告类型，主要涉及mindspore中的_parse_ckpt_proto方法和新增的入参crc_check，由于mindspore版本升级导致需要判断版本号确定是否需要该参数，可能是为了保证兼容性或者功能完整性。,fix pylint error,mindspore在2.3.0之后在`_parse_ckpt_proto`方法中，新增了一个入参`crc_check`； 因此通过判断版本号确定是否需要此参数。,2024-06-28T09:16:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1349
这个issue类型是一个协助标注文本内容的AI助手。,【社区实习】Donut-swin,ut已过 !pass,2024-06-28T07:43:42Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1348,/model donut_swin,/model donut,single model test已过：https://github.com/mindsporelab/mindnlp/actions/runs/9709383493/job/26797944968
这个issue属于用户提出需求的类型，涉及的主要对象是添加DonutSwin模型。由于某些原因导致该任务未能通过审核。,【社区实习】add DonutSwin model,ut已过： !pass,2024-06-28T07:38:15Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1347,/model donut_swin
这是一个用户提交需求的类型的issue，主要涉及的对象是UPerNet，可能由于项目实习而寻求帮助或者合作。,【开源实习】UPerNet (#I9V0HP),Gitee id: liujunyan_2024 Gitee issue: https://gitee.com/mindspore/community/issues/I9V0HP,2024-06-28T06:24:55Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1346,/model upernet,/model upernet,ut已过（包括slow），  请审核,auto没注册,已在auto中注册，  
该问题类型为社区实习（非bug报告），该问题单涉及的主要对象是Vilt 模型功能。由于社区实习项目的需要，用户可能提出关于 Vilt 模型的需求或需要相关帮助。,【社区实习】Vilt ,,2024-06-28T05:38:52Z,,closed,0,11,https://github.com/mindspore-lab/mindnlp/issues/1345,/model vilt,/model vilt,/model vilt,/model vilt,/model vilt,/model vilt,/model vilt,/model vilt,auto注册缺了,/model vilt,/model vilt
这是一个关于社区实习的类型，主要涉及mBART-50的问题。原因可能是用户在使用mBART-50时遇到了一些困难或者需要帮助。,【社区实习】mBART-50 (#I9UX1G) ,mBART50 (I9UX1G) ,2024-06-27T13:50:31Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1344,/model mbart50,/model mbart50
这个issue属于用户提出需求类型，主要涉及的对象是添加rag demo。由于用户需要展示rag demo，因此提出了这个需求。,add rag demo,add rag demo,2024-06-27T10:56:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1343
这是一个需求提交的issue，主要对象是mluke模型，用户提出了关于修改mluke模型的需求。,提交mluke模型修改,,2024-06-27T02:41:41Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1342,/model mluke
这是一个bug报告类型的issue，主要涉及的对象是swiftformer代码库。由于未提供具体内容，无法分析导致的原因。,fix swiftformer :格式化代码删除print,,2024-06-26T13:56:26Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1341,/model swiftformer
这是一个bug报告，涉及到Swiftformer的代码格式化功能，用户提出删除print函数精度的问题。问题可能是由代码格式化逻辑不正确而导致。,fix swiftformer :格式化代码删除print精度,,2024-06-26T13:13:37Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1340,/model swiftformer
这个issue是一个用户提出的需求类型，主要对象是safetensor，可能由于safetensor的加载速度较慢导致用户提出了快速加载的需求。,支持safetensor快速加载,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-06-26T07:02:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1339
这是一个用户提出需求的issue，主要涉及动静态图实现分隔的功能。,动静态图实现分隔,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-06-26T07:01:59Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1338,已实现同一套代码切换
这个 issue 类型是 bug 报告，主要涉及的对象是删除不必要的 injection。这个问题可能是由于未完整描述导致。,删除不必要的injection,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-06-26T07:01:27Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1337,已清除injection
"该issue类型为bug报告，涉及主要对象为mindnlp下的modeling_bit.py文件。原因是将con2v的pad_mode参数从""same""改为""valid""导致功能异常。",【社区实习】add Vit hybrid model,"对**modeling_bit.py**文件的修改主要是将有一处con2v的pad_mode参数从""same""改为""valid"" `pad_mode='pad' if padding != 0 else 'valid',` 经验证，当padding为0时，pad_mode应该为'valid'，'same'应该是pytorch的写法，应该是原作者疏漏了没改 还有就是vscode自动将行首的空格给删掉了。",2024-06-25T18:23:49Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1336,/model vit_hybrid,single model test 已过：https://github.com/mindsporelab/mindnlp/actions/runs/9667675823/job/26670041537
这是一个bug报告。该问题主要涉及Mindnlp项目中的FocalNet自动配置错误。这个bug可能是由于程序逻辑问题或配置错误引起的。,🚨 fix focalnet autoconfig bug,,2024-06-25T16:08:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1335
这是一个类型为bug报告的issue，涉及的主要对象是CI（持续集成）。原因是用户希望强制使用pip版本为24.0，可能出现了与当前环境不兼容的情况。,force ci pip==24.0,,2024-06-25T02:37:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1334
这是一个用户提出需求的issue，主要对象是Vilt。由于缺少具体内容，无法分析导致的具体症状或问题。,【社区实习】Vilt,,2024-06-24T12:42:21Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1333,/model vilt
这是一个bug报告，涉及主要对象为mindnlp中的vision_encoder_decoder模型。由于误删了一个模型文件导致bug，现已修正。,fix vision_encoder_decoder,误删了一个模型文件，现已修正。,2024-06-24T11:16:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1332
这个issue类型是用户提出需求，主要涉及的对象是Vilt模型。,【社区实习】Vilt,,2024-06-24T11:13:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1331
这是一个提交Revert操作的Issue，涉及的主要对象是mindnlp仓库下的一个名为vision_encoder_decoder的CC（Change or Comment）。原因可能是需要回退之前的操作或变更。,"Revert ""【昇腾AI创新大赛】vision_encoder_decoder""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】vision_encoder_decoder),2024-06-24T09:10:08Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1330,为什么将所有的nn.Cell改成nn.Module？以及其它Mindspore的api也都换成Pytorch的？目前跑这些都会报错，之前的commit没有问题。
这个issue类型是需求提出，涉及大模型任务下的retnet任务，并希望在PR内容中添加相关任务链接。,大模型任务-retnet,**PR内容** 添加大模型任务下的retnet任务 **任务链接** https://gitee.com/mindspore/community/issues/I835ND?from=projectissue,2024-06-23T22:08:34Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1329,auto没注册，而且trl的改动不要一起提交
这是一个需求提交类型的issue，主要对象是向mindnlp项目添加M-CTC-T模型。当前issue中的内容为!pass，可能是暂时无需进一步操作或者待处理。,【社区实习】add M-CTC-T model,!pass,2024-06-23T10:24:07Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1328,\model mctct,\model mctct,\model mctct
这是一个请求特定模型的issue，主要对象是需要使用tapas模型的用户。,【昇腾ai创新大赛】tapas,/model tapas,2024-06-22T21:38:03Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1327,/model tapas," 仓库CI测试通过 令use_gumbel_for_cells=True,自定义RelaxedBernoulli 令use_gumbel_for_aggregation=True,自定义RelaxedOneHotCategorical",通过CI测试：https://github.com/mindsporelab/mindnlp/actions/runs/9628917715/job/26557691207,/model tapas,修正误差，loss达到1e6，通过CI门禁测试：https://github.com/mindsporelab/mindnlp/actions/runs/9631230358/job/26562759008 !image,commit中存在其他PR代码，此PR无效
这个issue类型是bug报告，主要对象是从huggingface加载预训练模型时使用revision参数的情况，可能由于无法正确解析参数导致问题出现。,从huggingface获取预训练模型revision参数可能不能正确解析的问题,"从huggingface/transformer 迁移TAPAS模型过程中发现从huggingface加载预训练模型，使用revision参数存在不能正确获取到对应版本的问题 代码链接：https://github.com/deepawake/mindnlp/blob/master/tests/ut/transformers/models/tapas/test_modeling_tapas.py test_inference_question_answering_head_conversational_absolute_embeddings部分代码如下： model = TapasForQuestionAnswering.from_pretrained(""google/tapassmallfinetunedsqa"", revision=""no_reset"", from_pt=True) 多次清空本地缓存模型测试，获取到的都是revision='reset'的版本（main版本），而不是指定的no_reset版本",2024-06-22T14:04:39Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1326,预训练模型位置：https://huggingface.co/google/tapassmallfinetunedsqa,fixed 新代码采用和hf同样的逻辑
这是一个关于昇腾AI创新大赛中TAPAS相关问题的讨论，类型为用户提出需求或寻求帮助的类型，主要涉及到TAPAS。可能是用户在竞赛中遇到了问题或需要更多信息。,【昇腾AI创新大赛】TAPAS,,2024-06-22T08:04:44Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1325,/model tapas,"CI通过：https://github.com/mindsporelab/mindnlp/actions/runs/9624022144/job/26547190702 目前存在问题：  1.由于mindspore中要求nn.probability.distribution要求每项概率大于0,pytorch中要求的是大于等于0,所以添加了如下代码替换原来的softmax: EPSILON_PROB_ZERO_DIVISION = 1e6 避免出现概率出现0报错 def softmax_with_epsilon(logits):     probs  = ops.softmax(logits)     probs = probs + EPSILON_PROB_ZERO_DIVISION probs不能存在0     probs = probs/probs.sum(axis=1, keepdims=True)     return probs 导致TapasModelIntegrationTest::test_training_question_answering_head_weak_supervision部分无法达到pytorch测试文档1e6的atol取值，EPSILON_PROB_ZERO_DIVISION取值1e6时候误差为3.5e4,EPSILON_PROB_ZERO_DIVISION 取值1e7时，误差为3.6e5,取更小值时存在检查概率和不为1或者检查仍然认为存在0概率之类的错误。log如下图： !log  2.TapasModelIntegrationTest:test_inference_question_answering_head_conversational_absolute_embeddings中TapasForQuestionAnswering.from_pretrained(""google/tapassmallfinetunedsqa"", revision=""no_reset"", from_pt=True)按照参数获取的应该是no_reset版本的配置文件，但是实际上下载的是reset(main)版本的配置文件(多次尝试清空后缓存后重新下载都如此，但是也有成功获取到no_reset版本的情况)，需要添加model.config.reset_position_index_per_cell = False或者手动修改config.json中该参数才能通过测试。",测试通过，本赛题完成
这个issue类型是需求提出，主要涉及对象是昇腾AI创新大赛中的TAPAS模型。,【昇腾AI创新大赛】TAPAS,,2024-06-22T07:20:24Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1324,/model tapas
这个issue是关于bug报告，涉及到mindnlp的配置和分词问题。由于配置问题和分词错误，导致了bug现象。,fix configuration and tokenization,,2024-06-21T09:37:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1323
这是一个需求类型的issue，主要涉及mindnlp/trl/models文档下的文件更新操作。由于作者未能通过本地测试，导致未能完成所有文件的更新。,renew all files under mindnlp/trl/models document,"**PR内容** add all files under trl/models document. I haven't pass all  the local pylint test, but for updating the progress with the tutor, I pull a requests. There are still some tests that need to be done. Fixes https://gitee.com/mindspore/community/issues/I97VRL",2024-06-20T22:42:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1322
这是一个用户提出需求的issue，主要涉及的对象是向mindnlp项目中添加vit_msn模型。,【社区实习】add vit_msn model,,2024-06-20T11:37:57Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1321,/model vit_msn,single model test passed: https://github.com/mindsporelab/mindnlp/actions/runs/9617391070/job/26529043529
"这是一个开源实习（实习招聘）类型的issue，主要涉及项目""DINOv2""。",【开源实习】DINOv2,https://gitee.com/mindspore/community/issues/I9UUPK,2024-06-19T13:14:24Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1320,/model dinov2,https://github.com/mindsporelab/mindnlp/actions/runs/9582688595,有问题，还要修改
"这是一个用户提出需求的issue，主要对象是一个名为""vision_encoder_decoder""的项目。",【昇腾AI创新大赛】vision_encoder_decoder,,2024-06-19T12:38:07Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1319,/model vision_encoder_decoder,/model vision_encoder_decoder,/model vision_encoder_decoder,之前的团队所做的vision_encoder_decoder模型缺少5个关键模型的测试，包括，deit、layoutlmv3、trocr、donut和nougat。目前，我已完成所有模型的相关文件（包括模型文件和测试文件），且所有相关测试都已通过。 （1）deit的本地测试我已在 https://github.com/mindsporelab/mindnlp/pull/1296 中完成。 （2）layoutlmv3的本地测试： !layoutlmv3 （3）trocr的本地测试： !trocr （4）donut的本地测试： !donut （5）nougat的本地测试： !nougat （7）最终，vision_encoder_decoder的本地测试： !vision_encoder_decoder 而vision_encoder_decoder的single model test可能由于内存不足等原因会导致测试中断，但并未报failed的错误。 测试链接为：https://github.com/mindsporelab/mindnlp/actions/runs/9582697669/job/26422254369
该issue类型为社区实习相关，主要涉及的对象是DINOv2。原因是该issue是关于社区实习生在mindnlp项目中工作的相关事宜。,【社区实习】DINOv2,https://gitee.com/mindspore/community/issues/I9UUPK,2024-06-19T09:44:05Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1316,/model dinov2,Single model test已过：https://github.com/mindsporelab/mindnlp/actions/runs/9581742791
这是一个bug报告类型的issue，涉及到mindnlp项目的一个bug。由于没有内容，导致了待解决的bug。,fixbug,,2024-06-19T06:42:06Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1315,/model layoutlmv3,/model vision_encoder_decoder
这是一个bug报告，主要涉及mindnlp项目中的一个修复bug的问题。原因可能是程序中出现了错误导致某些功能无法正常运行。,fixbug,,2024-06-19T05:11:34Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1314,/model layoutlmv3,/model layoutlmv3,/model layoutlmv3
这是一条bug报告，涉及的主要对象是mindnlp的测试模型。这个问题可能是由于模型在测试过程中出现了问题，无法正常运行或者产生了错误的结果。,test model,,2024-06-19T04:24:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1313
这是一个空白issue，类型为用户提出需求，涉及主要对象为测试模型。,TEST MODEL,,2024-06-19T04:16:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1312
"这是一个bug报告，主要对象是""test model""，由于缺少具体内容，无法确定具体问题所在。",test model,,2024-06-19T03:53:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1311
这是一个bug报告，主要对象是qdqbert（修复auto注册冲突）。原因是auto注册冲突导致bug需要修复。,【昇腾AI创新大赛】qdqbert（修复auto注册冲突）,,2024-06-18T16:51:43Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1310,/model qdqbert,第一张图中是使用hf原始仓代码运行transformer测试得到的结果，也出现精度问题，精度差异较大，达到了0.0632，经测试7e2才能pass。 同时，第二张图使用不同的量化设置，将8位量化改成4位量化，精度差异更显著，证明初始量化设置对精度有一定影响。 !1718727950295 !1718728482503,测试通过https://github.com/mindsporelab/mindnlp/actions/runs/9569058635,测试通过，本赛题完成
该类型为用户提出需求，主要对象为“qdqbert”模型。由于issue内容为空导致用户提出了需求或问题。,【昇腾AI创新大赛】qdqbert,,2024-06-18T11:14:55Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1309,/model qdqbert,/model qdqbert,"ut测试通过：https://github.com/mindsporelab/mindnlp/actions/runs/9564872286， 但最后一个test的精度仍有问题，主要是hf源码中使用的初始设置QuantDescriptor(num_bits=8, calib_method=""max"")对精度有一定程度的影响，正在寻找解决措施",/model qdqbert,!1718727950295 第一张图中是使用hf原始仓代码运行transformer测试得到的结果，也出现精度问题，精度差异较大，达到了0.0632，经测试7e2才能pass。 同时，第二张图使用不同的量化设置，将8位量化改成4位量化，精度差异显著，证明初始量化设置对精度有较大影响。 !1718728482503
"这个issue属于用户提出需求，主要涉及对象是""mvp 注册auto""。由于用户想要在昇腾AI创新大赛中注册mvp时遇到了问题，需要寻求帮助解决。",【昇腾AI创新大赛】mvp 注册auto,,2024-06-18T11:08:22Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1308,/model mvp,测试通过：https://github.com/mindsporelab/mindnlp/actions/runs/9563923313
这是一个缺少具体内容的issue，类型为空issue，主要对象为mindnlp项目。缺乏具体内容可能是由于提交者未填写相关信息或者意外操作导致。,d,,2024-06-18T09:03:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1307
这个issue类型为用户提出需求，主要涉及的对象是增加 Focalnet 算法模型到 mindnlp 中。这是由于用户希望社区实习项目中能够新增加 Focalnet 模型，以丰富模型选择和功能的原因。,【社区实习】Add Focalnet,,2024-06-18T07:42:12Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1306,/model focalnet,single model test已通过: https://github.com/mindsporelab/mindnlp/actions/runs/9561014739
这是一个用户提出需求类型的issue，主要涉及的对象是owlv2注册auto功能和精度提升。,【昇腾AI创新大赛】owlv2 注册auto&提升精度,,2024-06-18T06:51:27Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1305,/model owlv2,测试通过：https://github.com/mindsporelab/mindnlp/actions/runs/9562008626
这是一则用户提出需求的issue，主要涉及到增加owlv2模型，原因可能是为了提升精度和注册auto。,【昇腾AI创新大赛】add owlv2 model , CC(【昇腾AI创新大赛】add owlv2 model) 提升精度&注册auto,2024-06-18T06:24:37Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1304,/model owlv2
这个issue类型是bug报告，主要涉及的对象是ibert配置文件。由于ibert配置文件存在错误，导致需要修复。,fix ibert config,,2024-06-17T08:33:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1303
这是一个用户提出需求的类型的issue，主要涉及要更新Lilt模型，可能是由于目前的模型不满足用户需求或者有新数据需要更新。,【开源实习】update Lilt model,https://gitee.com/mindspore/community/issues/I9UWEA !image,2024-06-17T08:18:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1302
这个issue是关于撤销添加owlv2模型的更改，主要对象是mindnlp项目。因为该更改引发了某种问题或者用户提出了关于该模型添加的问题或请求。,还原【昇腾AI创新大赛】add owlv2 model,"Reverts mindsporelab/mindnlp CC(Revert ""【昇腾AI创新大赛】add owlv2 model"")",2024-06-17T04:21:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1301
这个issue属于用户提出需求类型，主要涉及mindnlp的Whisper graph模式功能支持。用户希望能够通过README.MD快速开始使用这个功能。,support for Whisper graph mode,support for whisper graph mod can quickly started with the README.MD,2024-06-17T02:38:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1300
该issue类型为需求提出，主要对象是向MindNLP项目添加Swin2SR模型。,Add Swin2SR model,,2024-06-15T03:21:17Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1299,/model swin2sr
"这个issue是用户提出需求或者建议，主要涉及到""昇腾AI创新大赛""的""vision-encoder-decoder""。",【昇腾AI创新大赛】vision-encoder-decoder,,2024-06-13T09:34:47Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1298,/model visionencoderdecoder,/model vision_encoder_decoder,/model vision_encoder_decoder,/model vision_encoder_decoder,/model vision_encoder_decoder,CI通过：https://github.com/mindsporelab/mindnlp/actions/runs/9497973505/job/26175714258 visionencoderdecoder的test中有mindnlp中还未实现的模型：deit、layoutlmv3、swin、trocr 这里实现了swin，其它三个未实现 本地slow !vedslow,测试通过，本赛题完成
这个issue是一个bug报告，涉及主要对象是添加视觉编码器-解码器功能。由于未能捕获到数据，导致出现了此bug。,add vision-encoder-decoder,!捕获 !捕获,2024-06-12T16:13:28Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1297,/model visionencoderdecoder,/model visionencoderdecoder,/model visionencoderdecoder,/model visionencoderdecoder,/model vision_encoder_decoder,https://github.com/mindsporelab/mindnlp/actions/runs/9486502870,测试用例明显少于竞争团队。 本赛题已有其他团队完成，本PR关闭
该issue类型为用户提出需求，主要涉及的对象是需要补充deit的模型代码和测试代码以及vision_text_dual_encoder和deit模型相关的测试代码。由于缺乏相关代码，用户提出了需要补充的需求。,【昇腾AI创新大赛】vision_text_dual_encoder,补充deit的模型代码和测试代码，补充vision_text_dual_encoder和deit模型相关的测试代码。,2024-06-12T12:07:44Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1296,/model vision_text_dual_encoder,/model vision_text_dual_encoder,deit本地测试结果： !deit vision_text_dual_encoder本地测试结果： !vision_text_dual_encoder,https://github.com/mindsporelab/mindnlp/actions/runs/9482358909,测试通过，本赛题完成
这是一个社区实习相关的问题，涉及主要对象为TrOCR。用户提供了Gitee ID并希望参与实习项目。,【社区实习】TrOCR (#I9V07B),Gitee ID: liujunyan_2024,2024-06-12T12:06:43Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1295,"测一下模型，参考其他pr，回复/model  name, 然后去action里看CI情况",/model trocr,/model trocr,test 已过：https://github.com/mindsporelab/mindnlp/actions/runs/9695315599  ,auto没注册,已在auto中注册 ,把冲突解掉
"这个issue属于用户提出需求的类型，主要涉及的对象是在github上的mindnlp项目中的""vision_text_dual_encoder""相关代码。原因是用户想要补充deit模型相关的代码和测试代码。",【昇腾AI创新大赛】vision_text_dual_encoder,补充deit的模型代码和测试代码，补充vision_text_dual_encoder和deit模型相关的测试代码。,2024-06-12T11:52:15Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1294,/model vision_text_dual_encoder
该issue为技术讨论，涉及到DETR模型在昇腾AI创新大赛中的后续迁移与更新操作。由于此前的PR中只是迁移了transformers而没有完整更新，故需要进一步处理和讨论。,【昇腾AI创新大赛】DETR (the lastest HF commit),⚠ 该 PR 为 CC(【昇腾AI创新大赛】DETR) 和 CC(【昇腾AI创新大赛】DETR) 的后续！ 此前 pr 中迁移的是 transformers 的最新发行版 v4.41.2，迁完之后我们发现 **完成度很低**，两方面原因：  MindNLP 不能依赖 timm，但DETR模型很依赖timm的预训练权重  底层 from_pretrain 的 bug 导致权重初始化测试挂了一个 （参见 PR CC([bugfix] PreTrainedModel.from_pretrained.load_param_into_net) ） 我们发现 4 天前 master 分支中加入了一些**声称**能 ”直接加载HF backbone“ 的commit，于是在此次 pr 中我们尝试对标 transformers 的mastrer 分支最新 commit 35a6d9d6483d4d4d7cd817ed4ecfd5f86e1f9a23 再次做 **完全重新迁移**，最终完成度仍然不是很理想  **声称**能 ”直接加载HF backbone“ 的功能仍然并不存在  预训练权重仍然加载不了，查明原因为：DETR 只有一个比较官方的的 ckpt 仓库 detrresnet50，这个ckpt的key名字是符合torchvision定义的resnet50，而非transformers中的resnet（详见下面附图）；除非手动转一个静态的checkpoint出来测 ，否则很难去动态地适配这一点  因为上述原因，精度测试都无法进行 !detr加载预训练权重失败的说明 > 写在最后：如果这个模型无论如何不能算通过的话，希望老师能把这个题换成改成我们组之前在 mask2former 和 oneformer 中顺带迁移的 swin 模型；我们已经在这个 detr 上耗费太多时间了……,2024-06-12T09:04:09Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1293,/model detr,/model detr,Single model test 已通过：https://github.com/mindsporelab/mindnlp/actions/runs/9481830414,考虑到题目难度和完成情况，本赛题完成,继续解决一下加载的问题
这是一个bug报告，涉及对象为`PreTrainedModel.from_pretrained.load_param_into_net`方法。导致问题的原因是前缀判定仅与字符串的开头有关，因此在进行replace操作时只需要设置count=1。,[bugfix] PreTrainedModel.from_pretrained.load_param_into_net,根据 1165~1166 行的逻辑，前缀判定只与字符串**开始**有关，故此处replace只需要count=1,2024-06-12T08:36:25Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1292,是什么bug？,"> 是什么bug？ 是加载预训练权重的时，极端情况下可能会导致不兼容 考虑模型的 prefix 是 ""model""，预训练权重文件里有一个 key 的路径**中间也含有** “model”，例如 “model.encoder.backbone.model.embed.conv.weight”， 那么这句 replace 会把两个 ""model."" 都删除，导致后面的代码查无此key，预训练权重被跳过加载，无exception 受此bug影响的情况目前可能只有一个，即 detr 模型的单元测试中，暂时被注释掉的 `DetrModelTest::test_save_load_fast_init_from_base` ```python .skip(""MindNLP AutoModel.from_pretrained() not compatible"") def test_save_load_fast_init_from_base(self):     pass ``` 实测加上此 fix 后，detr 这个 ut 能过。 但是意义也不大，不是特别 fatal 的 bug，酌情考虑（"
这是一个需求类型的Issue，主要涉及对象是splinter模型。,【社区实习任务】splinter,/model splinter,2024-06-12T08:07:29Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1291,!PixPin_20240612_164259,/model splinter,https://github.com/mindsporelab/mindnlp/actions/runs/9481205593/job/26123475000,https://gitee.com/mindspore/community/issues/I9UZYHnote_28562681
这个issue类型是用户提出需求，请求添加一个名为convnextv2的模型。主要对象是mindnlp的项目。,add model convnextv2,,2024-06-12T02:05:24Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1290,/model convnextv2,single model test 已执行通过 https://github.com/mindsporelab/mindnlp/actions/runs/9475557100/job/26107039768
这是一个bug报告，涉及的主要对象是Mobilenet_v2模型。该问题由于反序列化的bug，导致仍然存在与Mobilenet_v1相同的问题。,【社区实习】Mobilenet_v2,还是有和mobilenet_v1一样的反序列化的bug，其他地方都没问题了。,2024-06-11T16:59:51Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1289,/mobilenet_v2,学长，如果没问题的话顺道把https://gitee.com/mindspore/community/issues/I9UXI2任务也done一下叭,https://github.com/huggingface/transformers/commit/25245ec26dc29bcf6102e1b4ddd0dfd02e720cf5 学长，这个特性有必要和huggingface同步吗？如果需要的话我可以去做一下。
该issue为bug报告，主要涉及的对象是mindnlp下的Sew&Sew模型，由于权重归一化的bug导致了需要更新模型并修复bug。,update sew&sew_d model and fix weight_norm bug,,2024-06-11T14:36:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1288
这个issue类型是撤销提交，涉及主要对象为mindnlp下的owlv2 model。由于不明确原因导致了提交的要撤销。,"Revert ""【昇腾AI创新大赛】add owlv2 model""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】add owlv2 model),2024-06-11T13:21:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1287
"这个issue是一个代码回退（revert），不涉及具体bug报告或用户需求，主要对象是mindnlp下的一个特定提交""【昇腾AI创新大赛】owlv2""。","Revert ""【昇腾AI创新大赛】owlv2""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】owlv2),2024-06-11T12:57:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1286
这个issue类型是bug报告，主要涉及的对象是更新sew&sew_d模型以及修复weight_norm bug。原因导致了weight_norm bug的症状。,【开源实习】update sew&sew_d model and fix weight_norm bug,,2024-06-11T12:38:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1285
"这是一个用户提出需求或咨询问题的类型，主要对象是""【昇腾AI创新大赛】clap""。由于缺乏具体的内容描述，无法确定具体问题或需求。",【昇腾AI创新大赛】clap,,2024-06-11T12:26:42Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1284,/model clap,!image,/model clap,https://github.com/mindsporelab/mindnlp/actions/runs/9466671128/job/26078872533 single model test通过,测试通过，本赛题完成
这个issue类型是bug报告，主要涉及的对象是ibert模块。由于代码存在慢、pylint等问题，导致了该issue的产生。,【昇腾AI创新大赛】ibert,ut !1718101006475 slow !1718101116384 pylint !1718102205092,2024-06-11T12:00:37Z,,closed,0,10,https://github.com/mindspore-lab/mindnlp/issues/1283,/model ibert,/model ibert,/model ibert,/model ibert,/model ibert,/model ibert,/model ibert,/model ibert,CI： https://github.com/mindsporelab/mindnlp/actions/runs/9470703104/job/26092227774 线上测试报错，怀疑是内存问题，本地slow运行正常 !slow,测试通过，本赛题完成
这是一个用户提出需求的类型，主要对象是昇腾AI创新大赛的项目iBert。,【昇腾AI创新大赛】iBert,,2024-06-11T11:48:56Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1282,/model ibert,/model ibert
"这个issue类型是代码回退，该问题单涉及的主要对象是""【昇腾AI创新大赛】ibert""。由于某些原因导致的需要回退操作，可能是出现了异常或者需要重新恢复到之前的代码状态。","Revert ""【昇腾AI创新大赛】ibert""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】ibert),2024-06-11T11:07:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1281
"这是一个bug报告，主要涉及的对象是mindnlp下的四个模型（canine, git, speecht5, switch_transformers），由于bf16的问题导致switch_transformers在测试生成文字时出现正确和错误交替的情况。","improve auto for canine, git, speecht5 and switch_tranformers, and add tokenization for speecht5",已在本地完整对四个模型RUN_SLOW 其中switch_transformers仍旧因为bf16的问题在一个点上时正确时错误(test_generate_with_past_key_values) 详情描述见https://github.com/mindsporelab/mindnlp/pull/1190issuecomment2151644356,2024-06-11T09:01:24Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1280,/model speecht5,/model canine,/model git,/model switch_transformers,single model test link: speecht5 canine git switch_transformers
这是一个用户提出需求的issue，主要涉及要向mindnlp添加模型DPR。用户可能因为希望增加DPR模型的功能而提出这个需求。,add model dpr,,2024-06-11T08:27:39Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1279,/model dpr,/model dpr,/model dpr,Single model test已执行通过 https://github.com/mindsporelab/mindnlp/actions/runs/9462618945
该issue属于用户提出需求类别，主要涉及的对象是昇腾AI创新大赛owlv2。,【昇腾AI创新大赛】owlv2,,2024-06-11T07:21:08Z,,closed,0,11,https://github.com/mindspore-lab/mindnlp/issues/1278,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,测试通过：https://github.com/mindsporelab/mindnlp/actions/runs/9463935172/job/26070178178,测试通过，本赛题完成,经鉴定代码抄袭，取消参赛资格
这是一个bug报告，主要涉及对象为Mindnlp下的SqueezeBERT模型，问题是mirror URL错误导致无法下载模型。,fix mirror url in squeezebert,,2024-06-11T07:10:46Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1277,/model dpr
这个issue类型为用户提出需求，主要涉及的对象是在GitHub上的mindnlp仓库。,【昇腾AI创新大赛】add owlv2 model,,2024-06-11T06:47:29Z,,closed,0,17,https://github.com/mindspore-lab/mindnlp/issues/1276,/model owlv2, 本地测试通过,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,/model owlv2,测试通过：https://github.com/mindsporelab/mindnlp/actions/runs/9464249183,测试通过，本赛题完成,抄袭情况存疑，按最终判定结果确认
"这是一个用户提出需求的issue，主要对象是新增一个名为""tokenizer_fast""的功能模块。由于需要加快分词器的处理速度或者增加支持更快速的分词方式，用户提出了这个需求。",add tokenizer_fast,,2024-06-11T03:35:50Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1275,/model squeezebert,/model dpr,/model flava
这是一个用户提出需求的issue，请求在mindnlp中添加一个dpr模型。,add dpr model,,2024-06-11T02:08:04Z,,closed,0,9,https://github.com/mindspore-lab/mindnlp/issues/1274,/model dpr,/model dpr,/model dpr,/model dpr,/model dpr,/model dpr,/model dpr,/model dpr,/model dpr
这是一个用户提出需求的issue，主要对象是在mindnlp中添加模型pegasusx。 由于缺乏该模型，用户希望可以在mindnlp中使用pegasusx模型进行相关任务。,add model pegasusx,,2024-06-10T18:55:00Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1273,/model pegasus_x,/model pegasus_x
这个issue属于bug报告类型，涉及到DETR模型的代码修复。原因可能是最近的几个PR合并导致了模型参数初始化存在问题。,【昇腾AI创新大赛】DETR,这是转自  CC(【昇腾AI创新大赛】DETR) 的PR，队友人不在，我来帮他修剩下的小bug NOTE: 最近的几个PR合入疑似导致有2个【模型参数初始化】相关的测试无法通过了，暂时先skip了  `DetrModelTest::test_initialization`  `DetrModelTest::test_save_load_fast_init_from_base` 错误原因藏得很深，与 `PreTrainedModel.from_pretrained()` 实现的兼容性有关，位于文件 `mindnlp\transformers\modeling_utils.py:1177`，大致错误逻辑如下：  DETR 模型依赖 ResNet 作为其 backbone，两个的模型 base_model_prefix 都是 “model”    DETR 模型的预训练ckpt中的 key 会形如 backbone.conv_encoder.model.embedder.embedder.convolution.weight    注意到中间的 model. 就是 ResNet   在 `PreTrainedModel.from_pretrained()` 中有加载预训练权重的代码，第 1170 行 `remove_prefix_from_model` 判定为 True，导致 第1177 行执行，把上述 key 中间的 `model.` 删除掉了，故**预训练权重加载不了**     这个未加载权重的 key 仍然存在于 `keys_missing` 列表中     但第 1282 行的逻辑会把同样的作用的 key 加入 `_loaded_keys` 列表中     于是 `_fast_init` 的表现异常，两个测试无法通过,2024-06-10T15:15:06Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1272,/model detr,/model detr,single model test 通过：https://github.com/mindsporelab/mindnlp/actions/runs/9452425816,/model detr
这是一个用户提出需求的issue，主要涉及到昇腾AI创新大赛的ibert。,【昇腾AI创新大赛】ibert,,2024-06-10T08:55:04Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1271,/model ibert,/model ibert,/model ibert,https://github.com/mindsporelab/mindnlp/actions/runs/9445764718,测试通过，本赛题完成,按自定义反向通过重新评测。
这个issue类型为bug报告，主要涉及到Detr的修改。由于Detr的改动，可能导致了出现bug或者用户提出了相关问题。,Detr changed,,2024-06-10T06:26:32Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1270,/model detr
这是一个用户提交的需求问题，涉及的主要对象是Detr模型。这个问题可能是用户在使用Detr模型时遇到了一些困难或者希望对该模型进行改进。,Detr,,2024-06-10T06:07:42Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1269,/model detr,/model detr,/model detr,/model detr,/model detr,/model detr,/model detr
这是一个用户提出需求的类型，主要涉及的对象是名为Vitdet的开源实习项目。,【开源实习】Vitdet,,2024-06-10T03:37:25Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1268,/model vitdet,/model vitdet,  https://github.com/mindsporelab/mindnlp/actions/runs/9442402246/job/26004500648, test链接：https://github.com/mindsporelab/mindnlp/actions/runs/9442402246/job/26004500648                                                 实习任务链接：https://gitee.com/mindspore/community/issues/I9V0IJ,/model vitdet
这是一个用户提出需求的issue，主要涉及的对象是昇腾AI创新大赛speecht5。,【昇腾AI创新大赛】speecht5,,2024-06-09T15:40:41Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1267,/model speecht5,/model speecht5,/model speecht5,/model speecht5,  single model test: https://github.com/mindsporelab/mindnlp/actions/runs/9443667691 本地run_slow: !image 非slow的两个测试点test_one_to_many_generation与test_batch_generation中的6个精度标准1e8无法通过，改为了2个5e4以及4个1e5，所有测试均通过,测试通过，本赛题完成
这是一个bug报告类型的issue，主要涉及Mindnlp中的修改。这个问题可能由于近期的代码更改所致。,Add detr changed,,2024-06-09T15:11:12Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1266,/model detr
这是一个用户提出需求的类型，主要涉及DETR模型。由于参与昇腾AI创新大赛，用户可能在使用DETR模型时遇到了问题或需要相关支持。,【昇腾AI创新大赛】DETR,,2024-06-09T14:17:22Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1265,/model detr
这个issue类型属于用户提出需求，主要对象是昇腾AI创新大赛 DETR model，用户寻求关于该模型在比赛中的相关问题的帮助。,昇腾AI创新大赛 DETR model,,2024-06-09T13:57:07Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1264,/model detr
该issue类型为用户提出需求，主要涉及的对象是文档（docs for transformers），由于任务地址指向错误导致用户无法访问相关页面。,docs for transformers,任务地址： 可能是这个：https://gitee.com/mindspore/community/issues/I9GVLNnote_28264845 该页面已 404，如果该地址有误请自行确认。 !pr,2024-06-09T05:34:15Z,,closed,0,16,https://github.com/mindspore-lab/mindnlp/issues/1263,"ok Original From: ""Bo ***@***.***&gt; Date: Sun, Jun 9, 2024 23:21 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers))  commented on this pull request. In mindnlp/transformers/cache_utils.py:  &gt;              The rerotation cosine and sine values are calculated based on the input key_states, cos, and sin tensors.          +          Raises:              N/A   这个Raises是一定要包含的一项么，如果是的话，可不可以统一一下，有的Raises写的是None，有的写的是N/A。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;","https://gitee.com/mindspore/community/blob/master/guidelines/docs_comments_guidelines_zh_cn.mdpythonapi%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83 以上是我在另一个项目里用到的文档写作规范，可能和mkdocs的不完全一样。 可不可以请你： 1. 看一下这个规范在mkdocs下能不能跑通。 2. 如果可以的话，我们可以按照这个规范修改当前的PR。 3. 如果按照这个规范，mkdocs下有跑不通的地方，我们可以在其基础上写一个自己的文档规范。 举个例子，现在的PR里Example的写法不太统一，有的是 ``` Example:     ```python ``` 有的是 ``` Example:     ```python     >>> from transformers import AlbertConfig, AlbertModel ``` 要修改的话，工作量会有点大，有问题随时问。  您看以上这样操作行不行。我不确定文档需要规范到什么程度，如果只要mkdocs通过，不需要太统一格式的话，我也可以快速过一遍就合入哈。","当前版本我按自己的理解规范已经较仔细地改了一遍，不只是mkdocs能跑通。 比如说所有的Examples改为Example，添加所有缺失的Returns，Args，以及Args等内部的有层次的内容统一用引用块处理不同层级缩进，等等。可以mkdocs输出看一下，风格是统一的。 如果需要按另一个规范改的话，我建议新开一个任务。 Original From: ""Bo ***@***.***&gt; Date: Mon, Jun 10, 2024 20:27 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers)) https://gitee.com/mindspore/community/blob/master/guidelines/docs_comments_guidelines_zh_cn.mdpythonapi%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83  以上是我在另一个项目里用到的文档写作规范，可能和mkdocs的不完全一样。  可不可以请你： 看一下这个规范在mkdocs下能不能跑通。 如果可以的话，我们可以按照这个规范修改当前的PR。 如果按照这个规范，mkdocs下有跑不通的地方，我们可以在其基础上写一个自己的文档规范。 举个例子，现在的PR里Example的写法不太统一，有的是  Example:     ```python   有的是  Example:     ```python     &gt;&gt;&gt; from transformers import AlbertConfig, AlbertModel   要修改的话，工作量会有点大，有问题随时问。  您看以上这样操作行不行。我不确定文档需要规范到什么程度，如果只要mkdocs通过，不需要太统一格式的话，我也可以快速过一遍就合入哈。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;","我看了一下你给的规范，我们之间有差异应该只有示例代码那部分。 此外，Description里面有层次的内容要用引用块mkdocs才能展现出来。 我们可以定一个面向mkdocs的文档规范。 如果只是要修改示例代码的前缀的话，这个工作量和现在已完成的工作量相比还是很小的。 最后还是想咨询下这个任务的分值问题，这个任务的工作量是其他文档修改工作量的四五倍不止，10分的分值是否不太合理，是否要改调整为20或30分呢？ Original From: ""Bo ***@***.***&gt; Date: Mon, Jun 10, 2024 20:27 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers)) https://gitee.com/mindspore/community/blob/master/guidelines/docs_comments_guidelines_zh_cn.mdpythonapi%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83  以上是我在另一个项目里用到的文档写作规范，可能和mkdocs的不完全一样。  可不可以请你： 看一下这个规范在mkdocs下能不能跑通。 如果可以的话，我们可以按照这个规范修改当前的PR。 如果按照这个规范，mkdocs下有跑不通的地方，我们可以在其基础上写一个自己的文档规范。 举个例子，现在的PR里Example的写法不太统一，有的是  Example:     ```python   有的是  Example:     ```python     &gt;&gt;&gt; from transformers import AlbertConfig, AlbertModel   要修改的话，工作量会有点大，有问题随时问。  您看以上这样操作行不行。我不确定文档需要规范到什么程度，如果只要mkdocs通过，不需要太统一格式的话，我也可以快速过一遍就合入哈。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;","> https://gitee.com/mindspore/community/blob/master/guidelines/docs_comments_guidelines_zh_cn.mdpythonapi%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83 以上是我在另一个项目里用到的文档写作规范，可能和mkdocs的不完全一样。 可不可以请你： >  > 1. 看一下这个规范在mkdocs下能不能跑通。 > 2. 如果可以的话，我们可以按照这个规范修改当前的PR。 > 3. 如果按照这个规范，mkdocs下有跑不通的地方，我们可以在其基础上写一个自己的文档规范。 >  > 举个例子，现在的PR里Example的写法不太统一，有的是 >  > ``` > Example: >     ```python > ``` >  > 有的是 >  > ``` > Example: >     ```python >     >>> from transformers import AlbertConfig, AlbertModel > ``` >  > 要修改的话，工作量会有点大，有问题随时问。 >  >  您看以上这样操作行不行。我不确定文档需要规范到什么程度，如果只要mkdocs通过，不需要太统一格式的话，我也可以快速过一遍就合入哈。 感觉可以用这个","> 我看了一下你给的规范，我们之间有差异应该只有示例代码那部分。 此外，Description里面有层次的内容要用引用块mkdocs才能展现出来。 我们可以定一个面向mkdocs的文档规范。 如果只是要修改示例代码的前缀的话，这个工作量和现在已完成的工作量相比还是很小的。 最后还是想咨询下这个任务的分值问题，这个任务的工作量是其他文档修改工作量的四五倍不止，10分的分值是否不太合理，是否要改调整为20或30分呢？ > […]() > Original From: ""Bo ***@***.***&gt; Date: Mon, Jun 10, 2024 20:27 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers)) https://gitee.com/mindspore/community/blob/master/guidelines/docs_comments_guidelines_zh_cn.mdpythonapi%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83 以上是我在另一个项目里用到的文档写作规范，可能和mkdocs的不完全一样。 可不可以请你： 看一下这个规范在mkdocs下能不能跑通。 如果可以的话，我们可以按照这个规范修改当前的PR。 如果按照这个规范，mkdocs下有跑不通的地方，我们可以在其基础上写一个自己的文档规范。 举个例子，现在的PR里Example的写法不太统一，有的是 Example: ```python 有的是 Example: ```python &gt;&gt;&gt; from transformers import AlbertConfig, AlbertModel 要修改的话，工作量会有点大，有问题随时问。  您看以上这样操作行不行。我不确定文档需要规范到什么程度，如果只要mkdocs通过，不需要太统一格式的话，我也可以快速过一遍就合入哈。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt; 我给你改到50分吧","爱你 峰哥。 干活去了 Original From: ***@***.***&gt; Date: Mon, Jun 10, 2024 22:33 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers)) 我看了一下你给的规范，我们之间有差异应该只有示例代码那部分。 此外，Description里面有层次的内容要用引用块mkdocs才能展现出来。 我们可以定一个面向mkdocs的文档规范。 如果只是要修改示例代码的前缀的话，这个工作量和现在已完成的工作量相比还是很小的。 最后还是想咨询下这个任务的分值问题，这个任务的工作量是其他文档修改工作量的四五倍不止，10分的分值是否不太合理，是否要改调整为20或30分呢？  …  Original From: ""Bo @.&gt; Date: Mon, Jun 10, 2024 20:27 PM To: @.&gt;; Cc: @.&gt;;""State @.&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers)) https://gitee.com/mindspore/community/blob/master/guidelines/docs_comments_guidelines_zh_cn.mdpythonapi%E6%B3%A8%E9%87%8A%E8%A7%84%E8%8C%83 以上是我在另一个项目里用到的文档写作规范，可能和mkdocs的不完全一样。 可不可以请你： 看一下这个规范在mkdocs下能不能跑通。 如果可以的话，我们可以按照这个规范修改当前的PR。 如果按照这个规范，mkdocs下有跑不通的地方，我们可以在其基础上写一个自己的文档规范。 举个例子，现在的PR里Example的写法不太统一，有的是 Example: python 有的是 Example: python &gt;&gt;&gt; from transformers import AlbertConfig, AlbertModel 要修改的话，工作量会有点大，有问题随时问。  您看以上这样操作行不行。我不确定文档需要规范到什么程度，如果只要mkdocs通过，不需要太统一格式的话，我也可以快速过一遍就合入哈。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: @.***&gt; 我给你改到50分吧 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;",那我们就在这个文档规范的基础上，建一个mkdocs能跑通的规范，尽量最小化修改当前PR的工作量。接着只要保证每个API doctring的格式统一就行？,已提交新PR，该PR做出的改动有： 1. 示例代码添加前缀 “>>>” 2. 添加并修订了这段时间新入库的模型文档 我明天将拟一份文档规范，该规范以你所提规范为框架，目的为使得mkdocs排版清晰美观。 该规范细节繁杂，我将辅以示例来说明规定各项规范的原因。 此外还有些小问题，比如docstring中存在转义字符会造成 mkdocs 排版混乱。明天将一并修订好并提交PR,你的规范没问题的。 我之前用引用块加缩进，来表示不同层级，而不是空行加缩进。 我把所有的这些 “>(缩进) ” 改成空行加缩进吧。 就按你这个规范来改，修改完毕后在提交PR,"N/A统一改为None，但None后面的description还是保留吧，有一些是有信息的 Original From: ""Bo ***@***.***&gt; Date: Tue, Jun 11, 2024 23:18 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers))  commented on this pull request. In mindnlp/transformers/convert_slow_tokenizer.py:  &gt;          Args:              self (SpmConverter): The instance of the SpmConverter class.              proto: The proto object containing the trainer specification.          +          Returns:              None: This method does not explicitly return a value, as it directly accesses and returns the unknown token ID from the proto object.   如果没有Returns，或者没有Raises，要不就直接去掉Returns或者Raises这一项，要不就统一写成None。当前PR里有的写的是None，有的是N/A，有的是很长一段话。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;",我这边用mkdoc serve的时候遇到如下问题： ERROR     mkdocstrings:            mindnlp.transformers.models.poolformer.configuration_roc_bert could            not be found ERROR     Error reading page 'en/api/transformers/models/roc_bert.md': ERROR     Could not collect            'mindnlp.transformers.models.poolformer.configuration_roc_bert' mindnlp.transformers.models.poolformer.configuration_roc_bert 在相对应的目录下没有文件。,"> N/A统一改为None，但None后面的description还是保留吧，有一些是有信息的 > […]() > Original From: ""Bo ***@***.***&gt; Date: Tue, Jun 11, 2024 23:18 PM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers))  commented on this pull request. In mindnlp/transformers/convert_slow_tokenizer.py: &gt; Args: self (SpmConverter): The instance of the SpmConverter class. proto: The proto object containing the trainer specification.  + Returns: None: This method does not explicitly return a value, as it directly accesses and returns the unknown token ID from the proto object. 如果没有Returns，或者没有Raises，要不就直接去掉Returns或者Raises这一项，要不就统一写成None。当前PR里有的写的是None，有的是N/A，有的是很长一段话。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt; 行，如果有有用的信息的就保留吧，如果description中的信息没啥用，就删掉只写None就好。","我明天看看 Original From: ""Bo ***@***.***&gt; Date: Wed, Jun 12, 2024 00:14 AM To: ***@***.***&gt;; Cc: ***@***.***&gt;;""State ***@***.***&gt;; Subject: Re: [mindsporelab/mindnlp] docs for transformers (PR CC(docs for transformers)) 我这边用mkdoc serve的时候遇到如下问题：  ERROR     mkdocstrings:  mindnlp.transformers.models.poolformer.configuration_roc_bert could  not be found  ERROR     Error reading page 'en/api/transformers/models/roc_bert.md':  ERROR     Could not collect  'mindnlp.transformers.models.poolformer.configuration_roc_bert' mindnlp.transformers.models.poolformer.configuration_roc_bert 在相对应的目录下没有文件。 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;",mkdocs.yml已修改，所有新添加的models的markdown文件已添加。 docstring 修订进度：目前已修订到 models/ernie,最新的PR已提交，transformers中所有位置的docstring均已按规范修改，且对mkdocs生成的所有文档进行了多次校对，确认所有文档均整洁统一。
这是一个用户提出需求的issue，主要对象是transformers测试文档。由于缺乏详细文档，用户需要进一步了解如何测试transformers功能。,docs for transformers test,test test test,2024-06-09T03:19:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1262
这是一个需求类型的issue，主要涉及测试文档transformers，用户可能在使用过程中遇到了一些需求相关的问题。,test docs transformers,,2024-06-08T17:27:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1261
这个issue类型是需求类型，主要涉及的对象是测试文档中的transformers部分。,test docs transformers,,2024-06-08T16:59:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1260
这是一个用户需求类型的issue，涉及到MindNLP下的transformers文档，用户提出了一个地址任务和提交请求的需求。,docs for transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN !pr,2024-06-08T15:32:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1259
这是一个用户提出需求的issue，主要涉及的对象是名称为Data2VecText的功能模块。,【社区实习】Data2VecText,,2024-06-08T11:41:59Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1258,/model data2vec,!image https://github.com/mindsporelab/mindnlp/actions/runs/9428472438/job/25973827304,峰哥，通过的话，顺道down一下 https://gitee.com/mindspore/community/issues/I9UTY7note_28269082
这是一个用户提出需求的issue，主要涉及的对象是昇腾AI创新大赛的gptj，具体内容为本地通过。,【昇腾AI创新大赛】gptj, 本地通过,2024-06-08T10:27:16Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1257,/model gptj,/model gptj,/model gptj,https://github.com/mindsporelab/mindnlp/actions/runs/9428223109 Single model test通过,测试通过，本赛题完成
这是一个bug报告，主要涉及到两个模型mask2former和oneformer，问题表现为测试用例test_initialization无法通过。,【昇腾AI创新大赛】mask2former & oneformer,mask2former 和 oneformer 都依赖 swin，就合在一起交吧 两个模型均有一个测试用例 `test_initialization` 过不了，暂时 skip 了，只能保证翻译是对标 hf 代码的 不能通过的 **主要原因** 是：在 `_init_weights` 中会对模型进行随机参数初始化，但某些特定参数不会显示地指定初始化方式，于是会 fallback 到 mindspore 的默认参数初始化方式，而其对应在 pytorch 中的默认初始化方式不同。 现已查明主要受影响的是一系列 Dense 层的 bias 参数初始化与 hf 中不同。,2024-06-08T09:35:49Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1256,/model mask2former,/model oneformer,> /model mask2former single model test 已通过：https://github.com/mindsporelab/mindnlp/actions/runs/9429251320 > /model oneformer single model test 已通过：https://github.com/mindsporelab/mindnlp/actions/runs/9429251795,测试通过，本赛题完成
这个issue是用户提出需求类型的问题，涉及的主要对象是MindNLP中的transformers文档，用户想要获取关于transformers的文档内容。,docs for transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN,2024-06-08T07:56:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1255
"这是一个用户提出需求类型的空content issue，主要涉及的对象是""videomae""。",【昇腾AI创新大赛】videomae,,2024-06-08T07:53:40Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1254,/model videomae,/model videomae,https://github.com/mindsporelab/mindnlp/actions/runs/9427343122/job/25971352584,测试通过，本赛题完成
这个issue类型为bug报告，主要对象为visual_bert auto模块。产生bug的原因可能是代码中的错误导致了visual_bert auto模块的功能异常。,fix visual_bert auto bug,,2024-06-08T07:30:12Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1253,/model visual_bert
这个issue类型为用户提出需求，主要涉及对象是文档中的transformers部分。由于缺少文档或指导，用户提出了需要补充transformers部分的文档的需求或建议。,docs for transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN,2024-06-08T07:27:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1252
"这是一个与""昇腾AI创新大赛""相关的问题，类型是用户提出需求或寻求帮助。",【昇腾AI创新大赛】led,,2024-06-08T07:06:30Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1251,/model led,CI: https://github.com/mindsporelab/mindnlp/actions/runs/9427015877,!capture_20240608145853193 tests/ut/transformers/models/led/test_modeling_led.py::LEDModelIntegrationTests::test_seq_to_seq_generation需要内存过大，本地pass,测试通过，本赛题完成
这是一个社区实习相关的issue，主要对象是mobilenet_v1模型。原因可能是需要对mobilenet_v1模型进行实习调研，学习并提供相关反馈。,【社区实习】mobilenet_v1(#I9UXB7),,2024-06-08T06:32:37Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1250,/model mobilenet_v1
这是一个社区招募实习生的类型。主要对象是Mobilenet_v1。,【社区实习】mobilenet_v1(#I9UXB7),,2024-06-08T06:20:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1249
这是一个缺少内容的issue，类型为信息不完整，无法确定具体问题所属对象。,【昇腾AI创新大赛】flava,,2024-06-08T05:43:47Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1248,/model flava,/model flava,/model flava,https://github.com/mindsporelab/mindnlp/actions/runs/9426752156/job/25970055414,/model flava,https://github.com/mindsporelab/mindnlp/actions/runs/9426908470/job/25970390975,测试通过，本赛题完成
这个issue是一个用户提出需求的类型，主要对象是文档的更新。由于文档缺失或不清晰，用户希望添加关于transformers测试的相关内容。,docs for transformers test1,,2024-06-08T05:32:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1247
该issue类型为代码回滚，涉及主要对象为mindnlp中的wavlm模型。原因可能是对wavlm模型进行了一些不符合预期的修改或者更新，需要进行回滚操作。,"Revert ""【昇腾AI创新大赛】wavlm""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】wavlm),2024-06-08T04:28:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1246
这个issue是关于bug报告，主要涉及的对象是代码中的一个操作符。可能是由于函数名错误导致的bug或者用户需要修复一个特定函数的问题。,fix ops.empty to ms.numpy.empty,,2024-06-08T03:50:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1245
这是一个空白的issue，类型为用户提出需求或其他类型，主要涉及对象为昇腾AI创新大赛中的seggpt项目。,【昇腾AI创新大赛】seggpt,,2024-06-08T03:24:08Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1244,/model seggpt,/model seggpt,ci链接：https://github.com/mindsporelab/mindnlp/actions/runs/9425996184/job/25968368011 ut问题说明： 1.首先该模型的test_few_shot_inference 精度测试用例，在线上ci一跑到这里就会挂掉，我本地是正常测试通过的 2.skip的三个精度测试ut是test_one_shot_with_label，test_seggpt_loss和test_one_shot_inference 前两个分别用到了torch.randperm和torch.rand 来生成测试数据，mindspore中没法直接生成一模一样的测试数据，只能在本地直接读取由torch.randperm和torch.rand生成好的数据文件来测试，test_one_shot_inference目前测下来精度的误差是2e4，无法通过用例里的1e4的误差 !image 误差数据打印 !a4628557325fe05d5081314ff25490ca
这是一个缺少具体内容的问题报告，涉及主要对象为MindNLP下的transformers测试文档。由于内容缺失，用户未提供导致bug或问题的具体信息。,docs for transformers test,,2024-06-08T02:42:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1243
这是一个用户提出需求的类型的issue，主要涉及文档的缺失。由于文档的内容为空，用户希望得到有关transformers的相关信息。,docs for transformers,test,2024-06-08T02:20:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1242
这个issue类型为用户提出需求，涉及主要对象为transformers文档，用户提出问题或寻求帮助，由于缺少transformers文档而导致。,docs for transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN,2024-06-08T01:36:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1241
"这是一个用户提出需求的类型，主要涉及的对象是""flava""。由于未提供具体内容，无法分析导致症状的原因。",【昇腾AI创新大赛】flava,,2024-06-08T01:15:11Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1240,/model flava
这是一个用户提出需求的类型，主要涉及MindNLP中的文档内容，由于缺乏transformers相关文档，用户提出了更新的请求。,docs for transformers,任务地址 https://gitee.com/mindspore/community/issues/I9GVLN !pr,2024-06-07T20:27:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1239
这是一个用户提出需求类型的issue，主要涉及到mindnlp中的transformers的文档问题。原因可能是用户希望添加或改善transformers的文档内容。,docs for transformers,任务地址 https://gitee.com/mindspore/community/issues/I9GVLN !pr,2024-06-07T19:38:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1238
这个issue是一个需求报告，主要涉及mindnlp下的transformers文档，用户提出希望添加文档的需求。,docs for transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN !pr,2024-06-07T19:25:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1237
这个issue类型是用户提出需求，涉及的主要对象是DETR模型。由于昇腾AI创新大赛，用户可能在提出关于DETR模型的问题或寻求相关帮助。,【昇腾AI创新大赛】DETR,,2024-06-07T17:05:04Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1236,/model detr,single model test 已通过：https://github.com/mindsporelab/mindnlp/actions/runs/9430357109,该PR已转向 https://github.com/mindsporelab/mindnlp/pull/1272 是同一份代码，队友暂时不在，我来帮忙改最后的小bug，望老师知情 Orz
这个issue类型属于用户提出需求，主要涉及到 transformers 的文档。由于缺乏文档，用户可能需要了解有关 transformers 的相关信息。,docs for transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN !pr,2024-06-07T16:04:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1235
"这是一个用户提出需求的issue， 主要涉及的对象是昇腾AI创新大赛。用户可能因为想了解""wav2vec2bert""相关信息或者想咨询有关该主题的内容。",【昇腾AI创新大赛】wav2vec2_bert,!wav2vec2bert,2024-06-07T15:49:23Z,,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1234,/model wav2vec2_bert,/model wav2vec2_bert,/model wav2vec2_bert,single model test 已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9420169023,/model wav2vec2_bert,/model wav2vec2_bert,single model test 已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9426599258,测试通过，本赛题完成
这是一个关于更新模型以及提交 Pull Request 的类型。该问题涉及到MindNLP 模型库中的 Segformer 模型。原因可能是赛题要求使用的 Segformer 模型与 MindNLP 当前版本中的有所不同，用户试图尝试更新并提交修复。, segformer,模型库中已有segformer，但赛题中仍具有此模型，查看了hf对segformer的更新，同步修改了下，虽不知是否还有效，但也申请pr试试，已通过本地pylint+run_slow !image,2024-06-07T13:52:27Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1233,/model segformer
这是一个空白的Issue，无法确定其类型和内容。,【昇腾AI创新大赛】wavlm,,2024-06-07T13:33:01Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1232,/model wavlm,/model wavlm,/model wavlm,/model wavlm,/model wavlm,/model wavlm,/model wavlm
这是一个bug报告，主要涉及的对象是mindnlp下的wavlm模型。由于无法通过本地run_slow，用户可能遇到了无法正常运行该模型的问题。,【昇腾AI创新大赛】wavlm,通过本地run_slow,2024-06-07T12:20:50Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1231,/model wavlm,本地 !image,/model wavlm,single model test： https://github.com/mindsporelab/mindnlp/actions/runs/9416971540 !image large测试点在本地可以正常通过：https://github.com/mindsporelab/mindnlp/pull/1231issuecomment2154724457   麻烦查看下是否可以合并,经判定本PR时间非最早，本赛题无效
这是一个用户提出需求的issue，主要对象是昇腾AI创新大赛中的wavlm模型。由于缺少具体内容，用户可能是想咨询关于该模型的使用方法或者反馈使用过程中的问题。,【昇腾AI创新大赛】wavlm,,2024-06-07T11:36:51Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1230,/model wavlm,本地ut通过  actions中test_large时卡住但无报错信息,> 本地ut通过  actions中test_large时卡住但无报错信息 https://github.com/mindsporelab/mindnlp/actions/runs/9416375466,/model wavlm,经判定本PR时间更早，本赛题完成
这是一个用户提出需求的issue，主要对象是向mindnlp这个项目添加GPTJ模型。可能由于用户希望使用GPTJ模型的功能或者增强项目的整体功能性而提出此需求。,add gptj,,2024-06-07T09:07:39Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1229,/model gptj
这个issue类型是改进文档，主要涉及到Transformer库中的文档注释。原因可能是要提高代码可读性或者准确性。,Has revised all of the docstrings in transformers,任务地址： https://gitee.com/mindspore/community/issues/I9GVLN !pr,2024-06-07T09:03:24Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1228,当前的PR和master有conflicts，需要rebase一下吗,Pylint好像过不了，可以在本地进行pylintcheck检查吗,是我手动解决冲突的时候改出问题了，我修改下,> Pylint好像过不了，可以在本地进行pylintcheck检查吗 可以的，跑这个脚本即可scripts/pylint_check.sh,"好的谢谢！ 我原来的仓有点问题，重新fork了一下提了新PR，麻烦转到这里Review： https://github.com/mindsporelab/mindnlp/pull/1235 梦想 ***@***.*** &nbsp; &nbsp;原始邮件&nbsp; 发件人:                                                                                                                        ""mindsporelab/mindnlp""                                                                                    ***@***.***&gt;; 发送时间:&nbsp;2024年6月7日(星期五) 晚上11:37 ***@***.***&gt;; ***@***.***&gt;;""State ***@***.***&gt;; 主题:&nbsp;Re: [mindsporelab/mindnlp] Has revised all of the docstrings in transformers (PR CC(Has revised all of the docstrings in transformers)) Pylint好像过不了，可以在本地进行pylintcheck检查吗 可以的，跑这个脚本即可scripts/pylint_check.sh — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you modified the open/close state.Message ID: ***@***.***&gt;"
这是一个用户提出需求类的issue，主要涉及的对象是昇腾AI创新大赛中的gptj模型。,【昇腾AI创新大赛】gptj,,2024-06-07T08:28:44Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1227,!3a7ec014f5d82b07606bea4a3bbf46c Single model test Passed。
这个issue属于用户提出需求类型，主要涉及昇腾AI创新大赛中LED相关问题。,【昇腾AI创新大赛】LED,,2024-06-07T08:18:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1226
"该问题是一个需求类型的issue，主要涉及的对象是""昇腾AI创新大赛""。",【昇腾AI创新大赛】Tapas,,2024-06-07T08:07:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1225
这是一个缺乏内容的issue，类型为用户提出需求，并涉及到昇腾AI创新大赛的相关主题。,【昇腾AI创新大赛】nat,,2024-06-07T08:04:21Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1224,/model nat
这个issue类型是bug报告，主要涉及FastSpeech2ConformerModelIntegrationTest中的随机性问题，可能由于随机性导致训练集成测试出现问题。,【昇腾AI创新大赛】fastspeech2_conformer,暂时忽略 FastSpeech2ConformerModelIntegrationTest::test_training_integration 随机性问题 !fastspeech_conformer,2024-06-07T07:51:44Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1223,/model fastspeech2_conformer,/model fastspeech2_conformer,single model test 已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9426645560,测试通过，本赛题完成
"这是一个用户提出需求的issue，主要涉及的对象是""昇腾AI创新大赛""，用户可能提出关于Tapas项目的相关问题或寻求相关帮助。",【昇腾AI创新大赛】Tapas,,2024-06-07T07:38:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1222
"这是一个bug报告，涉及的主要对象是""canine""。由于run_slow本地化时出现了问题，导致无法通过!image命令运行。",【昇腾AI创新大赛】canine,本地run_slow通过 !image,2024-06-07T06:53:02Z,,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1221,/model canine,/model canine,/model canine,本地 !image,  Single model test 已通过： https://github.com/mindsporelab/mindnlp/actions/runs/9413253085,/model canine,  https://github.com/mindsporelab/mindnlp/actions/runs/9415568368,测试通过，本赛题完成
这是一个bug报告，涉及主要对象为decision_transformer。原因可能是由于未添加自动注册功能导致的bug。,fix bug for decision_transformer,添加了auto注册,2024-06-07T05:03:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1220
这是一个bug报告类型的issue，涉及的主要对象是`deberta_v2`模型。由于未添加auto注册功能，导致出现了bug需要修复。,fix bug for deberta_v2,添加了auto注册,2024-06-07T04:56:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1219
这是一个缺少具体内容的问题报告issue，类型为bug报告，主要涉及的对象是MindNLP的nat模块。,【昇腾AI创新大赛】nat,,2024-06-07T04:08:09Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1218,/model nat
这是一则缺少内容的issue，类型为用户提出需求，涉及的主要对象是mindnlp中的sew and sew_d模型初始化。,sew and sew_d modell init,,2024-06-07T03:49:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1217
该问题为用户提出需求类型的issue，主要对象是关于昇腾AI创新大赛中的一个项目Tapas。,【昇腾AI创新大赛】Tapas,,2024-06-07T03:12:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1216
这是一个Bug报告，主要涉及MindNLP测试失败的问题，由于RuntimeError导致输出错误文档。,测试失败，提示runtimeerror，详细错误在文档里面,!image !image !image !image !image !image !image output1.txt,2024-06-07T02:30:52Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1215,非mindnlp问题
这个issue类型是用户提出需求，针对的主要对象是昇腾AI创新大赛的marian模型。,【昇腾AI创新大赛】marian,,2024-06-06T21:48:20Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1214,/model marian,/model marian,/model marian,https://github.com/mindsporelab/mindnlp/actions/runs/9411710168/job/25925426787,测试通过，本赛题完成
"这是一个用户提出需求的 issue，主要涉及的对象是""昇腾AI创新大赛]marian""项目。由于缺少具体内容，用户可能提出了关于项目在比赛中遇到的问题或寻求相关帮助的请求。",【昇腾AI创新大赛】marian,,2024-06-06T21:29:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1213
这是一个用户提出需求的类型的issue，主要涉及的对象是昇腾AI创新大赛的wav2vec2_conformer模型。由于用户想要参与AI创新大赛，需要相关模型的支持。,【昇腾AI创新大赛】wav2vec2_conformer,,2024-06-06T18:54:58Z,,closed,0,10,https://github.com/mindspore-lab/mindnlp/issues/1212,/model wav2vec2_conformer,/model wav2vec2_conformer,/model wav2vec2_conformer,/model wav2vec2_conformer,!Screenshot_20240607_064209 似乎是内存不够用了,/model wav2vec2_conformer,https://github.com/mindsporelab/mindnlp/actions/runs/9408898066,> !Screenshot_20240607_064209 似乎是内存不够用了 本地截图回复,!Screenshot_20240607_200630 测试已过，auto已更新,测试通过，本赛题完成
"这是一个其它类型的issue，主要对象是""昇腾AI创新大赛""。",【昇腾AI创新大赛】 videomae,,2024-06-06T16:49:18Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1211,/model videomae,https://github.com/mindsporelab/mindnlp/actions/runs/9404786610,/model videomae
"这是一个bug报告，涉及对象为名为""rocbert""的项目。原因可能是代码错误或功能异常导致了bug，用户因此提出了修复请求。",fix bug for rocbert,!Snipaste_20240607_003725 !Snipaste_20240607_003731 真的不好意思。。。,2024-06-06T16:46:47Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1210,/model roc_bert,https://github.com/mindsporelab/mindnlp/actions/runs/9404855546/job/25904711623
这是一个用户提出需求的issue，主要对象是昇腾AI创新大赛的git相关问题。,【昇腾AI创新大赛】git,,2024-06-06T16:40:21Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1209,/model git,"!image 本地run_slow  仅有两个RuntimeError: The memcpy_s error, errorno(34) 怀疑是内存问题 写于 20240607 01:03",/model git   本地run_slow  全部通过 !image,/model git,  single model test 已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9410915449,测试通过，本赛题完成
这是一个空白的issue，类型为用户提出需求，主要对象是昇腾AI创新大赛。,【昇腾AI创新大赛】 xlm-roberta-xl,,2024-06-06T16:21:42Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1208,/model xlm_roberta_xl,/model xlm_roberta_xl,https://github.com/mindsporelab/mindnlp/actions/runs/9404580357/job/25903797145,精度对齐UT截图,!image,!image,测试通过，本赛题完成
这是一个bug报告，主要涉及的对象是修复gpt_neox_japanese的问题，可能是由于多余的不需要测试模块导致的bug。,fix bug for gpt_neox_japanese,!Snipaste_20240607_001910 !Snipaste_20240607_001915 这次和squeeze不同，是多了不需要测试的冗余的模块。,2024-06-06T16:21:06Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1207,/model gpt_neox_japanese,https://github.com/mindsporelab/mindnlp/actions/runs/9404696962
"这是一个bug报告，主要涉及""SqueezeBERT""，由于注册过程不完整导致问题。",fix bug for squeezebert,!Snipaste_20240606_234908 !Snipaste_20240606_234914 不好意思，第一次注册auto不彻底。。故补上该结果。,2024-06-06T16:06:06Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1206,/model squeezebert ,https://github.com/mindsporelab/mindnlp/actions/runs/9404213074/job/25902604023
这是一个bug报告类型的issue，涉及的主要对象是git工具。由于未填写具体内容，导致用户提交了一个空的issue。,git,,2024-06-06T15:50:56Z,,closed,0,13,https://github.com/mindspore-lab/mindnlp/issues/1205,/model git,/model git,/model git,/model git,/model git,/model git,/model git,/model git,/model git,/model git,/model git,/model git,此题目已有人完成，关闭PR
这个issue类型为功能需求，主要涉及对象是 GPT_NeoX 样本代码，用户希望基于 LoRa 进行指令微调。,Updated GPT_NeoX sample code for instruction fine-tuning based on LoRa.,Updated GPT_NeoX sample code for instruction finetuning based on LoRa.,2024-06-06T15:44:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1204
这是一个空白的issue，类型为用户提出需求。主要涉及对象是昇腾AI创新大赛。,【昇腾AI创新大赛】nat,,2024-06-06T15:02:48Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1203,/model NAT
这是一个用户提出需求的类型，主要涉及的对象是昇腾AI创新大赛的wav2vec2_conformer模型。,【昇腾AI创新大赛】wav2vec2_conformer,,2024-06-06T13:44:26Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1202,/model wav2vec2_conformer
"这是一个用户提出需求的类型，主要涉及的对象是""昇腾AI创新大赛""。由于用户希望利用""xlm-roberta-xl""来参与比赛，但具体内容并未给出，可能需要相关支持或反馈。",【昇腾AI创新大赛】 xlm-roberta-xl ,,2024-06-06T12:55:34Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1201,/model xlm_roberta_xl,https://github.com/mindsporelab/mindnlp/actions/runs/9401267544
这是一个用户提出需求的issue，主要涉及的对象是昇腾AI创新大赛的wav2vec2_conformer，该需求可能是用户寻求相关帮助或提出bug问题。,【昇腾AI创新大赛】wav2vec2_conformer,,2024-06-06T12:32:11Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1200,/model  wav2vec2conformer
这是一个用户提出需求的issue，主要对象是添加一个名为PEFT的教程。,Add tutorial PEFT,,2024-06-06T12:28:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1199
"这是一个用户提出需求的类型的issue，主要涉及对象为""vision_encoder_decoder""，用户寻求关于参与昇腾AI创新大赛的帮助。",【昇腾AI创新大赛】vision_encoder_decoder,,2024-06-06T12:22:38Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1198,/model vision_encoder_decoder,/model vision_encoder_decoder,/model vision_encoder_decoder,https://github.com/mindsporelab/mindnlp/actions/runs/9411849482,没有看到任何精度测试，不通过
这是一个用户提出需求的类型，主要涉及到昇腾AI创新大赛和xlm-roberta-xl。由于用户希望参与昇腾AI创新大赛，可能在使用xlm-roberta-xl时遇到了问题或需要相关支持。,【昇腾AI创新大赛】 xlm-roberta-xl,,2024-06-06T11:42:48Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1197,/model xlm_roberta_xl
这个issue类型是代码回退，涉及的主要对象是mindnlp下的【昇腾AI创新大赛】xlm_roberta_xl，原因可能是代码实现或效果不符合期望。,"Revert ""【昇腾AI创新大赛】xlm_roberta_xl""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】xlm_roberta_xl),2024-06-06T10:58:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1196
这个issue属于用户提出需求类型，主要涉及的对象是在昇腾AI创新大赛中添加犬类模型。,【昇腾AI创新大赛】 add canine model,,2024-06-06T10:48:53Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1195,/model canine
这个issue是关于bug报告，主要涉及的对象是openelm功能。原因可能是openelm功能存在错误导致特定症状的bug。,fix openelm,,2024-06-06T10:37:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1194
这个issue类型是用户提出需求，该问题单涉及的主要对象是昇腾AI创新大赛中的videomae项目。由于没有具体内容，用户可能提出了关于该项目的问题或寻求相关帮助。,【昇腾AI创新大赛】 videomae,,2024-06-06T09:35:54Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1193,/model videomae,\model videomae,\model videomae,\model videomae,\model videomae,"我的“test_inference_for_pretraining”测试中出现了这个情况：在使用float16时，outputs.logits不通过1e3的精度测试，而outputs.loss可以通过1e3的精度测试；而使用float32时，outputs.logits可以通过1e3的精度测试，而outputs.loss可以不通过1e3的精度测试。 下面结果是使用float16时对应的outputs.logits[0, :3, :3]以及expected_slice outputs.logits[0, :3, :3]： [[0.8003 0.962  0.852 ]  [0.7437 0.8984 0.833 ]  [0.5903 0.75   0.7354]]  expected_slice： [[0.7994 0.9612 0.8508]  [0.7401 0.8958 0.8302]  [0.5862 0.7468 0.7325]]  若使用1e2对outputs.logits[0, :3, :3]、expected_slice进行精度测试则可以通过"
这是一个bug报告类型的issue，主要涉及Bloom相关接口无法导入的问题。原因可能是接口调用方式错误或者库文件缺失。,Bloom相关接口无法导入,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 参考：https://github.com/mindsporelab/mindnlp/issues/554 ```py from mindspore import ops from mindnlp.transformers import BloomTokenizerFast, BloomForCausalLM from mindnlp.engine import TrainingArguments, Trainer from mindnlp.dataset import load_dataset, BaseMapFuction from dataclasses import dataclass, field from typing import Optional ``` 报错 ```  ImportError                               Traceback (most recent call last) Cell In[4], line 5       3 from mindnlp.transformers import BloomTokenizerFast, BloomForCausalLM       4 from mindnlp.engine import TrainingArguments, Trainer > 5 from mindnlp.dataset import load_dataset, BaseMapFuction       8 from dataclasses import dataclass, field       9 from typing import Optional ImportError: cannot import name 'BaseMapFuction' from 'mindnlp.dataset' (/home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/dataset/__init__.py) ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14 gpu mindnlp从github源码安装  Python version (e.g., Python 3.7.5) : 3.9",2024-06-06T09:13:57Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1192,BaseMapFuction > BaseMapFunction
这是一个bug报告，用户在OpenELMForCausalLM推理过程中遇到了代码报错。,OpenELMForCausalLM推理报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** ```py from mindnlp.transformers import AutoTokenizer from mindnlp.transformers import OpenELMForCausalLM model = OpenELMForCausalLM.from_pretrained(""Apple/OpenELM270MInstruct"")trust_remote_code=True  tokenizer = AutoTokenizer.from_pretrained(""Apple/OpenELM270MInstruct"")Llama27bhf tokenizer = AutoTokenizer.from_pretrained(""NousResearch/Llama27bchathf"") prompt = '\nDataWhalechina is an organization founded at Shanghai Jiao Tong University that helps learners learn artificial intelligence.' inputs = tokenizer(prompt, return_tensors=""ms"")  Generate generate_ids = model.generate(inputs.input_ids, max_length=300) tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] ``` 代码报错： ``` /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html   from .autonotebook import tqdm as notebook_tqdm Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.785 seconds. Prefix dict has been built successfully. MindSpore do not support bfloat16 dtype, we will automaticlly convert to float16 /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py:1561: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://hfmirror.com/docs/transformers/generation_strategiesdefaulttextgenerationconfiguration )   warnings.warn( The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results. Setting `pad_token_id` to `eos_token_id`:2 for openend generation.  TypeError                                 Traceback (most recent call last) Cell In[3], line 11       8 inputs = tokenizer(prompt, return_tensors=""ms"")      10  Generate > 11 generate_ids = model.generate(inputs.input_ids, max_length=300)      12 tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0] File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/utils/generic.py:543, in no_grad..wrapper(*args, **kwargs)     541 def wrapper(*args, **kwargs):     542     _pynative_executor.set_enable_grad(False) > 543     outputs = func(*args, **kwargs)     544     _pynative_executor.set_enable_grad(True)     545     return outputs File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py:1770, in GenerationMixin.generate(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)    1753     return self.assisted_decoding(    1754         input_ids,    1755         assistant_model=assistant_model,    (...)    1766         **model_kwargs,    1767     )    1768 if generation_mode == GenerationMode.GREEDY_SEARCH:    1769      11. run greedy search > 1770     return self.greedy_search(    1771         input_ids,    1772         logits_processor=logits_processor,    1773         stopping_criteria=stopping_criteria,    1774         pad_token_id=generation_config.pad_token_id,    1775         eos_token_id=generation_config.eos_token_id,    1776         output_scores=generation_config.output_scores,    1777         return_dict_in_generate=generation_config.return_dict_in_generate,    1778         synced_gpus=synced_gpus,    1779         streamer=streamer,    1780         **model_kwargs,    1781     )    1783 elif generation_mode == GenerationMode.CONTRASTIVE_SEARCH:    1784     if not model_kwargs[""use_cache""]: File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/generation/utils.py:2591, in GenerationMixin.greedy_search(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)    2589 model_inputs = self.prepare_inputs_for_generation(input_ids, **model_kwargs)    2590  forward pass to get next token > 2591 outputs = self(    2592     **model_inputs,    2593     return_dict=True,    2594     output_attentions=output_attentions,    2595     output_hidden_states=output_hidden_states,    2596 )    2598 if synced_gpus and this_peer_finished:    2599     continue   don't waste resources running the code we don't need File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/openelm/modeling_openelm.py:1256, in OpenELMForCausalLM.construct(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)    1252 return_dict = (    1253     return_dict if return_dict is not None else self.config.use_return_dict    1254 )    1255  decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn) > 1256 outputs = self.transformer(    1257     input_ids=input_ids,    1258     attention_mask=attention_mask,    1259     position_ids=position_ids,    1260     past_key_values=past_key_values,    1261     inputs_embeds=inputs_embeds,    1262     use_cache=use_cache,    1263     output_attentions=output_attentions,    1264     output_hidden_states=output_hidden_states,    1265     return_dict=return_dict,    1266     cache_position=cache_position,    1267 )    1269 hidden_states = outputs[0]    1270 if self.lm_head is None:    1271      shared File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/openelm/modeling_openelm.py:964, in OpenELMModel.construct(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)     953     layer_outputs = self._gradient_checkpointing_func(     954         decoder_layer.__call__,     955         hidden_states,    (...)     961         cache_position,     962     )     963 else: > 964     layer_outputs = decoder_layer(     965         hidden_states,     966         attention_mask=causal_mask,     967         position_ids=position_ids,     968         past_key_value=past_key_values,     969         output_attentions=output_attentions,     970         use_cache=use_cache,     971         cache_position=cache_position,     972     )     974 hidden_states = layer_outputs[0]     976 if use_cache: File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/openelm/modeling_openelm.py:723, in OpenELMDecoderLayer.construct(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)     720 hidden_states = self.attn_norm(hidden_states)     722  Self Attention > 723 hidden_states, self_attn_weights, present_key_value = self.attn(     724     hidden_states=hidden_states,     725     attention_mask=attention_mask,     726     past_key_value=past_key_value,     727     output_attentions=output_attentions,     728     use_cache=use_cache,     729     cache_position=cache_position,     730     **kwargs,     731 )     732 hidden_states = residual + hidden_states     734  Fully Connected File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindnlp/transformers/models/openelm/modeling_openelm.py:512, in OpenELMMultiHeadCausalAttention.construct(self, hidden_states, attention_mask, past_key_value, output_attentions, use_cache, cache_position)     509 if attention_mask is not None and cache_position is not None:     510     causal_mask = causal_mask[:, :, cache_position, : keys.shape[2]] > 512 attn_output, _ = _scaled_dot_product_attention(     513     queries,     514     keys,     515     values,     516     attn_mask=causal_mask,     517     dropout_p=0,     518     is_causal=False,     519     is_training=self.training,     520     dtype=queries.dtype     521 )     523 attn_output = attn_output.swapaxes(1, 2)     524 attn_output = attn_output.reshape(     525     batch_size, seq_length, self.num_q_heads * self.head_dim     526 ) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/function/nn_func.py:7115, in _scaled_dot_product_attention(query, key, value, attn_mask, dropout_p, is_causal, is_training, dtype)    7113     attn = attn + attn_mask    7114 attn = ops.softmax(attn, 1) > 7115 attn = _inner_dropout(attn, dropout_p, is_training)    7116 output = ops.matmul(attn, value)    7118 return (output, attn) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/function/nn_func.py:7045, in _inner_dropout(x, p, training)    7043 def _inner_dropout(x, p, training):    7044     """"""inner dropout"""""" > 7045     _dropout = _get_cache_prim(P.Dropout)(1  p)    7046     if 0. ._get_cache_prim_for_pynative(*args, **kwargs)      82     prim = Primitive.__new__(cls, *args, **kwargs)      83      Only init once. > 84     prim.__init__(*args, **kwargs)      85     _PRIM_CACHE[key] = prim      86 return _PRIM_CACHE.get(key) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/primitive.py:734, in prim_attr_register..deco(self, *args, **kwargs)     732     self.add_prim_attr(name, value)     733     self.init_attrs[name] = value > 734 fn(self, *args, **kwargs) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/ops/operations/nn_ops.py:7186, in Dropout.__init__(self, keep_prob, Seed0, Seed1)    7184 self.seed0 = validator.check_value_type(""Seed0"", Seed0, [int], self.name)    7185 self.seed1 = validator.check_value_type(""Seed1"", Seed1, [int], self.name) > 7186 self.keep_prob = validator.check_float_range(keep_prob, 0, 1, validator.INC_RIGHT, ""keep_prob"", self.name)    7187 self.add_prim_attr(""side_effect_hidden"", True) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/_checkparam.py:532, in check_float_range(arg_value, lower_limit, upper_limit, rel, arg_name, prim_name)     524 def check_float_range(arg_value, lower_limit, upper_limit, rel, arg_name=None, prim_name=None):     525     """"""     526     Method for checking whether input value is in float range.     527     (...)     530      number = check_float_range(number, 0.0, 1.0, INC_NEITHER, ""number"")  number in [0.0, 1.0]     531     """""" > 532     return check_number_range(arg_value, lower_limit, upper_limit, rel, float, arg_name, prim_name) File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/_checkparam.py:267, in check_number_range(arg_value, lower_limit, upper_limit, rel, value_type, arg_name, prim_name)     264         rel_str = _format_str_two_value(lower_limit, upper_limit, rel)     265         raise ValueError(f""{prim_name} {arg_name} must be in range of {rel_str}, "" \     266                          f""but got {arg_value} with type '{type(arg_value).__name__}'."") > 267 _check_param()     268 return arg_value File /home/data/ckw/micromamba/envs/mindnlp/lib/python3.9/sitepackages/mindspore/_checkparam.py:260, in check_number_range.._check_param()     258 type_mismatch = not isinstance(arg_value, (np.ndarray, np.generic, value_type)) or isinstance(arg_value, bool)     259 if type_mismatch: > 260     raise TypeError(f""{prim_name} {arg_name} must be '{value_type.__name__}',  "" \     261                     f""but got '{type(arg_value).__name__}'."")     263 if not _check_inc_rel(arg_value, lower_limit, upper_limit, rel):     264     rel_str = _format_str_two_value(lower_limit, upper_limit, rel) TypeError: For 'Dropout', the 'keep_prob' must be 'float',  but got 'int'. ```  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.14 gpu（已经测试，mindspore的gpu版本正常安装）  Python version (e.g., Python 3.7.5) :3.9",2024-06-06T08:52:40Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1191,是nn.Dropout调用出错了，我改一下
这是一则用户提出需求的issue，主要涉及的对象是mindnlp下的switch_transformers模型，其原因可能是用户希望在昇腾AI创新大赛中使用这个模型。,【昇腾AI创新大赛】switch_transformers,,2024-06-06T07:50:53Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1190,/model switch_transformers,/model switch_transformers,"!image SwitchTransformerModelIntegrationTests::test_small_generate Except: man beer a whiskey. Output: man beer a whiskey. Reason: Unless we stop stripping left and right by default for all special tokens, the expected ids obtained here will not match the original ones. Wait for https://github.com/huggingface/transformers/pull/23909 to be merged",/model switch_transformers, 请问可以合并了么 Single model test  因为那个bfloat16的问题  时正确时错误  hf :https://github.com/mindsporelab/mindnlp/pull/1190issuecomment2151644356 https://github.com/mindsporelab/mindnlp/actions/runs/9397570629,测试通过，本赛题完成
这个issue是关于需求的，主要涉及 Speech encoder decoder。用户提出了关于昇腾AI创新大赛的问题。,【昇腾AI创新大赛】Speech encoder decoder,,2024-06-06T06:49:28Z,,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1189,\model speech_encoder_decoder,\model speech_encoder_decoder,\model speech_encoder_decoder,\model speech_encoder_decoder,/model speech_encoder_decoder,/model speech_encoder_decoder,https://github.com/mindsporelab/mindnlp/actions/runs/9398299336  single model test过了,测试通过，本赛题完成
这是一个撤销提交的类型。主要对象是mindnlp下的一个提交（【昇腾AI创新大赛】switch_transformers）导致的问题或需求。,"Revert ""【昇腾AI创新大赛】switch_transformers""",Reverts mindsporelab/mindnlp CC(【昇腾AI创新大赛】switch_transformers),2024-06-06T06:40:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1188
这个issue类型是用户提出需求，主要对象是昇腾AI创新大赛的time_series_transformer项目。,【昇腾AI创新大赛】time_series_transformer,,2024-06-06T06:07:48Z,,closed,0,9,https://github.com/mindspore-lab/mindnlp/issues/1187,/model time_series_transformer,/model time_series_transformer,/model time_series_transformer,/model time_series_transformer,https://github.com/mindsporelab/mindnlp/actions/runs/9400341632  通过single model test,/model time_series_transformer,/model time_series_transformer,https://github.com/mindsporelab/mindnlp/actions/runs/9446333761,测试通过，本赛题完成
"这是一个用户提出需求的issue，主要涉及的对象是昇腾AI创新大赛的项目""vision_text_dual_encoder""。",【昇腾AI创新大赛】vision_text_dual_encoder,,2024-06-06T05:00:03Z,,closed,0,12,https://github.com/mindspore-lab/mindnlp/issues/1186,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,/model vision_text_dual_encoder,  https://github.com/mindsporelab/mindnlp/actions/runs/9396268904,测试通过，本赛题完成
这是一个用户反馈通过门禁脚本测试所引起的issue，类型为验证测试结果。,【昇腾AI创新大赛】switch_transformers,本地已通过门禁脚本测试,2024-06-06T03:31:06Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1185,/model switch_transformers,/model switch_transformers,  CI测试已通过 https://github.com/mindsporelab/mindnlp/actions/runs/9394765197,本PR没有测试精度，未完成
"这是一个用户确认测试通过的issue，主要对象是""switch_transformers""模块。",【昇腾AI创新大赛】switch_transformers,已在本地通过门禁脚本测试,2024-06-06T03:06:09Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1184,/model switch_transformers
这个issue类型是bug报告，涉及的主要对象是swiftformer & autoformer模块。该问题可能是由于代码中的错误或不完善导致了bug，需要修复以解决相关问题。,fix swiftformer & autoformer,,2024-06-06T02:25:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1183
这是一个bug报告，涉及主要对象为Python 3.7版本。由于Python 3.7版本兼容性问题导致的错误。,fix python 3.7 error,,2024-06-06T02:22:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1182
这个issue类型为测试反馈、功能性确认，主要涉及对象为switch_transformers模型。可能是由于开发人员进行门禁测试后本地通过，但仍有问题导致用户在issue中进行反馈。,【昇腾AI创新大赛】switch_transformers,本地已通过门禁测试,2024-06-06T01:15:00Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1181,/model switch_transformers
这是一条用户提出需求的issue，主要对象是昇腾AI创新大赛的项目videomae。,【昇腾AI创新大赛】videomae,,2024-06-05T22:16:07Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1180,/model videomae,/model videomae,/model videomae,/model videomae,https://github.com/mindsporelab/mindnlp/actions/runs/9399514150/job/25887093565
这个issue属于误解类型，涉及对象为 Chinese-Clip 模型，导致原因可能是用户错误地将 Chinese-Clip 错认为是一个赛题。,chinese_clip-错认为是赛题了,,2024-06-05T20:32:57Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1179,!image 在本地通过了门禁测试,/model chinese_clip,有几个赛题对此有依赖，就不关闭pr了,已在switch_transformers赛题一起提交了，故关闭pr，如有需要分开录入，后续再开启。
这个issue类型是bug报告，主要对象是git。由于某些原因导致了未给出具体内容的bug报告。,git,,2024-06-05T17:00:45Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1178,/model git,/model git
该issue类型为上传文件问题，主要涉及文件添加的功能。由于用户上传文件的操作，导致了此问题的出现。,Add files via upload,,2024-06-05T16:36:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1177
这是一个上传文件类型的非常简短的issue，该问题单可能涉及到上传功能的bug报告。,Add files via upload,,2024-06-05T16:35:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1176
这是一个用户提出需求的issue，主要涉及到MindNLP中的模型cohere。,【昇腾AI创新大赛】Cohere,/model cohere,2024-06-05T15:24:46Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1175,/model cohere,本赛题已由其他人完成，PR关闭
这个issue属于用户提出需求类型，主要涉及Mobilenet_v1模型。由于社区实习的需要，用户可能正在寻求关于Mobilenet_v1的具体问题或帮助。,【社区实习】mobilenet_v1(#I9UXB7),,2024-06-05T13:21:59Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1174,/model mobilenet_v1,pylint没过
这是一个用户提出需求的类型，主要对象是EfficientFormer模型。,【昇腾AI创新大赛】EfficientFormer,,2024-06-05T13:08:44Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1173,/model efficientformer,测试通过，本赛题完成
"该issue类型为用户提出需求，主要对象是""昇腾AI创新大赛""，用户寻求关于""Cohere""方面的帮助。",【昇腾AI创新大赛】Cohere,,2024-06-05T12:38:24Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1172,/model cohere,测试通过，本赛题完成
该issue类型为功能需求，涉及的主要对象是添加昇腾AI控制模型，问题由于需要为昇腾AI创新大赛添加新的控制模型而提出。,【昇腾AI创新大赛】add ctrl model,,2024-06-05T09:47:40Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1171,本赛题已有其他人完成，PR关闭
"这是一个用户提出需求的issue，主要对象是""decision_transformer""模块。",【昇腾AI创新大赛】decision_transformerFmy mindnlp,,2024-06-05T09:21:03Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1170,/model decision_transformer,/model decision_transformer,本赛题已由其他人完成，关闭PR
这个issue类型是用户提出需求，该问题单涉及的主要对象是昇腾AI创新大赛的decision_transformer模块。,【昇腾AI创新大赛】decision_transformer,,2024-06-05T09:11:09Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1169,/model decision_transformer,/model decision_transformer,https://github.com/mindsporelab/mindnlp/actions/runs/9381600811/job/25831175588,测试通过，本赛题完成
这个issue类型是bug报告，主要对象是qwen2模型在进行测试时的速度过慢。原因可能是代码实现导致运行速度慢，用户需要优化代码以提高速度。,qwen2速度慢,/tests/ut/transformers/models/qwen2/test_modeling_qwen2.py 现在跑通了，速度非常非常慢 _Originally posted by  in https://github.com/mindsporelab/mindnlp/issues/1152issuecomment2148693146_,2024-06-05T09:04:58Z,,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1168,请问你现在解决问题了吗，我这边使用ChatGLM6B进行推理大概也就34tokens每秒,gpu还是昇腾,> gpu还是昇腾 昇腾910B,> 请问你现在解决问题了吗，我这边使用ChatGLM6B进行推理大概也就34tokens每秒 这个需要官方解决,> > 请问你现在解决问题了吗，我这边使用ChatGLM6B进行推理大概也就34tokens每秒 >  > 这个需要官方解决 你用的mindspore2.2吗，这个跟算子执行速度有关,> > > 请问你现在解决问题了吗，我这边使用ChatGLM6B进行推理大概也就34tokens每秒 > >  > >  > > 这个需要官方解决 >  > 你用的mindspore2.2吗，这个跟算子执行速度有关 我用的最新版，2.3.0rc2,"有两部分原因： 1. python执行的处理造成的算子下发间隔 2. 鲲鹏处理器执行会跳核影响 算子下发速度 我今天改了一下chatglm2的代码，能从320ms/token优化到160ms/token, 在鲲鹏CPU环境下需要使用以下方式执行： ```taskset c 023 python cli_demo.py```",qwen2的执行速度我晚点再看看怎么优化
这是一个用户提出需求的类型，主要涉及的对象是decision_transformer模块。 由于需求参赛者在昇腾AI创新大赛中需要相关支持。,【昇腾AI创新大赛】decision_transformer,,2024-06-05T09:02:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1167
"这是一个新功能提议，待实现""。",【昇腾AI创新大赛】mvp,first version,2024-06-05T08:46:56Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1166,!图片,!图片,/model mvp,/model mvp,/model mvp,https://github.com/mindsporelab/mindnlp/actions/runs/9386591303,测试通过，本赛题完成
"这是一个bug报告，主要涉及的对象是""昇腾AI创新大赛ctrl""，由于未知原因导致了无法识别的字符显示在内容中。",【昇腾AI创新大赛】ctrl,!18d182a78c47a43f4ea3bbb637978107 !a835474c1b47db819f26f3145d85dcad,2024-06-05T08:15:14Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1165,/model ctrl,/model ctrl,https://github.com/mindsporelab/mindnlp/actions/runs/9380690806,测试通过，本赛题完成
这个issue属于功能需求类型，主要涉及在MindNLP中增加一个用于加载和编码sentence transformer模块的功能。,add sentence transformer module,增加了sentence transformer模块，支持模型加载和encode,2024-06-05T07:15:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1164
这是一个用户提出需求的issue，主要涉及的对象是GLM4-9b，用户希望提供一个适配GLM4-9b并提供推理代码的请求。,适配GLM4-9b，提供一个推理代码可以吗？,代码仓库： THUDM/GLM4: GLM4 series: Open Multilingual Multimodal Chat LMs | 开源多语言多模态对话模型 (github.com) 模型仓库： THUDM/glm49bchat · Hugging Face glm49b · 模型库 (modelscope.cn),2024-06-05T06:57:26Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1163,今天搞一下,> 今天搞一下 嗯呐，Qwen2也开源了，大佬, CC(add glm4) 
"这是一个用户提出需求的issue，主要涉及的对象是""昇腾AI创新大赛""。",【昇腾AI创新大赛】xlm_roberta_xl,,2024-06-05T05:11:08Z,,closed,0,9,https://github.com/mindspore-lab/mindnlp/issues/1162,/model xlm_roberta_xl,/model xlm_roberta_xl,/model xlm_roberta_xl,https://github.com/mindsporelab/mindnlp/actions/runs/9378859340,测精度的ut不允许skip，要和hf一样写,github内存不足，本地可以通过 （最后一个skip transformers中本身就跳过） !image,!image,!image,模型注册不完整，导致框架UT无法执行，此PR无效
这是一个类型为测试反馈（非bug报告）的issue，主要对象是funnel-transformer模型。由于已完成门禁测试，用户提出该问题通知其他参与者测试进展。,【昇腾AI创新大赛】funnel-transformer,已完成门禁测试,2024-06-05T03:54:05Z,,closed,0,23,https://github.com/mindspore-lab/mindnlp/issues/1161,/model funnel,/model funnel,/model funnel,/model funnel,/model funnel,/model funnel,/model funnel,/model funnel,https://github.com/mindsporelab/mindnlp/actions/runs/9380501638,邮件已收到,/model funnel,/model funnel,/model funnel,!swiftformmer swiftformmer是不是merge出错了，导致pytest失败, ,/model funnel,/model funnel,https://github.com/mindsporelab/mindnlp/actions/runs/9394578046,/model funnel,https://github.com/mindsporelab/mindnlp/actions/runs/9396842415/job/25878806971,/model funnel,https://github.com/mindsporelab/mindnlp/actions/runs/9397117741/job/25879661791,测试通过，本赛题完成
这是一个用户提出需求的issue，主要涉及的对象是mindnlp下的时间序列转换器（time_series_transformer）。,【昇腾AI创新大赛】time_series_transformer,,2024-06-04T23:41:53Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1160,!image,/model time_series_transformer,/model time_series_transformer,/model time_series_transformer,3个ut没过，https://github.com/mindsporelab/mindnlp/actions/runs/9375862366/job/25814766292,/model time_series_transformer,/model time_series_transformer
这是一个用户提出需求的类型，主要涉及的对象是昇腾AI创新大赛中的roc_bert。由于没有提供具体描述或细节，无法确定具体问题或需求的原因。,【昇腾AI创新大赛】roc_bert,!image !image,2024-06-04T21:49:04Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1159,/model roc_bert,测试通过，本赛题完成
这是一个用户提出需求的issue，主要涉及的对象是昇腾AI创新大赛的poolformer模型。由于在issue内容中未提供具体信息，无法确定具体问题或请求的性质。,【昇腾AI创新大赛】 poolformer,,2024-06-04T18:00:53Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1158,/model poolformer,/model poolformer,/model poolformer,测试通过，本赛题完成
这个issue属于用户提出需求类型，主要对象是参加昇腾AI创新大赛的swiftformer模型。,【昇腾AI创新大赛】 swiftformer,,2024-06-04T16:52:47Z,,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1157,/model swiftformer,/model swiftformer,/model swiftformer,/model swiftformer,/model swiftformer,有一个ut没过，https://github.com/mindsporelab/mindnlp/actions/runs/9377038213/job/25817946010,/model swiftformer,测试通过，本赛题完成
这个issue属于用户提出需求类型，主要涉及到昇腾AI创新大赛中的与ctrl相关的问题。,【昇腾AI创新大赛】ctrl,,2024-06-04T15:21:55Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1156,没跑测试
这是一个用户提交需求的issue，主要对象是DeBERTa-v2模型。,【昇腾AI创新大赛】DeBERTa-v2,,2024-06-04T13:44:56Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1155,/model debertav2,/model deberta_v2,/model deberta_v2,测试通过，本赛题完成
这是一个空白issue，类型为用户提出需求，主要对象是昇腾AI创新大赛的seggpt项目。,【昇腾AI创新大赛】seggpt,,2024-06-04T13:30:50Z,,closed,0,12,https://github.com/mindspore-lab/mindnlp/issues/1154,/model seggpt,/model seggpt,/model seggpt,/model seggpt,这个模型还得找时间倒腾下，ut上有点问题，ops.rand和torch.rand在随机种子设置一直的情况下，测试下来似乎误差也比较大,/model seggpt,/model seggpt,/model seggpt,/model seggpt,/model seggpt,/model seggpt,/model seggpt
这是一个用户提出需求的issue，主要涉及的对象是昇腾AI创新大赛中的nystromformer模型。,【昇腾AI创新大赛】nystromformer,,2024-06-04T10:51:41Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/1153,/model nystromformer,/model nystromformer,pytest没过，自行到action页面查看问题 https://github.com/mindsporelab/mindnlp/actions/runs/9369676772/job/25794765511,/model nystromformer,> pytest没过，自行到action页面查看问题 https://github.com/mindsporelab/mindnlp/actions/runs/9369676772/job/25794765511 本地可以通过，actions中numpy api报错  ,测试通过，本赛题完成
这个Issue属于Bug报告类型，主要涉及MindNLP中的qwen1.5，由于无法运行，用户提到了无法成功描述bug的问题。,无法跑通qwen1.5,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 运行qwen1.5  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:   Ascend > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片     ascend 910  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :最新  Python version (e.g., Python 3.7.5) :3.9.18  OS platform and distribution (e.g., Linux Ubuntu 16.04):OE22  GCC/Compiler version (if compiled from source):12  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ``` from mindnlp.transformers import (     Qwen2ForCausalLM,     Qwen2ForSequenceClassification,     Qwen2Model, ) model = Qwen2ForCausalLM.from_pretrained(DEFAULT_CKPT_PATH, device_map=""auto"", ms_dtype=mindspore.float16) ``` See error ``` /root/anaconda3/envs/sakura/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /root/anaconda3/envs/sakura/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /root/anaconda3/envs/sakura/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /root/anaconda3/envs/sakura/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) Building prefix dict from the default dictionary ... Dumping model to file cache /tmp/jieba.cache Loading model cost 1.302 seconds. Prefix dict has been built successfully. /root/anaconda3/envs/sakura/lib/python3.9/sitepackages/torch_npu/dynamo/__init__.py:18: UserWarning: Register eager implementation for the 'npu' backend of dynamo, as torch_npu was not compiled with torchair.   warnings.warn( Special tokens have been added in the vocabulary, make sure the associated word embeddings are finetuned or trained. Traceback (most recent call last):   File ""/opt/panda/mindnlp/my_tests/qwen1.5.py"", line 46, in      model = Qwen2ForCausalLM.from_pretrained(DEFAULT_CKPT_PATH, device_map=""auto"", ms_dtype=mindspore.float16)   File ""/opt/panda/mindnlp/mindnlp/transformers/modeling_utils.py"", line 1099, in from_pretrained     model = cls(config, *model_args, **model_kwargs) TypeError: __init__() got an unexpected keyword argument 'device_map' ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 模型正常运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-06-04T09:42:53Z,bug,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1152,没有device_map这个参数，删掉,/tests/ut/transformers/models/qwen2/test_modeling_qwen2.py 你文件里这么写的，另外现在跑通了，速度非常非常慢,而且无法支持流式输出,能否给一个代码demo
该issue类型为用户提出需求，主要涉及的对象是昇腾AI创新大赛的Visual bert模型。该问题由于用户希望参与昇腾AI创新大赛，并对Visual bert模型进行相关开发或应用而提出。,【昇腾AI创新大赛】Visual bert,,2024-06-04T07:52:10Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1151,/model visual_bert,/model visual_bert,测试通过，本赛题完成
该问题为用户提出需求。它涉及的主要对象是昇腾AI创新大赛中关于speech_encoder_decoder的内容。,【昇腾AI创新大赛】speech_encoder_decoder,,2024-06-04T07:00:18Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1150,/model speech_encoder_decoder,pylint未通过，测试后自行去action页面查看问题 https://github.com/mindsporelab/mindnlp/actions/runs/9363990367/job/25775986320
这个issue属于用户提出需求的类型，主要涉及到昇腾AI创新大赛中的imagegpt项目。由于缺少具体内容，用户可能是在请教问题、寻求帮助或提出建议。,【昇腾AI创新大赛】imagegpt,,2024-06-04T05:48:50Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1149,/model imagegpt,/model imagegpt,/model imagegpt,测试通过，本赛题完成
该issue属于需求类型，主要对象为添加transformers的文档说明。原因可能是缺乏有关transformers的文档，需要补充说明来丰富项目文档内容。,Add docs for transformers,https://gitee.com/mindspore/community/issues/I9GVLN?from=projectissue !doc_1,2024-06-03T17:41:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1148
"这是一个关于需求的issue，涉及对象为""昇腾AI创新大赛""和""chinese_clip模型""。该问题的产生原因是需要调用chinese_clip模型来进行推理测试。",【昇腾AI创新大赛】groupvit," 由于测试推理脚本发现需要调用chinese_clip模型，所以我把chinese_clip相关的代码也一起加入提交了，推理测试脚本如下： ``` from PIL import Image  import requests from mindnlp.transformers import AutoProcessor, GroupViTModel from mindspore import ops model = GroupViTModel.from_pretrained(""nvidia/groupvitgccyfcc"") processor = AutoProcessor.from_pretrained(""nvidia/groupvitgccyfcc"")  url = ""http://images.cocodataset.org/val2017/000000039769.jpg""  image = Image.open(requests.get(url, stream=True).raw) image = Image.open('000000039769.jpg') inputs = processor(     text=[""a photo of a cat"", ""a photo of a dog""], images=image, return_tensors=""ms"", padding=True ) outputs = model(**inputs)  print(outputs) logits_per_image = outputs.logits_per_image   this is the imagetext similarity score probs = ops.softmax(logits_per_image, axis=1)   we can take the softmax to get the label probabilities print(probs) ```",2024-06-03T16:32:09Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1147,/model groupvit,/model groupvit,groupvit赛题已完成，chineseclip单独提交pr
"该问题单为需求提出，主要对象是参与“昇腾AI创新大赛”的团队""groupvit""，问题由于需要提交相关比赛作品而提出。",【昇腾AI创新大赛】groupvit,groupvit,2024-06-03T15:33:56Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/1146,!image,/model groupvit,测试通过，本赛题完成
"这是一个类型未知的issue，主要对象是""rembert""。由于未提供具体内容，无法确定问题类型。",【昇腾AI创新大赛】rembert,,2024-06-03T15:12:31Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1145,/model rembert,测试通过，本赛题完成
"这是一个用户提出需求的issue，主要涉及到mindnlp下的一个模型groupvit。由于用户只提供了简单的命令""/model groupvit""，可能是要求示例代码或查看模型详情的请求。",【昇腾AI创新大赛】groupvit,/model groupvit,2024-06-03T12:12:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1144
这是一个用户提出需求的类型issue，主要涉及的对象是pynative核心模块。,add new core module for pynative,,2024-06-03T03:34:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1143
"该问题单为需求提出，主要涉及昇腾AI创新大赛的参赛作品""owlvit""。",【昇腾AI创新大赛】owlvit,,2024-06-02T18:54:04Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1142,/model owlvit,测试通过，本赛题完成
"该issue类型为用户提出需求，主要对象是""gpt_neox_japanese""模型。由于内容为空，用户可能在寻求关于该模型的帮助或者相关信息。",【昇腾AI创新大赛】gpt_neox_japanese,!image,2024-06-02T14:56:41Z,,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/1141,/model gpt_neox_japanese,在进行测试时github ci内存不足，在本地测试全部通过。,给出slow用例的pass截图,!image !image,test_generation没跑，无法确定推理结果是否正确,!image !image,测试通过，本赛题完成
这个issue类型为bug报告，主要涉及的对象是mindnlp下的stablelm模块。原因导致症状的bug或用户的问题可能是与模块在昇腾AI创新大赛中的应用相关。,【昇腾AI创新大赛】stablelm,,2024-06-02T12:40:02Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1140,/model stablelm,测试通过，本赛题完成
"这是一个关于""【昇腾AI创新大赛】camembert""的issue，类型为用户提出需求，寻求帮助。",【昇腾AI创新大赛】camembert,,2024-06-02T10:49:22Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/1139,/model camembert,/model camembert,/model camembert,/model camembert,测试通过，本赛题完成
"该issue类型为技术需求，主要对象是""昇腾AI创新大赛""。",【昇腾AI创新大赛】mobilevit,,2024-06-02T08:52:39Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1138,/model mobilevit,/model mobilevit,/model mobilevit,测试通过，本赛题完成
这个issue是用户提出需求。该问题单涉及的主要对象是MindSpore模型开发挑战赛。原因是用户在寻求有关MindSpore模型开发挑战赛的支持。,support for ctrl,昇思MindSpore模型开发挑战赛【模型迁移赛】,2024-06-01T20:12:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1137
这是一个用户提出需求的issue，主要涉及的对象是昇思MindSpore模型开发挑战赛。,【昇腾AI创新大赛】 squeezebert,昇思MindSpore模型开发挑战赛【模型微调赛】,2024-06-01T17:30:27Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1136,/model squeezebert,测试通过，本赛题完成
这是一个用户提出需求类型的问题，主要对象是昇腾AI创新大赛。,【昇腾AI创新大赛】 x_clip,,2024-06-01T09:11:58Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1135,/model x_clip,/model x_clip,/model x_clip,测试通过，本赛题完成
这是一个bug报告类型的issue，主要涉及的对象是Ascend910A，由于某种原因导致了conv2d功能出现问题。,fix conv2d on Ascend910A,,2024-05-31T10:01:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1134
这是一个 bug 报告类型的 issue， 主要涉及对象是 mindnlp 下的 Transformer 模块，问题原因可能是损失函数计算的错误导致了输出数据的尺寸不匹配。,step_into_llm/Season1.step_into_chatgpt/1.Transformer / 中使用损失函数计算loss有误,"dec_outputs: [batch_size, src_len, trg_vocab_size] 调整后为[batch_size, * src_len, trg_vocab_size] dec_inputs: [batch_size, trg_len] targets = dec_inputs[:, 1:].view(1) loss = loss_fn(logits, targets) 其中logits的大小和dec_outputs相同（[batch_size, * src_len, trg_vocab_size]），targets大小为[batch_size * trg_len] 明显维数不一样，而且计算出来的loss没有意义",2024-05-31T04:35:26Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1133,提错地方了 去step_into_llm提
这是一个bug报告，主要涉及Transformer模型中损失函数计算错误导致的问题。,step_into_llm/Season1.step_into_chatgpt/1.Transformer / 中使用损失函数计算loss有误,"dec_outputs: [batch_size, src_len, trg_vocab_size] 调整后为[batch_size, * src_len, trg_vocab_size] dec_inputs: [batch_size, trg_len] targets = dec_inputs[:, 1:].view(1) loss = loss_fn(logits, targets) 其中logits的大小和dec_outputs相同（[batch_size, * src_len, trg_vocab_size]），targets大小为[batch_size * trg_len] 明显维数不一样，而且计算出来的loss没有意义",2024-05-31T04:34:26Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1132
这是一个bug报告，涉及到针对Ascend 910A修复BERT UT测试的问题。可能由于硬件兼容性问题导致测试无法通过，需要进行修复。,fix bert ut test on Ascend 910A,,2024-05-31T04:10:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1131
这是一个描述bug的issue，主要涉及到调用Accumulator时报RuntimeError的情况，原因是调用from mindnlp.modules import Accumulator。,调用Accumulator报RuntimeError,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 调用from mindnlp.modules import Accumulator，运行代码出现RuntimeError: Failed to import transformers.pipelines because of the following error (look up to see its traceback) !3 22ELL{D5XJ} U Y_~9I  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.11  Python version (e.g., Python 3.7.5) :python 3.9.18  OS platform and distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04.6 LTS  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 直接导入from mindnlp.modules import Accumulator，运行文件后便会出现该错误。 **Expected behavior / 预期结果 (Mandatory / 必填)** 可以正常使用Accumulator **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-05-30T13:18:47Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1130,换2.2.14试试,"do not use Accumulator,  attach Tensor.grad automatically."
这个issue类型是用户提出需求，针对的主要对象是ln_tuning功能。由于缺少ln_tuning支持和示例，用户提出了希望添加ln_tuning支持并提供一个相应示例的需求。,support ln_tuning and add one example(seq2seq for cls) for it .,ln_tuining_torch可训练参数 !ln_tuining_torch可训练参数 ln_tuining_mindnlp可训练参数 !ln_tuining_mindnlp可训练参数,2024-05-30T13:18:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1129
这是一个bug报告类的issue，主要涉及PEFT微调过程中使用add_adapter时出现peft_config属性缺失的问题，可能是由于加载模型后的某些原因导致的。,Add adapter过程中peft_config缺少属性,"**Describe the bug/ 问题描述** 在使用LoRA进行PEFT微调的过程中，模型加载后使用add_adapter，会出现peft_config缺少属性的报错。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU  **Software Environment / 软件环境**:  MindSpore version : 2.2.11  Python version: 3.8.18  OS platform and distribution: Ubuntu 20.04  **Excute Mode / 执行模式**: `pynative` **To Reproduce / 重现步骤** ``` python from mindnlp.transformers import AutoModelForSeq2SeqLM from mindnlp.peft import get_peft_model, LoraConfig, TaskType model = AutoModelForSeq2SeqLM.from_pretrained(""googlet5/t5small"") peft_config = LoraConfig(task_type=TaskType.SEQ_2_SEQ_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1)  The approach that works  model = get_peft_model(model, peft_config)  The approach that gives error model.add_adapter(peft_config) model.enable_adapters() model.print_trainable_parameters() ``` **Expected behavior / 预期结果** ``` Traceback (most recent call last):   File ""/home/ernaux/Projects/mindspore/tmp/test_adapter.py"", line 9, in      model.add_adapter(peft_config)   File ""/home/ernaux/Projects/mindspore/mindnlp/mindnlp/transformers/integrations/peft.py"", line 244, in add_adapter     inject_adapter_in_model(adapter_config, self, adapter_name)   File ""/home/ernaux/Projects/mindspore/mindnlp/mindnlp/peft/mapping.py"", line 131, in inject_adapter_in_model     if peft_config.is_prompt_learning or peft_config.is_adaption_prompt: AttributeError: 'LoraConfig' object has no attribute 'is_adaption_prompt' ```",2024-05-30T12:57:35Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1128
这是一个功能需求类型的issue，主要涉及的对象是核心文件core.py，由于之前版本的core.py存在问题，需要重新提交修复后的core.py文件。,renew the core.py file,"** PR 内容** 再次提交core.py, 已经在本地完成pylint测试",2024-05-30T09:34:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1127
这是一个bug报告，涉及 mindspore 项目的 trl 模块下的 core.py 文件更新导致的问题。,renew mindspore/trl/core.py,**PR 内容**： 更新了trl的配置文件core.py **PR 修复的issue**： Fixes https://github.com/mindsporelab/mindnlp/mindnlp/trl/core.py,2024-05-30T07:17:26Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1126,/retest
这是一个bug报告，主要针对mindnlp库中的clip函数精度错误问题。,fix clip precision error,,2024-05-30T06:13:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1125
这是一个需求提出的issue，主要涉及的对象是ln_tuning功能。由于未提供具体的问题描述或需求细节，导致无法准确了解用户所需的支持或反馈内容。,Support for ln_tuning,```Python max_length = 64 lr = 1e2 num_epochs = 8 batch_size = 12 ``` !mindnlp,2024-05-29T16:53:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1124
这是一个用户提出的需求类型的issue，主要涉及到支持多任务提示调整。可能由于现有功能限制或用户需求，需要支持在模型训练中进行多任务提示调整。,support multi-task prompt tuning,,2024-05-29T10:17:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1123
这是一个需求类型的issue，主要涉及的对象是要在mindnlp中添加ViT模型。由于现有ViT模型缺失，用户希望通过添加该模型来提升mindnlp的功能。,add ViT model,add ViT model,2024-05-29T08:53:32Z,,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1122,/model vit,/model vit,/model vit,/model vit,/model vit,/model vit,/model vit,/model vit
这是一个用户需求类型的issue，主要涉及的对象是mindnlp/print_trainable_parameters函数。由于用户需要基本支持Poly，并且提到了print_trainable_parameters函数，推测用户可能希望实现对Poly的基本支持功能。,Basic support for Poly,```Python r = 8   rank of lora in poly n_tasks = 4   number of tasks n_skills = 2   number of skills (loras) n_splits = 4   number of heads ``` mindnlp/print_trainable_parameters !image peft/print_trainable_parameters !image,2024-05-28T18:07:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1121
这是一个用户提出需求的 issue，主要对象是mindnlp/print_trainable_parameters函数，可能由于功能实现不完整导致用户提出了该需求。,Basic support for Poly,```Python r = 8   rank of lora in poly n_tasks = 4   number of tasks n_skills = 2   number of skills (loras) n_splits = 4   number of heads ``` mindnlp/print_trainable_parameters !image peft/print_trainable_parameters !image,2024-05-28T17:03:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1120
这个issue类型是需求提出，涉及的主要对象是代码注释生成功能。由于用户希望自动生成代码注释以提高代码质量和可读性，因此提出了这个需求。,Auto generate comments code,自动生成注释的代码,2024-05-28T14:16:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1119
这个issue类型是代码质量问题，涉及到注释过的代码，由于代码中存在过多的注释或者注释不清晰导致阅读和维护困难。,commented code,注释过的代码,2024-05-28T12:28:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1118
这是一个bug报告，涉及解析注释的问题。原因可能是解析注释的逻辑错误导致错误行为。,fix parse comment,,2024-05-28T09:38:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1117
这是一个bug报告，涉及的主要对象是fix model ci，由于修复模型构建时出现了问题导致了此bug。,fix model ci,,2024-05-28T09:27:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1116
这个issue类型是测试CI，主要对象是mindnlp。由于需要改进持续集成（CI）的测试部分，用户提出了这个issue。,test ci,,2024-05-28T09:24:01Z,,closed,0,16,https://github.com/mindspore-lab/mindnlp/issues/1115,/model bert,/model bert,/model bert,/model bert,/model bert,/model bert,/model bert,/model bert,/model bert,/model bert,/model bert,test,123,123,123,/model test
这个issue类型属于用户提出需求，请教问题，主要涉及的对象是comment check model。由于用户希望使用评论检查模型，因此提出了这个问题。,use comment check model,,2024-05-28T09:18:46Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1114,/model bert
这是一个bug报告，该问题主要涉及到Mindnlp仓库中的BlenderbotTokenizerFast。由于修复问题导致了BlenderbotTokenizerFast存在bug。,fix BlenderbotTokenizerFast,,2024-05-28T09:02:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1113
这是一个用户提出需求的issue，主要涉及的对象是代码示例库。由于缺乏前缀调整示例，用户希望添加一个示例来补充代码库的功能。,add prefix tuning example,,2024-05-28T08:46:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1112
这是一个bug报告，主要涉及weight_norm模块，原因可能是删除的weight权重重新添加回去。,weight_norm 将已经删除的weight权重又重新添加回去,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 使用weight_norm 时候，应删除原本的weight，代码中也确实删除了，但是后续又重新注册了一个weight参数  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2  Python version (e.g., Python 3.7.5) :3.9.5  OS platform and distribution (e.g., Linux Ubuntu 16.04):20.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 代码为：https://github.com/mindsporelab/mindnlp/blob/master/mindnlp/modules/weight_norm.pyL58 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 返回的nn.Cell没有weight，只有weight_v和weight_g **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !6}KIX`HV8GBQM}ISP`NYX(0 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-05-28T03:31:12Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1111,可以试试使用 mindnlp/modules/functional/weight_norm.py 里的weight_norm实现,重构后完全对齐Pytorch，应该没问题了
这是一个CI/CD相关的问题，涉及到模型测试的持续集成。由于缺乏模型测试的CI配置，导致需要添加模型测试相关的CI操作。,add model test ci,,2024-05-28T02:23:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1110
这是一个bug报告，涉及的主要对象是loha组件。原因可能是loha组件存在bug或者缺少示例，用户希望修复bug并提供示例用法。,Fix bugs in loha and add example for it,!image !image,2024-05-26T15:15:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1109
"这是一个需求提出类型的issue，主要涉及的对象是""Generate_Comments""功能。由于功能不可用或者效果不理想，用户提出了需要生成评论或者改进评论生成功能的需求。",Generate_Comments,,2024-05-26T08:16:13Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1108,pylint问题太多了，要修复
"这是一个bug报告，该问题单涉及的主要对象是""generate_comments""功能。由于未提供具体内容，用户可能遇到了无法生成评论的问题。",generate_comments,,2024-05-26T08:12:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1107
这是一个未填写内容的bug报告，涉及评论功能，导致用户无法正常添加评论。,Comments,,2024-05-26T08:09:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1106
这是一个用户提出需求类型的issue，主要涉及到engine docs，用户寻求相关实习任务的帮助。,Engine docs,engine docs 实习任务链接：https://gitee.com/mindspore/community/issues/I9GVKW,2024-05-25T15:24:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1105
这个issue类型是功能需求，主要涉及到支持 prefix-tuning、p-tuning 和 multitask-prompt-tuning。由于用户希望增加这些功能以改善模型性能和应用范围。,"support prefix-tuning, p-tuning, multitask-prompt-tuning",,2024-05-25T14:52:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1104
这是一个用户提出需求的issue，主要涉及的对象是dataset module documentation，由于缺少文档，用户需要相关内容的说明。,Create dataset module documentation,    ,2024-05-25T12:17:08Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1103,你这个目录层级不对,主要是我看dataset模块好像没做什么功能，主要就是load_dataset这个方法和transforms模块，还给了一个BaseMapFunction，不知道应该怎么规划。
这是一个关于代码问题的bug报告，主要涉及mindnlp中tutorial的使用。可能由于错误导入TrainingArguments模块，导致在使用trainer时出现问题。,Correct import TrainingArguments in tutorial use_trainer,,2024-05-23T11:49:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1102
这是一个需求类型的issue，主要对象是为mindnlp添加关于mkdocs的教程markdown文件。原因是可能用户需要更多关于mkdocs的操作指南和数据准备教程。,Add tutorial markdown for mkdocs,"Added markdown file into docs/en/tutorials for mkdocs for quick_start, data_preprocess and use_trainer",2024-05-23T09:11:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1101
这是一个需求修改类的issue，主要涉及到engine文档的修改，需要更换部分内容。原因可能是为了更新相关内容或者修复问题。,engine doc,engine文档修改，更换了带有torch nn.module这些的内容 任务链接：https://gitee.com/mindspore/community/issues/I9GVKW,2024-05-23T04:20:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1100
这是一个需求类型的issue，主要涉及MindSpore的任务链接替换。由于需要替换带torch nn.Module的任务链接，用户可能遇到此问题并寻求帮助。,engine documentation,带torch nn.Module的替换 任务链接：https://gitee.com/mindspore/community/issues/I9GVKW,2024-05-23T03:12:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1099
这是一个用户提出需求的issue，主要对象是要在mindnlp中添加seq2seq lora功能。,add seq2seq lora,,2024-05-23T02:20:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1098
这是一个bug报告，涉及的主要对象是BaseMapFunction。由于拼写错误导致了Bug。,Fix BaseMapFunction typo,,2024-05-22T13:55:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1097
这是一个bug报告，涉及主要对象是BaseMapFunction。由于拼写错误导致程序无法正常运行。,Fix BaseMapFunction typo,,2024-05-22T13:49:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1096
这个issue类型是需求提出，主要对象是Mindnlp项目。由于缺乏数据预处理和使用训练器的教程，用户请求添加相应的教程来指导操作。,Add tutorial for data preprocess and use trainer,,2024-05-22T12:07:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1095
这是一个需求提出的Issue，主要涉及到支持LoHa，由于用户需要在MindNLP上支持LoHa，可能是因为LoHa是用户感兴趣的工具或框架，希望在MindNLP中实现相关功能。,Support LoHa,,2024-05-22T00:39:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1094
这是一个需求反馈类型的issue，涉及到LoHa的支持；可能由于参数设置不正确导致无法成功训练LoHa模型。,support LoHa,peftlohatrainparams !peftloha mindnlplohatrainparams !mindnlploha,2024-05-21T14:17:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1093
这是一个用户提出需求的issue，主要涉及mindnlp模型的可训练参数问题。原因可能是用户想了解和比较不同模型的参数情况。,Support LoHa,peft model trainable params !image minnlp model trainable params !image,2024-05-21T12:15:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1092
这个issue类型属于bug报告，主要涉及的对象是Lora通信功能。由于出现了错误，导致需要修复Lora通信方面的问题。,fix lora error,,2024-05-21T10:05:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1091
这是一个用户提出需求类型的issue，主要涉及适配支持 EMU2多模态模型，可能是由于当前系统不支持该模型导致的需求。,希望适配支持 EMU2多模态模型,希望适配支持 EMU2多模态模型 github连接：https://github.com/baaivision/Emu/tree/main/Emu2 huggingface连接：https://huggingface.co/BAAI/Emu2,2024-05-21T07:19:44Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1090
这是一个用户提出需求的issue，主要涉及的对象是在mindnlp下添加幻灯片。,add mindnlp slides,,2024-05-21T04:00:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1089
"这是一个bug报告类型的issue，主要涉及到""lok""对象。原因是由于修复 ""lok"" 导致了错误。",fix lokr casued error,,2024-05-19T00:03:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1088
这是一个用户提出需求的issue，主要涉及到Engine文档的补充完善。由于文档内容不完整，用户提出了需要完善Engine文档的需求。,Engine documentation completion,补齐Engine文档 issue链接： https://gitee.com/mindspore/community/issues/I9GVKW,2024-05-18T08:44:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1087
这是一个用户提出需求类别的issue，主要涉及到MindNLP引擎文档的完善。由于文档不完整导致用户需求相关的信息或操作步骤无法获得，需要补充完成文档以解决用户使用中的困扰。,Engine documentation completion,补齐engine文档 issue链接：[](https://gitee.com/mindspore/community/issues/I9GVKW),2024-05-18T08:40:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1086
这是一个bug报告类型的issue，主要涉及pipelines推理中document_question_answering.py示例2代码，由于dqa_pipeline入参缺少image导致的bug。,pipelines推理中document_question_answering.py示例 2，其中dqa_pipeline入参缺少image,"**Describe the bug/ 问题描述 (Mandatory / 必填)** pipelines推理中document_question_answering.py示例 2，其中dqa_pipeline入参缺少image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) ：2.2.14  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: python document_question_answering.py **Expected behavior / 预期结果 (Mandatory / 必填)** 执行成功 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** dqa_pipeline入参缺少image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-05-17T05:51:24Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1085
这是一个用户提出需求的类型，主要对象是更新文档，可能是为了完善现有的文档内容或者修正错误。,update docs,,2024-05-17T02:07:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1084
这是一个bug报告，主要对象是mindnlp下的pipeline中的fill_mask功能。由于存在tensor索引错误，导致用户提出了这个issue。,fill_mask,添加了fill_mask的pipeline，目前ut存在tensor索引错误的问题 issue链接： https://gitee.com/mindspore/community/issues/I97UT8,2024-05-16T15:48:52Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1083,second_commit_github fill_mask的pipeline，修复了tensor索引错误问题 issue链接： https://gitee.com/mindspore/community/issues/I97UT8
这是一个类型为bug报告的issue，主要涉及tensor的索引错误问题，原因可能是代码实现中出现了错误导致此bug。,tensor索引错误,**Describe the bug/ 问题描述 (Mandatory / 必填)** tensor索引错误 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !1 !2 !3,2024-05-16T13:05:22Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1082
这是一个bug报告，涉及到CLIPProcessor和CLIPScore处理图像后获得的feature与transforemers结果差距较大的问题。,CLIPProcessor和CLIPScore处理图像后获得的feature与transforemers结果差距较大,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. CLIPProcessor和CLIPScore处理图像后获得的feature与transforemers结果差距较大  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.13  Python version (e.g., Python 3.7.5) : 2.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): windows11  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: `from mindnlp.transformers import CLIPProcessor, CLIPModel from transformers import CLIPProcessor as TorchCLIPProcessor, CLIPModel as TorchCLIPModel import numpy as np import mindspore as ms np_img = np.random.randint(0, 255, (3, 224, 224)) text = ""an image of dog"" processor_ms = CLIPProcessor.from_pretrained(""openai/clipvitlargepatch14"") model_ms = CLIPModel.from_pretrained(""openai/clipvitlargepatch14"", ignore_mismatched_sizes=True) processed_input_ms = processor_ms(text=text, images=np_img, return_tensors=""np"") image_features_ms = model_ms.get_image_features(pixel_values=ms.Tensor(processed_input_ms['pixel_values'])) text_features_ms = model_ms.get_text_features(input_ids=ms.Tensor(processed_input_ms['input_ids']), attention_mask=ms.Tensor(processed_input_ms['attention_mask'])) processor_torch = TorchCLIPProcessor.from_pretrained(""openai/clipvitlargepatch14"") model_torch = TorchCLIPModel.from_pretrained(""openai/clipvitlargepatch14"") processed_input_torch = processor_torch(text=text, images=np_img, return_tensors=""pt"") image_features_torch = model_torch.get_image_features(pixel_values=processed_input_torch['pixel_values']) text_features_torch = model_torch.get_text_features(input_ids=processed_input_torch['input_ids'], attention_mask=processed_input_torch['attention_mask']) print(""image_features_ms"", image_features_ms[0][0:5]) print(""image_features_torch"", image_features_torch[0][0:5]) print(""text_features_ms"", text_features_ms[0][0:5]) print(""text_features_torch"", text_features_torch[0][0:5])` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. `image_features_ms [ 0.19177139  1.2455583   0.85580724 1.4593458  1.8108404 ] image_features_torch tensor([0.0462,  0.7193,  0.8034,  0.6526, 0.0212], grad_fn=) text_features_ms [1.6040958  1.297238  0.8092618  1.6023345 2.6258645] text_features_torch tensor([0.0300,  0.1251,  0.4510, 0.1160,  0.4756], grad_fn=)` **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-05-16T04:14:48Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1081,找到问题了，ignore_mismatched_sizes=False，这个地方我要修复一下clip的实现
这个issue是关于bug报告，主要对象是starcoder example。由于代码中可能存在错误或缺陷，导致示例无法正常工作。,fix starcoder example,,2024-05-15T16:23:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1080
这个issue类型为功能需求，主要涉及对象是MindNLP Starcoder vscode demo，用户提出了希望添加相关功能的需求。,Add MindNLP Starcoder vscode demo,,2024-05-15T15:36:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1079
这是一个用户提出需求的类型的issue，主要涉及peft模块的文档完善。由于缺乏完善的文档，用户提出了需要完善peft模块文档的需求。,peft module documentation completion,issue编号(I9GVLA) https://gitee.com/mindspore/community/issues/I9GVLA,2024-05-15T11:03:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1078
这是一个bug报告，涉及pipeline base error的修复。这个issue很可能是由于代码实现中的错误或者逻辑缺陷导致pipeline base出错，需要修复以解决这个问题。,fix pipeline base error,,2024-05-15T09:55:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1077
这是一个需求类型的issue，主要涉及对PEFT集成的建议。,add peft integration,,2024-05-15T02:28:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1076
该issue类型为功能实现，并涉及到实现cogvlm模型和demo。原因是迁移模型完成后，进行了精度校验并与torch版本进行了对比。,implement cogvlm model and demo,实现了cogvlm模型的迁移，完成了精度校验，推理结果和torch版本一致。,2024-05-14T12:39:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1075
这是一个bug报告，主要涉及到StarCoder2-2b pipeline生成时出现的错误，原因是Tokenizers对象缺少'get_added_tokens_decoder'属性。,StarCoder2-2b pipeline生成时报错'AttributeError: 'tokenizers.Tokenizer' object has no attribute 'get_added_tokens_decoder',"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. StarCoder22b pipeline生成时报错'AttributeError: 'tokenizers.Tokenizer' object has no attribute 'get_added_tokens_decoder'  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.2.14  Python version (e.g., Python 3.7.5) : 3.9.19  OS platform and distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: PyNative > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ```python from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM, PreTrainedTokenizer, PreTrainedModel, GenerationConfig from mindnlp.transformers import Pipeline, pipeline import mindspore class GeneratorBase:     def generate(self, query: str, parameters: dict) > str:         raise NotImplementedError     def __call__(self, query: str, parameters: dict = None) > str:         return self.generate(query, parameters) class StarCoder(GeneratorBase):     def __init__(self, pretrained: str):         self.pretrained: str = pretrained         self.pipe: Pipeline = pipeline(             ""textgeneration"", model=pretrained)         self.generation_config = GenerationConfig.from_pretrained(pretrained)         self.generation_config.pad_token_id = self.pipe.tokenizer.eos_token_id     def generate(self, query: str, parameters: dict) > str:         config: GenerationConfig = GenerationConfig.from_dict({             **self.generation_config.to_dict(),             **parameters         })         json_response: dict = self.pipe(query, generation_config=config)[0]         generated_text: str = json_response['generated_text']         return generated_text if __name__ == '__main__':     pretrained = 'bigcode/starcoder27b'     g = StarCoder(pretrained)     print(g('def fibonacci(n):', {'max_new_tokens': 10})) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 代码成功运行无报错 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. ```text Traceback (most recent call last):   File ""/home/daiyuxin/xyr/mindnlpprojects/huggingfacevscodeendpointserver/tests_ms.py"", line 22, in test_starcoder     g = StarCoder(pretrained)   File ""/home/daiyuxin/xyr/mindnlpprojects/huggingfacevscodeendpointserver/generators_ms.py"", line 38, in __init__     self.pipe: Pipeline = pipeline(   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/pipelines/__init__.py"", line 570, in pipeline     tokenizer = AutoTokenizer.from_pretrained(   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/models/auto/tokenization_auto.py"", line 775, in from_pretrained     return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_base.py"", line 1723, in from_pretrained     return cls._from_pretrained(   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_base.py"", line 1942, in _from_pretrained     tokenizer = cls(*init_inputs, **init_kwargs)   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/models/gpt2/tokenization_gpt2_fast.py"", line 134, in __init__     super().__init__(   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_fast.py"", line 154, in __init__     tokens_to_add = [   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_fast.py"", line 157, in      if token not in self.added_tokens_decoder   File ""/home/daiyuxin/miniconda3/envs/xyr_ms2.2.12/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_fast.py"", line 228, in added_tokens_decoder     return self._tokenizer.get_added_tokens_decoder() AttributeError: 'tokenizers.Tokenizer' object has no attribute 'get_added_tokens_decoder' ``` **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-05-14T11:10:26Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1074,"0.3.1可以用这个方式加速 """"""python pipeline(""textgeneration"", model=pretrained, mirror='modelscope') """"""",tokenizers版本太低了，装个新版
这个issue类型是用户提出需求，主要对象是支持prompt_tuning。原因可能是用户希望mindnlp支持prompt_tuning功能。,support prompt_tuning,,2024-05-14T06:51:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1073
这是一个bug报告，涉及主要对象是flash_attn kernel，由于精度错误导致症状问题。,fix precision error of flash_attn kernel in some case,modified the initialization code in forward kernel,2024-05-14T06:04:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1072
这个issue属于用户提出需求类型，主要涉及使用mkdocs生成文档，可能是由于现有文档不清晰或希望改善文档呈现方式而提出。,use mkdocs to generate documentation,,2024-05-13T04:09:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1070
这是一个用户提出需求的类型，该问题单涉及主要对象是需添加教程快速入门。这个问题由于项目缺乏入门指导，用户希望能有一份快速入门教程来帮助新用户快速上手。,Add tutorial quick start,,2024-05-11T13:40:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1069
这是一个bug报告，涉及到BaseTunerLayer类的get_base_layer()方法导致Python对象递归深度超过最大限制。,BaseTunerLayer类的get_base_layer()方法循环调用导致Python对象时超过的最大递归深度。,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在微调模型时候，出现了因为BaseTunerLayer类的get_base_layer()方法的循环引用，导致调用Python对象时超过的最大递归深度。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:GPU > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.11  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填): ```  出问题的内部代码 class BaseTunerLayer(ABC):     def get_base_layer(self) > nn.Cell:         base_layer = self         while hasattr(base_layer, ""base_layer""):             base_layer = base_layer.base_layer         return base_layer          def weight(self) > Tensor:          This is required for some transformers code, e.g. for T5, weight is accessed as:              self.wo.weight          where ""wo"" is the adapter layer.          https://github.com/huggingface/transformers/blob/78f6ed6c70b29c1560780e3869a7ad4c6b3d2710/src/transformers          /models/t5/modeling_t5.pyL292         base_layer = self.get_base_layer()         weight = base_layer.weight         return weight ``` **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: > 对MindNLP进行编包装包 > 然后在mindnlp/llm/peft/里面选择一个模型放到一个新的目录下 > 使用有MindNLP包的环境执行里面的train.py进行微调训练，例子如下： > $ ./run_peft.sh **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)**  (yy_env) daiyuxin:/data1/yy/train_gpt_bigcode$ ./run_peft.sh  Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.614 seconds. Prefix dict has been built successfully. /home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0. You can remove this warning by passing 'token=' instead.   warnings.warn( Size of the train set: 5875. Size of the validation set: 30   0% 400/400 00:03     main(args)   File ""/data1/yy/train_gpt_bigcode/train.py"", line 171, in main     model = get_peft_model(model, peft_config)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/mapping.py"", line 97, in get_peft_model     return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 390, in __init__     super().__init__(model, peft_config, adapter_name)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/peft_model.py"", line 80, in __init__     self.base_model = PEFT_TYPE_TO_MODEL_MAPPINGpeft_config.peft_type.__init__(model, config, adapter_name)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 100, in __init__     self.inject_adapter(self.model, adapter_name)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 250, in inject_adapter     self._create_and_replace(peft_config, adapter_name, target, target_name, parent, **optionnal_kwargs)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/lora.py"", line 262, in _create_and_replace     new_module = self._create_new_module(lora_config, adapter_name, target, **kwargs)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/lora.py"", line 539, in _create_new_module     new_module = Linear(adapter_name, in_features, out_features, has_bias=bias, **kwargs)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/lora.py"", line 691, in __init__     nn.Dense.__init__(self, in_features, out_features, **kwargs)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/injection.py"", line 587, in __init__     self.weight = Parameter(initializer(   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 966, in __setattr__     self._set_attr_for_parameter(name, value)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 859, in _set_attr_for_parameter     self.insert_param_to_cell(name, value)   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1224, in insert_param_to_cell     if hasattr(self, param_name) and param_name not in self._params:   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 329, in weight     weight = base_layer.weight   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 329, in weight     weight = base_layer.weight   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 329, in weight     weight = base_layer.weight   [Previous line repeated 974 more times]   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 328, in weight     base_layer = self.get_base_layer()   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindnlp/peft/tuners/tuners_utils.py"", line 317, in get_base_layer     while hasattr(base_layer, ""base_layer""):   File ""/home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 440, in __getattr__     ""The '{}' object has no attribute '{}'."".format(type(self).__name__, name) RecursionError: maximum recursion depth exceeded while calling a Python object **Additional context / 备注 (Optional / 选填)**",2024-05-10T01:48:10Z,bug,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1068,具体的例子是哪个？,> 具体的例子是哪个？ falcon和gpt都会这样,fixed,"> **Describe the bug/ 问题描述 (Mandatory / 必填)** 在微调模型时候，出现了因为BaseTunerLayer类的get_base_layer()方法的循环引用，导致调用Python对象时超过的最大递归深度。 >  > * **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:GPU >  > > Please delete the backend not involved / 请删除不涉及的后端: > > /device ascend/GPU/CPU/kirin/等其他芯片 >  > * **Software Environment / 软件环境 (Mandatory / 必填)**: >    MindSpore version (e.g., 1.7.0.Bxxx) :2.2.11 >    Python version (e.g., Python 3.7.5) :3.9 >    OS platform and distribution (e.g., Linux Ubuntu 16.04): >    GCC/Compiler version (if compiled from source): > * **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: >  > > Please delete the mode not involved / 请删除不涉及的模式: > > /mode pynative > > /mode graph >  >  Related testcase / 关联用例 (Mandatory / 必填): > ``` >  出问题的内部代码 > class BaseTunerLayer(ABC): >     def get_base_layer(self) > nn.Cell: >         base_layer = self >         while hasattr(base_layer, ""base_layer""): >             base_layer = base_layer.base_layer >         return base_layer >  >      >     def weight(self) > Tensor: >          This is required for some transformers code, e.g. for T5, weight is accessed as: >              self.wo.weight >          where ""wo"" is the adapter layer. >          https://github.com/huggingface/transformers/blob/78f6ed6c70b29c1560780e3869a7ad4c6b3d2710/src/transformers >          /models/t5/modeling_t5.pyL292 >         base_layer = self.get_base_layer() >         weight = base_layer.weight >         return weight > ``` >  > **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: >  > > 对MindNLP进行编包装包 > > 然后在mindnlp/llm/peft/里面选择一个模型放到一个新的目录下 > > 使用有MindNLP包的环境执行里面的train.py进行微调训练，例子如下： > > $ ./run_peft.sh >  > **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. >  > **Screenshots/ 日志 / 截图 (Mandatory / 必填)** (yy_env) daiyuxin:/data1/yy/train_gpt_bigcode$ ./run_peft.sh Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.614 seconds. Prefix dict has been built successfully. /home/daiyuxin/miniconda3/envs/yy_env/lib/python3.9/sitepackages/datasets/load.py:2516: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0. You can remove this warning by passing 'token=' instead. warnings.warn( Size of the train set: 5875. Size of the validation set: 30 0% 400/400 [00:03  > **Additional context / 备注 (Optional / 选填)** 我也遇到了 请问解决了吗 ？"
这是一个缺少内容的bug报告，该问题涉及的主要对象是mindnlp库，由于内容缺失导致了无法有效识别问题，需要进一步补充详细信息。,Peft lokr support,,2024-05-09T12:07:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1067,peft trainable parameters： !image mindnlp trainable parameters: !image peft demo result: !image mindnlp demo result: !image
这是一个用户提出需求的类型的issue，主要对象是添加音乐生成器到gradio演示。,add musicgen gradio demo,,2024-05-08T16:48:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1066
这是一个bug报告类型的issue，涉及主要对象是执行ut test_modeling_graph_chatglm.py脚本。由于反序列化报错，导致出现了bug症状。,执行ut test_modeling_graph_chatglm.py反序列化报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 用例顺利执行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. self =           def test_chat(self): >       model, tokenizer = get_model_and_tokenizer() tests/ut/transformers/models/chatglm/test_modeling_graph_chatglm.py:57: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ tests/ut/transformers/models/chatglm/test_modeling_graph_chatglm.py:45: in get_model_and_tokenizer     model = MSChatGLMForConditionalGeneration.from_pretrained(""THUDM/chatglm6b"").half() mindnlp/transformers/modeling_utils.py:1185: in from_pretrained     state_dict = load_ckpt(name) mindnlp/transformers/modeling_utils.py:1065: in load_ckpt     state_dict = load(resolved_archive_file) mindnlp/utils/serialization.py:349: in load     return _legacy_load(opened_file, pickle_module, **pickle_load_args) ....... >       magic_number = pickle_module.load(f, **pickle_load_args) E       _pickle.UnpicklingError: invalid load key, '<'. mindnlp/utils/serialization.py:433: UnpicklingError **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-05-08T08:53:06Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1065,应该是下载了无法连接网站的网页了
该issue类型为用户需求，主要涉及的对象是支持phi3，用户要求添加对phi3的支持。,support phi3,,2024-05-06T13:09:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1064
这个issue属于用户提出需求类别，主要对象是添加gsm8k prompt示例。可能是用户希望在mindnlp中添加gsm8k prompt示例用于文本生成。,add gsm8k prompt example,,2024-05-06T09:43:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1063
"这是一个bug报告类型的issue，主要涉及""whisper-tiny""模块，用户无法获取简中推理结果。可能是由于程序逻辑错误或设置问题导致。",whisper-tiny无法输出简中,"无法返回简中推理结果，使用以下代码： ```import time import mindspore as ms  指定设备 ms.set_context(device_target=""Ascend"", device_id=1) from mindnlp.transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline model_id = ""openai/whispertiny"" model = AutoModelForSpeechSeq2Seq.from_pretrained(     model_id, ms_dtype=ms.float16, low_cpu_mem_usage=True, use_safetensors=True, ) processor = AutoProcessor.from_pretrained(model_id) pipe = pipeline(     ""automaticspeechrecognition"",     model=model,     tokenizer=processor.tokenizer,     feature_extractor=processor.feature_extractor,     max_new_tokens=128,     chunk_length_s=30,     batch_size=16,     return_timestamps=True,     ms_dtype=ms.float16, ) sample = ""/test.wav"" start_time = time.time() prompt = ""以下是普通话的句子。"" result = pipe(sample, generate_kwargs={""language"": ""zh"", ""initial_prompt"": prompt}) end_time = time.time() execution_time = end_time  start_time print(result) print(f""推理执行时间: {execution_time}秒"") ```",2024-05-06T05:27:33Z,bug,closed,0,8,https://github.com/mindspore-lab/mindnlp/issues/1062,好像这个模型就是不支持中文的吧,> 好像这个模型就是不支持中文的吧 支持中文的。 https://github.com/openai/whisper/discussions/277,我测一下看看，mindspore版本、mindnlp版本提供一下,> 我测一下看看，mindspore版本、mindnlp版本提供一下 mindnlp==0.2.4 mindspore==2.3.0rc1,2.3我还真没测过，我看看哈,> > 我测一下看看，mindspore版本、mindnlp版本提供一下 > > mindnlp==0.2.4 > > mindspore==2.3.0rc1 你打印的结果也给附一下吧,"> > > 我测一下看看，mindspore版本、mindnlp版本提供一下 > > > mindnlp==0.2.4 > > > mindspore==2.3.0rc1 >  > 你打印的结果也给附一下吧 `/root/miniconda3/envs/whisper/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /root/miniconda3/envs/whisper/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /root/miniconda3/envs/whisper/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /root/miniconda3/envs/whisper/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 0.962 seconds. Prefix dict has been built successfully. Special tokens have been added in the vocabulary, make sure the associated word embeddings are finetuned or trained. {'text': '有些变车的一些促易啊而是在跟大家一些过程所的一场上我们传统的就是断盗就是我们认为它的理解性能选择比较好的因为它这个点还有这种半节经过的这种股然后它断盗的过程中对于这种变形它我有这种精神的这种没有骗成自己在理解性能体制中然后最终它币来说呢就是它币里边会有这种就是结果这主要是融化对融化来说呢在里边它是有这种体系的这种加热融化然后说呢他在那边他是用这种起决动加热融化然后他在不同的温度上面他要有这种属次经历的一个不同所以他这边他是他是他的一个居民的这种然后接触的这种主席过来真的错了然后他的这种然后他这个变灭呢就是我们要考虑主持的接铲的動作接铺真的錯差了主持的然後它的這種然後它這個屁裡面呢就是我們要考慮一個前方合適的這種看貼的融化看的時候一樣考慮它這裡面不同的這種它變得很公異啊是抗後然後對它平平平平的熱水一樣所以改一下我們这个组织的核心的上层体的一些确面这种压传的因为它这种温度比较低它没有刀子的蜜蜂刀的温度所以它的这种这种气氛和会消灭好的一些然后对我们的先传的它是这种我们的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那裡的那種它是在那所以他就主持在植住台中整体的彈奖就是听一台就到接种时候又到这个木材所以他整体也是呈现所以天后来说他也是呈现不至于的那怎么来把算我们的这种想到來把這種天上的海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海就是他在这个通所就是不同的这种成品在这种公益上是他在公益设计的时候他会有关键关键的点数不同的不同的这体的方式在这种公益控制的这种公益上面他会有其关键的动作就是对付大了时候我们有节目关键要考虑的情况主席上的通常要考虑它的推体面是要重处的方便我不见拿出来吃所以它在面才要考虑这种生意体面它有它是我们教育部的微却教育部的这种方向就是确实我们公密上面也需要供好一些這些東西然後對我們的段道來說段道來說呢那幾你也要考慮不是這麼就是段道來稱為我怎麼把它取出來所以它這裡面也會有這種森姆面就是這個這個這個這個這個這個這個這幾年你這類似的一個就是康復的好有的方式然後還有這個半上的時候這裡面那些各種邊緣的工具或者整個安排也是先去說這個去找我的這種結構它是一些先做哪一個可能成体,再做哪一个,就是就是,今年要解冠,解冠,解冠里面的这种功气,然后要把其他可能成体,其他这种斜体,其他这种斜体,就需要考慮他這種判接的成績走他來自接合這種情緒如果是懂方判的話還要考慮他這個縣縣者什麼樣的就是判施的或者是按條這三個年還就是特別要做到半告 衝壓還有飯街集餐餐這個背景就是你選擇的這種毛病如果是直接選用其一台的話你就直接用這個集餐切形就是其實一些切學的即加工那些操作但是你又很就是用形態來進行但造的或者是進行從壓的這些操作但是它就把這個那些呢就是直接歸到我們這個毛批的�这种 直接规刀这种从而或者是这种 这种 按照的这个里面呢就是就我们在这里的这个分呢就是它是阿米这个 最终就是最终成現在這個毛屁它上一 它的下一部它是什麼夾動出來就是它是像它一個按這個人的它這個裡面呢就是它們成本就在前進方下這個原來是要被提搖走完使用的一些材料使用的一些場合跟那種還有主持以及它有防空的我們只用身材的產品身材的周期我們來教育然後是一身材的用體質用一些棒的樣子等等就是就是它有各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各受力主大的自動就是結構面或者是有一些邀請這種敗模樣變真了有這種邀請的情況是我們的護照的特別就是不結的這種明天就本吃著我們無論在這一般然後當然還有一些故意的�的这种重建就是它这种密写性能会更好一些但是杜杜杜就是这种建的它是做造性能就稍微稍微弱一点在这个红米上的小株炮裂然后小关�片呢就是灌片呢就比較遲喝就是有些效率比較普通發的這種明天所以說從沒了一下兩個類類啊或者是就是就是效率比較普雜它必須比較多的重載特的這種租的保險產品然後對於我們的宗壓電腦是不是它租的宗壓力然後這個租的貨物就是貨物比較平靈的運用產就是可以對它可以進行其中的一些變化它會在這裏製作可以接受一些其中的一些變化的不小心然後在我們的看見的話就是對於一些組織來提醒明天你看看其實大幅做的話可能做出來在這裡我們的期待的話就是要中小的一些一些些人的这个这些是对的就是不同的零件啊就是阿阿他有个小的这种关它有些畫面,比如說,第一位就是走感,這個明天,所以我们就要用这种影片的其实开始形容方面共产就是有一些背景到就是然后打过5D3的反馁要尝不过的这种节那是我们的电脑就是那它这种秀率它有大一小或者是有的有的还是秀受一些彎曲交变了一些彈課了多一些但是有的還要進行一些補充所以他們的這種怎麼辦就是受力的這種美景啊就不一樣來和美景就一樣那這邊就是一般的這種走感那個這種明天啊就是受測到的美的美景的比較符大一般的這種走感沒得這麼明天所測到的比例的類型的比較似的所以因為它的這種微協性能要求比較好的這個是類型的形形的方式通常會選用這種斷斷', 'chunks': [{'timestamp': (0.0, 3.0), 'text': '有些变车的一些促易啊'}, {'timestamp': (5.0, 7.6), 'text': '而是在跟大家一些过程所的一场上'}, {'timestamp': (8.0, 10.0), 'text': '我们传统的就是断盗'}, {'timestamp': (10.0, 14.0), 'text': '就是我们认为它的理解性能选择比较好的'}, {'timestamp': (14.0, 18.0), 'text': '因为它这个点还有这种半节经过的这种股'}, {'timestamp': (18.0, 22.0), 'text': '然后它断盗的过程中对于这种变形'}, {'timestamp': (22.0, 26.08), 'text': '它我有这种精神的这种没有骗成自己'}, {'timestamp': (26.08, 28.76), 'text': '在理解性能体制中'}, {'timestamp': (28.76, 31.48), 'text': '然后最终它币来说呢'}, {'timestamp': (31.48, 34.32), 'text': '就是它币里边会有这种'}, {'timestamp': (34.32, 37.24), 'text': '就是结果'}, {'timestamp': (37.24, 40.24), 'text': '这主要是融化'}, {'timestamp': (40.24, 41.56), 'text': '对融化来说呢'}, {'timestamp': (41.56, 44.48), 'text': '在里边它是有这种'}, {'timestamp': (44.48, 46.8), 'text': '体系的这种加热融化然后说呢他在那边他是用这种起决动加热融化'}, {'timestamp': (46.8, 49.28), 'text': '然后他在不同的温度上面'}, {'timestamp': (49.28, 53.24), 'text': '他要有这种属次经历的一个不同'}, {'timestamp': (53.24, 56.4), 'text': '所以他这边他是'}, {'timestamp': (56.4, 59.2), 'text': '他是他的一个居民的这种'}, {'timestamp': (59.2, 62.2), 'text': '然后接触的这种主席过来'}, {'timestamp': (62.2, 63.2), 'text': '真的错了'}, {'timestamp': (63.2, 65.38), 'text': '然后他的这种然后他这个变灭呢就是我们要考虑主持的接铲的動作接铺真的錯差了主持的然後它的這種'}, {'timestamp': (65.38, 67.94), 'text': '然後它這個屁裡面呢'}, {'timestamp': (67.94, 70.0), 'text': '就是我們要考慮'}, {'timestamp': (70.0, 72.16), 'text': '一個前方合適的這種'}, {'timestamp': (72.16, 73.04), 'text': '看貼的'}, {'timestamp': (73.04, 74.64), 'text': '融化看的時候一樣'}, {'timestamp': (74.64, 76.4), 'text': '考慮它這裡面不同的這種'}, {'timestamp': (76.4, 77.92), 'text': '它變得很公異啊'}, {'timestamp': (77.92, 78.7), 'text': '是'}, {'timestamp': (78.7, 79.58), 'text': '抗後'}, {'timestamp': (79.58, 81.5), 'text': '然後對它平平平平的熱水一樣'}, {'timestamp': (81.5, 88.0), 'text': '所以改一下我們这个组织的核心的上层体的一些确面'}, {'timestamp': (88.0, 90.0), 'text': '这种压传的'}, {'timestamp': (90.0, 93.0), 'text': '因为它这种温度比较低'}, {'timestamp': (93.0, 96.0), 'text': '它没有刀子的蜜蜂刀的温度'}, {'timestamp': (96.0, 101.0), 'text': '所以它的这种这种气氛和会消灭好的一些'}, {'timestamp': (101.0, 104.0), 'text': '然后对我们的先传的'}, {'timestamp': (104.0, 107.0), 'text': '它是这种我们的那種它是在那裡的那種'}, {'timestamp': (107.0, 109.0), 'text': '它是在那裡的那種'}, {'timestamp': (109.0, 111.0), 'text': '它是在那裡的那種'}, {'timestamp': (111.0, 113.0), 'text': '它是在那裡的那種'}, {'timestamp': (113.0, 115.0), 'text': '它是在那裡的那種'}, {'timestamp': (115.0, 116.0), 'text': '它是在那裡的那種'}, {'timestamp': (116.0, 117.0), 'text': '它是在那裡的那種'}, {'timestamp': (117.0, 118.0), 'text': '它是在那裡的那種'}, {'timestamp': (118.0, 119.0), 'text': '它是在那裡的那種'}, {'timestamp': (119.0, 120.0), 'text': '它是在那裡的那種'}, {'timestamp': (120.0, 127.0), 'text': '它是在那裡的那種它是在那所以他就主持在植住台中整体的彈奖'}, {'timestamp': (127.0, 132.0), 'text': '就是听一台就到接种时候又到这个木材'}, {'timestamp': (132.0, 135.0), 'text': '所以他整体也是呈现'}, {'timestamp': (135.0, 138.0), 'text': '所以天后来说他也是呈现不至于的'}, {'timestamp': (138.0, 166.14), 'text': '那怎么来把算我们的这种想到來把這種天上的海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海南海就是他在这个通所就是不同的这种成品在这种公益上是'}, {'timestamp': (166.14, 168.44), 'text': '他在公益设计的时候'}, {'timestamp': (168.44, 172.28), 'text': '他会有关键关键的点数不同的不同的'}, {'timestamp': (172.28, 173.74), 'text': '这体的方式'}, {'timestamp': (173.74, 177.4), 'text': '在这种公益控制的这种公益上面'}, {'timestamp': (177.4, 179.46), 'text': '他会有其关键的动作'}, {'timestamp': (179.46, 180.9), 'text': '就是对付大了时候'}, {'timestamp': (180.9, 186.72), 'text': '我们有节目关键要考虑的情况主席上的通常要考虑它的推体面'}, {'timestamp': (186.72, 193.84), 'text': '是要重处的方便我不见拿出来吃'}, {'timestamp': (193.84, 197.64), 'text': '所以它在面才要考虑这种生意体面'}, {'timestamp': (197.64, 200.0), 'text': '它有它是我们教育部的微却'}, {'timestamp': (200.0, 201.64), 'text': '教育部的这种方向'}, {'timestamp': (201.64, 204.44), 'text': '就是确实我们公密上面'}, {'timestamp': (204.44, 207.04), 'text': '也需要供好一些這些東西'}, {'timestamp': (207.04, 209.0), 'text': '然後對我們的段道來說'}, {'timestamp': (209.0, 210.4), 'text': '段道來說呢'}, {'timestamp': (210.4, 211.52), 'text': '那幾'}, {'timestamp': (211.52, 214.32), 'text': '你也要考慮不是這麼'}, {'timestamp': (214.32, 217.32), 'text': '就是段道來稱為我怎麼把它取出來'}, {'timestamp': (217.32, 220.72), 'text': '所以它這裡面也會有這種森姆面'}, {'timestamp': (220.72, 224.0), 'text': '就是這個'}, {'timestamp': (224.0, 225.0), 'text': '這個這個這個這個這個這個這幾年'}, {'timestamp': (225.0, 228.0), 'text': '你這類似的一個就是康復的'}, {'timestamp': (228.0, 230.0), 'text': '好有的方式'}, {'timestamp': (230.0, 232.0), 'text': '然後還有這個半上的時候'}, {'timestamp': (232.0, 235.0), 'text': '這裡面那些各種邊緣的工具'}, {'timestamp': (235.0, 236.0), 'text': '或者整個安排'}, {'timestamp': (236.0, 240.0), 'text': '也是先去說這個去找'}, {'timestamp': (240.0, 242.0), 'text': '我的這種結構'}, {'timestamp': (242.0, 248.26), 'text': '它是一些先做哪一個可能成体,再做哪一个,就是'}, {'timestamp': (248.26, 265.18), 'text': '就是,今年要解冠,解冠,解冠里面的这种功气,然后要把其他可能成体,其他这种斜体,其他这种斜体,就需要考慮他這種判接的成績走'}, {'timestamp': (265.18, 268.58), 'text': '他來自接合這種情緒'}, {'timestamp': (269.58, 271.7), 'text': '如果是懂方判的話'}, {'timestamp': (271.7, 275.62), 'text': '還要考慮他這個縣縣者什麼樣的'}, {'timestamp': (275.62, 279.2), 'text': '就是判施的或者是按條'}, {'timestamp': (292.0, 300.0), 'text': '這三個年還就是特別要做到半告 衝壓還有飯街集餐餐這個背景就是你選擇的這種毛病如果是直接選用其一台的話'}, {'timestamp': (300.0, 307.74), 'text': '你就直接用這個集餐切形就是其實一些切學的'}, {'timestamp': (307.74, 309.22), 'text': '即加工那些操作'}, {'timestamp': (309.22, 312.34), 'text': '但是你又很'}, {'timestamp': (312.34, 317.14), 'text': '就是用形態來進行'}, {'timestamp': (317.14, 320.86), 'text': '但造的或者是進行從壓的這些操作'}, {'timestamp': (320.86, 323.32), 'text': '但是它就把這個'}, {'timestamp': (323.32, 324.36), 'text': '那些呢'}, {'timestamp': (324.36, 329.94), 'text': '就是直接歸到我們這個毛批的�这种 直接规刀这种'}, {'timestamp': (329.94, 334.62), 'text': '从而或者是这种 这种 按照的这个里面呢'}, {'timestamp': (334.62, 336.9), 'text': '就是'}, {'timestamp': (337.9, 340.16), 'text': '就我们在这里的这个分呢'}, {'timestamp': (340.16, 343.7), 'text': '就是它是阿米这个 最终'}, {'timestamp': (343.7, 346.48), 'text': '就是最终成現在這個毛屁'}, {'timestamp': (346.92, 351.64), 'text': '它上一 它的下一部它是什麼夾動出來'}, {'timestamp': (351.64, 354.6), 'text': '就是它是像它一個按這個人的'}, {'timestamp': (355.36, 356.36), 'text': '它這個裡面呢'}, {'timestamp': (356.64, 358.56), 'text': '就是它們'}, {'timestamp': (359.2, 361.92), 'text': '成本就在前進方下'}, {'timestamp': (361.92, 363.76), 'text': '這個原來是要被提搖走完'}, {'timestamp': (363.76, 366.74), 'text': '使用的一些材料使用的一些場合'}, {'timestamp': (368.74, 369.24), 'text': '跟那種'}, {'timestamp': (369.96, 371.48), 'text': '還有主持以及'}, {'timestamp': (373.48, 374.4), 'text': '它有防空的'}, {'timestamp': (374.4, 375.96), 'text': '我們只用身材的產品'}, {'timestamp': (375.96, 377.0), 'text': '身材的周期'}, {'timestamp': (377.0, 377.92), 'text': '我們來教育'}, {'timestamp': (377.92, 379.2), 'text': '然後是一'}, {'timestamp': (379.72, 381.12), 'text': '身材的用體質'}, {'timestamp': (381.12, 382.72), 'text': '用一些棒的樣子'}, {'timestamp': (382.72, 383.36), 'text': '等等'}, {'timestamp': (383.36, 384.08), 'text': '就是'}, {'timestamp': (384.36, 386.0), 'text': '就是它有各自的可憐'}, {'timestamp': (386.0, 387.0), 'text': '是在這種各自的可憐是在這種各自的可憐'}, {'timestamp': (387.0, 389.0), 'text': '是在這種各自的可憐'}, {'timestamp': (389.0, 409.0), 'text': '是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各自的可憐是在這種各受力主大的自動就是結構面或者是有一些邀請這種敗模樣'}, {'timestamp': (409.0, 410.0), 'text': '變真了'}, {'timestamp': (410.0, 413.0), 'text': '有這種邀請的情況'}, {'timestamp': (413.0, 418.0), 'text': '是我們的護照的特別就是不結的這種明天'}, {'timestamp': (418.0, 421.0), 'text': '就本吃著我們無論在這一般'}, {'timestamp': (421.0, 426.14), 'text': '然後當然還有一些故意的�的这种重建就是'}, {'timestamp': (426.14, 429.22), 'text': '它这种密写性能会更好一些'}, {'timestamp': (429.22, 432.54), 'text': '但是杜杜杜就是这种建的'}, {'timestamp': (432.54, 436.38), 'text': '它是做造性能'}, {'timestamp': (436.38, 439.72), 'text': '就稍微稍微弱一点'}, {'timestamp': (439.72, 444.32), 'text': '在这个红米上的小株炮裂'}, {'timestamp': (444.32, 446.0), 'text': '然后小关�片呢'}, {'timestamp': (446.0, 450.0), 'text': '就是灌片呢就比較遲喝'}, {'timestamp': (450.0, 455.0), 'text': '就是有些效率比較普通發的這種明天'}, {'timestamp': (455.0, 458.0), 'text': '所以說從沒了一下兩個類類啊'}, {'timestamp': (458.0, 462.0), 'text': '或者是就是'}, {'timestamp': (462.0, 469.44), 'text': '就是效率比較普雜它必須比較多的重載特的這種租的保險產品'}, {'timestamp': (469.44, 472.0), 'text': '然後對於我們的宗壓電腦是不是'}, {'timestamp': (472.0, 474.36), 'text': '它租的宗壓力'}, {'timestamp': (474.36, 479.52), 'text': '然後這個租的貨物就是貨物比較平靈的運用產'}, {'timestamp': (479.52, 483.08), 'text': '就是可以對它可以進行其中的一些變化'}, {'timestamp': (483.08, 487.34), 'text': '它會在這裏製作可以接受一些其中的一些變化的不小心然後在我們的看見的話'}, {'timestamp': (487.34, 491.62), 'text': '就是對於一些組織來提醒明天'}, {'timestamp': (491.62, 492.8), 'text': '你看看'}, {'timestamp': (492.8, 496.4), 'text': '其實大幅做的話可能做出來'}, {'timestamp': (496.4, 499.6), 'text': '在這裡我們的期待的話'}, {'timestamp': (499.6, 503.66), 'text': '就是要中小的一些'}, {'timestamp': (503.66, 506.8), 'text': '一些些人的这个'}, {'timestamp': (514.8, 517.4), 'text': '这些是对的'}, {'timestamp': (517.4, 520.2), 'text': '就是不同的零件啊'}, {'timestamp': (520.2, 521.64), 'text': '就是阿阿'}, {'timestamp': (521.64, 546.0), 'text': '他有个小的这种关它有些畫面,比如說,第一位就是走感,這個明天,所以我们就要用这种影片的其实开始形容方面共产就是有一些背景到'}, {'timestamp': (546.0, 549.0), 'text': '就是然后打过5D3的反馁'}, {'timestamp': (549.0, 552.0), 'text': '要尝不过的这种节'}, {'timestamp': (552.0, 554.0), 'text': '那是我们的电脑'}, {'timestamp': (554.0, 555.0), 'text': '就是'}, {'timestamp': (555.0, 558.0), 'text': '那它这种秀率'}, {'timestamp': (558.0, 560.0), 'text': '它有大一小'}, {'timestamp': (560.0, 563.0), 'text': '或者是有的'}, {'timestamp': (563.0, 566.14), 'text': '有的还是秀受一些彎曲'}, {'timestamp': (566.14, 567.68), 'text': '交变了一些彈課了'}, {'timestamp': (567.68, 568.64), 'text': '多一些'}, {'timestamp': (568.64, 571.0), 'text': '但是有的還要進行一些補充'}, {'timestamp': (571.0, 572.5), 'text': '所以他們的這種'}, {'timestamp': (572.5, 574.2), 'text': '怎麼辦'}, {'timestamp': (574.2, 575.7), 'text': '就是受力的這種'}, {'timestamp': (575.7, 576.5), 'text': '美景啊'}, {'timestamp': (576.5, 577.3), 'text': '就不一樣'}, {'timestamp': (577.3, 578.24), 'text': '來和美景'}, {'timestamp': (578.24, 579.0), 'text': '就一樣'}, {'timestamp': (579.0, 580.1), 'text': '那這邊'}, {'timestamp': (580.1, 581.1), 'text': '就是'}, {'timestamp': (581.1, 582.8), 'text': '一般的這種走感'}, {'timestamp': (582.8, 584.0), 'text': '那個這種明天啊'}, {'timestamp': (584.0, 586.0), 'text': '就是受測到的美的美景的比較符大一般的這種走感沒得這麼明天'}, {'timestamp': (589.0, 593.0), 'text': '所測到的比例的類型的比較似的所以因為它的這種微協性能要求比較好的'}, {'timestamp': (593.0, 599.0), 'text': '這個是類型的形形的方式通常會選用這種斷斷'}]} 推理执行时间: 235.3162121772766秒 `",我在huggingface下载的文件，代码就一直报safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooLarge，是文件没下全么
这是一个用户提出需求的类型，主要涉及添加openELM模型。可能是由于openELM模型尚未集成到项目中，用户希望能添加这个新模型。,add openelm model,,2024-05-02T06:18:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1061
这是一个bug报告，用户反映whisper推理速度问题。,whisper推理速度问题,服务器：Atlas 800 (9000) 推理卡：Ascend910ProB * 8  version mindnlp==0.2.4 mindspore==2.2.0  问题描述： whisper推理速度太慢，10s的视频耗时60s，请问这个是正常的吗？还是说需要加速框架支持？  !image,2024-04-30T08:38:15Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1060,使用mindspore2.3试试,> 使用mindspore2.3试试 谢谢，有效！切换到了mindspore2.3， 10分钟音频推理耗时20分钟，这个算是正常速度吗？
该issue属于bug报告类型，主要涉及lora layer中继承BaseTunerLayer导致的功能重定义问题。,Fix lora Error,之前lora layer继承BaseTunerLayer，并重定义了BaseTunerLayer的功能，ia3算法pr中将BaseTunerLayer完全移植过来，导致了冲突，lora算法无法训练，出现这个 https://gitee.com/mindspore/community/issues/I9JPA5?from=projectissue issue中问题，先暂时将loralayer父类BaseTunerLayer去掉，可以正常运行，不影响lora功能，后续将lora算法重写一下,2024-04-30T02:34:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1059
这是一个功能需求提出的issue，主要对象是Huggingface PEFT中的add_adapter接口。由于MindNLP当前不支持add_adapter接口导致存在功能缺失。,PEFT中的add_adapter接口,Huggingface PEFT教程 中用到了add_adapter接口。 MindNLP目前似乎不支持。 MindNLP现有的PEFT样例代码用的是get_peft_model 可以考虑加上add_adapter的支持。,2024-04-29T13:55:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1058
该issue类型为用户提出需求，需要加速初始化操作；主要对象是mindnlp项目。由于用户需求在项目初始化阶段操作速度较慢，需要加速处理。,init accelerate,,2024-04-27T11:50:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1057
这是一个功能需求问题，主要涉及下载功能，用户提出了需求支持断点续传下载。,support resume download,,2024-04-27T10:08:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1056
这是一个用户提出需求的issue，主要涉及添加convnext、cvt、resnet和van模型。,"add convnext, cvt, resnet and van model",,2024-04-26T15:50:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1055
这是一个用户提出需求类型的issue，主要对象是MindNLP介绍PPT。由于缺少具体内容导致用户无法了解MindNLP的相关信息，请求提供介绍PPT。,MindNLP介绍PPT,,2024-04-26T13:34:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1054
这是一个用户提出需求的issue，主要涉及的对象是设计新的张量。由于目前的模块不包括设计张量的核心模块，用户希望增加一个核心模块来设计新的张量。,add core module to design a New Tensor,,2024-04-26T10:08:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1053
这是一个用户提出需求的issue，主要涉及对象是mindnlp库，用户提出了支持类bitsandbytes的量化能力。,支持类bitsandbytes的量化能力,,2024-04-26T10:07:44Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1052
这个issue类型是需求提出，主要对象是支持huggingface、modelscope、openmind、wisemodel等平台的模型上传。,支持huggingface、modelscope、openmind、wisemodel等平台的模型上传,,2024-04-26T10:07:22Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/1051
这是一个需求类型的issue，主要涉及到实习任务地址的问题，可能是用户寻求关于实习任务地址的帮助。,Peft adalora,实习任务地址：https://gitee.com/mindspore/community/issues/I9C04J?from=projectissue 原版训练参数： !image 移植训练参数： !image 原版训练效果： !image 移植训练效果： !image,2024-04-26T08:31:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1050
这是一个bug报告，主要涉及mindnlp中的actions功能，可能由于错误的实现导致了bug。,fix actions error,,2024-04-25T09:02:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1049
这个issue类型是bug报告，该问题单涉及的主要对象是t5和llava，由于未提供具体内容，无法分析具体原因和症状。,fix t5 & llava,,2024-04-25T03:36:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1048
这是一个需求类型的issue，主要涉及迁移hf的llava_next llava 和vipllava模型。由于用户希望迁移这两个模型，可能是因为需要进行模型更新或者优化。,迁移hf的llava_next llava 和vipllava模型,,2024-04-24T04:39:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1047
这个issue是关于模型迁移的需求，主要涉及的对象是名为llava-next、llava和vipllava的三个模型。由于原有模型无法满足需求或者有更好的模型可供使用，导致用户提出迁移到新模型的需求。,迁移hf的llava-next llava vipllava三个模型,,2024-04-24T04:00:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1046
这个issue类型是需求提出，该问题涉及的主要对象是增加modelscope & wisemodel endpoint。,add modelscope & wisemodel endpoint,,2024-04-23T15:48:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1045
这个issue属于需求类型，该问题单涉及的主要对象是mindnlp库中的convbert模型；由于需要在convbert模型中添加数据并行处理，用户提出了这个需求。,Add convbert data parallel,,2024-04-23T14:08:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1044
这个issue类型为功能请求，主要对象是支持HuggingFace镜像。该问题由于缺乏对HuggingFace镜像的支持而导致功能无法实现。,support huggingface mirrors,,2024-04-23T12:44:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1043
这个issue是用户提出需求，涉及主要对象是为MindNLP设计的微调模块Adaption Prompt。这个问题由于缺少model directory导致用户需要为Adaption Prompt微调模块引入可训练的提示（Prompts）时遇到困难。,Add model directory,Adaption Prompt 微调模块 Adaption Prompt 是一个专为 MindNLP 设计的微调模块，旨在通过引入可训练的提示（Prompts）来增强预训练模型的任务适应性。这种方法基于最新的研究成果，通过在模型的输入阶段或内部结构中插入少量的可学习参数，即“提示”，来指导模型更好地适应下游特定任务。 主要特点 灵活性增强： Adaption Prompt 允许用户在不同层级和位置插入提示，从而为不同的模型架构和任务需求提供高度的自定义能力。 效率提升： 与传统的完全微调相比，Adaption Prompt 通过仅训练极少数额外引入的参数，显著减少了训练的资源消耗和时间成本，同时避免了过拟合的风险。 易于集成： 设计为与 MindNLP 现有的模型和架构无缝集成，用户可以通过简单的API调用启用或配置提示功能，无需改动现有的代码结构。 广泛的适用性： 支持多种类型的NLP任务，包括但不限于文本分类、情感分析、问答系统和语言生成等。 下面是在MindSpore Huggingface Transformers使用Adaption Prompt 进行微调的示例和参数结果  下面是在Huggingface peft使用Adaption Prompt 进行微调的示例和参数结果  可以看到两者结果一致，说明迁移成功,2024-04-22T00:27:52Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1042,pylint必须过,> pylint必须过 安装pylint的要求改了，请您再测试一下pylint
这是一个bug报告类型的issue，主要涉及flash_attn_bwd的更新问题。原因可能是在更新过程中出现了错误导致bug或者问题。,update flash_attn_bwd,,2024-04-21T15:19:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1041
这是一个用户提出需求的issue，主要对象是t5_finetune。由于用户需要进一步细化和确认t5_finetune内容，因此提出了这个issue。,t5_finetune,t5_finetune_v1,2024-04-20T16:08:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1040
这是一个需求提出类型的issue，主要涉及到olmo支持的问题。原因可能是出于扩展或增强功能的目的，用户提出了对olmo的支持需求。,support olmo,,2024-04-20T11:12:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1039
此issue类型为功能需求，主要对象是MPT Model。由于模型可能存在更新或改进的需求，用户提出了更新MPT Model的请求。,update MPT Model,,2024-04-20T04:38:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1038
"这是一个bug报告，主要涉及""load ckpt""错误，由于路径中包含'ckpt'导致bug。",fix load ckpt error when path include 'ckpt',,2024-04-20T03:49:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1037
这是一个需求提出类型的issue，主要涉及MindNLP中添加一个类似torch.amp的新amp模块，使用autocast代替amp level。原因可能是为了提供更方便和灵活的自动混合精度训练方法。,"add new amp module like torch.amp, usse autocast instead of amp level",,2024-04-20T02:38:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1036
这个issue是一个功能需求类型，涉及主要对象为starcoder with llm-vscode。很可能是用户在该项目中缺少示例代码，因此提出添加此功能的请求。,add an example of starcoder with llm-vscode,**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.,2024-04-20T02:19:29Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1035
这是一个需求类型的issue，主要涉及mindnlp下的Mpt Model。由于用户需要添加Mpt Model，因此提出了这个需求。,add Mpt Model,,2024-04-19T13:45:33Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1034,pylint没过
"这是一个用户提出需求的类型，该问题单涉及的主要对象为""ia3微调模块""，用户寻求开发这个模块的帮助。",add ia3 peft,【开源实习】ia3微调模块开发 https://gitee.com/mindspore/community/issues/I97V50?from=projectissue peft demo !image mindnlp demo !image peft demo results !image mindnlp demo results !image,2024-04-19T13:30:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1033
这个issue类型是功能需求，主要涉及Mindnlp项目中添加对llama3的支持。由于llama3现在还不被支持，用户提出了这个需求。,add llama3 support,,2024-04-19T06:43:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1032
这是一个bug报告，主要涉及AutoModelForCausalLM传入模型路径时报错，请传入.ckpt。导致该问题的原因是传入的模型路径文件格式不正确。,在使用AutoModelForCausalLM传入llama3模型路径使用bin加载时，报错请传入.ckpt,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 在使用`AutoModelForCausalLM`传入模型路径使用bin加载时，报错请传入`.ckpt`  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.13.20240327  Python version (e.g., Python 3.7.5) :3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04 **To Reproduce / 重现步骤 (Mandatory / 必填)** 运行以下代码: ```python from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM model_dir='./ckpt/LLMResearch/MetaLlama38B' tokenizer = AutoTokenizer.from_pretrained(model_dir) model = AutoModelForCausalLM.from_pretrained(model_dir, use_safetensors=True) input_text = ""Write me a poem about Machine Learning."" input_ids = tokenizer(input_text, return_tensors=""ms"") outputs = model.generate(**input_ids) print(tokenizer.decode(outputs[0])) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 正常加载并且成功运行 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image",2024-04-19T06:37:20Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1031
这是一个bug报告，涉及到Map_fn和ops.dropout导致训练速度错误的问题。,fix map_fn error & ops.dropout caused training speed error,,2024-04-18T09:36:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1030
这是一个用户提出需求的类型，主要涉及到希望提供COT推理的代码样例。询问的原因可能是想要用llama模型基于GSM8K数据集和CommonsenseQA进行推理。,希望可以提供COT推理的代码样例,能否提供基于mindspore版本开源llama模型的chainofthought 推理的代码样例呢，比如说基于GSM8K数据集和CommonsenseQA等数据集构建思维链推理的模板做一些测试，感谢！,2024-04-17T12:37:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1029
这是一个用户需求类型的issue，主要涉及到mindnlp库中关于prompt tuning代码样例的需求。由于当前教程中未提供prompt tuning的代码示例，用户希望能够得到相关示例以便实现该功能。,希望可以提供prompt tuning的代码样例,在当前关于prompt的教程中https://github.com/mindsporecourses/step_into_llm/tree/master/Season1.step_into_chatgpt/7.Prompt 并没有prompt tuning的代码（将自然语言形式的prompt template替换成soft prompt，仅仅对soft prompt的embedding进行训练），方便的话能否提供一下prompt tuning的代码样例呢，感谢！,2024-04-17T12:33:16Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1028,https://github.com/mindsporelab/mindnlp/blob/master/llm%2Fpeft%2Fprompt_tuning%2Froberta_sequence_classification.ipynb
这是一个bug报告，涉及的主要对象是Mindnlp的Trainer，导致的症状是在不设置map_fn的情况下运行时报错。,"Trainer support map_fn后不支持不设置map_fn,运行bert_emotect_finetune.ipynb报错","**Describe the bug/ 问题描述 (Mandatory / 必填)** Trainer support map_fn后不支持不设置map_fn,运行bert_emotect_finetune.ipynb报错  **Hardware Environment(`GPU`)  / 硬件环境**: >/GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 2.2.13) :  Python version (e.g., Python 3.8.10) :  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** 运行bert_emotect_finetune.ipynb，加上map_fn不报错 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !59f1b000b05a07415a52c5bf6130e776 !b5f90a9549b1b34cbb58ac245f9ad490",2024-04-17T11:21:56Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1027
这个issue类型是bug报告，涉及主要对象是flash_attn_v2模块。由于未提供具体内容，无法分析具体问题导致的原因。,update flash_attn_v2,,2024-04-17T09:26:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1026
这是一个空白的issue，类型无法确定。,update flash_attn_v2,,2024-04-17T09:10:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1025
这是一个用户提出需求的issue，主要涉及的对象是Mixtral 8x7B模型。由于尚未进行Mixtral 8x7B模型的适配，导致用户无法在910A上部署该模型，希望能够获得适配模型的代码。,希望可以提供Mixtral 8x7B模型适配版本,客户想在910A上部署Mixtral 8x7B模型，但是我们还没有进行Mixtral 8x7B的适配，希望可以提供Mixtral 8x7B适配模型代码,2024-04-17T01:31:27Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1024,看下这个仓，https://github.com/lvyufeng/mistralmindspore
这是一个用户提出需求的issue，主要涉及mindnlp库不支持stream_generate功能。这可能导致用户无法使用该功能，需要开发人员提供支持。,mindnlp不支持stream_generate，影响使用，麻烦开发支持，谢谢,mindnlp不支持stream_generate，影响使用，麻烦开发支持，谢谢,2024-04-17T01:00:41Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/1023,我记得支持啊，报错和用例附一下
这个issue是用户提出需求，希望Trainer能够支持'map_fn'，并添加bloom finetune示例。,Trainer support 'map_fn'  & add bloom finetune example,,2024-04-16T15:03:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1022
这是一个bug报告，主要涉及到mindnlp项目中的chatglm3-cli_demo.py脚本。由于某种原因导致用户在直接拉取chatglm36b32k时出现报错。,应用chatglm3-cli_demo.py直接拉取报错，麻烦协助看下,用此级目录下的cli_demo.py，直接拉chatglm36b32k： !image chatglm36b32k目录如下： !image 出现报错： !image 使用的是910b64G单卡，请麻烦看看。,2024-04-16T09:02:25Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/1021,附上mindspore、mindnlp版本,> 附上mindspore、mindnlp版本 mindspore=2.2.0 mindnlp=0.2.4 python=3.9.0,mindspore升级到2.2.1113,使用mindspore2.3
这个issue属于用户提出需求类型，主要涉及的对象是Trainer，由于当前的限制导致用户希望Trainer能够支持data_collator操作。,希望Trainer支持data_collator,**虽然mindspore的dataset支持per_batch_map操作，但是per_batch_map的输入仅支持list[numpy.ndarray]类型，不能适应各种nlp任务的需求，希望可以像hf transformers库的Trainer一样支持data_collator**,2024-04-16T08:42:07Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1020,因为MindSpore的dataset机制不同，这里我们会设计一个map_fn的入参,已支持，参考：https://github.com/mindsporelab/mindnlp/blob/master/llm/finetune/bloom/bloom_alpaca.py
这是一个bug报告，该问题单涉及的主要对象是Pegasus，由于错误导致Pegasus在使用过程中出现了问题。,fix pegasus ut error,,2024-04-16T07:40:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1019
这是一个bug报告，该问题涉及mindnlp套件的本地快速拉起推理失败。由于硬件及软件环境和启动代码可能导致了推理失败的症状。,使用mindnlp套件本地快速拉起推理失败，麻烦协助,我使用的是910b双卡，mindspore=2.2.0，python=3.9.0，我的启动代码如下： !a831a17d_13741193 我使用的模型是Qwen1.532BChatInt4，从hf获取的safetensors版本，具体结构如下所示： !c4c5d799_13741193 使用我的启动代码运行后，系统提示“TypeError: init() got an unexpected keyword argument 'torch_dtype'”，具体实现过程如下所示： !730b44a4_13741193 劳烦协助排查下这个错误该如何修正？谢谢。,2024-04-15T14:51:31Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1018,torch_dtype → ms_dtype,> torch_dtype → ms_dtype 修改了这个参数后，直接运行启动脚本，报错： !2 怀疑是这两个参数的问题，是否有其他的命名方式？ !1 注掉这两个参数后，仍然报错，这个该如何处理？ !3 !4
这个issue是关于需求变更的，主要涉及到metrics ut（单元测试）的迁移。由于项目需要进行功能迁移或代码重构，导致需要将该部分代码迁移到legacy（遗留代码）中，可能存在一些兼容性或功能实现方面的问题。,move metrics ut to legacy,,2024-04-15T12:32:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1017
这是一个需要升级到新Trainer的issue，主要涉及到情感分类模型。这个问题可能是由于原有的Trainer不再兼容，需要更新到新的版本才能正常运行。,update bert_emotect_finetune to new Trainer,,2024-04-15T12:09:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1016
这是一个用户提出需求的issue，主要涉及的对象是support sam。由于用户需要sam的支持，可能是希望解决一些问题或需要相关帮助。,support sam,,2024-04-14T15:51:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1015
这是一个用户提出需求的issue，主要对象是支持segformer模型。,support segformer,,2024-04-14T13:24:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1014
这是一个bug报告，主要涉及的对象是Pegasus和GPT_NeoX模型。由于某些原因导致这两个模型存在问题需要修复。,fix pegasus & gpt_neox,,2024-04-14T09:14:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1013
这是一个新增功能请求，要求添加Pegasus模型和单元测试到MindNLP。,"Add pegasus, both modeling and unittest",,2024-04-14T04:13:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1012
这个issue类型是bug报告，该问题涉及的主要对象是mindspore 2.2.11版本。由于什么样的原因导致了什么样症状的bug目前无法确定。,fix bugs on mindspore 2.2.11,,2024-04-14T02:33:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1011
该issue类型是bug报告，主要涉及mindnlp下的trainer ut，由于未提供具体内容，无法分析导致症状的具体原因。,fix all trainer ut,,2024-04-13T18:31:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1010
这是一个用户提出需求的类型，主要涉及到需要将SAM适配到https://github.com/huggingface/transformers的问题。原因可能是用户希望在transformers项目中使用SAM。,适配 SAM,🤗能不能迁移一下SAM：https://github.com/huggingface/transformers/blob/main/src/transformers/models/sam 🧐自己尝试迁移官方开源代码遇到了精度未对齐问题😭你们快点迁移一下hf的吧,2024-04-13T13:49:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1009
这是一个缺少具体内容的bug报告，主要涉及MindNLP下的trainer组件。由于缺少具体内容，无法准确分析问题的原因和表现出什么样的症状。,fix part of trainer ut,,2024-04-12T18:11:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1008
这是一个用户提出需求的类型。该问题主要涉及MindNLP库中的图模式以及训练脚本的添加。由于现有模型功能的限制或用户需求的改进，导致用户提出了对新增图模式`convbert`以及相关训练脚本的需求。,Add graph mode `convbert` and train scripts,,2024-04-12T14:53:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1007
这是一个bug报告，涉及到mindspore框架中nn.Dense层在模型推理时卡住的问题。可能由于什么样的原因导致了这个bug，导致用户提出了这个问题。,mindspore框架同步问题,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 跑模型推理时，nn.Dense层会卡住，若在Dense层之前打印tensor信息或断点调试，可正常继续运行；设置`mindspore.set_context(pynative_synchronize＝True)`也可正常继续运行 !image  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.2.11  Python version :python 3.9.19  OS platform and distribution:Linux Ubuntu 18.04  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 开发过程中发现，非必现 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.",2024-04-12T10:40:27Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1006
这是一个用户需求类型的issue，主要涉及到项目中的segformer适配问题。原因可能是用户希望对该模型进行适配或相关功能的使用。,segformer 适配,https://github.com/huggingface/transformers/blob/main/src/transformers/models/segformer/modeling_segformer.py,2024-04-12T09:06:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1005
这是一个bug报告，主要涉及MindSpore_lite和mindnlp的使用，由于MindSpore2.1.0版本进行推理时报错。,如何通过MindSpore_lite来使用mindnlp,"MindSpore版本：2.1.0 mindnlp版本：0.2.4 推理卡型号为：Ascend310P3 使用MindSpore2.1.0版本进行推理报错，错误内容如下：  RuntimeError: Load op info form json config failed, version: Ascend310P3  通过检索得知Ascend310P3卡被MindSpore_lite支持，但是我不知道如何使用。 无法检索到相关有用的信息，麻烦辛苦答复。",2024-04-12T08:06:41Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/1004,mindnlp的模型要先转静态图，然后导出mindir，才能被mindspore lite推理,> mindnlp的模型要先转静态图，然后导出mindir，才能被mindspore lite推理 请问有相关操作的官方文档吗？这方面的新手，谢谢！
该issue类型为bug报告，主要涉及的对象为import error。由于导入错误，导致了该bug症状的出现。,fix import error,,2024-04-12T08:00:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1003
这是一个bug报告，涉及pythia-410m-deduped test model与GPT NeoX结合时使用float16参数时出现权重消失问题。,"When using the pythia-410m-deduped test model with GPT NeoX, there is a weight disappearance issue when using the float16 parameter","**Describe the bug/ 问题描述 (Mandatory / 必填)** When using the pythia410mdeduped test model with GPT NeoX, there is a weight disappearance issue when using the float16 parameter.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:    GPU: NVIDIA 4070    CUDA: 11.6.2    cudnn: 8.9.2.26  **Software Environment / 软件环境 (Mandatory / 必填)**:    MindSpore version: 2.2.12    Python version: 3.8.18    OS platform and distribution: Ubuntu 22.04.3 LTS  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:   > Please delete the mode not involved / 请删除不涉及的模式:   > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. `$export RUN_SLOW=True` 2. Run `$pytest s v ./tests/ut/transformers/models/gpt_neox/` 3. See Error **Expected behavior / 预期结果 (Mandatory / 必填)** ``` E           + My favorite food is a good oldfashioned, oldfashioned, oldfashioned. E            E           I'm not sure ``` **Screenshots/ 日志 / 截图 (Mandatory / 必填)** ``` >           self.assertEqual(output_str, expected_output) E           AssertionError: 'My favorite food is' != ""My favorite food is a good oldfashioned[43 chars]sure"" E            My favorite food is E           + My favorite food is a good oldfashioned, oldfashioned, oldfashioned. E            E           I'm not sure tests/ut/transformers/models/gpt_neox/test_gpt_neox.py:341: AssertionError ``` 在Attention里面的Dense，在第14层出现问题。 测试截图 !cf01b8ca2bee267b981d57d4d48bcc84 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-04-11T13:45:37Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1002
这是一个用户提出需求的issue，主要对象是添加MPNet模型。 ,add MPNet Model,,2024-04-11T11:31:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1001
这是一个用户提出需求的issue，主要涉及的对象是关于添加类似hf-transformers的新Trainer。,add new Trainer like hf-transformers,,2024-04-10T15:43:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1000
这是一个需求更新的issue，主要对象是支持列表。用户可能发现当前支持列表不完整或有错误，需要更新以确保准确性和完整性。,update supported list,,2024-04-09T08:29:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/999
"该issue类型为bug报告，涉及的主要对象为""support jetmoe & fix python id() caused bugs""。根据标题和内容，用户可能提出了关于修复Python `id()`引起bug的问题或寻求相关帮助。",support jetmoe & fix python id() caused bugs,,2024-04-09T06:55:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/998
这是一个需求提出类型的issue，主要涉及的对象是针对mindnlp中的convbert模型的微调，用户提出了在SQuAD数据集上进行问答任务时采用PEFT方法的需求。,loar fintune convbert,finetune convbert 1. Dataset: squad 2. Task: question and answer 3. Method: peft lora ,2024-04-08T12:59:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/997
这是关于迁移llava1.6 llava_mistral模型推理的issue，属于功能迁移类型问题，主要涉及的对象是模型推理。由于模型迁移的原因导致了可能出现的bug或用户所提问题。,llava1.6 llava_mistral模型迁移,迁移了llava1.6 llava_mistral模型的推理,2024-04-08T12:37:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/996
这是一个功能增强的问题，主要涉及到增加了hypercomplex Tensor分解功能及其示例的使用。,Added hypercomplex Tensor Decomposition and example of using it,Added hypercomplex Tensor decomposition and example of using it for dualvalued Bert model,2024-04-08T11:02:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/995
这是一个用户提出需求的类型，主要对象是支持 Bridgetower & Bros 模型。,support bridgetower & bros model,,2024-04-08T09:52:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/994
这是一个空issue，类型为需求提出，用户提出了对支持blip_2的需求。,support blip_2,,2024-04-08T03:52:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/993
这个issue类型是功能需求提议，主要涉及的对象是新增名为timesformer的模型及对应的单元测试。,"Add timesformer, both modeling and unittest",,2024-04-07T12:07:22Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/992,pylint要过,"整网单测结果： test case: 0 pytorch_output: tensor([[0.5734,  0.7325]]) mindspore_output: [[0.5733707   0.73254424]] test case: 1 pytorch_output: tensor([[0.2084,  0.0546]]) mindspore_output: [[0.2083677   0.05464582]] test case: 2 pytorch_output: tensor([[0.3507, 0.6902]]) mindspore_output: [[0.35066652 0.6902201 ]] test case: 3 pytorch_output: tensor([[0.1027, 0.6495]]) mindspore_output: [[0.10272774 0.64949995]] test case: 4 pytorch_output: tensor([[0.5176, 0.0092]]) mindspore_output: [[0.5176308  0.00917375]] test case: 5 pytorch_output: tensor([[0.3630, 0.4937]]) mindspore_output: [[0.36303946 0.4936852 ]] test case: 6 pytorch_output: tensor([[ 0.4550, 0.5239]]) mindspore_output: [[ 0.45498836 0.5239444 ]] test case: 7 pytorch_output: tensor([[0.0581,  1.1381]]) mindspore_output: [[0.05814777  1.1380824 ]] test case: 8 pytorch_output: tensor([[1.0047,  0.8307]]) mindspore_output: [[1.0047089  0.8306871]] test case: 9 pytorch_output: tensor([[0.2202, 0.2220]]) mindspore_output: [[0.22021395 0.22201693]]"
这是一个需求类型的issue，要求添加`ConvBert`模型并传递。,Add `ConvBert` model and pass ut.,,2024-04-05T15:04:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/991
这是一个用户提出需求的issue，主要对象是GPT2 inference performance，由于性能需要提升才能与PyTorch竞争。,"GPT2 inference performance need to be boosted, if we want to beat pytorch","**Is your feature request related to a problem? Please describe.** When using mindnlp to infer GPT2, I found that the inference speed is 10X slower than pytorch. Here is the torch version implementation: https://github.com/graykode/gpt2Pytorch The hardware I use is Nvidia V100. MindSpore version: 2.2.12, 2.1.1 Pytorch version: 2.2.0 args I use: ms_dtype=mindspore.float16, use_cache=True **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.",2024-04-03T09:13:06Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/990,try new version of mindspore
这是一个用户提出需求的issue，主要涉及mindnlp下embedding模型的调用示例问题，可能是由于调用代码问题导致无法成功运行。,关于embedding模型的调用示例,"参考transformers调用bge 的模型写调用mindnlp条用bge模型代码，并不能运行成功，是否可以给使用mindnlp使用bge的参考样例。 ``` transformers 调用示例： from transformers import AutoTokenizer, AutoModel import torch  Sentences we want sentence embeddings for sentences = [""样例数据1"", ""样例数据2""]  Load model from HuggingFace Hub tokenizer = AutoTokenizer.from_pretrained('BAAI/bgelargezhv1.5') model = AutoModel.from_pretrained('BAAI/bgelargezhv1.5') model.eval()  Tokenize sentences encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')  for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)  encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')  Compute token embeddings with torch.no_grad():     model_output = model(**encoded_input)      Perform pooling. In this case, cls pooling.     sentence_embeddings = model_output[0][:, 0]  normalize embeddings sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1) print(""Sentence embeddings:"", sentence_embeddings) ``` 我写的mindnlp调用： ``` from mindnlp.transformers import AutoTokenizer, AutoModel     Sentences we want sentence embeddings for    sentences = [""样例数据1"", ""样例数据2""]     Load model from HuggingFace Hub    tokenizer = AutoTokenizer.from_pretrained('BAAI/bgelargezhv1.5')    model = AutoModel.from_pretrained('BAAI/bgelargezhv1.5')     model.eval()     Tokenize sentences    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')     for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)     encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')     Compute token embeddings     with torch.no_grad():    model_output = model(**encoded_input)    Perform pooling. In this case, cls pooling.    sentence_embeddings = model_output[0][:, 0]     normalize embeddings     sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)    print(""Sentence embeddings:"", sentence_embeddings) ```",2024-04-03T09:12:36Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/989,参考：https://github.com/mindsporelab/mindnlp/tree/master/llm/inference/bge_m3
这是一个需求类型的issue，主要涉及的对象是mindnlp的库，用户提出了添加Xlnet模型的请求。,add model: xlnet,添加Xlnet模型,2024-04-03T08:07:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/988
"这是一条bug报告，主要涉及的对象是mindnlp库，用户提出了关于""support blip""的问题。",support blip,,2024-04-02T15:03:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/987
这是一个Bug报告类型的Issue，主要涉及Bert-LSTM-CRF代码出现了维度错误导致数学运算失败的问题。,"Bert-LSTM-CRF 例子，提示ValueError: For 'MatMul' the input dimensions must be equal, but got 'x1_col': 768 and 'x2_row': 3072.","**Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. 使用MindNLP 0.2.3版本运行 BertLSTMCRF 时，提示提示ValueError: For 'MatMul' the input dimensions must be equal, but got 'x1_col': 768 and 'x2_row': 3072.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: 910A  **Software Environment / 软件环境 (Mandatory / 必填)**:   MindSpore version (e.g., 1.7.0.Bxxx) :  2.2.0  Python version (e.g., Python 3.7.5) :    3.9.18  OS platform and distribution (e.g., Linux Ubuntu 16.04): 欧拉2.8  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative 、 **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1.安装所有MindNLP所需依赖 2.进入mindnlp/examples/sequence_labeling 3.打开BertLSTMCRF.ipynb 4.依次执行 5.执行到trainer.run(tgt_columns=""labels"")时 `Cell In[11], line 1 > 1 trainer.run(tgt_columns=""labels"") File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:200, in Trainer.run(self, tgt_columns)     197 run_context = RunContext(args_dict)     198 self.callback_manager.train_begin(run_context) > 200 self._run(run_context, tgt_columns)     201 self.callback_manager.train_end(run_context) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/base.py:238, in Trainer._run(self, run_context, tgt_columns)     236 self.callback_manager.train_step_begin(run_context)     237 if self.obj_network: > 238     loss = self.train_fn(**data)     239 else:     240     loss = self.train_fn(tgts, **data) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/utils.py:85, in get_default_train_step_fn..default_run_step_for_obj_net(*args, **kwargs)      83 status = init_status()      84 args = ops.depend(args, status) > 85 loss, grads = grad_fn(*args, **kwargs)      86 loss = loss_scaler.unscale(loss)      87 if check_gradients: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:625, in _Grad.__call__..after_grad(*args, **kwargs)     624 def after_grad(*args, **kwargs): > 625     return grad_(fn_, weights)(*args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:121, in _wrap_func..wrapper(*arg, **kwargs)     119 (fn)     120 def wrapper(*arg, **kwargs): > 121     results = fn(*arg, **kwargs)     122     return _convert_python_data(results) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:600, in _Grad.__call__..after_grad(*args, **kwargs)     598      599 def after_grad(*args, **kwargs): > 600     res = self._pynative_forward_run(fn, grad_, weights, args, kwargs)     601     _pynative_executor.grad(fn, grad_, weights, grad_position, *args, **kwargs)     602     out = _pynative_executor() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py:650, in _Grad._pynative_forward_run(self, fn, grad, weights, args, kwargs)     648 _pynative_executor.set_grad_flag(True)     649 _pynative_executor.new_graph(fn, *args, **new_kwargs) > 650 outputs = fn(*args, **new_kwargs)     651 _pynative_executor.end_graph(fn, outputs, *args, **new_kwargs)     652 return outputs File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/engine/trainer/utils.py:49, in get_default_forward_fn_without_loss_fn..forward_fn(*args, **kwargs)      47 def forward_fn(*args, **kwargs):      48     outputs_list = () > 49     outputs = network(*args, **kwargs)      50     if isinstance(outputs, tuple):      51         outputs_list += outputs File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) Cell In[6], line 13, in Bert_LSTM_CRF.construct(self, ids, seq_length, labels)      11 def construct(self, ids, seq_length=None, labels=None):      12     attention_mask = (ids > mindspore.tensor(0)) > 13     output = self.bert_model(input_ids=ids, attention_mask=attention_mask)      14     lstm_feat, _ = self.bilstm(output[0])      15     emissions = self.crf_hidden_fc(lstm_feat) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/bert/modeling_bert.py:802, in BertModel.construct(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)     792 head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)     794 embedding_output = self.embeddings(     795     input_ids=input_ids,     796     position_ids=position_ids,    (...)     799     past_key_values_length=past_key_values_length,     800 ) > 802 encoder_outputs = self.encoder(     803     embedding_output,     804     attention_mask=extended_attention_mask,     805     head_mask=head_mask,     806     encoder_hidden_states=encoder_hidden_states,     807     encoder_attention_mask=encoder_extended_attention_mask,     808     past_key_values=past_key_values,     809     use_cache=use_cache,     810     output_attentions=output_attentions,     811     output_hidden_states=output_hidden_states,     812     return_dict=return_dict,     813 )     815 sequence_output = encoder_outputs[0]     816 pooled_output = self.pooler(sequence_output) if self.pooler is not None else None File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/bert/modeling_bert.py:525, in BertEncoder.construct(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)     523 layer_head_mask = head_mask[i] if head_mask is not None else None     524 past_key_value = past_key_values[i] if past_key_values is not None else None > 525 layer_outputs = layer_module(     526     hidden_states,     527     attention_mask,     528     layer_head_mask,     529     encoder_hidden_states,     530     encoder_attention_mask,     531     past_key_value,     532     output_attentions,     533 )     534 hidden_states = layer_outputs[0]     535 if use_cache: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/bert/modeling_bert.py:474, in BertLayer.construct(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)     471     cross_attn_present_key_value = cross_attention_outputs[1]     472     present_key_value = present_key_value + cross_attn_present_key_value > 474 layer_output = apply_chunking_to_forward(     475     self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output     476 )     477 outputs = (layer_output,) + outputs     479  if decoder, return the attn key/values as the last output File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/ms_utils.py:188, in apply_chunking_to_forward(forward_fn, chunk_size, chunk_axis, *input_tensors)     185      concatenate output at same dimension     186     return ops.cat(output_chunks, axis=chunk_axis) > 188 return forward_fn(*input_tensors) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/bert/modeling_bert.py:488, in BertLayer.feed_forward_chunk(self, attention_output)     486 """"""feed forward chunk""""""     487 intermediate_output = self.intermediate(attention_output) > 488 layer_output = self.output(intermediate_output, attention_output)     489 return layer_output File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/bert/modeling_bert.py:397, in BertOutput.construct(self, hidden_states, input_tensor)     395 hidden_states = self.dense(hidden_states)     396 hidden_states = self.dropout(hidden_states) > 397 hidden_states = self.LayerNorm(hidden_states + input_tensor)     398 return hidden_states File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:705, in Cell.__call__(self, *args, **kwargs)     703 except Exception as err:     704     _pynative_executor.clear_res() > 705     raise err     707 if isinstance(output, Parameter):     708     output = output.data File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:701, in Cell.__call__(self, *args, **kwargs)     699 try:     700     _pynative_executor.new_graph(self, *args, **kwargs) > 701     output = self._run_construct(args, kwargs)     702     _pynative_executor.end_graph(self, output, *args, **kwargs)     703 except Exception as err: File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:482, in Cell._run_construct(self, cast_inputs, kwargs)     480     output = self._shard_fn(*cast_inputs, **kwargs)     481 else: > 482     output = self.construct(*cast_inputs, **kwargs)     483 if self._enable_forward_hook:     484     output = self._run_forward_hook(cast_inputs, output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/injection.py:789, in LayerNorm.construct(self, input_x)     787 def construct(self, input_x):     788     if self.elementwise_affine: > 789         y, _, _ = self.layer_norm(input_x, self.weight.astype(input_x.dtype), self.bias.astype(input_x.dtype))     790     else:     791         y, _, _ = self.layer_norm(input_x, ops.ones(self.normalized_shape, input_x.dtype),     792                                   ops.zeros(self.normalized_shape, input_x.dtype),) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py:94, in StubTensor.dtype(self)      92 if self.stub:      93     if not hasattr(self, ""stub_dtype""): > 94         self.stub_dtype = self.stub.get_dtype()      95     return self.stub_dtype      96 return self.tensor.dtype ValueError: For 'MatMul' the input dimensions must be equal, but got 'x1_col': 768 and 'x2_row': 3072.   Ascend Warning Message:  W49999: If want to reuse binary file, please donwload binary file and install first![FUNC:BuildFusionOp][FILE:fusion_manager.cc][LINE:4254] W11001: Op [DropOutGenMask] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGrad/dgateReshapeNode] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGrad/DynamicRNNGraddxReshapeNode] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradBody/DynamicRNNGradbodyDgateReshapeNode] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradBody/DynamicRNNGradbodyDxReshapeNode] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_2_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_3_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_4_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_7_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_8_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_9_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_10_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_12_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DynamicRNNGradWhile_Op_input_11_Memcpy] does not hit the highpriority operator information library, which might result in compromised performance.   C++ Call Stack: (For framework developers)  mindspore/core/ops/mat_mul.cc:107 InferShape`",2024-04-02T09:28:36Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/986,mindspore的动态shape bug，待2.3修复
这是一个用户提出需求的issue，主要涉及对象是mindnlp中的Blenderbot small模型。其存在的原因可能是用户希望支持Blenderbot small模型的相关功能。,support blenderbot samll,,2024-04-02T08:22:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/985
这是一个用户提出需求的issue，该问题单涉及的主要对象是mindnlp项目，用户希望支持blenderbot。,support blenderbot,,2024-04-02T03:15:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/984
这是一个用户提出需求的issue，主要涉及的对象是mindnlp的text2vec模块。用户希望增加text2vec模块，可能是为了提供更多文本向量化的功能或者提升文本处理的效率。,add text2vec module,,2024-04-01T15:30:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/983
这是一个bug报告，涉及的主要对象是mindnlp项目中的tokenized index问题。此问题可能由于tokenized索引问题引起的错误或不正确的输出。,Fix tokenized index problem, https://github.com/mindsporelab/mindnlp/issues/981 ,2024-04-01T02:53:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/982
这是一个bug报告类型的issue，主要涉及到mindnlp中的text_generation示例，用户遵循示例步骤后出现问题。,Bug in examples/text_generation,"**Describe the bug/ 问题描述 (Mandatory / 必填)** Following the steps in the example and run those code blocks one by one, an error will occur in block 5 when called by block 7. The error report says:  `map operation: [PyFunc] failed. Error description: KeyError: Traceback (most recent call last):   File ""/home/mindspore/miniconda3/envs/ms_py39/lib/python3.9/sitepackages/mindspore/dataset/transforms/py_transforms_util.py"", line 198, in __call__     result = self.transform(*args)   File ""/home/mindspore/projs/gpt2testmnlpv0.2.3/run_gpt2.py"", line 25, in merge_and_pad     return tokenized[0], tokenized[0]   File ""/home/mindspore/miniconda3/envs/ms_py39/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_base.py"", line 200, in __getitem__     raise KeyError( KeyError: 'Invalid key. Only three types of key are available: (1) string, (2) integers for backend Encoding, and (3) slices for data subsetting.' `  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > GPU V100  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : >=2.1.1  Python version (e.g., Python 3.7.5) : >=3.7.16  OS platform and distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !error report **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-04-01T02:36:51Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/981,"I changed `tokenized[0]` into `tokenized['input_ids']`, and then the bug is fixed",tokenizer的api变化了，改成了完全对齐Huggingface的api，所以必须按key来取了，你能直接提个pr吗？,已提pr https://github.com/mindsporelab/mindnlp/pull/982
"这是一个用户提出需求的类型，涉及主要对象是在mindnlp中添加名为""musicgen_melody""的功能。",add musicgen_melody,,2024-03-31T16:47:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/980
这是一个用户提出需求的issue，主要涉及mindnlp库，由于未提供具体内容，无法分析具体问题产生的原因。,add bit,,2024-03-31T12:39:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/979
"这是一个需求提出类型的issue，主要对象是在mindnlp中添加名为""jamba""的东西。",add jamba,,2024-03-31T11:46:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/978
这是一个关于bug报告的issue，主要对象是mindnlp在macOS上出现的错误。由于某些原因导致了在macOS下使用mindnlp时出现错误。,fix error on macOS,,2024-03-31T00:06:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/977
这是一个需求类型的issue，用户提出需要添加table_transformer模型，可能是为了增强系统的模型支持。,Add table_transformer model,From gitee issue: https://gitee.com/mindspore/community/issues/I835ND,2024-03-30T08:22:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/976
这是一个用户需求类型的issue，用户请求添加RLHF demo。主要对象涉及于mindnlp项目的功能演示。,Add RLHF demo,,2024-03-30T05:30:14Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/975
这是一个用户提出需求的issue，主要涉及的对象是llama index(sql) demo。可能是用户希望增加一个llama index(sql) demo示例，以展示相关功能或特性。,Add llama index(sql) demo,,2024-03-30T05:27:48Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/974
这个issue属于功能需求类型，主要涉及对象是ChatPDF demo。由于缺乏ChatPDF demo，用户提出了需要添加的需求。,Add ChatPDF demo,,2024-03-30T05:27:27Z,,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/973,use langchain,use langchain,test,test,123,done for other repo
这是一个bug报告，该问题单涉及的主要对象是零负载支持。由于硬件或软件中的特定问题，导致无法支持零负载。,support zero offload,,2024-03-30T05:26:43Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/972
这个issue类型是用户提出需求，请教问题等，该问题涉及的主要对象是dbrx。由于缺少具体内容，导致用户提出了关于dbrx支持的问题或需求帮助。,Support dbrx,,2024-03-30T05:25:31Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/971,done
这是一个需求问题，涉及主要对象为qwen2 moe，由于用户对其提出了支持的要求。,Support qwen2 moe,,2024-03-30T05:23:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/970
这个issue属于用户提出需求类型，主要涉及Mindnlp库支持管道并行推理的问题。,Support pipeline parallel inference,,2024-03-30T05:23:04Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/969,done
这个issue类型是用户提出需求，主要涉及的对象是支持jamba。由于用户需要新增对jamba的支持，可能是因为jamba是用户使用的一种新的功能或工具，需要在项目中集成。,Support jamba,,2024-03-30T05:22:35Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/968
这是一个bug报告类型的issue，主要涉及对象是find_cuda_home函数，由于没有正确获取CUDA路径导致raise error。,fix find_cuda_home raise error,,2024-03-30T00:18:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/967
这是一个优化建议类型的issue，主要涉及到CPU运行速度较慢的问题。,skip big and slow ut on CPU,,2024-03-30T00:06:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/966
这是一个bug报告，涉及的主要对象是在mindnlp中添加qwen2_moe的过程中出现了问题。 由于未给出具体的问题描述或内容，因此无法分析导致了什么样症状的bug或者用户提出了关于什么的问题或者寻求什么样的帮助。,add qwen2_moe & fix bugs,,2024-03-29T13:09:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/965
这个issue类型是用户提出需求，主要涉及对象是适配 Yi-VL-34B 模型，并由于需要适配该模型到指定地址而产生。,适配 Yi-VL-34B,联通智算 项目： YiVL34B  适配  https://huggingface.co/01ai/YiVL34B    github 代码地址：https://github.com/01ai/Yi/tree/main/VL,2024-03-29T01:06:11Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/964
这是一个bug报告，问题主要涉及Mindnlp中的LayoutLM模型在使用HF-Mirror时出现的错误。可能是由于URL链接错误或者网络连接问题导致LayoutLM模型无法正常使用。,fix layoutlm & use hf-mirror for all urls,,2024-03-28T15:38:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/963
这是一个用户建议更新FlashAttention核心的issue，涉及的主要对象是MindNLP。由于新版本的FlashAttention核心可能带来更好的性能或功能，用户提出了更新的需求。,update flashattention kernel,,2024-03-28T12:35:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/962
这是一个用户提出需求的issue，主要对象是对mindnlp项目的支持。由于缺乏对internlm的支持，用户提出了相应需求。,support for internlm,,2024-03-28T12:32:41Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/961,pylint要通过，不要加ignore，直接改代码,好的，哥~
这个issue属于用户提出需求类型，主要对象是向mindnlp仓库请求添加bigbird_pegasus模型。,add bigbird_pegasus model,,2024-03-28T06:03:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/960
这是一个bug报告类型的issue，主要涉及的对象是 `easydict` 模块，由于 easydict 模块存在错误导致了无法使用的情况。,fix easydict error,,2024-03-28T00:45:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/959
这是一个需求类型的issue，主要涉及更新模型并移除特定依赖。最可能由于项目中需要更新模型版本且不再需要某些依赖，所以提出此需求。,update layoutlmv2 & remove mindocr dependency,,2024-03-27T18:00:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/958
这个issue类型是bug报告，主要对象是模块 modeling_gpt_neox，问题是由于冗余类导入导致了问题。,Fixed redundant class import in modeling_gpt_neox,,2024-03-27T13:00:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/957
这是一个用户提出需求的类型，需要更新编码模型并添加音乐生成模型。可能是因为现有模型不足以满足用户的需求，所以提出了这个问题。,update encodec model & add musicgen model,,2024-03-27T09:38:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/956
这是一个用户需求报告，主要对象是GPT-SOVITS模型在MindSpore上的适配问题，用户希望提供GPT-SOVITS的适配版本。,希望可以提供gpt-sovits的适配版本,我们测试了同类型的多个代码，感觉gptsovits的表现是最好的，但是它没有适配mindspore的版本，希望能在后续提供gptsovits的适配版本,2024-03-27T01:05:37Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/955,参考社区同学迁移版本 https://github.com/ultranationalism/GPTSoVITSmindspore
这是一个用户请求支持hf-style flagembedding bge_m3模型的需求，主要对象是MindNLP。,support hf-style flagembedding bge_m3 model,,2024-03-25T16:32:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/954
这是一个用户提出需求的issue，主要涉及的对象是向mindnlp项目添加bert_generation模型。由于项目当前没有该模型，用户希望团队能够考虑添加这个模型以丰富功能。,add bert_generation model,,2024-03-25T13:45:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/953
这是一个需求提出类型的Issue。主要涉及的对象是添加GPTNeoX模型。由于尚未具体描述问题或提供更多细节，原因导致用户提出了关于添加GPTNeoX模型的需求。,Add GPT GPTNeoX model,,2024-03-25T13:34:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/952
这是一个用户提出需求的issue，主要对象是在mindnlp项目中添加GPTNeoX模型。,Add GPT GPTNeoX model,,2024-03-25T13:19:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/951
这是一个用户提出需求的类型的issue，主要涉及的对象是添加beit模型和更新pylint规则。,add beit model & update pylint rules,,2024-03-25T12:03:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/950
这个issue类型是用户提出需求，涉及主要对象是mindnlp下的question answering pipeline，用户寻求帮助或者提出了一个需求。,Document question answering pipeline,开源实习  https://gitee.com/mindspore/community/issues/I97T7V,2024-03-25T04:32:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/949
这个issue类型是需求更新，涉及的主要对象是bert-crf示例。由于bert-crf示例需要更新，用户提出了更新该示例的需求。,update bert-crf example,,2024-03-24T20:18:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/948
这个issue是bug报告，主要涉及对象是AutoTokenizer加载bge-m3时出现的TypeError: unhashable type: 'dict'错误。导致这个bug的原因可能是AutoTokenizer无法正确处理参数字典的情况。,使用AutoTokenizer加载bge-m3时，提示TypeError: unhashable type: 'dict',"加载代码： from mindnlp.transformers import AutoTokenizer  tokenizer tokenizer = AutoTokenizer.from_pretrained(""/home/mauser/work/bgem3"") test_tokenized = tokenizer('hello') test_tokenized.keys() 提示错误： /usr/local/Ascend/ascendtoolkit/7.0.RC1/python/sitepackages/tbe/tvm/contrib/ccec.py:766: DeprecationWarning: invalid escape sequence \L   if not dirpath.find(""AppData\Local\Temp""): /usr/local/Ascend/ascendtoolkit/latest/python/sitepackages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \B   """""" /usr/local/Ascend/ascendtoolkit/latest/python/sitepackages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:140: DeprecationWarning: invalid escape sequence \c   """""" /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/Ascend/ascendtoolkit/latest/python/sitepackages/tbe/dsl/unify_schedule/extract_image_patches_without_cbuf_schedule.py:317: SyntaxWarning: ""is not"" with a literal. Did you mean ""!=""?   if _ is not 1: /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html   from .autonotebook import tqdm as notebook_tqdm Building prefix dict from the default dictionary ... Loading model from cache /tmp/jieba.cache Loading model cost 1.327 seconds. Prefix dict has been built successfully.  TypeError                                 Traceback (most recent call last) Cell In[1], line 3       1 from mindnlp.transformers import AutoTokenizer       2  tokenizer > 3 tokenizer = AutoTokenizer.from_pretrained(""/home/mauser/work/bgem3"")       5 test_tokenized = tokenizer('hello')       6 test_tokenized.keys() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/models/auto/tokenization_auto.py:740, in AutoTokenizer.from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs)     736     if tokenizer_class is None:     737         raise ValueError(     738             f""Tokenizer class {tokenizer_class_candidate} does not exist or is not currently imported.""     739         ) > 740     return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)     742  Otherwise we have to be creative.     743  if model is an encoder decoder, the encoder tokenizer class is used by default     744 if isinstance(config, EncoderDecoderConfig): File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_base.py:1728, in PreTrainedTokenizerBase.from_pretrained(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, *init_inputs, **kwargs)    1725     else:    1726         logger.info(f""loading file {file_path} from cache at {resolved_vocab_files[file_id]}"") > 1728 return cls._from_pretrained(    1729     resolved_vocab_files,    1730     pretrained_model_name_or_path,    1731     init_configuration,    1732     *init_inputs,    1733     cache_dir=cache_dir,    1734     local_files_only=local_files_only,    1735     _is_local=is_local,    1736     **kwargs,    1737 ) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindnlp/transformers/tokenization_utils_base.py:1940, in PreTrainedTokenizerBase._from_pretrained(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _is_local, *init_inputs, **kwargs)    1938     if added_tokens_map and init_kwargs[key] is not None:    1939         if key != ""additional_special_tokens"": > 1940             init_kwargs[key] = added_tokens_map.get(init_kwargs[key], init_kwargs[key])    1942 init_kwargs[""added_tokens_decoder""] = added_tokens_decoder    1943  convert {'__type': 'AddedToken', 'content': '', 'lstrip': False, 'normalized': True, ...} to AddedTokens TypeError: unhashable type: 'dict'",2024-03-24T10:49:51Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/947,问题已修复，要使用和flagembedding库等效的执行参考这个demo： https://github.com/mindsporelab/mindnlp/blob/master/llm/inference/bge_m3/run_bge_m3.py
该issue为用户提出需求，针对主要对象为支持Layoutlm2的大模型任务。由于缺乏对Layoutlm2的支持，用户提出了关于此功能的需求。,support Layoutlm2,https://gitee.com/mindspore/community/issues/I835ND?from=projectissue 大模型任务 layoutlmv2,2024-03-23T08:32:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/946
这是一个bug报告，主要对象是minicpm autotokenizer，由于一个错误或者缺陷导致用户寻求修复。,fix minicpm autotokenizer,,2024-03-22T14:25:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/945
这个issue属于用户提出需求的类型，主要对象是要为mindnlp添加altclip和ast model。,add altclip & ast model,,2024-03-20T16:06:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/944
这是一个用户提出需求的issue，主要涉及Zero_Shot_Classification Pipeline。由于链接指向了gitee而非github，用户可能在寻求与该主题相关的开源实习机会或项目。,Zero_Shot_Classification Pipeline,https://gitee.com/mindspore/community/issues/I97UPQ?from=projectissue 【开源实习】Zero_Shot_Classification Pipeline !image,2024-03-20T15:42:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/943
这是一个用户提出需求的issue，主要涉及MindNLP支持对齐模型的功能。,support align model,,2024-03-20T09:59:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/942
这个issue类型是bug报告，涉及的主要对象是 _scaled_dot_product_attention 函数。由于什么导致了症状的bug还需要进一步分析。,fix _scaled_dot_product_attention bug,,2024-03-20T09:59:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/941
这是一个用户提出需求的类型，主要对象是在Mindnlp中添加biogpt模型。由于用户希望扩展Mindnlp支持的模型，因此提出了这个需求。,add biogpt,,2024-03-19T16:34:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/940
这是一个功能需求类型的issue，主要涉及需要添加一个evaluate模块。这个需求可能由于现有模块的不完整或者用户需要更全面的功能而提出。,add evaluate module,,2024-03-19T16:00:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/939
这是一个bug报告，主要涉及对象是mindnlp的whisper模块，由于返回token的时间戳错误导致了问题。,fix whisper return_token_timestamps error,,2024-03-19T15:13:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/938
这是一个bug报告，主要涉及mindnlp中的whisper推理在Ascend平台上的问题，主要原因是存在推理功能无法正常工作的bug。,fix whisper inference on Ascend,,2024-03-19T14:00:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/937
这是一个用户提出需求类型的issue，主要涉及对象是mindnlp库的支持，由于缺乏对wav2vec2_with_lm功能的支持，用户提出希望增加相关支持的需求。,support wav2vec2_with_lm,,2024-03-18T12:35:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/936
该issue类型为请求功能（feature request），主要涉及对象为添加tokenization_layoutlm功能。由于模糊的issue描述，用户可能正在请求添加新的tokenization_layoutlm功能，但尚未提供具体的内容或信息。,add tokenization_layoutlm,,2024-03-18T11:49:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/935
这个issue属于用户提出需求。主要对象是mindnlp项目，用户提出希望支持自动语音识别流水线。由于目前不支持该功能，用户提出了这个需求。,support automatic_speech_recognition pipeline,,2024-03-18T11:41:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/934
这是一个用户提出需求的issue，主要涉及mindnlp的支持融合注意力（fused attention）功能。,support fused attention,,2024-03-18T05:57:36Z,,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/933
这是一个bug报告，该问题涉及到mindnlp下的roll操作在CPU上不支持的问题。由于该功能不支持在CPU上运行，导致了bug。,fix roll not support on CPU,,2024-03-18T02:46:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/932
这是一个用户提出需求的issue，主要涉及的对象是新增对Reformer模型的支持。,support reformer,,2024-03-17T07:47:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/931
这是一个用户提出需求的issue，主要对象是增加一个bce示例，可能是为了更好地展示如何使用该功能。,add bce example,,2024-03-16T17:00:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/930
这个issue是一个bug报告，涉及mindnlp加载本地模型文件出错的问题，可能是由于文件路径错误或模型文件损坏导致的。,mindnlp加载gemma-7b本地模型文件出错,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: GPU > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : MindSpore  Python version (e.g., Python 3.7.5) : 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04): WSL 22.04  GCC/Compiler version (if compiled from source): gcc9.5  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: ``` from transformers import AutoTokenizer, AutoModelForCausalLM from mindnlp.transformers import AutoTokenizer, AutoModelForCausalLM model_path = ""/mnt/e/models/google/gemma7b"" model_path = ""google/gemma7b"" hf_token=""hf_xxx"" tokenizer = AutoTokenizer.from_pretrained(model_path,token=hf_token) model = AutoModelForCausalLM.from_pretrained(model_path,token=hf_token) input_text = ""Write me a poem about Machine Learning."" input_ids = tokenizer(input_text, return_tensors=""ms"") outputs = model.generate(**input_ids) print(tokenizer.decode(outputs[0])) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.  **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-03-16T16:42:52Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/929
这是一个用户提出需求的类型的issue，主要涉及支持DeBERTa模型的问题。由于DeBERTa是一个相对新的模型，用户可能希望MindNLP能够支持该模型以获得更好的性能。,support deberta model,,2024-03-16T14:43:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/928
这个issue类型是需求更新，涉及的主要对象是CI/CD pipeline。可能是由于项目需求变更或优化导致的。,udate ci pipeline,,2024-03-16T11:35:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/927
这是一个bug报告类型的issue，涉及到peft示例的更新。这可能是由于过时的示例或者需要修复当前示例中存在的问题所导致的。,update peft examples,,2024-03-16T08:50:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/926
这是一个缺少具体内容的issue，需要进一步完善描述才能确定问题类型和相关主体。,layoutlm module,,2024-03-16T07:24:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/925
这是一个bug报告，主要涉及的对象是在Windows系统上运行mixtral ut出现问题。由于未提供具体内容，无法得知具体原因和症状。,fix mixtral ut on windows,,2024-03-15T11:31:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/924
这是用户提出需求的类型，主要涉及的对象是mindnlp下的question answering功能。由于用户希望开源实习自然语言问答pipeline，因此提出了这个issue。,add:question answering,【开源实习】https://gitee.com/mindspore/community/issues/I97TKG 自然语言问答pipeline,2024-03-15T06:56:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/923
这是一个bug报告类型的issue，主要涉及到mindnlp库中的超复杂数学计算引起的错误。,fix hypercomplex casued errors,,2024-03-15T03:38:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/922
这个issue类型是功能增强，主要涉及的对象是新增的双值Bert模型实现。,Added dual-valued Bert model and example of using it,"Added an implementation of the Bert model using dual operators, as well as an example of training it from scratch on IMDB dataset.",2024-03-14T17:39:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/921
这个issue是一个bug报告，主要对象是mindnlp库中的GPU代码生成错误。由于何种原因导致的这个bug，以及用户提出了什么问题或需要何种帮助并未在描述中提及。,fix codegen error on GPU,,2024-03-14T16:48:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/920
这个issue类型为功能需求反馈，主要涉及对象为mamba软件，用户提出需要支持图模式，并希望相关功能能够得到支持。,mamba support graph mode,,2024-03-14T05:20:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/919
该issue属于用户发出需求类型，主要对象是text generation pipeline，由于issue链接缺失部分内容导致用户寻求帮助。,Text generation,https://gitee.com/mindspore/community/issues/I97U63 【开源实习】text_generation pipeline,2024-03-14T04:16:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/918
这是一个用户提出需求的issue，主要对象是text2text generation pipeline，用户希望添加该功能至原有项目中。,Text2Text generation pipeline feat,https://gitee.com/mindspore/community/issues/I97TXT 【开源实习】text2text pipeline,2024-03-13T11:37:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/917
这是一个用户提出需求的issue，主要涉及对象是对于软件支持mamba。可能由于当前软件不兼容mamba导致用户无法使用或者希望更快的包管理。,support mamba,,2024-03-13T09:07:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/916
这是一个用户提出需求的issue，主要对象是要求适配Bark或者更多的语音合成模型。,请求适配Bark，或者更多的语音合成模型,,2024-03-12T15:45:06Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/915,Bark支持,你可以直接试一下
这是一个bug报告，涉及主要对象为windows用户。原因可能是由于使用同步时出现致命错误导致的问题。,windows use synchronize since fatal errors,,2024-03-12T15:27:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/914
"这是一个bug报告类型的issue，主要涉及到mindnlp的whisper模型无法支持AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline，导致需要适配。","whisper 请适配 AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline","我们已经适配的whisper 模型无法支持AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline，请适配 模型地址：https://github.com/mindsporelab/mindnlp/tree/master/mindnlp/transformers/models/whisper huggingface:https://huggingface.co/openai/whisperlargev3 huggingface的推理示例： import torch from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline from datasets import load_dataset device = ""cuda:0"" if torch.cuda.is_available() else ""cpu"" torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32 model_id = ""openai/whisperlargev3"" model = AutoModelForSpeechSeq2Seq.from_pretrained(     model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True ) model.to(device) processor = AutoProcessor.from_pretrained(model_id) pipe = pipeline(     ""automaticspeechrecognition"",     model=model,     tokenizer=processor.tokenizer,     feature_extractor=processor.feature_extractor,     max_new_tokens=128,     chunk_length_s=30,     batch_size=16,     return_timestamps=True,     torch_dtype=torch_dtype,     device=device, ) dataset = load_dataset(""distilwhisper/librispeech_long"", ""clean"", split=""validation"") sample = dataset[0][""audio""] result = pipe(sample) print(result[""text""])",2024-03-12T09:02:58Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/913,!image
这个issue类型为用户提出需求，主要涉及的对象是支持mixtral，由于没有明确的内容，无法分析导致的问题或需求。,support mixtral,,2024-03-12T03:00:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/912
这是一个用户提出需求的类型，主要对象是郑州智算项目，需把模型迁移到npu上。,适配 bce-reranker-base_v1,郑州智算项目 要把https://huggingface.co/maidalun1020/bcererankerbase_v1模型迁移到npu上 ,2024-03-12T01:28:38Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/911,模型地址: https://huggingface.co/maidalun1020/bcererankerbase_v1   是否有已经支持的模型?  
这个issue属于bug报告，主要涉及到mindnlp库下的big_bird模型。导致该bug的原因可能是big_bird模型出现了错误。,fix big_bird error,,2024-03-10T18:43:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/910
这是一个Bug报告类型的Issue，涉及的主要对象是百川（Baichuan）。由于某种问题导致了Baichuan错误，需要修复。,fix baichuan error,,2024-03-09T16:50:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/909
这是一个用户提出需求的issue，涉及对象为如何在指定显存大小情况下同时运行glm3和bgelargezh，原因是想在具有64G显存的环境中同时运行这两个任务。,如何使用context指定占用显存大小,"**Describe the bug/ 问题描述 (Mandatory / 必填)** 我想在910B2（64G显存）同时运行glm3和bgelargezh，通过mindformers运行glm3，通过mindnlp运行bgelargezh，mindformers可以通过 context.set_context(max_device_memory='28GB', mode=ms.GRAPH_MODE, device_target=""Ascend"", device_id=0)  方式指定显存，但是在mindnlp中如果通过该方式会显示重复指定context（报错见最后的图）  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: ``` [mauser bgelargezhv1_5]$npusmi info ++  +===========================+===============+====================================================+ ```  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.2.0  Python version (e.g., Python 3.7.5) :3.9.10  OS platform and distribution (e.g., Linux Ubuntu 16.04): Linux notebook7f74bd2065e349f68d04f1b61d838e79 4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch64 CC(Change module dataset structure and add 4 datasets) SMP Tue Jun 6 07:58:07 UTC 2023 aarch64 aarch64 aarch64 GNU/Linux  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: 都有 /mode pynative /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 代码如下： ``` from mindnlp.transformers.models.bert import BertModel import mindspore as ms ms.set_context(max_device_memory='15GB', mode=ms.GRAPH_MODE, device_target=""Ascend"", device_id=0) model = BertModel.from_pretrained('/home/mauser/infer/checkpoint_download/bgelargezhv1_5', from_pt=True) ``` **Expected behavior / 预期结果 (Mandatory / 必填)** 指定bgelargezh的显存大小 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** . !image",2024-03-09T04:35:50Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/908,由于mindnlp里import过mindspore导致已经默认配置过一次了，你应该先import mindspore，然后设置，然后再import mindnlp
这是一个用户提出需求的类型，主要涉及的对象是百川模型。原因可能是加载了baichuan13bchat模型后，却没有chat功能的视线，用户希望添加chat功能以便体验百川模型的chat功能。,体验百川时，发现没有chat方法,在加载了baichuan13bchat模型后，发现还没有chat功能的视线，希望加一下这个，方便体验百川模型的chat功能 !image,2024-03-08T17:51:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/907
这是一个Bug报告类型的Issue，主要对象是MindNLP下的13B-chat，在使用mindspore2.2.12版本时出现问题，原因可能是GPU和CUDA环境的不匹配。,体验百川13B-chat时，发现有3个地方需要改动一下,"mindspore2.2.12版本， 4090 GPU，cuda11.6环境 我的体验代码是这样的： import mindspore as ms from mindnlp.transformers import BaiChuanForCausalLM, BaiChuanTokenizer from mindnlp.transformers.generation.utils import GenerationConfig tokenizer = BaiChuanTokenizer.from_pretrained(""baichuaninc/Baichuan13BChat"") model = BaiChuanForCausalLM.from_pretrained(""baichuaninc/Baichuan13BChat"",                                                ms_dtype=ms.float16, size='13b') model.generation_config = GenerationConfig.from_pretrained(""baichuaninc/Baichuan13BChat"") texts = '请问你是谁？' input_ids = tokenizer(texts, return_tensors=""ms"") print(input_ids) print(f'input_ids[""input_ids""].shape:{input_ids[""input_ids""].shape}') outputs = model(input_ids=input_ids['input_ids']) print(outputs) print(outputs[0].shape) 运行过程中发现有3个地方需要改动 : 1:这边，需要把ops.zeros原来的参数list改成了tupe的形式，否则会报一个奇怪的错误  2.这边代码需要挪下位置， 因为运行过程中发现，在父类的初始化中就需要使用到子类的self.sp_model对象，如果写在下面，使用时还没有初始化，就会出错  3.这边有个数据需要转换，我印象中GPU上必须转一下，做矩阵相称时，数据类型必须一致，昇腾上是不需要的 ",2024-03-08T17:49:01Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/906
这是一个关于bug报告类型的issue，主要涉及的对象是big_bird，由于precision问题导致ut失败。,big_bird has a ut failure,It has an ut failure because of precision.,2024-03-08T14:29:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/905
这个issue类型是功能需求提出，主要涉及的对象是支持混合语言（例如中英文）的支持。,support mixtral,,2024-03-08T09:29:03Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/904
该issue类型为需求提出，主要对象是支持Reformer模型。原因可能是用户希望在项目中集成Reformer模型以改善自然语言处理任务的效果。,support reformer ,,2024-03-08T09:26:20Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/903
这是一个关于用户提出需求的issue，主要对象是支持unified_transformer模型的实现。原因可能是用户希望在项目中使用这种模型，但目前尚未提供相关支持。,support unified_transformer,,2024-03-08T09:25:32Z,requirement,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/902
该issue类型是用户提出需求，主要涉及的对象是对DeBERTa模型的支持。,support deberta ,,2024-03-08T09:23:41Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/901
这个issue是一个用户提出需求的类型，主要涉及的对象是支持biogpt。这个问题可能是由于Biogpt模型尚未集成到MindNLP中而导致用户希望得到支持。,support biogpt ,,2024-03-08T09:22:57Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/900
"这是一个bug报告，主要涉及的对象是模型 ""big_bird""。由于 precision 出现问题，导致了ut（单位测试）的失败。",add the model of big_bird,It has an ut failure due to precision.,2024-03-08T09:15:19Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/899,!image 无关文件不要上传,您好，您发的文件已经收到，谢谢！
这个issue类型是用户提出需求，该问题单涉及的主要对象是支持starcoder2。原因可能是用户希望mindnlp能支持starcoder2，但具体内容未提供。,support starcoder2,,2024-03-08T08:55:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/898
这个issue类型为用户提出需求，主要涉及的对象是模型迁移至npu，原因是项目需要将模型从CPU迁移到NPU进行使用。,bce-embedding-base_v1 模型迁移到910B上,"郑州智算项目 要把https://huggingface.co/maidalun1020/bceembeddingbase_v1 模型迁移到npu上 , bceembeddingbase_v1的介绍在https://github.com/neteaseyoudao/BCEmbedding/blob/master/README_zh.md",2024-03-08T03:23:14Z,requirement,closed,0,7,https://github.com/mindspore-lab/mindnlp/issues/897,模型地址:https://huggingface.co/maidalun1020/bceembeddingbase_v1,看了下模型结构是XLMRoberta，已经支持了，能给个环境我验一下不,https://github.com/mindsporelab/mindnlp/tree/master/mindnlp/transformers/models/xlm_roberta,"好的，下午我也搞个环境发给你哈，十分感谢  回复的原邮件   看了下模型结构是XLMRoberta，已经支持了，能给个环境我验一下不 — Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***>","> 好的，下午我也搞个环境发给你哈，十分感谢 >  >  >  >  回复的原邮件  >  >  > 看了下模型结构是XLMRoberta，已经支持了，能给个环境我验一下不 >  > — > Reply to this email directly, view it on GitHub, or unsubscribe. > You are receiving this because you authored the thread.Message ID: ***@***.***> 加下QQ群吧: 742130668","import mindspore from mindspore import Tensor from mindnlp.transformers import AutoModel, XLMRobertaTokenizer  from mindnlp.transformers import * model = AutoModel.from_pretrained('/home/mauser/work/bceembeddingbase_v1') tokenizer = XLMRobertaTokenizer.from_pretrained('/home/mauser/work/bceembeddingbase_v1')  推理函数 def predict_with_model(text):     label_map = {0: ""消极"", 1: ""中性"", 2: ""积极""}      对文本进行tokenize     text_tokenized = tokenizer(text, padding=True, truncation=True, max_length=64, return_tensors='np')      转换为mindspore tensor     input_ids = Tensor(text_tokenized['input_ids'])     attention_mask = Tensor(text_tokenized['attention_mask'])      模型推理     logits = model(input_ids, attention_mask)      获取预测结果     predict_label = logits[0].asnumpy().argmax()     return label_map[predict_label]  通过模型进行推理 infer_text = ""家人们咱就是说一整个无语住了 绝绝子叠buff"" predicted_label = predict_with_model(infer_text) print(f""输入文本: '{infer_text}'，预测情感: '{predicted_label}'"") 这个推理代码 ,到最后 报错: >>> predicted_label = predict_with_model(infer_text) \  Traceback (most recent call last):   File """", line 1, in    File """", line 8, in predict_with_model KeyError: 14412",你这个代码有问题，这个模型输出是词向量，我测了一下模型完全支持，把你最终想要实现的效果对应的pytorch代码发一下
这是一个用户提出需求的类型的issue，主要涉及的对象是在昇腾上运行fastwhisperlargeV3模型。,适配fast-whisper-largeV3,希望在昇腾上运行fastwhisperlargeV3 huggingface链接：https://huggingface.co/Systran/fasterwhisperlargev3,2024-03-08T03:13:49Z,requirement unrelated,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/896,whisper模型是支持的，但是动态图估计还不够快，预计要330发MindSpore 2.3alpha版本速度才能上去，,链接方便发一下么 ，或者可以给一个demo么
这个issue是用户提出需求类型，讨论新增BGE模型的适配以及提供了适配链接。,希望新增BGE模型适配,huggingface 模型连链接https://huggingface.co/BAAI/bgem3,2024-03-07T02:31:25Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/895," CC(中文embedding模型适配需求（m3elarge,bgelargezhv1.5）)  BEG模型已支持，本质上就是个BERT，我可以加个DEMO", 你好，现在支持bge的微调吗？
"这个issue类型为需求提出，主要涉及到对""starcoder2""的支持。",support starcoder2,,2024-03-06T16:19:47Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/894
这个issue是关于bug报告，涉及到mindnlp下的whisper模型在wav识别时出现了result.token_timestamps错误。这可能是由于代码逻辑错误或数据处理问题导致的。,whisper return_token_timestamps error,"when I use the whisper model for wav recognition: ``` wav, sr = torchaudio.load(file_path) input_features = processor.feature_extractor(raw_speech=wav.numpy()[0], return_tensors=""ms"", sampling_rate=16000).input_features result=model.generate(input_features, num_beams=1, max_length=80, return_timestamps=True,  return_token_timestamps=True) ``` result.token_timestamps is all zeros",2024-03-06T03:02:55Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/893,"i will check it, can you give the result of huggingface transformers?","> i will check it, can you give the result of huggingface transformers? for any audio, result.token_timestamps is not all zeros ``` import torchaudio from transformers import WhisperForConditionalGeneration, WhisperProcessor processor = WhisperProcessor.from_pretrained(r""model/whispermedium"", from_pt=True) model = WhisperForConditionalGeneration.from_pretrained(r""model/whispermedium"") wav, src = torchaudio.load('xxxxxx.wav') input_features = processor.feature_extractor(raw_speech=wav.numpy()[0], return_tensors='pt', sampling_rate=16000).input_features generated_ids = model.generate(input_features, num_beams=1, max_length=80, return_timestamps=True) transcript = processor.decode(generated_ids[0], decode_with_timestamps=True) print(transcript) ``` You can try it with these codes"," Try this code with daily build: ```python from mindnlp.data.io import audio from mindnlp.transformers import WhisperForConditionalGeneration, WhisperProcessor processor = WhisperProcessor.from_pretrained(""openai/whispermedium"") model = WhisperForConditionalGeneration.from_pretrained(""openai/whispermedium"") wav, src = audio.read('ted_767.wav') print(wav.shape) input_features = processor.feature_extractor(raw_speech=wav, return_tensors='ms', sampling_rate=16000).input_features generated_ids = model.generate(input_features, num_beams=1, max_length=80, return_timestamps=True) transcript = processor.decode(generated_ids[0], decode_with_timestamps=True) print(transcript) ```"
这是一个bug报告，主要涉及mindnlp项目中的bark encodec推断错误的问题。由于推断bug导致的症状可能是编码错误或者无法正确处理数据。,correct bark encodec inference bug,,2024-03-06T02:14:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/892
这是一个关于开发对标huggingface的TrainingAuguments类的需求提出。该问题主要涉及的对象是开发者。由于huggingface提供了优秀的TrainingAuguments类，用户想要开发一个类似的功能，以提升模型训练的效率和灵活性。,开发对标huggingface的TrainingAuguments类,,2024-03-05T15:18:42Z,requirement,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/891,正在开发中，预计三月底上线
这个issue类型是bug报告，主要涉及的对象是bark encodec inference。由于什么样的原因导致了什么样症状的bug或者用户提出了关于什么的问题或者寻求什么样的帮助在描述中并未提及。,bark encodec inference commit,,2024-03-05T06:37:59Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/890,bark模型不要改，我这个是最新的
这是一个请求更新文档的issue，涉及的主要对象是项目的README文件。,update readme,,2024-03-04T16:14:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/889
该issue属于用户提出需求类型，主要涉及对象为模型下载功能。原因可能是用户希望限制只能从Hugging Face下载模型。,only download models from huggingface,,2024-03-04T14:48:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/888
这是一个用户提出需求的类型，主要涉及Mindnlp支持Olmo模型的问题。可能是由于用户想要在Mindnlp中使用Olmo模型，但目前该模型尚未被支持，因此提出了这个需求。,support olmo model,,2024-03-04T08:55:59Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/887
这是一个bug报告，涉及的主要对象是MindSpore2.2的ESM模块。,fix esm on MindSpore2.2,,2024-03-04T00:29:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/886
这是一个bug报告，主要涉及MindNLP库在Windows环境下缺少mindspore.scripy的问题。这个问题可能是由于未正确配置依赖或者缺少相关文件导致。,fix lack of mindspore.scripy on windows,,2024-03-03T16:13:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/885
这是一个用户提出需求的issue，主要涉及的对象是要在mindnlp中添加qwen2模型。可能由于用户需要使用qwen2模型来进行特定的任务，因此提出了这个需求。,add qwen2 model,,2024-03-03T15:15:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/884
这个issue类型是用户提出需求，主要对象是在mindnlp下新增esm模型。原因是用户希望能够使用该模型进行相关的文本处理任务。,add esm model,,2024-03-03T07:43:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/883
这是一个用户提出需求的issue，主要涉及mindnlp是否能够支持qwen、qwen1.5系列的大模型。,希望 mindnlp 能支持 qwen、qwen1.5 系列的大模型,qwen 系列大模型在中文评测榜单上已经名列前茅，社区已有非常多人使用，希望能支持 qwen 系列大模型！,2024-03-03T06:10:29Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/882,今天晚上支持
这是一个bug报告，问题主要涉及到Windows平台下的ops.full操作。由于未提供具体内容，无法分析导致bug的具体原因。,fix ops.full on Windows,,2024-03-02T14:45:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/881
这是一个空内容的issue，无法确定具体类型，涉及主要对象是代码生成（codegen）。,update codegen,,2024-03-02T13:45:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/880
该issue类型是用户提出需求，该问题单涉及的主要对象是更新bark模型。由于bark模型可能存在过时或者需要改进的情况，用户提出了更新bark模型的需求。,update bark model,,2024-03-02T01:15:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/879
这是一个用户提出需求的issue，涉及到更新clip。可能是由于clip功能不足或者需要改进所致。,update clip,,2024-03-01T12:25:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/878
这是一个关于修复 chatglm3 的 bug 报告，主要涉及 chatglm3 模块。这个问题可能由于 chatglm3 模块内部的代码错误导致功能异常或者无法正常工作。,fix chatglm3,,2024-02-29T11:16:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/877
这是一个bug报告，涉及mindnlp库中的模型加载失败问题。这个问题可能是由于llm模型加载chatglm3失败引起的。,llm推理加载chatglm3失败,mindnlp                   0.2.0.20240227 tokenizers                0.15.2 device：CPU  mindspore                 2.2.11  Python                 3.8.18  windows 代码原封不动 !image !image,2024-02-27T12:44:54Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/876,chatglm3的tokenizer在7天前被修改了，我今天同步一下,fixed
这个issue类型是问题询问，主要涉及对象是如何加载CLIP模型的预训练权重。用户提出了关于加载CLIP预训练权重的问题，是否需要手动转换hugginface.co上的权重。,如何加载CLIP模型？,请问如何加载CLIP预训练权重？需要手动转换hugginface.co上的权重吗？,2024-02-27T08:47:46Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/875,不需要手动转换，这个模型没更新，明天更新下,已更新，可以直接使用AutoModel.from_pretrained加载
这是一个用户提出需求的issue，主要涉及的对象是在GitHub上的MindNLP仓库中的LayoutLM模型初始化问题。可能原因是用户尝试初始化LayoutLM时遇到了困难，需要帮助或指导。,Initialize layoutlm,,2024-02-25T07:24:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/874
这个issue类型是功能需求，主要涉及到CPM模型的更新和添加streamers，可能提出了需要更新模型和添加新功能的请求。,update cpm models & add streamers,,2024-02-23T17:38:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/873
这是一个关于bug的报告，该问题涉及MindNLP中的AutoModel.from_pretrained方法。原因可能是与token相关的功能出现了问题。,fix AutoModel.from_pretrained with token,,2024-02-22T05:25:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/872
"这是一个请求支持 ""gemma"" 的问题，类型为用户提出需求，主要对象是 gemma。这个问题可能是因为用户需要关于 gemma 的支持或帮助。",support gemma,,2024-02-22T05:08:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/871
这是一个需求类型的issue，主要涉及mindnlp的推理速度优化。 ,speed up inference,,2024-02-21T13:59:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/870
这是一个功能需求类型的issue，主要涉及MindNLP项目中的BERT模型在IMDB数据集上微调的示例添加。,add bert_imdb_finetune example,,2024-02-21T02:42:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/869
这个issue类型是bug报告，涉及到mindnlp库中pipeline和injection功能的错误修复。由于某些错误导致了pipeline和injection功能无法正常工作。,fix errors for pipeline and injection,,2024-02-20T10:07:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/868
这是一个用户提出需求的类型的issue，主要涉及支持文本分类管道，原因可能是现有功能无法满足用户的需求。,support text classification pipeline,,2024-02-20T08:43:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/867
这是一个需求类型的issue，主要对象是支持minicpm，可能是由于缺乏相关功能导致用户提出需求。,support minicpm,,2024-02-18T08:39:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/866
这是一个用户提出需求的issue，主要涉及的对象是对模型Hubert的添加。,add Hubert model,"Contents update:  Hubert: model  Wav2Vec: processor, feature_extractor, tokenizer  weight_norm  hijacks    new: GroupNorm, Parameter inits    fix: LayerNorm, Dense The commit passed all following tests (on Windows): ```shell  unittest SET RUN_SLOW=1 pytest v s tests/ut/transformers/models/hubert/test_modeling_hubert.py  pylint pylint rcfile=.github/pylint.conf mindnlp\injection.py pylint rcfile=.github/pylint.conf mindnlp\modules\functional\weight_norm.py pylint rcfile=.github/pylint.conf mindnlp\transformers\models\hubert pylint rcfile=.github/pylint.conf mindnlp\transformers\models\wav2vec2 pylint rcfile=.github/pylint.conf tests\ut\transformers\models\hubert pylint rcfile=.github/pylint.conf tests\ut\transformers\models\wav2vec2 ```",2024-02-07T13:08:34Z,,closed,0,5,https://github.com/mindspore-lab/mindnlp/issues/865,c7ad0b8 删去了依赖项 `pyctcdecode`， 将在后续 Wav2Vec2 中添加,d96d1b9 Parameter inits refactor & bugfix,add Wav2Vec2 model The commit passed all following tests (on Windows): ```  unittest pytest v s tests/ut/transformers/models/wav2vec2/test_feature_extraction_wav2vec2.py pytest v s tests/ut/transformers/models/wav2vec2/test_tokenization_wav2vec2.py pytest v s tests/ut/transformers/models/wav2vec2/test_processor_wav2vec2.py pytest v s tests/ut/transformers/models/wav2vec2/test_modeling_wav2vec2.py  pylint pylint rcfile=.github/pylint.conf mindnlp\transformers\models\wav2vec2 pylint rcfile=.github/pylint.conf tests\ut\transformers\models\wav2vec2 ```,Pylint问题需要修一下,> Pylint问题需要修一下 早上修了 https://github.com/mindsporelab/mindnlp/pull/865/commits/ebeeb304981d694d43967de08d8a34244fe1f390
这是一个用户提出需求的issue，主要涉及MindNLP库中使用jieba替换cjieba的问题。原因可能是jieba更普遍、更稳定、或者包含更多的功能。,use jieba instead of cjieba,,2024-02-07T08:02:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/864
"这是一个bug报告，主要涉及的对象是CellUtilMixin类。由于移除了名称为""ut""的方法导致此bug产生。",remove CellUtilMixin ut,,2024-02-05T07:15:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/863
这是一个bug报告，主要涉及的对象是model.half()方法。由于在调用model.half()方法时出现错误，需要修复这个bug。,fix model.half() error,,2024-02-05T04:13:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/862
这是一个bug报告，主要涉及pop2piano工具的问题。由于修复不完整或错误的代码导致了这个bug。,fix pop2piano ut,,2024-02-02T20:27:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/861
这是一个用户提出需求的issue，主要涉及到添加BERT的自动并行训练，由于需要修改MindSpore的源代码，可能用户希望实现BERT模型在MindSpore中自动并行训练的功能。,add auto parallel training for bert,use mindspore auto parallel. > still need to change mindspore's source code to enable `model.build()` for `GPU`,2024-02-01T14:44:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/860
这是一个需求提出类的issue，主要涉及音乐生成模型Pop2piano的添加。原因可能是用户想要在Mindnlp中使用Pop2piano生成钢琴音乐。,Add Pop2piano ,,2024-02-01T09:34:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/859
该issue属于功能需求类型，主要涉及的对象是Cell类。用户提出需求支持Cell类中的half()和float()方法。,support Cell.half()/Cell.float(),,2024-02-01T03:27:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/858
该issue类型为用户提出需求，主要对象是mindnlp下的utils工具包。原因是希望为工具包添加python懒加载模块。,add python _LazyModule,为utils工具包添加python懒加载模块,2024-01-30T16:11:55Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/857,这个模块我们应该用不到，加上去有啥好处？
这是一个bug报告，涉及Mindnlp执行推断时出现的TypeError错误问题。导致这个问题的原因可能是输入类型不匹配导致出错。,"执行推断时出错TypeError: For primitive[Dense], the input type must be same.","If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** 执行推断时报错： TypeError: For primitive[Dense], the input type must be same. name:[w]:Ref[Tensor[Float32]]. name:[x]:Tensor[Float16].  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend 910B3  **Software Environment / 软件环境 (Mandatory / 必填)**: Mindspore 20231215  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: Graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 使用bert类型的model，先用tokenizer进行encode，随后使用Tensor转为Tensor，最后使用model(Tensor)获得logistics **Expected behavior / 预期结果 (Mandatory / 必填)** 输出一个embedding序列 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2024-01-30T07:15:57Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/856,"```python from mindnlp.models import MSBertModel import mindspore from mindnlp.transformers import BertTokenizer from mindspore import Tensor import json import numpy as np from gaussdb_vector.gauss_db_vector import GaussDBVector from gaussdb_vector.gauss_table import FieldSchema, IndexSchema, TableSchema from gaussdb_vector.gauss_types import DataType, MetricType, IndexType, IndexParamType, IndexParams import sys sys.path.append('/home/workspace/dongjian/gauss_test/code/gauss_python_program/gaussdb_vector')  tokenizer = BertTokenizer.from_pretrained('/home/mauser/data/bert_base_chinese') tokenizer = BertTokenizer.from_pretrained('/home/workspace/dongjian/gauss_test/code/m3e_model') mindspore.set_context(mode=mindspore.GRAPH_MODE)  model = MSBertModel.from_pretrained('/home/mauser/data/bert_base_chinese') model = MSBertModel.from_pretrained('/home/workspace/dongjian/gauss_test/code/m3e_model') model = model.to_float(mindspore.float16) def predict(text, label=None):      print(tokenizer.encode(text))      if len(tokenizer.encode(text).idx) >= 512:     if len(tokenizer.encode(text)) >= 512:         return None      text_tokenized = Tensor([tokenizer.encode(text).ids])     print(tokenizer.encode(text))     text_tokenized = Tensor(np.array(tokenizer.encode(text)))     print(type(text_tokenized))     logits = model(text_tokenized)     print(logits[0].shape)     embedding = np.mean(logits[0][0].asnumpy(), axis=0)     embedding = embedding.tolist()     return embedding print(predict('你好')) ```"
这是一个bug报告类型的issue，涉及的主要对象是mindspore 2.1版本。原因可能是mernie & ernie_m在GRAPH_MODE下不支持，导致用户提出了需要支持此功能的问题。,mernie & ernie_m on GRAPH_MODE support mindspore 2.1 version,,2024-01-30T03:26:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/855
这是一个bug报告，主要涉及的对象是MindNLP库中的`__init__`模块。这个问题可能是由于`__init__`模块中存在错误导致出现了初始化错误。,fix __init__ error,,2024-01-30T02:41:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/854
"这个issue属于用户提出需求类型，主要涉及的对象是添加名为""regnet""的模型到mindnlp中。由于缺少regnet模型目录和初始化文件，用户希望将其添加到mindnlp中。",add regnet model,创建了regnet目录，并初始化init文件,2024-01-29T16:33:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/853
这是一个请求需求类型的issue，主要涉及的对象是Electra模型初始化。原因可能是开发者之前未实现相关功能，用户提出这个需求来初始化Electra模型。,Initialize Electra model,,2024-01-29T14:54:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/852,这是来自QQ邮箱的假期自动回复邮件。 您好，我最近正在休假中，无法亲自回复您的邮件。我将在假期结束后，尽快给您回复。
这是一个需求提出类型的issue，主要涉及的对象是pangu更新。由于用户想要更新pangu，因此提出了这个需求。,update pangu,,2024-01-29T04:57:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/851
这是一个bug报告，涉及的主要对象是pytorch模型加载时出现的错误。这个issue反映了无法加载ckpt文件的问题，可能是由于numpy.lib.stride_tricks.as_strided函数造成的。,fix pytorch ckpt load error by numpy.lib.stride_tricks.as_strided,,2024-01-28T16:08:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/850
这是一个需求更新的issue，主要对象是whisper ut & crf ut。由于需要维护和更新代码库，用户提出了更新的需求。,update whisper ut & crf ut,,2024-01-28T13:23:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/849
"这是一个需求。该问题单涉及的主要对象是更新名为""bloom""的功能。",update bloom,,2024-01-28T12:44:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/848
这个issue是关于需求更新的，涉及到phi模型。原因可能是需要改进模型功能或性能。,update phi model,,2024-01-28T05:38:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/847
"这是一个bug报告，该问题单涉及的主要对象是""rwkv""模块。由于""rwkv""模块的更新导致了某种bug或者用户提出了关于该模块的问题或者寻求相关帮助。",update rwkv,,2024-01-27T16:43:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/846
这个issue类型是用户提出需求，该问题单涉及的主要对象是XLMRobertaModel。由于XLMRobertaModel目前不支持AutoModel，用户提出希望增加对AutoModel的支持。,XLMRobertaModel support AutoModel,,2024-01-27T03:47:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/845
这是一个用户提出需求的issue，主要涉及对象是为MindNLP添加关于phi2的Streamlit示例。由于缺少此示例，用户请求添加以展示如何在Streamlit中使用phi2。,add streamlit example for phi2,,2024-01-26T14:21:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/844
这是一个bug报告类型的issue，主要涉及Phi2模型推理时避免后端异步错误。出现该问题的原因可能是后端代码无法正确处理异步请求，导致模型推理出现错误。,avoid backend async error for Phi2 model inference,,2024-01-26T09:30:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/843
这个issue类型是bug报告，主要涉及的对象是GPTForSequenceClassification模块，由于动态形状错误和Ascend处理器的问题导致bug。,fix GPTForSequenceClassification dynamic shape error & use static sha…,…pe on Ascend,2024-01-26T06:16:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/842
这是一个bug报告，该问题涉及mindnlp项目中的图模式下的数据连接失败。导致这个bug的原因可能是某些数据连接的相关代码问题。,fix Type Join Failed on graph mode,,2024-01-26T02:11:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/841
这是一个bug报告，涉及到MBart错误的修复。由于MBart错误，用户在使用时遇到了问题。,fix mbart errors,,2024-01-24T12:25:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/840
这个issue类型是用户提出需求，主要涉及的对象是添加mbart模型。这个问题可能是由于使用mbart模型能够提高多语言处理效果的需求而导致。,add mbart model,,2024-01-24T07:47:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/839
这是一个bug报告，涉及到MindNLP项目中BART模型在Ascend硬件上出现错误的问题。可能是由于硬件兼容性或代码实现问题导致的。,fix bart errors on Ascend,,2024-01-23T17:26:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/838
这是一个用户提出需求的 issue，主要对象是更新名为bart的功能。由于需要添加新功能或改进现有功能，用户提出了对bart的更新请求。,update bart,,2024-01-23T16:06:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/837
这是一个bug报告，主要涉及到在执行 GPTForSequenceClassification.construct 方法时存在张量维度不匹配的问题。这可能是由于模型设计或输入数据格式不匹配导致的。,gpt_imdb_finetune任务训练时执行 GPTForSequenceClassification.construct 方法时，存在张量维度不匹配的问题。,"环境为：openI智算集群910npu，mindspore2.2.1，mindnlp0.2.0， 项目地址为：https://github.com/mindsporelab/mindnlp/blob/master/examples/classification/gpt_imdb_finetune.ipynb 执行代码为 ```python from mindnlp.transformers import GPTForSequenceClassification  set bert config and define parameters for training model = GPTForSequenceClassification.from_pretrained('openaigpt', from_pt=True, num_labels=2) model.config.pad_token_id = gpt_tokenizer.pad_token_id model.resize_token_embeddings(model.config.vocab_size + 3) optimizer = nn.Adam(model.trainable_params(), learning_rate=2e5) metric = Accuracy()  define callbacks to save checkpoints ckpoint_cb = CheckpointCallback(save_path='checkpoint', ckpt_name='gpt_imdb_finetune', epochs=1, keep_checkpoint_max=2) best_model_cb = BestModelCallback(save_path='checkpoint', ckpt_name='gpt_imdb_finetune_best', auto_load=True) trainer = Trainer(network=model, train_dataset=dataset_train,                   eval_dataset=dataset_train, metrics=metric,                   epochs=3, optimizer=optimizer, callbacks=[ckpoint_cb, best_model_cb],                   jit=False) ``` 报错代码为 ``` ValueError: The accumulate of x_shape must be equal to out_shape, but got x_shape: [const vector]{8192, 2}, and out_shape: [const vector]{16, 445, 2}   Ascend Warning Message:  W11001: Op [Range] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [Cast] does not hit the highpriority operator information library, which might result in compromised performance. W11001: Op [DropOutGenMask] does not hit the highpriority operator information library, which might result in compromised performance. W49999: If want to reuse binary file, please donwload binary file and install first![FUNC:BuildFusionOp][FILE:fusion_manager.cc][LINE:4254]   C++ Call Stack: (For framework developers)  mindspore/core/ops/reshape.cc:89 update_shape ```",2024-01-22T15:47:02Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/836,试一下最新代码呢？
该issue属于用户提出需求，并希望添加mbart模型。,add mbart model,add mbart model,2024-01-19T14:51:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/835
这是一个用户提出需求的issue，主要涉及的对象是在mindnlp中添加图注意力模型（Graphormer）微调的功能。,add graphormer finetune,,2024-01-17T22:28:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/834
这是一个功能需求提出的issue，主要涉及到添加phi_2模型和加快加载速度；由于速度较慢的模型加载，用户提出需要添加一个新模型并改善加载速度。,add phi_2 model & speed up ckpt load,,2024-01-17T14:23:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/833
这个issue类型是用户提出需求，主要涉及对象是ERNIE & ERNIE_M模型的支持图模式，用户提出希望支持图模式的功能。,ernie & ernie_m support graph mode,,2024-01-16T10:05:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/832
这是一个用户提出需求的issue，主要涉及mindnlp对xlm-robert-base和xlm-roberta-large模型的适配问题，导致无法对bgerank模型进行解析。,请新增适配xlm-robert-base ，xlm-roberta-large,"你好， 我在使用mindnlp对bgerank模型进行解析的过程中遇到目前不支持xlmrobertbas The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'.  并且希望可以使用large模型，所以话希望可以适配xlmrobertalarge BAAI/bgererankerlarge https://huggingface.co/BAAI/bgererankerlarge/blob/main/config.json ""_name_or_path"": ""xlmrobertalarge"", ""XLMRobertaForSequenceClassification"" BAAI/bgererankerbase https://huggingface.co/BAAI/bgererankerbase/blob/main/config.json ""_name_or_path"": ""xlmrobertabase"", ""XLMRobertaForSequenceClassification""",2024-01-15T08:43:11Z,,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/831,"已经找到【/home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/mindnlp/transformers/models/xlm_roberta】，tokenization_xlm_roberta.py还没有完成，但是我使用XLMRobertaModel解析模型没有解析成功，报错 from  mindnlp.transformers import XLMRobertaModel model = XLMRobertaModel.from_pretrained('/home/Embedding/FlagEmbedding/FlagEmbedding/baai_general_embedding/finetune/BAAI/bgererankerbase') model.eval() 报错： (embedding_J) [root home] /home/anaconda3/envs/embedding_J/bin/python /home/Embedding/FlagEmbedding/FlagEmbedding/baai_general_embedding/finetune/demo_rank.py /home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) Traceback (most recent call last):   File ""/home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 897, in load_ckpt     state_dict = load_checkpoint(str(resolved_archive_file))   File ""/home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/mindspore/train/serialization.py"", line 1027, in load_checkpoint     ckpt_file_name = _check_ckpt_file_name(ckpt_file_name)   File ""/home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/mindspore/train/serialization.py"", line 1147, in _check_ckpt_file_name     raise ValueError(""For 'load_checkpoint', the checkpoint file should end with '.ckpt', please "" ValueError: For 'load_checkpoint', the checkpoint file should end with '.ckpt', please input the correct 'ckpt_file_name'. The above exception was the direct cause of the following exception: Traceback (most recent call last):   File ""/home/Embedding/FlagEmbedding/FlagEmbedding/baai_general_embedding/finetune/demo_rank.py"", line 19, in      model = XLMRobertaModel.from_pretrained('/home/Embedding/FlagEmbedding/FlagEmbedding/baai_general_embedding/finetune/BAAI/bgererankerbase')   File ""/home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 992, in from_pretrained     state_dict = load_ckpt(resolved_archive_file, from_pt)   File ""/home/anaconda3/envs/embedding_J/lib/python3.9/sitepackages/mindnlp/transformers/modeling_utils.py"", line 899, in load_ckpt     raise OSError( OSError: Unable to load weights from mindspore checkpoint file '/home/Embedding/FlagEmbedding/FlagEmbedding/baai_general_embedding/finetune/BAAI/bgererankerbase/model.safetensors'.  double free or corruption (out) 错误信息显示期望加载 .ckpt 文件，但实际尝试加载的是 model.safetensors 文件。 似乎还并不支持模型",最近更新了下，再试试,> 最近更新了下，再试试 tokenization_xlm_roberta.py还是空的，不需要用到吗？ 还是说没配置AutoModel，希望用mindnlp解析的话怎么操作，改什么呢 我看下,AutoModel已支持
"这是一个用户提出需求的issue，主要对象是要求在mindnlp中添加""add falcon finetune""功能。",add falcon finetune,!image,2024-01-15T02:32:25Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/830,加一个readme，说明下： 1. 数据集下载 2. 训练命令,> 需不需要加一个调用train_mrpc.py的bash脚本？ 这个可以不加
这是一个需求类型的issue，主要涉及对象是mindnlp下的falcon模块，用户提出需添加falcon finetune功能。可能是因为用户希望能够使用finetune功能来对falcon模型进行微调，以满足特定任务需求。,add falcon finetune,!image,2024-01-15T02:28:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/829
这个issue类型是bug报告，主要涉及mindnlp库中的代码错误导致train_dataset.create_tuple_iterator()输出数据时报错。,gpt2文本摘要示例中通过train_dataset.create_tuple_iterator()输出数据时报错," 环境： openI启智算力集群单卡npu算力，镜像为mindspore2.2_cann7+mindnlp master  执行代码： ```python import numpy as np tokenizer = BertTokenizer.from_pretrained('bertbasechinese') def process_dataset(dataset, tokenizer, batch_size=8, max_seq_len=1024, shuffle=False):     def read_map(text):         data = json.loads(text.tobytes())         return np.array(data['article']), np.array(data['summarization'])     def merge_and_pad(article, summary):         article_len = len(article)         summary_len = len(summary)         sep_id = np.array([tokenizer.sep_token_id])         pad_id = np.array([tokenizer.pad_token_id])         if article_len + summary_len > max_seq_len:             new_article_len = max_seq_len  summary_len             merged = np.concatenate([article[:new_article_len], sep_id, summary[1:]])         elif article_len + summary_len  1  1 next(train_dataset.create_tuple_iterator()) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/validators.py:988, in check_tuple_iterator..new_method(self, *args, **kwargs)     985 if columns is not None:     986     check_columns(columns, ""column_names"") > 988 return method(self, *args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:1579, in Dataset.create_tuple_iterator(self, columns, num_epochs, output_numpy, do_copy)    1577 if Dataset._noop_mode():    1578     return DummyIterator(self, 'tuple', output_numpy) > 1579 return TupleIterator(self, columns, num_epochs, output_numpy, do_copy) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/iterators.py:290, in TupleIterator.__init__(self, dataset, columns, num_epochs, output_numpy, do_copy)     288         columns = [columns]     289     dataset = dataset.project(columns) > 290 super().__init__(dataset, num_epochs, output_numpy, do_copy) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/iterators.py:75, in Iterator.__init__(self, dataset, num_epochs, output_numpy, do_copy)      72  create a copy of tree and work on it.      73 self.__ori_dataset = dataset > 75 self.ir_tree, self.dataset = dataset.create_ir_tree()      77 self._runtime_context = cde.PythonRuntimeContext()      78 self._runtime_context.Init() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:406, in Dataset.create_ir_tree(self, getter_mode)     404 global _OP_NAME     405 _OP_NAME = Dataset._get_operator_id(dataset) > 406 ir_tree = dataset.parse_tree(getter_mode)     407 self.parent = parent     408 _init_device_info() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:423, in Dataset.parse_tree(self, getter_mode)     421 if len(self.parent) > 1:     422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"") > 423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool     426 self.pre_parse(getter_mode) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:423, in (.0)     421 if len(self.parent) > 1:     422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"") > 423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool     426 self.pre_parse(getter_mode) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:423, in Dataset.parse_tree(self, getter_mode)     421 if len(self.parent) > 1:     422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"") > 423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool     426 self.pre_parse(getter_mode) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:423, in (.0)     421 if len(self.parent) > 1:     422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"") > 423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool     426 self.pre_parse(getter_mode)     [... skipping similar frames:  at line 423 (15 times), Dataset.parse_tree at line 423 (15 times)] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:423, in Dataset.parse_tree(self, getter_mode)     421 if len(self.parent) > 1:     422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"") > 423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool     426 self.pre_parse(getter_mode) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:423, in (.0)     421 if len(self.parent) > 1:     422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"") > 423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool     426 self.pre_parse(getter_mode) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/dataset/engine/datasets.py:422, in Dataset.parse_tree(self, getter_mode)     412 """"""     413 Internal method to parse the API tree into an IR tree.     414     (...)     419     DatasetNode, the root node of the IR tree.     420 """"""     421 if len(self.parent) > 1: > 422     raise ValueError(""The data pipeline is not a tree (i.e., one node has 2 consumers)"")     423 ir_children = [d.parse_tree(getter_mode) for d in self.children]     424  Bootstrap can only be performed on a copy of the original dataset node.     425  Bootstrap on original dataset node will make all iterators share the same process pool ValueError: The data pipeline is not a tree (i.e., one node has 2 consumers) ```",2024-01-12T07:12:56Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/828,这应该是你多次对同一个dataset处理导致的，不是问题
这个issue属于用户提出需求，主要涉及的对象是Mindnlp。由于Ascend平台上不支持flash attention，用户提出需要在Ascend平台上支持flash attention。,support flash attention on Ascend,,2024-01-12T03:14:10Z,requirement,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/827
这个issue是用户提出需求。该问题涉及主要对象是添加 LongStorage 支持。,add LongStorage support,,2024-01-12T02:30:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/826
这是一个bug报告，主要涉及到MindNLP的设置错误。原因导致了无法正确设置的bug。,fix setup error,,2024-01-12T02:24:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/825
这是一个bug报告类型的issue，涉及主要对象是用于load pytorch checkpoint的功能。由于参数dtype cast缺失，导致bug出现或用户提出了相关问题。,"support load pytorch checkpoint(*.bin) directly, and fix missing valu…",…e parameter dtype cast.,2024-01-11T16:48:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/824
这是一个bug报告，涉及到mindnlp中的模型加载参数类型转换问题。由于在modeling_utils.py中先转换参数数据类型再加载参数进model，导致key_missing参数不能正确类型转换。,模型加载参数类型转换问题,modeling_utils.py中先转换参数数据类型，再把参数加载进model，导致key_missing参数不能正确类型转换 !image !image,2024-01-11T13:08:59Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/823
这是一个用户提出的需求类型的issue，主要对象是mindnlp的API文档。由于API文档是英文的，用户希望提供中文翻译，以帮助更多后来学习mindnlp的用户。,我可以协助翻译mindnlp的api文档,我看mindspore上的api文档都是中文的，mindnlp上的api文档却是英文的，目前我正在学习mindnlp，可以帮助翻译一下文档，帮助更多后来学习mindnlp的同学，不知道行不行,2024-01-10T13:32:22Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/822,感谢感谢，请加群721548151
这个issue类型为功能需求，主要对象是Tensor.expand函数。由于该函数目前不支持以元组或列表形式作为输入扩展维度，用户提出了增加这一功能的需求。,Tensor.expand support tuple/list as input,,2024-01-10T02:00:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/821
这是一个用户提出需求的类型，该问题单涉及的主要对象是在mindnlp项目中添加uie推理代码的功能。,add uie inference code,,2024-01-09T09:56:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/820
这个issue类型为bug报告，主要涉及的对象是mindnlp下的代码库中的robert模型，问题是因为token_type_ids.tile操作导致了内存溢出问题。,fix robert token_type_ids.tile caused oom problem,,2024-01-09T09:07:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/819
这是一个bug报告，主要涉及的对象是mindnlp下的mindspore 2.3，由于np.finfo错误导致了bug症状。,fix np.finfo error for mindspore 2.3,,2024-01-09T08:51:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/818
这是一个用户提出需求类型的issue，主要涉及Mindnlp缺少用于Mask LM任务的数据集处理器。造成该需求的原因是用户在预训练模型时需要进行mask等处理，但目前的Mindnlp功能不支持该处理器。,希望可以提供用于Mask LM任务的数据集处理器,在预训练一个模型的时候，需要对该数据集进行mask等处理，但mindnlp缺少相应的处理器。希望能够支持该功能！,2024-01-08T07:06:26Z,requirement,open,0,3,https://github.com/mindspore-lab/mindnlp/issues/817,这周我写个用例,> 在预训练一个模型的时候，需要对该数据集进行mask等处理，但mindnlp缺少相应的处理器。希望能够支持该功能！ 你是要预训练bert吗,> > 在预训练一个模型的时候，需要对该数据集进行mask等处理，但mindnlp缺少相应的处理器。希望能够支持该功能！ >  > 你是要预训练bert吗 是的是的
这是一个用户提出需求的issue，主要涉及的对象是在mindnlp框架下预训练llama模型所需的运行环境。由于无法准确加载或训练llama模型，用户请求提供相关的运行环境，希望得到帮助。,希望可以提供llama在此框架下预训练所需运行环境,在modelarts的开发环境中试了很多镜像和尝试安装不同的mindspore版本都无法准确加载或者训练llama模型，希望可以提供一下相关的运行环境，比如说mindspore版本其他依赖版本等。如果可以提供预训练示例代码就更好了，感谢作者大大,2024-01-02T13:44:30Z,requirement,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/816,是llm目录下的吗？ 当前master分支需要mindspore>=2.2.0,预训练由于现在动态图没有实现zero，所以只能用静态图，可以去mindformers做预训练，如果想要和pytorch+transformers一样的用法，估计得等等。,十分感谢，大致有了点方向！
这个issue是关于bug报告，主要涉及ernie_m模型在fp16计算中出现NaN问题。可能是由于fp16计算精度的问题导致了NaN值的出现。,fix ernie_m fp16 nan problem,,2023-12-27T09:32:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/815
这个issue是用户提出需求，主要对象是支持uie & uie_m。由于缺少具体描述内容，无法分析具体问题的原因。,support uie & uie_m,,2023-12-26T15:45:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/814
这是一个需要填充内容的issue，类型是用户提出需求。该问题单涉及的主要对象是Bark提交功能。由于未填写具体内容，用户提出了对Bark提交功能的相关问题或需求。,Bark提交,,2023-12-26T06:43:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/813
这个issue是一个bug报告，涉及主要对象是Bark精度。导致此bug的原因可能是数据处理错误或算法实现问题。,Bark精度通过,,2023-12-26T06:07:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/812
这个issue属于质量问题，主要涉及的对象是encodec模块。原因可能是某些输入数据导致的精度问题。,encodec 精度测试通过,,2023-12-25T04:13:17Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/811,Pylint没过
这个issue类型是需求提出，主要涉及的对象是支持UIE和ERNIE模型。,support uie & ernie,,2023-12-20T03:42:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/810
这是一个bug报告，主要涉及mindnlp项目下的修复bug工作。由于出现了未具体描述的bug，用户提出需要修复。,fix bugs,,2023-12-17T16:30:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/809
这是一个bug报告，涉及主要对象是MindNLP库中的bias_add函数。这个issue可能是由于bias_add函数在使用过程中出现错误导致的。,fix bias_add error,,2023-12-17T09:14:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/808
这个issue是用户提出需求。主要对象是mindnlp下的chatglm2 & chatglm3模块。,support chatglm2 & chatglm3,,2023-12-17T01:16:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/807
这是一个用户提出需求的类型，该问题单涉及的主要对象是新增功能的添加。原因是用户请求添加名为seamless_m4t和seamless_m4t_v2的功能。,add seamless_m4t & seamless_m4t_v2,,2023-12-16T06:32:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/806
这是一个用户提出需求的 issue， 主要涉及的对象是调整 `gpt_bigcode-santacoder` 模型的性能。,Tuning `gpt_bigcode-santacoder` with peft lora,,2023-12-15T12:41:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/805
这是一个bug报告，主要对象是代码中的数据类型错误，由于缺少easydict的使用导致。,use easydict to fix dict type error,,2023-12-15T08:10:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/804
这是一个用户提出需求的类型，主要对象是增加chatglm图实现和使用ops.dense的功能。原因可能是为了增加模型的功能或提升性能。,add chatglm graph implementation & use ops.dense,,2023-12-15T07:15:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/803
这是一个用户提出需求的issue，主要对象是在mindnlp的README中希望添加代码使用示例。原因可能是用户需要更直观的代码示例来理解如何使用该项目。,希望在README怎么代码使用示例,如： !image,2023-12-14T05:03:21Z,documentation requirement,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/802,最近在招人更新文档了,最新readme已增加
这是一个bug报告，主要涉及mindnlp库的llama推理代码和cache加载功能。该issue可能由于推理代码的错误或缓存加载问题而导致bug或功能异常。,fix llama inference code & load_from_cache,,2023-12-13T12:22:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/801
这是一个用户提出需求的issue，主要涉及适配模型facebook/seamless-m4t-v2-large。用户请求添加对该模型的适配支持。,建议适配模型facebook/seamless-m4t-v2-large,https://huggingface.co/facebook/seamlessm4tv2large facebook推出业界领先的allinone翻译模型，建议适配。,2023-12-13T09:24:02Z,requirement,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/800,ok,已适配，目前mindspore不支持weight_norm，因此暂不支持对标训练,"$ python c 'from mindnlp.transformers import SeamlessM4Tv2Model;model = SeamlessM4Tv2Model.from_pretrained(""/home/fuq/ckpt/seamlessm4tv2large"", from_pt=True)' Segmentation fault (core dumped) $ pytest c pytest.ini tests/ut/transformers/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelIntegrationTest::test_to_rus_speech =========================================================================== test session starts ===========================================================================platform linux  Python 3.7.5, pytest7.4.3, pluggy1.2.0 rootdir: /home/fuq/mindnlp configfile: pytest.ini plugins: anyio3.7.1 collected 1 item                                                                                                                                                           tests/ut/transformers/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelIntegrationTest::test_to_rus_speech Fatal Python error: Segmentation fault","OS:ubuntu 18.04.5 server CPU：X86_64 NPU:910B 32G MS:2.2.0 CANN:7.0.RC1.beta1 $ pytest c pytest.ini tests/ut/transformers/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelIntegrationTest::test_to_rus_speech =========================================================================== test session starts ===========================================================================platform linux  Python 3.9.18, pytest7.4.3, pluggy1.3.0 rootdir: /home/fuq/mindnlp configfile: pytest.ini collected 1 item                                                                                                                                                           tests/ut/transformers/models/seamless_m4t_v2/test_modeling_seamless_m4t_v2.py::SeamlessM4Tv2ModelIntegrationTest::test_to_rus_speech Fatal Python error: Segmentation fault"
这是一个功能需求的issue，主要涉及对象是支持pytorch模型的加载和保存。原因可能是现有方法不够方便或者不够灵活。,support load pytorch checkpoint(*.bin) directly.,1. use pickle instead of ms.load_checkpoint 2. support save model by pickle.,2023-12-13T08:49:09Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/799
这个issue是关于bug报告，涉及的主要对象是mindspore 2.2中longformer模型的Tensor.stride()函数，由于未正确处理Tensor.stride()导致了bug。,fix Tensor.stride() for longformer on mindspore 2.2,,2023-12-12T10:54:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/798
这是一个需求类型的issue，主要对象是支持旧版本。由于用户可能在使用过程中遇到兼容性问题或对旧版本的功能有需求，因此提出了支持旧版本的需求。,support old version,,2023-12-12T09:42:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/797
这个issue属于用户提出需求类型，涉及的主要对象是支持chatglm2。,support chatglm2,,2023-12-12T07:25:12Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/796
这个issue属于需求提出类型，主要涉及支持混合MOE模型(7b*8)，用户提出了对新模型的需求。,support mixtral moe model(7b*8),,2023-12-12T06:56:42Z,requirement,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/795,see https://github.com/lvyufeng/mistralmindspore
这是一个需求类型的issue，涉及的主要对象是chatglm模块。,add test_chat_random_init ut for chatglm,,2023-12-10T14:53:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/794
这是一个bug报告类型的issue，主要涉及的对象是mindnlp中的Longformer模型。由于Longformer需要更新，导致出现了bug或需要进行相关问题的升级和修复。,update longformer,,2023-12-10T13:37:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/793
这是一个用户提出需求的issue，主要涉及mindnlp中支持在GPU上进行快速注意力的功能。原因可能是当前版本没有实现此功能，用户希望使用mindspore的aot自定义运算符来解决这个问题。,support flash attention on GPU,use mindspore aot custom operator,2023-12-09T15:01:17Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/792
这是一个需求类型的issue， 主要涉及的对象是支持Mistral。用户提出了关于支持Mistral的需求。,support mistral,,2023-12-09T13:27:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/791
这是一个bug报告类型的问题，涉及的主要对象是mindnlp library。原因是出现了错误，但具体内容未提供。,fix error,,2023-12-09T07:59:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/790
"该issue类型为用户提出需求，主要对象是增加一个名为""zero_init""的功能。",add zero_init,,2023-12-09T05:37:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/789
这是关于迁移Falcon模型的问题，属于功能需求类别，主要涉及Falcon模型。由于未提供具体内容，无法确定具体原因或症状。,migration of falcon model,,2023-12-08T09:45:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/788
这是一个关于模型迁移的问题，主要涉及到Falcon模型。问题可能是由于库的更新或者项目结构变动导致模型无法正常迁移。,migration of falcon model,,2023-12-08T09:34:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/787
这是一个关于迁移Falcon模型的问题，类型为需求。该问题涉及Falcon模型的迁移。原因可能是为了实现更高级别的功能或是解决之前版本的问题。,migration of falcon model ,,2023-12-08T09:20:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/786
这是一个缺少具体内容的issue，无法确定是bug报告还是其它类型，主要对象涉及到falcon model。,migration of falcon model,,2023-12-08T09:10:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/785
这个issue类型为迁移（migration）问题，主要涉及的对象是falcon model。由于某种原因导致了模型迁移过程中出现的bug或问题。,migration of falcon model,,2023-12-08T07:56:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/784
这是一个bug报告，主要涉及mindnlp库中的示例更新到动态形状。可能由于动态形状的更改，导致示例中的部分代码出现错误或不适配的情况。,update examples to dynamic shape,,2023-12-08T06:14:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/783
这是一个 bug 报告，涉及的主要对象是 `MaskedFill` 操作。 据描述，这个 issue 是由于 `MaskedFill` ops 存在问题导致的。,Fix `MaskedFill` ops's issue.,,2023-12-07T15:07:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/782
这个issue类型为代码更新需求，主要涉及的对象是longT5模型。可能是由于mindnlp的最新修改，需要对longT5的代码进行相应更新。,update_longt5_2,根据最新的mindnlp修改longT5的代码。,2023-12-07T08:19:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/781
该issue属于用户提出需求类型，主要涉及更新gpt模型和示例。由于使用的模型需要更新或改进，用户希望更新gpt模型及示例。,update gpt model & example,,2023-12-07T03:50:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/780
这是一个关于Falcon模型迁移的需求提出 issue，主要涉及到Falcon模型和其迁移过程。由于原因未提供，无法确定具体问题症状或用户所需帮助内容。,Falcon model migration,,2023-12-07T03:15:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/779
这是一个用户提出需求的类型，该问题涉及到Graphormer模型迁移。用户可能遇到了模型迁移的困难或者需要帮助进行相关的迁移操作。,Graphormer model migration,,2023-12-06T20:57:17Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/778,Finished the first stage of Graphormer model migration from PyTorch to mindspore.
这是一个bug报告，主要涉及到MindNLP库中的AutoTokenizer对`gpt_bigcode`的修复。可能由于当前AutoTokenizer无法正确处理`gpt_bigcode`相关操作导致bug出现。,fix AutoTokenizer for `gpt_bigcode`,,2023-12-06T15:53:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/777
这个issue为需求更新(chatglm)的类型，主要涉及到Mindnlp的chatglm模块。由于可能有新功能需求或者更新需求导致此issue的创建。,update chatglm,,2023-12-06T12:51:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/776
这个issue类型是需求更新，主要涉及chatglm功能的更新。,update chatglm,,2023-12-05T16:16:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/775
这是一个bug报告类型的issue，涉及的主要对象为Ascend（AI芯片）。由于ACL和VM之间的冲突，导致了bug症状。,fix conflict of ACL and VM on Ascend,,2023-12-05T09:31:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/774
这个issue类型是需求新增，涉及的主要对象是代码库中的UT（unit test）。这个issue由于作者没有填写具体内容，未能说明需要新增什么样的UT。,add new  ut,,2023-12-05T03:29:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/773
这是一个bug报告，主要对象是autoformer uts模块。由于什么样的原因导致了什么样症状的bug尚未提供具体信息。,fix autoformer uts,,2023-12-05T02:58:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/772
这是一个空内容的issue，无法确定具体问题类型及主要对象。,一点点修改,,2023-12-05T01:36:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/771
这是一个bug报告，主要涉及mindnlp中LLAMA模型的import错误，可能由于mindnlp版本0.2.0导致。,[mindnlp]LLAMA代码import错误,使用最新版mindnlp运行llm/inference/llama/llama/model.py时出现如下错误： !image 版本为mindnlp0.2.0.20231204,2023-12-04T07:46:47Z,bug,closed,0,4,https://github.com/mindspore-lab/mindnlp/issues/770,我看一下,目录变了，我今天修改一下demo代码,好的，多谢,fixed
这是一个bug报告，涉及主要对象是mindnlp的trainer_utils模块。由于缺少trainer_utils模块，导致出现问题。,缺少trainer_utils模块,缺少trainer_utils模块 !U6W5U%AT7%~ ~4 F`O7 !image,2023-12-04T07:10:19Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/769
"该issue类型为需求提出，主要涉及对象为mindnlp项目中的mt5模型，用户提出将变量名称'gamma, beta, embedding_table'改为'weight, bias'。","add mt5 model & rename 'gamma, beta, embedding_table' to 'weight, bias'",,2023-12-03T15:36:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/768
这是一个功能需求类型的issue，主要涉及的对象是MindNLP的BERT模型在图模式下的更新。这个需求是为了支持通过重新计算来节省内存。,"update bert on graph mode, support recompute to save memory",,2023-12-02T17:34:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/767
这个issue是一个需求提出类型的问题，主要涉及更新白船支持7b和13b模型。用户需求更新白船，支持更大模型的能力。,"update baichuan, support 7b & 13b",,2023-12-01T04:13:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/766
这是一个bug报告类型的issue，主要涉及到mindnlp中的hf端点。错误可能是由于网络连接问题导致的。,fix hf endpoint,,2023-11-30T09:22:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/765
这个issue类型是bug报告，主要涉及的对象是tokenization。由于忽略了tokenization测试，导致了bug或者需要用户寻求相关问题的帮助。,ignore tokenization ut,,2023-11-30T08:13:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/764
这是一个用户提交需求的issue，主要对象是要更新T5模型。,update t5,,2023-11-29T07:32:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/763
这是一个代码迁移的issue，类型为升级需求，涉及的主要对象是代码库中的功能或模块。原因是代码迁移导致暂时无法进行测试。,code_migration_longt5,代码迁移，暂时没有测试,2023-11-28T04:43:33Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/762,CI没过
该issue类型为需求提交，用户提出了添加pop2piano模型的请求，希望该模型被加入到项目中。,Add pop2piano model,,2023-11-26T15:21:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/761
这是一个缺少内容的bug报告，涉及到需要更新多项式概率模型。,update multinomial,,2023-11-26T02:53:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/760
这是一个bug报告，主要涉及的对象是MindNLP项目中的Ascend平台，并提出了在其上修复错误并将ACL设置为默认的建议。由于可能存在错误实施或配置问题，导致需要修复并优化ACL的使用方式。,fix errors on Ascend and use ACL as default,,2023-11-24T15:34:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/759
这是一个需求更新（Feature Request）类的issue，主要涉及到github上的mindnlp项目中GPT示例的更新。可能由于GPT示例的代码或示例文本需要更新或改进，导致用户提出了此需求。,update gpt example,,2023-11-24T07:01:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/758
这是一个bug报告，涉及主要对象为`gpt_bigcode`，由于`AutoTokenizer`问题导致了两个测试用例被跳过。,Merge `gpt_bigcode` ut from hf, Skip two cases  > Because of the `AutoTokenizer` Issue  1. test_generate_batched 2. test_generate_simple,2023-11-23T15:26:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/757
这个issue属于用户提出需求，主要对象是支持 llama2，可能是由于当前版本不支持 llama2，用户希望功能能够覆盖 llama2 ，所以提出了这个需求。,support llama2,,2023-11-23T07:55:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/756
这是一个用户提出需求的issue，该问题单主要涉及的对象是添加百川功能。由于没有提供具体的内容，无法分析出具体的原因或症状。,add BaiChuan,,2023-11-22T05:59:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/755
这是一个用户提出需求的类型，主要涉及的对象是T5模型的数据并行训练。该需求是因用户希望能够使用T5模型进行单机多卡的数据并行训练，以及未来希望支持多机多卡训练。,T5模型数据并行训练需求,希望能使用T5模型进行单机多卡的数据并行训练、后续希望支持多机多卡训练,2023-11-21T07:19:41Z,requirement,open,0,0,https://github.com/mindspore-lab/mindnlp/issues/754
这是一个空白的bug报告，涉及主要对象为GPT2模型的更新。,update gpt2,,2023-11-18T12:11:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/753
这是一个需求类型的issue，主要涉及对象是bert示例。由于示例代码需要更新，用户提出了更新bert示例的请求。,update bert example,,2023-11-16T15:34:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/752
这是一个需求类型的 issue， 主要涉及的对象是更新 Ernie 和 GPT tokenizer。原因可能是现有的 tokenizer 不再适用或需要升级到最新版本。,update ernie and gpt tokenizer,,2023-11-16T08:40:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/751
这是一个bug报告，涉及的主要对象是mindnlp库中的gather_nd函数。由于不支持在CPU后端上使用-1作为参数导致出现bug。,fix gather_nd not support -1 on CPU backend,,2023-11-16T02:18:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/750
该issue属于技术升级类型，主要涉及到Megatron_BERT模型的升级和优化。,"upgrade megatron_bert, opt",,2023-11-15T16:21:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/749
这是一个bug报告类型的issue，主要涉及到github actions，由于慢速的ut导致了该问题的产生。,skip slow ut on github actions,,2023-11-15T09:37:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/748
这个issue属于用户提出需求类型，关注的主要对象是中文embedding模型的适配需求，由于需要在910B上训练和推理指定的中文embedding模型，用户请求进行相关工作。,急切需要中文embedding模型适配需求（bge-large-zh和bge-reranker-large）,我们需要在910B上训练和推理以下中文embedding模型： https://huggingface.co/BAAI/bgelargezh https://huggingface.co/BAAI/bgererankerlarge 能否适配一下，谢谢！,2023-11-15T06:47:12Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/747,"直接使用```BertModel.from_pretrained('BAAI/bgelargezh', from_pt=True)```即可"
这个issue类型是bug报告，主要涉及tutorials文件夹中几个ipynb文件全为空的问题。这可能是因为文件内容未正确加载或遗失导致。,tutorials 里几个ipynb文件全是空的？,,2023-11-15T01:44:28Z,bug requirement,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/746,最近重构，还没写
这是一个bug报告，涉及对象是mindnlp库中的BERT模型。这个问题可能是由于调用了不存在的from_pretrained方法而导致。,AttributeError: type object 'BertModel' has no attribute 'from_pretrained',!image,2023-11-15T01:42:25Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/745,请使用最新的包，readme里有下载链接,> 请使用最新的包，readme里有下载链接 通过下载wheel安装吗？最新包需要MindSpore大于2.1.0？,> > 请使用最新的包，readme里有下载链接 >  > 通过下载wheel安装吗？最新包需要MindSpore大于2.1.0？ 2.1应该也可以，但是我没有环境测，都是2.2测的，2.0有一些接口不一致，目前不考虑支持了
这是一个关于需求的 issue，主要涉及的对象是使用自托管的action runner。在这个 issue 中，用户提出了希望使用自托管的action runner的需求。,use self-hosted action runner,,2023-11-14T12:51:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/744
这个issue是一个需求提出，主要对象是更新whisper模型。原因可能是需要改进模型的性能或添加新功能至模型。,update whisper model,,2023-11-14T10:04:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/743
这个issue属于用户提出需求类型，主要对象是Dev autoformer模块，向项目中添加time_series_utils.py文件。,"Dev autoformer,add time_series_utils.py",,2023-11-14T02:45:34Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/742,CI要过
这是一个用户提出需求的issue，涉及主要对象是albert模型。由于albert模型需要进行更新，用户提出了更新请求。,update albert model,,2023-11-13T14:28:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/741
这是一个功能更新需求，主要涉及的对象是XLM模型。,update xlm model,,2023-11-13T04:07:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/740
这是一个用户提出需求的类型，该问题单涉及的主要对象是添加Ascendpatch。,add Ascend patch,,2023-11-12T07:44:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/739
这是一个用户提出需求的issue，主要涉及的对象是mindnlp中的tokenization模块。 由于目前缺乏tokenization模块，用户希望添加这一功能以提升文本处理的能力。,add tokenization modules,,2023-11-10T14:29:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/738
这是一个用户提出需求的issue，主要对象是创建MiniGPT4模型。,Create MiniGPT4.,,2023-11-10T05:46:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/737
这是一个用户提出需求的issue，主要涉及的对象是minigpt4模块。由于缺少__init__.py文件，用户提交了创建该文件的请求。,Create __init__.py,init for minigpt4.,2023-11-09T11:55:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/736
这是一个bug报告，主要涉及的对象是mindNLP的文本分类功能。由于版本为mindnlp0.2.0+m所导致，用户在执行文档中的文本分类时出现错误。,执行mindNLP文档中的文本分类报错,"文档地址：https://mindnlp.cqu.ai/zhcn/latest/examples/fasttext.html 版本：mindnlp0.2.0+mindsopore2.2.0+python3.9.0 报错信息： 20231109 12:27:53,645  modelscope  INFO  PyTorch version 2.1.0 Found. 20231109 12:27:53,645  modelscope  INFO  Loading ast index from C:\Users\admin\.cache\modelscope\ast_indexer 20231109 12:27:53,741  modelscope  INFO  Loading done! Current index file version is 1.9.4, with md5 8f77de9ffdbc3753da5c95aecd3a3a67 and a total number of 945 components indexed [WARNING] ME(27324:24752,MainProcess):2023110912:27:54.567.466 [mindspore\common\api.py:954] 'mindspore.ms_class' will be deprecated and removed in a future version. Please use 'mindspore.jit_class' instead. Traceback (most recent call last):   File ""F:\PycharmProjects\text_classification\package01\src01.py"", line 45, in      ag_news_train, ag_news_test = load('ag_news', shuffle=True) TypeError: 'module' object is not callable",2023-11-09T04:36:12Z,,closed,0,9,https://github.com/mindspore-lab/mindnlp/issues/735,感谢反馈，应该是文档需要更新了,from mindnlp.dataset import CoNLL2000Chunking from mindnlp.dataset import CoNLL2000Chunking_Process from mindnlp.dataset import process 你好，请问这几个包也无法导入。,https://github.com/mindsporelab/mindnlp/blob/master/examples/classification/bert_emotect_finetune.ipynb 版本：mindnlp0.2.0.20231112+mindspore2.2.0.20231113+python3.7.10 硬件环境：Ascend: 2*Ascend 910|ARM:48核 192GB 这个里面的代码也是，BartTokenizer没有token_to_id()函数了，tokenized.dtype报错，应该还有别的问题，无法执行模型训练 毕设弄不下去了QAQ，希望作者改一下相关的文档和示例，十分感谢,> https://github.com/mindsporelab/mindnlp/blob/master/examples/classification/bert_emotect_finetune.ipynb 版本：mindnlp0.2.0.20231112+mindspore2.2.0.20231113+python3.7.10 硬件环境：Ascend: 2*Ascend 910|ARM:48核 192GB 这个里面的代码也是，BartTokenizer没有token_to_id()函数了，tokenized.dtype报错，应该还有别的问题，无法执行模型训练 毕设弄不下去了QAQ，希望作者改一下相关的文档和示例，十分感谢 最近在改造，你参考huggingface的用法试试,> https://github.com/mindsporelab/mindnlp/blob/master/examples/classification/bert_emotect_finetune.ipynb 版本：mindnlp0.2.0.20231112+mindspore2.2.0.20231113+python3.7.10 硬件环境：Ascend: 2*Ascend 910|ARM:48核 192GB 这个里面的代码也是，BartTokenizer没有token_to_id()函数了，tokenized.dtype报错，应该还有别的问题，无法执行模型训练 毕设弄不下去了QAQ，希望作者改一下相关的文档和示例，十分感谢 话说你们是自己有机器吗，能用最新的daily版,我有空参考一下huggingface的用法，我的是学校申请的modelarts平台 然后在首页readme里面有这个mindnlp的daily https://repo.mindspore.cn/mindsporelab/mindnlp/newest/any/ 然后在里面也找到了mindspore的daily版 https://repo.mindspore.cn/mindspore/vision/daily/202311/,从这拿https://repo.mindspore.cn/mindspore/mindspore/newest/unified/aarch64/,"参考了一下huggingface用法，我把处理函数改成这个，其他基本上和之前我提到的示例文档相同。但是报错，问了一下gpt可能是在深度学习框架的内部执行过程中出现的问题，我也不太懂……麻烦大佬看看，谢谢 ```python  数据集处理函数，包括文本tokenize，序列填充 def process_dataset(source, tokenizer, max_seq_len=128, batch_size=32, shuffle=True):     dataset = GeneratorDataset(source, column_names=[""label"", ""text""], shuffle=shuffle)      transforms     type_cast_op = transforms.TypeCast(mindspore.int32)     pad_value = tokenizer.pad_token_id     def tokenize_and_pad(text):         tokenized = tokenizer.encode(str(text.tolist()))         input_ids = tokenized[:max_seq_len]         mask = [1] * len(input_ids) + [0] * (max_seq_len  len(input_ids))         input_ids = input_ids + [pad_value] * (max_seq_len  len(input_ids))         return input_ids, mask      map dataset     dataset = dataset.map(operations=tokenize_and_pad, input_columns=""text"", output_columns=['input_ids', 'attention_mask'])     dataset = dataset.map(operations=[type_cast_op], input_columns=""label"", output_columns='labels')     return dataset    ```    ```    ~/anaconda3/envs/python3.7.10/lib/python3.7/sitepackages/mindspore/common/api.py in end_graph(self, obj, output, *args, **kwargs)    1215             None.    1216         """""" > 1217         self._executor.end_graph(obj, output, *args, *(kwargs.values()))    1218     1219     def check_run(self, grad, obj, weights, grad_hash_id, *args, **kwargs): RuntimeError: For 'GatherD', the value of 'index' must be in [2, 2), but got: 2 ```","> 参考了一下huggingface用法，我把处理函数改成这个，其他基本上和之前我提到的示例文档相同。但是报错，问了一下gpt可能是在深度学习框架的内部执行过程中出现的问题，我也不太懂……麻烦大佬看看，谢谢 >  > ```python >  数据集处理函数，包括文本tokenize，序列填充 > def process_dataset(source, tokenizer, max_seq_len=128, batch_size=32, shuffle=True): >     dataset = GeneratorDataset(source, column_names=[""label"", ""text""], shuffle=shuffle) >      transforms >     type_cast_op = transforms.TypeCast(mindspore.int32) >     pad_value = tokenizer.pad_token_id >     def tokenize_and_pad(text): >         tokenized = tokenizer.encode(str(text.tolist())) >         input_ids = tokenized[:max_seq_len] >         mask = [1] * len(input_ids) + [0] * (max_seq_len  len(input_ids)) >         input_ids = input_ids + [pad_value] * (max_seq_len  len(input_ids)) >         return input_ids, mask >      map dataset >     dataset = dataset.map(operations=tokenize_and_pad, input_columns=""text"", output_columns=['input_ids', 'attention_mask']) >     dataset = dataset.map(operations=[type_cast_op], input_columns=""label"", output_columns='labels') >      >     return dataset > ``` >  > ``` > ~/anaconda3/envs/python3.7.10/lib/python3.7/sitepackages/mindspore/common/api.py in end_graph(self, obj, output, *args, **kwargs) > 1215             None. > 1216         """""" > > 1217         self._executor.end_graph(obj, output, *args, *(kwargs.values())) > 1218  > 1219     def check_run(self, grad, obj, weights, grad_hash_id, *args, **kwargs): >  > RuntimeError: For 'GatherD', the value of 'index' must be in [2, 2), but got: 2 > ``` 最新的example已修改"
这个issue属于用户提出需求类型，主要涉及的对象是mindnlp项目的README文件。由于README文件缺少支持的模型列表，用户提出希望在README中添加支持的模型的需求。,add supported models to readme,,2023-11-09T03:09:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/734
这是一个需求提出类型的issue，主要对象是需要为MindNLP添加一个whisper模型。由于目前缺少这个模型，用户希望可以为项目增加这一功能。,add whisper model,,2023-11-08T18:04:23Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/733, CC(Whisper largev3适配需求)
这是一个用户提出需求的issue，主要对象是中文embedding模型，用户希望对m3e-large和bge-large-zh-v1.5进行适配以解决大模型无法处理长记忆的问题。,"中文embedding模型适配需求（m3e-large,bge-large-zh-v1.5）",为了解决大模型无法处理长记忆的问题，业界一般采用先做向量检索，然后再把相关内容交给大模型处理的办法缓解，而这其中embedding模型至关重要，能否适配一下相关的embedding模型，比如： https://huggingface.co/mokaai/m3elarge https://huggingface.co/BAAI/bgelargezhv1.5 多谢大佬,2023-11-08T08:02:59Z,requirement,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/732,建议适配下bgelargezh模型，m3e模型无法商用，使用起来有点风险。,"直接使用```BertModel.from_pretrained('BAAI/bgelargezhv1.5', from_pt=True)```即可"
该issue为用户提出需求，请求大神适配Whisper large-v3版本。主要对象是Whisper large-v3模型。由于新版本提升巨大，用户希望大神进行适配。,Whisper large-v3适配需求,"Whisper largev3最近刚刚发布，对上一个版本提升巨大，大神能否做一下适配哈，感谢大神。 环境： CPU:x86_64 NPU:910b( Huawei Technologies Co., Ltd. Device d801 (rev 20))",2023-11-08T06:45:15Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/731
这个issue是关于更新roberta到hf风格，类型为功能需求提出，主要涉及对象是代码库中的roberta模型。这个问题可能由于当前代码库的roberta模型风格与hf（Hugging Face）风格不匹配，导致需要将其更新为符合hf风格的代码结构。,update roberta to hf style,,2023-11-08T05:13:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/730
这是一个用户提出需求的issue， 主要对象是gpt_bigcode，由于需要增加一个名为`ut`的功能。,Add gpt_bigcode `ut`,,2023-11-06T15:02:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/729
这是一个用户提出需求的issue，主要对象是`gpt_bigcode` ut。由于未提供具体内容，无法确定具体问题或需求。,Add `gpt_bigcode` ut,,2023-11-06T14:03:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/728
这是一个需求更新的类型，主要对象是einsum函数。原因可能是einsum函数功能需要更新或者优化。,update einsum,,2023-11-05T16:45:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/727
这是一个bug报告，主要涉及MindNLP安装时报错的问题，可能是由于权限限制导致的无法访问文件。,安装mindnlp0.2.0时报错,"根据指令安装mingnlp0.2.0时的报错： error: [WinError 5] 拒绝访问。: 'build\\bdist.winamd64\\wheel\\mindnlp0.2.0.distinfo\\dependency_links.txt' WARNING: Skipping mindnlp as it is not installed. WARNING: Requirement 'dist/*.whl' looks like a filename, but the file does not exist ERROR: *.whl is not a valid wheel filename. 请问该问题如何解决？",2023-11-05T09:58:02Z,,closed,1,4,https://github.com/mindspore-lab/mindnlp/issues/726,这个是windows系统的问题，python库无法打包，只能用linux打个包然后windows装,> 这个是windows系统的问题，python库无法打包，只能用linux打个包然后windows装 请问是将整个项目都打包吗，还是就是把wheel那一块打包？命名有什么规范吗？,python setup.py bdist_wheel 然后去dist目录拿到whl包,> python setup.py bdist_wheel 然后去dist目录拿到whl包 OK，问题已解决，感谢您的回答！
该issue类型为用户提出需求，问题涉及使用自定义einsum。原因可能是用户希望能够使用自定义的einsum函数进行特定的计算。,use self-defined einsum,,2023-11-04T17:25:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/725
这是一个需求类型的issue，主要涉及到porting huggingface函数和ut。原因可能是为了整合huggingface的功能和进行单元测试。,port huggingface functions and ut,,2023-11-03T08:45:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/724
这是一个用户提出需求的issue，该问题单涉及的主要对象是要为'mindnlp'添加'mbart.py'和'mbart_config.py'。,Add 'mbart.py' and 'mbart_config.py',,2023-11-03T07:08:56Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/723,pylint没过
这是一个需求提出类型的issue，主要涉及的对象是`gpt_bigcode`模块。由于用户需要为`gpt_bigcode`添加ut，因此提出了这个issue。,Add ut for `gpt_bigcode`,,2023-11-01T16:14:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/722
这是一个用户提出需求的issue，主要涉及物理机上使用MindSpore实现语料向量化的功能。由于目前参照文档介绍运行代码时遇到问题，需要实现与给出代码相同功能的解决方案。,【物理机】【MS2.0.0】【T5_small】使用mindspore如何实现语料向量化的实例,"问题描述：目前已经参照mindformers/docs/model_cards/t5.md的文档的介绍，跑通文档中的推理代码。 现需实现与如下代码相同的功能，暂时无法实现，是否有参考的实例或可通过阅读哪些mindspore的文档可以实现。 from transformers import T5Tokenizer, T5Model import torch MODEL_NAME = 't5small' print(f'Loading {MODEL_NAME} Model...')  加载模型和tokenizer tokenizer = T5Tokenizer.from_pretrained('t5small') model = T5Model.from_pretrained(MODEL_NAME)  输入文本并进行tokenizer text = ['Hello world!', 'Hello python!'] inputs = tokenizer(text, return_tensors='pt', padding=True) output = model.encoder(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], return_dict=True) pooled_sentence = output.last_hidden_state  shape is [batch_size, seq_len, hidden_size]  pooled_sentence will represent the embeddings for each word in the sentence  you need to sum/average the pooled_sentence pooled_sentence = torch.mean(pooled_sentence, dim=1)  得到n_sample*512的句向量 print('pooled_sentence.shape', pooled_sentence.shape) print(pooled_sentence)  输出：  pooled_sentence.shape torch.Size([2, 512])  tensor([[ 0.0123,  0.0010,  0.0202,  ..., 0.0176,  0.0122, 0.1353],          [ 0.0854,  0.0613, 0.0568,  ...,  0.0230, 0.0131, 0.2288]],         grad_fn=)",2023-11-01T02:21:22Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/721,Mindformers问题请到对应仓提issue
这个issue是用户提出需求。用户请求添加`gpt_bigcode`的URL信息并修正cell名称，同时支持从预训练载入模型。,Add `gpt_bigcode` url and correct cell name,+ Add `url` and upload `ckpt` to `modelscope` to support `from_pretrainde` + correct `self.blocks` to `self.h` to sync with origin model  How to verify I create an gitee repo for verification. Gitee Repo: verify_mindnlp_gpt_bigcode,2023-10-31T15:35:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/720
这是一个bug报告，主要涉及的对象是在mindnlp中添加GPT_Bigcode URL和修复单元格名称的问题。可能由于单元格名称错误或缺少GPT_Bigcode的URL导致相关功能无法正常使用。,Add GPT_Bigcode URL and fix cell name,,2023-10-31T14:48:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/719
这是一个用户提出需求的issue，主要对象是在mindnlp库中添加xlm_roberta模型。,add xlm_roberta,,2023-10-31T14:39:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/718
这个issue类型是用户提出需求，主要对象是longformer ut插件。由于缺少相关打印信息，用户希望增加打印信息以便更好地调试。,longformer ut add print info,,2023-10-31T02:05:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/717
这个issue是一个bug报告，涉及到mindnlp库中的Graphormer模块。由于Graphormer初始化时失败，导致出现了这个问题。,init graphormer,,2023-10-30T19:27:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/716
这是一个用户提出需求的issue，主要涉及持续集成（CI）流水线。由于缺少将ms2.2添加到CI流水线的支持，用户希望对应的功能能够被添加进去。,add ms2.2 to ci pipeline,,2023-10-30T14:38:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/715
这是一个需求更新的issue，主要涉及到修改了modelscope的url和BERT Graph模式。原因可能是需要更新模型的链接和改进BERT Graph模式功能。,update modelscope url and BERT Graph mode,,2023-10-30T13:39:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/714
这是一个用户提出需求的issue，主要涉及的对象是更新T5模型的开放链接。 造成这个问题的原因可能是当前的Checkpoint链接已过期或无法正常访问。,update t5 for openi ckpt url,,2023-10-29T08:55:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/713
这个issue类型为功能需求，主要涉及对象为gpt_bigcode模型及其相关组件，用户提出了完成gpt_bigcode模型、配置和分词器的需求。,"finish gpt_bigcode's model, config and tokenizer", Code change + `gpt_bigcode.py`                          gpt_bigcode model + `gpt_bigcode_config.py`              gpt_bigcode config + `gpt_bigcode_tokenizer.py`         gpt_bigcode_tokenizer  Verification method using `trouble shooter` to check `bigcode/gpt_bigcodesantacoder` model,2023-10-28T12:59:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/712
这是一个bug报告，主要涉及数据加载功能，由于数据集更改导致了无法获取数据的问题或需求。,Load data from ModelScope,"We have changed the datasets through huggingface few weeks ago. Given the poor Connection to Huggingface, we added the ""load_modelscope.py"" to help users download datasets through modelscope.cn.  If you have such errors: `'HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: …… (Caused by ConnectTimeoutError(, 'Connection to huggingface.co timed out. (connect timeout=10)'))' thrown while requesting HEAD [https://huggingface.co]`",2023-10-28T05:23:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/711
这是一个用户提出需求的issue，主要涉及ChatYuan模型和分词器的添加。,add ChatYuan model and tokenizer,,2023-10-27T07:48:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/710
这是一个bug报告，涉及的主要对象是mindnlp仓库中的readme文件。由于readme中的引用代码被截断，导致无法完整显示所需的引用符号引用的代码，用户提出了相关的问题寻求帮助。,readme错误,根据get_started板块中的Training Process子板块中的提示，运行以下代码: from mindnlp.engine.metrics import Accuracy from mindnlp.engine.trainer import Trainer metric = Accuracy() 直接报错，报错信息如下： !image,2023-10-27T07:04:50Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/709,readme已经删掉这部分了，现在的用法是from mindnlp.metrics import Accuracy
这个issue类型是需求更新，主要涉及的对象是CRF模块。该问题可能是由于需要改进CRF模块的性能、功能或者bug修复而提出的。,update crf,,2023-10-25T08:59:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/708
这是一个需求类型的issue，用户提出了更新名为bert的功能的请求。,update bert,,2023-10-24T15:19:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/707
这个issue类型是功能需求，主要涉及的对象是Graphormer初始化。由于用户希望添加初始化Graphormer的功能，因此提出了这个问题。,Initialize graphormer,,2023-10-24T11:23:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/706
"这是一个用户提出需求的issue，涉及的主要对象是新增一个名为""graphormer""的功能模块。",init graphormer,,2023-10-23T21:44:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/705
该issue类型为用户需求，涉及的主要对象是在mindnlp项目中集成falcon模块。,init falcon,,2023-10-20T14:27:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/704
这是一个需求类型的issue，主要涉及创建 __init__.py 文件。原因可能是为了在Python包中正确初始化代码。,Create __init__.py,,2023-10-19T12:40:08Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/703,要加上版权信息 参考https://github.com/mindsporelab/mindnlp/pull/702/files
这是一个用户提交需求的issue，涉及的主要对象是mindnlp/transformers/models/autoformer/__init__.py文件。,add new file: mindnlp/transformers/models/autoformer/__init__.py,,2023-10-19T12:29:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/702
这是一个bug报告，涉及主要对象是MindNLP库中的CRF模块。这个问题可能是由于transpose操作符导致的跳过CRF单元测试。,skip crf ut caused by transpose operator,,2023-10-19T08:05:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/701
该issue类型是代码重构，涉及的主要对象是Mindnlp在较老版本的兼容性问题。这个问题可能由于新的代码更新导致Mindnlp无法兼容旧版本，需要进行重构以解决兼容性问题。,Refactor to be compatible with older versions,,2023-10-19T03:19:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/700
这个issue类型为功能/需求提议，主要涉及对象为MindNLP中的Maskformer模型，用户可能提出希望将Maskformer模型进行移动的需求。,move maskformer,,2023-10-18T12:43:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/699
这是一个功能需求的issue，主要涉及要将models重构为transformers以兼容Hugging Face的架构。,refactor models to transformers for huggingface compatible,,2023-10-18T12:40:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/698
"这个issue类型是用户提出需求，涉及的主要对象是""maskformer""模块。用户可能想要对""maskformer""模块进行初始化或有关初始化的问题。",init maskformer,init maskformer,2023-10-16T16:10:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/697
这是一个bug报告，主要涉及无法加载预训练模型的问题。由于某种原因导致了预训练模型无法加载的症状。,无法加载预训练模型,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is. ``` from mindnlp.models import BertModel model = BertModel.from_pretrained('bertbasechinese') ``` 报错： `ImportError: cannot import name 'PreTrainedModel' from 'mindnlp.abc' (/home/mauser/anaconda3/envs/MindSpore/lib/python3.7/sitepackages/mindnlp/abc/__init__.py)`  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend: 2*Ascend 910|CPU: 48核 192GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.1.0  Python version (e.g., Python 3.7.5) : 3.7.10  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source): mindspore1.8.0cann5.1.2py3.7euler2.8.3  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 使用华为modelarts服务的，notebook ``` !pip install mindspore==2.1.0 !pip install git+https://github.com/mindsporelab/mindnlp.git ``` 然后 ``` from mindnlp.models import BertModel model = BertModel.from_pretrained('bertbasechinese') ``` 报错 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. 可以正常加载模型 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !image **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.  然后发现是huggingfacehub没有安装好 然后报错 !image",2023-10-16T08:58:08Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/696,fixed, CC(update bert) 
这是一个用户提出需求的类型，该问题单涉及主要对象是model implementation of dynamic graphs and static graphs。由于需求功能的区分，用户希望实现动态图和静态图的模型有所区分。,Separate model implementation of dynamic graphs and static graphs,,2023-10-16T06:57:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/695
这个issue类型是新功能请求，主要对象是minigpt4项目。,first init for minigpt4,,2023-10-15T11:41:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/694
这是一个用户提出需求的issue，主要对象是为mindspore添加codellama模型。原因可能是为了扩展mindspore的模型库或优化模型性能。,create the codeLlama model for mindspore,add the codellama model,2023-10-15T10:32:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/693
这是一个新功能需求的issue，主要涉及Mindnlp中的minigpt4。,first init for minigpt4,,2023-10-15T06:34:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/692
这个issue属于用户提出需求类型，主要对象是支持在 npu 上多机多卡训练的 baichuan 1 和 2。由于用户希望在 npu 上使用多机多卡训练，因此提出了这个需求。,baichuan 支持,支持 baichuan 1 和 2 在 npu 上多机多卡训练,2023-10-14T09:49:46Z,requirement,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/691,目前多机多卡需要借助mindformers，我们正在计划怎么import mindformers进来,当前单卡版已支持
这是一个新功能/特性请求的issue，主要涉及MindNLP中的minigpt4初始化。,first init for minigpt4,,2023-10-13T14:13:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/690
这个issue属于用户提出需求，主要对象是minigpt4模型的初始化。原因可能是用户希望获取关于如何初始化minigpt4模型的信息。,init minigpt4 model.,,2023-10-13T13:57:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/689
这是一个需求类型的issue，涉及到在mindnlp下创建一个名为__init__.py的空文件。由于可能需要与其他文件进行相关性连接，因此需要此空文件作为初始化的一部分。,Create __init__.py,first init for minigpt4 model. Just add empty __init__.py file with Licenses.,2023-10-13T13:50:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/688
这是一个关于重构parallel dir的issue，类型为需求提出，主要涉及的对象是代码结构。这个issue可能由于代码结构混乱、命名不清晰导致了需要重构的需要。,refactor parallel dir,,2023-10-13T03:41:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/687
这是一个用户提出需求的issue，主要涉及mT5模型适配的问题，用户希望能够加载mT5架构的模型。原因可能是用户需要在文本生成等任务中使用多国语言版本的mT5模型，但目前系统似乎无法实现该需求。,mT5模型适配需求, 需求概述 能够加载mT5架构的模型  具体内容 在文本生成等任务中，除去适合英文的模型T5，目前它的多国语言版本（mT5）也有着广泛的应用，并在很多领域（如中文文本生成）等任务中取得了较好的效果，但目前mindnlp不能完全加载mT5架构的模型的参数，希望能够适配mT5模型架构  环境配置 mindspore 1.10 模型地址：https://huggingface.co/imxly/t5pegasus,2023-10-13T01:56:39Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/686,ok,Support mt5
这是一个功能增强类的issue，主要涉及的对象是longt5模型。原因可能是为了longt5模型的初始化而创建了__init__.py文件。,first init for longt5,__init__.py for longt5 model,2023-10-12T12:29:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/685
这是一个关于添加`__init__.py`文件的issue，类型为代码优化。,First init for convbert and gpt_bigcode model,first init for `convbert` and `gpt_bigcode` model. Just add  empty `__init__.py` file with Licenses.,2023-10-11T14:43:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/684
这是一个需求提出类型的issue，该问题单涉及的主要对象是mindnlp/models/gpt_neox模块。由于缺少__init__.py文件，用户需要添加该文件。,init gpt_neox,add mindnlp/models/gpt_neox/__init__.py file.,2023-10-11T13:24:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/683
该issue属于bug报告类型，主要涉及到mindnlp项目中的shard文件缓存及预训练模型支持的问题。造成这个bug可能是由于未正确处理缓存或忽略特定的关键信息而导致。,fix shard files cache & Pretrained model support ignore_keys,,2023-10-11T09:48:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/682
这是一个bug报告，主要涉及的对象是MindNLP中的bark initial和ernie pull。由于某种原因导致了未提供具体内容的issue。,bark initial and ernie pull,,2023-10-11T06:39:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/681
该issue类型为模型初始化问题，主要涉及模型timesformer。可能是由于模型初始化不成功导致的bug或者用户寻求关于模型初始化的帮助。,init timesformer,Init model timesformer,2023-10-11T03:43:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/680
这是一个bug报告，主要涉及StaticGRU/StaticLSTM在Ascend平台上的问题，可能由于代码实现或者环境兼容性导致模型无法正常运行。,fix StaticGRU/StaticLSTM on Ascend,,2023-10-10T06:50:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/679
这是一个需求提出的issue，涉及主要对象是要在`mindnlp`中添加xnli数据集，这是由于用户希望扩展文本分类的数据集。,Add xnli cn dataset,添加了一个新的数据集xnli中的中文部分，实际上是一个文本分类的数据集,2023-10-09T11:22:07Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/678,upgraded /close
这是一个需求更新类型的issue，主要涉及到multi30k示例。原因可能是multi30k示例的内容需要更新或改进。,update multi30k example,,2023-10-09T08:47:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/677
该issue类型为需求提交，主要对象是在mindnlp项目中添加Longformer模型支持。,add longformer st,,2023-10-09T07:06:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/676
这个issue类型是bug报告，涉及的主要对象是加载数据集（load_dataset）功能。由于某种原因导致加载数据集出现问题需要修复，并更新示例代码。,fix load_dataset issue & update examples,,2023-10-08T10:09:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/675
这个issue类型是用户提出需求，主要对象是使用huggingface datasets。由于MindNLP目前没有使用huggingface datasets，用户想请求添加该功能。,use huggingface datasets,,2023-10-04T03:56:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/674
这是一个用户提出需求的issue，主要涉及的对象是加载simcse-chinese-roberta-wwm-ext模型和加载AlbertForMaskedLM架构的模型。由于用户需要使用这两种模型，因此提出了对模型读取的需求。,simcse-chinese-roberta-wwm-ext模型、AlbertForMaskedLM读取需求,**需求概述** 1. 能够加载simcsechineserobertawwmext模型 2. 能够加载AlbertForMaskedLM架构的模型 **具体内容** 目前，多数的相似任务采用了simcsechineserobertawwmext模型，并使用SentenceTransformer进行读取，但使用mindnlp对这类模型读取时存在多数参数无法加载，致使使用mindspore+mindnlp进行推理验证得到的效果与transformers得到的效果相差较大，需要mindnlp能够加载该模型，更好的进行相似任务的训练和推理。 当前，除去torch，tensorflow也有着广泛的使用，部分下载到的模型只有tensorflow版本，目前mindnlp主要针对torch模型进行转换与读取，需要mindspore模型的转换与读取 **环境配置** mindspore 1.10 模型地址：https://huggingface.co/cyclone/simcsechineserobertawwmext/tree/main,2023-09-28T08:53:35Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/673,"albert和bert已支持， 直接使用```BertModel.from_pretrained('cyclone/simcsechineserobertawwmext', from_pt=True)```即可"
这是一个关于dataset mt_eng_vietnamese的issue，类型是需求提出，涉及的主要对象是数据集。,dataset   mt_eng_vietnamese,,2023-09-26T13:51:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/672
这是一个请求添加新数据集的issue，主要对象是MindNLP，用户希望添加hf_dureader_robust数据集。,add hf_dureader_robust dataset,,2023-09-25T10:34:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/671
"这个issue类型是用户提出需求，主要对象是""funsd dataset""。由于数据集缺失，用户请求添加该数据集。",funsd dataset,,2023-09-25T07:48:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/670
这个issue是一个bug报告，主要涉及的对象是mindnlp库中的parallel layers。由于缺少使用trace来加速的功能，导致用户提出了加速的需求。,parallel layers use trace to speed up,,2023-09-25T07:22:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/669
这是一个请求功能的issue，主要涉及BertTokenizer库中支持'id_to_token'功能。可能由于用户需要通过'id_to_token'来快速获取单词对应的标识符，从而提出了这个需求。,BertTokenizer support 'id_to_token',,2023-09-25T03:59:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/668
这是一个用户提出需求的issue，该问题单涉及的主要对象是添加hf_squad数据集。,add hf_squad dataset,,2023-09-24T04:21:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/667
"这是一个用户提出需求的issue，主要涉及的对象是添加名为""LlamaTokenizer""的tokenizer。可能是用户需要新的tokenizer来处理特定类型的文本数据。",Add LlamaTokenizer,,2023-09-19T13:00:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/666
这是一个关于优化性能的 issue，主要对象是 Llama 模块。,speed up Llama,,2023-09-18T15:31:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/665
这是一个功能需求类型的issue，该问题单涉及的主要对象是MindNLP中生成任务的greedy search和T5模型。由于缺乏greedy search算法和需要更新T5模型，用户提出了需求来添加greedy search功能和更新T5模型。,"add greedy search for generation, update T5 model",,2023-09-18T11:15:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/664
"这是一个用户提出需求类型的issue，主要对象是在MindNLP中添加名为""llama2""的功能。",add llama2,,2023-09-18T03:55:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/663
这是一个bug报告，主要涉及的对象是mindnlp库中的gpt2_summarization.ipynb文件。由于该文件中的功能尚未实现，导致出现NotImplementedError错误。,examples/summarization/gpt2_summarization.ipynb  NotImplementedError,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** When I simply run the example code of 'examples/summarization/gpt2_summarization.ipynb', an error exists. `Traceback (most recent call last):   File ""test.py"", line 178, in      output_text = tokenizer.decode(output_ids[0].tolist())   File ""/home/boot/anaconda3/envs/huawei_2/lib/python3.7/sitepackages/mindnlp/abc/transforms/pretrained_tokenizer.py"", line 156, in decode     **kwargs,   File ""/home/boot/anaconda3/envs/huawei_2/lib/python3.7/sitepackages/mindnlp/abc/transforms/pretrained_tokenizer.py"", line 169, in _decode     filtered_tokens = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)   File ""/home/boot/anaconda3/envs/huawei_2/lib/python3.7/sitepackages/mindnlp/abc/transforms/pretrained_tokenizer.py"", line 266, in convert_ids_to_tokens     tokens.append(self._convert_id_to_token(index))   File ""/home/boot/anaconda3/envs/huawei_2/lib/python3.7/sitepackages/mindnlp/abc/transforms/pretrained_tokenizer.py"", line 270, in _convert_id_to_token     raise NotImplementedError NotImplementedError`  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > MindSpore version 2.0.0  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python 3.7.13  OS platform and distribution (e.g., Linux Ubuntu 22.04.2 LTS):  GCC/Compiler version 7:  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** **Expected behavior / 预期结果 (Mandatory / 必填)** Just run the code of the example, and after trainning, error occurs. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !问题 **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2023-09-16T03:13:06Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/662
这个issue类型是bug报告，主要对象是gpt2_summarization例子。由于原因修复的问题导致该例子无法正常运行。,fix gpt2_summarization example,,2023-09-15T06:49:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/661
这个issue类型是项目更新需求，主要涉及更新项目的README和支持的任务。,update readme and supported tasks,,2023-09-15T03:35:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/660
这是一个bug报告，涉及的主要对象是mindnlp下的gpt2_summarization.ipynb文件，出现这个bug的原因是输入参数中使用了一个数据集中不存在的列名。,"examples/summarization/gpt2_summarization.ipynb [ERROR] Invalid parameter, input column name: text doesn't exist in the dataset columns.","**Describe the bug/ 问题描述 (Mandatory / 必填)** When I simply run the example code of 'examples/summarization/gpt2_summarization.ipynb', an error exists.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > /device GPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version 2.0.0  Python version 3.9.18  OS platform and distribution (e.g., Linux  Ubuntu 22.04.2 LTS):  GCC/Compiler version 7:  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Just run the code of the example, and after trainning, error occurs. **Expected behavior / 预期结果 (Mandatory / 必填)** The test runs smoothly. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !问题 **Additional context / 备注 (Optional / 选填)** none.",2023-09-15T00:10:45Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/659
这个issue是一个bug报告。问题涉及的主要对象是mindnlp代码库中的ops.GatherV2模块。这个bug由于ops.GatherV2模块无法处理超出边界值而导致。,fix ut errors since ops.GatherV2 do not deal with out of boundary values,,2023-09-14T09:40:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/658
这个issue类型为用户提出需求，涉及的主要对象是在Mindnlp中增加PEFT:LORA的支持。原因是需要对提交进行重新基于。,add PEFT:LORA support,rebase commits,2023-09-13T17:30:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/657
该issue类型是重构请求，主要涉及语料库的示例目录。由于目前示例目录混乱或结构不清晰，用户请求重构例子目录。,refactor examples dir,,2023-09-13T08:57:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/656
这是一个功能需求类型的issue，主要涉及PEFT模块的支持和修改。原因可能是使用PEFT模块时出现了错误，需要支持CellDict并进行修复，并提出了关于加载和保存PEFT模型的需求。,PEFT support for mindnlp,1. PEFT:LORA support CellDict & fix some errors in peft. 2. Load & Save peft models. 3. Write a example to test peft classification model. 4. Add model_type to Bert & Roberta model 5. Add name_or_path to PretrainedModel and PretrainedConfig.,2023-09-13T08:34:17Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/655,为了不弄错，新搞了个分支，再提了一次PR。
这是一个用户请求需求的类型，用户要求添加Llama示例。这可能是因为用户想要在Mindnlp中添加一个新的示例以展示Llama的功能。,add Llama example,,2023-09-12T15:04:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/654
"这个issue类型是用户提出需求，该问题单涉及的主要对象是mindnlp库中的函数。由于缺少具体描述，导致无法明确用户需要添加什么样的功能到""llama2 repeat kv function""中。",add llama2 repeat kv function,,2023-09-12T02:28:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/653
这是一个用户提出需求的类型，该问题单主要涉及添加xfund功能。这个需求是为了提供xfund功能的支持或者相关的帮助。,add xfund ,,2023-09-10T10:01:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/652
这个issue类型是bug报告，涉及的主要对象是TinyBERT模型。由于某种原因导致TinyBERT出现了问题，需要修复。,fix tinybert issue,,2023-09-06T04:19:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/651
这个issue类型是bug报告，主要涉及的对象是Roberta模型。由于resize_token_embeddings方法不正确实现，导致了bug症状。,fix 'resize_token_embeddings' for Roberta,,2023-09-05T09:27:21Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/650
这是一个需求提出类型的issue，主要涉及的对象是在mindnlp中添加amp测试。,add amp test,,2023-09-05T07:56:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/649
这是一个bug报告类型的issue，主要涉及的对象是OPT Model的checkpoint URL。导致这个问题的原因可能是原始的checkpoint URL不正确。,Correct checkpoint`s URL for OPT Model.,Correct checkpoint`s URL for OPT Model.,2023-09-04T16:31:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/648
这个issue类型是bug报告，主要涉及的对象是mindnlp库中的agnews数据集，可能由于数据错误导致问题或者用户在数据集上遇到了一些bug。,fix agnews dataset error,,2023-08-31T09:16:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/647
这是一个bug报告类型的issue，涉及的主要对象是mindnlp的文档构建。由于文档构建过程中出现了错误，导致无法正常生成文档，用户提交了这个issue寻求修复。,fix docs build bug,,2023-08-30T16:38:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/646
这是一个用户提出需求的issue，主要涉及的对象是mindnlp项目。,add hf_glue process,,2023-08-30T03:17:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/645
这个issue是关于用户需求的，主要对象是在Ascend上使用amp时遇到的问题，由于Ascend仅支持fp16，用户可能遇到了相关设置或兼容性方面的困难。,ut on Ascend use amp,since Ascend support fp16 only,2023-08-30T02:14:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/644
这是一个bug报告，涉及的主要对象是修复多语言任务30k数据集链接，由于链接失效导致用户无法获取数据。,fix multi30k url,fix CC(multi30k dataset url not avaliable) ,2023-08-29T07:17:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/643
这是一个bug报告类型的issue，主要涉及的对象是multi30k数据集。由于数据集的URL不可用，导致无法获取数据集，需要解决URL无法访问的问题。,multi30k dataset url not avaliable,,2023-08-29T01:32:01Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/642
这是一个功能需求类型的issue，主要涉及Mindnlp库中的新增功能。,"add TemperatureLogitsWarper, TopPLogitsWarper, TopKLogitsWarper",,2023-08-27T16:24:10Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/641,!image CI没过,已修复
这是一个用户提出需求的issue，主要涉及MindNLP中的GPT2预训练模型和LogitsWarper。原因可能是用户希望能够导入GPT2PreTrainedModel并实现LogitsWarper与TopPLogit类的功能。,make 'GPT2PreTrainedModel' can be import; implement LogitsWarper with some classes ,make 'GPT2PreTrainedModel' can be import; implement LogitsWarper with 'TopPLogitsWarper' and 'TopKLogitsWarper';,2023-08-26T08:29:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/640
这是一个bug报告类型的issue，主要涉及到MindNLP中的dataset  mt_eng_vietnamese.py和test_mt_eng_vietnamese.py文件。由于某些原因导致了未提供具体的内容描述该bug或需求。,dataset  mt_eng_vietnamese.py  test_mt_eng_vietnamese.py,,2023-08-25T15:36:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/639
这是一个Bug报告，针对Pangu-Alpha模型中可能缺失了部分权重的问题。,pangu-alpha,pangualpha13B迁移自https://huggingface.co/sunzeyeah/pangu13B，模型中h.39.mlp可能缺失一些权重，暂不支持13B,2023-08-25T12:31:54Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/638,暂时不需要fix
这是一个用户提出需求的issue，主要涉及对象是 LukeTokenizer。由于缺少具体内容，无法分析是什么原因导致了问题。,LukeTokenizer,,2023-08-25T01:52:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/637
"这是一个bug报告，该问题涉及的主要对象是在MindNLP中无法找到模型，导致出现""Error displaying widget: model not found""的错误提示。",Error displaying widget: model not found,Error displaying widget: model not found,2023-08-24T09:07:08Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/636,seems like a jupyter notebook error.
"这是一个bug报告，问题涉及到在显示widget时出现""model not found""错误。可能是由于缺少相应的模型导致的。",Error displaying widget: model not found,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2023-08-24T09:05:41Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/635
这是一个bug报告类型的issue，主要涉及的对象是Mindnlp。由于内容为空导致这个issue。,fix ut,,2023-08-24T02:14:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/634
这是一个需求提出的issue，主要对象是Basic PEFT support，其原因可能是需要添加数据集支持和基本PEFT功能。,Basic PEFT support.,"1. Add a dataset supportCMMLU hfaddress. 2. Support basic PEFT utilities, MLP test passed.",2023-08-18T13:26:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/633
这是一个用户提出需求的issue，主要涉及到支持text2vec。通过用户提供的链接，可以推断用户希望mindnlp项目能够支持text2vec功能。,support text2vec,https://github.com/shibing624/text2vec/,2023-08-18T09:14:02Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/632
这是一个Bug报告，涉及的主要对象是 mindnlp._legacy.amp.auto_mixed_precision。由于内存泄露问题，训练过程中内存持续增加，导致程序报错。,mindnlp._legacy.amp.auto_mixed_precision存在内存泄露问题，训练过程中，内存持续增加，直至程序报错,"**Describe the bug/ 问题描述 (Mandatory / 必填)** mindnlp._legacy.amp.auto_mixed_precision，当amp_level='O1'时，出现内存泄露的现象，导致程序报错；当amp_level='O0'时，不存在内存泄露现象。  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: Ascend Ascend Driver: Version=22.0.0.3  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version  :1.10.1  Python version :Python 3.20.9.1  OS platform and distribution (e.g., Linux Ubuntu 16.04):启智 openi的智算Ascend的训练环境  GCC/Compiler version (if compiled from source): None  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > /mode pynative **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 在启智 openi 的云脑，创建一个训练任务，计算资源为NPU，镜像为mindspore_1.10.1_train，无论何种资源规格，启动文件 为gpt_qa/gpt2_qa.py mindnlp 版本：mindnlp0.1.1.20230617py3noneany.whl 我的启智代码库地址：https://openi.pcl.ac.cn/lld2002/step_into_chatgpt.git 2. 执行训练 问题同时记录在启智 issue 里：https://openi.pcl.ac.cn/zeizei/OpenI_Learning/issues/1092issuecomment105677 **Expected behavior / 预期结果 (Mandatory / 必填)** 希望训练时，内存可以进行回收，不持续增加 **Screenshots/ 日志 / 截图 (Mandatory / 必填)** !image !image !image",2023-08-16T02:49:04Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/631,O1是做了个内部的cast，应该不影响内存，看起来是数据集的问题？,使用的时候jit是否配置为True？,no reply. closed
这个issue类型属于用户提出需求，请教问题类型，主要涉及对象为mindnlp与mindformers，用户想了解mindnlp是否适用于训练大模型的基础框架以及其背后是否有研发团队支撑。,想了解一下mindnlp与mindformers各自适用的场景,目前在各个计算中心的运营过程中，都在使用mindformers作为基础训练框架，想了解一下mindnlp是否可以作为训练大模型的基础框架，背后是否有研发团队支撑,2023-08-14T09:34:26Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/630,mindnlp目前都是社区开发者在开发，目前没做大规模并行的支持（没人力也没算力），但是MindSpore现在那套并行过于难用，所以我们自己在搞单独的，猥琐发育中。有兴趣可以一起来搞~
这是一个需求提出的issue，主要涉及的对象是在mindnlp中添加opt模型、opt分词器和opt模型测试，用户希望对opt350m进行测试。,opt-model,1. Add opt model 2. Add opt tokenizer 3. Add opt model test (opt350m),2023-08-11T14:47:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/629
这个issue属于用户提出需求类型，主要对象是trainer模块，由于缺乏保存模型的功能，用户提出希望支持模型保存的需求。,trainer support save_model,,2023-08-11T03:40:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/628
这个issue是bug报告，主要涉及的对象是MindNLP中的squad2和moss模块。原因可能是代码中的错误或者逻辑问题导致这两个模块出现bug或错误。,fix squad2 and moss errors,,2023-08-11T02:14:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/627
"这是一个bug报告，问题涉及的主要对象是""pangu-alpha""。此问题可能是由于程序逻辑错误或代码实现问题导致的BUG。",pangu-alpha,,2023-08-10T11:03:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/626
这是一个bug报告类型的issue，主要涉及的对象是项目“mindnlp”，可能是由于代码逻辑错误或者数据处理不当导致的错误症状。,squad2,,2023-08-10T07:26:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/625
这是一个bug报告，该问题涉及Trainer微调完的模型不能持久化保存下来，原因是缺少保存ckpt的方法。,"Trainer微调完的模型不能持久化保存下来,这一块期待早日实现保存ckpt的方法","def _save_checkpoint(self, path):         """"""Save checkpoint.""""""         raise NotImplementedError",2023-08-10T03:16:11Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/624,今天加一下
这是一个用户提出需求的issue，主要涉及对象是MegatronBertTokenizer的完善。此issue由于当前MegatronBertTokenizer并未完全实现功能而产生。,Complete MegatronBertTokenizer,,2023-08-09T16:21:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/623
这个issue类型是bug报告，主要涉及下载错误；由于何种原因导致了下载错误的bug。,fix download errors,,2023-08-08T08:43:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/622
这是一个bug报告类型的issue，主要涉及llm模型加载时报OSError的问题。原因可能是加载模型时出现了错误导致的异常情况。,运行项目示例llm模型(Bert)加载报OSError,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** 报错如下: OSError: Couldn't reach server at 'https://download.mindspore.cn/toolkits/mindnlp/models/bert/bertbasecased/config.json' to downl oad configuration file or configuration file is not a valid JSON file.  **Hardware Environment(`CPU`)  / 硬件环境**:  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.1  Python version (e.g., Python 3.7.5) :3.7  OS platform and distribution (e.g., Linux Ubuntu 16.04):windows10  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 复制示例代码运行 **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. !1691204873943 !1691204814651 **Additional context / 备注 (Optional / 选填)**",2023-08-05T03:08:31Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/621,fixed
这是一个Bug报告，主要涉及的对象是metric评估功能。由于`y_pred`和`y_tru`的维度不一致，导致出现了`ValueError`异常。,对于metric 目前好像只有单标签的评估,"ValueError: The dimension of `y_pred` should be equal to the dimension of `y_true` add 1, but got `y_pred` dimension: 2 and `y_true` dimension: 2. 希望增加多标签的分类功能",2023-08-04T07:32:41Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/620,try https://zhuanlan.zhihu.com/p/66440354,暂无多标签需求
这是一个bug报告类型的issue，主要涉及的对象是kaggle相关的gpu测试。由于kaggle gpu测试存在问题，用户需要修复这个bug。,fix kaggle gpu test,,2023-08-02T06:38:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/619
这是一个回滚修复Kaggle GPU测试的问题单，涉及主要对象为mindnlp。由于一次修复导致的问题，需要进行回滚操作。,"Revert ""fix kaggle gpu test""",Reverts mindsporelab/mindnlp CC(fix kaggle gpu test),2023-08-02T06:37:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/618
这个issue是bug报告，主要涉及的对象是修复Kaggle GPU测试，由于未给出详细的内容，无法确定具体导致的原因和症状。,fix kaggle gpu test,,2023-08-02T04:52:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/617
这是一个关于bug的报告，主要涉及mindnlp中的cached file错误。产生该bug可能是由于缓存文件处理过程中的错误操作所致。,fix cached file error,,2023-08-02T02:22:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/616
这是一个用户提出需求的issue，主要涉及到chatglm模块使用图形和动态形状的问题。由于缺少描述具体问题的内容，无法确定具体问题所在。,chatglm use graph+dynamic shape,,2023-08-01T10:54:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/615
这是一个用户提出需求的类型，该问题单涉及的主要对象是T5模型生成功能。由于链接未完整导致用户需求无法完整展示。,T5 生成,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md ** 问题描述** A clear and concise description of what the bug is.  **硬件环境**: GPU  **软件环境**:  MindSpore 2.0  Python version 3.9.16   Linux Ubuntu 22.04 **描述** 在使用T5模型生成时，‎mindnlp/abc/mixins/generation_mixin.py中疑似存在多个错误 执行代码： ``` outputs = model.generate(input_ids=input_ids, attention_mask=input_masks, max_length=100) ``` 一些问题如下：  greedy_search中1003行，model_inputs是一个dict， 但却使用*model_inputs传递，导致参数解析错误，应该为**model_inputs  解决完上述问题后，报告数据类型错误，我t5.py的T5ForConditionalGeneration中的construct中添加decoder_input_ids = decoder_input_ids.astype(mindspore.int32)解决。  解决完上述两个问题后，报NotImplementedError，代码似乎没有实现完整",2023-07-28T08:38:30Z,bug,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/614,T5的生成任务代码还没有迁移完，这礼拜我处理一下,fixed
这是一个用户提出需求的issue，主要对象是从mindnlp中下载tokenizer.json文件，可能出现在代码中导入NezhaConfig时的问题。,下载tokenizer.json,"mindspore版本1.10 代码如下 import json from mindnlp.models.nezha import NezhaConfig, NezhaForSequenceClassification from mindnlp.models import BertForSequenceClassification from mindnlp.transforms.tokenizers import BertTokenizer tokenizer = BertTokenizer.from_pretrained('checkpoint') pad_value = tokenizer.token_to_id('[PAD]') with open(""checkpoint/config.json"") as f:     config = json.load(f) config = bert_config(**config) config.num_labels = 3 model = BertForSequenceClassification(config) import mindspore as ms params_dict = ms.load_checkpoint(""checkpoint/bert_emotect_best.ckpt"") params_not_load = ms.load_param_into_net(model, params_dict) 报错信息  UnboundLocalError                         Traceback (most recent call last)  in        4 from mindnlp.transforms.tokenizers import BertTokenizer       5  > 6 tokenizer = BertTokenizer.from_pretrained('checkpoint')       7 pad_value = tokenizer.token_to_id('[PAD]')       8  ~/.local/lib/python3.7/sitepackages/mindnlp/abc/transforms/pretrained_tokenizer.py in from_pretrained(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)      78                     cache_dir=cache_dir,      79                     proxies=proxies, > 80                     folder_name=folder_name      81                 )[0])      82             except EnvironmentError as exc: UnboundLocalError: local variable 'folder_name' referenced before assignment 报错源码如下         pretrained_model_name_or_path = str(pretrained_model_name_or_path)          Get files from url, cache, or disk depending on the case          Load tokenizer         if pretrained_model_name_or_path is not None:             if pretrained_model_name_or_path in cls.pretrained_vocab_map:                 archive_file = cls.pretrained_vocab_map[pretrained_model_name_or_path]                 **folder_name** = pretrained_model_name_or_path             elif os.path.isdir(pretrained_model_name_or_path):                 archive_file = os.path.join(pretrained_model_name_or_path, ""tokenizer.json"")             elif os.path.isfile(pretrained_model_name_or_path):                 archive_file = pretrained_model_name_or_path             else:                 raise ValueError(f'not found model of {pretrained_model_name_or_path}.')              redirect to the cache, if necessary             try:                 resolved_archive_file = str(cached_path(                     archive_file,                     cache_dir=cache_dir,                     proxies=proxies,                     folder_name=**folder_name**                 )[0]) 如果没有走上面的if pretrained_model_name_or_path in cls.pretrained_vocab_map 就会存在 folder_name未被赋值",2023-07-26T03:02:47Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/613
这个issue类型是用户提出需求，主要对象是xlm tokenizer，由于用户想要在mindnlp中添加对xlm tokenizer的支持。,xlm tokenizer,,2023-07-23T15:11:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/612
这个issue是一个需求类型，涉及的主要对象是在安装 triton 时添加条件判断。由于缺乏条件判断，可能导致安装过程出现问题。,add condition judgement on 'pip install triton',,2023-07-20T12:12:37Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/611,"  pylintcheck runson ubuntulatest, it could install triton. But I delete it in requirements. In pylintcheck block, add 'pip install triton' after 'pip install r requirements/requirements.txt'(line 39)."
这是一个bug报告，涉及的主要对象是pip安装triton失败。由于什么样的原因导致了这个问题，用户提出了关于triton安装失败的问题。,Complete transferring moss. Set ut gpu_only.,"""pip install triton"" failed on windows and mac. Set "".mark.gpu_only"" in test_modeling_moss.py.",2023-07-19T13:00:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/610
该issue属于用户提交需求类型，主要对象是在mindnlp项目中正在进行的迁移操作。由于未提供具体的描述，无法分析导致的具体症状。,Complete transferring moss,,2023-07-19T12:03:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/609
这个issue是一个用户提出需求的类型，主要涉及的对象是mindnlp库。由于用户需要支持llama2，所以提出了这个问题。,support llama2,,2023-07-19T01:18:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/608
这是一个用户提出需求或寻求帮助的issue，主要涉及HF_Squad。由于某些原因导致出现了bug或用户对HF_Squad功能有疑问或需求帮助。,HF_Squad,,2023-07-17T08:24:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/607
这是一个缺少完整内容或者格式错误的用户提问类型的问题，用户提出了关于mindnlp训练用例报错的问题。,mindnlp 训练用例报错,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : **mindspore2.1.0cp39cp39linux_x86_64**  Python version (e.g., Python 3.7.5) : **python3.9**  OS platform and distribution (e.g., Linux Ubuntu 16.04): **ubuntu1~18.04.1**  GCC/Compiler version (if compiled from source):  **gcc version 7.4.0**  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** 源码文件 train_callback.py： `import os import mindspore from mindspore.dataset import text, GeneratorDataset, transforms from mindspore import nn, context, jit, GraphJit, ops from mindnlp.transforms import PadTransform from mindnlp.transforms.tokenizers import BertTokenizer from mindnlp.engine import Trainer, Evaluator from mindnlp.engine.callbacks import CheckpointCallback, BestModelCallback from mindnlp.metrics import Accuracy  prepare dataset class SentimentDataset:     """"""Sentiment Dataset""""""     def __init__(self, path):         self.path = path         self._labels, self._text_a = [], []         self._load()     def _load(self):         with open(self.path, ""r"", encoding=""utf8"") as f:             dataset = f.read()         lines = dataset.split(""\n"")         for line in lines[1:1]:             label, text_a = line.split(""\t"")             self._labels.append(int(label))             self._text_a.append(text_a)     def __getitem__(self, index):         return self._labels[index], self._text_a[index]     def __len__(self):         return len(self._labels) def process_dataset(source, tokenizer, pad_value, max_seq_len=64, batch_size=32, shuffle=True):     column_names = [""label"", ""text_a""]     rename_columns = [""label"", ""input_ids""]     dataset = GeneratorDataset(source, column_names=column_names, shuffle=shuffle)      transforms     pad_op = PadTransform(max_seq_len, pad_value=pad_value)     type_cast_op = transforms.TypeCast(mindspore.int32)      map dataset     dataset = dataset.map(operations=[tokenizer, pad_op], input_columns=""text_a"")     dataset = dataset.map(operations=[type_cast_op], input_columns=""label"")      rename dataset     dataset = dataset.rename(input_columns=column_names, output_columns=rename_columns)      batch dataset     dataset = dataset.batch(batch_size)     return dataset tokenizer_op = BertTokenizer(vocab=""data/vocab.txt"", lower_case=True) tokenizer = tokenizer_op.from_pretrained(pretrained_model_name_or_path=""bertbasechinese"") pad_value = tokenizer.token_to_id('[PAD]') dataset_train = process_dataset(SentimentDataset(""data/train.tsv""), tokenizer, pad_value) dataset_val = process_dataset(SentimentDataset(""data/dev.tsv""), tokenizer, pad_value) dataset_test = process_dataset(SentimentDataset(""data/test.tsv""), tokenizer, pad_value, shuffle=False)` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. !image 如果直接调用BertTokenizer.from_pretrained('bertbasechinese')则会报以下错误。 !image **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem.",2023-07-17T07:14:35Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/606,fixed
这是一个需求类型的issue，主要涉及修改DuConv模块。可能由于功能改进或错误修复的需求而产生。,add duconv,modify DuConv,2023-07-14T09:54:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/605
这是一个关于修复数据集错误的bug报告，主要涉及数据集的问题。可能由于数据集标注错误或者数据格式问题导致用户反馈需要修复。,fix dataset errors,,2023-07-14T06:29:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/604
这个issue类型是bug报告，主要涉及的对象是rwkv kernel path，由于path错误导致了bug。,fix rwkv kernel path,,2023-07-14T02:03:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/603
这个issue类型为功能需求，主要对象是在mindnlp项目下的hf_duconv模块。由于需要对test_hfduconv和init进行修改，可能是为了添加新的功能或改进现有功能。,add hf_duconv,modify test_hfduconv and init,2023-07-13T18:00:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/602
这是一个需求提出类型的issue，主要对象是向mindnlp添加hf_duconv模块，用户提出此需求可能是希望扩展MindNLP的功能或者改进现有功能。,add hf_duconv,add hf_duconv modify test,2023-07-13T17:47:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/601
这个issue类型是需求添加，主要对象是为mindnlp添加'peft'目录并下载文件到当前工作目录，可能是用户希望将文件下载到指定目录以便更方便地使用。,add 'peft' dir & download files to current work dir,,2023-07-13T09:37:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/600
这是一个增加功能的issue，主要对象是添加hf_cmrc2018。,add hf_cmrc2018,,2023-07-12T13:43:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/599
这个issue类型是用户提出需求，主要对象是使用bucket功能。由于需要使用bucket功能但没有相关的说明或功能实现，用户提出了这个需求。,use bucket,,2023-07-12T01:51:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/598
这是一个bug报告，涉及修复http_get方法抛出异常并支持ms1.10，由于未提供具体内容，无法进一步分析问题。,fix http_get raise info & support ms1.10,,2023-07-10T07:02:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/597
这是一个需求：提升chatglm推理速度的issue，主要涉及chatglm推理部分。原因可能是现有的推理速度较慢，需要针对性的优化。,speed up chatglm inference,,2023-07-07T03:13:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/596
这是一个bug报告，涉及的主要对象是opt model。原因可能是参数设置不正确导致了bug的产生。,opt model,,2023-07-04T08:42:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/594
这是一个需求更新的issue，主要涉及更新API文档，问题可能是由于之前文档内容多余或过时而产生。,update api docs,1.解决了Issues CC(【文档】多余的内容)，将之前多余的内容删除。 2.将已有api文档更新，现在是up to date的，和主库已有api内容匹配。 3.增添新的四个api目录：workflow、generation、parallel和vocab。,2023-07-04T02:42:55Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/593,https://gitee.com/mindspore/community/issues/I76JSG
这是一个bug报告，主要涉及HTTP错误，可能是由于网络请求问题或程序逻辑错误导致的。,raise http error,,2023-07-04T01:59:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/592
这是一个bug报告，涉及的主要对象是自定义的类类型，由于不支持梯度累加，导致出现了相关问题。,自定义的类类型在梯度累加中不支持,"**Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] 在迁移模型完成，进行训练过程中，mindspore的获取gradient function（grad_fn = mindspore.value_and_grad(forward_fn, None, model.trainable_params())），不支持自定义的类类型。 !image 图片中，batch是一个自定义的Tree类型，来源于https://github.com/bogatyy/cs224d/blob/master/assignment3/tree.py中的Class  Tree !image 模型construct中的代码如上，应该如何能够使其进行正常的梯度累加。 **Describe the solution you'd like** A clear and concise description of what you want to happen. 想要能够正常地训练代码，使其能够正向和反向传播 **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.",2023-07-03T14:56:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/591
这个issue类型是用户提出需求，主要涉及的对象是预训练语言模型中的token embeddings调整问题，由于resize_token_embeddings方法暂未实现，用户提出了如何修改模型的问题。,预训练模型resize_token_embeddings方法是否暂未实现？,请问对于预训练语言模型中改变其token embeddings的方法resize_token_embeddings是不是暂未实现，如果暂未实现有其他办法修改模型token embeddings的大小吗？谢谢 !1688023726909,2023-06-29T07:32:37Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/590,具体用的哪个模型? mindnlp和transformers一样，基类都是不实现，然后模型实现。所以要看具体是哪个模型,具体用的是这个模型RobertaForMaskedLM !1688024562886,> 具体用的是这个模型RobertaForMaskedLM !1688024562886 找到问题了， !image 这一句没加导致的
这是一个bug报告类型的issue，主要涉及 llama model 在推断过程中的问题。由于问题导致 llama model在推断时出现错误，用户需要修复此问题来确保推断结果准确。,fix llama model for inference,,2023-06-28T09:46:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/589
这个issue是一个bug报告类型，涉及到了mindnlp下的duconv和test_duconv，可能由于代码修改导致了特定功能或测试出现问题。,modify duconv and test_duconv,,2023-06-28T08:38:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/588
这是一个用户提出需求的问题，该问题单涉及的主要对象是模型从预训练加载的处理，用户询问默认保存路径。,请问模型from_pretrained保存在哪里了？,请问模型from_pretrained默认保存到哪里了？  我在本地没找到,2023-06-28T02:14:23Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/587,~/.mindnlp
这个issue属于需求提出类型，主要涉及的对象是添加cmrc2018和进行测试。,add cmrc2018 and test,,2023-06-27T12:59:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/586
这个issue属于需求类型，主要对象是项目mindnlp的添加duconv和测试功能。,add duconv and test,,2023-06-27T07:13:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/585
这是一个用户提出需求的issue，主要涉及对象是nezha模型的fine-tuning，可能由于指导不清或者功能不完善导致用户需要相关帮助或解决问题。,nezha finetune,,2023-06-26T14:24:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/584
这是一个功能需求类型的issue，主要涉及添加对CMRC2018数据集的支持。这个需求可能由于该数据集在项目中需要使用，但目前尚未提供对应的处理代码而产生。,add cmrc2018.py,Add support for CMRC2018 dataset.,2023-06-25T15:05:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/583
这是一个bug报告，该问题涉及的主要对象是安装mindnlp时的Python setup，由于setup过程出现错误导致需修复。,fix setup-python error,,2023-06-25T14:25:43Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/582,CI error mentioned: https://github.com/actions/setuppython/issues/682
这个issue类型为功能需求，主要涉及的对象是添加信息提取（UIEWork）到工作流程中并修复ernie_tokenizer。原因是需要将信息提取功能整合到工作流程中并修复ernie_tokenizer的问题。,Add information_extraction(UIEWork) to workflow & fix ernie_tokenizer,Add information_extraction(UIEWork) to workflow & fix ernie_tokenizer,2023-06-24T07:04:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/581
这是一个bug报告类型的issue，主要涉及的对象是megatron-bert模型。由于未提供具体内容，无法分析具体原因和症状。, resubmit megatron-bert .,,2023-06-22T00:12:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/580
这个issue类型是用户提出需求，用户请求重新提交megatron-bert。,resubmit megatron-bert,,2023-06-20T05:36:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/579
这是一个升级请求类型的issue，主要涉及的对象是CRF模块，用户提出升级以支持mindspore 1.10版本，可能是由于该模块在mindspore 1.10中存在不兼容或其他问题而导致。,update CRF to support mindspore 1.10,,2023-06-19T03:47:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/578
这是一个bug报告，主要涉及的对象是mindnlp项目中的duconv.py文件。由于修改导致的bug或问题需要解决。,qinchen2023,modify duconv.py,2023-06-18T09:26:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/577
这是一个更新README的issue，类型属于用户提出需求，针对的主要对象是项目文档。,update readme,,2023-06-15T01:53:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/576
这个issue类型是用户提出需求，主要涉及的对象是软件chatglm，用户想知道该软件是否支持在x86 cpu+910 gpu的9010服务器上运行。,chatglm是否支持x86 cpu+910 gpu的9010服务器,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** 提示ReduceSumReduceSum错误  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片 9010服务器，ntel(R) Xeon(R) Gold 6240 CPU @ 2.60GHz+910b gpu npusmi info ++  +======================+===============+====================================================+  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.0.0  Python version (e.g., Python 3.7.5) :3..75  OS platform and distribution (e.g., Linux Ubuntu 16.04):centos 7.6  GCC/Compiler version (if compiled from source): **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: python3 m pytest tests/ut/models/glm/test_modeling_chatglm.py  **Screenshots/ 日志 / 截图 (Mandatory / 必填)** E           TypeError:  E            E            Kernel select failed: E            E           Select CPU operator[ReduceSum] fail! Unsupported data type! E           The supported data types are input[Float32 Int32], output[Float32]; input[Float32 Int64], output[Float32]; input[Float64 Int32], output[Float64]; input[Float64 Int64], output[Float64]; input[Int8 Int32], output[Int8]; input[Int8 Int64], output[Int8]; input[Int16 Int32], output[Int16]; input[Int16 Int64], output[Int16]; input[Int32 Int32], output[Int32]; input[Int32 Int64], output[Int32]; input[Int64 Int32], output[Int64]; input[Int64 Int64], output[Int64]; input[UInt8 Int32], output[UInt8]; input[UInt8 Int64], output[UInt8]; input[UInt16 Int32], output[UInt16]; input[UInt16 Int64], output[UInt16]; input[UInt32 Int32], output[UInt32]; input[UInt32 Int64], output[UInt32]; input[UInt64 Int32], output[UInt64]; input[UInt64 Int64], output[UInt64]; input[Complex64 Int32], output[Complex64]; input[Complex64 Int64], output[Complex64]; input[Complex128 Int32], output[Complex128]; input[Complex128 Int64], output[Complex128]; , but get input[Bool Int64 ] and output[Bool ] E           node: :[CNode]1{[0]: ValueNode ReduceSum, [1]: :[Parameter]2, [2]: ValueNode Tensor(shape=[1], dtype=Int64, value=[0])} E            E            E            C++ Call Stack: (For framework developers) E            E           mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:340 SetOperatorInfo /usr/local/python3.7.5/lib/python3.7/sitepackages/mindspore/common/_stub_tensor.py:150: TypeError",2023-06-14T13:46:03Z,bug,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/575,看其实是reduce sum算子的问题，我修一下,是啊。多谢老大。,> 是啊。多谢老大。 已支持，在启智的1.10环境已测试。
这是一个用户提出需求的issue，主要对象是要求添加名为duconv.py的文件。,add duconv.py ,,2023-06-09T21:55:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/574
该issue是用户提出需求，希望添加duconv.py文件并修改__init__文件，主要涉及MindNLP项目中的代码结构。,add duconv.py,add duconv.py and modify __init__,2023-06-09T19:14:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/573
这是一个用户需求类型的issue，主要涉及的对象是添加MobileBERT tokenizer。由于用户希望在MINDNLP中使用MobileBERT tokenizer功能，因此提出了这个需求。,add mobilebert tokenizer,,2023-06-08T09:21:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/572
这是一个bug报告，主要涉及的对象是README.md文件中的错误。这个问题是由于文件中的拼写错误导致。,Fix typo,There is an error in README.md file of example.,2023-06-08T02:51:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/571
这个issue是用户提出需求，请求添加Duconv数据集。,My machine translation,add Duconv data set ,2023-06-08T01:47:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/570
这个issue属于用户提出需求类型，主要涉及到DuConv数据集加载器。用户提出修改根路径以适应个人位置。,qinchenwu2023 duConv dataset update,DuConv data set loader. root path should be modified to fit personal location.  qinchen wu  ,2023-06-07T19:15:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/569
这个issue是关于bug报告，涉及的主要对象是chatglm-lora微调部分接口。由于部分接口不支持，在进行lora微调时会出现问题。,chatglm-lora微调部分接口不支持,!image 可以正常运行chatglm 进行lora微调，有一些小问题。 !image 不少接口不支持 可以正常encode decode，但是没有special token，也就是开头、结尾和mask !image 迁移代码之后 !image 与torch的chatglm相比，有一点小问题。 !image 我迁移后的代码（还没有完全迁移完成） https://openi.pcl.ac.cn/kewei/mindglm/src/branch/master/main.ipynb,2023-06-07T14:43:03Z,bug,closed,0,6,https://github.com/mindspore-lab/mindnlp/issues/568,"我报这个错误咋回事？貌似不会自动把ckpt文件拼接起来。 Traceback (most recent call last):   File ""test1.py"", line 34, in      model = ChatGLMForConditionalGeneration.from_pretrained(""/home/HwHiAiUser/mindnlp2/chatglm6b/chatglm6b"", from_pt=True)   File ""/home/HwHiAiUser/mindnlp2/mindnlp/abc/models/pretrained_model.py"", line 393, in from_pretrained     raise exc   File ""/home/HwHiAiUser/mindnlp2/mindnlp/abc/models/pretrained_model.py"", line 364, in from_pretrained     folder_name=folder_name   File ""/home/HwHiAiUser/mindnlp2/mindnlp/utils/download.py"", line 312, in cached_path     f""file {filename_or_url} not found in {dataset_cache}."") FileNotFoundError: file /home/HwHiAiUser/mindnlp2/chatglm6b/chatglm6b/mindspore_model.ckpt not found in /home/HwHiAiUser/mindnlp2/chatglm6b/chatglm6b.", 可以from_pretrain直接下载，但是如果网络连接可能不够稳定。或者在colab打开。或者手动下载。,>  可以from_pretrain直接下载，但是如果网络连接可能不够稳定。或者在colab打开。或者手动下载。 华为NPU也是一样的代码么, 应该是一样的。但是可能需要手动下载到本地改成本地路径。, lora需要全量把huggingface的peft适配，我们会先适配GPU+动态图，好做一点,相关接口已实现
该issue类型为用户提出需求，针对的主要对象为CPM_generate功能。由于更新导致CPM_generate功能出现问题，用户提交了该issue请求支持更新。,updata support_CPM_generate,,2023-06-07T10:19:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/567
这个issue类型是用户提出需求，主要涉及的对象是给mindnlp项目添加BART tokenizer。由于当前尚未支持BART tokenizer，用户希望团队将其添加到项目中。,add bart tokenizer,add bart tokenizer,2023-06-07T09:19:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/566
这个issue类型是bug报告，主要涉及的对象是MindNLP的CRF模型，由于Graph模式下出现错误，导致需要修复bug。,fix crf error on Graph mode.,,2023-06-07T07:22:24Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/565,```ops.Gather``` do not support Tensor with Bool dtype
这个issue是一个bug报告，涉及的主要对象是代码中的数据类型（dtype）。原因可能是程序报错并且需要修复类型错误。,fix error and add dtype,,2023-06-07T03:03:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/564
这个issue类型是需求提出，主要对象是为mindnlp添加hf_xnli.py和test_hfxnli.py文件。,add hf_xnli.py test_hfxnli.py,,2023-06-06T17:09:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/563
这是一个需求提出类型的issue，主要涉及MindNLP中的hf_xnli.py和test_hfxnli.py，由于未提供具体内容，导致无法准确判断问题类型。,add hf_xnli.py test_hfxnli.py,,2023-06-06T16:51:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/562
这个issue类型是bug报告，主要涉及Roberta使用了一个过时的'arange' API，导致出现了问题。,Roberta use legacy 'arange' api,,2023-06-06T09:47:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/561
这是一个用户提出需求的issue，主要涉及对象是添加下载链接。原因可能是用户想要方便地下载相关内容。,add download url,,2023-06-06T08:42:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/560
这是一个用户报告bug的issue，主要涉及MindNLP库下载后无法找到module的问题。可能是由于安装路径未正确指定导致无法加载相关模块的情况。,下载mindnlp后，没有module,!pip install git+https://github.com/mindsporeecosystem/mindnlp.git user i https://mirror.baidu.com/pypi/simple 下载完成 !image,2023-06-06T07:02:42Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/559,看起来使用了老包
这是一个功能请求类型的issue，主要对象是在mindnlp项目中添加hf_squad2.py和test_hfsquad2.py文件。,"add hf_squad2.py, test_hfsquad2.py",,2023-06-05T13:57:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/558
这个issue是一个bug报告，主要涉及RoBERTa模型中的`ops.arange`不支持老版本，导致了bug症状。,RoBERTa 里面 ops.arange不支持老版本，需要支持老版本,**Describe the bug/ 问题描述 (Mandatory / 必填)** RoBERTa 里面 ops.arange不支持老版本，需要支持老版本,2023-06-05T13:42:17Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/557,!error
这是一个用户提出需求的类型，该问题单涉及的主要对象为mindnlp库中的nezha模型。由于用户想要使用预训练的nezha模型，所以提出了这个问题来寻求帮助。,nezha from pretrained,,2023-06-05T08:15:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/556
这个issue是一个用户提出需求的类型，主要涉及的对象是mindnlp库中的bloom功能和finetune方法，用户希望增加相关调用方法和示例。,mindnlp增加bloom使用案例和finetune方法,希望可以增加bloom的调用方法和finetune的example,2023-06-02T15:22:23Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/554,这两天会加一个bloom1b7的finetune案例，基于新Trainer
这是一个bug报告，主要对象是CPMTokenizer。由于版本更新导致的bug，用户提出需要更新CPMTokenizer。,updata CPMTokenizer,,2023-06-02T14:47:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/553
这是一个bug报告，涉及对象为mindnlp中sequence_labeling/LSTM-CRF.ipynb代码文件，可能由于错误的代码实现导致bug产生。,sequence_labeling/LSTM-CRF.ipynb  代码出现bug,"代码链接https://github.com/mindsporelab/mindnlp/blob/master/examples/sequence_labeling/LSTMCRF.ipynb 我使用readme里面mindspore1.8.1 进行运行 grad_fn = mindspore.value_and_grad(model, None, optimizer.parameters) 得到了报错信息AttributeError: module 'mindspore' has no attribute 'value_and_grad' 请问对应的接口变更成了什么",2023-06-02T09:19:33Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/552,1.8.1的接口是ops.value_and_grad
这是一个用户提出需求的issue，主要对象是更新`generation_mixin`和`logits_process`。,update generation_mixin and logits_process,,2023-06-02T05:01:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/551
这是一个用户提出需求的issue，主要对象是Tinybert tokenizer。由于用户希望在mindnlp中引入Tinybert tokenizer来完成特定任务，因此提出了这个需求。,Tinybert tokenizer,,2023-06-01T15:51:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/550
这是一个bug报告，主要对象是mindnlp项目中的teardown方法。由于teardown方法中包含了多余的.mindnlp代码，导致出现了问题。,fix: remove .mindnlp in teardown,fix: remove .mindnlp in teardown,2023-06-01T12:16:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/549
这是一个需求类型的issue，主要涉及的对象是新增一个名为hf_squad2.py的文件和对应的测试文件。,"add hf_squad2.py, test_hfsquad2.py",,2023-06-01T09:55:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/548
这是一个用户提出需求的issue，主要涉及的对象是将torch模型转换为mindspore模型。原因可能是用户希望能够在mindnlp中使用mindspore模型替代torch模型。,updata torch_to_mindspore,,2023-05-31T13:08:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/547
这是一个用户提出需求的issue，主要涉及的对象是支持ChatGLM。由于用户希望在MindNLP中实现ChatGLM功能，因此提出了这个需求。,support chatglm,,2023-05-30T13:49:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/546
这是一个bug报告类型的issue，主要涉及的对象是test_generation_config。原因可能是由于升级代码中的ut测试配置。,update test_generation_config ut,,2023-05-30T04:46:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/544
"这个issue是一个bug报告，涉及主要对象是""xlm code""。由于内容为空，导致用户无法正常使用该功能或代码。",xlm code,,2023-05-30T03:33:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/543
这是一个bug报告，主要涉及WKV操作符错误。由于WKV操作符的错误导致了功能无法正常运行的问题。,fix WKV operator error,,2023-05-29T12:38:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/542
这是一个需求类型的issue，主要涉及对象是mindnlp项目中的hf_ptb_text_only.py和test_ptb_test_only.py文件。,add hf_ptb_text_only.py test_ptb_test_only.py,,2023-05-29T10:53:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/541
"这个issue类型是用户提出需求，主要对象是""xlm code""。由于缺乏具体内容，造成用户提出了关于""xlm code""的问题或者寻求帮助。",xlm code,,2023-05-29T04:40:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/540
这是一个关于新增测试文件的issue，属于功能性需求。主要涉及的对象是代码的测试。,add hf_ptb_text_only.py test_ptb_text_only.py,,2023-05-28T16:19:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/539
这是一个用户提出需求的issue，主要对象是上传生成文件。原因可能是用户需要上传生成的文件或者需要相关功能改进。,upload generation files,,2023-05-28T12:30:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/538
这是一个用户提出需求类型的issue，主要对象是为mindnlp添加cpm bee支持。,add cpm bee support,,2023-05-28T09:45:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/537
这是一个需求变更的issue，主要涉及到重构parallel模块。由于代码结构或性能需要优化，导致需要对parallel模块进行重构。,refactor parallel module,,2023-05-28T09:28:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/536
这个issue类型是bug报告，主要涉及的对象是mindnlp中的Trainer类。由于mindspore控制流问题，在执行Trainer.run()时需要设置GRAPH_MODE来规避此问题。,Trainer.run() set GRAPH_MODE to avoid mindspore control flow issue,Trainer.run() set GRAPH_MODE  to avoid mindspore control flow issue.,2023-05-28T06:53:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/535
这是一个用户提出需求的issue，请求添加cpm & cpm_ant功能。,add cpm & cpm_ant,,2023-05-28T06:46:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/534
这个issue类型是请求更新代码，主要涉及的对象是项目中的XLM代码。这可能是因为需要更新XLM代码以修复bug、增加功能或者提高性能。,update xlm code,,2023-05-26T10:07:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/533
这个issue是一个需求类型，主要涉及的对象是xlm tokenizer。用户提出这个需求可能是希望添加一种支持多语言的分词器。,xlm tokenizer,,2023-05-26T03:30:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/531
这是一个用户提出的需求。该问题涉及的主要对象为mindnlp库，并要求添加tensor parallel功能。,add tensor parallel,,2023-05-25T12:24:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/530
该issue为需求类型，主要涉及的对象为pylint.conf配置文件。原因可能是需要更新pylint.conf文件以满足特定需求。,update pylint.conf,,2023-05-25T06:36:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/529
这是一个缺少具体内容的需求提出类型的issue，主要涉及的对象是添加pylint配置，由于缺少具体描述，无法确定具体问题或帮助需求。,add_pylint_config,,2023-05-25T06:31:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/528
"该issue类型为用户提出需求，请教问题， 主要涉及对象为添加名为""hf_msra_ner.py""的文件到mindnlp库中，由于需要增加新的NER模型的支持，用户提出了这个需求。",add hf_msra_ner.py,,2023-05-24T06:10:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/527
"这是一则用户提出需求的issue，主要涉及的对象是mindnlp库。由于缺少具体内容，用户可能正在请求添加一个名为""add_generation_mixin""的功能模块到该库中。",add_generation_mixin,,2023-05-23T15:49:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/526
"这是一个用户提出需求的类型，该问题单涉及的主要对象是MindNLP项目中的生成模型。由于缺少""add_generation_mixin""功能，用户希望能够添加该功能来增强生成模型的功能性。",add_generation_mixin,,2023-05-23T12:59:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/525
这是一个用户提出需求的issue，主要对象是LLM的stream_chat支持。可能是由于缺少相应功能或接口导致用户请求添加stream_chat支持。,Support stream_chat for LLM,"If this is your first time, please read our contributor guidelines: https://gitee.com/mindspore/mindspore/blob/master/CONTRIBUTING.md **Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.",2023-05-23T04:32:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/524
这个issue类型是bug报告，涉及的主要对象是Linux服务器上的某个命令。原因可能是命令无法正常执行或者产生意外结果。,fix which command on linux server,,2023-05-22T16:17:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/523
这是一个bug报告，主要涉及ERNIE模型的提交问题。该问题由于提交失败导致无法成功修改ERNIE模型的代码。,ernie model commit ut,,2023-05-22T15:12:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/522
这是一个用户提出需求的issue，主要涉及在GPU上添加wkv自定义运算符并支持RWKV预训练模型。,add wkv custom operator on GPU & support RWKV pretrained model,,2023-05-22T13:43:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/521
这个issue类型是bug报告，涉及的主要对象是ErnieConfig和ErniePretrainedModel。由于Ernie的配置和模型在使用from_pretrained时存在问题，可能导致UIE无法正确加载预训练模型或配置文件。,"Fix Ernie's config and model for ""from_pretrained""","Fix ErnieConfig and ErniePretrainedModel for  UIE's ""from_pretrained""",2023-05-20T13:45:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/520
这个issue是bug报告，涉及代码生成测试的更新。由于代码生成模块的更新导致测试不通过。,update_codegen_ut,,2023-05-19T11:13:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/519
这个issue属于用户提出需求类型，主要对象是添加中文文档问答数据集(docvqa_zh)，用户希望能够获取该数据集的下载链接。,Add docvqa_zh dataset,Add a url to download the dataset.,2023-05-19T09:17:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/518
这是一个需求类型的issue，主要对象是模型的单元测试（models ut），问题是如何降低成本。,reduce models ut cost,,2023-05-19T08:27:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/517
这是一个需求添加类型的issue，主要涉及的对象是添加ERNIE tokenizer（UIE部分）。这个需求可能由于现有的文本处理功能不足而产生。,Add ernie tokenizer (uie part),Add ernie tokenizer (uie part),2023-05-19T04:16:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/516
这是一个用户提出需求的类型，主要对象是要添加BART模型到mindnlp中。可能是因为目前mindnlp没有包含BART模型的原因，用户提出该需求以扩展模型库。,add bart model,add bart model,2023-05-18T16:47:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/515
这是一个用户提出需求的issue，主要涉及的对象是代码中的Bert LSTM CRF模块，用户希望对其进行简化。 ,simplify bert lstm crf,,2023-05-18T12:21:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/514
这个issue是一个bug报告，涉及的主要对象是pretrained_tokenizer.py文件。由于链接未完整导致无法正常访问，可能是由于输入错误或文本截断等原因引起的。,pretrained_tokenizer.py,"If this is your first time, please read our contributor guidelines: https://github.com/mindsporelab/mindcv/blob/main/CONTRIBUTING.md **Describe the bug/ 问题描述 (Mandatory / 必填)** A clear and concise description of what the bug is.  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**: /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**: /mode pynative /mode graph **To Reproduce / 重现步骤 (Mandatory / 必填)** Steps to reproduce the behavior: 1. 在`mindnlp/abc/transforms/pretrained_tokenizer.py`的72行中，当try语句执行失败时，无法找到`cls.pretrained_model_archive_map`属性 2. `mindnlp/abc/transforms/pretrained_tokenizer.py`基类不支持`vocab.txt` **Expected behavior / 预期结果 (Mandatory / 必填)** A clear and concise description of what you expected to happen. **Screenshots/ 日志 / 截图 (Mandatory / 必填)** If applicable, add screenshots to help explain your problem. **Additional context / 备注 (Optional / 选填)** Add any other context about the problem here.",2023-05-18T11:41:24Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/513,seems fixed
这个issue是用户提出需求，请求添加LoRA模块。主要对象是想要在MindNLP中使用LoRA模块的用户。,Add LoRA Modules,LoRA modules,2023-05-18T09:22:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/512
这是一个缺少具体内容的bug报告，主要涉及修复amp错误。可能是由于未经过充分测试或AMP（加速移动页面）相关功能的缺陷导致。,fix amp errors,,2023-05-18T04:57:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/511
这个issue类型是需求提交，涉及的主要对象是ERNIE模型。由于开发者需要提交ERNIE模型的代码或相关文档，因此提出了这个需求。,ernie model commit,,2023-05-18T03:43:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/510,需要加ut
这个issue类型是用户提出需求，主要对象是支持对象网络与损失函数，用户寻求帮助实现这一功能。,support object network with loss function,,2023-05-18T02:33:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/509
这是一个空白的issue，类型为bug报告，主要涉及ERNIE模型。原因可能是模型训练过程中出现了问题。,ernie model finish,,2023-05-17T09:26:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/508
这个issue是一个功能更新建议，主要涉及到GPT2摘要示例的更新。这个问题可能由于现有示例过时或需要改进而导致用户提出需更新的请求。,update gpt2_summarization example,,2023-05-17T07:03:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/507
这个issue类型为需求添加，主要对象是BART模型的版权信息，导致用户提出此问题可能是为了明确模型的版权信息。,add bart model copyright info,add bart model copyright info,2023-05-16T07:11:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/506
这个issue属于bug报告，涉及主要对象是mindnlp下的bart模型文件夹。由于误操作或系统问题导致bart模型文件夹为空，需要删除。,delete the empty bart model folder,delete the empty bart model folder,2023-05-14T14:43:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/505
这个issue属于需求类型，主要对象是需要在mindnlp中添加BART模型。原因可能是用户希望使用BART模型进行某些特定的任务或者实验。,add bart model,add bart model,2023-05-14T08:41:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/504
"这是一个用户需求类型的issue，主要对象是添加""nezha tokenizer""功能。",add nezha tokenizer,,2023-05-14T04:12:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/503
这是一个用户提出的需求类型的issue，主要涉及的对象是添加Longformer tokenizer。, add longformer tokenizer,,2023-05-13T06:16:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/502
这是一个bug报告，主要涉及mindnlp库中版本1.10存在的错误。可能是由于1.10版本中的某些代码问题导致产生了错误。,fix error on 1.10,,2023-05-13T05:22:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/501
这是一个用户提出需求的issue，主要涉及GPT1在MS1.10上的支持。由于GPT1当前无法与MS1.10兼容，用户提出希望新增该支持的需求。,gpt1 support ms1.10 (#498),,2023-05-13T05:19:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/500
这是一个用户提出需求类型的issue，主要对象是Mindnlp项目下的Longformer Tokenizer。由于当前库中尚未添加Longformer Tokenizer，用户希望对其进行添加。,add longformer tokenizer,,2023-05-13T04:58:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/499
这是一个用户提出需求的issue，主要需求是让GPT-2模型支持Microsoft 1.10版本的问题。,gpt2 support ms1.10,,2023-05-12T03:40:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/498
这是一个bug报告，涉及的主要对象是Trainer类。由于传入的loss_fn为None时，导致Trainer类中的_data_process函数返回值问题。,当传入的loss_fn为None时，Trainer类的一些报错,1.Trainer类中_data_process函数的返回值问题 当传入Trainer的loss_fn为None时，变量obj_network会赋值为True，导致_data_process只返回input，input是一个包含多个Tensor的元组，但是只有有两个变量接收_data_process的返回值，造成“too many values to unpack (expected 2)”报错。 2.Trainer类好像不支持loss_fn为None Trainer类中的_prepare_train_func函数只能用loss_fn计算loss，不支持network直接返回loss的情况。,2023-05-12T03:05:37Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/497
这是一个用户提出需求的类型，该问题单涉及的主要对象是添加Glue数据集。由于缺乏Glue数据集，用户希望将其添加到项目中以丰富数据集的内容。,add glue dataset,,2023-05-11T17:25:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/496
这是一个需求类型的issue，主要涉及的对象是增加Clip模型到项目中。,add clip model,add clip model,2023-05-11T12:26:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/493
这是一个用户提出需求的issue，该问题涉及mindnlp的支持GPT2的图模式功能。产生这个问题可能是因为用户希望在应用中使用GPT2的图模式，但目前该功能尚未支持。,gpt2 support graph mode,,2023-05-10T16:02:32Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/492,"mindspore1.8.1 not support following syntax: ```python for i, (x, y) in enumerate(zip(x_list, y_list)):     ...... ``` avoid this problem by: ```python for i, x in enumerate(x_list, y_list)):     y = y_list[i]     ...... ```"
这个issue是用户提出需求，并涉及到更新gpt2_summarization。用户想要对项目中的gpt2_summarization进行更新，可能由于模型效果不佳或者需要增加新功能而提出此需求。,update gpt2_summarization,,2023-05-10T15:04:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/491
这是一个需求类型的issue，主要涉及的对象是更新tokenizers和添加accumulator功能。可能由于之前的tokenizers存在一些问题或者缺少累加器功能，导致用户提出了这个需求。,update tokenizers & add accumulator,,2023-05-10T09:38:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/490
这是一个bug报告，该问题涉及代码生成（codegen）的修复。这个issue可能是由于代码生成的错误或问题导致的。,fix codegen,,2023-05-10T06:26:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/489
这个issue类型是需求提出，主要对象是添加一个RoBERTa tokenizer。 原因是当前代码库缺少RoBERTa tokenizer的支持，用户希望能够扩展该功能。,add roberta tokenizer,,2023-05-10T04:06:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/488
这是一个用户提出需求的类型，主要对象是albert model的更新和添加保存函数。原因可能是希望更新模型并增加保存功能以提高其性能和灵活性。,update albert model and add save func,,2023-05-09T08:21:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/487
"这是一个 bug 报告类的 issue，主要涉及的对象是 ""mindnlp"" 项目中的一个模块。由于未提供具体内容，无法分析该 bug 产生的原因或用户提出的问题。",updata n_layer,,2023-05-09T03:31:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/486
这是一个用户请教问题类型的issue，主要涉及的对象是GPT相关模型。由于缺乏对在Ascend 910上使用GPT模型的了解，用户提出了关于如何使用该模型的问题并寻求帮助。,请教一下，如何使用GPT相关模型？,新手请教，如何在Ascend 910上使用GPT模型，感谢~,2023-05-08T08:40:02Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/485,使用如下代码即可： ```python from mindnlp.models import GPT model=GPT.from_pretrained('openaigpt') ``` 也可以看下example： https://github.com/mindsporelab/mindnlp/blob/master/examples/sentiment_analysis/gpt_imdb_finetune.ipynb,怎么生成文本呢？,> 怎么生成文本呢？ 文本生成案例请参考：https://github.com/mindsporelab/mindnlp/tree/master/examples/summarization
这是一个功能需求的issue，主要涉及的对象是GenerationConfig和ut。问题可能是用户需要添加GenerationConfig并制定测试。,add GenerationConfig and ut,,2023-05-07T07:50:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/484
这个issue属于用户提出需求类型，涉及对象是代码生成器。原因可能是用户希望添加一个名为codegentokenizer的功能。,add_codegentokenizer,,2023-05-07T05:55:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/483
"该issue类型为功能需求，涉及的主要对象是代码生成的tokenizer。因为用户希望添加一个名为""add_codegentokenizer""的功能，所以提出了这个issue。",add_codegentokenizer,,2023-05-07T05:09:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/482
这是一个用户提出需求的issue，主要涉及情感分析示例的更新。可能是由于现有示例不够具体或者不符合需求，用户希望更新这些示例。,update sentiment examples,,2023-05-07T03:06:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/481
这是一个关于修复GPT微调错误的Bug报告，主要涉及MindNLP项目中GPT模型微调的问题。由于什么样的原因导致了GPT微调错误无法确定。,fix gpt finetune error.,,2023-05-06T18:16:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/480
这是一个bug报告，主要涉及fix readthedocs sphinx build的问题。由于readthedocs sphinx build的错误，导致需要修复。,fix readthedocs sphinx build,Fix readthedocs sphinx build,2023-05-06T12:19:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/479
这是一个用户提出需求的issue，主要涉及的对象是对将torch转换为mindspore的功能需求。,add torch_to_mindspore,,2023-05-06T10:29:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/478
这是一个需求报告， 主要对象是 T5 模型中添加 from_pretrained 方法的功能。可能由于用户希望能够直接加载预训练的 T5 模型而提出该需求。,add from_pretrained of t5,,2023-05-06T03:19:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/477
"这是一个bug报告，问题涉及到""TakeDataset""的检测和对低速率发出警告。这个问题可能是因为在检测""TakeDataset""时出现了速率过低的情况，导致需要发出警告。",detect TakeDataset and raise warning for low speed.,,2023-05-06T03:17:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/476
这个issue是一个bug报告，主要涉及的对象是mindnlp下的GPT分类模型。这个bug可能导致GPT分类模型不能正常工作，用户提出了需要修复这个问题的请求。,fix gpt classification model,,2023-05-06T01:06:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/475
这是一个需求提出类型的issue，主要涉及GPT支持ms1.8。原因可能是用户希望Mindnlp的GPT模型能够支持Microsoft 1.8版本。,GPT support ms1.8,,2023-05-06T00:44:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/474
这是一个用户提出需求的issue，主要对象是支持resize embedding，由于当前系统不支持该功能，用户提出了这个需求。,support resize embedding,,2023-05-05T16:06:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/473
这个issue类型是用户提出需求，要求在MindNLP中增加T5模型的torch转MindSpore功能。这涉及的主要对象是T5模型的转换操作。由于用户希望在MindNLP中实现T5模型在torch和MindSpore之间的转换，因此提出了这个需求。,add torch_to_mindspore of T5,,2023-05-05T11:52:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/472
这是一个用户提出需求的issue，主要涉及tokenizer支持添加特殊标记，可能是为了提供更灵活的特殊标记功能。,tokenizer support add_special_tokens,,2023-05-05T10:40:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/471
"这个issue类型是用户提出需求，主要涉及的对象是""Cnn-dailymail""数据集。由于数据集下载链接失效，导致用户无法下载该数据集。",Cnn-dailymail,,2023-05-04T19:47:46Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/470,1.数据文件不要传 2. 需要写ut测试,3. 看imdb那个咋写的，不是放在根路径
这个issue类型是更新请求，主要对象是T5 tokenizer和其UT。由于T5 tokenizer及其UT需要更新，导致用户提出了更新请求。,update t5 tokenizer and its ut,,2023-05-04T17:27:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/469
这是一个用户提出需求的 issue，主要对象是为 mindnlp 增加一个 torch 到 mindspore 的功能转换。,add torch_to_mindspore,,2023-05-04T11:33:36Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/468,"加一个ut，这么测 ```python model = GPT2Model.from_pretrained('gpt2base', from_pt=True) ```"
这是一个需求提出类型的issue，主要涉及的对象是在mindnlp项目中需要添加Clip模型。原因是要将从PyTorch转换到MindSpore/MindNLP的Clip模型添加到项目中。,add clip model,add clip model and ut test(from torch to mindspore/mindnlp).,2023-05-04T07:47:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/467
这是一个用户提出需求的issue，主要对象是让mindnlp添加GPT2Tokenizer功能。可能是用户需要在mindnlp中使用GPT2Tokenizer功能，因此提出了这个需求。,add GPT2Tokenizer,,2023-05-04T01:29:53Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/466,加一个ut
这个issue是关于bug报告，主要涉及的对象是complete glm model。由于在issue中没有具体描述内容，无法确定导致bug的具体原因。,complete glm model,,2023-05-03T15:41:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/465
这个issue类型为需求提出，涉及主要对象为GPT模型和GPTTokenizer，用户提出需要为mindnlp库添加对GPT模型的支持以及添加GPTTokenizer。,gpt model support from_pretrained & add GPTTokenizer,,2023-05-03T09:44:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/464
这是一个用户提出需求的issue，主要对象是gpt模型支持图模式。由于当前模型不支持图模式，用户希望项目能够增加该功能。,gpt model support graph mode,,2023-05-03T04:18:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/463
这个issue属于改进需求类型，主要涉及mindnlp项目中的backbones模块。原因可能是为了优化项目结构或提高代码可维护性。,remove mixin to abc.backbones and add generation folder,,2023-05-02T09:21:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/462
这个issue属于需求提出类型，主要涉及的对象是BertTokenizer，用户希望支持`from_pretrained`和修改bert_finetune示例。,BertTokenizer support `from_pretrained` and modify bert_finetune example,,2023-05-01T09:10:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/461
这是一个用户提出需求的issue，主要涉及到在mindnlp中添加bert-lstm-crf示例的功能。由于内容简洁且含糊不清，可能是用户希望增加有关于bert-lstm-crf示例的相关信息。,add bert-lstm-crf example,add bertlstmcrf example,2023-04-27T10:53:27Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/460,pr名改一下，要有含义
这个issue类型为功能需求，主要涉及对象为mindnlp项目，用户提出需增加bertlstmcrf示例的功能。,My mindnlp,add bertlstmcrf example,2023-04-27T07:59:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/459
该issue属于代码回退类型，涉及mindnlp库中的gpt2_config更新导致的问题。,"Revert ""updata gpt2_config""",Reverts mindsporelab/mindnlp CC(updata gpt2_config),2023-04-22T16:13:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/458
类型：需求提出；涉及的主要对象：gpt2_config；原因：需要对gpt2_config进行更新。,updata gpt2_config,,2023-04-22T06:20:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/457
这是一个用户提出需求的issue，主要涉及到的对象是CI（持续集成）系统。,resume window ci,,2023-04-21T18:21:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/456
这是一个bug报告，主要涉及到mindnlp下的bert_finetune功能。由于fix bert_finetune，可能会出现该功能在使用过程中出现bug或无法正常使用的情况。,fix bert_finetune,,2023-04-21T17:46:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/455
"这是一个用户提出需求的类型，该问题单涉及的主要对象是""feat: PET""。由于需要新增PET功能，用户提出了该需求。",feat: PET,,2023-04-21T01:22:16Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/454,新建个目录，叫LLM，然后里面放这个，名字叫BertPET,OK，你看是这样吗,> OK，你看是这样吗 对，合入了
这是一个bug报告，主要对象是mindnlp仓库下的bertTokenizer模块。由于bertTokenizer存在问题，导致用户在使用时遇到困扰，需要修复。,fix bertTokenizer,,2023-04-20T14:11:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/453
这是一个用户提出需求的类型，该问题单涉及的主要对象是新增的news_summary功能。由于issue内容为空，用户可能希望添加新闻摘要功能到MindNLP中。,add news_summary,,2023-04-20T01:52:26Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/452,文件夹名字改成 summarization
这是一个用户提出需求的issue，主要涉及Mindnlp软件库支持Microsoft 1.8版本的问题。,support ms1.8,,2023-04-19T14:50:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/451
这是一个bug报告，主要对象是mindnlp项目中的下载功能，可能由于某种原因导致无法正常下载文本数据。,remove download ut,,2023-04-19T02:38:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/450
这是一个需求变更类型的issue，主要涉及预训练模型的更新。原因可能是为了改进模型性能或者增加新功能。,updata pretrainModel,,2023-04-18T13:39:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/448
这是一个用户提出问题的issue，主要涉及mindnlp的兼容性问题。由于未完整提供链接，用户可能遇到了无法查看贡献者指南的问题。,【mindnlp】【r1.8】【bert】【兼容性问题】,"If this is your first time, please read our contributor guidelines: https://gitee.com/mindspore/mindspore/blob/master/CONTRIBUTING.md **Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] 1. 在mindspore r1.8版本上基于mindnlp运行bert，会遇到一些API在2.0版本有，1.8版本没有的情况，eg:truncate 另外还包括诸如 msjit的新版本特性。 **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.",2023-04-18T07:39:15Z,requirement,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/447,fixed
这是一个类型为功能改进的issue，涉及主要对象为将mixin.py文件移动到abc.backbones目录。,Move mixin.py to abc.backbones,,2023-04-17T16:50:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/446
这是一个代码更新的issue，主要对象是代码生成器。由于代码可能过时或有bug，需要更新以解决问题。,update codegen,,2023-04-17T12:26:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/445
这是一个用户提出需求的类型，主要涉及的对象是在mindnlp库中添加Roberta模型。,add roberta,,2023-04-17T09:56:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/444
这是一个bug报告，涉及的主要对象是mindnlp下的模型Nezha，由于激活函数和模型配置不正确导致的bug。,correct activations and model nezha,,2023-04-16T16:48:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/443
这是一则用户提出需求的 issue，主要对象是为 mindnlp 添加 kaggle GPU 测试。,add kaggle gpu test,,2023-04-16T11:15:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/442
这是一个需求提出的issue，主要涉及到需要添加T5Tokenizer及其单元测试。由于当前代码库缺少T5Tokenizer及其相关测试，用户提出了在代码库中添加这些内容的需求。,add T5Tokenizer and its ut,,2023-04-16T07:39:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/441
这个issue是关于需求的，主要涉及更新预训练模型中的from_json_file，并由于用户需要新功能或改进。,updata pretrained from_json_file,,2023-04-15T11:24:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/440
这个issue属于需求提出类型，主要涉及mindnlp项目中的词向量模型 llama_hf 的完善。,complete llama_hf,,2023-04-14T06:40:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/439
这是一个需求类型的issue，主要涉及到添加 llama_hf 功能。,add llama_hf,,2023-04-13T13:27:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/438
这是一个需求类型的issue，主要涉及Mindnlp项目中添加完整的哪吒模型和单元测试。,add complete nezha model and ut,,2023-04-11T16:09:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/437
这是一个用户提出需求的issue，主要涉及的对象是模型预训练。由于缺乏详细描述，无法确定具体问题原因。,updata pretrained,,2023-04-10T15:06:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/436
这是一个需求类型的issue，主要涉及到修复squad流程和添加bidaf scratch。,fix squad process and add bidaf scratch,,2023-04-10T14:09:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/435
这个issue类型为bug报告，主要涉及的对象是缓存文件。由于存在无用的缓存文件导致该问题，用户希望移除这些无用文件。,remove useless cache file,,2023-04-10T13:25:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/434
"这是一个用户提出需求的类型 issue，主要对象是添加一个名为""model_codegen""的功能。",add model_codegen,,2023-04-10T08:33:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/433
这是一个bug报告，问题单涉及的主要对象是数据集 dataset_ut_test.yaml。由于数据集的问题，导致了需要修复该数据集的bug。,fix dataset_ut_test.yaml,,2023-04-09T14:07:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/432
这是一个用户提出需求的issue，主要对象是对MobileBERT fine-tuning的功能增加。,add mobilebert finetune,,2023-04-09T11:30:30Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/431,文件有点太多了，能不能合并下？
这个issue类型是用户提出需求，主要涉及的对象是GPT-2模型参数和模块更新。,updata gpt2 parm_and_module,,2023-04-09T04:32:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/430
这个issue是关于bug报告的，涉及的主要对象是SQuAD处理流程和BIDAF模型。这个问题可能由于SQuAD处理流程出现问题和缺少BIDAF的源代码版本而导致。,fix squad process and add bidaf scratch version,fix squad process and add bidaf scratch version,2023-04-09T03:50:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/429
这是一个bug报告，涉及的主要对象是ErnieModel attention_mask，由于添加了错误的tile操作而导致问题。,Fix ErnieModel attention_mask add tile operation,Fix ErnieModel attention_mask add tile operation,2023-04-08T06:20:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/428
这是一个用户提出需求的issue，主要涉及的对象是完善 MegatronBert 模型。,complete MegatronBert,,2023-04-08T03:16:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/427
该issue属于任务类型，主要涉及迁移完MegatronBert代码并完成精度对齐，可能由代码迁移和精度校准过程中的问题导致。,迁移完MegatronBert代码,迁移完MegatronBert代码，完成精度对齐,2023-04-07T17:10:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/426
该问题类型是需求提出，主要对象是添加Attention模型。,add Attention model,,2023-04-07T15:08:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/425
这个issue是一个bug报告，主要涉及的对象是mindnlp中的LSTM-CRF示例。由于某些原因导致了未提供任何内容。,examples/sequence_labeling/LSTM-CRF.ipynb,,2023-04-07T14:58:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/424
该issue类型为需求提出，主要对象是在mindnlp项目中添加预训练模型。由于用户希望在项目中加入预训练模型，故提出了这个需求。,add pretrained,,2023-04-06T09:31:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/423
这是一个请求将所有模型添加到Mindnlp中的需求类型的issue。该问题涉及的主要对象是Mindnlp项目。,add all model,,2023-04-06T01:58:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/422
这个issue属于用户需求，请求在utils中添加一个功能。主要对象是utils模块。可能是由于现有功能不足或者用户需要更多实用的功能而提出了该需求。,add function to utils,,2023-04-05T11:45:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/421
这个issue类型为功能需求，主要涉及的对象是GPTNeo模块。该问题由于用户需要添加GPTNeo模块而提出。,add GPTNeo Modules.,,2023-04-05T06:14:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/420
这是一个用户提出需求的issue，主要对象是添加所有模型。可能由于当前仓库尚未包含所有模型，用户希望将所有模型添加进去。,add all model,,2023-04-05T03:42:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/419
这是一个需求类型的issue，提出了添加所有模型的要求。 ,add all model,,2023-04-05T03:06:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/418
这是一个用户提出需求的issue，主要对象是mindnlp库，用户提出需要添加bloom模型以及fp16支持，但不支持bf16。,add bloom model,1. bloom model 2. fp16 support 3. not support bf16,2023-04-05T02:43:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/417
这是一个bug报告，涉及的主要对象是MindSpore 2.0rc1版本。由于MindSpore 2.0rc1版本存在问题，导致了错误的现象。,fix mindspore 2.0rc1 version caused error,,2023-04-04T14:14:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/416
这个issue类型是用户提出需求，目的是添加Ernie和UIE模型到项目中。,Add Ernie and UIE model,Add Ernie and UIE model,2023-04-04T13:53:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/415
这是一个bug报告，主要对象是mobilebert，由于mobilebert的ut存在问题导致需要修复。,fix mobilebert ut,,2023-04-03T03:34:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/414
这个issue类型是bug报告，主要对象是修复验证错误功能。原因是可能存在的代码逻辑错误导致验证报错，需要修复该错误以确保正常的验证功能。,fix validator error,,2023-04-02T14:35:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/413
"这是一个需求提出类型的issue，主要对象是添加一个名为""erine""的功能模块。",add erine,,2023-03-31T07:55:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/412
这是一个缺少详细描述的用户提出需求的issue，主要涉及更新XLM代码，原因可能是为了修复BUG或添加新功能。,update xlm code,,2023-03-30T09:21:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/411
这个issue是用户提出需求，请求添加Llama模型和RMSNorm UT测试。该问题单涉及的主要对象是模型和测试工具。由于用户希望增加新的功能模型和测试，因此提出了这个需求。,add llama model and rmsnorm ut,,2023-03-30T08:59:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/410
这个issue属于用户提出需求类型，主要涉及的对象是添加albert模型。这个需求是由于缺乏albert模型而提出的。,add albert model,,2023-03-30T07:29:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/409
这个issue类型是bug报告，主要涉及BertLMPredictionHead参数问题，可能由于参数设置错误导致了相关问题。,BertLMPredictionHead参数问题,https://github.com/mindsporelab/mindnlp/blob/740a6aa28faa776c2a4f64e91f8416702eafe151/mindnlp/models/bert/bert.pyL295 `masked_lm_positions`形参是否应该加默认值`None`？,2023-03-30T07:06:33Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/408,另外该模块的Dense是否也要和pytorch保持一致？,Dense可以不一致
这是一个用户提出需求的issue，主要涉及的对象是在MindNLP中添加Longformer SelfAttention类。由于缺乏Longformer SelfAttention类，用户发现无法满足其需求，因此提出了该需求。,add longformer selfAttention class,裘博航,2023-03-30T02:30:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/407
这是一个bug报告类型的issue，主要涉及到mindnlp下的Question Answer的样例与昇腾Ascend设备不适配的问题，可能由于设备兼容性或依赖库问题导致。,Question Answer 的样例存在和昇腾Ascend设备不适配的问题,"https://github.com/mindsporelab/mindnlp/blob/master/examples/question_answer/bidaf_squad_concise.ipynb          3. Contextual Embedding Layer         self.context_LSTM = StaticLSTM(input_size=hidden_size * 2, hidden_size=hidden_size,                                     bidirectional=True, batch_first=True, dropout=dropout) 在上述链接中所示代码部分，昇腾平台运行会报错： Traceback (most recent call last):   File ""nlp_test.py"", line 338, in      encoder = Encoder(char_vocab_size, char_vocab, char_dim, char_channel_size, char_channel_width,   File ""nlp_test.py"", line 91, in __init__     self.context_LSTM = StaticLSTM(input_size=hidden_size * 2, hidden_size=hidden_size,   File ""/home/xiafukun/mindnlp/mindnlpmaster/mindnlp/modules/rnns.py"", line 593, in __init__     super().__init__(mode, *args, **kwargs)   File ""/home/xiafukun/mindnlp/mindnlpmaster/mindnlp/modules/rnns.py"", line 385, in __init__     self.rnn = MultiLayerRNN('LSTM', input_size, hidden_size, num_layers, has_bias, bidirectional, dropout)   File ""/home/xiafukun/mindnlp/mindnlpmaster/mindnlp/modules/rnns.py"", line 265, in __init__     rnn_class = eval(f""Single{mode}Layer_{backend}"")   File """", line 1, in  NameError: name 'SingleLSTMLayer_Ascend' is not defined",2023-03-30T02:21:21Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/406
这是一个功能需求类型的issue，主要涉及的对象是mindnlp库中的半精度操作warper。由于缺乏添加半精度操作warper的功能，用户提出了这个需求。,add half precision op warper,,2023-03-29T11:31:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/405
这是一个用户提出需求的Issue，请求新增适配xlm-robert-base，xlm-roberta-large，flan-t5-base，flan-t5-large等四个模型到mindnlp的xlmrobert。,请新增适配xlm-robert-base ，xlm-roberta-large，flan-t5-base，flan-t5-large,请将xlmrobertbase ，xlmrobertalarge，flant5base，flant5large这四个模型加入到mindnlp xlmrobertbase链接： https://huggingface.co/xlmrobertabase flant5链接： https://huggingface.co/google/flant5base,2023-03-29T06:10:58Z,requirement,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/404
这个issue类型是用户提出需求，主要对象是新增GPTNeo模块。,add GPTNeo modules.,,2023-03-28T08:25:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/403
这是一个用户提出需求的issue，主要对象是向MindNLP项目添加GPT模型。,add gpt model,,2023-03-26T15:18:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/402
这是一个用户提出需求的issue，主要对象是在github上的mindnlp项目，用户希望添加GPT模型。,add gpt model,,2023-03-25T16:56:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/401
这是一个功能需求的issue，主要涉及支持旧版mindspore，但不包括预训练模型。可能由于用户需要在旧版mindspore中使用自定义模型，因此提出了这个问题。,"support legacy mindspore, excluding pretrained models",,2023-03-25T10:43:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/400
这是一个用户提出需求的Issue，主要涉及的对象是Luke模型的模块和单元测试。,add modules and ut tests of luke model,,2023-03-24T15:12:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/399
这是一个用户提出需求的类型，主要涉及的对象是添加功能。由于未提供具体内容，导致无法确定用户需要添加何种功能。,add erine,,2023-03-24T08:47:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/398
这个issue是一个用户提出需求类型的问题单，主要涉及修改文档需求，由于可能当前的文档内容不全或有错误导致用户需要修改。,modify doc_requirement,,2023-03-24T08:24:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/397
"这个issue是用户提出需求的类型，主要对象是在mindnlp仓库中的一个名为""add bidaf_squad_concise.ipynb""的文件。",add bidaf_squad_concise.ipynb,,2023-03-23T15:05:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/396
这是一个用户提出需求的issue，主要对象是添加XLM模型。由于缺少XLM模型，用户希望在项目中添加该模型。,add xlm model,,2023-03-23T14:36:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/395
这是一个功能需求类的issue，主要涉及到fasttext和glove的词汇表实用性问题，用户提出需要为这两个模型添加vocab ut。,fasttext and glove vocab ut,add  vocab ut for fasttext and glove,2023-03-23T08:58:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/394
这个issue类型是需求提出，主要涉及的对象是luke模型的添加和版权声明修改。这个问题由于需要在mindnlp中添加luke模型的代码块，并修改版权声明。,add blocks of luke model and modify copyright notice.,,2023-03-23T07:54:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/393
这个issue类型为功能请求，主要涉及的对象是添加LUKE模型的相关代码块和修改版权声明。这个问题来源于用户的需求，希望增加LUKE模型的支持和修改版权声明。,add blocks of luke model and modify copyright notice.,,2023-03-23T05:26:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/392
这个issue类型是需求类型，提出了修改版权的要求。寻求对版权的修改帮助。,modify copyright,,2023-03-23T04:41:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/391
这是一个bug报告类型的issue，涉及到mindnlp项目中的models_utils模块。由于未提供具体内容，无法分析导致的bug症状或用户提出的问题。,updata models_utils.,,2023-03-23T04:37:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/390
这是一个功能需求提出的issue，主要对象是modele_utils工具。它由于功能不完善而需要更新，用户提出了相关的问题和需求。,updata modele_utils,,2023-03-23T04:24:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/389
这个issue是一个功能需求提出类型，主要涉及对象是情感分析模型的优化。,use StackLSTM for sentiment analysis,,2023-03-23T00:14:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/388
这是一个bug报告，主要涉及对象是神经网络中的Dropout操作。由于命名使用的参数不一致导致了问题。,use p instead of keep_prob for nn.Dropout,,2023-03-22T09:13:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/387
这是一个bug报告，涉及的主要对象是MindNLP中的StaticGRU和StaticLSTM在GPU上的修复。由于静态GRU和静态LSTM在GPU上存在问题，用户希望寻求修复的帮助。,fix StaticGRU and StaticLSTM on GPU,,2023-03-22T08:33:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/386
这是一个bug报告，该问题涉及的主要对象是版权信息。这个问题的出现可能是因为版权信息有误或者缺失，需要修复。,Fix copyright,,2023-03-22T07:39:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/385
这是一个用户提出需求的issue，主要对象是向mindnlp仓库添加GPTNeo预训练模型，问题产生的原因是用户希望能够使用GPTNeo模型进行相关的任务。,add GPTNeo PretrainedModel,,2023-03-22T01:08:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/384
这是一个用户需求类型的issue，主要涉及MindNLP库中使用Pythonic词汇和支持MindData管道的功能。原因可能是用户希望改进库的易用性和整合性。,use pythonic vocab and support minddata pipeline,,2023-03-21T12:42:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/383
这是一个需求提交类型的issue，主要涉及MindNLP中添加T5 tokenizer和更新T5注释。原因是用户希望在MindNLP中添加T5 tokenizer以及更新相关的T5注释。,add t5 tokenizer and update t5 annotations,,2023-03-21T11:20:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/382
这是一个用户提出需求的issue，主要涉及MindNLP中支持BERT的RandomMask Transform，目的是用于运行时数据集处理。,support RandomMask Transform for BERT,for runtime dataset processing,2023-03-21T10:02:10Z,requirement,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/381,use tokenizer instead
这是一个用户提出需求类型的issue，主要涉及对象为添加bert_senta_ipynb和_check_work_files的内容。可能是用户希望文档中增加这两个内容，以便更好地理解和使用相关功能。,add bert_senta_ipynb and _check_work_files content,add bert_senta_ipynb and _check_work_files content,2023-03-21T08:31:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/380
这个issue类型为功能更新请求，主要对象是modles.utils模块。由于可能发现现有功能不够完善或有待改进，用户提出了对utils模块的更新需求。,updata modles.utils,,2023-03-21T03:56:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/379
该issue属于用户提出需求类型，主要涉及为mindnlp添加TinyBert模型。由于当前仓库并未包含TinyBert模型，用户提出了添加该模型的请求。,Add TinyBert models,https://github.com/PurRigiN/mindnlp/blob/b80b4ebe5c0ae7d49a4b9552ee6387454929b7d2/tests/ut/models/tinybert/test_tinybert.pyL15 for `tests/ut/models/tinybert/test_tinybert.py:27:0: R0904: Too many public methods (22/20) (toomanypublicmethods)`,2023-03-20T12:59:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/378
这是一个用户提出需求的issue，主要对象是增加MobileBERT模块，可能是由于项目需要使用MobileBERT模型进行相关任务而提出的。,add mobilebert modules,,2023-03-20T12:48:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/377
这是一个bug报告，涉及的主要对象是MindNLP代码库中的pylint错误。由于代码中存在一些pylint错误，导致需要对其进行修复。,fix pylint error.,,2023-03-20T02:30:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/376
这个issue是用户提出需求，并希望添加XLM模型到MindNLP中。,add xlm model,,2023-03-20T01:25:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/375
这是一个缺少具体内容的bug报告，主要涉及mindnlp中的lookup和vocab功能，原因可能是代码实现缺失或逻辑错误导致无法正常运行。,fix lookup and vocab,,2023-03-19T17:30:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/374
这个issue是关于bug报告，主要涉及的对象是CI下载错误。由于下载错误导致的症状是CI无法正常使用。,fix ci download error,,2023-03-19T17:24:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/373
这是一个用户提出需求类型的issue，主要涉及的对象是在mindnlp中添加Luke模型的LukeEmbeddings功能。,add LukeEmbeddings of luke model,,2023-03-19T12:42:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/372
该issue类型为功能需求提出，主要对象是希望在mindnlp中添加MobileBERT模块的开发者。,add mobilebert modules,,2023-03-19T12:36:53Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/371
这个issue类型是用户提出需求，请求获取最新的whl文件，主要涉及的对象是mindspore。由于用户希望获取最新版本的whl文件，因此提出了这个问题。,user repo.mindspore.cn to get newest whl,,2023-03-19T10:06:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/370
这是一个需求类型的issue，主要涉及的对象是向mindnlp项目添加GPTNeo SelfAttention功能。,add GPTNeo SelfAttention,,2023-03-17T15:58:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/369
这个issue是关于bug报告的，主要对象是模块导入失败，可能由于导入模块路径错误或者模块文件损坏导致无法成功导入。,导入模块失败,涉及的URL：https://github.com/mindsporelab/mindnlp/blob/master/tests/ut/modules/test_fasttext_embedding.py 尝试运行ut脚本训练报错：ImportError: cannot import name 'MultiheadAttention' from 'mindspore.nn' (/root/miniconda3/envs/Python375/lib/python3.7/sitepackages/mindspore/nn/__init__.py),2023-03-17T06:36:53Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/368,使用的mindspore版本不对
这是一个用户提出需求的issue，主要对象是在mindnlp中添加GPT1模型。,add gpt modules,GPT1 model ,2023-03-16T18:09:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/367
这是一个用户提出需求的issue，主要涉及的对象是向MindNLP工作流程中添加情感分析工作和模型。,add sentiment analysis work and model in workflow,add sentiment analysis work and model in workflow,2023-03-16T15:54:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/366
这是一个bug报告，主要涉及的对象是CRF模型在MindNLP中的实现。由于某些情况下CRF出现nan值，用户提出需要修复这一问题。,fix crf nan problem,,2023-03-16T15:50:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/365
这是一个用户提出需求的issue，主要对象是mindnlp库下的StaticGRU和StaticLSTM模型。由于缺乏这两种静态循环神经网络模型的实现，用户希望添加它们到mindnlp库中。,add StaticGRU and StaticLSTM,,2023-03-16T13:23:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/364
这是一个用户提出需求的issue，主要对象是修改文档结构。,modify doc structure,,2023-03-16T12:38:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/363
这是一个功能需求问题，主要涉及对象是mindnlp套件中的Vocab对象，用户需要一个用于处理Vocab对象的类，同时删除word2vec embedding和gensim库相关部分。,vocab class,一个用于处理套件中Vocab对象的类，以及删除了word2vec embedding和gensim库及相关部分,2023-03-16T08:54:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/362
这是一个文档修改类型的issue，主要涉及到使用回调函数的相关文档内容更新。,fix issue #283, CC(【文档】quick_start/use_callback.rst) ,2023-03-16T07:24:10Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/361,fix CC(【文档】quick_start/use_callback.rst) 
这是一个bug报告，主要涉及Longformer的修改。原因可能是之前的实现有误或者需要进一步优化。,modify longformer,,2023-03-16T02:37:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/360
这是一个bug报告，主要涉及的对象是longformer模型，用户提出的问题是需要根据review修改longformer。这个问题可能是由于longformer模型的性能问题或者功能改进的需求而引起的。,modify longformer accroding to review,,2023-03-16T02:34:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/359
这是一个用户提出需求的issue，主要涉及到MobileBERT添加模块的功能。由于用户希望增加一些新的模块，因此提出了这个需求。,mobilebert add modules,,2023-03-15T14:09:22Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/358,已修改
这个issue类型是用户提出需求，主要对象是mindnlp的functional和embedding class，用户请求在这两个类中添加cumsum功能和长表征（long former）。,add cumsum to functional && embedding class to long former,,2023-03-15T13:10:13Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/357
"这个issue类型是功能需求提议，主要对象是mindnlp中的T5模型相关组件。由于当前代码库缺少T5模型相关的组件（如T5Stack, T5Model, T5ForConditionalGeneration, T5EncoderModel），用户提出了需要添加这些组件的需求。",add blocks of T5 model and uts,"T5Stack, T5Model, T5ForConditionalGeneration, T5EncoderModel",2023-03-15T10:47:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/356,delete ms_release_ut_test
"这是一个用户提出需求的issue，主要对象是为mindnlp增加mobilebert中的selfoutput,attention,intermediate和outputbottleneck功能。","add mobilebert:selfoutput,attention,intermediate and outputbottleneck",,2023-03-15T06:37:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/355
"这是一个用户提出需求的 issue，主要涉及的目标是在 mindnlp 中添加 selfoutput, attention, intermediate 和 outputbottleneck。由于缺乏这些功能，用户希望对模型进行更深入的细节处理。","add selfoutput,attention,intermediate and outputbottleneck",,2023-03-15T05:39:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/354
这个issue类型为代码优化和功能增强，主要涉及到指标重构和添加机器翻译的scratch笔记本。,refactor metrics && add mt scratch notebook,,2023-03-14T16:47:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/353
这个issue属于用户提出需求类型，主要涉及的对象是修改BertTokenizer。原因可能是用户希望对BertTokenizer进行定制化以满足特定需求。,modify BertTokenizer,,2023-03-14T10:08:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/352
这是一个用户提出需求的类型，该问题单涉及的主要对象是添加LUKE模型。,add luke model,,2023-03-14T08:51:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/351
这是一个需求提出类型的issue，主要涉及的对象是添加T5PreTrainedModel和CellUtilMixin，可能是为了增加模型的功能性或者灵活性。,add T5PreTrainedModel and CellUtilMixin,,2023-03-14T08:45:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/350
这是一个用户提出需求的类型。该问题单涉及的主要对象是向mindnlp仓库添加MobileBERT模型。由于当前MindNLP仓库尚未包含MobileBERT模型，用户希望添加该模型以扩展仓库的功能。,add mobilebert,,2023-03-14T07:07:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/349
这个issue是用户提出需求，希望添加MobileBERT embeddings和self-attention。,add mobilebert embeddings and selfattention,,2023-03-14T06:27:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/348
"这是一个需求提出类型的issue，主要涉及的对象是""mobilebert""模型。由于用户需要了解有关""mobilebert""模型的信息，所以提出了这个问题。",mobilebert,mobilebert,2023-03-14T06:15:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/347
"这个issue类型是需求提出，主要对象是添加一个名为""gpt2_mmodule""的功能模块。",add gpt2_mmodule.,,2023-03-14T04:39:06Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/346,/retest
这是一个特性要求类型的issue，主要涉及到添加两个新模型到代码库中。原因可能是为了扩展模型的功能或者提供更好的支持。, Add 'cumsum' model to _legacy/functional.py and add longformer_embedding model to models/longformer.py,,2023-03-14T03:10:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/345
这是一个用户提出需求的issue，主要对象是_legacy/functional和longformer_embedding模型，用户提出了添加'cumsum'功能的需求。,Add 'cumsum' to _legacy/functional and longformer_embedding model,,2023-03-14T02:40:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/344
这是一个用户提出需求的类型，主要涉及的对象是在Mindnlp库中添加Longformer Embedding模型。这可能是因为用户希望在该库中使用Longformer Embedding模型来进行自然语言处理任务。,Add Longformer Embedding model,,2023-03-13T13:06:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/343
这是一个用户提出需求的 issue，需要添加xlmpredlayer。由于缺乏xlmpredlayer，用户无法完成特定操作或功能的需求。,add xlmpredlayer,,2023-03-13T12:43:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/342
这个issue是用户提出的需求，主要涉及的对象是添加Longformer embedding模型。用户希望在MindNLP中加入这个预训练模型，以扩展其功能。,add longformer embedding model,,2023-03-13T12:17:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/341
这是一个需求类型的问题，主要涉及 mindnlp 下的 models.models.utils 路径调整的问题。由于路径调整不正确导致了错误或不符合预期的行为。,adjust utils for models to models.utils path,,2023-03-13T10:03:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/340
这是一个撤销之前提交的补丁的issue，涉及主要对象是MindNLP项目，由于之前的提交引发了问题，需要撤销以解决相关症状。,"Revert ""[MindNLP] Support GPT2 (#301)""",This reverts commit cfed76a608cdd1a5f6d90f95cfe6ede4586187d8.,2023-03-13T07:52:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/339
"这是一个需求提出类型的issue，主要涉及的对象是添加一个名为""utils_modeling_util""的工具类。原因可能是为了提供更多关于模型的实用工具函数或方法。",add utils_modeling_util.,utils模型工具类,2023-03-11T14:38:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/338
这是一个需求类型的issue，主要对象是mindnlp项目中的models目录。,refactor models dir,,2023-03-11T14:00:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/337
这是一个用户提出需求的issue， 主要涉及的对象是mindnlp下的T5模型模块。可能是由于缺少相关模块，用户希望添加T5模型中的几个blocks。,add blocks of T5 model,"T5Config, T5LayerNorm, T5DenseActDense, T5DenseGatedActDense, T5LayerFF, T5Attention, T5LayerSelfAttention, T5LayerCrossAttention, T5Block and ut of these blocks",2023-03-11T08:46:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/336
这是一个用户提出需求的类型，主要涉及MindNLP中的gpt2模块添加activations功能。,add_activations,添加MindNLP中的gpt2模块,2023-03-10T14:45:50Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/335,/retest ,/retest
这个issue类型是功能需求，主要对象是添加utils activations功能。,add utils activations,,2023-03-10T12:05:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/334
这是一个用户提出需求的issue，主要涉及的对象是在mindnlp库中添加GPT-2模型声明。,add gpt2 declaration,gpt2的空模型提交,2023-03-10T09:24:25Z,,closed,0,3,https://github.com/mindspore-lab/mindnlp/issues/333,这个提了啥内容？,"预提交的，好像没有修改内容一直提交不了，我等会重新改过 原始邮件 发件人：""nate.river""< ***@***.*** &gt;; 发件时间：2023/3/10 17:28 收件人：""mindsporelab/mindnlp""< ***@***.*** &gt;; 抄送人：""FLoutione""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;; 主题：Re: [mindsporelab/mindnlp] add gpt2 declaration (PR CC(add gpt2 declaration)) 这个提了啥内容？ &mdash; Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;","> 预提交的，好像没有修改内容一直提交不了，我等会重新改过 原始邮件 发件人：""nate.river""< ***@***.*** &gt;; 发件时间：2023/3/10 17:28 收件人：""mindsporelab/mindnlp""< ***@***.*** &gt;; 抄送人：""FLoutione""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;; 主题：Re: [mindsporelab/mindnlp] add gpt2 declaration (PR CC(add gpt2 declaration)) 这个提了啥内容？ &mdash; Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt; 提一个有意义的文件"
这是一个bug报告，主要涉及的对象是MindNLP中的BertWordPieceTokenizer。由于在初始化时实例化BertWordPieceTokenizer导致了问题，需要对这部分代码进行检查和修复。,instantial BertWordPieceTokenizer in __init__,,2023-03-10T08:14:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/332
这是一个用户提出需求的类型，主要对象是创建Longformer模型，由于缺少三个空白的Python文件而无法完成。,create longformer model,add three blank python files,2023-03-10T03:48:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/331
"这是一个bug报告，涉及主要对象为""nezha""。由于什么样的原因导致了空内容的bug。",nezha,,2023-03-09T14:53:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/330
该issue是用户提出需求，希望添加BertTokenizer到mindnlp中。,add BertTokenizer,,2023-03-09T12:19:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/329
这是一个用户提出需求的 issue，主要对象是添加一个名为 Vocab 的类。原因可能是用户想要在项目中使用 Vocab 类来实现特定功能。,add Vocab class,,2023-03-09T11:36:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/328
这是一个用户提出需求的类型，主要涉及接入Hugging Face数据集的问题。,huggingface imdb dataset,以接入imdb数据集为例的一个接入huggingface数据集的demo,2023-03-09T09:26:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/327
这是一个用户提出需求的issue，该问题涉及的主要对象是GRUV2 operator。这可能是用户希望通过使用GRUV2 operator来实现高性能的GRU模型。,use GRUV2 operator achieve high performerance GRU,,2023-03-09T09:21:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/326
这是一个关于接入huggingface数据集的demo的需求类型issue，主要涉及项目中的数据集接入功能。,huggingface imdb dataset,一个接入huggingface数据集的demo,2023-03-09T09:04:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/325
这是一个bug报告类型的issue，涉及的主要对象是TinyBert Embeddings。由于某种原因导致了TinyBert Embeddings功能出现问题或者bug。,TinyBert Embeddings,,2023-03-09T08:41:13Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/324,approve
这是一个用户提出需求的issue，该问题主要涉及mindnlp库中的PadTransform模块。由于缺乏PadTransform模块，用户可能无法对文本进行填充操作，因此请求添加该功能以提升库的功能性。,add PadTransform,,2023-03-09T07:25:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/323
这是一个用户提出需求的issue，主要对象是legacy MindSpore。这个问题是因为需要支持AddToken transform而产生的。,support AddToken transform for legacy MindSpore,,2023-03-09T03:38:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/322
"这是一个用户提出需求的类型，主要对象是""easy pr test""。由于该issue标题和内容为空，用户可能在尝试进行某项操作时遇到了问题或者需要进行简单的测试。",easy pr test,,2023-03-09T03:27:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/321
这是一个用户提出需求的issue，主要涉及的对象是models模块。由于缺乏 megatron_bert 模型，用户请求将其添加到models中。,add megatron_bert into models,,2023-03-09T01:07:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/320
这个issue类型是需求提出，涉及主要对象是pagua_alphago_init。这可能是用户提出对于pagua_alphago_init的初始化方面的需求或者建议。,pagua_alphago_init,,2023-03-09T00:51:45Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/319,文件名不符合python规范 First 
这是一个用户提出需求的issue，主要对象是在mindnlp中添加transformer模型。,add transformer model,,2023-03-08T17:47:45Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/318,pr名要有含义  
该issue类型为需求提出，主要对象是在mindnlp项目中增加gpt_neo模型。,add gpt_neo model,,2023-03-08T14:53:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/317
这是一个用户提出需求的类型(issue)。该问题单涉及的主要对象是mindnlp项目。由于缺少具体描述内容，无法分析导致了什么样症状的bug或者用户提出了关于什么的问题或者寻求什么样的帮助。,add megatron_gpt2 model,,2023-03-08T14:33:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/316
这个issue类型是用户提出需求，主要对象是增加一个双向LSTM模型用于IMDB数据集的情感分类，用户提出了对模型实现的需求。,add bilstm_imdb st,,2023-03-08T14:27:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/315
这是一个用户提出需求的issue，主要对象是添加XLM模型。,add xlm model,,2023-03-08T13:36:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/314
这是一个bug报告类型的issue，涉及到修复问题#277和文档错误。可能由于之前的问题和文档错误导致了软件无法正确运行或者用户无法正确使用该软件。,fix issue#277 and doc bugs,,2023-03-08T12:52:39Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/313,fix CC(【文档】中文文档为空) 
这是一个用户需求类型的issue，主要涉及mindnlp项目中的models目录结构规划。该issue源于用户对模型文件夹opt的需求。,add opt model,create a forder named opt in the mindnlp/models and created basic files in it,2023-03-08T12:20:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/312
这个issue是用户提出需求，请求在mindnlp下添加bart模型。,add bart model.,https://gitee.com/mindspore/community/issues/I6GEPH?from=projectissue,2023-03-08T11:17:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/311
这是一个用户提出需求的类型，主要涉及的对象是在Mindnlp中添加OpenAI GPT1模型。用户之所以提出该需求可能是希望增加OpenAI GPT1模型在项目中的可用性和功能性。,add openai_gpt model,GPT1 model from OpenAI ,2023-03-08T11:14:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/310
"这是一个用户提出需求的类型，主要对象是想要创建名为""roberta""的文件夹。由于还未提供具体内容，可能是用户希望组织Roberta模型相关的文件或数据。",create roberta folder,,2023-03-08T10:47:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/309
这是一个bug报告，涉及的主要对象是empty tinybert files。原因可能是由于文件为空导致的bug。,empty tinybert files,empty tinybert files,2023-03-08T09:02:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/308
"这个issue是用户提出需求，主要对象是在github上的mindnlp下的mobilebert项目。由于用户需要关于mobilebert的启动信息，用户提出了""mobilebert start""的问题。",mobilebert luo zhihao,mobilebert start,2023-03-08T07:56:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/307
"这是一个需求提出类型的issue，主要对象是""mobilebert""模型。由于用户需要更多关于""mobilebert""的信息或者功能，因此提出了这个问题。",mobilebert,mobilebert,2023-03-08T07:38:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/306
该issue是添加Longformer模型的需求提出，涉及主要对象为代码中的文件组织和配置。由于未完成的代代码导致了需要添加Longformer模型时出现问题。,add longformer model（qiubohang),"创建longformer文件夹以及__init__, config_longformer，longformer文件, 其中longformer文件中有未写完的代码",2023-03-08T05:08:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/305
这是一个需求类型的issue，主要对象是要创建longformer文件夹以及相应文件。这个需求可能是为了添加新的功能或模块以支持longformer模型的集成。,裘博航创建文件,"创建longformer文件夹以及__init__, config_longformer，longformer文件",2023-03-08T05:04:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/304
"该issue类型为需求创建，并主要涉及创建名为__init__, longformer_config和longformer_model的文件。",裘博航创建文件,"创建__init__, longformer_config, longformer_model文件。",2023-03-08T04:48:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/303
该issue类型为用户提出需求，主要对象是给mindnlp添加T5模型。,add t5 model,,2023-03-08T02:39:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/302
这个issue类型为需求提出，主要对象是MindNLP库，用户提出希望支持GPT2模型。,[MindNLP] Support GPT2,,2023-03-08T02:22:41Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/301,/retest 
这个issue属于需求提出类型，主要对象是mindnlp的文档目录结构调整。可能是由于当前文档目录结构不够清晰或者易用，用户提出需要调整以提高文档的可阅读性或者使用性。,adjust dir structure of doc,,2023-03-07T17:41:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/300
这是一个用户提出需求的issue，主要对象是希望增加一个notebook示例，用户认为当前的文档不足以提供足够的指导。,add notebook example,,2023-03-07T11:16:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/299
这个issue类型为bug报告，涉及主要对象为mindnlp项目。由于缺失URL的一部分导致了无法正确链接相关issue，需要修复这个问题。,fix issues #284 and #281,Fixes https://github.com/mindsporelab/mindnlp/issues/284 and https://github.com/mindsporelab/mindnlp/issues/281,2023-03-07T01:59:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/298
这是一个bug报告，主要涉及train_and_eval.rst文件，由于文件存在问题导致用户提出了该issue。,fix train_and_eval.rst,Fixes https://github.com/mindsporelab/mindnlp/issues/281,2023-03-07T01:34:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/297
"这是一个需求修复类型的issue，主要涉及到""machine_translation""部分代码的修复。原因可能是jit参数导致了错误，同时需要完善数据集的文档翻译。",fix issue #289 and part of #276,删除machine_translation中的jit参数 补充数据集部分文档翻译,2023-03-06T17:17:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/296
这是一个bug报告类型的issue，主要涉及的对象是Mindnlp项目中的模块文件。原因可能是对MultiHeadAttention模块的删除引起了问题或需求。,fix issue 282 quick_start/modules.rst,删除MutiHeadAttention,2023-03-06T09:50:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/295
这是一个重构目录结构的issue，类型为需求提出，主要对象为项目的文件组织结构。,refactor dir,,2023-03-06T07:41:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/294
这是一个功能需求类型的issue，主要涉及到需要移除self-defined multiheadattention模块，可能是因为该模块不再需要或者存在其他更好的替代方案。,remove self-defined multiheadattention module,,2023-03-06T03:53:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/293
这个issue类型为文档修复，主要对象是项目的文档。原因可能是文档中存在错误或缺失信息，需要进行修复。,docs fixed,,2023-03-05T06:21:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/292
这个issue类型是用户提出需求，需要添加关于transforms的文档说明。该问题单涉及的主要对象是MindNLP库中的transforms功能。由于缺乏transforms的文档说明，用户提出了需要补充transforms文档的需求。,add transforms doc,,2023-02-28T14:24:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/291
这是一个bug报告类型的issue，主要涉及到Mindnlp下的CRF模块在macOS上出现RuntimeError的情况。可能是由于某些原因导致CRF模块无法在macOS上正常运行，用户在此提出寻求帮助。,avoid macOS RuntimeError of crf ut,,2023-02-28T09:56:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/290
"这个issue是关于缺少参数""jit""的文档问题，不属于bug报告，而是与文档内容相关的问题，影响的主要对象是希望使用机器翻译示例的用户。缺乏了""jit""参数导致用户无法正确使用示例，需要文档作者进行更新补充。",【文档】examples/machine_translation.rst,没有jit参数 !image,2023-02-28T08:20:25Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/289
这个issue属于bug报告类型，主要涉及mindnlp库在macOS上的logsoftmax修复问题，可能是由于计算逻辑或环境不兼容导致的bug。,fix logsoftmax on macOS,,2023-02-28T08:20:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/288
这个issue类型是bug报告，主要涉及的对象是nn.Transformer模块。由于更新导致的代码改动或者功能异常，产生了这个bug。,update nn.Transformer,,2023-02-28T07:51:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/287
这是一个用户提出需求的issue，主要涉及文档示例的编写，导致缺少必要的参数说明。,【文档】examples/fasttext.rst,要先导入 !image 没有jit参数 !image,2023-02-28T06:54:47Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/286
该问题类型为用户提出需求，主要对象是为MindNLP增加工作流框架。这个需求可能是为了提升MindNLP的处理效率和功能多样性。,Add workflow framework,Add workflow framework,2023-02-27T10:58:46Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/285, pylint没过,>  pylint没过 好像是common.nn 下面的模块我没动过
这是一个bug报告，主要涉及的对象是代码中的参数传递。由于缺少jit参数，导致trainer运行时出现问题。,【文档】quick_start/use_metrics.rst,没有jit参数 trainer.run(tgt_columns='label'),2023-02-24T06:26:32Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/284
这是一个文档问题，用户指出缺少了模块导入的代码。,【文档】quick_start/use_callback.rst,"缺少模块导入 import numpy as np from mindnlp.engine.callbacks.timer_callback import TimerCallback eval_dataset设置为None trainer = Trainer(network=net, train_dataset=train_dataset, eval_dataset=None,                   epochs=6, optimizer=optimizer, loss_fn=loss_fn, callbacks=timer_callback) 没有jit参数 trainer.run(tgt_columns='label') 缩进 !image",2023-02-24T06:24:19Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/283
这是一个文档修改的issue，主要涉及的对象是MindNLP中的模块文档。原因可能是要删除MultiHeadAttention模块并进行相关文档更新。,【文档】quick_start/modules.rst,删除MutiHeadAttention !image,2023-02-24T02:35:24Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/282, 
这是一个用户提出需求的issue，主要涉及到MindNLP的文档中关于模型训练和评估的内容，可能是由于缺少初始值和参数变化导致运行错误和评估报错。,【文档】quick_start/train_and_eval.rst,建议给drop初始值 !image 先导入math !image 建议给lr初始值 !image run方法的jit参数已删除 !image eval报错 !image,2023-02-23T08:30:15Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/281
这是一个bug报告，主要涉及的对象是CNNREmodel。这个问题出现的原因是embedding和dataset的处理尚未完成，导致了该功能的无法使用。,unfinished CNNREmodel,The processing of embedding and dataset has not been finished.,2023-02-23T08:08:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/280, pylint语法问题要解决
这个issue属于bug报告，主要涉及到torch text下载文件时指定的文件夹问题。这个问题可能是由于下载路径设置不正确导致的。,"torch text download files on pwd folder, not global dir(~/.xxx)",1. download dataset on ``{pwd}/.data/{dataset_name}`` 2. download embedding on ``{pwd}/.vector_cache/{dataset_name}``,2023-02-22T07:44:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/279
这是一个文档相关的Issue，涉及的主要对象是mindnlp模块的文档。由于多余的内容在页面中显示，导致了需要修正的问题。,【文档】多余的内容,https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmindnlp.modules.embeddings.fasttext_embedding.Fasttext.dims !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmodulemindnlp.modules.embeddings.fasttext_embedding !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmodulemindnlp.modules.embeddings.glove_embedding !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmindnlp.modules.embeddings.glove_embedding.Glove.dims !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmodulemindnlp.modules.embeddings.word2vec_embedding !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmindnlp.modules.embeddings.word2vec_embedding.Word2vec.dims !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/embeddings.htmlmindnlp.modules.embeddings.word2vec_embedding.Word2vec.urls !image https://mindnlp.cqu.ai/zh_CN/latest/api/modules/attentions.htmlmindnlp.modules.attentions.AdditiveAttention !image,2023-02-21T09:38:33Z,bug documentation,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/278,PRhttps://github.com/mindsporelab/mindnlp/pull/593已解决，若检查后无异可关闭。  
这是一个文档缺失的issue，主要对象是MindNLP的中文文档页面，原因是文档链接中的内容为空。,【文档】中文文档为空,https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/transforms.html,2023-02-21T08:26:12Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/277
该issue类型为文档问题，用户反馈中文文档中有未翻译的英文，主要涉及到mindnlp文档中关于TokenEmbedding的部分。由于文档中存在未翻译的英文内容，导致用户在查看文档时无法理解相关信息。,【文档】中文文档中有未翻译的英文,https://mindnlp.cqu.ai/zh_CN/latest/api/abc.htmlmindnlp.abc.TokenEmbedding https://mindnlp.cqu.ai/zh_CN/latest/api/common/amp.html https://mindnlp.cqu.ai/zh_CN/latest/api/common/nn.html https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/sequence_tagging.htmlmodulemindnlp.dataset.sequence_tagging.conll2000chunking !image https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/sequence_tagging.htmlmindnlp.dataset.sequence_tagging.udpos.UDPOS !image https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.amazonreviewfull https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.dbpedia https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.mnli https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.mrpc https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.qnli https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.rte https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.sst2 https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.stsb https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.wnli https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.yahooanswers https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.yelpreviewfull https://mindnlp.cqu.ai/zh_CN/latest/api/dataset/text_classification.htmlmodulemindnlp.dataset.text_classification.yelpreviewpolarity https://mindnlp.cqu.ai/zh_CN/latest/api/modules/attentions.htmlmindnlp.modules.attentions.SelfAttention.construct https://mindnlp.cqu.ai/zh_CN/latest/api/models.html https://mindnlp.cqu.ai/zh_CN/latest/api/utils.htmlmodulemindnlp.utils.decompress https://mindnlp.cqu.ai/zh_CN/latest/overview/prerequisites.html,2023-02-21T08:21:38Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/276,  !image   !image   !image
这是一个bug报告类型的issue，涉及的主要对象是mindnlp库中的中文文本分类文档。由于文档中英文符号未被正确处理，导致了显示问题。,【文档】文本分类中文文档符号问题,"https://mindnlp.cqu.ai/zh_CN/latest/examples/fasttext.html 文档中，“,”、“.”、“:”等英文符号，应对应改为“，”、“。”、“：”等中文符号。 !image",2023-02-21T08:16:20Z,bug documentation,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/275
该issue类型为功能开发需求，主要涉及Attentions模块的开发。,Attentions模块开发,,2023-02-16T06:45:10Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/274, 已完成
这是一个功能请求类型的issue，主要涉及到函数式metrics的开发。,函数式metrics开发,,2023-02-16T06:44:54Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/273, 已完成
这个issue类型是用户提出需求，主要涉及的对象是mindnlp的基类开发。,基类开发,,2023-02-16T06:29:58Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/272, 已完成
这个issue类型是bug报告，主要涉及到beam search功能。由于某些原因导致了beam search算法出现了问题。,beam search,,2023-02-16T06:28:02Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/271,use `mindnlp.transformers`
这是一个bug报告，主要涉及linear_attention相关问题。这个问题可能由于代码实现逻辑错误或者参数设置不当导致bug出现。,linear_attention,,2023-02-16T06:27:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/270, 已完成
"这个issue类型是bug报告，主要涉及的对象是""binary_linear_attention""模块，由于代码中的某些错误导致了症状的bug。",binary_linear_attention,,2023-02-16T06:27:40Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/269, 已完成
这是一个用户提出需求的issue，主要涉及PretrainedModel基类，可能是在使用过程中发现该基类功能不完善或者需要优化。,PretrainedModel基类,,2023-02-16T06:27:29Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/268, 已完成
这是一个bug报告类型的issue，主要涉及的对象是TransformerEncoder。由于什么样的原因导致了该bug或用户提出了什么问题或寻求帮助。,TransformerEncoder,,2023-02-16T06:27:11Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/267, 已完成
这是一个bug报告，主要涉及TransformerDecoder，由于某些原因导致了未填写内容。,TransformerDecoder,,2023-02-16T06:21:47Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/266, 已完成
这是一个用户提出需求的issue，主要涉及的对象是CheckpointCallback，用户希望开发相关功能。,CheckpointCallback开发,,2023-02-16T06:21:38Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/265, 已完成
这是一个需求提出类的issue，主要对象是BestModelCallback开发。用户可能因为需要在Mindnlp中引入更高效的模型回调机制而提出这个需求。,BestModelCallback开发,,2023-02-16T06:21:28Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/264, 已完成
这个issue属于用户提出需求类型，主要涉及条件随机场，可能是由于库中条件随机场功能不完善或者用户对该功能的使用方式不清楚而导致。,条件随机场,,2023-02-16T06:21:19Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/263, 已完成
该issue类型为需求提出，主要涉及对象是Trainer接口。由于缺乏Trainer接口的开发，用户提出需要开发该功能的需求。,Trainer接口开发,,2023-02-16T06:21:10Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/262, 已完成
这是一个关于需求开发的issue，主要涉及的对象是Evaluator接口。由于需要开发该接口，用户提出了相关需求或问题，寻求帮助。,Evaluator接口开发,,2023-02-16T06:21:01Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/261, 已完成
这是一个用户提出需求的issue，主要涉及的对象是TimerCallback功能。,TimerCallback开发,,2023-02-16T06:20:51Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/260, 已完成
这是一个用户提出需求的issue，主要涉及EarlyStopCallback的开发。,EarlyStopCallback开发,,2023-02-16T06:20:41Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/259, 已完成
这个issue类型为功能需求提议，主要涉及对象是Trainer和Evaluator，用户提出了希望在训练过程中能够边训练边测试的功能需求。,边训练边测试逻辑（Trainer内调用Evaluator）,,2023-02-16T06:20:31Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/258, 已完成
这个issue类型为bug报告，涉及的主要对象是下载功能。由于缺少具体描述，无法确定导致的bug症状或用户提出的问题。,Download: check_md5,,2023-02-16T03:54:51Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/257, 已完成
这是一个用户请求下载http_get的issue，该问题属于需求类型，主要涉及mindnlp库中的下载功能。,Download: http_get,,2023-02-16T03:54:42Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/256, 已完成
这是一个需求问题，用户提出希望获取下载文件路径的功能。,Download: get_file_path,,2023-02-16T03:54:32Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/255, 已完成
该issue类型为bug报告，主要涉及对象为Download功能。由于缓存机制出现问题导致无法从缓存中获取下载文件，用户提出需要修复这一问题。,Download: get_from_cache,,2023-02-16T03:54:21Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/254, 已完成
这是一个缺少内容的bug报告，主要涉及下载时的缓存路径设置问题，可能是由于程序逻辑缺陷导致用户无法正确设置或获取缓存路径。,Download: cache_path,,2023-02-16T03:54:13Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/253, 已完成
这是一个bug报告，主要涉及到下载功能，用户提出了无法获取数据集URL的问题。,Download: get_dataset_url,,2023-02-16T03:54:04Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/252, 已完成
这是一条bug报告，涉及的主要对象是perplexity计算功能。由于某些原因导致perplexity计算错误或不准确，用户提出需要修复这个bug或改进计算功能的需求。,perplexity,,2023-02-16T03:53:54Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/251, 已完成
这是一个bug报告，主要涉及的对象是mindnlp中的BLEU评估指标。由于没有具体内容，用户可能遇到了关于BLEU评估指标的问题而在issue中寻求帮助。,bleu,,2023-02-16T03:53:06Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/250, 已完成
这个issue是一个bug报告，主要涉及的对象是mindnlp库中的rouge_n函数，可能由于某种原因导致了该函数无法正常工作。,rouge_n,,2023-02-16T03:52:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/249, 已完成
这是一个bug报告类型的issue，主要涉及rouge_l指标计算的问题，可能由于计算逻辑bug或数据输入造成了不正确的rouge_l值。,rouge_l,,2023-02-16T03:52:46Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/248, 已完成
"这是一个bug报告类型的issue，主要涉及mindnlp下的""distinct""功能。原因可能是代码逻辑错误或者数据处理异常导致了此问题。",distinct,,2023-02-16T03:52:33Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/247, 已完成
这个issue类型是bug报告，主要涉及的对象是模型的accuracy。由于某些原因导致模型的accuracy出现异常或者不符合预期，用户提出了对于模型准确性的疑问或需要帮助。,accuracy,,2023-02-16T03:52:21Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/246, 已完成
这是一个Bug报告类型的Issue，主要涉及到Mindnlp项目中的Precision计算。由于某种原因导致了Precision计算结果不准确或者无法正常使用，用户希望对此进行修复或改进。,precision,,2023-02-16T03:52:11Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/245, 已完成
这个issue类型是用户提出需求，主要对象是recall功能。由于某种原因导致用户需要使用具体的recall功能或者有关recall功能的问题。,recall,,2023-02-16T03:51:59Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/244, 已完成
这是一个bug报告，主要针对f1_score计算的问题。这个问题可能由于算法实现不完整或者数据处理错误导致f1_score计算结果不准确。,f1_score,,2023-02-16T03:51:48Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/243, 已完成
"这个issue类型是bug报告，主要涉及的对象是名称为""confusion_matrix""的函数，由于某些情况下生成的混淆矩阵结果错误或不准确导致用户提出了这个问题。",confusion_matrix,,2023-02-16T03:51:37Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/242, 已完成
这是一个用户提出需求的类型，该问题涉及对象是mcc。由于issue内未提供具体内容，无法分析导致 bug 或问题的具体原因。,mcc,,2023-02-16T03:51:25Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/241, 已完成
这是一个关于计算皮尔逊相关系数的问题，类型为功能需求。该问题涉及的主要对象是mindnlp库中的数据处理功能。,pearson,,2023-02-16T03:51:15Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/240, 已完成
"这个issue属于用户提出需求类型，主要对象是MindNLP中的""spearman""功能。",spearman,,2023-02-16T03:51:05Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/239, 已完成
"这是一个需求问题，涉及主要对象是""em_score""计算功能。可能出现这个问题的原因是开发者希望添加或优化em_score功能，或用户对现有功能有建议或需求。",em_score,,2023-02-16T03:50:53Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/238, 已完成
这是一个用户提出需求的issue，主要对象是mindnlp这个项目。由于缺少具体内容，无法确定用户提出了何种需求。,additive_attention,,2023-02-16T03:50:34Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/237, 已完成
"这是一个用户提出需求的issue，主要涉及的对象是""consine_attention""。由于需要改进注意力机制的效果，用户提出了关于cosine attention的问题或寻求相关帮助。",consine_attention,,2023-02-16T03:50:19Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/236, 已完成
"这个issue类型是功能需求提出，主要涉及对象是""location_attention""功能。由于缺少具体描述或内容，用户可能提出关于如何实现或改进该功能的问题或寻求相关帮助。",location_attention,,2023-02-16T03:50:08Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/235, 已完成
这是一篇关于bug报告的issue，主要涉及到binary attention模块。可能是因为模块在运行时产生了错误或者不符合预期的行为，所以用户提出了这个问题。,binary attention,,2023-02-16T03:49:58Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/234, 已完成
"这是一个用户提出需求类型的issue，主要涉及的对象是""scaled_dot_attention""。需要解决的问题可能是该功能在某些情况下无法正常工作，导致用户希望能够改进或修复这部分功能。",scaled_dot_attention,,2023-02-16T03:49:45Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/233, 已完成
这个issue类型是用户提出需求，该问题单涉及的主要对象是 self attention。由于issue内容为空，用户可能提出了关于 self attention 的问题或寻求关于 self attention 的帮助。,self_attention,,2023-02-16T03:49:32Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/232, 已完成
这是一个用户提出需求的类型，主要涉及多头注意力机制的问题。原因可能是该机制在使用过程中出现了某些不符合预期的行为或效果，用户希望能够解决或改进相关问题。,muti-head attention,,2023-02-16T03:49:18Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/231, 已完成
这是一个用户提出需求的issue，主要对象是BaseModel基类。,BaseModel基类,,2023-02-16T03:48:58Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/230, 已完成
这个issue属于用户提出需求，主要涉及的对象是Seq2seqModel基类。用户可能对该基类功能或设计有建议或需要额外的功能支持。,Seq2seqModel基类,,2023-02-16T03:48:45Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/229, 已完成
这是一个用户提出需求的类型的issue，主要涉及Seq2vecModel的基类。由于缺少具体内容，用户可能提出了关于Seq2vecModel基类的问题或寻求相关帮助。,Seq2vecModel基类,,2023-02-16T03:48:31Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/228, 已完成
这是一个需求提出类的issue，主要涉及的对象是MindNLP中的EncodeBase基类。由于缺乏具体内容，用户可能提出对该基类的新增或修改需求。,EncodeBase基类,,2023-02-16T03:48:18Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/227, 已完成
该issue为功能需求提报，主要涉及的对象是DecoderBase基类。,DecoderBase基类,,2023-02-16T03:48:06Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/226, 已完成
这是一个缺少具体内容的Issue，类型为用户提需求，主要涉及的对象是Metric基类。,Metric基类,,2023-02-16T03:47:51Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/225, 已完成
这是一个缺少具体内容的issue，类型为用户提出需求，主要涉及的对象是CNNEncoder。,CNNEncoder,,2023-02-16T03:47:36Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/224, 已完成
这是一个需求类型的issue，主要对象是Seq2seq模型。,Seq2seq模型,,2023-02-16T03:47:18Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/223, 已完成
这个issue类型是用户提出需求，主要对象是CNN关系抽取模型。由于用户希望提供关于该模型的功能或改进建议，所以提出了这个问题。,CNN关系抽取模型,,2023-02-16T03:47:02Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/222, 模型开发完成，精度待调试
这个issue类型是用户提出需求，该问题单涉及的主要对象是下载缓存文件。由于缓存文件下载可能出现问题，用户提出了需要从缓存中下载文件的需求。,Download: cache_file,,2023-02-16T03:46:49Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/221, 已完成
这个issue类型是bug报告，该问题涉及到Download模块的get_cache_path功能，可能出现bug导致无法正确获取缓存路径。,Download: get_cache_path,,2023-02-16T03:46:30Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/220, 已完成
这个issue类型是bug报告，主要涉及的对象是mindnlp中的XavierNormal，可能是由于参数设置不正确导致模型训练出现问题。,XavierNormal,,2023-02-16T03:46:17Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/219, 提交代码已合入MindSpore主仓
这个issue类型为需求提出，主要涉及的对象是Callback基类。由于缺乏Callback基类的具体描述和实现细节，用户提出了关于Callback基类的需求或问题，希望得到更多帮助或解决方案。,Callback基类,,2023-02-16T03:44:57Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/218, 已完成
这是一个bug报告，主要涉及RNNEncoder，由于某种原因导致出现了问题。,RNNEncoder,,2023-02-16T03:44:43Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/217, 已完成
这是一个bug报告，涉及对象为RNNDecoder。这个问题可能是由于模型实现中的错误导致了某种症状的bug。,RNNDecoder,,2023-02-16T03:44:31Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/216, 已完成
这个issue类型是功能需求提出，涉及主要对象是LSTMEncoder模块。由于该模块在功能上有待完善或缺失导致用户提出改进建议或功能补充。,LSTMEncoder,,2023-02-16T03:44:18Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/215, 已完成
这是一个bug报告，涉及对象为MindNLP中的LSTMDecoder模块。可能是由于模型参数配置不当导致模型训练或推理过程中出现错误。,LSTMDecoder,,2023-02-16T03:44:05Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/214, 已完成
这是一个缺少具体内容的 issue，类型为用户提出需求。主要对象是 GRUEncoder。由于信息缺失，用户未提供关于 GRUEncoder 的具体问题或需求，导致无法了解他们想要什么样的帮助。,GRUEncoder,,2023-02-16T03:43:54Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/213, 已完成
这是一个未提供内容的bug报告，涉及GRUDecoder类。由于没有提供具体内容，无法确定导致了怎样的bug或用户提出了什么问题。,GRUDecoder,,2023-02-16T03:43:40Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/212, 已完成
这个issue是未提供具体内容的bug报告类型，涉及的主要对象是Trainer数据下沉。由于未提供具体内容，很难确定具体的bug症状或用户诉求。,Trainer数据下沉,,2023-02-16T03:38:05Z,feature,open,0,1,https://github.com/mindspore-lab/mindnlp/issues/211,非紧急需求
这是一个bug报告，问题涉及的主要对象是MindNLP项目中的Windows CI。由于MindData出现错误，导致需要移除Windows CI。,remove windows ci since minddata errors,,2023-02-09T08:59:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/210
这是一个bug报告类型的issue，主要涉及到修复pylint错误。原因可能是由于代码中存在一些语法问题或者规范性错误，导致pylint报错。,fix pylint error,,2023-02-08T10:10:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/209
这是一个用户提出需求类型的issue，该问题单涉及的主要对象是mindnlp下的一个支持旧版本的问题。用户可能由于需要在旧版本中使用特定功能或者修复一些旧版的bug而提出了这个需求。,support legacy version,,2023-02-08T04:00:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/208
这是一个用户提出需求的issue，主要涉及mindnlp下的common/nn catalog。由于未提供具体内容，无法分析问题的具体原因。,add commom/nn catalog,,2023-02-06T16:41:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/207
这个issue类型是优化建议，主要对象是CRF模块。可能是由于当前实现中的效率较低，用户建议使用while循环来加速CRF算法的执行。,use while loop to speed up CRF,,2023-02-06T07:45:52Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/206
这是一个bug报告，主要涉及的对象是CRF在GRAPH_MODE下在序列长度超过100时编译过慢。由于这个原因导致了编译速度慢的问题。,CRF compilation too slow,in GRAPH_MODE， CRF compilation is too slow if sequence length is larger than 100,2023-02-01T09:03:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/205
这是一个用户提出需求类型的issue，主要涉及对象是legacy MindSpore，用户提出添加Transformer API的需求。,add Transformer api for legacy MindSpore,,2023-01-28T09:16:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/204
这个issue属于bug报告类型，主要涉及MindSpore 1.8.1版本，用户遇到了错误并希望进行修复。,fix errors on MindSpore 1.8.1,,2023-01-28T06:28:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/203
这是一个更新构建版本的issue，主要对象是软件的构建版本。由于需要将构建版本从0.0.1更新到0.1.1，用户可能遇到了一些功能或者性能方面的改进，或者修复了一些bug。,update build version,build version：from 0.0.1 to 0.1.1,2023-01-13T09:14:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/202
这是一个关于更新构建版本的issue，类型是需求报告，主要对象是软件的版本号。,Update build version to 0.1.1,Update build version from 0.0.1 to 0.1.1.,2023-01-13T09:07:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/201
这是一个用户提出需求的类型issue，主要涉及对象是添加中文attention的快速入门指南。原因是用户希望能够更快地了解和使用中文attention相关功能。,add chinese attention quick start,,2023-01-08T11:23:56Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/200
这个issue属于需求提出类型，主要对象是MindNLP库的文档，用户提出了希望增加关于数据集和数据转换的文档内容的需求。,docs: dataset and transforms (zh_CN), ,2023-01-07T15:19:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/199
"这是一个缺少具体内容的bug报告，涉及的主要对象是mindnlp项目中的翻译文件""quick_start.po""。",update quick_start.po,,2023-01-07T12:46:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/198
这是一个文档相关的需求问题，主要涉及的对象是数据集和数据转换。,docs: dataset and transforms (en), ,2023-01-07T09:52:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/197
这是一个用户提出需求类型的issue，主要涉及的对象是attention模块。由于缺少具体描述或内容，用户可能在期望快速开始使用attention模块时遇到困难。,quick_start for attention in English,,2023-01-05T09:14:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/196
这是一个用户提出需求的issue，主要涉及添加回调函数快速入门文档的中文翻译，原因可能是为了帮助中文用户更好地理解回调函数的使用方法。,Add callback quick_start docs zh,,2023-01-03T14:14:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/195
这个issue类型是bug报告，主要对象是更新快速入门翻译文件。由于原翻译可能存在错误或过时，导致需要对快速入门翻译文件进行更新。,update quick_start.po,,2023-01-03T03:23:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/194
"这个issue类型是用户提出需求，涉及主要对象是mindnlp仓库。用户希望在目录树中添加""use_callback""功能，可能是为了增强代码的可维护性或者提升开发效率。",add use_callback into dir tree,,2023-01-03T03:06:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/193
这是一个需求类型的issue单，主要对象是添加回调函数的文档，并提出需要新增回调函数文档的请求。,add callback docs,,2023-01-02T10:14:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/192
这是一个bug报告，主要涉及到mindnlp库中的evaluator对象，问题出现在每个epoch之前编译的步骤存在错误。,fix evaluator compile before each epoch,,2022-12-30T10:10:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/191
这是一个用户提出需求的类型，主要涉及的对象是项目中的Encoder-Decoder translation功能。该需求可能是由于用户希望增加一种新的翻译功能，以满足特定的需求。,add Encoder-Decoder translation,,2022-12-28T13:36:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/190
这是一个需求提出类型的issue，主要涉及embedding module translate功能的开发需求。,embedding module translate,,2022-12-28T11:14:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/189
这是一个bug报告，问题涉及神经网络中的LSTM模块，由于训练速度慢而导致的未知错误。,An unknown error occured when training for a period time,"To solve the slow speed of nn.LSTM (issue), when I'm training the model I change nn.LSTM into LSTM written by lvyufeng. However, an error occured when training for a period time. (And I once used the validation set of  squad dataset for training for a try, which can trains successfully without any problem) Here is the error message: !OOXV6BE7$)T{$591{SB)M45",2022-12-28T10:15:41Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/188,use `mindnlp.modules.StaticLSTM` instead
这个issue类型是更新po文件，涉及到主要对象是多语言翻译。,update po files,,2022-12-28T09:59:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/187
这是一个关于bug报告的issue，主要涉及MindSpore中LSTM模型运行速度极慢的问题，可能由于使用squad数据集和bidaf模型进行QA任务训练导致。,The running speed of LSTM model from MindSpore is extremely slow.,"When using the squad dataset and bidaf model to train the QA task (question_answer.py), the training progress always maintains at 0% because of the slow speed of nn.LSTM.",2022-12-28T09:19:06Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/186,use `mindnlp.modules.StaticGRU` and `mindnlp.modules.StaticLSTM`
这是一个用户提出需求的类型，主要涉及情感分类更新问题，用户想要进行情感分类的相关更新。,update sentiment_classification,,2022-12-28T08:15:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/185
这是一个请求更新嵌入模块文档的问题，主要涉及嵌入模块（embedding module）。由于文档可能过时或不完整，导致用户需要更新或添加更多关于嵌入模块的信息。,embedding module docs,,2022-12-28T04:10:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/184
这是一个需求类型的issue，主要涉及fasttext的文档更新。,fasttext docs,,2022-12-27T16:06:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/183
这个issue类型是文档修改请求，涉及到修改一些 .rst 文件。原因可能是文档内容需要更新或者更正。,modify some .rst files,,2022-12-27T14:03:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/182
这是一个需求更新类型的issue，涉及主要对象是项目中的中文文档。由于文档需要更新，用户提出了更新关于中文文档的请求。,update sequence_tagging chinese doc,update sequence_tagging chinese doc,2022-12-27T12:55:48Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/181
这是一个用户提出需求的issue，主要涉及的对象是mindnlp库。由于缺少具体内容，用户提出了添加 QA zh_doc 的需求。,add QA zh_doc,,2022-12-27T10:30:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/180
这个issue类型是文档修改需求，主要涉及的对象是mindnlp的第一个模型文档和encoder-decoder部分。原因可能是前文档存在错误或缺漏，需要修复并添加新的内容。,fix first model docs and add encoder-decoder in modules part,,2022-12-27T09:52:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/179
"这个issue类型是需求提出，该问题单涉及的主要对象是 ""ut"" 类。由于缺少具体描述，用户可能提出了需要使用 ""ddt"" 来进行 ""ut"" 相关功能的需求问题。",use ddt for ut,,2022-12-27T08:37:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/178
这个issue是用户提出需求类型的，主要对象是metrics功能。该需求由于缺乏中文语言支持而导致用户提出了关于使用metrics的问题或者寻求中文语言相关的帮助。,use metrics zh,,2022-12-27T06:40:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/177
这个issue类型为文档更新请求，涉及主要对象为机器翻译。这个问题可能是由于文档内容过时或者不清晰导致用户需要更新或者补充相关内容。,update machine_translation docs,,2022-12-27T03:52:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/176
该issue属于bug报告类型，涉及的主要对象是更新po文件。原因可能是提交的文件版本不正确或者文件格式出现了问题。,update po files 3,,2022-12-27T03:19:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/175
这个issue类型是请求添加文档内容，主要对象是mindnlp项目，由于缺少question_answer.rst文档，用户提出了添加该文档的需求。,add question_answer.rst,,2022-12-27T02:29:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/174
该issue类型为用户提出需求或者建议，主要涉及的对象是在MindNLP中添加名为machine_translation.rst的文件。由于可能需要扩充或者补充与机器翻译相关的文档内容，用户提出了添加这个文件的建议。,add machine_translation.rst,,2022-12-26T15:09:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/173
这个issue是关于bug报告，主要涉及sequence_tagging示例文档的修复问题，可能是由于示例文档错误或不完整而导致用户无法正确理解或使用相关功能。,fix sequence_tagging example doc,fix sequence_tagging example doc,2022-12-26T13:57:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/172
"该issue是关于bug报告，主要涉及Bi-LSTM+CRF模型的loss出现""nan""的问题，可能是由于数据集或模型参数设置不当导致的。","Bi-LSTM+CRF model loss appears ""nan""","Using the CoNLL2000Chunking dataset and the BiLSTM+CRF model to train the Chunking task loss will appear ""nan"".",2022-12-26T12:48:21Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/171,use `minspore.ops.logsumexp` to avoid overflow problem
该issue类型为待进一步明确，暂无具体内容。,use metrics en,,2022-12-26T11:45:18Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/170
该issue为添加空的use_metrics.rst文件，类型为用户提出需求，涉及主要对象为mindnlp项目。,add empty use_metrics.rst,,2022-12-25T17:13:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/169
这是一个缺少内容的 Issue，类型是用户提出需求。该问题单涉及的主要对象是 fasttext。由于没有提供具体内容，无法分析导致的症状或问题的原因。,fasxttext example.po,,2022-12-24T10:33:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/168
这是一个用户提出需求的类型的issue，主要涉及MindNLP第一个模型的文档缺失问题，可能由于项目缺乏相关文档或者尚未完善导致用户提出关于添加第一个模型文档的需求。,add docs for first model,,2022-12-24T10:10:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/167
这是一个用户提出需求的类型，主要对象是在mindnlp项目下新增模型文档。原因可能是用户需要更详细的模型文档来了解各个模型的功能和用法。,add models docs,,2022-12-24T09:19:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/166
这是一个用户提出需求的issue，该问题涉及mindnlp项目中的中文训练和评估功能。原因可能是用户想要训练和评估中文模型，但在实现过程中遇到了困难。,train&eval zh,,2022-12-24T06:39:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/165
"这是一个需求报告，主要涉及""sequence_tagging example chinese doc""。由于缺少详细说明，导致用户可能需要关于这个示例文档的更多信息。",sequence_tagging example chinese doc,sequence_tagging example chinese doc,2022-12-24T05:30:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/164
这是一个用户提出需求的issue，主要对象是dataset。由于未提供具体内容，用户可能是在请求添加有关dataset的注册函数。,add registered function of dataset,,2022-12-24T01:40:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/163
这个issue类型为更新po文件，主要对象是国际化语言文件。由于内容为空，用户可能在更新po文件时遇到了问题或者希望进行更新。,update po files 2,,2022-12-23T14:52:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/162
这个issue类型为训练和评估英文模型，涉及主要对象为mindnlp项目。由于缺少具体内容，无法确定具体问题原因或提出的问题。,train&eval en,,2022-12-23T12:43:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/161
这是一个用户提出需求的issue，主要涉及fasttext示例的使用。,fasttext example,,2022-12-23T09:59:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/160
该issue是关于给出了fasttext示例文档。这是一个用户提出需求的issue，主要涉及fasttext的文档内容。可能是由于文档不全或不清晰导致用户需要更多关于fasttext示例的解释或示例。,fasttext example docs,,2022-12-23T09:55:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/159
这是一个文档相关的issue，主要对象是sequence_tagging示例文档。原因可能是示例文档标题和内容不匹配，导致用户难以理解示例用法。,sequence_tagging example doc,sequence_labeling example doc,2022-12-23T08:53:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/158
"这是一个用户提出需求的类型，该问题单涉及的主要对象是在mindnlp中增加一个名为""machine_translation.rst""的内容。",add machine_translation.rst,,2022-12-23T08:18:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/157
这个issue类型是用户提出需求，请教问题，主要对象是train&eval en功能。用户可能提出这个问题是因为希望了解如何训练和评估英文模型。,train&eval en,,2022-12-23T06:32:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/156
这个issue类型是需求提出，主要对象是训练和评估英文模型，在其中可能由于缺乏具体的训练和评估流程导致用户需要帮助或指导。,train&eval en,,2022-12-23T05:09:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/155
这是一个缺少具体内容的 issue，无法确定其类型和主要对象。,train&eval en,,2022-12-23T04:01:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/154
这是一个用户提出需求的类型，在此问题中用户主要关注的对象是文档嵌入（embedding docs），可能是希望了解如何对文档进行嵌入以进行后续的分析或处理。,embedding docs,,2022-12-22T08:18:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/153
这是一个用户提出需求的issue，主要涉及embedding文档，用户可能希望增强文档相关性分析的功能。,embedding docs,,2022-12-22T08:14:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/152
这个issue是 bug 报告类型，主要涉及的对象是数据集的注释更新。可能是由于数据集中注释有误或缺失，需要修复或完善。,update annotations in datasets,,2022-12-21T18:27:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/151
这是一个用户提出需求的issue，主要涉及的对象是embedding文档。原因是用户希望添加关于嵌入文档的信息。,embedding docs,,2022-12-21T12:55:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/150
这是一个用户提出需求的issue，主要涉及的对象是关于下载和CNN编码器相关文档的问题。可能由于缺少相应的文档，用户希望添加下载和CNN编码器的文档。,add download and cnnencoder docs.,,2022-12-20T12:15:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/149
该issue类型为用户提出需求，主要涉及对象为下载和CNN编码器文档，原因可能是用户希望获取有关这些文档的信息并请求其添加到项目中。,add download and cnnencoder docs.,,2022-12-20T11:29:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/148
这是一个用户提出需求的issue，主要涉及的对象是关于embedding文档的问题。,embedding docs,,2022-12-20T09:34:28Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/147
这个issue属于文档改进类型，涉及的主要对象是数据集处理（dataset process）。由于文档不清晰或不完整，用户可能无法准确理解如何处理数据集，因此提出了需要改进的建议。,docs: dataset process,,2022-12-20T06:18:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/146
"这是一个bug报告，涉及到""mindnlp""下的metrics中文相关问题。由于某种原因导致了metrics中文相关功能出现了问题或异常。",metrics chinese,,2022-12-20T03:36:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/145
其他类型，文档更新。主要对象是三个不同的NLP任务：机器翻译、问答系统和文本生成。这个issue可能是为了更新相关模块的文档信息，或者修正其中的错误。,"docs: machine_translation,question_answer,text_generation","docs: machine_translation,question_answer,text_generation",2022-12-19T05:50:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/144
该issue是关于需求的，主要对象是自动镜像功能；用户因自动镜像功能存在的问题或不符合预期的行为提出了这个issue。,remove auto mirror,,2022-12-19T01:14:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/143
这是一个用户提出需求的issue，主要涉及的对象是文本分类、序列标注和文本生成，可能是用户希望在MindNLP中增加相关文档内容。,"docs: text_classification, sequence_tagging, text_generation",,2022-12-17T10:21:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/142
这是一个用户提需求的issue，主要涉及到嵌入式文档（embedding docs）。通过Issue标题，用户提出了对嵌入式文档的需求。,embedding docs,,2022-12-17T09:23:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/141
这是一个功能增强的issue，该问题单涉及的主要对象是MindNLP的中文注释引擎。,add engine chinese annotations.,,2022-12-16T08:23:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/140
这个issue是文档更新类型，提及了注意力机制和BERT建模相关内容。,docs:attentions and bert modeling,docs:attentions and bert modeling,2022-12-14T02:56:41Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/139
这是一个bug报告，主要对象是api.po文件。由于未提供具体内容，无法确定导致bug的原因和症状。,update api.po 1,,2022-12-13T17:26:37Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/138
这是一条 bug 报告，针对 mindnlp 项目中的注释问题。 由于可能是由于原始文本遗漏或错误导致的，可能会影响模型训练结果。,fix some annotation,,2022-12-13T16:25:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/137
这个issue是一个关于需求的问题，主要涉及的对象是embedding文档。由于缺少具体内容，用户可能正在寻求关于如何使用或生成嵌入文档的帮助。,embedding docs,,2022-12-13T13:31:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/136
这是一个用户提出需求的issue，主要涉及的对象是embedding中文部分文档，用户希望实现文档的中文部分embedding。,embedding  docs ,embedding中文部分文档,2022-12-13T11:57:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/135
这是一个bug报告，主要涉及到attention模块注释的问题。原因是attention模块注释存在错误导致bug。,fix attention annotation,fix attention annotation 修复了attention模块注释的问题,2022-12-13T11:54:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/134
这是一个需求提出的issue，关注embedding部分的中文文档。由于缺乏embedding部分的中文文档，用户提出希望补充相关内容的需求。,embedding docs,embedding部分中文文档,2022-12-13T11:43:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/133
这是一个需求更改的issue，涉及主要对象是mindnlp项目中的imdb_process和seq2seq模块。由于需要更新imdb_process注释并删除seq2seq模块而产生。,update imdb_process annotation and del seq2seq,,2022-12-13T11:39:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/132
这是一个用户提出需求的issue，主要涉及的对象是文档和源代码，用户希望为attention和BERT模型添加中文注释。,docs:attentions and bert modeling,添加attention和bert的中文注释,2022-12-13T10:12:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/131
该issue类型为文档需求提出，主要对象涉及mindnlp库中的backbones、rnn_encoder、rnn_decoder和about模块，用户希望添加相应的文档说明。,"add docs for backbones, rnn_encoder, rnn_decoder and about",,2022-12-13T09:49:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/130
这是一个bug报告，涉及到修复 conll2000chunking 和 udpos 标注的问题。原因可能是由于标注错误或不一致导致的bug。,fix conll2000chunking and udpos annotation,,2022-12-13T09:46:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/129
这是一个用户需求问题，主要涉及到对数据集标注的修改。这个问题可能是由于数据集中存在标注不准确或缺失的情况，用户希望改进数据集的质量。,modify some datasets annotation,,2022-12-13T09:38:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/128
这是一个bug报告，主要涉及到需要修复英文注释的问题。原因可能是之前的英文注释有误或缺失，需要进行修正或添加。,fix the english annotations.,,2022-12-12T11:29:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/127
这是一个bug报告类型的issue，主要涉及的对象是mindnlp库。由于该issue内容为空，用户可能在提交时忘记填写具体信息，导致需要修复annotation的问题无法具体描述。,fix annotation,,2022-12-12T09:03:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/126
这是一个bug报告，主要对象涉及MindNLP下的IWSLT2016数据集。由于数据集存在问题，导致需要修复bug。,fix iwslt2016 dataset and CoNLL2000Chunking_Process annotation,fix iwslt2016 dataset.,2022-12-11T14:57:35Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/125
这是一个文档相关的需求提出类型的issue，主要涉及的对象是loss文档。由于原文缺少中文注释，用户提出了补充中文注释的需求。,docs: loss,docs: add Chinese comments in loss,2022-12-11T12:03:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/124
这个issue是一个bug报告，涉及主要对象是mindnlp中的embedding rst文件，原因是文件名导致的问题。,fix embedding rst,修改了rst文件的名字来解决问题,2022-12-10T10:41:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/123
这是一个用户提出需求的问题，主要涉及Mindnlp的文档修改操作。用户可能提出这个问题是因为希望对文档中的某些内容进行修改或更新。,modify embeddings.rst,,2022-12-10T10:26:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/122
这是一个功能需求类型的issue，主要对象是对MindNLP的BERT模型实现。由于缺乏函数式融合编程的BERT模型实现，因此用户提出了对标Hugging Face并添加MindNLP Bert modeling的需求。,函数式融合编程的BERT实现，对标huggingface,add MindNLP Bert modeling  函数式融合编程的BERT实现，对标huggingface,2022-12-08T04:26:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/121
这是一个用户提出需求类型的issue，主要涉及文档翻译。用户希望在项目中添加翻译文档，可能是为了扩大项目的受众群体或提供更好的用户体验。,add translation docs,,2022-12-06T12:54:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/120
该问题类型是新功能需求，主要涉及的对象是README文档。由于缺乏介绍，用户希望添加README的介绍。,add README introduction,,2022-12-06T09:19:06Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/119
"这是一个用户提出需求的类型，该问题单涉及的主要对象是添加一个名为""make_wheel_releases""的action。由于目前项目中缺少该action，用户提出了需求来增加这个功能。",add make_wheel_releases action,add make_wheel_releases action,2022-12-05T10:29:57Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/118
"这个issue是关于需求的，主要对象是项目的README文档。原因是缺少""Get Started""部分，导致用户无法快速开始使用该项目。",readme: get started,readme中Get Started部分的编写。,2022-12-05T07:31:51Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/117
这是一个需求提出类型的issue，主要涉及的对象是添加BiLSTM-CRF序列标注模型示例。由于标题和内容不一致，可能是用户在提出需求时出现了错误。 ,add BiLSTM-CRF sequence tagging model example,add BiLSTMCRF sequence tagging model example,2022-12-03T13:03:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/116
这是一个bug报告，主要涉及到MindNLP中训练器（trainer）不支持BiLSTM+CRF模型的问题，可能是由于自定义损失在模型层导致的。,"""trainer"" does not support Bi-LSTM+CRF model (custom loss is in the model layer)","""trainer"" does not support BiLSTM+CRF model (custom loss is in the model layer)",2022-11-25T12:07:36Z,bug,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/115
这是一个用户提出需求的issue，主要涉及MindNLP中添加SQuAD1数据集处理和Bidaf示例的需求。,add squad1 dataset process and bidaf example,,2022-11-25T07:26:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/114
这个issue类型是功能需求提议，主要涉及对象是添加Conll2000Chunking处理过程。由于缺乏Conll2000Chunking处理步骤，用户提议添加此功能以完善MindNLP。,add conll2000chunking process,add conll2000chunking process,2022-11-23T15:03:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/113
这是一个用户提出需求的 issue，主要涉及的对象是 RTE dataset。由于数据可能过时或者质量有待改进，用户建议更新 RTE dataset。,update RTE dataset,,2022-11-23T02:43:45Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/112
这个issue类型是用户提出需求，该问题单涉及的主要对象是fasttext模型的example函数。由于用户可能希望在agnews数据集上使用fasttext模型，因此提出了对相关示例的修改请求。,fasttext example,fasttext模型的example，同时做了agnews对应的一点修改,2022-11-21T11:17:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/111
这个issue是用户提出的需求类型的，涉及的主要对象是向MindNLP项目添加机器翻译功能和更新Multi30k数据集处理方法。,"add machine_translation, update multi30k process",,2022-11-20T03:31:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/110
这是一个bug报告，主要涉及的对象是ag_news数据预处理。由于数据预处理相关的修改出现了问题，导致需要修复这部分代码。,ag_news process fix,ag_news 数据预处理相关修改,2022-11-19T09:01:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/109
这是一个bug报告，主要涉及BiDAF Model在调用Trainer时发生错误。由于多输出模型调用Trainer时出现了错误，导致该问题的出现。,Error occured when multi-output model calls Trainer,BiDAF Model will generate two outputs. Error occured when Trainer was called. Parts of the code: !image Error information: !viDZi7nhQy,2022-11-18T07:33:29Z,bug,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/108,"When the network model returns more than one value, loss function needed to be reconstructed before put into Trainer."
"这是一个bug报告，问题涉及的主要对象是MindNLP库中的Trainer类。这个问题由于""Trainer""类没有考虑到""loss_fn""参数可以为None而导致的。",trainer support loss_fn=None,"Fixes CC(""Trainer"" doesn't take into account the case that ""loss_fn"" doesn't need to be passed in.)",2022-11-17T05:50:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/107
这是一个用户提出的功能需求。主要目的是为了在mindnlp的load函数中添加能够使用npy文件加载embedding的功能。,embedding load npy file,在load函数里添加了能用npy文件加载embedding的功能,2022-11-15T12:16:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/106
"这是一个bug报告，主要涉及的对象是使用""TextBaseDataset.build_vocab""构建""vocab""后在使用""text.Lookup(vocab)""时出现错误。这个问题可能是由于不正确的使用方法或者代码逻辑错误导致的。","Using ""TextBaseDataset.build_vocab"" to construct ""vocab"", and then using ""text.Lookup(vocab)"" will report an error.","Using ""TextBaseDataset.build_vocab"" to construct ""vocab"", and then using ""text.Lookup(vocab)"" will report an error.",2022-11-15T12:09:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/105
这是一种功能需求问题，涉及到嵌入表加载逻辑，导致无法使用特定的npy类型文件。,"""Embedding"" may need to add the logic for loading npy files","Some Datasets have their own embedding tables which are npy tpye files. However, the loading of npy files is missing in the  ""embedding"" API.",2022-11-12T13:49:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/104
这是一个bug报告，主要对象是MindNLP中的Trainer类。由于Trainer类在某些情况下没有考虑到loss已经定义的情况，导致了这个问题的产生。,"""Trainer"" doesn't take into account the case that ""loss_fn"" doesn't need to be passed in.","""Trainer"" does not take into account the case where ""loss"" is already defined in the model, and there is no need to pass ""loss_fn"" to ""Trainer"".",2022-11-12T13:26:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/103
这是一个用户提出需求的issue，主要涉及到更新openi仓库的URL链接。,upgrade openi repo url,,2022-11-11T14:45:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/102
这是一个bug报告，主要涉及的对象是mindnlp中的bucket batch功能。这个bug可能由于代码中的错误导致了bucket batch功能无法正常工作。,fix bucket batch error,,2022-11-11T05:38:04Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/101
这是一个需要添加IMDB数据集处理流程的功能需求，涉及主要对象为Mindnlp。由于现有处理流程没有包含IMDB数据集，用户提出了需要新增该处理流程的需求。,add IMDB process,,2022-11-10T18:26:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/100
这是一个用户提出需求类型的issue，主要涉及的对象是mindnlp库中的trainer.py文件。由于训练器（trainer）的注释（annotation）需更新，用户提出了这个问题来寻求帮助。,update trainer.py annotation,,2022-11-10T12:14:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/99
这是一个文档缺失的issue，标签类型为文档问题，问题涉及主要对象为mindnlp项目的README文档，原因是开发者没有填写内容导致。,README,,2022-11-09T08:16:44Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/98
这个issue是一个bug报告，主要涉及的对象是MindNLP中的CRF（Conditional Random Fields）模块。该问题可能由于CRF模块存在错误或者不完善的实现导致无法正常工作。,fix crf,fix crf,2022-11-08T12:22:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/97
这是一个bug报告，涉及mindnlp中情感分析示例的修复。由于情感分析示例存在错误，用户提出需要修复这个bug。,fix sentiment analysis example,,2022-11-06T04:05:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/96
这个issue类型是bug报告，涉及的主要对象是mindnlp代码库。由于cmrc2018loss模块在图模式下存在问题，用户提出了修复的需求。,fix: cmrc2018loss graph mode,,2022-11-04T12:26:33Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/95
这是一个需求提出类型的issue，主要对象是在mindnlp中增加CRF功能。可能由于用户希望在项目中使用CRF模型来提升自然语言处理性能而提出了此问题。,add crf,add crf,2022-11-04T03:44:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/94
这个issue属于bug报告，涉及更新数据集中的注释，用户可能遇到数据集注释有误或不完整的问题。,update  annotation in datasets,,2022-11-03T13:00:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/93
这是一个用户提出需求的issue，主要涉及的对象是添加在Windows下的单元测试和文档部分。,add windows ut-test and doc sections,,2022-11-02T04:24:52Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/92
这是一个用户提出需求的issue，主要对象是要求添加openi sync功能。可能是由于用户需要在该项目中实现实时同步功能，所以提出了这个需求。,add openi sync,,2022-11-01T14:30:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/91
这是一个关于文档目录重排的issue，类型为需求提出，主要对象为文档结构。,rearange docs dir,,2022-11-01T13:26:28Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/90,lgtm
该issue类型为格式修复，主要涉及mindnlp项目。这个问题由于格式错误导致内容排版混乱，需要进行修复。,minor repairs of format,,2022-11-01T13:12:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/89
该issue为用户需求类型，主要对象是测试框架pytest。这个问题由于缺少pytest标签导致用户希望补充该标签。,add pytest tag, ,2022-11-01T12:47:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/88
这个issue属于bug报告类型，主要对象是mindnlp下的loss.py和machine_translation模块。原因可能是存在着这两个模块中的某些问题或者bug需要修复。,fix: comment on loss.py and machine_translation,,2022-11-01T11:29:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/87
该issue为需求升级文档类型，涉及主要对象为文档内容。,upgrade docs,,2022-11-01T11:18:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/86
这个issue属于bug报告类型，涉及主要对象是代码中的函数do_eval。由于该函数在代码中出现问题，需要被移除。,remove do_eval,,2022-11-01T03:01:19Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/85
这是一个bug报告，涉及到mindnlp下的文档更新和数据集工具错误。可能是由于文档未及时更新或数据集工具的bug导致的问题。,update doc and fix dataset ut error,,2022-10-31T22:31:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/84
这个issue是一个bug报告，涉及的主要对象是embedding function and docstring，可能是由于函数错误或文档描述不准确导致了问题。,embedding function and docstring fix,,2022-10-31T12:30:25Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/83
这个issue属于bug报告类型，主要涉及embedding class和test function的修复。由于修改了部分代码和测试功能，可能导致相关功能无法正常运行或者出现错误。,embedding class and test function fix ,根据glove_embedding修改了其余2个，以及对应的ut测试反向。,2022-10-31T11:37:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/82
这是一个bug报告类型的issue，主要涉及mindnlp下的文本标注功能。由于缺少具体内容，用户反馈了需要修复标注问题的情况。,fix annotation,,2022-10-31T08:48:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/81
该issue是关于更新下载和cnn_encoder的注释，属于文档更新类型，主要涉及到代码注释补充。,update comments of download and cnn_encoder.,,2022-10-30T18:16:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/80
这是一个bug报告类型的issue，主要涉及的对象是mindnlp项目中的注释功能。导致这个issue的原因可能是之前的注释存在错误或者缺失，需要进行修复。,repair the annotation,repair the annotation,2022-10-30T12:12:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/79
这是一个功能需求，提出了关于数据集模块需要升级以实现自动删除下载文件的问题。,upgrade dataset ut to autoremove downloaded file,,2022-10-30T09:38:55Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/78
该issue类型为用户提出需求，涉及主要对象是添加独立数据集的工作流。原因可能是用户希望能够方便地将独立数据集集成到项目中。,add standalone dataset workflow,,2022-10-30T08:53:15Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/77
这是一个bug报告，主要涉及embedding的修复问题，可能是由于文档字符串和构造、保存函数有问题导致的。,"embedding fix:docstring and construct,save function",,2022-10-30T06:58:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/76
这个issue是需求性质的，涉及到RNNDecoder的代码修改，用户要求将RNN替换为RNNCell。,change RNN to RNNCell in RNNDecoder,,2022-10-29T15:09:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/75
这个issue类型是bug报告，涉及的主要对象是LocationAwareAttention和BinaryAttention。由于一些代码问题，这两个模块无法正常工作，需要修改修复。,fix LocationAwareAttention and BinaryAttention,,2022-10-29T12:27:22Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/74
该issue为bug报告类型，涉及修改指标的代码注释，可能由于当前的代码注释不清晰或者有误导性导致了bug或用户困惑。,Modify the code annotations of metrics,,2022-10-29T12:20:20Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/73
这是一个bug报告类型的issue。该问题单涉及的主要对象是metrics的代码注释。由于代码注释有误，导致症状是需要修改metrics的代码注释。,Modify the code annotations of metrics,,2022-10-29T12:11:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/72
这是一个bug报告，主要涉及MindNLP库中的嵌入和训练器问题，可能原因是嵌入问题导致的错误或训练器功能无法正常运行。,fix embedding and trainer problems,,2022-10-29T09:40:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/71
这是一个bug报告类型的issue，涉及对象是mindnlp下的conf.py文件。由于conf.py文件中存在问题，导致需要修复。,fix conf.py,,2022-10-28T03:22:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/70
这是一个bug报告，主要涉及mindnlp下的rdrop loss backward test，由于Windows平台mindspore.grad报错导致。,add rdrop loss backward test,在linux平台已经验证 windows平台mindspore.grad会报错 已经打上skip标签 验证图片如下 !image,2022-10-28T03:12:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/69
这是一个用户提出需求的issue，主要涉及文档（Docs）部分。,Docs,,2022-10-27T07:17:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/68
这是一个功能需求类型的issue，主要涉及的对象是embedding module。可能是用户希望给embedding module新增保存和加载功能，以提高模型的持久化和复用性。,embedding module:add save and load function,,2022-10-27T03:34:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/67
这是一个bug报告，主要涉及的对象是metrics test ut。由于需要移除pytest中的skip操作，可能出现测试用例无法正常执行或者无法完整测试相关功能的情况。,remove pytest skip for metrics test ut,,2022-10-25T01:48:26Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/66
这是一个用户提出需求的类型，该问题单涉及的主要对象是text_classification datasets，用户提出了关于处理文本分类数据集的相关问题。,process of the text_classification datasets,,2022-10-24T17:55:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/65
这是一个关于补丁下载参数注释的bug报告，主要涉及下载参数的注释问题。这个问题可能由于未清晰定义下载参数导致用户无法正确使用或理解相关功能。,patch download parameter annotation,patch download parameter annotation,2022-10-24T12:42:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/64
这是一个功能需求类型的issue，该问题涉及主要对象是BasicTokenizer，由于缺乏Windows支持，用户提出需要为BasicTokenizer增加Windows支持。,add windows support for BasicTokenizer,,2022-10-23T15:57:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/63
这个issue属于修改指标（metrics）的类型，涉及的主要对象是MindNLP项目。可能是由于指标不准确或者需要定制化的需求，用户提出了修改指标的需求。,modify metrics,,2022-10-20T15:57:54Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/62
这是一个简短的bug报告，主要涉及MindNLP库中注意力机制的修复。原因可能是注意力机制的实现存在错误或缺陷导致了问题的产生。,fix attentions,fix attentions,2022-10-20T15:27:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/61
这个issue类型是用户提出需求，该问题单涉及的主要对象是添加自定义amp，由于可能用户需要对mindnlp进行定制化，导致提出了这个需求。,add custom amp,,2022-10-20T10:10:43Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/60
这是一个用户提出需求的issue，主要涉及的对象是需要为mindnlp添加对mindspore 1.8.1的支持。可能是由于mindnlp目前不支持mindspore 1.8.1版本导致用户提出该需求。,add support for mindspore 1.8.1,,2022-10-20T07:36:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/59
这是一个bug报告，涉及到MindNLP中的embedding token修复。由于embedding token的问题，导致了某些症状或者功能无法正常工作。,embedding token fix,,2022-10-20T03:49:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/58
这个issue类型是bug报告，主要涉及的对象是tokenembedding，可能是由于代码中的错误导致了相关问题或者症状。,tokenembedding fix,,2022-10-19T05:14:00Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/57
这是一个缺少具体信息的功能需求问题，主要涉及工具或软件的缺陷。,solve left problems.,,2022-10-18T13:02:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/56
这是一个用户提交需求的issue，主要对象是在机器翻译和文本生成中添加进程。可能是用户希望为这两个功能增加相关的处理流程。,"add process in machine_translation,text_generation","add processes in machine_translation, text_generation",2022-10-18T07:54:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/55
这个issue类型是bug报告，涉及主要对象是tokenembedding，由于修复问题导致的bug症状。,tokenembedding fix,,2022-10-18T05:48:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/54
"这是一个bug报告，主要对象是""fix Register decorator""。原因可能是Register装饰器存在问题导致相关功能无法正常使用。",fix Register decorator,,2022-10-17T13:58:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/53
这个issue类型是bug报告，主要对象是embedding的修复。由于某种原因导致了embedding出现问题，用户提出需要修复的帮助。,embedding fix,,2022-10-17T05:22:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/52
这个issue属于bug报告类型，主要涉及的对象是mindnlp项目下的嵌入修复。原因可能是嵌入在使用过程中出现问题，导致需要修复。,fix embeddings,,2022-10-17T05:08:07Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/51
这个issue是一个bug报告，涉及的主要对象是embedding。由于某种原因导致了embedding出现问题，需要修复。,embedding fix,,2022-10-17T03:43:32Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/50
这是一个缺少内容的issue，类型为用户提出了需求，主要涉及修改metrics。由于未提供具体内容，用户可能想要增加或修改评估指标以改进模型性能。,modify metrics,,2022-10-16T14:47:23Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/49
这个issue类型是用户提出需求，涉及的主要对象是向mindnlp仓库添加一些新的度量类。可能是用户希望在mindnlp中使用这些度量类来评估模型性能。,add metric classes,"add metric classes Perplexity, RougeN, RougeL, Distinct, Precision, Recall, ConfusionMatrix, MCC, Pearson, Spearman, EmScore",2022-10-16T09:37:14Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/48
"这是一个用户提出需求的issue，主要涉及添加Metric类（Perplexity, RougeN, RougeL, Distinct, Precision, Recall, Conf），用户希望这些Metric类能够被加入到项目中。",add metric classes,"add metric classes Perplexity, RougeN, RougeL, Distinct, Precision, Recall, ConfusionMatrix, MCC, Pearson, Spearman, EmScore",2022-10-16T09:30:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/47
这个issue类型是需求提出，主要涉及的对象是要在mindnlp中添加一些评估指标类，原因可能是为了增强模型评估的功能和可靠性。,add metric classes,"add metric classes Perplexity, RougeN, RougeL, Distinct, Precision, Recall, ConfusionMatrix, MCC, Pearson, Spearman, EmScore",2022-10-16T09:21:59Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/46
这是一个bug报告，主要涉及参数名、参数值和位置的统一问题。这个问题的症状是参数的不统一性，可能导致程序在处理参数时出现错误。,"fix: Unify parameter names, values and positions",统一了参数名与参数位置，添加了默认参数,2022-10-16T09:20:29Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/45
这是一个用户提出需求的issue，主要涉及更新训练器和评估器参数及函数名称，可能是因为需要统一命名或者提高代码的可读性。,update trainer and evaluator args and fun names,,2022-10-16T08:59:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/44
这是一个功能需求提议，主要涉及到添加各种度量指标类，如Perplexity、RougeN、RougeL、Distinct、Precision、Recall和Conf。,add metric classes,"add metric classes Perplexity, RougeN, RougeL, Distinct, Precision, Recall, ConfusionMatrix, MCC, Pearson, Spearman, EmScore",2022-10-16T07:40:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/43
这是一个需求类型的issue，主要涉及参数类型提示和代码注释的修改。可能是由于现有代码中的类型提示不清晰或者注释不准确而导致需要修改。,Modify parameter type hints and code comments,Modify parameter type hints and code comments,2022-10-16T07:24:09Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/42
这个issue类型是需求提出， 主要对象是trainer，由于使用时需要支持多个返回值的情况。,trainer support multiple return value,,2022-10-16T06:35:34Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/41
这是一个bug报告，主要涉及情感分类功能，问题可能是由修复情感分类方面的错误引起的。,fix sentiment classification,,2022-10-15T13:16:42Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/40
这是一个需求提出类型的issue，主要涉及到三个数据集的处理过程。由于缺少具体描述，用户可能在处理数据集时遇到了问题，需要获取帮助或解决方案。,the process of three datasets,the process of three datasets,2022-10-13T15:19:12Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/39
这是一个用户提交的需求类型的issue，主要对象是项目中的README.md文件。这个问题可能是用户想要修改项目的说明文档，更新其中的内容或者格式。,modify readme.md,,2022-10-13T13:02:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/38
这个issue类型是用户提出的需求，主要涉及的对象是代码中的数据处理流程。由于可能需要针对特殊数据集进行不同处理，用户在提出了对通用处理逻辑使用方法的建议。,add iwslt2017 process with common process,看一下这样的写法行不行 如果逻辑相同，调用`mindnlp.utils`的`common_process` 如果遇到特殊的数据集，也可以不进行调用，另外写,2022-10-12T12:29:20Z,,closed,0,2,https://github.com/mindspore-lab/mindnlp/issues/37,已将`common_process`改在了`dataset`目录下的`process.py`,> 已将`common_process`改在了`dataset`目录下的`process.py` ok
这是一个bug报告，主要涉及到修复GloVe嵌入、IMDb、RNN编码器和解码器的问题。由于代码逻辑错误或者数据处理不当，导致相关功能无法正常运行，需要修复以恢复功能正常。,"fix glove embedding, imdb, rnn encoder and decoder",,2022-10-12T08:16:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/36
"这个issue属于bug报告，涉及主要对象为mindnlp项目。由于对一些功能的修复操作（fix glove embedding, imdb, rnn encoder and decoder）产生了反向变化，导致需要撤销这些改动。","Revert ""fix glove embedding, imdb, rnn encoder and decoder""","Reverts mindsporeecosystem/mindnlp CC(fix glove embedding, imdb, rnn encoder and decoder)",2022-10-12T08:15:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/35
这是一个bug报告，涉及MindNLP中的GloVe嵌入、IMDb、RNN编码器和解码器。可能由于嵌入问题导致的错误或不准确。,"fix glove embedding, imdb, rnn encoder and decoder",,2022-10-12T08:02:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/34
这个issue是一个测试相关的需求，主要涉及的对象是数据集的单元测试。,add pytest.mark.skip in all dataset ut,,2022-10-11T05:31:50Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/33
这个issue类型为功能需求提出，主要对象是Seq2Seq模型。由于旧的初始化格式不符合需求，用户提出升级初始化格式的请求。,upgrade init format of Seq2Seq,,2022-10-10T10:10:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/32
这是一个用户提出需求的issue，主要涉及增加新的数据集到mindnlp中。,"add ungz, CoNLL2000Chunking, UDPOS, WNLI, RTE, SogouNews",,2022-10-09T16:42:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/31
这是一个需求提出类型的Issue，主要涉及了添加YelpReviewPolarity、YelpReviewFull和YahooAnswers。其原因可能是为了扩展数据集或增加模型训练的多样性。,Add YelpReviewPolarity YelpReviewFull YahooAnswers,Add YelpReviewPolarity YelpReviewFull YahooAnswers,2022-10-09T08:41:05Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/30
这是一个用户提出需求的issue，主要涉及数据集的添加，可能是为了增加模型训练的多样性。,"add IMDB, MNLI, MRPC, QNLI, QQP",,2022-10-08T11:38:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/29
这是一个bug报告，该问题涉及的主要对象是下载功能。这个问题是由于下载函数“http_get”访问问题导致的。,Fixed download “http_get“ download issues,Fixed download “http_get“ download issues,2022-10-05T17:38:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/28
"这个issue是一个类型为用户提出需求的问题，涉及的主要对象是在mindnlp中增加AmazonReviewFull, AmazonReviewPolarity, STSB, DBpedia数据集。","add AmazonReviewFull, AmazonReviewPolarity, STSB, DBpedia",,2022-10-05T09:28:10Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/27
这个issue是一个需求类型，主要对象是数据集。由于需要将代理添加到所有现有数据集，用户希望为数据集添加代理的功能或支持。,add proxies to all existing datasets,,2022-10-03T09:38:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/26
这是一个需求类型的issue，主要对象是将Mindnlp中的pipeline移动到工作流中。,move pipeline to workflow,,2022-10-02T01:13:49Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/25
这是一个需求提出类型的issue，主要涉及的对象是提取通用工具。由于缺乏通用工具的支持，用户提出了需要提取常用工具的需求。,extract common utils,,2022-10-01T16:41:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/24
这是一个需求类型的issue，主要涉及对象是mindnlp库的运行模式。由于需要将运行模式修改为jit，用户提出了此需求。,modify running mode to jit,,2022-10-01T15:51:58Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/23
这是一个请求移动脚本的问题，涉及对象是脚本文件。由于未提供具体内容，无法确定具体原因。,move scripts,,2022-10-01T15:04:38Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/22
这是一个用户提出需求的类型，该问题单涉及的主要对象是在Mindnlp中添加代理的功能。,add proxies,,2022-10-01T03:16:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/21
这个issue是一个功能增强需求，主要对象是测试文件。由于缺少Pylint检查，导致测试文件可能存在代码质量问题。,add pylint check for tests,,2022-09-30T21:05:08Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/20
"这个issue是关于Bug报告，可能涉及到Mindnlp项目中某个Python包的安装问题，用户反映在运行""python setup.py bdist_wheel""时出现错误导致安装失败。","error occured when running ""python setup.py bdist_wheel""","fail to run ""python setup.py bdist_wheel""; error information is as folloews: ..... running install_scripts error: [WinError 5] 拒绝访问。: 'build\\bdist.winamd64\\wheel\\mindnlp0.0.1.distinfo\\dependency_links.txt' !image",2022-09-30T09:27:06Z,,closed,0,1,https://github.com/mindspore-lab/mindnlp/issues/19,"This is an issue of python `wheel` lib.  See Building wheel from readonly source on Windows gives ""Access Denied"" on cleanup CC(huggingface imdb dataset). The contributor claims the bug has been fixed but seems not."
这是一个用户提出需求的issue，主要涉及下载和AG_NEWS功能，用户希望添加代理支持。,add proxies in download and AG_NEWS,,2022-09-30T07:55:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/18
这是一个功能需求的issue，主要涉及的对象是添加SST2数据集和相关的单元测试。,add SST2 dataset and ut test_sst2,,2022-09-30T01:26:11Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/17
该issue是一个功能请求，主要涉及添加四个数据集和修复download.py文件。,Add four datasets and fix download.py,Add four datasets and fix download.py,2022-09-29T10:41:17Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/16
这是一个用户提出需求的issue，主要对象是向项目中添加CoLA数据集和进行单元测试。,add CoLA dataset and ut test_cola,,2022-09-29T09:27:47Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/15
这是一个需求类型的issue，主要涉及的对象是增加CoLA数据集和添加ut test_cola测试。,add CoLA dataset and ut test_cola,,2022-09-29T07:46:40Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/14
这是一个用户提出需求的issue，主要涉及添加ag_news数据集的处理。产生这个需求的原因可能是用户希望在mindnlp中增加对该数据集的支持。,add ag_news process,,2022-09-27T10:16:39Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/13
此issue类型为需求提出，主要对象是添加情感分类功能。这个问题的提出可能是为了增强mindnlp的功能和实用性。,add semtiment classification st,,2022-09-27T10:08:31Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/12
这个issue是一个功能需求，该问题单涉及的主要对象是Mindnlp项目。由于缺少BleuScore功能，用户提出了需要添加BleuScore的需求。,add BleuScore,,2022-09-27T08:34:02Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/11
这个issue属于用户提出需求，请求添加BleuScore，主要涉及Mindnlp项目的代码。,add BleuScore,,2022-09-27T08:06:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/10
这是一个用户提出需求的类型，主要对象是项目中的CNNEncoder。这个需求是为了添加CNNEncoder，可能是为了提升项目的性能或功能。,add CNNEncoder,add CNNEncoder,2022-09-27T08:04:30Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/9
"这是一个用户提出需求的issue，主要对象是向mindnlp添加一个""map_rule""用于注册的功能。",add map_rule for register,,2022-09-27T07:50:24Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/8
这是一个需求提出的issue， 主要涉及文件的重命名和测试文件的添加，由于需要统一命名规范或者补充测试部分，用户提出了这个问题。,"rename agnews.py, add test_agnews.py,",,2022-09-26T16:27:27Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/7
这个issue类型是需求提出，涉及的主要对象是注册功能。这个问题可能由于缺少注册功能导致用户无法创建账户或体验某些特定功能而提出需求。,add register,,2022-09-26T15:58:01Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/6
这是一个需求类型的issue，主要对象是对于mindnlp项目的multi30k数据集处理流程的新增需求。,add multi30k process,add multi30k process,2022-09-26T10:16:16Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/5
"该issue类型为用户提出需求，主要对象是名为""use action matrix""的功能。由于在内容中未提及具体的问题或需求，很难确定用户所关心的具体信息。",use action matrix,,2022-09-26T09:12:03Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/4
这个issue类型是bug报告，主要对象是Windows下的UT测试。由于某些原因导致需要关闭Windows下的UT测试，用户提出该问题以寻求相关帮助。,turn off windows ut test,,2022-09-25T16:56:46Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/3
这是一个用户提出需求类型的issue，主要对象是添加GitHub工作流。,add github workflow,,2022-09-25T10:58:21Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/2
这是一个需求提出类型的issue，主要涉及到项目中的数据集结构变更和添加4个新的数据集。可能是由于项目需要新增数据集或者对数据集结构进行调整而提出的需求。,Change module dataset structure and add 4 datasets,Change module dataset structure and add 4 datasets,2022-09-25T09:38:36Z,,closed,0,0,https://github.com/mindspore-lab/mindnlp/issues/1
