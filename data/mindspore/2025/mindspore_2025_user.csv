wangxiaoke,②	【CAAI】在我的getitem中没有MindSpore的Tensor计算，但是pynative模式下仍有报错 The pointer[top_cell_] is null,我尝试使用mindnlp下的掩码语言模型进行微调，但是在训练过程中遇到以下问题： !输入图片说明,2025-05-08T18:33:42+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC6EBZ
AIR-hl,【CAAI】 RuntimeError: The pointer[top_cell_] is null.,使用mindspore以及相关套件时，经常会在不同地方出现错误`RuntimeError: The pointer[top_cell_] is null.`，但是日志信息十分不明确，导致无法定位错误原因。 !输入图片说明,2025-05-08T18:27:18+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC6E9R
wangxiaoke,【CAAI】MindFormers中缺乏掩码语言模型的封装," 1.Describe the current behavior / 尝试手动封装掩码语言模型，但是在运行过程中遇到如下问题： Traceback (most recent call last):   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 567, in      main()   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 528, in main     _,relation_best_hit1,relation_best_hit3,relation_best_hit10,len_dataset,relation_best_mrr = trainer.train()   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 434, in train     test_loss, test_hit1, test_hit3, test_hit10, len_dataset, mrr = self.evaluate(epoch_idx, 'Test')   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 199, in evaluate     current_loss, current_hit1, current_hit3, current_hit10, current_mrr = self.model(   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\cell.py"", line 720, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\cell.py"", line 1138, in compile_and_run     self.compile(*args, **kwargs)   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\cell.py"", line 1121, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\common\api.py"", line 1840, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) TypeError:   Kernel select failed:  Select CPU operator[Gather] fail! Unsupported data type! The supported data types are input[UInt8 Int32 Int64 Int64], output[UInt8]; input[UInt16 Int32 Int64 Int64], output[UInt16]; input[UInt32 Int32 Int64 Int64], output[UInt32]; input[UInt64 Int32 Int64 Int64], output[UInt64]; input[Int8 Int32 Int64 Int64], output[Int8]; input[Int16 Int32 Int64 Int64], output[Int16]; input[Int32 Int32 Int64 Int64], output[Int32]; input[Int64 Int32 Int64 Int64], output[Int64]; input[Float16 Int32 Int64 Int64], output[Float16]; input[Float32 Int32 Int64 Int64], output[Float32]; input[Float64 Int32 Int64 Int64], output[Float64]; input[Bool Int32 Int64 Int64], output[Bool]; input[Complex64 Int32 Int64 Int64], output[Complex64]; input[Complex128 Int32 Int64 Int64], output[Complex128]; , but get input[Float32 Float32 Int64 Int64 ] and output[Float32 ]   The Function Call Stack: (For framework developers)  In file C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\layer\embedding.py:155, 33~79/            output_for_reshape = self.gather(self.embedding_table, flat_ids, 0)/ In file C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\layer\embedding.py:145~158, 4~21/    def construct(self, ids):/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:63, 21~36/        raw_embeds = self.embeddings(queries_for_embedding)/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:55~81, 4~25/    def embed_input(self, queries):/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:169, 24~40/        inputs_embeds = self.embed_input(padded_queries)/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:139~246, 4~39/    def construct(self, token_ids, x_hs, x_ts, evaluate_type, epoch, return_candidates=False):/ node: :output_for_reshape{[0]: ValueNode PrimFunc_Gather, [1]: :CNode_87{[0]: ValueNode Load, [1]: param_embeddings.embedding_table, [2]: ValueNode U}, [2]: :flat_ids{[0]: ValueNode PrimFunc_Reshape, [1]: CNode_88, [2]: ValueNode (1)}, [3]: ValueNode 0, [4]: ValueNode 0}   C++ Call Stack: (For framework developers)  mindspore\ccsrc\plugin\device\cpu\hal\hardware\cpu_device_context.cc:517 mindspore::device::cpu::CPUKernelExecutor::SetOperatorInfo",2025-05-08T18:27:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC6E9Q
looop5,dvm pynative op精度对齐,,2025-05-08T15:49:40+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC6BM2
yangzhenzhang,解决reduceall分布式算子在axis=None时报错的问题,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any. ReduceAll算子，允许axis=None，它等价于axis={}，分布式算子未适配axis=None的场景，需适配  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed 如果axis未获取到值，且输出shape为空，则认为它的axis={},2025-05-08T10:46:04+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC67AF
caifubi,合并Tensor/BaseTensor,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-05-07T17:31:40+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC62YM
Tomahawkd,【文档】mindspore CANN 错误码参考文档无法被搜索," 1. 【Document Link】/【文档链接】 无文档链接 2. 【Issues Section】/【问题文档片段】 mindspore 运行报错时提示： ``` Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) ``` !输入图片说明 3. 【Existing Issues】/【存在的问题】 根据说明搜索文档，无法搜索到对应文档信息 4. 【Expected Result】【预期结果】 可以搜索到对应文档信息，且应为搜索结果第一位",2025-05-06T10:58:42+08:00,"www,foruda,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC5LVM,cann层面爆出的错误码通常在昇腾文档里搜索查看的，可以在搜索页直接输入错误码进行搜索： https://www.hiascend.com/zh/document !输入图片说明 !输入图片说明
虞良斌,Fix the bug of sorting step ids by time,,2025-05-06T09:58:28+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC5KMZ
黄晶晶,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/parallel/mindspore.parallel.Layout.htmlmindspore.parallel.Layout 2. 【Issues Section】/【问题文档片段】 > print(layout0.to_dict()) 3. 【Existing Issues】/【存在的问题】 rank_list打印出错，有两个1 !输入图片说明 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-05-06T09:54:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC5KJC
majun-bot,CVE20223786,"一、漏洞信息 漏洞编号：CVE20223786 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A buffer overrun can be triggered in X.509 certificate verification, specifically in name constraint checking. Note that this occurs after certificate chain signature verification and requires either a CA to have signed a malicious certificate or for an application to continue certificate verification despite failure to construct a path to a trusted issuer. An attacker can craft a malicious email address in a certificate to overflow an arbitrary number of bytes containing the `.' character (decimal 46) on the stack. This buffer overflow could result in a crash (causing a denial of service). In a TLS client, this can be triggered by connecting to a malicious server. In a TLS server, this can be triggered if the server requests client authentication and a malicious client connects. 漏洞公开时间：20221102 02:15:11 漏洞创建时间：20250506 01:45:35 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20223786 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:45:36+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J94,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20233817,"一、漏洞信息 漏洞编号：CVE20233817 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 5.3 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L 漏洞简述： Issue summary: Checking excessively long DH keys or parameters may be very slow. Impact summary: Applications that use the functions DH_check(), DH_check_ex() or EVP_PKEY_param_check() to check a DH key or DH parameters may experience long delays. Where the key or parameters that are being checked have been obtained from an untrusted source this may lead to a Denial of Service. The function DH_check() performs various checks on DH parameters. After fixing CVE20233446 it was discovered that a large q parameter value can also trigger an overly long computation during some of these checks. A correct q value, if present, cannot be larger than the modulus p parameter, thus it is unnecessary to perform these checks if q is larger than p. An application that calls DH_check() and supplies a key or parameters obtained from an untrusted source could be vulnerable to a Denial of Service attack. The function DH_check() is itself called by a number of other OpenSSL functions. An application calling any of those other functions may similarly be affected. The other functions affected by this are DH_check_ex() and EVP_PKEY_param_check(). Also vulnerable are the OpenSSL dhparam and pkeyparam command line applications when using the ""check"" option. The OpenSSL SSL/TLS implementation is not affected by this issue. The OpenSSL 3.0 and 3.1 FIPS providers are not affected by this issue. 漏洞公开时间：20230801 00:15:10 漏洞创建时间：20250506 01:41:13 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20233817 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:41:14+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J93,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20230464,"一、漏洞信息 漏洞编号：CVE20230464 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A security vulnerability has been identified in all supported versions of OpenSSL related to the verification of X.509 certificate chains that include policy constraints.  Attackers may be able to exploit this vulnerability by creating a malicious certificate chain that triggers exponential use of computational resources, leading to a denialofservice (DoS) attack on affected systems. Policy processing is disabled by default but can be enabled by passing the `policy' argument to the command line utilities or by calling the `X509_VERIFY_PARAM_set1_policies()' function. 漏洞公开时间：20230323 01:15:13 漏洞创建时间：20250506 01:38:57 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20230464 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:38:57+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J92,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20230215,"一、漏洞信息 漏洞编号：CVE20230215 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： The public API function BIO_new_NDEF is a helper function used for streaming ASN.1 data via a BIO. It is primarily used internally to OpenSSL to support the SMIME, CMS and PKCS7 streaming capabilities, but may also be called directly by end user applications. The function receives a BIO from the caller, prepends a new BIO_f_asn1 filter BIO onto the front of it to form a BIO chain, and then returns the new head of the BIO chain to the caller. Under certain conditions, for example if a CMS recipient public key is invalid, the new filter BIO is freed and the function returns a NULL result indicating a failure. However, in this case, the BIO chain is not properly cleaned up and the BIO passed by the caller still retains internal pointers to the previously freed filter BIO. If the caller then goes on to call BIO_pop() on the BIO then a useafterfree will occur. This will most likely result in a crash. This scenario occurs directly in the internal function B64_write_ASN1() which may cause BIO_new_NDEF() to be called and will subsequently call BIO_pop() on the BIO. This internal function is in turn called by the public API functions PEM_write_bio_ASN1_stream, PEM_write_bio_CMS_stream, PEM_write_bio_PKCS7_stream, SMIME_write_ASN1, SMIME_write_CMS and SMIME_write_PKCS7. Other public API functions that may be impacted by this include i2d_ASN1_bio_stream, BIO_new_CMS, BIO_new_PKCS7, i2d_CMS_bio_stream and i2d_PKCS7_bio_stream. The OpenSSL cms and smime command line applications are similarly affected. 漏洞公开时间：20230209 04:15:24 漏洞创建时间：20250506 01:38:39 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20230215 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:38:40+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J91,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20230217,"一、漏洞信息 漏洞编号：CVE20230217 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： An invalid pointer dereference on read can be triggered when an application tries to check a malformed DSA public key by the EVP_PKEY_public_check() function. This will most likely lead to an application crash. This function can be called on public keys supplied from untrusted sources which could allow an attacker to cause a denial of service attack. The TLS implementation in OpenSSL does not call this function but applications might call the function if there are additional security requirements imposed by standards such as FIPS 1403. 漏洞公开时间：20230209 04:15:24 漏洞创建时间：20250506 01:38:35 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20230217 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:38:36+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J90,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20224450,"一、漏洞信息 漏洞编号：CVE20224450 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： The function PEM_read_bio_ex() reads a PEM file from a BIO and parses and decodes the ""name"" (e.g. ""CERTIFICATE""), any header data and the payload data. If the function succeeds then the ""name_out"", ""header"" and ""data"" arguments are populated with pointers to buffers containing the relevant decoded data. The caller is responsible for freeing those buffers. It is possible to construct a PEM file that results in 0 bytes of payload data. In this case PEM_read_bio_ex() will return a failure code but will populate the header argument with a pointer to a buffer that has already been freed. If the caller also frees this buffer then a double free will occur. This will most likely lead to a crash. This could be exploited by an attacker who has the ability to supply malicious PEM files for parsing to achieve a denial of service attack. The functions PEM_read_bio() and PEM_read() are simple wrappers around PEM_read_bio_ex() and therefore these functions are also directly affected. These functions are also called indirectly by a number of other OpenSSL functions including PEM_X509_INFO_read_bio_ex() and SSL_CTX_use_serverinfo_file() which are also vulnerable. Some OpenSSL internal uses of these functions are not vulnerable because the caller does not free the header argument if PEM_read_bio_ex() returns a failure code. These locations include the PEM_read_bio_TYPE() functions as well as the decoders introduced in OpenSSL 3.0. The OpenSSL asn1parse command line application is also impacted by this issue. 漏洞公开时间：20230209 04:15:23 漏洞创建时间：20250506 01:38:17 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20224450 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:38:17+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J8Z,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20230401,"一、漏洞信息 漏洞编号：CVE20230401 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A NULL pointer can be dereferenced when signatures are being verified on PKCS7 signed or signedAndEnveloped data. In case the hash algorithm used for the signature is known to the OpenSSL library but the implementation of the hash algorithm is not available the digest initialization will fail. There is a missing check for the return value from the initialization function which later leads to invalid usage of the digest API most likely leading to a crash. The unavailability of an algorithm can be caused by using FIPS enabled configuration of providers or more commonly by not loading the legacy provider. PKCS7 data is processed by the SMIME library calls and also by the time stamp (TS) library calls. The TLS implementation in OpenSSL does not call these functions however third party applications would be affected if they call these functions to verify signatures on untrusted data. 漏洞公开时间：20230209 04:15:24 漏洞创建时间：20250506 01:38:11 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20230401 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:38:12+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J8Y,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20230216,"一、漏洞信息 漏洞编号：CVE20230216 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： An invalid pointer dereference on read can be triggered when an application tries to load malformed PKCS7 data with the d2i_PKCS7(), d2i_PKCS7_bio() or d2i_PKCS7_fp() functions. The result of the dereference is an application crash which could lead to a denial of service attack. The TLS implementation in OpenSSL does not call this function however third party applications might call these functions on untrusted data. 漏洞公开时间：20230209 04:15:24 漏洞创建时间：20250506 01:38:08 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20230216 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:38:08+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J8X,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20232650,"一、漏洞信息 漏洞编号：CVE20232650 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 漏洞简述： Issue summary: Processing some specially crafted ASN.1 object identifiers or data containing them may be very slow. Impact summary: Applications that use OBJ_obj2txt() directly, or use any of the OpenSSL subsystems OCSP, PKCS7/SMIME, CMS, CMP/CRMF or TS with no message size limit may experience notable to very long delays when processing those messages, which may lead to a Denial of Service. An OBJECT IDENTIFIER is composed of a series of numbers  subidentifiers  most of which have no size limit.  OBJ_obj2txt() may be used to translate an ASN.1 OBJECT IDENTIFIER given in DER encoding form (using the OpenSSL type ASN1_OBJECT) to its canonical numeric text form, which are the subidentifiers of the OBJECT IDENTIFIER in decimal form, separated by periods. When one of the subidentifiers in the OBJECT IDENTIFIER is very large (these are sizes that are seen as absurdly large, taking up tens or hundreds of KiBs), the translation to a decimal number in text may take a very long time.  The time complexity is O(n^2) with 'n' being the size of the subidentifiers in bytes (*). With OpenSSL 3.0, support to fetch cryptographic algorithms using names / identifiers in string form was introduced.  This includes using OBJECT IDENTIFIERs in canonical numeric text form as identifiers for fetching algorithms. Such OBJECT IDENTIFIERs may be received through the ASN.1 structure AlgorithmIdentifier, which is commonly used in multiple protocols to specify what cryptographic algorithm should be used to sign or verify, encrypt or decrypt, or digest passed data. Applications that call OBJ_obj2txt() directly with untrusted data are affected, with any version of OpenSSL.  If the use is for the mere purpose of display, the severity is considered low. In OpenSSL 3.0 and newer, this affects the subsystems OCSP, PKCS7/SMIME, CMS, CMP/CRMF or TS.  It also impacts anything that processes X.509 certificates, including simple things like verifying its signature. The impact on TLS is relatively low, because all versions of OpenSSL have a 100KiB limit on the peer's certificate chain.  Additionally, this only impacts clients, or servers that have explicitly enabled client authentication. In OpenSSL 1.1.1 and 1.0.2, this only affects displaying diverse objects, such as X.509 certificates.  This is assumed to not happen in such a way that it would cause a Denial of Service, so these versions are considered not affected by this issue in such a way that it would be cause for concern, and the severity is therefore considered low. 漏洞公开时间：20230530 22:15:09 漏洞创建时间：20250503 00:24:58 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20232650 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-03T00:24:58+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5DBO,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：googletest, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.8.1 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:50 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:50+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC58WH,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：opencv, https://gitee.com/mindspore/mindspore 漏洞归属的版本：4.5.2 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:44 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:45+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58WG,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：abseilcpp, https://gitee.com/mindspore/mindspore 漏洞归属的版本：2.0210324e+07 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:41 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:42+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58WF,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：icu, https://gitee.com/mindspore/mindspore 漏洞归属的版本：69.1 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:36 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:36+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58WE,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：tinyxml2, https://gitee.com/mindspore/mindspore 漏洞归属的版本：8.0.0 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:32 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:32+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58WD,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：re2, https://gitee.com/mindspore/mindspore 漏洞归属的版本：20191201 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:28 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:28+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58WC,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：grpc, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.36.1 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:20 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:21+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58WB,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：cares, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1_19_1 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:13 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:14+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58W8,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：glog, https://gitee.com/mindspore/mindspore 漏洞归属的版本：0.4.0 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:10 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:11+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC58W6,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：jemalloc, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.3.0 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:02:00 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:02:01+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58W4,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：sqlite, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.36.0 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:01:53 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:01:54+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58W3,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：openmpi, https://gitee.com/mindspore/mindspore 漏洞归属的版本：4.1.4 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:01:43 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:01:44+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC58VY,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：pybind11, https://gitee.com/mindspore/mindspore 漏洞归属的版本：>= 2.4.3 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:01:35 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:01:35+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58VW,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：libjpegturbo, https://gitee.com/mindspore/mindspore 漏洞归属的版本：2.0.4 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:01:32 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:01:32+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58VU,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：zlib, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.2.11 CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:01:20 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:01:21+08:00,"CVE/UNFIXED,gitee",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IC58VO,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,上游推送出现bug，多创建了很多同样的漏洞单。
majun-bot,CVE202530898,"一、漏洞信息 漏洞编号：CVE202530898 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:C/C:L/I:L/A:L 漏洞简述： Improper Neutralization of Input During Web Page Generation ('Crosssite Scripting') vulnerability in Mahdi Yousefi [MahdiY] افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری) allows Stored XSS. This issue affects افزونه حمل و نقل ووکامرس (پست پیشتاز و سفارشی، پیک موتوری): from n/a through 4.2.3. 漏洞公开时间：20250327 19:15:50 漏洞创建时间：20250430 18:01:07 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202530898 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-30T18:01:08+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC58VM,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
zhanghanLeo,MoeInitRoutingQuantV2 support, **粗体** ,2025-04-30T09:51:02+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC52IX
majun-bot,CVE20224304,"一、漏洞信息 漏洞编号：CVE20224304 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 5.9 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:N 漏洞简述： A timing based side channel exists in the OpenSSL RSA Decryption implementation which could be sufficient to recover a plaintext across a network in a Bleichenbacher style attack. To achieve a successful decryption an attacker would have to be able to send a very large number of trial messages for decryption. The vulnerability affects all RSA padding modes: PKCS1 v1.5, RSAOEAP and RSASVE. For example, in a TLS connection, RSA is commonly used by a client to send an encrypted premaster secret to the server. An attacker that had observed a genuine connection between a client and a server could use this flaw to send trial messages to the server and record the time taken to process them. After a sufficiently large number of messages the attacker could recover the premaster secret used for the original connection and thus be able to decrypt the application data sent over that connection. 漏洞公开时间：20230209 04:15:23 漏洞创建时间：20250429 23:12:16 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20224304 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-29T23:12:16+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC51FL,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20230286,"一、漏洞信息 漏洞编号：CVE20230286 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.4 High &emsp;Vector： CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:N/A:H 漏洞简述： There is a type confusion vulnerability relating to X.400 address processing inside an X.509 GeneralName. X.400 addresses were parsed as an ASN1_STRING but the public structure definition for GENERAL_NAME incorrectly specified the type of the x400Address field as ASN1_TYPE. This field is subsequently interpreted by the OpenSSL function GENERAL_NAME_cmp as an ASN1_TYPE rather than an ASN1_STRING. When CRL checking is enabled (i.e. the application sets the X509_V_FLAG_CRL_CHECK flag), this vulnerability may allow an attacker to pass arbitrary pointers to a memcmp call, enabling them to read memory contents or enact a denial of service. In most cases, the attack requires the attacker to provide both the certificate chain and CRL, neither of which need to have a valid signature. If the attacker only controls one of these inputs, the other input must already contain an X.400 address as a CRL distribution point, which is uncommon. As such, this vulnerability is most likely to only affect applications which have implemented their own functionality for retrieving CRLs over a network. 漏洞公开时间：20230209 04:15:24 漏洞创建时间：20250429 23:12:11 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20230286 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-29T23:12:11+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC51FK,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
zhanghanLeo,clean code,,2025-04-29T17:27:08+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4ZDR
wuweikang,parallel codecheck,,2025-04-28T20:56:46+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4QUR
hbhdlxx08,权重量化转化工具转换操作，无法找到 hool.json 文件,"1.问题现象截图： !输入图片说明 !输入图片说明 2.操作指引： bash convert_quant_weight.sh src /data/QwQ32B/ dst /data/QwQ32Bw8a8/ type qwen_w8a8 3.硬件信息：910B1 https://gitee.com/ascend/msit/tree/master/msmodelslim 量化操作 4.详细报错 FileNotFoundError: The file is expected to exist, but it does not.   Please check the input path: /usr/local/Ascent/atbmodels/examples/models/gwenn/examples/convert/model_slim/hool.json",2025-04-28T19:54:00+08:00,"www,gitee",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC4QG6,hool.json文件？是不是应该hccl.json? 看你提供的那个码云链接，这里的量化转换好像不是mindspore框架这边的，是用了昇腾直接提供的一些工具，昇腾工具的相关问题可以直接去昇腾论坛的cann板块提问： https://www.hiascend.com/forum/forum01061013859211750041.html?filterCondition=1&topicClassId=0607101389987648003 或者如果用了上面码云仓库的相关工具，可以直接在上述码云仓库的issue里提问： https://gitee.com/ascend/msit/tree/master/msmodelslim 那边应该有专门负责这块的研发团队来解答问题
zhangyinxia,tcp_store接口设置key在1G左右会core,"   Describe the current behavior / 问题描述 (Mandatory / 必填) tcp_store接口设置key在1G左右会core ` def test_tcp_store_004():     this_rank = get_rank()     store = TCPStore()     if this_rank == 0:         store.set('A' * 1024 * 1024 * 1024, 'B' * 1024 * 1024 * 1024)     barrier()     out_get_key_3 = store.get('A' * 1024 * 1024 * 1024)     assert out_get_key_3 == b'B' * 1024 * 1024 * 1024 `  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-27T15:55:06+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4DB3
hbhdlxx08,mindie跑GLM4ms一直显示The meta server node can not be finalized because there are still 2 alive nodes.,1.问题现象截图： !输入图片说明 执行bash run_mindie.sh modelname GLMZ132B0414 modelpath /data/GLMZ132B0414 maxprefillbatchsize 4会出现该现象 2.操作指引： https://mp.weixin.qq.com/s/VBrsu6r3GM8nxMe5XK93YA 3.硬件信息：910B1 4.docker镜像：swr.cncentral221.ovaijisuan.com/mindformers/mindspore_glm_z1:20250414,2025-04-27T14:56:40+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC4C86,可能是进程没杀干净，请清空缓存再试
花园宝宝,模型训练报错," ===============================================================================================  The following shows the last analyze fail log message.  ===============================================================================================   Caught exception:  OSError: Mindspore can not compile temporary source code in terminal. Please write source code to a python file and run the file. At:   mindspore\_extends\parse\parser.py(1232): parse   mindspore\common\api.py(737): compile   mindspore\common\api.py(625): __call__   mindspore\common\api.py(190): wrapper   mindspore\common\api.py(1016): staging_specialize   mindspore\nn\cell.py(743): __call__   paddle2ms_onenet.py(350): _train_epoch   paddle2ms_onenet.py(266): train   main.py(54): train   flask\app.py(902): dispatch_request   flask\app.py(917): full_dispatch_request   flask\app.py(1511): wsgi_app   flask\app.py(1536): __call__   gevent\pywsgi.py(1053): run_application   gevent\pywsgi.py(1107): handle_one_response   gevent\pywsgi.py(804): handle_one_request   gevent\pywsgi.py(574): handle   gevent\pywsgi.py(1700): handle   gevent\baseserver.py(34): _handle_and_close_when_done   The Traceback of Net Construct Code:   ===============================================================================================  The following shows the IR when the function graphs evaluation fails to help locate the problem.  You can search the last > to the node which is evaluated failure.  Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.ir to get more instructions.  ===============================================================================================  IR entry:   Total subgraphs: 0  Total params: 1  Params: %para1_args0:  subgraph attr: subgraph instance: mindspore_nn_optim_adam_Adam_construct_2 : 000001F87EB31120 subgraph () { > 0   %0(CNode_3) = resolve(NameSpace[Entry: 'mindspore.nn.optim.adam.Adam.construct'], mindspore.nn.optim.adam.Adam.construct)       : (, ) > ()       scope: (Default)   %1(CNode_4) = MakeTuple(%para1_args0)       : () > ()       scope: (Default)   %2(CNode_5) = MakeTuple()       scope: (Default)   %3(CNode_6) = MakeTuple()       scope: (Default)   %4(CNode_7) = make_dict(%2, %3)       : (, ) > ()       scope: (Default)   %5(CNode_8) = DoUnpackCall(%0, %1, %4)       : (, , ) > ()       scope: (Default)   Return(%5)       : ()       scope: (Default) }  Order:    1: :CNode_3{[0]: ValueNode resolve, [1]: ValueNode Entry: 'mindspore.nn.optim.adam.Adam.construct', [2]: ValueNode mindspore.nn.optim.adam.Adam.construct}    2: :CNode_8{[0]: ValueNode DoUnpackCall, [1]: CNode_3, [2]: CNode_4, [3]: CNode_7}    3: :CNode_9{[0]: ValueNode Return, [1]: CNode_8}  ===============================================================================================  The total of function graphs in evaluation stack: 1  ===============================================================================================  ===============================================================================================  The rest function graphs are the following:  =============================================================================================== No more function graphs. }执行训练时报错，返回的analyze_fail.ir文件内容如上，这个怎么解决，用try捕捉异常报的是 编译时报错“could not get source code”以及“Mindspore can not compile temporary source code in terminal. Please write source code to a python file and run the file.”",2025-04-27T14:35:52+08:00,"foruda,foruda",open,0,5,https://gitee.com/mindspore/mindspore/issues/IC4BQM,能否提供下具体的环境信息，mindspore版本，代码运行方式等等，以及运行出错的代码，不然不好定位具体问题； 这个错误提示在几年前的旧版本上看到过，新版本很久没看到了，如果用的是旧版本的话，建议安装下最新的版本试试；," 虚拟环境的库  flask == 3.1.0 mindspore == 2.5.0 numpy == 1.26.4 redis == 5.2.1 gevent == 24.11.1 pyinstaller == 6.13.0 在笔记本的cpu环境下运行  代码训练在VScode或者终端通过python train.py都可以执行 具体报错是使用pyinstaller打包为exe后出现，打包后貌似只能执行预测，训练模型就会出现上面的错误  代码出错的位置 ```python for data in dataset:                 _, grads = grad_fn(*data)                 optimizer(grads) ``` 这里我的optimizer是Adam",感觉不是mindspore的问题，像是打包过程中缺少了什么。麻烦问一下之前旧版本中出现这个报错如果不更新版本要怎么解决，谢谢啦,应该是和python打包有关，好像目前确实没法解决； 刚翻了下群聊记录，之前也是有人尝试打包然后然后和你一样，推理能运行，训练就不行，没看到后续反馈如何解决的，但提到有可能是打包过程中有些文件没有打包进去导致的，可以尝试下这方面的思路，我记得pyInstaller可以通过adddata参数添加MindSpore的动态链接库及配置文件的； 这是2023年的时候有人反馈的了： !输入图片说明 !输入图片说明,好的，我再尝试尝试，谢谢啦
张泰来,mindspore.mint.logical_xor算子反向传播未定义," 1.问题描述 mindspore.mint.logical_xor接口不支持反向传播   2.环境信息  **硬件环境**:   3.重现步骤  (1) 测试代码 ```python import torch import mindspore as ms import numpy as np from mindspore import value_and_grad import pytest from mindspore import ops .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_forward_backward(mode):     """"""     (2) 测试两个框架的正向推理结果和反向梯度精度差异     """"""     ms.set_context(mode=mode, device_target='Ascend')     data_lst1 = [[1.1, 1.2, 1.3, 1.4], [1.5, 1.6, 1.7, 1.8]]     data_lst2 = [[1.1, 0, 1.3, 0], [0, 1.6, 0, 1.8]]     input_ms1 = ms.tensor(data_lst1, dtype=ms.float64)     input_ms2 = ms.tensor(data_lst2, dtype=ms.float64)     input_pt1 = torch.tensor(data_lst1, dtype=torch.float64, requires_grad=True)     input_pt2 = torch.tensor(data_lst2, dtype=torch.float64, requires_grad=True)     def func_pt(x, y):         output1 = x * torch.logical_xor(x, y)         return output1.sum()     def func_ms(x, y):         output1 = x * ms.mint.logical_xor(x, y)         return output1.sum()     output_pt = func_pt(input_pt1, input_pt2)     output_pt.backward()     gradient_pt1 = input_pt1.grad     gradient_pt2 = input_pt2.grad     grad_func = value_and_grad(func_ms, grad_position=(0,1))     output_ms, gradient_ms = grad_func(input_ms1, input_ms2)     gradient_ms1 = gradient_ms[0]     gradient_ms2 = gradient_ms[1]      print(""output:"", output_pt, output_ms)      print(""gradient"", gradient_pt1, gradient_ms)     assert np.allclose(output_ms.numpy(), output_pt.detach().numpy(), rtol=1e3)     assert np.allclose(gradient_pt1.numpy(), gradient_ms1.numpy(), rtol=1e3)     assert np.allclose(gradient_pt2.numpy(), gradient_ms2.numpy(), rtol=1e3) ``` 将以上代码保存为test_logical_xor.py文件 （2）执行代码 在终端内进入test_logical_xor.py所在的目录下，输入pytest sv test_logical_xor.py命令即可查看测试结果  4.预期结果 > **【预期结果】**：使用了mindspore.mint.logical_xor接口的函数可以正常进行反向传播，且函数的反向传播的梯度与pytorch框架下对应的反向传播梯度的相对误差小于1e3  5.报错信息展示 完整报错信息如下： ```python ______________________________________________________________________________ test_forward_backward[0] ______________________________________________________________________________ mode = 0     .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE])     def test_forward_backward(mode):         """"""         (2) 测试两个框架的正向推理结果和反向梯度精度差异         """"""         ms.set_context(mode=mode, device_target='Ascend')         data_lst1 = [[1.1, 1.2, 1.3, 1.4], [1.5, 1.6, 1.7, 1.8]]         data_lst2 = [[1.1, 0, 1.3, 0], [0, 1.6, 0, 1.8]]         input_ms1 = ms.tensor(data_lst1, dtype=ms.float64)         input_ms2 = ms.tensor(data_lst2, dtype=ms.float64)         input_pt1 = torch.tensor(data_lst1, dtype=torch.float64, requires_grad=True)         input_pt2 = torch.tensor(data_lst2, dtype=torch.float64, requires_grad=True)         def func_pt(x, y):             output1 = x * torch.logical_xor(x, y)             return output1.sum()         def func_ms(x, y):             output1 = x * ms.mint.logical_xor(x, y)             return output1.sum()         output_pt = func_pt(input_pt1, input_pt2)         output_pt.backward()         gradient_pt1 = input_pt1.grad         gradient_pt2 = input_pt2.grad         grad_func = value_and_grad(func_ms, grad_position=(0,1)) >       output_ms, gradient_ms = grad_func(input_ms1, input_ms2) test_logical_xor.py:309:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:960: in staging_specialize     out = _MindsporeFunctionExecutor(func, hash_obj, dyn_args, process_obj, jit_config)(*args, **kwargs) ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:188: in wrapper     results = fn(*arg, **kwargs) ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:582: in __call__     raise err ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:579: in __call__     phase = self.compile(self.fn.__name__, *args_list, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = , method_name = 'after_grad' args = (Tensor(shape=[2, 4], dtype=Float64, value= [[ 1.10000000e+00,  1.20000000e+00,  1.30000000e+00,  1.40000000e+00],  [ ...000000e+00,  1.30000000e+00,  0.00000000e+00],  [ 0.00000000e+00,  1.60000000e+00,  0.00000000e+00,  1.80000000e+00]])) kwargs = {} compile_args = (Tensor(shape=[2, 4], dtype=Float64, value= [[ 1.10000000e+00,  1.20000000e+00,  1.30000000e+00,  1.40000000e+00],  [ ...000000e+00,  1.30000000e+00,  0.00000000e+00],  [ 0.00000000e+00,  1.60000000e+00,  0.00000000e+00,  1.80000000e+00]])) key_id = '1876507875570161745726118521118976' generate_name = 'mindspore.ops.composite.base.after_grad./home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py.599.1745726118521118976' echo_function_name = 'function ""after_grad"" at the file ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 599' full_function_name = 'mindspore.ops.composite.base.after_grad./home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py.599' create_time = '1745726118521118976', key = 0, parameter_ids = '' phase = 'mindspore.ops.composite.base.after_grad./home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py.599.1745726118521118976.0' jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...}     def compile(self, method_name, *args, **kwargs):         """"""Returns pipeline for the given args.""""""          Check whether hook function registered on Cell object.         if self.obj and hasattr(self.obj, ""_hook_fn_registered""):             if self.obj._hook_fn_registered():                 logger.warning(f""For 'Cell', it's not support hook function when using 'jit' decorator. ""                                f""If you want to use hook function, please use context.set_context to set ""                                f""pynative mode and remove 'jit' decorator."")          Chose dynamic shape tensors or actual input tensors as compile args.         compile_args = self._generate_compile_args(args)         key_id = self._get_key_id()         compile_args = get_auto_dynamic_shape_args_with_check_input_signature(compile_args, key_id,                                                                               self.input_signature)          Restore the mutable attr for every arg.         compile_args = _restore_mutable_attr(args, compile_args)         self._compile_args = compile_args         generate_name, echo_function_name = self._get_generate_name()          The full Function name         full_function_name = generate_name         create_time = ''          Add key with obj         if self.obj is not None:             if self.obj.__module__ != self.fn.__module__:                 logger.info(                     f'The module of `self.obj`: `{self.obj.__module__}` is not same with the module of `self.fn`: '                     f'`{self.fn.__module__}`')             self.obj.__parse_method__ = method_name             if isinstance(self.obj, ms.nn.Cell):                 generate_name = generate_name + '.' + str(self.obj.create_time)                 create_time = str(self.obj.create_time)             else:                 generate_name = generate_name + '.' + str(self._create_time)                 create_time = str(self._create_time)             generate_name = generate_name + '.' + str(id(self.obj))             full_function_name = generate_name         else:              Different instance of same class may use same memory(means same obj_id) at diff times.              To avoid unexpected phase matched, add create_time to generate_name.             generate_name = generate_name + '.' + str(self._create_time)             create_time = str(self._create_time)         self.enable_tuple_broaden = False         if hasattr(self.obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = self.obj.enable_tuple_broaden         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(self.fn, compile_args, kwargs, self.enable_tuple_broaden)         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             key = str(key) + '.' + parameter_ids         phase = generate_name + '.' + str(key)         update_auto_dynamic_shape_phase_with_check_input_signature(compile_args, key_id, phase, self.input_signature)         if phase in ms_compile_cache:              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             return phase         _check_recompile(self.obj, compile_args, kwargs, full_function_name, create_time, echo_function_name)          If enable compile cache, get the dependency files list and set to graph executor.         self._set_compile_cache_dep_files()         if self.jit_config_dict:             self._graph_executor.set_jit_config(self.jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         if self.obj is None:              Set an attribute to fn as an identifier.             if isinstance(self.fn, types.MethodType):                 setattr(self.fn.__func__, ""__jit_function__"", True)             else:                 setattr(self.fn, ""__jit_function__"", True) >           is_compile = self._graph_executor.compile(self.fn, compile_args, kwargs, phase, True) E           RuntimeError: Illegal primitive: Primitive LogicalXor's bprop not defined.node:ValueNode fake_bprop, location: E            E            E            Framework Unexpected Exception Raised: E            E           This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help. E            E            E            C++ Call Stack: (For framework developers) E            E           mindspore/ccsrc/pipeline/jit/ps/validator.cc:83 ValidateOperation ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:674: RuntimeError ```  6.备注 **【定位人】** 张泰来",2025-04-27T12:01:12+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4AFQ
wuweikang,add accuracy and memory testcase for deepseek v3,,2025-04-27T11:47:34+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4A8K
zhanghanLeo,DTS2025042511021  PA error.,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-26T16:53:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC451M
majun-bot,CVE20244741,"一、漏洞信息 漏洞编号：CVE20244741 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： Issue summary: Calling the OpenSSL API function SSL_free_buffers may cause memory to be accessed that was previously freed in some situations Impact summary: A use after free can have a range of potential consequences such as the corruption of valid data, crashes or execution of arbitrary code. However, only applications that directly call the SSL_free_buffers function are affected by this issue. Applications that do not call this function are not vulnerable. Our investigations indicate that this function is rarely used by applications. The SSL_free_buffers function is used to free the internal OpenSSL buffer used when processing an incoming record from the network. The call is only expected to succeed if the buffer is not currently in use. However, two scenarios have been identified where the buffer is freed even when still in use. The first scenario occurs where a record header has been received from the network and processed by OpenSSL, but the full record body has not yet arrived. In this case calling SSL_free_buffers will succeed even though a record has only been partially processed and the buffer is still in use. The second scenario occurs where a full record containing application data has been received and processed by OpenSSL but the application has only read part of this data. Again a call to SSL_free_buffers will succeed even though the buffer is still in use. While these scenarios could occur accidentally during normal operation a malicious attacker could attempt to engineer a stituation where this occurs. We are not aware of this issue being actively exploited. The FIPS modules in 3.3, 3.2, 3.1 and 3.0 are not affected by this issue. 漏洞公开时间：20241113 19:15:04 漏洞创建时间：20250424 18:16:09 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20244741 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-24T18:16:10+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC3QNM,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
zhajiangtao2025,mindspore.mint.all 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.all 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_all.py::test_all_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_all_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 all 函数             ms_output = mint.all(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 all 函数             torch_output = torch.all(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-24T13:56:25+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M70
zhajiangtao2025,mindspore.mint.argmin 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.argmin 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_argmin.py::test_argmin_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_argmin_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 argmin 函数             ms_output = mint.argmin(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 argmin 函数             torch_output = torch.argmin(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-04-24T13:55:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M6J
zhajiangtao2025,mindspore.mint.argmax 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.argmax 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_argmax.py::test_argmax_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_argmax_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 argmax 函数             ms_output = mint.argmax(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 argmax 函数             torch_output = torch.argmax(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-04-24T13:53:48+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M5S
zhajiangtao2025,mindspore.mint.xlogy 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！精度不对齐！框架支持度不对齐！," 1.Describe the current behavior / 问题描述 > mindspore.mint.xlogy 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！精度不对齐！框架支持度不对齐！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_xlogy.py::test_xlogy_all_dtypes test_xlogy.py::test_xlogy_fixed_dtype_random_input test_xlogy.py::test_xlogy_different_input_types  4.Steps to reproduce the issue / 重现步骤  ``` ''' 1.对应Pytorch 的相应接口进行测试： a) 测试random输入不同dtype，对比两个框架的支持度 ''' .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_xlogy_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 xlogy 函数             ms_output = mint.xlogy(ms_input,ms.tensor([2.0] * len(input_data),ms_dtype))              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 xlogy 函数             torch_output = torch.xlogy(torch_input,torch.tensor([2.0] * len(input_data)))              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ''' b) 测试固定dtype，random输入值，对比两个框架输出是否相等（误差范围为小于1e3） ''' .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_xlogy_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.xlogy(ms_input,ms.tensor([2.0] * len(input_data),dtype))             torch_output = torch.xlogy(torch_input,torch.tensor([2.0] * len(input_data),dtype=torch_dtype))              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ''' c) 测试固定shape，固定输入值，不同输入参数（string/bool等类型），两个框架的支持度(测试的函数没有输入参数，因此这里测试不同的输入类型) ''' .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_xlogy_different_input_types(mode):     ms.set_context(mode=mode)      固定 shape 为 (3,)     shape = (3,)      定义不同的输入类型     input_data = [1.1, 2.5, 1.5]   基础数据     input_types = {         ""list"": input_data,   Python list         ""np.array"": np.array(input_data, dtype=np.float32),   NumPy array         ""mindspore.tensor"": ms.tensor(input_data, ms.float32),   MindSpore mindspore.tensor         ""torch.tensor"": torch.tensor(input_data, dtype=torch.float32),   PyTorch tensor         ""tuple"": tuple(input_data),   Python tuple         ""string"": ""1.1, 2.5, 1.5"",   String     }      初始化支持和不支持的列表     ms_supported_types = []     ms_unsupported_types = []     torch_supported_types = []     torch_unsupported_types = []      遍历所有输入类型     for input_name, input_value in input_types.items():         try:              测试 MindSpore             ms_output = mint.xlogy(input_value,ms.tensor([2.0] * len(input_data),ms_dtype))              shape 与预期一致             assert ms_output.shape == shape             ms_supported_types.append(input_name)         except Exception as e:             ms_unsupported_types.append(input_name)         try:              测试 PyTorch             torch_output = torch.xlogy(input_value,torch.tensor([2.0] * len(input_data)))              shape 与预期一致             assert torch_output.shape == shape             torch_supported_types.append(input_name)         except Exception as e:             torch_unsupported_types.append(input_name)      打印支持和不支持的输入类型     print(f""MindSpore supported input types: {ms_supported_types}"")     print(f""MindSpore unsupported input types: {ms_unsupported_types}"")     print(f""PyTorch supported input types: {torch_supported_types}"")     print(f""PyTorch unsupported input types: {torch_unsupported_types}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int8, mindspore.int16, mindspore.int32, mindspore.int64, mindspore.uint8, mindspore.float16, mindspore.float32, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.float64, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] MindSpore supported input types: [] MindSpore unsupported input types: ['list', 'np.array', 'mindspore.tensor', 'torch.tensor', 'tuple', 'string'] PyTorch supported input types: ['torch.tensor'] PyTorch unsupported input types: ['list', 'np.array', 'mindspore.tensor', 'tuple', 'string'] args = (.compare at 0xfffe84d65ee0>, array([0.37695312, 0.11328125,  0.02844238, 0.69140...0.69140625,  0.51171875,        0.35351562, 0.15820312, 0.6875    , 1.7734375 , 0.1328125 ],       dtype=float32)) kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=0.001, atol=0', 'verbose': True}     (func)     def inner(*args, **kwds):         with self._recreate_cm(): >           return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 6 / 10 (60%) E           Max absolute difference: 0.00390625 E           Max relative difference: 0.00763359 E            x: array([0.376953, 0.113281,  0.028442, 0.691406,  0.515625, 0.355469, E                  0.158203, 0.691406, 1.773438, 0.132812], dtype=float32) E            y: array([0.375   , 0.112793,  0.02832 , 0.691406,  0.511719, 0.353516, E                  0.158203, 0.6875  , 1.773438, 0.132812], dtype=float32) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  args = (.compare at 0xfffe84d07160>, array([0.421875  , 0.09521484,  0.6640625 ,  0.14453...0.14355469,  0.21289062,        0.7578125 , 0.609375  ,  1.2421875 , 0.5078125 ,  1.1484375 ],       dtype=float32)) kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=0.001, atol=0', 'verbose': True}     (func)     def inner(*args, **kwds):         with self._recreate_cm(): >           return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 3 / 10 (30%) E           Max absolute difference: 0.00390625 E           Max relative difference: 0.00680272 E            x: array([0.421875, 0.095215,  0.664062,  0.144531,  0.213867, 0.757812, E                  0.609375,  1.242188, 0.507812,  1.148438], dtype=float32) E            y: array([0.421875, 0.095215,  0.660156,  0.143555,  0.212891, 0.757812, E                  0.609375,  1.242188, 0.507812,  1.148438], dtype=float32) ../../anaconda3/envs/MindSpore/lib/python3.9/contextlib.py:79: AssertionError  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image !image",2025-04-24T13:51:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M4V
zhajiangtao2025,mindspore.mint.trunc 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.trunc 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_trunc.py::test_trunc_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_trunc_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 trunc 函数             ms_output = mint.trunc(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 trunc 函数             torch_output = torch.trunc(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-24T13:46:28+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M0Q
wangyibo,bugfix msadapter st_test,"   Describe the current behavior / 问题描述 (Mandatory / 必填) 因端口问题导致的通信初始化失败。  !输入图片说明  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-24T11:38:15+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC3L45
XuefengJin,教程中，tensor的样例与实际输出不一致,"window cpu版本 https://www.mindspore.cn/tutorials/zhCN/master/beginner/tensor.html 从NumPy数组生成 可以从NumPy数组创建张量。 np_array = np.array(data) x_np = Tensor(np_array) print(x_np, x_np.shape, x_np.dtype) [1 0 1 0] (4,) Int64 实际运行结果： Tensor(shape=[4], dtype=Int32, value= [1, 0, 1, 0]) (4,) Int32 数据类型不一致",2025-04-24T09:01:51+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC3IJU,之前碰到过这个情况，win上int32，然后到香橙派上变成int64，导致某一步cast走了ai cpu算子，增加了耗时，就去仔细分析了一下；最后发现，其实只是numpy库的原因，python的list里的整数数字默认都是int64类型，同样的numpy版本，在win的numpy包装list后就会自动转成int32，而linux环境的依旧是原来的int64类型，文档上的应该就是linux环境下的运行示例结果
majun-bot,CVE20233446,"一、漏洞信息 漏洞编号：CVE20233446 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： Issue summary: Checking excessively long DH keys or parameters may be very slow. Impact summary: Applications that use the functions DH_check(), DH_check_ex() or EVP_PKEY_param_check() to check a DH key or DH parameters may experience long delays. Where the key or parameters that are being checked have been obtained from an untrusted source this may lead to a Denial of Service. The function DH_check() performs various checks on DH parameters. One of those checks confirms that the modulus ('p' parameter) is not too large. Trying to use a very large modulus is slow and OpenSSL will not normally use a modulus which is over 10,000 bits in length. However the DH_check() function checks numerous aspects of the key or parameters that have been supplied. Some of those checks use the supplied modulus value even if it has already been found to be too large. An application that calls DH_check() and supplies a key or parameters obtained from an untrusted source could be vulernable to a Denial of Service attack. The function DH_check() is itself called by a number of other OpenSSL functions. An application calling any of those other functions may similarly be affected. The other functions affected by this are DH_check_ex() and EVP_PKEY_param_check(). Also vulnerable are the OpenSSL dhparam and pkeyparam command line applications when using the 'check' option. The OpenSSL SSL/TLS implementation is not affected by this issue. The OpenSSL 3.0 and 3.1 FIPS providers are not affected by this issue. 漏洞公开时间：20230719 20:15:10 漏洞创建时间：20250424 02:18:31 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20233446 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-24T02:18:31+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC3I3L,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20232975,"一、漏洞信息 漏洞编号：CVE20232975 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： Issue summary: The AESSIV cipher implementation contains a bug that causes it to ignore empty associated data entries which are unauthenticated as a consequence. Impact summary: Applications that use the AESSIV algorithm and want to authenticate empty data entries as associated data can be misled by removing, adding or reordering such empty entries as these are ignored by the OpenSSL implementation. We are currently unaware of any such applications. The AESSIV algorithm allows for authentication of multiple associated data entries along with the encryption. To authenticate empty data the application has to call EVP_EncryptUpdate() (or EVP_CipherUpdate()) with NULL pointer as the output buffer and 0 as the input buffer length. The AESSIV implementation in OpenSSL just returns success for such a call instead of performing the associated data authentication operation. The empty data thus will not be authenticated. As this issue does not affect nonempty associated data authentication and we expect it to be rare for an application to use empty associated data entries this is qualified as Low severity issue. 漏洞公开时间：20230714 20:15:09 漏洞创建时间：20250424 02:18:08 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20232975 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-24T02:18:08+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC3I3K,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20234807,"一、漏洞信息 漏洞编号：CVE20234807 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： Issue summary: The POLY1305 MAC (message authentication code) implementation contains a bug that might corrupt the internal state of applications on the Windows 64 platform when running on newer X86_64 processors supporting the AVX512IFMA instructions. Impact summary: If in an application that uses the OpenSSL library an attacker can influence whether the POLY1305 MAC algorithm is used, the application state might be corrupted with various application dependent consequences. The POLY1305 MAC (message authentication code) implementation in OpenSSL does not save the contents of nonvolatile XMM registers on Windows 64 platform when calculating the MAC of data larger than 64 bytes. Before returning to the caller all the XMM registers are set to zero rather than restoring their previous content. The vulnerable code is used only on newer x86_64 processors supporting the AVX512IFMA instructions. The consequences of this kind of internal application state corruption can be various  from no consequences, if the calling application does not depend on the contents of nonvolatile XMM registers at all, to the worst consequences, where the attacker could get complete control of the application process. However given the contents of the registers are just zeroized so the attacker cannot put arbitrary values inside, the most likely consequence, if any, would be an incorrect result of some application dependent calculations or a crash leading to a denial of service. The POLY1305 MAC algorithm is most frequently used as part of the CHACHA20POLY1305 AEAD (authenticated encryption with associated data) algorithm. The most common usage of this AEAD cipher is with TLS protocol versions 1.2 and 1.3 and a malicious client can influence whether this AEAD cipher is used by the server. This implies that server applications using OpenSSL can be potentially impacted. However we are currently not aware of any concrete application that would be affected by this issue therefore we consider this a Low severity security issue. As a workaround the AVX512IFMA instructions support can be disabled at runtime by setting the environment variable OPENSSL_ia32cap:    OPENSSL_ia32cap=:~0x200000 The FIPS provider is not affected by this issue. 漏洞公开时间：20230908 20:15:08 漏洞创建时间：20250424 02:14:23 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20234807 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-24T02:14:24+08:00,"CVE/UNFIXED,gitee",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC3I3E,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142"
zhajiangtao2025,mindspore.mint.rsqrt 静态图与动态图下，mindspore与torch精度不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.rsqrt 静态图与动态图下，mindspore与torch精度不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_rsqrt.py::test_rsqrt_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_rsqrt_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.rsqrt(ms_input)             torch_output = torch.rsqrt(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： test_rsqrt.py:112:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ args = (.compare at 0xfffe99071790>, array([      nan,       nan, 4.9375   ,       nan, 1.1...rray([    nan,     nan, 4.9375 ,     nan, 1.15625,     nan,     nan,            nan,     nan,     nan], dtype=float32)) kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=0.001, atol=0', 'verbose': True}     (func)     def inner(*args, **kwds):         with self._recreate_cm(): >           return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 1 / 10 (10%) E           Max absolute difference: 0.0078125 E           Max relative difference: 0.00675676 E            x: array([     nan,      nan, 4.9375  ,      nan, 1.164062,      nan, E                       nan,      nan,      nan,      nan], dtype=float32) E            y: array([    nan,     nan, 4.9375 ,     nan, 1.15625,     nan,     nan, E                      nan,     nan,     nan], dtype=float32) ../../anaconda3/envs/MindSpore/lib/python3.9/contextlib.py:79: AssertionError            return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 1 / 10 (10%) E           Max absolute difference: 0.0078125 E           Max relative difference: 0.004329 E            x: array([     nan,      nan, 1.023438, 2.1875  , 1.796875,      nan, E                       nan, 0.746094,      nan, 0.777344], dtype=float32) E            y: array([     nan,      nan, 1.023438, 2.1875  , 1.804688,      nan, E                       nan, 0.746094,      nan, 0.777344], dtype=float32) ../../anaconda3/envs/MindSpore/lib/python3.9/contextlib.py:79: AssertionError  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:27:41+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GTM
zhajiangtao2025,mindspore.mint.round 动态图下，mindspore与torch支持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.round 动态图下，mindspore与torch支持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_round.py::test_round_different_input_types  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_round_different_input_types(mode):     ms.set_context(mode=mode)      固定 shape 为 (3,)     shape = (3,)      定义不同的输入类型     input_data = [1.1, 2.5, 1.5]   基础数据     input_types = {         ""list"": input_data,   Python list         ""np.array"": np.array(input_data, dtype=np.float32),   NumPy array         ""mindspore.tensor"": ms.tensor(input_data, ms.float32),   MindSpore mindspore.tensor         ""torch.tensor"": torch.tensor(input_data, dtype=torch.float32),   PyTorch tensor         ""tuple"": tuple(input_data),   Python tuple         ""string"": ""1.1, 2.5, 1.5"",   String     }      初始化支持和不支持的列表     ms_supported_types = []     ms_unsupported_types = []     torch_supported_types = []     torch_unsupported_types = []      遍历所有输入类型     for input_name, input_value in input_types.items():         try:              测试 MindSpore             ms_output = mint.round(input_value)              shape 与预期一致             assert ms_output.shape == shape             ms_supported_types.append(input_name)         except Exception as e:             ms_unsupported_types.append(input_name)         try:              测试 PyTorch             torch_output = torch.round(input_value)              shape 与预期一致             assert torch_output.shape == shape             torch_supported_types.append(input_name)         except Exception as e:             torch_unsupported_types.append(input_name)      打印支持和不支持的输入类型     print(f""MindSpore supported input types: {ms_supported_types}"")     print(f""MindSpore unsupported input types: {ms_unsupported_types}"")     print(f""PyTorch supported input types: {torch_supported_types}"")     print(f""PyTorch unsupported input types: {torch_unsupported_types}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：.MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:24:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GTA
zhajiangtao2025,mindspore.mint.roll mindspore与torch⽀持的支持度不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.roll mindspore与torch⽀持的支持度不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_roll.py::test_roll_different_input_types  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_roll_different_input_types(mode):     ms.set_context(mode=mode)      固定 shape 为 (3,)     shape = (3,)      定义不同的输入类型     input_data = [1.1, 2.5, 1.5]   基础数据     input_types = {         ""list"": input_data,   Python list         ""np.array"": np.array(input_data, dtype=np.float32),   NumPy array         ""mindspore.tensor"": ms.tensor(input_data, ms.float32),   MindSpore mindspore.tensor         ""torch.tensor"": torch.tensor(input_data, dtype=torch.float32),   PyTorch tensor         ""tuple"": tuple(input_data),   Python tuple         ""string"": ""1.1, 2.5, 1.5"",   String     }      初始化支持和不支持的列表     ms_supported_types = []     ms_unsupported_types = []     torch_supported_types = []     torch_unsupported_types = []      遍历所有输入类型     for input_name, input_value in input_types.items():         try:              测试 MindSpore             ms_output = mint.roll(input_value,shifts=0)              shape 与预期一致             assert ms_output.shape == shape             ms_supported_types.append(input_name)         except Exception as e:             ms_unsupported_types.append(input_name)         try:              测试 PyTorch             torch_output = torch.roll(inputvalue,shifts=0)              shape 与预期一致             assert torch_output.shape == shape             torch_supported_types.append(input_name)         except Exception as e:             torch_unsupported_types.append(input_name)      打印支持和不支持的输入类型     print(f""MindSpore supported input types: {ms_supported_types}"")     print(f""MindSpore unsupported input types: {ms_unsupported_types}"")     print(f""PyTorch supported input types: {torch_supported_types}"")     print(f""PyTorch unsupported input types: {torch_unsupported_types}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： .MindSpore supported input types: ['mindspore.tensor'] MindSpore unsupported input types: ['list', 'np.array', 'torch.tensor', 'tuple', 'string'] PyTorch supported input types: [] PyTorch unsupported input types: ['list', 'np.array', 'mindspore.tensor', 'torch.tensor', 'tuple', 'string']  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:17:16+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GRS
zhajiangtao2025,mindspore.mint.roll 静态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.roll 静态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_roll.py::test_roll_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_roll_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 roll 函数             ms_output = mint.roll(ms_input,shifts=0)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 roll 函数             torch_output = torch.roll(torch_input,shifts=0)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int8, mindspore.int32, mindspore.int64, mindspore.uint8, mindspore.float16, mindspore.float32, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int16, mindspore.float64, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.complex64, torch.complex128] PyTorch unsupported dtypes: []  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:11:51+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GQX
zhajiangtao2025,mindspore.mint.remainder 静态图推理测试时报RuntimeError," 1.Describe the current behavior / 问题描述 > mindspore.mint.remainder 静态图推理测试时报 FAILED test_remainder.py::test_forward_backward[0]  RuntimeError: Compile graph kernel_graph0 failed.  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_remainder.py::test_forward_backward  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_forward_backward(mode):     ms.set_context(mode=mode)     class SimpleModel(nn.Module):         def __init__(self):             super(SimpleModel, self).__init__()             self.linear = nn.Linear(3, 3)   输入维度为3，输出维度也为3         def forward(self, x):             return torch.remainder(self.linear(x),2.0)     class SimpleModelMS(mnn.Cell):         def __init__(self):             super(SimpleModelMS, self).__init__()             self.linear = mnn.Dense(3, 3)   输入维度为3，输出维度也为3         def construct(self, x):             return  mint.remainder(self.linear(x),2.0)      创建固定输入和权重     input_data_np = np.array([[1.5, 2.3, 3.6], [1.2, 0.4, 0.9]], dtype=np.float32)     weight_np = np.random.randn(3, 3).astype(np.float32)     bias_np = np.random.randn(3).astype(np.float32)      PyTorch模型设置     model_torch = SimpleModel()     model_torch.linear.weight.data = torch.tensor(weight_np)       model_torch.linear.bias.data = torch.tensor(bias_np)     input_torch = torch.tensor(input_data_np, requires_grad=True)      MindSpore模型设置     model_ms = SimpleModelMS()     model_ms.linear.weight.set_data(Tensor(weight_np))   不需要转置     model_ms.linear.bias.set_data(Tensor(bias_np))     input_ms = Tensor(input_data_np, dtype=ms.float32)      正向传播     output_torch = model_torch(input_torch)     output_ms = model_ms(input_ms).asnumpy()      比较正向传播结果     diff = np.abs(output_torch.detach().numpy()  output_ms)     if np.all(diff  **【预期结果】**：FAILED test_remainder.py::test_forward_backward[0]  RuntimeError: Compile graph kernel_graph0 failed.  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image !image  ",2025-04-23T19:04:33+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GQ1
emf,transformer案例训练报错,环境：启智社区910 B2，CANN8，ms2.5.0镜像 训练报错 !输入图片说明,2025-04-23T16:30:36+08:00,"foruda,ms-release,pypi",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC3EEF,使用启智910b环境的cann8_0_0beta_mindspore2_5镜像运行，主要有以下几个问题： 1.由于是notebook运行的，所以默认使用的是MindSpore这个虚拟环境，这个虚拟环境里的mindspore配置有点问题，镜像里的cann是8.0，但mindspore版本是2.3，这样不匹配，需要安装2.5.0，且使用pip install mindspore可能无法更新，需要指定版本，或者使用官网的命令： pip install https://msrelease.obs.cnnorth4.myhuaweicloud.com/2.5.0/MindSpore/unified/aarch64/mindspore2.5.0cp39cp39linux_aarch64.whl trustedhost msrelease.obs.cnnorth4.myhuaweicloud.com i https://pypi.tuna.tsinghua.edu.cn/simple 2.升级到2.5后，其它的te等依赖包需要重新安装，否则会出现ge错误： pip uninstall sympy te topi hccl y pip install sympy pip install /usr/local/Ascend/ascendtoolkit/latest/lib64/te*py3noneany.whl pip install /usr/local/Ascend/ascendtoolkit/latest/lib64/hccl*py3noneany.whl 3.由于该镜像的notebook环境中，环境变量有点问题，没有正确加载昇腾后端的环境变量，不能加载昇腾后端，且用户应该无法修改这个设置，只能由启智社区去处理，所以notebook环境目前跑不了昇腾后端，只能用CPU去运行； 通过上面1和2的配置，可以在终端里运行transformer的示例代码： !输入图片说明
zhangbuxue,精度故障不重启快恢偶现卡死问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-04-22T15:15:29+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC31NI
wangyibo,msadapter st_test init failed random,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  msadapter的模型用例偶现的初始化失败问题。 !输入图片说明  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-21T14:06:01+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC2OW1
zhuhuachao2024,mindspore.mint.nn.functional.grid_sample函数不支持bfloat16，但使用时在执行命令时不报错，却会导致后续命令报错," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.grid_sample函数不支持bfloat16，但执行命令时不报错，却会导致后续命令报错  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F def test_bfloat16():     batch_size = 2     channels = 3     height = 8     width = 8     grid_height = 6     grid_width = 6     np_input = np.random.randn(batch_size, channels, height, width).astype(np.float32)     np_grid = np.random.uniform(1, 1, (batch_size, grid_height, grid_width, 2)).astype(np.float32)     ms_dtype=ms.bfloat16     try:          首先尝试 mint.nn.functional.grid_sample         ms_input = Tensor(np_input, dtype=ms_dtype)         ms_grid = Tensor(np_grid, dtype=ms_dtype)         ms_output = mint_F.grid_sample(ms_input, ms_grid, mode='bilinear', padding_mode='zeros', align_corners=False)         print(f""MindSpore 输出 ({'mint API' if ms_using_mint else '替代实现'}): shape={ms_output.shape}"")         ms_support = ""支持""     except Exception as e:         print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")         ms_support = ""不支持""     input_shape = (2, 1, 8, 8),       单通道     grid_shape = (2, 6, 6, 2)     print(f""\n测试输入尺寸: 输入={input_shape}, 网格={grid_shape}"")      生成随机输入     np_input = np.random.randn(*input_shape).astype(np.float32)     np_grid = np.random.uniform(1, 1, grid_shape).astype(np.float32)      MindSpore     ms_input = Tensor(np_input, dtype=ms.float32)     ms_grid = Tensor(np_grid, dtype=ms.float32)     ms_output = mint_F.grid_sample(ms_input, ms_grid, mode='bilinear', padding_mode='zeros', align_corners=False)     print(f""MindSpore 输出: shape={ms_output.shape}"")     mindspore_np = mindspore_out.asnumpy()  这里报错 ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：在执行函数行报错  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:20:46+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NU4
zhuhuachao2024,mindspore.mint.nn.functional.grid_sample函数的mode和padding_mode参数输入错误内容时的报错信息不足," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.grid_sample函数的mode和padding_mode参数的报错信息不足，例如 PyTorch错误: ValueError: nn.functional.grid_sample(): expected padding_mode to be 'zeros', 'border', or 'reflection', but got: 'invalid_padding' MindSpore错误: ValueError: Failed to convert the value ""invalid_padding"" of input 'padding_mode' of 'GridSampler2D' to enum. PyTorch错误: ValueError: nn.functional.grid_sample(): expected mode to be 'bilinear', 'nearest' or 'bicubic', but got: 'invalid_mode' MindSpore错误: ValueError: Failed to convert the value ""invalid_mode"" of input 'interpolation_mode' of 'GridSampler2D' to enum. pytorch会说明具体可用mode，但是mindspore不会  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F batch_size = 2 channels = 3 height = 8 width = 8 grid_height = 6 grid_width = 6 np_input = np.random.randn(batch_size, channels, height, width).astype(np.float32) np_grid = np.random.uniform(1, 1, (batch_size, grid_height, grid_width, 2)).astype(np.float32) ms_input = Tensor(np_input, dtype=ms.float32) ms_grid = Tensor(np_grid, dtype=ms.float32) ms_output = mint_F.grid_sample(ms_input, ms_grid, padding_mode='invalid_padding') ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：提供具体报错信息  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:17:45+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NTO
zhuhuachao2024,mindspore.mint.nn.functional.grid_sample函数的grid参数最后一维不为2时报错位置不对," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.grid_sample函数中，grid参数最后一维不为2时，mindspore直到使用输出值时才报错  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F ms_output = mint_F.grid_sample(ms_input, ms_wrong_grid_dim) print(""MindSpore支持网格维度不是2"") print(ms_output)     这一行才报错 ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：报错位置在执行函数行  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:14:42+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NT9
zhuhuachao2024,mindspore.mint.nn.functional.grid_sample函数不支持bicubic模式," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.grid_sample函数的支持模式不足： pytorch  bilinear, nearest, bicubic mindspore  bilinear, nearest  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F try:     ms_output = mint_F.grid_sample(ms_input, ms_grid, mode='bicubic', padding_mode='zeros', align_corners=False)     print(f""MindSpore mode='{mode}': 支持"")     ms_mode_supported = True except Exception as e:     print(f""MindSpore 错误: {str(e)}"")     ms_mode_supported = False ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 Failed to convert the value ""bicubic"" of input 'interpolation_mode' of 'GridSampler2D' to enum.  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:12:34+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NSC
zhuhuachao2024,mindspore.mint.nn.functional.mse_loss函数不支持float64输入类型," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.mse_loss函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16，但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      首先尝试 mint.nn.functional.mse_loss     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.mse_loss(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出 : {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")     ms_support = ""不支持"" ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:09:43+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NRX
zhuhuachao2024,mindspore.mint.nn.functional.l1_loss函数不支持float64输入类型," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.l1_loss函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16，但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      MindSpore     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.l1_loss(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出: {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")     ms_support = ""不支持"" ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:07:11+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NRQ
zhuhuachao2024,mindspore.mint.nn.functional.binary_cross_entropy在pos_weight shape与target shape不一致时报错位置不对," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.binary_cross_entropy函数在pos_weight shape与target shape不一致时直到使用输出值时才报错  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F ms_input = Tensor(np.random.randn(2, 3), dtype=ms.float32) ms_target = Tensor(np.random.rand(2, 3), dtype=ms.float32) ms_wrong_pos_weight = Tensor(np.random.rand(2, 4), dtype=ms.float32)   错误的尺寸 try:     ms_output = mint_F.binary_cross_entropy_with_logits(ms_input, ms_target, pos_weight=ms_wrong_pos_weight)     print(""MindSpore支持不匹配的pos_weight尺寸"")     print(f""结果为{ms_output}"")  这一行才报错 except Exception as e:     print(f""MindSpore错误: {str(e)}"") ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：报错位置在执行函数行  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:03:03+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NR7
zhuhuachao2024,mindspore.mint.nn.functional.binary_cross_entropy_with_logits函数不支持float64输入类型," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.binary_cross_entropy_with_logits函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16 （和文档一致），但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      MindSpore     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.binary_cross_entropy_with_logits(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出: {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")     ms_support = ""不支持"" ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 TypeError: For primitive[BCEWithLogitsLoss], the input argument[input] must be a type of {BFloat16, Float16, Float32}, but got Float64.  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T11:59:02+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NPZ
zhuhuachao2024,mindspore.mint.nn.functional.binary_cross_entropy函数不支持float64类型输入," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.binary_cross_entropy函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16 （和文档一致），但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      MindSpore     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.binary_cross_entropy(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出: {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {str(e)}"")     ms_support = ""不支持"" print(f""PyTorch: {pt_support}, MindSpore: {ms_support}"") ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 For Primitive[BinaryCrossEntorpy], the type of the input must be [Float16, Float32, BFloat16], but got Float64!  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T11:55:16+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NOR
zhanghanLeo,undo ReshapeAndCache check.,,2025-04-19T22:48:48+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2GI4
tinymonster123,[GPU]uint8→int8类型下等价模型Max操作输出不一致（Where/Max/Cast链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（涉及uint8→int8的Cast、Where、Max等操作）推理结果出现不一致。理论上两个模型输出应完全一致，但实际Max结果有0.2%的元素不匹配，最大差异高达251。而Less操作输出完全一致，表明问题出现在Max操作在Cast前后的位置差异导致的整型数据流异常。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个数学上等价的模型：       T1Model 执行顺序：`Where → Max → Cast → Min → Less`       T2Model 执行顺序：`Where → Cast → Min → Less → Max` 2. 使用相同的 uint8/int8 输入数据进行推理：      ```python    import numpy as np    import mindspore as ms    import mindspore.nn as nn    import mindspore.ops as ops    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")    np.random.seed(42)     创建输入数据    mask = ms.Tensor(np.random.choice([True, False], size=(5, 14, 1, 14, 57)))    val1 = ms.Tensor(np.random.randint(0, 255, size=(57,), dtype=np.uint8))    val2 = ms.Tensor(np.random.randint(0, 255, size=(1, 1, 57), dtype=np.uint8))     执行两种模型    t1_max, t1_less = T1Model()(mask, val1, val2)    t2_max, t2_less = T2Model()(mask, val1, val2)    ``` 3. 比较结果，典型输出:    ```    == T1模型输出 ==    Max结果  形状: (5, 14, 1, 14, 57) 数据类型: UInt8    部分值 (前5个元素): [135  75 133 120  34]    统计信息  最小值: 0 最大值: 253    == T2模型输出 ==    Max结果  形状: (5, 14, 1, 14, 57) 数据类型: UInt8    部分值 (前5个元素): [135  75 133 120  34]    统计信息  最小值: 0 最大值: 253    == Max算子结果比较 ==    不匹配元素数量: 92 / 55860 (0.2%)    最大绝对差异: 251    最大差异位置(0, 0, 0, 9, 42): T1=0, T2=5    == Less算子结果比较 ==    Less输出完全一致    ``` 4. 理论上两个模型输出应完全一致，但实际Max结果有0.2%的元素不匹配，最大差异高达251。而Less结果完全一致，表明问题出现在Max操作的位置不同导致的整型数据流异常。 ```python import numpy as np import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.cast = ops.Cast()     def construct(self, v5_0, v6_0, v7_0):          v5_0: b[5, 14, 1, 14, 57], v6_0: u8[57], v7_0: u8[1, 1, 57]         v8_0 = ops.where(v5_0, v6_0, v7_0)            core.Where         v3_0 = ops.maximum(v8_0, v8_0)                core.Max         v1_0 = self.cast(v8_0, ms.int8)               Cast to int8         v2_0 = ops.minimum(v1_0, v1_0)                core.Min         v4_0 = ops.less(v2_0, v1_0)                   core.Less          返回多个结果方便分析         return v3_0, v4_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.cast = ops.Cast()     def construct(self, v2_0, v1_0, v0_0):          v2_0: b[5, 14, 1, 14, 57], v1_0: u8[57], v0_0: u8[1, 1, 57]           v3_0 = ops.where(v2_0, v1_0, v0_0)            core.Where         v4_0 = self.cast(v3_0, ms.int8)               Cast to int8         v5_0 = ops.minimum(v4_0, v4_0)                core.Min           v6_0 = ops.less(v5_0, v4_0)                   core.Less         v8_0 = ops.maximum(v3_0, v3_0)                core.Max          返回多个结果方便分析         return v8_0, v6_0 def reproduce_bug():      设置环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1 = T1Model()     t2 = T2Model()      根据图创建输入  严格按照DOT文件中的形状和类型     np.random.seed(42)     shape1 = (5, 14, 1, 14, 57)     shape2 = (57,)     shape3 = (1, 1, 57)      T1输入     v5_0_t1 = ms.Tensor(np.random.choice([True, False], size=shape1))     v6_0_t1 = ms.Tensor(np.random.randint(0, 255, shape2, dtype=np.uint8))     v7_0_t1 = ms.Tensor(np.random.randint(0, 255, shape3, dtype=np.uint8))      T2输入  保持相同输入以便比较     v2_0_t2 = v5_0_t1   布尔掩码     v1_0_t2 = v6_0_t1   uint8[57]     v0_0_t2 = v7_0_t1   uint8[1, 1, 57]      执行模型     t1_v3_0, t1_v4_0 = t1(v5_0_t1, v6_0_t1, v7_0_t1)     t2_v8_0, t2_v6_0 = t2(v2_0_t2, v1_0_t2, v0_0_t2)      打印T1和T2的输出     print(""\n== T1模型输出 =="")     print(""Max结果  形状:"", t1_v3_0.shape, ""数据类型:"", t1_v3_0.dtype)     print(""部分值 (前5个元素):"", t1_v3_0.asnumpy().flatten()[:5])     print(""统计信息  最小值:"", np.min(t1_v3_0.asnumpy()), ""最大值:"", np.max(t1_v3_0.asnumpy()))     print(""\n== T2模型输出 =="")     print(""Max结果  形状:"", t2_v8_0.shape, ""数据类型:"", t2_v8_0.dtype)     print(""部分值 (前5个元素):"", t2_v8_0.asnumpy().flatten()[:5])     print(""统计信息  最小值:"", np.min(t2_v8_0.asnumpy()), ""最大值:"", np.max(t2_v8_0.asnumpy()))      比较对应的输出结果     print(""\n== Max算子结果比较 =="")     print(""形状: T1:"", t1_v3_0.shape, ""T2:"", t2_v8_0.shape)     if np.array_equal(t1_v3_0.asnumpy(), t2_v8_0.asnumpy()):         print(""Max输出完全一致"")     else:         mismatched = (t1_v3_0.asnumpy() != t2_v8_0.asnumpy())         mismatched_count = np.sum(mismatched)         total_elements = t1_v3_0.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.1f}%)"")          计算差异         abs_diff = np.abs(t1_v3_0.asnumpy()  t2_v8_0.asnumpy())         max_diff = np.max(abs_diff)         print(f""最大绝对差异: {max_diff}"")          找出差异最大的位置         flat_idx = np.argmax(abs_diff.flatten())         idx = np.unravel_index(flat_idx, abs_diff.shape)         print(f""最大差异位置{idx}: T1={t1_v3_0.asnumpy()[idx]}, T2={t2_v8_0.asnumpy()[idx]}"")     print(""\n== Less算子结果比较 =="")     print(""形状: T1:"", t1_v4_0.shape, ""T2:"", t2_v6_0.shape)     if np.array_equal(t1_v4_0.asnumpy(), t2_v6_0.asnumpy()):         print(""Less输出完全一致"")      else:         bool_mismatched = (t1_v4_0.asnumpy() != t2_v6_0.asnumpy())         bool_mismatched_count = np.sum(bool_mismatched)         bool_total = t1_v4_0.size         bool_mismatch_percentage = 100.0 * bool_mismatched_count / bool_total         print(f""不匹配元素数量: {bool_mismatched_count} / {bool_total} ({bool_mismatch_percentage:.1f}%)"")          显示部分不匹配的布尔值         indices = np.where(bool_mismatched)         for i in range(min(3, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={t1_v4_0.asnumpy()[idx]}, T2={t2_v6_0.asnumpy()[idx]}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:53:13+08:00,"foruda,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G5M,"这里的问题应该不是max或者cast的问题，也不是那些api的执行顺序导致的，问题应该是出现在mindspore.ops.where上面，这个方法确实有点问题，用以下代码就能验证： import mindspore as ms import mindspore.ops as ops import numpy as np np.random.seed(42) shape1 = (5, 14, 1, 14, 57) shape2 = (57,) shape3 = (1, 1, 57) t1 = ms.Tensor(np.random.choice([True, False], size=shape1)) t2 = ms.Tensor(np.random.randint(0, 255, shape2, dtype=np.uint8)) t3 = ms.Tensor(np.random.randint(0, 255, shape3, dtype=np.uint8)) r1 = ops.where(t1, t2, t3) r2 = ops.where(t1, t2, t3) (r1==r2).sum() 执行两次where，输入一模一样的，但是输出却不完全相同，(r1==r2).sum()的值也小于总数55860，说明有元素不相同，执行多次，出现不同元素的个数还会有差异： !输入图片说明 更进一步分析，我觉得可能是where里面进行广播时出现了问题，因为如果三个参数condition, x, y都写成一样的shape，就不需要执行广播逻辑，而这样的结果就是正确的，如下示例代码所示： import mindspore as ms import mindspore.ops as ops import numpy as np np.random.seed(42) shape1 = (5, 14, 1, 14, 57) shape2 = (5, 14, 1, 14,57) shape3 = (5, 14, 1, 14, 57) t1 = ms.Tensor(np.random.choice([True, False], size=shape1)) t2 = ms.Tensor(np.random.randint(0, 255, shape2, dtype=np.uint8)) t3 = ms.Tensor(np.random.randint(0, 255, shape3, dtype=np.uint8)) r1 = ops.where(t1, t2, t3) r2 = ops.where(t1, t2, t3) (r1==r2).sum() !输入图片说明 这样的话执行多次，结果都是正确的"
tinymonster123,[GPU]uint8类型下等价模型整型张量输出不一致（Where/Max/Clip链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在 MindSpore GPU 模式下，两个数学上等价的 uint8 模型（链路：Where → Max → Clip）推理输出出现不一致。 典型运行结果： 不匹配元素数量: 66 / 58056 (0.10%) 最大绝对差异: 252 差异示例位置和值: (0,0,0,0,16) T1=1, T2=5 理论上两个模型输出应完全一致，但实际有 0.10% 元素不匹配，最大差异高达 252。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个数学等价的模型：       T1Model 执行顺序：`Ceil → Where → MatMul`       T2Model 执行顺序：`Where → Ceil → MatMul`   2. 生成相同的 float16 输入并推理 3. 打印并比较结果，典型输出如下（部分）：   ``` 输出形状: T1输出: (59, 24, 1, 1, 41) T2输出: (59, 24, 1, 1, 41) 不匹配元素数量: 66 / 58056 (0.10%) 最大绝对差异: 252 差异最大的3个元素位置和值: 位置(0, 0, 0, 0, 16): T1=1, T2=5, 差异=252 位置(0, 0, 0, 0, 15): T1=1, T2=7, 差异=250 位置(0, 13, 0, 0, 9): T1=249, T2=1, 差异=248 ``` 4. 理论上二者应输出完全一致，但实际有 0.10% 元素不匹配，且最大差异高达 252。 ```python import numpy as np import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          严格按照图中的常量初始化 v2_0 (u8[1, 1, 1])         self.const = ms.Tensor(np.ones((1, 1, 1), dtype=np.uint8))          创建其他必要的算子         self.clip_min = 0         self.clip_max = 255   uint8范围     def construct(self, v5_0, v1_0):          严格按照图中算子顺序执行          v5_0: u8[41], v1_0: b[59, 24, 1, 1, 41]          v6_0 = MSClip(v5_0)         v6_0 = ops.clip_by_value(v5_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v3_0 = Reshape(v6_0)         v3_0 = ops.reshape(v6_0, v6_0.shape)   按原形状reshape，实际可能不改变          v7_0 = Clip(v6_0)         v7_0 = ops.clip_by_value(v6_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v4_0 = Where(v1_0, v2_0, v6_0)         v4_0 = ops.where(v1_0, self.const, v6_0)          v0_0 = Max(v4_0, v2_0)         v0_0 = ops.maximum(v4_0, self.const)         return v0_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          严格按照图中的常量初始化 v0_0 (u8[1, 1, 1])         self.const = ms.Tensor(np.ones((1, 1, 1), dtype=np.uint8))          创建其他必要的算子         self.clip_min = 0         self.clip_max = 255   uint8范围     def construct(self, v1_0, v3_0):          严格按照图中算子顺序执行          v1_0: u8[41], v3_0: b[59, 24, 1, 1, 41]          v2_0 = MSClip(v1_0)         v2_0 = ops.clip_by_value(v1_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v4_0 = Where(v3_0, v0_0, v2_0)         v4_0 = ops.where(v3_0, self.const, v2_0)          v5_0 = Max(v4_0, v0_0)         v5_0 = ops.maximum(v4_0, self.const)          v7_0 = Clip(v2_0)         v7_0 = ops.clip_by_value(v2_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v9_0 = Reshape(v2_0)         v9_0 = ops.reshape(v2_0, v2_0.shape)   按原形状reshape，实际可能不改变         return v5_0 def reproduce_bug():      设置环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1 = T1Model()     t2 = T2Model()      严格按照图中的数据类型和形状创建输入      T1输入: v5_0 (u8[41]), v1_0 (b[59, 24, 1, 1, 41])      T2输入: v1_0 (u8[41]), v3_0 (b[59, 24, 1, 1, 41])     v5_0_t1 = ms.Tensor(np.random.randint(0, 255, (41), dtype=np.uint8))     v1_0_t1 = ms.Tensor(np.random.choice([True, False], size=(59, 24, 1, 1, 41)))     v1_0_t2 = ms.Tensor(np.random.randint(0, 255, (41), dtype=np.uint8))     v3_0_t2 = ms.Tensor(np.random.choice([True, False], size=(59, 24, 1, 1, 41)))      执行模型     t1_output = t1(v5_0_t1, v1_0_t1)     t2_output = t2(v1_0_t2, v3_0_t2)      输出形状     print(""\n输出形状:"")     print(""T1输出:"", t1_output.shape)     print(""T2输出:"", t2_output.shape)      由于输入随机，我们不能直接比较输出      但可以尝试用相同的输入比较      使相同的输入     v1_0_t2 = v5_0_t1.copy()   让T2的v1_0等于T1的v5_0     v3_0_t2 = v1_0_t1.copy()   让T2的v3_0等于T1的v1_0      重新执行     t1_output = t1(v5_0_t1, v1_0_t1)     t2_output = t2(v1_0_t2, v3_0_t2)      比较输出     if np.array_equal(t1_output.asnumpy(), t2_output.asnumpy()):         print(""\n输出完全一致"")     else:         mismatched = (t1_output.asnumpy() != t2_output.asnumpy())         mismatched_count = np.sum(mismatched)         total_elements = t1_output.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""\n不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.1f}%)"")          计算差异         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         max_diff = np.max(abs_diff)         print(f""最大绝对差异: {max_diff}"")          显示差异最大的部分         if total_elements > 3:             print(""\n差异最大的3个元素位置和值:"")             flat_indices = np.argsort(abs_diff.flatten())[3:]             for flat_idx in reversed(flat_indices):                 indices = np.unravel_index(flat_idx, abs_diff.shape)                 print(f""位置{indices}: T1={t1_output.asnumpy()[indices]}, ""                       f""T2={t2_output.asnumpy()[indices]}, ""                       f""差异={abs_diff[indices]}"")         else:             print(""\n所有元素的差异:"")             for idx in np.ndindex(t1_output.shape):                 print(f""位置{idx}: T1={t1_output.asnumpy()[idx]}, ""                       f""T2={t2_output.asnumpy()[idx]}, ""                       f""差异={abs_diff[idx]}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:47:57+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G5D,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
tinymonster123,[GPU]int8→uint8类型下等价模型整型张量输出不一致（Xor/Where/Cast链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（涉及int8→uint8的Cast、Xor、Where等操作）推理结果出现不一致。具体表现为：部分元素输出不同，最大差异高达255，1.92%的元素不匹配。该问题在整型张量数据流经Xor、Where、Cast链路时出现，理论上应完全一致。尤其是负值转换为uint8时，差异尤为明显。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个等价模型 T1Model 和 T2Model      * T1Model 执行流程：        1) ops.cast(bool1, ms.uint8) + ops.cast(bool2, ms.uint8)        2) ops.bitwise_xor(uint8_1, uint8_2)        3) ops.cast(xor_result, ms.bool_)        4) ops.squeeze(input_int8, axis=1)        5) ops.where(bool_result, const_int8, squeezed)        6) ops.squeeze(where_result, axis=1)        7) ops.cast(squeeze_result, ms.uint8)      * T2Model 执行流程（算子顺序相同，输入参数顺序略有差异）：        1) ops.squeeze(input_int8, axis=1)        2) ops.cast(bool1, ms.uint8) + ops.cast(bool2, ms.uint8)        3) ops.bitwise_xor(uint8_1, uint8_2)        4) ops.cast(xor_result, ms.bool_)        5) ops.where(bool_result, const_int8, squeezed)        6) ops.squeeze(where_result, axis=1)        7) ops.cast(squeeze_result, ms.uint8)   2. 生成随机的 int8 和 bool 输入数据      ```python    import numpy as np    import mindspore as ms     生成不同类型的输入     特殊边界值测试    v0_0 = ms.Tensor(np.array([[127], [0], [127]] * 17 + [[1]], dtype=np.int8).reshape(52, 1, 1))    v2_0 = ms.Tensor(True, dtype=ms.bool_)    v3_0 = ms.Tensor(True, dtype=ms.bool_)    v4_0 = ms.Tensor(128, dtype=ms.int8)   int8最小值    v7_0 = ms.Tensor(False, dtype=ms.bool_)    ``` 3. 在 MindSpore GPU + PyNative 模式下运行推理      ```python    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")     初始化并实例化模型    t1 = T1Model()    t2 = T2Model()     运行两模型（注意参数顺序不同）    t1_output = t1(v0_0, v2_0, v4_0, v7_0)    t2_output = t2(v0_0, v4_0, v3_0, v2_0)    ``` 4. 对比两模型输出，统计差异      ```python    import numpy as np    t1_output_np = t1_output.asnumpy()    t2_output_np = t2_output.asnumpy()    diff = np.abs(t1_output_np  t2_output_np)    total = diff.size    mismatches = np.sum(t1_output_np != t2_output_np)    max_diff = np.max(diff)    print(f""不匹配元素: {mismatches} / {total} ({100*mismatches/total:.2f}%)"")    print(f""最大绝对差异: {max_diff}"")     分析负值转换影响    negative_mask = (v0_0.asnumpy()  max_diff_overall:             max_diff_overall = current_max_diff             best_t1_output = t1_output             best_t2_output = t2_output             best_inputs = (v0_0, v2_0, v3_0, v4_0, v7_0)             print(f""   找到更大差异: {current_max_diff}"")      使用最佳或最后一轮输出     if best_t1_output is None:         print(""\n未发现显著差异，使用最后一轮测试结果"")         t1_output = last_t1_output         t2_output = last_t2_output         inputs = last_inputs     else:         print(f""\n发现最大差异: {max_diff_overall}"")         t1_output = best_t1_output         t2_output = best_t2_output         inputs = best_inputs         v0_0, v2_0, v3_0, v4_0, v7_0 = inputs         print(f""最大差异的输入:"")         print(f""  v2_0 (T1布尔值): {v2_0.asnumpy().item()}"")         print(f""  v7_0 (T1布尔值): {v7_0.asnumpy().item()}"")         print(f""  v3_0 (T2布尔值): {v3_0.asnumpy().item()}"")         print(f""  v4_0 (T1整数/T2布尔值): {v4_0.asnumpy().item()}"")     print(""\n输出形状:"")     print(""T1 output:"", t1_output.shape)     print(""T2 output:"", t2_output.shape)      输出统计信息     t1_output_np = t1_output.asnumpy()     t2_output_np = t2_output.asnumpy()     print(""\nT1模型输出统计:"")     print(f""最小值: {np.min(t1_output_np)}, 最大值: {np.max(t1_output_np)}, 平均值: {np.mean(t1_output_np)}"")     print(""\nT2模型输出统计:"")     print(f""最小值: {np.min(t2_output_np)}, 最大值: {np.max(t2_output_np)}, 平均值: {np.mean(t2_output_np)}"")      检查数据类型     print(f""\n输出数据类型: T1={t1_output.dtype}, T2={t2_output.dtype}"")      检查输出是否一致     if np.array_equal(t1_output_np, t2_output_np):         print(""\n输出完全一致"")     else:         mismatched = (t1_output_np != t2_output_np)         mismatched_count = np.sum(mismatched)         total_elements = t1_output_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(             f""\n不匹配元素: {mismatched_count} / {total_elements} ({mismatch_percentage:.2f}%)""         )          显示差异最大的前5个元素         flat_diff = abs_diff.flatten()         max_indices = np.argsort(flat_diff)[min(5, len(flat_diff)):][::1]         print(""\n差异最大的元素:"")         for idx in max_indices:             idx_tuple = np.unravel_index(idx, t1_output.shape)             t1_val = t1_output_np[idx_tuple]             t2_val = t2_output_np[idx_tuple]             diff = flat_diff[idx]             print(f""位置{idx_tuple}: T1={t1_val}, T2={t2_val}, 差异={diff}"")          分析int8负值转uint8的影响         negative_mask = (inputs[0].asnumpy() < 0)         if np.any(negative_mask):             print(""\n负值转换为uint8的影响分析:"")             print(f""负值数量: {np.sum(negative_mask)}"")             print(f""负值对应位置的差异平均值: {np.mean(abs_diff.flatten()[negative_mask.flatten()])}"") if __name__ == ""__main__"":     reproduce_bug_796() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 关键日志： ``` 使用GPU执行测试 开始测试... 运行测试 1/20...    最大差异: 0    找到更大差异: 0 运行测试 2/20...    最大差异: 0 运行测试 3/20...    最大差异: 0 运行测试 4/20...    最大差异: 255    找到更大差异: 255 运行测试 5/20...    最大差异: 126 运行测试 6/20...    最大差异: 0 运行测试 7/20...    最大差异: 255 运行测试 8/20...    最大差异: 231 运行测试 9/20...    最大差异: 255 运行测试 10/20...    最大差异: 124 运行测试 11/20...    最大差异: 255 运行测试 12/20...    最大差异: 0 运行测试 13/20...    最大差异: 255 运行测试 14/20...    最大差异: 255 运行测试 15/20...    最大差异: 255 运行测试 16/20...    最大差异: 255 运行测试 17/20...    最大差异: 255 运行测试 18/20...    最大差异: 255 运行测试 19/20...    最大差异: 255 运行测试 20/20...    最大差异: 255 发现最大差异: 255 最大差异的输入:   v2_0 (T1布尔值): True   v7_0 (T1布尔值): False   v3_0 (T2布尔值): True   v4_0 (T1整数/T2布尔值): 128 输出形状: T1 output: (52,) T2 output: (52,) T1模型输出统计: 最小值: 0, 最大值: 128, 平均值: 2.4615384615384617 T2模型输出统计: 最小值: 0, 最大值: 129, 平均值: 2.480769230769231 输出数据类型: T1=UInt8, T2=UInt8 不匹配元素: 1 / 52 (1.92%) 差异最大的元素: 位置(1,): T1=0, T2=0, 差异=255 位置(48,): T1=0, T2=0, 差异=255 位置(18,): T1=0, T2=0, 差异=255 位置(35,): T1=0, T2=0, 差异=255 位置(44,): T1=0, T2=0, 差异=255 负值转换为uint8的影响分析: 负值数量: 17 负值对应位置的差异平均值: 156.76470588235293 ```",2025-04-19T20:44:22+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IC2G51
tinymonster123,[GPU]float32类型下等价模型NaN值分布不一致（Where/Mul/Reduce/Max链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（均为float32类型）推理结果出现极端不一致。具体表现为：``98.15%``的元素值不匹配，且最大差异高达``195.55``。该问题在``Where→Add→Mul→ReduceMin→Max``与``Where→Add→Concat→Concat→Split→Split→Mul→ReduceMin→Max``两个等价计算链路之间产生，理论上这两种路径应完全一致。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建两个数学上等价的模型T1Model和T2Model，均包含Where、Add、Mul、ReduceMin、Max等核心算子，执行顺序如下：     T1Model执行顺序：Where → Add → Mul → ReduceMin → Max       T2Model执行顺序：Where → Add → Concat → Concat → Split → Split → Mul → ReduceMin → Max   2. 使用相同的float32输入数据，推理后直接输出两个模型的全部结果。 3. 对比输出，发现大部分元素不一致，最大绝对差异极大。例如：    ```    T1模型输出:    [ 5.0183954  18.028572    9.2797575   3.9463394 13.759254 ... ]    T2模型输出:    [ 5.0183954  18.028572    9.2797575   3.9463394 13.759254 ... ]    ``` 4. 统计不一致情况，例如：     不匹配元素数量: 46746 / 47628 (98.15%)     最大绝对差异: 195.55     最大差异位置如(0, 23, 0, 37, 13): T1=9.99, T2=185.56 5. 结论：理论上两个模型输出应完全一致，但实际推理结果绝大多数元素不一致，且最大差异极大。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          严格按照graph.dot1定义常量         self.cond = ms.Tensor(np.ones((1, 1, 1, 1, 1), dtype=bool))      v3_0         self.const1 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v8_0         self.const2 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v6_0          创建算子实例  严格按照graph.dot不使用keep_dims         self.reduce_min = ops.ReduceMin()   dim=1, 默认keep_dims=False     def construct(self, x):          准备图中的输入         v9_0 = x[:, :, :, :1, :1]                               [1, 54, 1, 1, 1]         v4_0 = ops.reshape(x[:, :1, :, :, :], (1, 1, 1, 63, 14))   [1, 1, 1, 63, 14]         v6_0 = self.const2                                      [1, 1, 1]          按照T1的dot图顺序执行算子          node 10: Where         v10_0 = ops.where(self.cond, self.const1, v9_0)         [1, 54, 1, 1, 1]          node 7: Add  注意顺序是v10_0, v6_0         v7_0 = ops.add(v10_0, v6_0)                            [1, 54, 1, 1, 1]          node 5: Mul  注意顺序是v7_0, v4_0         v5_0 = ops.mul(v7_0, v4_0)                             [1, 54, 1, 63, 14]          node 1: ReduceMin         v1_0 = self.reduce_min(v5_0, 1)                        [1, 1, 63, 14]          node 2: MSMax         v2_0 = ops.maximum(v1_0, v5_0)                         [1, 54, 1, 63, 14]         return v2_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          严格按照dot图定义常量         self.cond = ms.Tensor(np.ones((1, 1, 1, 1, 1), dtype=bool))      v2_0         self.const1 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v1_0         self.const2 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v6_0          创建算子实例  严格按照graph.dot不使用keep_dims         self.reduce_min = ops.ReduceMin()   dim=1, 默认keep_dims=False     def construct(self, x):          准备图中的所有输入  严格按照graph.dot中的描述         v0_0 = x[:, :, :, :1, :1]                               [1, 54, 1, 1, 1]         v4_0 = ops.reshape(x[:, :1, :, :, :], (1, 1, 1, 63, 14))   [1, 1, 1, 63, 14]         v6_0 = self.const2                                      [1, 1, 1]          node 3: Where         v3_0 = ops.where(self.cond, self.const1, v0_0)          [1, 54, 1, 1, 1]          node 5: Mul  并行分支1         v5_0 = ops.mul(v4_0, v3_0)                              [1, 54, 1, 63, 14]          node 7: Add  注意顺序是v6_0, v3_0         v7_0 = ops.add(v6_0, v3_0)                              [1, 54, 1, 1, 1]          node 8: Concat  必须确保输入形状正确         v8_0 = ops.concat((v7_0, v7_0), axis=0)                 [2, 54, 1, 1, 1]          node 9: Mul  并行分支2         v9_0 = ops.mul(v4_0, v7_0)                              [1, 54, 1, 63, 14]          node 10: Concat         v10_0 = ops.concat((v9_0, v9_0), axis=0)                [2, 54, 1, 63, 14]          node 11: Concat         v11_0 = ops.concat((v10_0, v10_0), axis=0)              [4, 54, 1, 63, 14]          node 12: Mul  并行分支3         v12_0 = ops.mul(v6_0, v4_0)                             [1, 1, 1, 63, 14]          node 13: Concat         v13_0 = ops.concat((v8_0, v8_0), axis=0)                [4, 54, 1, 1, 1]          node 14: Split  切片代替Split2以保证形状正确         v14_0 = v13_0[:2]                                       [2, 54, 1, 1, 1]          node 15: Split  切片代替Split2以保证形状正确         v15_0 = v14_0[:1]                                       [1, 54, 1, 1, 1]          node 16: Mul  注意顺序是v4_0, v15_0         v16_0 = ops.mul(v4_0, v15_0)                            [1, 54, 1, 63, 14]          node 17: ReduceMin  不使用keep_dims，与dot图一致         v17_0 = self.reduce_min(v16_0, 1)                       [1, 1, 63, 14]          node 18: MSMax         v18_0 = ops.maximum(v17_0, v16_0)                       [1, 54, 1, 63, 14]         return v18_0 def reproduce_bug():     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")     np.random.seed(42)      创建输入     x = ms.Tensor(np.random.uniform(10, 10, (1, 54, 1, 63, 14)).astype(np.float32))     t1 = T1Model()     t2 = T2Model()     t1_out = t1(x)     t2_out = t2(x)     print(""\n输出形状:"")     print(""T1输出:"", t1_out.shape)     print(""T2输出:"", t2_out.shape)     print(""\nT1模型输出(部分):"")     print(t1_out.asnumpy().flatten()[:5])     print(""\nT2模型输出(部分):"")     print(t2_out.asnumpy().flatten()[:5])     t1_np = t1_out.asnumpy()     t2_np = t2_out.asnumpy()      确保形状相同再比较     if t1_np.shape != t2_np.shape:         print(f""\n警告：输出形状不同! T1: {t1_np.shape}, T2: {t2_np.shape}"")         return     if np.allclose(t1_np, t2_np, rtol=1e3, atol=1e3):         print(""\n输出完全一致"")     else:         mismatched = ~np.isclose(t1_np, t2_np, rtol=1e3, atol=1e3)         mismatched_count = np.sum(mismatched)         total_elements = t1_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""\n不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.2f}%)"")         abs_diff = np.abs(t1_np  t2_np)         max_diff = np.max(abs_diff)         print(f""最大绝对差异: {max_diff}"")         flat_idx = np.argmax(abs_diff)         idx = np.unravel_index(flat_idx, abs_diff.shape)         print(f""\n最大差异位置{idx}: T1={t1_np[idx]:.4e}, T2={t2_np[idx]:.4e}, 差异={abs_diff[idx]:.4e}"")         indices = np.where(mismatched)         print(""\n部分不匹配元素:"")         for i in range(min(3, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={t1_np[idx]:.4e}, T2={t2_np[idx]:.4e}, 差异={abs_diff[idx]:.4e}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（float32张量理论上无数值异常，NaN/Inf分布应严格一致）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:40:38+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G44,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： IC2G5M:[GPU]uint8→int8类型下等价模型Max操作输出不一致（Where/Max/Cast链路） 可参考我在该issue中的说明
tinymonster123,[GPU]float32类型下等价模型LeakyReLU操作输出极端不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的float32模型（T1Model和T2Model）在执行完全相同的算子链路（Where、SquaredDifference、Min、LeakyReLU、Tril）时，推理结果出现明显不一致。具体表现为：  Min操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  LeakyReLU操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  Tril操作：272个输出元素中有21个不匹配（7.72%），最大绝对差异为1.0。例如位置(1, 0)：T1=1.0，T2=0.0，差异=1.0。 这些不一致在理论上不应出现，等价模型在同一输入下应输出完全一致的结果。代码已输出全部结果，并详细统计了不匹配元素数量、比例和最大差异及其具体位置。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 我创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果：  T1Model执行顺序：Where → SquaredDifference → Min → LeakyReLU → Tril  T2Model执行顺序：Where → SquaredDifference → LeakyReLU → Tril → Min 2. 使用相同的float32输入数据和常量，发现输出结果有明显差异：  Min操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  LeakyReLU操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  Tril操作：272个输出元素中有21个不匹配（7.72%），最大绝对差异为1.0。例如位置(1, 0)：T1=1.0，T2=0.0，差异=1.0。 这些不一致在理论上不应出现，等价模型在同一输入下应输出完全一致的结果。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn squared_difference = ops.SquaredDifference() class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          初始化常量         self.condition = ms.Tensor(np.random.choice([True, False], size=(8, 34)))         self.scalar_val = ms.Tensor(np.array([0.5], dtype=np.float32))         self.vector_val = ms.Tensor(np.random.uniform(size=(34)).astype(np.float32))     def construct(self, x):          先Where操作         where_out = ops.where(self.condition, self.scalar_val, self.vector_val)          平方差计算         squared_diff = squared_difference(where_out, x)          先进行Min操作         min_out = ops.minimum(x, squared_diff)          再进行LeakyReLU和Tril操作         leaky_relu_out = ops.leaky_relu(squared_diff)         tril_out = ops.tril(leaky_relu_out)          返回三个关键结果以便比较         return min_out, leaky_relu_out, tril_out class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          使用与T1Model相同的常量         self.condition = ms.Tensor(np.random.choice([True, False], size=(8, 34)))         self.scalar_val = ms.Tensor(np.array([0.5], dtype=np.float32))         self.vector_val = ms.Tensor(np.random.uniform(size=(34)).astype(np.float32))     def construct(self, x):          先Where操作         where_out = ops.where(self.condition, self.scalar_val, self.vector_val)          平方差计算         squared_diff = squared_difference(where_out, x)          先进行LeakyReLU和Tril操作         leaky_relu_out = ops.leaky_relu(squared_diff)         tril_out = ops.tril(leaky_relu_out)          后进行Min操作         min_out = ops.minimum(x, squared_diff)          返回三个关键结果以便比较         return min_out, leaky_relu_out, tril_out def reproduce_bug():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     np.random.seed(42)   确保可重复性     t1_model = T1Model()     t2_model = T2Model()      创建输入（使用可能触发问题的值）     x = ms.Tensor(np.array([[1.0]]).astype(np.float32))      运行模型     t1_min, t1_leaky, t1_tril = t1_model(x)     t2_min, t2_leaky, t2_tril = t2_model(x)      输出Min操作结果比较     print(""\n====== Min操作比较 ======"")     t1_min_np = t1_min.asnumpy()     t2_min_np = t2_min.asnumpy()     min_diff = np.abs(t1_min_np  t2_min_np)     min_max_diff = np.max(min_diff)     print(f""Min操作最大差异: {min_max_diff}"")     if min_max_diff > 0.001:         min_mismatched = np.abs(t1_min_np  t2_min_np) > 0.001         min_mismatched_count = np.sum(min_mismatched)         min_total_elements = t1_min_np.size         min_mismatch_percentage = 100.0 * min_mismatched_count / min_total_elements         print(f""Min操作不匹配元素: {min_mismatched_count} / {min_total_elements} ({min_mismatch_percentage:.2f}%)"")          找到最大差异的位置并显示         flat_idx = np.argmax(min_diff)         idx = np.unravel_index(flat_idx, min_diff.shape)         print(             f""Min操作最大差异位置{idx}: T1={t1_min_np[idx]}, T2={t2_min_np[idx]}, 差异={min_diff[idx]}""         )     else:         print(""Min操作输出一致"")      输出LeakyReLU操作结果比较     print(""\n====== LeakyReLU操作比较 ======"")     t1_leaky_np = t1_leaky.asnumpy()     t2_leaky_np = t2_leaky.asnumpy()     leaky_diff = np.abs(t1_leaky_np  t2_leaky_np)     leaky_max_diff = np.max(leaky_diff)     print(f""LeakyReLU操作最大差异: {leaky_max_diff}"")     if leaky_max_diff > 0.001:         leaky_mismatched = np.abs(t1_leaky_np  t2_leaky_np) > 0.001         leaky_mismatched_count = np.sum(leaky_mismatched)         leaky_total_elements = t1_leaky_np.size         leaky_mismatch_percentage = 100.0 * leaky_mismatched_count / leaky_total_elements         print(f""LeakyReLU操作不匹配元素: {leaky_mismatched_count} / {leaky_total_elements} ({leaky_mismatch_percentage:.2f}%)"")          找到最大差异的位置并显示         flat_idx = np.argmax(leaky_diff)         idx = np.unravel_index(flat_idx, leaky_diff.shape)         print(             f""LeakyReLU操作最大差异位置{idx}: T1={t1_leaky_np[idx]}, T2={t2_leaky_np[idx]}, 差异={leaky_diff[idx]}""         )     else:         print(""LeakyReLU操作输出一致"")      输出Tril操作结果比较     print(""\n====== Tril操作比较 ======"")     t1_tril_np = t1_tril.asnumpy()     t2_tril_np = t2_tril.asnumpy()     tril_diff = np.abs(t1_tril_np  t2_tril_np)     tril_max_diff = np.max(tril_diff)     print(f""Tril操作最大差异: {tril_max_diff}"")     if tril_max_diff > 0.001:         tril_mismatched = np.abs(t1_tril_np  t2_tril_np) > 0.001         tril_mismatched_count = np.sum(tril_mismatched)         tril_total_elements = t1_tril_np.size         tril_mismatch_percentage = 100.0 * tril_mismatched_count / tril_total_elements         print(f""Tril操作不匹配元素: {tril_mismatched_count} / {tril_total_elements} ({tril_mismatch_percentage:.2f}%)"")          找到最大差异的位置并显示         flat_idx = np.argmax(tril_diff)         idx = np.unravel_index(flat_idx, tril_diff.shape)         print(             f""Tril操作最大差异位置{idx}: T1={t1_tril_np[idx]}, T2={t2_tril_np[idx]}, 差异={tril_diff[idx]}""         )     else:         print(""Tril操作输出一致"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（float32张量理论上无数值异常）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:36:33+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G32,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
tinymonster123,[GPU]int8→int16类型下等价模型整型张量输出不一致（Where/Max/Cast链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个完全相同的int8→int16类型模型产生了不一致的输出结果。具体表现为：  在执行相同的 Where → Max → Cast 算子链路时，部分区域的值完全不一致  在总计27,664个元素中，有349个不匹配（1.26%）  最大绝对差异高达125（例如位置(0, 0, 27, 0)处：T1=0, T2=108）  特别是T1模型在部分区域输出全为0，而T2模型在相同位置有正负不同的值（如79和108） 这一现象在运算中理论上完全不应该发生。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 我创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果： T1Model执行顺序: Where → Max → Cast(to int16) T2Model执行顺序: Where → Max → Cast(to int16) 这两个模型逻辑完全等价，使用相同的int8输入和条件，但在GPU上运行时出现了明显的输出不一致：  在总计27,664个元素中，有349个不匹配（1.26%）  最大绝对差异达到125  具体不匹配元素示例：    位置(0, 0, 27, 0): T1=0, T2=108, 差异=108    位置(0, 0, 26, 18): T1=0, T2=79, 差异=79    位置(0, 0, 27, 2): T1=0, T2=79, 差异=79    位置(0, 0, 27, 3): T1=0, T2=79, 差异=79 特别是，T1模型输出在特定区域全为0，而T2模型在相同区域出现了正负不同的int16值，这在整型运算中应该是完全不可能的现象。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          初始化常量         self.const_false = ms.Tensor(np.array(0, dtype=np.int8))         self.const_true = ms.Tensor(np.array(127, dtype=np.int8))   int8最大值     def construct(self, x, condition):          核心算子链路：Where → Max → Cast         where_out = ops.where(condition, self.const_true, self.const_false)   i8[1,52,19]         max_out = ops.maximum(x, where_out)                                  i8[1,28,52,19]          cast_out = ops.cast(max_out, ms.int16)                               i16[1,28,52,19]         return cast_out class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          初始化常量         self.const_false = ms.Tensor(np.array(0, dtype=np.int8))         self.const_true = ms.Tensor(np.array(127, dtype=np.int8))   int8最大值     def construct(self, x, condition):          相同的核心算子链路：Where → Max → Cast         where_out = ops.where(condition, self.const_true, self.const_false)   i8[1,52,19]         max_out = ops.maximum(x, where_out)                                  i8[1,28,52,19]         cast_out = ops.cast(max_out, ms.int16)                               i16[1,28,52,19]         return cast_out def reproduce_bug():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1_model = T1Model()     t2_model = T2Model()      创建输入，确保可以触发问题      创建 unsqueeze 用的张量     x = ms.Tensor(np.random.randint(128, 127, (1, 28, 1)).astype(np.int8))     x_unsqueeze = ops.unsqueeze(x, 3)   变为[1,28,1,1]      创建用于 where 的条件     condition = ms.Tensor(np.random.choice([True, False], size=(1, 52, 19)))      运行模型     t1_output = t1_model(x_unsqueeze, condition)     t2_output = t2_model(x_unsqueeze, condition)      打印输出形状     print(""\n输出形状:"")     print(""T1输出:"", t1_output.shape)     print(""T2输出:"", t2_output.shape)      打印部分输出值     print(""\nT1模型输出(部分):"")     print(t1_output.asnumpy()[0, 0, :5, :5])     print(""\nT2模型输出(部分):"")     print(t2_output.asnumpy()[0, 0, :5, :5])      分析不一致     t1_np = t1_output.asnumpy()     t2_np = t2_output.asnumpy()     if np.array_equal(t1_np, t2_np):         print(""\n输出完全一致"")     else:         mismatched = (t1_np != t2_np)         mismatched_count = np.sum(mismatched)         total_elements = t1_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""\n不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.2f}%)"")          计算差异         diff = np.abs(t1_np  t2_np)         max_diff = np.max(diff)         print(f""最大绝对差异: {max_diff}"")          显示几个不匹配元素         indices = np.where(mismatched)         print(""\n部分不匹配元素:"")         for i in range(min(5, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={t1_np[idx]}, T2={t2_np[idx]}, 差异={abs(int(t1_np[idx])int(t2_np[idx]))}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:31:23+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G2R,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
tinymonster123,[GPU]int16类型下等价模型整型张量输出不一致（Min/Add操作）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（均为int16类型）推理结果出现不一致。具体表现为：部分元素输出不同，最大差异高达89，50%的元素不匹配。该问题在Min和Add操作的整型张量上出现，理论上应完全一致。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个等价模型 T1Model 和 T2Model      * T1Model 执行流程：        1) ops.where(bool_input, constant1, constant2)        2) ops.split(where_result, 2, axis=0)        3) ops.minimum(split[0], split[1])        4) ops.add(constant2, split[0])        5) ops.gt(constant1, where_result)      * T2Model 执行流程（算子顺序相同、图中连线顺序略有差异）：        1) ops.where(bool_input, constant1, constant2)        2) ops.split(where_result, 2, axis=0)        3) ops.minimum(split[0], split[1])        4) ops.add(constant2, split[0])        5) ops.gt(constant1, where_result)   2. 生成随机的 bool 输入数据和 int16 常量      ```python    import numpy as np    import mindspore as ms     以下是一种特别容易触发问题的输入模式    bool_array = np.zeros(22, dtype=bool)    bool_array[::2] = True   偶数位置为True    bool_input = ms.Tensor(bool_array)     常量初始化    scalar_val = np.random.randint(100, 100)    array_val = np.random.randint(100, 100, 1)    const1 = ms.Tensor(np.array([array_val], dtype=np.int16))   i16[1]    const2 = ms.Tensor(np.array(scalar_val, dtype=np.int16))    i16[]    ``` 3. 在 MindSpore GPU + PyNative 模式下运行推理      ```python    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")     初始化并共享常量    t1 = T1Model()    t2 = T2Model()    t1.v5_0 = const2; t1.v4_0 = const1    t2.v0_0 = const2; t2.v1_0 = const1     运行两模型    t1_min, t1_add = t1(bool_input)    t2_min, t2_add = t2(bool_input)    ``` 4. 对比两模型输出，统计差异      ```python    import numpy as np     比较Minimum操作结果    t1_min_np = t1_min.asnumpy()    t2_min_np = t2_min.asnumpy()    diff_min = np.abs(t1_min_np  t2_min_np)    total_min = t1_min_np.size    mismatches_min = np.count_nonzero(t1_min_np != t2_min_np)    max_diff_min = np.max(diff_min) if diff_min.size > 0 else 0     比较Add操作结果    t1_add_np = t1_add.asnumpy()    t2_add_np = t2_add.asnumpy()    diff_add = np.abs(t1_add_np  t2_add_np)    total_add = t1_add_np.size    mismatches_add = np.count_nonzero(t1_add_np != t2_add_np)    max_diff_add = np.max(diff_add) if diff_add.size > 0 else 0    print(f""Minimum操作不匹配元素: {mismatches_min} / {total_min} ({100*mismatches_min/total_min:.2f}%)"")    print(f""Minimum操作最大绝对差异: {max_diff_min}"")    print(f""Add操作不匹配元素: {mismatches_add} / {total_add} ({100*mismatches_add/total_add:.2f}%)"")    print(f""Add操作最大绝对差异: {max_diff_add}"")     示例输出：     Minimum操作不匹配元素: 1 / 2 (50.00%)     Minimum操作最大绝对差异: 89     Add操作不匹配元素: 1 / 2 (50.00%)     Add操作最大绝对差异: 89          具体元素差异：     位置(1,): Minimum操作 T1=89, T2=0, 差异=89     位置(1,): Add操作 T1=78, T2=11, 差异=89    ``` ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          常量初始化         self.v5_0 = ms.Tensor(np.array(5, dtype=np.int16))   i16[]         self.v4_0 = ms.Tensor(np.array([10], dtype=np.int16))   i16[1]     def construct(self, v3_0):          v3_0是布尔数组 b[22]          Where操作         v6_0 = ops.where(v3_0, self.v4_0, self.v5_0)   i16[22]          Greater操作         v7_0 = ops.gt(self.v4_0, v6_0)   b[22]          Split2操作         splits = ops.split(v6_0, 2, axis=0)   分成2等份         v1_0 = splits[0]   i16[11]         v1_1 = splits[1]   i16[11]          Add操作         v0_0 = ops.add(self.v5_0, v1_0)   i16[]          Min操作         v2_0 = ops.minimum(v1_0, v1_1)   i16[]          返回两个关键结果以便比较         return v2_0, v0_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          常量初始化         self.v0_0 = ms.Tensor(np.array(5, dtype=np.int16))   i16[]         self.v1_0 = ms.Tensor(np.array([10], dtype=np.int16))   i16[1]     def construct(self, v2_0):          v2_0是布尔数组 b[22]          Where操作         v3_0 = ops.where(v2_0, self.v1_0, self.v0_0)   i16[22]          Split2操作         splits = ops.split(v3_0, 2, axis=0)   分成2等份         v4_0 = splits[0]   i16[11]         v4_1 = splits[1]   i16[11]          Min操作         v5_0 = ops.minimum(v4_0, v4_1)   i16[]          Add操作         v7_0 = ops.add(self.v0_0, v4_0)   i16[]          Greater操作         v9_0 = ops.gt(self.v1_0, v3_0)   b[22]          返回两个关键结果以便比较         return v5_0, v7_0 def reproduce_bug_93():      设置 MindSpore 上下文     ms.set_context(mode=ms.PYNATIVE_MODE)     try:         ms.set_device(""GPU"")   尝试使用GPU         print(""使用GPU执行测试"")     except:         print(""GPU不可用，使用CPU执行测试"")      创建两个模型     t1_model = T1Model()     t2_model = T2Model()      设置随机种子以便复现     np.random.seed(42)     max_diff_overall_min = 1   对minimum操作的结果差异     max_diff_overall_add = 1   对add操作的结果差异     best_t1_outputs = None     best_t2_outputs = None     last_t1_outputs = None     last_t2_outputs = None     best_input = None      测试不同的输入场景     print(""开始测试..."")     for i in range(20):         print(f""运行测试 {i+1}/20..."")          生成不同的布尔数组输入         if i % 5 == 0:   全真             v3_0 = ms.Tensor(np.ones(22, dtype=bool))         elif i % 5 == 1:   全假             v3_0 = ms.Tensor(np.zeros(22, dtype=bool))         elif i % 5 == 2:   随机             v3_0 = ms.Tensor(np.random.choice([True, False], size=22))         elif i % 5 == 3:   前半真后半假             bool_array = np.zeros(22, dtype=bool)             bool_array[:11] = True             v3_0 = ms.Tensor(bool_array)         else:   交替真假             bool_array = np.zeros(22, dtype=bool)             bool_array[::2] = True   偶数位置为True             v3_0 = ms.Tensor(bool_array)          每隔几次更新常量值         if i % 4 == 0:              更新模型中的常量             scalar_val = np.random.randint(100, 100)             array_val = np.random.randint(100, 100, 1)             t1_model.v5_0 = ms.Tensor(np.array(scalar_val, dtype=np.int16))             t1_model.v4_0 = ms.Tensor(np.array(array_val, dtype=np.int16))             t2_model.v0_0 = ms.Tensor(np.array(scalar_val, dtype=np.int16))             t2_model.v1_0 = ms.Tensor(np.array(array_val, dtype=np.int16))          运行模型         t1_min, t1_add = t1_model(v3_0)         t2_min, t2_add = t2_model(v3_0)          保存最后一轮的输出         last_t1_outputs = (t1_min, t1_add)         last_t2_outputs = (t2_min, t2_add)          计算minimum操作的差异         abs_diff_min = np.abs(t1_min.asnumpy()  t2_min.asnumpy())         current_max_diff_min = np.max(abs_diff_min) if abs_diff_min.size > 0 else 0          计算add操作的差异         abs_diff_add = np.abs(t1_add.asnumpy()  t2_add.asnumpy())         current_max_diff_add = np.max(abs_diff_add) if abs_diff_add.size > 0 else 0         print(f""   最大差异 (Min操作): {current_max_diff_min}"")         print(f""   最大差异 (Add操作): {current_max_diff_add}"")          记录最大差异         if current_max_diff_min > max_diff_overall_min:             max_diff_overall_min = current_max_diff_min             best_t1_outputs = (t1_min, t1_add)             best_t2_outputs = (t2_min, t2_add)             best_input = v3_0             print(f""   找到更大差异 (Min操作): {current_max_diff_min}"")         if current_max_diff_add > max_diff_overall_add:             max_diff_overall_add = current_max_diff_add             if best_t1_outputs is None:                 best_t1_outputs = (t1_min, t1_add)                 best_t2_outputs = (t2_min, t2_add)                 best_input = v3_0             print(f""   找到更大差异 (Add操作): {current_max_diff_add}"")      使用最佳或最后一轮输出     if best_t1_outputs is None:         print(""\n未发现显著差异，使用最后一轮测试结果"")         t1_min, t1_add = last_t1_outputs         t2_min, t2_add = last_t2_outputs     else:         print(f""\n发现最大差异:"")         print(f""   Min操作: {max_diff_overall_min}"")         print(f""   Add操作: {max_diff_overall_add}"")         t1_min, t1_add = best_t1_outputs         t2_min, t2_add = best_t2_outputs         print(f""最大差异的输入: {best_input}"")     print(""\n====== Minimum操作比较 ======"")     print(""\n输出形状:"")     print(""T1 Min操作输出:"", t1_min.shape)     print(""T2 Min操作输出:"", t2_min.shape)      输出统计信息     t1_min_np = t1_min.asnumpy()     t2_min_np = t2_min.asnumpy()     print(""\nT1模型 Minimum操作输出:"")     print(t1_min_np)     print(""\nT2模型 Minimum操作输出:"")     print(t2_min_np)     print(""\nT1模型 Minimum操作统计:"")     if t1_min_np.size > 0:         print(             f""最小值: {np.min(t1_min_np)}, 最大值: {np.max(t1_min_np)}, 平均值: {np.mean(t1_min_np)}""         )     print(""\nT2模型 Minimum操作统计:"")     if t2_min_np.size > 0:         print(             f""最小值: {np.min(t2_min_np)}, 最大值: {np.max(t2_min_np)}, 平均值: {np.mean(t2_min_np)}""         )     abs_diff_min = np.abs(t1_min_np  t2_min_np)      检查输出是否一致     if np.array_equal(t1_min_np, t2_min_np):         print(""\nMinimum操作输出完全一致"")     else:         mismatched = t1_min_np != t2_min_np         mismatched_count = np.sum(mismatched)         total_elements = t1_min_np.size         mismatch_percentage = (             100.0 * mismatched_count / total_elements if total_elements > 0 else 0         )         print(             ""\nMinimum操作不匹配元素数量: {} / {} ({:.2f}%)"".format(                 mismatched_count, total_elements, mismatch_percentage             )         )         if total_elements > 0:             print(f""\nMinimum操作差异最大值: {np.max(abs_diff_min)}"")              显示差异最大的前5个元素             flat_diff_min = abs_diff_min.flatten()             max_indices_min = np.argsort(flat_diff_min)[5:][::1]             print(""\n差异最大的元素(Minimum操作):"")             for idx in max_indices_min:                 multi_idx = np.unravel_index(idx, t1_min.shape)                 t1_val = t1_min_np[multi_idx]                 t2_val = t2_min_np[multi_idx]                 diff = flat_diff_min[idx]                 print(f""位置{multi_idx}: T1={t1_val}, T2={t2_val}, 差异={diff}"")     print(""\n====== Add操作比较 ======"")     print(""\n输出形状:"")     print(""T1 Add操作输出:"", t1_add.shape)     print(""T2 Add操作输出:"", t2_add.shape)      输出统计信息     t1_add_np = t1_add.asnumpy()     t2_add_np = t2_add.asnumpy()     print(""\nT1模型 Add操作输出:"")     print(t1_add_np)     print(""\nT2模型 Add操作输出:"")     print(t2_add_np)     print(""\nT1模型 Add操作统计:"")     if t1_add_np.size > 0:         print(             f""最小值: {np.min(t1_add_np)}, 最大值: {np.max(t1_add_np)}, 平均值: {np.mean(t1_add_np)}""         )     print(""\nT2模型 Add操作统计:"")     if t2_add_np.size > 0:         print(             f""最小值: {np.min(t2_add_np)}, 最大值: {np.max(t2_add_np)}, 平均值: {np.mean(t2_add_np)}""         )     abs_diff_add = np.abs(t1_add_np  t2_add_np)      检查输出是否一致     if np.array_equal(t1_add_np, t2_add_np):         print(""\nAdd操作输出完全一致"")     else:         mismatched = t1_add_np != t2_add_np         mismatched_count = np.sum(mismatched)         total_elements = t1_add_np.size         mismatch_percentage = (             100.0 * mismatched_count / total_elements if total_elements > 0 else 0         )         print(             ""\nAdd操作不匹配元素数量: {} / {} ({:.2f}%)"".format(                 mismatched_count, total_elements, mismatch_percentage             )         )         if total_elements > 0:             print(f""\nAdd操作差异最大值: {np.max(abs_diff_add)}"")              显示差异最大的前5个元素             flat_diff_add = abs_diff_add.flatten()             max_indices_add = np.argsort(flat_diff_add)[5:][::1]             print(""\n差异最大的元素(Add操作):"")             for idx in max_indices_add:                 multi_idx = np.unravel_index(idx, t1_add.shape)                 t1_val = t1_add_np[multi_idx]                 t2_val = t2_add_np[multi_idx]                 diff = flat_diff_add[idx]                 print(f""位置{multi_idx}: T1={t1_val}, T2={t2_val}, 差异={diff}"") if __name__ == ""__main__"":     reproduce_bug_93() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 关键日志： ``` 使用GPU执行测试 开始测试... 运行测试 1/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0    找到更大差异 (Min操作): 0    找到更大差异 (Add操作): 0 运行测试 2/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 3/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 4/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 5/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 6/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 7/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 8/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 9/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 10/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 11/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 12/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 13/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 14/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 15/20...    最大差异 (Min操作): 89    最大差异 (Add操作): 89    找到更大差异 (Min操作): 89    找到更大差异 (Add操作): 89 运行测试 16/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 17/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 18/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 19/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 20/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 发现最大差异:    Min操作: 89    Add操作: 89 最大差异的输入: [ True False  True False  True False  True False  True False  True False   True False  True False  True False  True False  True False] ====== Minimum操作比较 ====== 输出形状: T1 Min操作输出: (2,) T2 Min操作输出: (2,) T1模型 Minimum操作输出: [48  89] T2模型 Minimum操作输出: [48   0] T1模型 Minimum操作统计: 最小值: 48, 最大值: 89, 平均值: 20.5 T2模型 Minimum操作统计: 最小值: 48, 最大值: 0, 平均值: 24.0 Minimum操作不匹配元素数量: 1 / 2 (50.00%) Minimum操作差异最大值: 89 差异最大的元素(Minimum操作): 位置(1,): T1=89, T2=0, 差异=89 位置(0,): T1=48, T2=48, 差异=0 ====== Add操作比较 ====== 输出形状: T1 Add操作输出: (2,) T2 Add操作输出: (2,) T1模型 Add操作输出: [59  78] T2模型 Add操作输出: [59 11] T1模型 Add操作统计: 最小值: 59, 最大值: 78, 平均值: 9.5 T2模型 Add操作统计: 最小值: 59, 最大值: 11, 平均值: 35.0 Add操作不匹配元素数量: 1 / 2 (50.00%) Add操作差异最大值: 89 差异最大的元素(Add操作): 位置(1,): T1=78, T2=11, 差异=89 位置(0,): T1=59, T2=59, 差异=0 ```",2025-04-19T20:26:07+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IC2G2I
tinymonster123,[GPU]等价模型在float32下输出极端不一致（出现巨大数值异常）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（均为float32类型）推理结果出现极端不一致。具体表现为：绝大多数元素输出不同，最大差异高达8.3e+34，99.94%的元素不匹配，部分输出甚至出现极大异常值（如8.3e+34）。该问题在张量全为float32数据时出现，理论上应完全一致。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个等价模型 T1Model 和 T2Model      * T1Model 执行流程：        1) ops.reshape(常量, (40, 45))        2) ops.where(input_bool, reshaped, 常量)        3) ops.floor(where_result)        4) ops.add(floor_result, where_result)      * T2Model 执行流程（核心算子等价、辅助操作不同）：        1) ops.reshape(常量, (40, 45))        2) ops.where(input_bool, reshaped, 常量)        3) ops.floor(where_result)        4) ops.add(where_result, floor_result)        5) 其他辅助操作（concat, transpose等）   2. 生成随机的 float32 输入数据和常量      ```python    import numpy as np    import mindspore as ms     两个常量    const1 = ms.Tensor(np.random.uniform(1, 1, (1800)).astype(np.float32))    const2 = ms.Tensor(np.array([[[0.5]]], dtype=np.float32))     布尔输入    input_bool = ms.Tensor(np.random.choice([True, False]))    ``` 3. 在 MindSpore GPU + PyNative 模式下运行推理      ```python    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")     初始化并共享常量    t1 = T1Model()    t2 = T2Model()    t1.v0_0 = const1; t1.v5_0 = const2    t2.v1_0 = const1; t2.v0_0 = const2     运行两模型    out1 = t1(input_bool)    out2 = t2(input_bool)    ``` 4. 对比两模型输出，统计差异      ```python    import numpy as np    y1 = out1.asnumpy()    y2 = out2.asnumpy()    diff = np.abs(y1  y2)    total = diff.size    mismatched = ~np.isclose(y1, y2, rtol=1e5, atol=1e5)    mismatched_count = np.sum(mismatched)    max_diff = np.max(diff)    print(f""不匹配元素: {mismatched_count} / {total} ({100*mismatched_count/total:.2f}%)"")    print(f""最大绝对差异: {max_diff}"")     示例输出：     不匹配元素: 1799 / 1800 (99.94%)     最大绝对差异: 8.307675964007756e+34     位置(0, 34, 6): T1=19.06, T2=8.31e+34, 差异=8.31e+34    ``` ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          常量初始化         self.v0_0 = ms.Tensor(np.random.uniform(1, 1, (1800)).astype(np.float32))         self.v5_0 = ms.Tensor(np.array([[[0.5]]], dtype=np.float32))     def construct(self, v3_0):          v3_0是布尔标量          Reshape操作         v7_0 = ops.reshape(self.v0_0, (40, 45))          Where操作         v6_0 = ops.where(v3_0, v7_0, self.v5_0)          Add操作         v4_0 = ops.add(v6_0, self.v5_0)          Floor操作         v1_0 = ops.floor(v6_0)          Add操作         v2_0 = ops.add(v1_0, v6_0)         return v2_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          常量初始化         self.v0_0 = ms.Tensor(np.array([[[0.5]]], dtype=np.float32))         self.v1_0 = ms.Tensor(np.random.uniform(1, 1, (1800)).astype(np.float32))     def construct(self, v3_0):          v3_0是布尔标量          Reshape操作         v2_0 = ops.reshape(self.v1_0, (40, 45))          Where操作         v4_0 = ops.where(v3_0, v2_0, self.v0_0)          Floor操作         v5_0 = ops.floor(v4_0)          Add操作         v6_0 = ops.add(v4_0, v5_0)          其余操作（Concat、Transpose等）         v7_0 = ops.concat((v6_0, v6_0), axis=0)         v8_0 = ops.add(self.v0_0, v4_0)         v9_0 = ops.transpose(v6_0, (1, 0, 2))         v10_0 = ops.transpose(v4_0, (1, 0, 2))          这些操作不影响主要输出，但为了完整性添加         v20_0 = ops.add(             ops.transpose(ops.transpose(v5_0, (1, 0, 2)), (1, 0, 2)),             ops.transpose(ops.transpose(v4_0, (1, 0, 2)), (1, 0, 2)),         )         return v6_0   返回主要结果 def reproduce_bug_89():      设置 MindSpore 上下文     ms.set_context(mode=ms.PYNATIVE_MODE)     try:         ms.set_device(""GPU"")   尝试使用GPU         print(""使用GPU执行测试"")     except:         print(""GPU不可用，使用CPU执行测试"")      创建两个模型     t1_model = T1Model()     t2_model = T2Model()      设置随机种子以便复现     np.random.seed(42)     max_diff_overall = 1     best_t1_output = None     best_t2_output = None     last_t1_output = None     last_t2_output = None     last_diff = None     best_input = None      测试不同的输入场景     print(""开始测试..."")     for i in range(20):         print(f""运行测试 {i+1}/20..."")          每次使用不同的布尔输入和随机常量         if i % 4 == 0:             v3_0 = ms.Tensor(True)         elif i % 4 == 1:             v3_0 = ms.Tensor(False)         elif i % 4 == 2:             v3_0 = ms.Tensor(np.random.choice([True, False]))         else:   重新初始化不同的常量值             v3_0 = ms.Tensor(np.random.choice([True, False]))              更新模型中的常量             t1_model.v0_0 = ms.Tensor(                 np.random.uniform(10, 10, (1800)).astype(np.float32)             )             t1_model.v5_0 = ms.Tensor(                 np.array([[[np.random.uniform(1, 1)]]], dtype=np.float32)             )             t2_model.v0_0 = t1_model.v5_0             t2_model.v1_0 = t1_model.v0_0          运行模型         t1_output = t1_model(v3_0)         t2_output = t2_model(v3_0)          保存最后一轮的输出         last_t1_output = t1_output         last_t2_output = t2_output          计算差异         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         current_max_diff = np.max(abs_diff)         last_diff = abs_diff         print(f""   最大差异: {current_max_diff}"")         if current_max_diff > max_diff_overall:             max_diff_overall = current_max_diff             best_t1_output = t1_output             best_t2_output = t2_output             best_input = v3_0             print(f""   找到更大差异: {current_max_diff}"")      使用最佳或最后一轮输出     if best_t1_output is None:         print(""\n未发现显著差异，使用最后一轮测试结果"")         t1_output = last_t1_output         t2_output = last_t2_output         abs_diff = last_diff     else:         print(f""\n发现最大差异: {max_diff_overall}"")         t1_output = best_t1_output         t2_output = best_t2_output         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         print(f""最大差异的输入: {best_input}"")     print(""\n输出形状:"")     print(""T1 output:"", t1_output.shape)     print(""T2 output:"", t2_output.shape)      输出统计信息     t1_output_np = t1_output.asnumpy()     t2_output_np = t2_output.asnumpy()     print(""\nT1模型全部输出:"")     print(t1_output_np)     print(""\nT2模型全部输出:"")     print(t2_output_np)     print(""\nT1模型输出统计:"")     print(         f""最小值: {np.min(t1_output_np)}, 最大值: {np.max(t1_output_np)}, 平均值: {np.mean(t1_output_np)}""     )     print(""\nT2模型输出统计:"")     print(         f""最小值: {np.min(t2_output_np)}, 最大值: {np.max(t2_output_np)}, 平均值: {np.mean(t2_output_np)}""     )      检查NaN和Inf值     t1_nan_count = np.isnan(t1_output_np).sum()     t2_nan_count = np.isnan(t2_output_np).sum()     t1_inf_count = np.isinf(t1_output_np).sum()     t2_inf_count = np.isinf(t2_output_np).sum()     print(f""\nNaN值统计: T1={t1_nan_count}, T2={t2_nan_count}"")     print(f""Inf值统计: T1={t1_inf_count}, T2={t2_inf_count}"")      检查输出是否一致     if np.allclose(t1_output_np, t2_output_np, rtol=1e5, atol=1e5):         print(""\n输出完全一致（在容差范围内）"")     else:         mismatched = ~np.isclose(t1_output_np, t2_output_np, rtol=1e5, atol=1e5)         mismatched_count = np.sum(mismatched)         total_elements = t1_output_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(             ""\n不匹配元素数量: {} / {} ({:.2f}%)"".format(                 mismatched_count, total_elements, mismatch_percentage             )         )          显示差异最大的前5个元素         flat_diff = abs_diff.flatten()         max_indices = np.argsort(flat_diff)[5:][::1]         print(""\n差异最大的元素:"")         for idx in max_indices:             multi_idx = np.unravel_index(idx, t1_output.shape)             t1_val = t1_output_np[multi_idx]             t2_val = t2_output_np[multi_idx]             diff = flat_diff[idx]             print(f""位置{multi_idx}: T1={t1_val}, T2={t2_val}, 差异={diff}"") if __name__ == ""__main__"":     reproduce_bug_89() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（float32张量理论上无数值异常）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 关键日志： ``` 使用GPU执行测试 开始测试... 运行测试 1/20...    最大差异: 1.887099027633667    找到更大差异: 1.887099027633667 运行测试 2/20...    最大差异: 0.0 运行测试 3/20...    最大差异: 1.887099027633667 运行测试 4/20...    最大差异: 0.0 运行测试 5/20...    最大差异: 0.0 运行测试 6/20...    最大差异: 0.9988986253738403 运行测试 7/20...    最大差异: 0.0 运行测试 8/20...    最大差异: 0.9992785453796387 运行测试 9/20...    最大差异: 0.0 运行测试 10/20...    最大差异: 0.0 运行测试 11/20...    最大差异: 0.0 运行测试 12/20...    最大差异: 0.0 运行测试 13/20...    最大差异: 2.076918991001939e+34    找到更大差异: 2.076918991001939e+34 运行测试 14/20...    最大差异: 1.401298464324817e45 运行测试 15/20...    最大差异: 0.0 运行测试 16/20...    最大差异: 0.0 运行测试 17/20...    最大差异: 0.0 运行测试 18/20...    最大差异: 0.0 运行测试 19/20...    最大差异: 0.0 运行测试 20/20...    最大差异: 8.307675964007756e+34    找到更大差异: 8.307675964007756e+34 发现最大差异: 8.307675964007756e+34 最大差异的输入: False 输出形状: T1 output: (1, 40, 45) T2 output: (1, 40, 45) T1模型全部输出: [[[  0.15907274  7.580059     0.52188027 ... 15.48713     9.2054405    11.224964  ]   [11.729143    3.7771134    8.080629   ...  1.5113018   7.324468      2.586268  ]   [ 14.780012     2.3860998    4.634448   ...  1.6547801  15.865764      4.9911203 ]   ...   [  4.4634485  17.511433     0.07383522 ...   0.34235862  16.161674     12.087488  ]   [17.683403     6.8514557    2.4379506  ...   2.619372     8.597782     3.781342  ]   [  4.584384     6.9862585    8.222437   ...  16.679749   13.328407     9.944683  ]]] T2模型全部输出: [[[ 1.5907274e01 8.0000000e+01 8.0000000e+01 ... 1.6000000e+01    6.4000000e+01 8.0000000e+01]   [ 4.0000000e+01  1.6000000e+01  3.2000000e+01 ... 5.6000000e+01    4.0000000e+01 5.6000000e+01]   [7.2000000e+01 6.4000000e+01 8.0000000e+00 ...  5.6000000e+01     8.0000000e+00  2.4000000e+01]   ...   [ 0.0000000e+00 4.1698099e+34  0.0000000e+00 ...  0.0000000e+00     0.0000000e+00  0.0000000e+00]   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00     0.0000000e+00  0.0000000e+00]   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0000000e+00    3.2000000e+01 1.2000000e+01]]] T1模型输出统计: 最小值: 19.995180130004883, 最大值: 18.989213943481445, 平均值: 0.6718649864196777 T2模型输出统计: 最小值: 8.307675964007756e+34, 最大值: 72.0, 平均值: 1.3863872322400244e+32 NaN值统计: T1=0, T2=0 Inf值统计: T1=0, T2=0 不匹配元素数量: 1799 / 1800 (99.94%) 差异最大的元素: 位置(0, 34, 6): T1=19.060710906982422, T2=8.307675964007756e+34, 差异=8.307675964007756e+34 位置(0, 34, 8): T1=10.265897750854492, T2=8.307674973655724e+34, 差异=8.307674973655724e+34 位置(0, 36, 44): T1=3.3512566089630127, T2=4.169809884390738e+34, 差异=4.169809884390738e+34 位置(0, 37, 1): T1=17.511432647705078, T2=4.169809884390738e+34, 差异=4.169809884390738e+34 位置(0, 9, 18): T1=18.924489974975586, T2=80.0, 差异=98.92449188232422 ```",2025-04-19T20:24:05+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IC2G2F
tinymonster123,[GPU]int16类型下等价模型整型张量输出不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上完全等价的int16类型模型在执行完全相同的算子链路（``argmax → maximum → equal → less → where``）时，输出结果出现严重不一致。具体表现为：  输入和常量均包含int16边界值（32768, 32767）  两模型输出形状一致，但有68.08%的元素不匹配  最大绝对差异高达32767  例如，位置(0, 0, 0, 43, 0) T1输出为0，T2输出为32767；位置(0, 0, 0, 43, 1) T1输出为100，T2输出为32768 理论上两个模型输出应完全一致，但实际有大量整型数值差异，且差异值覆盖int16全范围。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建两个模型 T1Model 和 T2Model，均执行算子序列：argmax → maximum → equal → less → where。 2. 输入张量和常量均为 int16，且包含边界值（32768, 32767）。 3. 观察到两个模型的输出结果存在严重差异： ``` 输出形状: (1, 48, 1, 61, 6) T1输出(部分): [[32768      0  32767]  [32768      0  32767]  [32768      0  32767]] T2输出(部分): [[32768      0  32767]  [32768      0  32767]  [32768      0  32767]] 不匹配元素: 11960/17568 (68.08%) 最大绝对差异: 32767 部分不匹配元素: 位置(0, 0, 0, 42, 5): T1=100, T2=0, 差异=100 位置(0, 0, 0, 43, 0): T1=0, T2=32767, 差异=32767 位置(0, 0, 0, 43, 1): T1=100, T2=32768, 差异=32868 位置(0, 0, 0, 43, 2): T1=32767, T2=0, 差异=32767 位置(0, 0, 0, 43, 3): T1=1000, T2=32767, 差异=31767 ``` 4. 预期结果是两个模型的输出应完全一致。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.constant = None   共享常量     def construct(self, x):          严格按照t1/model/graph.dot顺序执行          v3_0 > input x: i16[1, 48, 1, 1, 6]          v4_0 > constant: i16[1, 61, 1]         _ = ops.argmax(x, dim=1)                     ArgMax 操作: v3_0 > v6_0         maxed = ops.maximum(x, self.constant)        Max 操作: (v3_0, v4_0) > v5_0 [1, 48, 1, 61, 6]         _ = ops.equal(maxed, maxed)                  Equal 操作: (v5_0, v5_0) > v2_0         less = ops.less(maxed, maxed)                Less 操作: (v5_0, v5_0) > v1_0         out = ops.where(less, self.constant, self.constant)   Where操作: (v1_0, v4_0, v4_0) > v0_0         return out class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.constant = None   共享常量     def construct(self, x):          严格按照t2/model/graph.dot顺序执行          v0_0 > input x: i16[1, 48, 1, 1, 6]          v3_0 > constant: i16[1, 61, 1]         _ = ops.argmax(x, dim=1)                     ArgMax 操作: v0_0 > v1_0         maxed = ops.maximum(x, self.constant)        Max 操作: (v0_0, v3_0) > v4_0 [1, 48, 1, 61, 6]         _ = ops.equal(maxed, maxed)                  Equal 操作: (v4_0, v4_0) > v5_0         less = ops.less(maxed, maxed)                Less 操作: (v4_0, v4_0) > v7_0         out = ops.where(less, self.constant, self.constant)   Where操作: (v7_0, v3_0, v3_0) > v8_0         return out def main():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1 = T1Model()     t2 = T2Model()      严格按照graph.dot设置常量      i16[1, 61, 1]     const = ms.Tensor(np.array([32768, 0, 32767] * 20 + [0]).reshape(1, 61, 1).astype(np.int16))     t1.constant = const     t2.constant = const      严格按照graph.dot创建输入      i16[1, 48, 1, 1, 6]     input_data = []     for i in range(48):          创建有边界值的输入以更好地测试问题         input_data.extend([32768, 100, 0, 100, 32767, 1000])     x = ms.Tensor(np.array(input_data).reshape(1, 48, 1, 1, 6).astype(np.int16))      运行模型     y1 = t1(x)     y2 = t2(x)      结果分析     y1_np = y1.asnumpy()     y2_np = y2.asnumpy()      打印输出形状     print(""\n输出形状:"")     print(""T1输出:"", y1.shape)     print(""T2输出:"", y2.shape)      打印部分结果（第一层切片）     print(""\nT1模型输出(部分):"")     print(y1_np[0, 0, 0, :3, :3])     print(""\nT2模型输出(部分):"")     print(y2_np[0, 0, 0, :3, :3])      分析不一致     mismatched = (y1_np != y2_np)     mismatched_count = np.sum(mismatched)     total = y1_np.size     if mismatched_count > 0:         print(f""\n不匹配元素: {mismatched_count}/{total} ({100*mismatched_count/total:.2f}%)"")          计算差异         diff = np.abs(y1_np  y2_np)         max_diff = np.max(diff)         print(f""最大绝对差异: {max_diff}"")          输出前5个有差异的元素         indices = np.where(mismatched)         print(""\n部分不匹配元素:"")         for i in range(min(5, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={y1_np[idx]}, T2={y2_np[idx]}, 差异={abs(int(y1_np[idx])int(y2_np[idx]))}"")     else:         print(""\n输出完全一致"") if __name__ == ""__main__"":     main() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:21:49+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G2B,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
XuefengJin,set_ps_context的接口应该标识将被废止？,https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/mindspore.set_ps_context.htmlmindspore.set_ps_context,2025-04-19T11:29:18+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IC2DKX,已添加，网页明日更新
XuefengJin,get_context的接口是否应该标识要废止,https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/mindspore.get_context.htmlmindspore.get_context,2025-04-19T11:26:23+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IC2DHM,已添加，网页明日更新
XuefengJin,"device_target (str)  要运行的目标设备，仅支持 ""Ascend"" 、 ""GPU"" 和 ""CPU""。","https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/mindspore.set_device.htmlmindspore.set_device device_target (str)  要运行的目标设备，仅支持 ""Ascend"" 、 ""GPU"" 和 ""CPU""。 如果是第三方设备，怎么办，挂靠到ascend/gpu/cpu下面",2025-04-19T11:22:07+08:00,,progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IC2DGN,第三方设备感觉新增device_target更好一点，然后通过device_context实现硬件相关接口，包括第三方设备的算子kernelmod和实现，通过指定device_target选择指定的三方设备和算子
XuefengJin,jit的接口文档的样例中，建议增加print,https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/mindspore.jit.htmlmindspore.jit,2025-04-19T10:49:39+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2D69
虞良斌,Modify the description of the MemoryUB parameter deliverables,,2025-04-18T15:57:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC28SK
majun-bot,CVE20241394,"一、漏洞信息 漏洞编号：CVE20241394 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： A memory leak flaw was found in Golang in the RSA encrypting/decrypting code, which might lead to a resource exhaustion vulnerability using attackercontrolled inputs​. The memory leak happens in github.com/golangfips/openssl/openssl/rsa.goL113. The objects leaked are pkey​ and ctx​. That function uses named return parameters to free pkey​ and ctx​ if there is an error initializing the context or setting the different properties. All return statements related to error cases follow the ""return nil, nil, fail(...)"" pattern, meaning that pkey​ and ctx​ will be nil inside the deferred function that should free them. 漏洞公开时间：20240321 21:00:08 漏洞创建时间：20250418 10:55:20 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20241394 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 在RSA加密/解密代码中的Golang中发现了一个内存泄漏漏洞，这可能会导致使用攻击者控制的输入的资源耗尽漏洞。内存泄漏发生在github.com/Golangfips/openssl/openssl/RSA.goL113中。泄漏的对象是pkey和ctx。如果初始化上下文或设置不同属性时出错，该函数将使用命名返回参数释放pkey和ctx。所有与错误情况相关的return语句都遵循“returnnil，nil，fail（…）”模式，这意味着pkey和ctx在应该释放它们的deferred函数内将为nil。 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响",2025-04-18T10:55:21+08:00,"gitee,github,CVE/UNAFFECTED",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IC24N0,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明:在RSA加密/解密代码中的Golang中发现了一个内存泄漏漏洞，这可能会导致使用攻击者控制的输入的资源耗尽漏洞。内存泄漏发生在github.com/Golang fips/openssl/openssl/RSA.goL113中。泄漏的对象是pkey和ctx。如果初始化上下文或设置不同属性时出错，该函数将使用命名返回参数释放pkey和ctx。所有与错误情况相关的return语句都遵循“return nil，nil，fail（…）”模式，这意味着pkey和ctx在应该释放它们的deferred函数内将为nil。 漏洞评分(mindspore评分): BaseScore: 7.5 Vector:CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", Appearance & Root Cause 漏洞：CVE20241394 归属组件应为 golangfips， 非openssl代码漏洞，此漏洞单漏洞归属组件有误（patch链接：https://github.com/golangfips/openssl/commit/85d31d0d257ce842c8a1e63c4d230ae850348136） mindspore 未引入golangfips组件，因此不涉及 CVE20241394 漏洞  Fix Solution mindspore不受影响，无需修复。
zhanghanLeo,cherrypick some code from br_infer_deepseek_os to master,,2025-04-17T22:39:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC21M6
zhanghanLeo,update ms_kernels_internal.tar.gz and ms_kernels_dependency.tar.gz for br_infer_deepseek_os,,2025-04-17T18:00:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC201E
何鑫,"Atlas 800T a2 B3通过Mindyolo训练模型后转onnx/mindir，无法转成ms ，报错,同时mindir无法实现推理","  1.Describe the current behavior / 问题描述 (Mandatory / 必填) 910 B3 通过Mindyolo训练模型后转onnx/mindir，无法转成ms ，报错,同时mindir无法实现推理  2.Environment / 环境信息 (Mandatory / 必填)   样例：   4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) Mindspore安装参考：https://www.mindspore.cn/install/ 端侧模型转换参考：https://mindspore.cn/lite/docs/zhCN/r2.5.0/converter/vonverter_tool.html mindsporelite安装参考：mindspore.cn/versions/cn 代码一尝试Modelmaster： https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv5/README_CN.md%E6%95%B0%E6%8D%AE%E9%9B%86 代码二尝试mindyolo:github.com/mindsporelab/mindyolo/tree/v0.5.0  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 将训练得到的ckpt文件，导出为Onnx/mindir后，通过mindsporelite2.3.1linuxaarch64/tools/converter/.converter_lite 虚拟环境下执行：./converter_lite fmk=ONNX modelFile=/home/hwx1410890/ms/mindspore/mindsporelite2.5.0linuxaarch64/tools/converter/converter/yolov5.onnx outputFile=model         上述示例代码得到的是model.mindir,期望得到.ms文件，并部署鸿蒙端  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !报错日志 !报错日志 !报错日志    7.Special notes for this issue/备注 (Optional / 选填) 已尝试Mindsporelite2.2.14/2.3.0/2.3.1/2.5.0/（这三个版本是mindyolo官方给出的已经验证过的可支持的版本），均未成功转换和推理 **【定位人】**吴逸群（根据实际修改）",2025-04-17T10:58:59+08:00,"www,www,www,foruda",open,0,15,https://gitee.com/mindspore/mindspore/issues/IC1TE9,!输入图片说明 官方仓库里说的是这三个版本验证过mindir的推理，没有提到ms格式和2.5.0版本，ms的兼容比较有限，2.5可能也有问题； 我之前试过2.2.14版本在昇腾环境下的mindir推理是没问题的，cann版本是7.0，cann版本需要匹配，否则肯定出错；2.3我没亲自试过，不确定具体情况 至于其它操作，比如导出onnx然后再转om推理，2.2.14环境下我也试过，部分模型可以，有些模型调用的算子不支持直接导出onnx，可能需要等价替换，比如silu算子； 导出mindir再转om推理，我在2.2.14环境下试下来基本没问题，不过这个不是官方已正式发布版本的功能，喜欢倒腾的话可以试试； 至于转ms格式我没在昇腾环境试过，ms是端侧推理的格式，昇腾环境官方推荐使用云测推理方式，也就是mindir的格式推理，如果使用端侧的话，确实会有很多不支持的，端侧相比云测，支持的算子也要少很多；,!模型转换,!版本适配、 2.2.14/2.3.0/2.3.1跟Mindyolo的代码版本都不匹配啊,其实用个最接近的版本就可以了，比如0.3用2.2.14，或者用mindyolo 0.4在mindspore 2.2.14上跑也是可以的，就是有些api的参数变了不兼容，手动改一下变的那些地方适配下就可以了,"端侧转换工具生成的是.ms格式，一般就是在手机或者嵌入式设备上用的；云测转换工具生成的就是mindir,服务器环境，或者只要是昇腾的环境，都推荐用云测","2.3是怎么通的？ (ms1) hwx1410890:~/ms1/mindyolo$ python train.py /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) Traceback (most recent call last):   File ""/home/hwx1410890/ms1/mindyolo/train.py"", line 336, in      train(args)   File ""/home/hwx1410890/ms1/mindyolo/train.py"", line 94, in train     set_default(args)   File ""/home/hwx1410890/ms1/mindyolo/mindyolo/utils/utils.py"", line 25, in set_default     ms.set_recursion_limit(args.max_call_depth) AttributeError: module 'mindspore' has no attribute 'set_recursion_limit' !报错 代码是Mindyolov0.4,!AttributeError: module 'mindspore' has no attribute 'set_recursion_limit'",那为什么在GPU服务器上转ms可以,LSB Version:    :core4.1amd64:core4.1noarch Distributor ID: CentOS Description:    CentOS Linux release 7.9.2009 (Core) Release:        7.9.2009 Codename:       Core 这个GPU有区分？一个默认mindir一个默认Ms？,应该是你GPU服务器上安装了端侧的那个工具包吧？我自己的GPU环境一样可以转mindir,"是分端侧工具和云测工具包的，端侧就是转成ms的，云测工具包转mindir;但你要安装哪个都是可以安装的，通常转成来的ms文件就是在端侧推理，比如手机上推理；云测工具转出来的mindir,通常就是在昇腾环境，或者其它服务器上推理",默认值我不太清楚，我自己的GPU环境装的云测工具，默认转的就是mindir,这个api 2.5.0才有的，可能里面不同分支的代码混了吧，跑不起来直接删掉也没问题，不影响具体的模型逻辑,通过文档可以看到，云测和端侧的工具是两个包，长得有点像，转换工具的用法基本也差不多，可能容易搞混： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/use/downloads.html !输入图片说明 这个是云测转换的工具文档： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/mindir/converter_tool.html !输入图片说明 这个是端侧转换工具的文档： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/converter/converter_tool.html !输入图片说明,"将训练得到的ckpt文件，导出为Onnx/mindir后，通过mindsporelite2.3.1linuxaarch64/tools/converter/.converter_lite 虚拟环境下执行：./converter_lite fmk=ONNX modelFile=/home/hwx1410890/ms/mindspore/mindsporelite2.5.0linuxaarch64/tools/converter/converter/yolov5.onnx outputFile=model 上述示例代码得到的是model.mindir,期望得到.ms文件，并部署鸿蒙端 针对这个问题，可以参考mindspore lite官网教程解决，参考链接：https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/converter/converter_tool.html 此外，还需要注意mindspore lite版本包下载的来源，需要下载端上版本进行模型转换，不要使用云上版本进行模型转换；端上版本会默认生成ms的模型，云上版本默认生成.midnir的模型，详细的可以参考上面提供的mindspore的官网链接","onnx>ms (ms) hwx1410890:~/ms/minds/mindsporelite2.5.0linuxaarch64/tools/converter/converter$ ./converter_lite fmk=ONNX modelFile=model.onnx outputFile=model ERROR [mindspore/lite/src/common/file_utils.cc:230] RealPath] file path not exists: model.onnx [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.203 [mindspore/lite/tools/common/protobuf_utils.cc:82] ReadProtoFromBinaryFile] Binary proto file path model.onnx is not valid [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.240 [mindspore/lite/tools/converter/parser/onnx/onnx_model_parser.cc:717] InitOriginModel] Read onnx model file failed, model path: model.onnx [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.261 [mindspore/lite/tools/converter/parser/onnx/onnx_model_parser.cc:665] Parse] init origin model failed. [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.282 [mindspore/lite/tools/converter/converter_funcgraph.cc:106] Load3rdModelToFuncgraph] Get funcGraph failed for fmk: 2 [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.295 [mindspore/lite/tools/converter/converter_funcgraph.cc:186] Build] Load model file failed! [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.306 [mindspore/lite/tools/converter/converter.cc:1196] HandleGraphCommon] Build func graph failed [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.324 [mindspore/lite/tools/converter/converter.cc:1152] Convert] Handle graph failed: 1 Common error code. [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.337 [mindspore/lite/tools/converter/converter.cc:1344] RunConverter] Convert model failed [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.351 [mindspore/lite/tools/converter/cxx_api/converter.cc:374] Convert] Convert model failed, ret=Common error code. ERROR [mindspore/lite/tools/converter/converter_lite/main.cc:104] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code. (ms) hwx1410890:~/ms/minds/mindsporelite2.5.0linuxaarch64/tools/converter/converter$ ./converter_lite fmk=ONNX modelFile=yolov5.onnx outputFile=model [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.341.855 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.341.917 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.342.116 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.350.698 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.350.732 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.350.816 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.374.281 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.374.316 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.374.400 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.274 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.307 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.542 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.557 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.389.387 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.389.420 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.389.504 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.340 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.372 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.450 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.500 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.404.308 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.404.341 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.404.423 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.242 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.275 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.352 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.367 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.419.178 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.419.211 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.419.294 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.102 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.135 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.210 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.224 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.434.027 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.434.072 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.434.214 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.062 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.096 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.187 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.202 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.448.966 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.448.998 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.449.079 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.455.891 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.456.018 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.456.099 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.456.113 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.463.884 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.463.917 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.463.999 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.854 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.888 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.965 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.980 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.478.752 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.478.782 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.478.905 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.747 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.780 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.858 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.872 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.493.674 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.493.707 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.493.789 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.602 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.636 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.712 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.726 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.508.519 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.508.553 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.508.635 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.476 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.508 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.584 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.599 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.523.385 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.523.417 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.523.499 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.355 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.391 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.467 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.482 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.538.258 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.538.289 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.538.371 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.192 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.522 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.603 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.617 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.553.377 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.553.664 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.553.750 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.563 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.596 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.673 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.687 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.568.473 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.568.505 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.568.587 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.442 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.474 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.550 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.564 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.583.687 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.584.005 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.584.092 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.625.472 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.625.507 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.625.569 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.278 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.332 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.375 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.389 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.326 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.397 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.439 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.456 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.898.684 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.898.757 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.898.799 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.899.014 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.216 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.356 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.397 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.412 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.498 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.817 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.859 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.874 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.118.998 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.119.035 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.119.073 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.119.158 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.253 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.288 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.326 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.341 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.469 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.504 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.541 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.742 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.338.968 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.339.004 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.339.042 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.339.056 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.278 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.423 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.462 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.476 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.383 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.461 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.505 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.521 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.280 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.319 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.531 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.545 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.189 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.227 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.266 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.281 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.716.998 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.717.037 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.717.077 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.717.092 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.750.702 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.750.739 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.750.774 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.004 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.042 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.078 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.838 [mindspore/lite/tools/common/graph_util.cc:145] GetShapeVectorAndIdxFromCNode] Shape is empty 299Concat [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.906 [mindspore/lite/tools/common/graph_util.cc:145] GetShapeVectorAndIdxFromCNode] Shape is empty 323Concat [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.927 [mindspore/lite/tools/common/graph_util.cc:145] GetShapeVectorAndIdxFromCNode] Shape is empty 347Concat [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.246 [mindspore/lite/tools/converter/legacy_optimizer/graph/infershape_pass.cc:633] InferSubgraph] InferShape failed, name: 12Conv, type: Conv2DFusion [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.321 [mindspore/lite/tools/converter/legacy_optimizer/graph/infershape_pass.cc:650] Run] InferSubgraph index: 0 failed, ret: 500 [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.583 [mindspore/lite/tools/converter/optimizer.cc:78] Run] Run GraphPass failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.597 [mindspore/lite/tools/converter/graphdef_transform.cc:71] QuantTransform] Run quant_node_optimizer graphPasses Failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.667 [mindspore/lite/tools/converter/converter_metagraph.cc:102] Build] Transform meta graph failed!ret = 500 [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.321 [mindspore/lite/tools/converter/converter.cc:1259] SaveGraph] Convert to meta graph failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.364 [mindspore/lite/tools/converter/converter.cc:1212] HandleGraphCommon] Save graph failed: 1 Common error code. [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.385 [mindspore/lite/tools/converter/converter.cc:1152] Convert] Handle graph failed: 1 Common error code. [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.399 [mindspore/lite/tools/converter/converter.cc:1344] RunConverter] Convert model failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.423 [mindspore/lite/tools/converter/cxx_api/converter.cc:374] Convert] Convert model failed, ret=Common error code. ERROR [mindspore/lite/tools/converter/converter_lite/main.cc:104] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code. MINDIR>ms !报错"
liuhang105107,GLMZ132B0414 模型910B3环境测试通过后迁移到910B2环境报错 Failed to initialize LcCL group hccl_world_group," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) GLMZ132B0414 模型910B3环境测试通过后迁移到910B2环境报错 Failed to initialize LcCL group hccl_world_group,  2.Environment / 环境信息    >  **Excute Mode / 执行模式 (Mandatory / 必填)**: MindIE 服务化 >  **权重文件名字和路径 (Mandatory / 选填)**: GLMZ132B0414  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：参照魔乐社区文档进行部署 https://mp.weixin.qq.com/s/9cP2YLepEmpxKZpsOkkHjg  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：GLMZ132B0414在 910B2环境中推理服务正常启动",2025-04-16T21:38:03+08:00,"www,www,www,foruda,foruda,mindspore-assistant",progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IC1Q77,这个错误一般是多卡环境没配置好导致的；910b3和910b2都属于atlas a2训练系列产品，照理说是环境兼容性是一模一样的，可以先确认下有没有哪里配置不一样；比如是不是有什么rank_table之类的配置有差异？或者cann版本、驱动版本、框架版本的差异？还有多卡通信需要走端口号，看看会不会某些端口号在特定的机器上走不通？昇腾的docker是把物理机上的驱动等一些配置映射进容器的，确认下映射的那些目录是否都相同 你这边具体用到了mindie引擎进行推理，如果是mindie问题的话，建议查看下mindie的配置文档： https://www.hiascend.com/software/mindie 或者也可以直接拉取官方的mindie镜像，如果你目前用的镜像确定没有问题的话就不用管这个了（拉去镜像可能需要申请，一般手上有昇腾服务器或者其它昇腾设别的都可以申请到， 910b系列的用800i a2的镜像就可以）： https://www.hiascend.com/developer/download/community/result?module=ie+pt+cann !输入图片说明 !输入图片说明 也可以到昇腾社区论坛的mindie板块下进行咨询相关问题： https://www.hiascend.com/forum/forum01861567569004130641.html
zhangshucheng,TH unpad,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-04-16T10:54:46+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC1IK3
zhanghanLeo,将br_infer_hopeop代码cherrypick到br_infer_deepseek_os,,2025-04-15T22:01:41+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC1FSQ
caifubi,开memtracker进程卡死,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-15T20:25:51+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC1F98
wangyibo,msadapter用例报错,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  msadapter用例报错  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-15T17:45:53+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC1E1L
looop5,dvm动态图精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-04-15T10:21:18+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC16PU,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE20253277,"一、漏洞信息 漏洞编号：CVE20253277 漏洞归属组件：sqlite, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.36.0 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： An integer overflow can be triggered in SQLite’s `concat_ws()` function. The resulting, truncated integer is then used to allocate a buffer. When SQLite then writes the resulting string to the buffer, it uses the original, untruncated size and thus a wild Heap Buffer overflow of size ~4GB can be triggered. This can result in arbitrary code execution. 漏洞公开时间：20250415 01:15:27 漏洞创建时间：20250415 01:27:40 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20253277 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： SQLite的`concat_ws()`函数中可能触发整数溢出。截断后的整数随后会用于分配缓冲区。当SQLite将结果字符串写入缓冲区时，它会使用原始的、未截断的大小，从而触发大小约为4GB的堆缓冲区溢出。这可能导致任意代码执行。 其他分支生命周期结束。不在合入。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.9 &emsp;Vector： CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:L/VA:L/SC:L/SI:L/SA:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-04-15T01:27:41+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/FIXED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IC14UM,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： SQLite 的 `concat_ws()` 函数中可能触发整数溢出。截断后的整数随后会用于分配缓冲区。当 SQLite 将结果字符串写入缓冲区时，它会使用原始的、未截断的大小，从而触发大小约为 4GB 的堆缓冲区溢出。这可能导致任意代码执行。 其他分支生命周期结束。不在合入。2.3分支上的sqlite为3.36.0，该漏洞在这个版本不存在。 漏洞评分(MindSpore评分):  BaseScore：6.9 MEDIUM  Vector：CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:L/VA:L/SC:L/SI:L/SA:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：sqlite软件漏洞 根因： SQLite 的 `concat_ws()` 函数中可能触发整数溢出。截断后的整数随后会用于分配缓冲区。当 SQLite 将结果字符串写入缓冲区时，它会使用原始的、未截断的大小，从而触发大小约为 4GB 的堆缓冲区溢出。这可能导致任意代码执行。 Fix Solution 已经修复：https://gitee.com/mindspore/mindspore/pulls/84285 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不涉及 Introduction Analysis 引入类型：其他，三方库漏洞 引入PR：无 PR合入时间：无 问题是否偶现：否,开发已修复问题：https://gitee.com/mindspore/mindspore/pulls/84285 ，关闭问题单
zhangbuxue,fixed random seed,,2025-04-14T15:36:20+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC0ZWF
张泰来,mindspore.mint.optim.AdamW优化器在params参数下输入列表等对象时报错有误," 1.问题描述 mindspore.mint.optim.AdamW优化器在params参数下输入列表、字典、元组时报错有误。  2.环境信息  **硬件环境**:   3.重现步骤  (1) 测试代码 ```python import torch import mindspore as ms import numpy as np import pytest .mark.parametrize('mode', ['List', 'Dict', 'Tuple']) def test_chaotic_input(mode):     """"""     (1d) 测试随机混乱输入，报错信息的准确性     """"""      测试输入为列表的情况     if mode == 'List':         reported_flag = False         try:             optimizer = ms.mint.optim.AdamW(params=[1, 2, 3, 4, 5])         except Exception as e:             reported_flag = True             e = str(e)             assert 'List' in e             print(e)         if reported_flag == False:             assert ""No error message was reported when the input is List."" == 1      测试问题：报错存在异常: can only concatenate str (not ""type"") to str      测试输入为字典的情况     if mode == 'Dict':         reported_flag = False         try:             optimizer = ms.mint.optim.AdamW(params={""a"":1, ""b"":2})         except Exception as e:             reported_flag = True             e = str(e)             assert 'Dict' in e             print(e)         if reported_flag == False:             assert ""No error message was reported when the input is Dict."" == 1      测试问题：报错存在异常: can only concatenate str (not ""type"") to str      测试输入为元祖的情况     if mode == 'Tuple':         reported_flag = False         try:             optimizer = ms.mint.optim.AdamW(params=(1, 2, 3))         except Exception as e:             reported_flag = True             e = str(e)             assert 'Tuple' in e             print(e)         if reported_flag == False:             assert ""No error message was reported when the input is Tuple."" == 1      测试问题：报错存在异常: can only concatenate str (not ""type"") to str ``` 将以上代码保存为test_AdamW.py文件 （2）执行代码 在终端内进入test_AdamW.py所在的目录下，输入pytest sv test_AdamW.py命令即可查看测试结果  4.预期结果 mindspore.mint.optim.AdamW优化器在params参数下输入列表、字典、元组时出现的异常应该为输入参数类型不正确。  5.截图  报错关键信息： !输入图片说明 !输入图片说明  6.备注 **【定位人】** 张泰来",2025-04-12T16:52:36+08:00,mindspore-assistant,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IC0MMD
张泰来,mindspore.mint.linalg.inv接口在输入张量为奇异矩阵时不报错," 1.问题描述 mindspore.mint.linalg.inv接口在输入张量为奇异矩阵时不报错，而它所对应的pytorch框架下的torch.linalg.inv接口输入奇异矩阵会引发报错。  2.环境信息  **硬件环境**:   3.代码及运行结果截图 (1) mindspore框架下代码及截图 ```python import torch import mindspore as ms import numpy as np import pytest def test_random_input():     """"""     (1d) 测试混乱输入     """"""      测试输入矩阵奇异矩阵     input_ms = ms.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=ms.float32)     reported_flag = False     try:         output_ms = ms.mint.linalg.inv(input_ms)         print(output_ms)     except Exception as e:         reported_flag = True         e = str(e)         assert ""singular"" in e     if reported_flag == False:         assert ""No error message was reported when the input is singular matrix."" == 1 ```  对应测试截图如下： !输入图片说明 上图中的报错是通过assert手动引发的。 （2）pytorch框架下代码及截图 ```python import torch input_pt = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32) output_pt = torch.linalg.inv(input_pt) print(output_pt) ```  对应测试截图如下： !输入图片说明 pytorch框架下对应接口输入奇异矩阵自动引起报错。  4.预期结果 mindspore.mint.linalg.inv接口在输入矩阵为奇异矩阵时应当引发报错  5.备注 **【定位人】** 张泰来",2025-04-12T16:37:54+08:00,mindspore-assistant,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IC0MJI
张泰来,mindspore.mint.nn.functional.pad在选择circular模式的情况下执行时引起启动内核失败," 1.问题描述 mindspore.mint.nn.functional.pad接口在输入浮点数类型张量，且选择circular模式的情况下执行时会出现启动内核失败的问题  2.环境信息  **硬件环境**:   3.重现步骤  (1) 测试代码 ```python import torch import mindspore as ms import numpy as np import pytest .mark.parametrize('mode', ['constant', 'reflect', 'replicate', 'circular']) def test_modes(mode):     """"""     (1c) 测试不同的模式     """"""     data_lst = [[1.1, 1.2, 1.3, 1.4], [1.5, 1.6, 1.7, 1.8]]     input_pt = torch.tensor(data_lst, dtype=torch.float32)     input_ms = ms.tensor(data_lst, dtype=ms.float32)     if mode == 'constant':         output_pt = torch.nn.functional.pad(input_pt, (2, 2), mode, 1.2)         output_ms = ms.mint.nn.functional.pad(input_ms, [2, 2], mode, 1.2)     else:         output_pt = torch.nn.functional.pad(input_pt, (2, 2), mode)         output_ms = ms.mint.nn.functional.pad(input_ms, [2, 2], mode)      测试问题： 浮点类型的张量 执行circular模式下的这一函数会出现启动内核失败的问题     assert np.allclose(output_pt.numpy(), output_ms.numpy(), rtol=1e3) ``` 将以上代码保存为test_pad.py文件 （2）执行代码 在终端内进入test_pad.py所在的目录下，输入pytest sv test_pad.py命令即可查看测试结果  4.预期结果 > **【预期结果】**：mindspore.mint.nn.functional.pad接口在circular模式可以正常对张量进行填充  5.截图  报错关键日志截图： !输入图片说明  6.备注 **【定位人】** 张泰来",2025-04-12T16:19:50+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC0MEW,您好，问题已收到，已确认此版本CANN还未支持Pad在circular模式下的全部功能。 当前MindSpore已有计划在Q2对此进行能力补齐。
caifubi,Event queue的同步操作导致精度问题,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-04-11T16:28:42+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC0GA7
majun-bot,CVE202529088,"一、漏洞信息 漏洞编号：CVE202529088 漏洞归属组件：sqlite, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.36.0 CVSS分值： &emsp;BaseScore： 5.6 Medium &emsp;Vector： CVSS:3.1/AV:L/AC:H/PR:N/UI:N/S:C/C:L/I:L/A:L 漏洞简述： In SQLite 3.49.0 before 3.49.1, certain argument values to sqlite3_db_config (in the Clanguage API) can cause a denial of service (application crash). An sz*nBig multiplication is not cast to a 64bit integer, and consequently some memory allocations may be incorrect. 漏洞公开时间：20250410 22:15:27 漏洞创建时间：20250410 22:32:40 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202529088 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： sqlitev.3.49.0中存在一个问题，允许攻击者通过SQLITE_DBCONFIG_LOOKASIDE组件造成拒绝服务 其余分支生命周期已经结束。 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:受影响",2025-04-10T22:32:41+08:00,"gitee,CVE/FIXED",closed,0,8,https://gitee.com/mindspore/mindspore/issues/IC06WG,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： sqlite v.3.49.0 中存在一个问题，允许攻击者通过 SQLITE_DBCONFIG_LOOKASIDE 组件造成拒绝服务 漏洞评分(MindSpore评分):  BaseScore：7.5 HIGH  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:受影响 3.r1.9:受影响 4.r2.0:受影响 5.r2.1:受影响 6.r2.2:受影响 7.r2.3:受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：sqlite漏洞 根因： sqlite v.3.49.0 中存在一个问题，允许攻击者通过 SQLITE_DBCONFIG_LOOKASIDE 组件造成拒绝服务 Fix Solution 已经修复 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不涉及 Introduction Analysis 不涉及,影响性分析说明： sqlite v.3.49.0 中存在一个问题，允许攻击者通过 SQLITE_DBCONFIG_LOOKASIDE 组件造成拒绝服务 其余分支生命周期已经结束。 漏洞评分(MindSpore评分):  BaseScore：7.5 HIGH  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",开发已修复问题，关闭问题单，其余版本生命周期都已经结束，无需合入,分支 [r2.3] 未检测到关联PR合入，无法关闭issue，关联PR合入后再重试
kakyo82,cleancode告警清理,cleancode告警清理,2025-04-09T16:23:47+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBZRNI
李尚憬,启智社区CANN 8.0 Mindspore镜像run_check()错误,启智社区CANN8的mindspore镜像运行run_check()时报错 这是安装2.5.0版本的错误报告 !输入图片说明 这是原装的2.3.0版本的错误报告 !输入图片说明 这个错误我们能手动解决吗，还是CANN版本本身就不匹配。如果不能自己解决又该联系谁呢  有问题的镜像是这个 !输入图片说明 CANN7.0 Mindspore2.2.0的镜像没出过问题，就是装不了高版本mindspore,2025-04-09T09:04:54+08:00,foruda,closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBZKMR,启智的镜像有点问题，看这报错应该是缺了kernels算子包，你选择对应cann版本和芯片型号的kernels算子包装一下试试看； 下面这个是我之前用的一个镜像，里面就是缺了sympy和te包，需要手动装，否则运行不起来，直接报GE错误： !输入图片说明 我截图里的这个镜像pandas库也有版本冲突的问题，安装mindnlp的话我都是卸载pandas库然后重新装的，不然mindnlp都装不上,2.3.0在cann 8.0.beta1上应该是运行不了的，要用2.5.0，如果是缺少了我上面提到的sympy和te包可以自己装，kernels包其实也可以自己下载安装，但可能涉及到权限问题，自己搞定不了的话就得向启智社区反馈了,kernel包要root不然装不上，我当时装2.5.0的时候也是按官网教程来的，重装hccl和sympy什么的，但还是用不了，会报上面我截图那个错误。估计是kernel的问题，要让启智那边调一下,我刚试了下，在默认的环境里直接装mindspore2.5.0可以运行，不要切换到那个MindSpore的conda虚拟环境里去： !输入图片说明 直接官网的pip命令运行就可以，不用再去装其它依赖包； 那个MindSpore虚拟环境可能是环境变量不对，导致找不到算子二进制,好的感谢
majun-bot,CVE20253416,"一、漏洞信息 漏洞编号：CVE20253416 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 3.7 Low &emsp;Vector： CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:L 漏洞简述： A flaw was found in OpenSSL's handling of the properties argument in certain functions. This vulnerability can allow useafterfree exploitation, which may result in undefined behavior or incorrect property parsing, leading to OpenSSL treating the input as an empty string. 漏洞公开时间：20250409 03:15:53 漏洞创建时间：20250409 03:46:32 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20253416 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore： 0.0 &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-09T03:46:32+08:00,"gitee,CVE/UNFIXED",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBZK5T,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
gupengcheng0401,mindspore lite交叉编译开源25b ANDROID NDK报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > x86_64机器，CPU环境master分支交叉编译开源25b版本ANDROID NDK报错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：mindspore lite交叉编译成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image !报错截图 !报错相对loss误差 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】gupengcheng0401（根据实际修改）",2025-04-08T23:02:54+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBZJXG
徐微,[GPU]float16精度下where算子与内存布局交互导致(等价模型)计算不一致,"   1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下使用float16数据类型时，两个数学上等价的模型仅因where算子操作顺序和内存布局差异而产生完全不同的结果。 具体来说，当where算子与标量广播结合使用，且涉及不同的内存布局（如通过concat+split操作改变）时，会产生高达56.7%的元素不匹配，有些区域计算结果完全不同（如全变为0）。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果： ```python import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops import numpy as np class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.v2_0 = ms.Tensor(np.array([1.0], dtype=np.float16))     def construct(self, v3_0, v1_0):         v7_0 = ops.squeeze(self.v2_0)              core.Squeeze(dim=0)         v8_0 = ops.relu(v3_0)                      core.ReLU         v0_0 = ops.tan(v7_0)                       core.Tan         v6_0 = ops.transpose(v8_0, (0, 2, 1))      core.Transpose         v4_0 = ops.where(v1_0, v6_0, v7_0)         core.Where         v5_0 = ops.reshape(v4_0, v4_0.shape)       core.Reshape         return v5_0   返回v5_0作为最终输出 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.v5_0 = ms.Tensor(np.array([1.0], dtype=np.float16))     def construct(self, v0_0, v10_0):         v1_0 = ops.relu(v0_0)                       core.ReLU         v2_0 = ops.transpose(v1_0, (0, 2, 1))       core.Transpose         v3_0 = ops.concat((v2_0, v2_0), axis=1)     Concat {'axis'= 1}         v4_0 = ops.concat((v3_0, v3_0), axis=1)     Concat {'axis'= 1}         v6_0 = ops.squeeze(self.v5_0)               core.Squeeze(dim=0)         v7_0 = ops.tan(v6_0)                        core.Tan         v9_0, _ = ops.split(v3_0, v3_0.shape[1] // 2, axis=1)           v11_0 = ops.where(v10_0, v9_0, v6_0)        core.Where         v12_0 = ops.reshape(v11_0, v11_0.shape)     core.Reshape         return v12_0   返回v12_0作为最终输出 def reproduce_bug():     t1_model = T1Model()     t2_model = T2Model()     np.random.seed(42)     small_shape = (1, 5, 6)     v3_0_t1 = ms.Tensor(np.random.uniform(100, 100, small_shape).astype(np.float16))     v1_0_t1 = ms.Tensor(np.random.choice([True, False], size=(1, 1, 5)))     v0_0_t2 = v3_0_t1     v10_0_t2 = v1_0_t1     max_diff_overall = 0     max_run = 5       for run in range(max_run):         if run > 0:             v3_0_t1 = ms.Tensor(np.random.uniform(100, 100, small_shape).astype(np.float16))             v1_0_t1 = ms.Tensor(np.random.choice([True, False], size=(1, 1, 5)))             v0_0_t2 = v3_0_t1             v10_0_t2 = v1_0_t1         t1_output = t1_model(v3_0_t1, v1_0_t1)         t2_output = t2_model(v0_0_t2, v10_0_t2)         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         current_max_diff = np.max(abs_diff)         if current_max_diff > max_diff_overall:             max_diff_overall = current_max_diff             best_t1_output = t1_output             best_t2_output = t2_output             best_input = v3_0_t1             best_mask = v1_0_t1     t1_output = best_t1_output     t2_output = best_t2_output     print(""\n输出形状:"")     print(""T1 v5_0:"", t1_output.shape)     print(""T2 v12_0:"", t2_output.shape)      打印完整输出值     print(""\nT1模型输出:"")     print(t1_output.asnumpy()[0])     print(""\nT2模型输出:"")     print(t2_output.asnumpy()[0])     if np.allclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0):         print(""\n输出一致"")     else:         mismatched = ~np.isclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0)         mismatched_count = np.sum(mismatched)         total_elements = t1_output.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(""\n不匹配元素数量: {} / {} ({:.1f}%)"".format(             mismatched_count, total_elements, mismatch_percentage)) if __name__ == ""__main__"":     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")   使用GPU设备以便复现     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应该一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: !输入图片说明",2025-04-08T22:36:45+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBZJV8,应该是where算子的问题，GPU上我测试下来， 2.2.14是正确的，从2.3版本开始就有问题了；前段时间调试mindnlp里面的whisper模型，用的2.5.0的版本，发现在香橙派的310b上，两个地方调用where算子的结果都不对
majun-bot,CVE202531498,"一、漏洞信息 漏洞编号：CVE202531498 漏洞归属组件：cares, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1_19_1 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： cares is an asynchronous resolver library. From 1.32.3 through 1.34.4, there is a useafterfree in read_answers() when process_answer() may reenqueue a query either due to a DNS Cookie Failure or when the upstream server does not properly support EDNS, or possibly on TCP queries if the remote closed the connection immediately after a response. If there was an issue trying to put that new transaction on the wire, it would close the connection handle, but read_answers() was still expecting the connection handle to be available to possibly dequeue other responses. In theory a remote attacker might be able to trigger this by flooding the target with ICMP UNREACHABLE packets if they also control the upstream nameserver and can return a result with one of those conditions, this has been untested. Otherwise only a local attacker might be able to change system behavior to make send()/write() return a failure condition. This vulnerability is fixed in 1.34.5. 漏洞公开时间：20250408 22:15:35 漏洞创建时间：20250408 22:31:34 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202531498 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 改漏洞是1.32.3到1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 8.3 &emsp;Vector： CVSS:4.0/AV:N/AC:H/AT:N/PR:N/UI:N/VC:L/VI:L/VA:H/SC:N/SI:N/SA:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-04-08T22:31:34+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBZJTC,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明: 改漏洞是1.32.3 到 1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。 漏洞评分(mindspore评分): BaseScore: 8.3 HIGH Vector:CVSS:4.0/AV:N/AC:H/AT:N/PR:N/UI:N/VC:L/VI:L/VA:H/SC:N/SI:N/SA:N 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：cares漏洞 根因： 改漏洞是1.32.3 到 1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。 Fix Solution 不涉及 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不涉及 Introduction Analysis 引入类型：其他，三方库漏洞 引入PR：无 PR合入时间：无 问题是否偶现：否,改漏洞是1.32.3 到 1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。
徐微,[master][GPU] float16精度下不同操作顺序（等价模型）导致计算结果不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，使用float16数据类型时，发现两个等价的计算图仅因操作顺序不同而产生显著不同的结果。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 我创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果：     T1Model执行顺序: 先ceil再where再matmul     T2Model执行顺序: 先where再ceil再matmul    使用相同的float16输入数据，发现输出结果有明显差异：     40个输出元素中有14个不匹配（35%）     最大绝对差异达到1.5     特别是T1模型的第二行全为0，而T2模型的第二行与第一行完全相同 ```python import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops import numpy as np  T1和T2为等价模型，输出结果应该一致  T1Model执行顺序: 先ceil再where再matmul  T2Model执行顺序: 先where再ceil再matmul class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.v7_0 = ms.Tensor(np.array([[True]], dtype=bool))         self.v8_0 = ms.Tensor(np.ones((2, 1), dtype=np.float16) * 1.5)         self.v9_0 = ms.Tensor(np.ones(2, dtype=np.float16) * 1.5)      def construct(self, v0_0):           v6_0 = ops.ceil(v0_0)           v10_0 = ops.where(self.v7_0, self.v8_0, self.v9_0)         v5_0 = ops.matmul(v6_0, v10_0)         v1_0 = ops.transpose(v5_0, (1, 0))          v3_0 = ops.clip_by_value(v1_0, 1.5, 1.5)         return v3_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.v0_0 = ms.Tensor(np.ones(2, dtype=np.float16) * 1.5)          self.v1_0 = ms.Tensor(np.ones((2, 1), dtype=np.float16) * 1.5)          self.v2_0 = ms.Tensor(np.array([[True]], dtype=bool))       def construct(self, v4_0):           v3_0 = ops.where(self.v2_0, self.v1_0, self.v0_0)          v5_0 = ops.ceil(v4_0)           v6_0 = ops.matmul(v5_0, v3_0)           v7_0 = ops.transpose(v6_0, (1, 0))          v13_0 = ops.clip_by_value(v7_0, 1.5, 1.5)           return v13_0 def reproduce_bug():     np.random.seed(42)     t1_model = T1Model()     t2_model = T2Model()     input_shape = (20, 2)     input_data = np.random.uniform(2, 2, input_shape).astype(np.float16)     v0_0_t1 = ms.Tensor(input_data)     v4_0_t2 = ms.Tensor(input_data.copy())     t1_output = t1_model(v0_0_t1)     t2_output = t2_model(v4_0_t2)     print(""T1模型输出 (v3_0):"", t1_output.asnumpy())     print(""T2模型输出 (v13_0):"", t2_output.asnumpy())     if not np.allclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0):         print(""发现不一致! T1和T2模型的输出不同"")         mismatched = ~np.isclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0)         print(""不匹配元素数量: {} / {} ({:.1f}%)"".format(             np.sum(mismatched), t1_output.size, 100 * np.sum(mismatched) / t1_output.size))         print(""最大绝对差异:"", np.max(np.abs(t1_output.asnumpy()  t2_output.asnumpy())))     return t1_output, t2_output if __name__ == ""__main__"":     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")     t1_output, t2_output = reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应该一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: !输入图片说明",2025-04-08T20:31:39+08:00,repo,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBZJ9B,测试下来应该是正好3月16号的包有这个bug，最新的4月8号的包已经修复这个问题了，你可以试一下： https://repo.mindspore.cn/mindspore/mindspore/version/202504/20250408/master_20250408193412_63fe3cd9b52d7726eaa1068edb0d557e0d1cb93a/unified/x86_64/mindspore2.6.0cp310cp310linux_x86_64.whl 更早一些的版本，比如2.2.14， 2.4.10也都是正常的
虞良斌,The mindspore alarm is rectified,,2025-04-08T19:44:47+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBZIZG
虞良斌,Adapter aclprofGetSupportedFeaturesV2_ interface compatibility testing module,,2025-04-08T15:07:56+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBZDZ7
majun-bot,CVE202529087,"一、漏洞信息 漏洞编号：CVE202529087 漏洞归属组件：sqlite, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.36.0 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： Sqlite 3.49.0 is susceptible to integer overflow through the concat function. 漏洞公开时间：20250408 04:15:20 漏洞创建时间：20250408 13:10:03 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202529087 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞没有修复方案，不受影响 漏洞评分(MindSpore评分): &emsp;BaseScore： 0.0 &emsp;Vector： N/A 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-04-08T13:10:03+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,10,https://gitee.com/mindspore/mindspore/issues/IBZC2B,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明: 该漏洞没有修复方案，不受影响 漏洞评分(mindspore评分): BaseScore:N/A Vector:N/A 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明: 该漏洞没有修复方案，不受影响 漏洞评分(mindspore评分): BaseScore:0 Vector:N/A 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明: 该漏洞没有修复方案，不受影响 漏洞评分(mindspore评分): BaseScore:0.0 Vector:N/A 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：sqlite漏洞 根因： Sqlite 3.49.0 容易通过 concat 函数发生整数溢出。 Fix Solution 不修复，无修复方案 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 是否需要补充 ST/UT：否 不涉及 原因：不涉及 Introduction Analysis 引入类型：其他，三方库漏洞 引入PR：无 PR合入时间：无 问题是否偶现：否,不修复，无修复方案，关闭问题单
zhanghanLeo,OS branch需要更新ms_kernels_internal代码,,2025-04-07T19:45:43+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBZ6JZ
虞良斌,The mindspore alarm is rectified,,2025-04-07T14:24:59+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBZ0JY
TuDouNi,lite where算子fp16报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-04-07T14:08:15+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBZ09Q,【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
虞良斌,The sample code for mstx in the profiler is modified to the new interface,,2025-04-07T10:52:58+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBYXWY
Zhenghai Zhang,[MSLITE]使用delegate时tensor引用计数存在bug,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  使用delegate时tensor引用计数存在bug  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device /CPU/NPU/  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1  Python version (e.g., Python 3.7.5) :3.8.0  OS platform and distribution (e.g., Linux Ubuntu 16.04):18.04  GCC/Compiler version (if compiled from source): 7.5.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  无  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 首先构造一个网络，导出成mindir。 ``` import mindspore as ms from mindspore import Tensor, nn, ops import numpy as np input_x = np.array([[1, 2, 3], [4, 5, 6], [1, 2, 3]]).astype(np.float32) input_y = np.array([[7, 8, 9], [10, 11, 12], [1, 2, 3]]).astype(np.float32) class Net(nn.Cell):     def __init__(self):         super().__init__()         self.addn = ops.AddN()         self.matmul = ops.MatMul()     def construct(self, x, y):         z = self.addn([x, y])         w = self.matmul(x, z)         h = self.matmul(y, z)         res = self.addn([w, h])         return res net = Net() x_tensor = ms.Tensor(input_x) y_tensor = ms.Tensor(input_y) out = net(x_tensor, y_tensor) ms.export(net, x_tensor, y_tensor, file_name=""pnna_model"", file_format='MINDIR') print(out) ``` 2. 再将mindir文件转换成ms文件，可视化ms如下图： !输入图片说明 3. 使用mindspore lite进行推理，推理时设置addn算子使用delegate模式代理，matmul使用cpu运行。下面是运行时的log信息： ``` DEBUG [mindspore/lite/src/litert/scheduler.cc:459] Schedule] schedule kernels success. DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph0,  type:0 DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : CpuFP32SubGraph0,  type:1 DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop1] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop0] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph1,  type:0 ``` 经过schedule之后会划分成3个子图，其中PNNASubGraph的arch == kDelegate，打印出每个kernel的引用计数发现，delegate子图PNNASubGraph0输出tensor：Default/AddNop0的引用计数为1，显然不正确，应该为2才对，否则当CpuFP32SubGraph0子图运行完第一个Default/MatMulop1 kernel时就会将该kernel的输入tensor Default/AddNop0进行释放，从而导致结果错误。 !输入图片说明  Describe the expected behavior / 预期结果 (Mandatory / 必填) delegate子图PNNASubGraph0输出tensor：Default/AddNop0的引用计数为2,结果正确。  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  DEBUG [mindspore/lite/src/litert/scheduler.cc:459] Schedule] schedule kernels success. DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph0,  type:0 DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : CpuFP32SubGraph0,  type:1 DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop1] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop0] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph1,  type:0 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph0 in_kernels size: 0 out_kernels size: 2 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: Default/MatMulop1 in_kernels size: 1 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: Default/MatMulop0 in_kernels size: 1 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph1 in_kernels size: 2 out_kernels size: 0 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph0 in_kernels size: 0 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: CpuFP32SubGraph0 in_kernels size: 1 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph1 in_kernels size: 1 out_kernels size: 0 DEBUG [mindspore/lite/src/litert/lite_session.cc:781] PrepareKernels] kernel size: 3 DEBUG [mindspore/lite/src/litert/lite_session.cc:849] SetTensorInitRefCount] kernel name: PNNASubGraph0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name PNNASubGraph0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/AddNop0 IsGraphOutput: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name PNNASubGraph0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/AddNop0 schema::Format: NHWC DataType: 43 Category: 0 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1 DEBUG [mindspore/lite/src/litert/lite_session.cc:849] SetTensorInitRefCount] kernel name: CpuFP32SubGraph0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name Default/MatMulop1 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/MatMulop1 IsGraphOutput: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name Default/MatMulop1 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/MatMulop1 schema::Format: NHWC DataType: 43 Category: 0 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name Default/MatMulop0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/MatMulop0 IsGraphOutput: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name Default/MatMulop0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/MatMulop0 schema::Format: NHWC DataType: 43 Category: 0 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1 DEBUG [mindspore/lite/src/litert/lite_session.cc:854] SetTensorInitRefCount] IsIsolatedSubGraph: 0 DEBUG [mindspore/lite/src/litert/lite_session.cc:849] SetTensorInitRefCount] kernel name: PNNASubGraph1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name PNNASubGraph1 out kernel size: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/AddNop1 IsGraphOutput: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name PNNASubGraph1 out kernel size: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/AddNop1 schema::Format: NHWC DataType: 43 Category: 4 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1  Special notes for this issue/备注 (Optional / 选填)",2025-04-07T10:42:05+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBYXO7
Xinrui Chen,社区资料模型页的链接没有跳转到模型说明文档," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 社区资料模型页的链接没有跳转到模型说明文档  2.Environment / 环境信息 (Mandatory / 必填) 不涉及    3.Related testcase / 关联用例 (Mandatory / 必填) 不涉及  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 点击链接![](https://foruda.gitee.com/images/1743681388971230070/d5ed7994_9674352.png ""屏幕截图"")  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 跳转到模型readme  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**陈心锐（根据实际修改）",2025-04-03T19:57:40+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBYNSI
zhangyinxia,fix barrier op,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-03T09:08:27+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBYEZJ
虞良斌,Supplementary st use cases can be exported by step for communication data in multicard scenarios,,2025-04-02T17:05:45+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBYC6C
caifubi,Tensor.move_to触发PythonTensor创建，单次耗时10us.,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-04-02T11:16:10+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBY6XR
虞良斌,Fixed dynamic profiling bug,,2025-04-02T10:50:59+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBY6F1
caifubi,动态图的EndGraph里面触发了wait launch_queue.,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-04-02T10:44:04+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBY6BO
zhuguodong,重构MSLite benchmark,,2025-04-01T21:16:51+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBY3DM
虞良斌,Example Repair pylint alarms,,2025-04-01T15:10:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBXXWB
tanxinglian,"[CT][MS][OPS][ops.prompt_flash_attention][function][全量]prompt_flash_attention ascend后端报错RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check!"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > prompt_flash_attention ascend后端报错RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2 test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：O0 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v  test_f_prompt_flash_attention.py::test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2 pytest s v test_f_prompt_flash_attention.py::test_f_prompt_flash_attention_gqa_opt_b16  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```  ()     (reason='只支持910B')     (reason='只支持910B')     def test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2():         n, kv_n, d = (25, 5, 16)         s, kv_s = (3, 3)         layout = 'BNSD'         causal = False         enable_gpu = False         pre_tokens, next_tokens = 2147483647, 0         if enable_gpu and (not causal):              allMask 全0             pre_tokens, next_tokens = 65535, 65535         s = s * 1024         kv_s = kv_s * 1024         actual_seq_lengths = [s, s]         actual_seq_lengths_kv = [kv_s, kv_s]         pse_shift = np.random.randn(2, n, s, kv_s).astype(np.float16)         deq_scale1_np = np.array([1.7])         quant_scale1_np = np.array([1.7])         deq_scale2_np = np.array([1.3])         quant_scale2_np = None         quant_offset2_np = None         quant_params = (             deq_scale1_np, quant_scale1_np, deq_scale2_np, quant_scale2_np, quant_offset2_np)         args = PFAParam(b=2, n=n, q_s=s, kv_s=kv_s, d=d, pre_tokens=pre_tokens, next_tokens=next_tokens,                         data_format=layout,                         actual_seq_lengths=actual_seq_lengths,                         atten_mask_shape=[s, kv_s],                         actual_seq_lengths_kv=actual_seq_lengths_kv,                         quant_params=quant_params,                         num_key_value_heads=kv_n, sparse_mode=0,                         np_type=np.int8, ms_type=mindspore.int8, pse_shift=pse_shift)         fact = PromptFlashAttentionFactory(args, causal=causal) >       fact.forward_cmp() ../test_f_prompt_flash_attention.py:1516:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/prompt_flash_attention_ops.py:1314: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/prompt_flash_attention_ops.py:1114: in forward_mindspore_impl     out = net(query, key, value, attn_mask, acs, acs_kv, ../../share/utils.py:289: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1262: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1706: in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1997: in __call__     return self.run(obj, *args, phase=phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2048: in run     return self._exec_pip(obj, *args, phase=phase_real) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:189: in wrapper     results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp() phase = 'train.1743291204253196288.281468505601456.0....................' args = (Tensor(shape=[2, 25, 3072, 16], dtype=Int8, value= [[[[0, 0, 0 ... 0, 0, 0],    [0, 0, 0 ... 0, 0, 0],    [0, 0, 0 .....alse]]), Tensor(shape=[2], dtype=Int64, value= [3072, 3072]), Tensor(shape=[2], dtype=Int64, value= [3072, 3072]), ...) fn =           def _exec_pip(self, obj, *args, phase=''):         """"""Execute the generated pipeline.""""""         fn = obj.construct         obj.__parse_method__ = fn.__name__ >       return self._graph_executor(args, phase) E       RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 742227] 2025033007:33:26.563.765 PromptFlashAttention LaunchAicore failed.[THREAD:759874] E               TraceBack (most recent call last): E               tensor key shape (128) do not equal to tensor value shape(448) in dim 3[FUNC:CheckKeyValueParamsConsistency][FILE:prompt_flash_attention_tiling.cpp][LINE:940][THREAD:759874] E               key value consistency check failed![FUNC:RunBigKernelTilingWithParams][FILE:prompt_flash_attention_tiling.cpp][LINE:2820][THREAD:759874] E               Tiling failed[THREAD:759874] E               Tiling Failed.[THREAD:759874] E               Kernel GetWorkspace failed. opType: 4[THREAD:759874] E               PromptFlashAttention LaunchAicore failed.[THREAD:759874] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/opapi/aclnn/prompt_flash_attention_aclnn_kernel.h:50 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2028: RuntimeError ``` ```      ()     (reason='只支持910B')     (reason='只支持910B')     def test_f_prompt_flash_attention_gqa_opt_b16():         pre_tokens, next_tokens = 748647, 10         causal = False         enable_gpu = False         layout = 'BNSD'         if enable_gpu and (not causal):              allMask 全0             pre_tokens, next_tokens = 65535, 65535         n, kv_n, d = (10, 5, 16)         s, kv_s = (2, 2)         s = s * 1024         kv_s = kv_s * 1024         actual_seq_lengths = []         actual_seq_lengths_kv = []         for _ in range(16):             value = np.random.randint(1, s)             actual_seq_lengths.append(value)             actual_seq_lengths_kv.append(value)         args = PFAParam(b=16, n=n, q_s=s, kv_s=kv_s, d=d, pre_tokens=pre_tokens,                         next_tokens=next_tokens,                         data_format=layout,                         actual_seq_lengths=actual_seq_lengths,                         actual_seq_lengths_kv=actual_seq_lengths_kv,                         num_key_value_heads=kv_n, sparse_mode=0, atten_mask_shape=[s, kv_s],                         np_type=np.float32, ms_type=mindspore.float16)         fact = PromptFlashAttentionFactory(args, causal=causal) >       fact.forward_cmp() ../test_f_prompt_flash_attention.py:993:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/prompt_flash_attention_ops.py:1314: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/prompt_flash_attention_ops.py:1114: in forward_mindspore_impl     out = net(query, key, value, attn_mask, acs, acs_kv, ../../share/utils.py:289: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1262: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1706: in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1997: in __call__     return self.run(obj, *args, phase=phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2048: in run     return self._exec_pip(obj, *args, phase=phase_real) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:189: in wrapper     results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp() phase = 'train.1743290378095004672.281467745319120.0....................' args = (Tensor(shape=[16, 10, 2048, 16], dtype=Float16, value= [[[[6.7578e01,  2.1387e01,  4.3762e02 ...  9.8633e02, 7.... dtype=Int64, value= [ 492,  662, 1717, 1260, 1691, 1271,  822, 1324, 1688, 1505,   49, 1526, 1237,  434, 1491, 1589])) fn =           def _exec_pip(self, obj, *args, phase=''):         """"""Execute the generated pipeline.""""""         fn = obj.construct         obj.__parse_method__ = fn.__name__ >       return self._graph_executor(args, phase) E       RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 636302] 2025033007:19:40.136.807 PromptFlashAttention LaunchAicore failed.[THREAD:640624] E               TraceBack (most recent call last): E               tensor key shape (112) do not equal to tensor value shape(192) in dim 3[FUNC:CheckKeyValueParamsConsistency][FILE:prompt_flash_attention_tiling.cpp][LINE:940][THREAD:640624] E               key value consistency check failed![FUNC:RunBigKernelTilingWithParams][FILE:prompt_flash_attention_tiling.cpp][LINE:2820][THREAD:640624] E               Tiling failed[THREAD:640624] E               Tiling Failed.[THREAD:640624] E               Kernel GetWorkspace failed. opType: 4[THREAD:640624] E               PromptFlashAttention LaunchAicore failed.[THREAD:640624] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/opapi/aclnn/prompt_flash_attention_aclnn_kernel.h:50 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2028: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e8869af31fc3250cda2eba&workspaceId=67e8869a5050f12edd53280f https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e8869af31fc3250cda2f3f&workspaceId=67e8869a5050f12edd53280f    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-04-01T11:25:29+08:00,"gitee,foruda,rct/cann",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBXV11,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 修改了PromptFlashAttention算子的Infer流程，没有考虑key和value保持一致的情况 CANN问题单： 暂无，最新商发版本已解决（Milan_C21/20250402_atlas已解决） !输入图片说明 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 解决方案 (Fix Solution) 2. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,cann包：Milan_C21/20250402_atlas !输入图片说明
tanxinglian,[CT][MS][OPS][ops.triuindices][function][全量]triuindices ascend后端计算结果错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > triuindices ascend后端计算结果错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_p_triuindices_matrix_shape_1_1 test_f_triuindices_matrix_shape_1_1 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O0 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_triuindices.py::test_p_triuindices_matrix_shape_1_1 pytest s v test_f_triu_indices.py::test_f_triuindices_matrix_shape_1_1  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       def test_p_triuindices_matrix_shape_1_1():         fact = TriuIndicesMock(attributes={""row"": 1, ""col"": 1}) >       fact.forward_cmp() ../test_triuindices.py:97:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/primitive/triuindices_ops.py:53: in forward_cmp     allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0],        [0]], dtype=int32) data_me = array([[1],        [1]], dtype=int32), rtol = 0, atol = 0     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_f_triu_indices.py:92:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/triuindices_ops.py:56: in forward_cmp     allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0],        [0]], dtype=int32) data_me = array([[1],        [1]], dtype=int32), rtol = 0, atol = 0     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0 0] E       data_me_error:[1 1] E       loss:[1 1] ../../share/utils.py:57: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e5dca68dd14476537e7e86&workspaceId=67e9bb29a1196417b05f5d64 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e5dca68dd14476537e7ec2&workspaceId=67e82c1e6ae691186d8c67b6    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-04-01T11:12:26+08:00,"gitee,foruda,foruda,rct/oldrelease,ctl/componenttest,rca/algorithm",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBXURK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,新包仍无规律重现问题 !输入图片说明," Appearance & Root Cause 问题：triuindices ascend后端计算结果错误，对于1*1的矩阵，预期返回下标[0, 0]，实际返回下标[1, 1]。 根因：该算子是MS的AICPU算子，其没有输入，直接输出下标。分析代码发现，mindspore实现的triuindices和trilindices套用同一套infer逻辑，两者没有做出区分。两个算子实际计算的逻辑有差别，导致triuindices计算错误。  Fix Solution triuindices中对于offset的处理需要增加一个offset1操作。  Fix Description & Test Suggestion 修复pr：https://gitee.com/mindspore/mindspore/pulls/84014 使用该pr合入后的每日构建包回归。 测试建议：算子开发需要自验充分，尽可能排除偶现问题，避免浪费大家时间  Selftest Report & DT Review 用例通过。 是否需要补充 ST/UT：否 如果选择否，请补充理由 原因：非基本功能问题  Introduction Analysis 引入类型：旧版本算子遗留问题 引入PR：不涉及 PR合入时间：不涉及 问题是否偶现：否","新版本执行一天未再复现 【回归版本号】：__commit_id__ = '[sha1]:1abfba19,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
tanxinglian,[CT][MS][OPS][ops.bincount][function][全量]bincount 910b graph模式报错RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > bincount 910b graph模式报错RuntimeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_bincount_input_1d_uint8_weights_1d_int8 test_f_bincount_input_1d_int64_weights_1d_float64 test_f_bincount_input_1d_int64_weights_1d_float16 test_f_bincount_input_1d_int32_weights_1d_int16 test_f_bincount_input_1d_int32_weights_1d_float32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O0 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_f_bincount.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='GE does not support dynamic shape')     def test_f_bincount_input_1d_uint8_weights_1d_int8():         input_x = Tensor(np.random.randint(0, 128, (3,)), mstype.uint8)         weights = Tensor(np.random.randint(128, 127, (3,)), mstype.int8)         minlength = 7         fact = BincountMock(             attributes={'minlength': minlength},             inputs=[input_x, weights]) >       fact.forward_cmp() ../test_f_bincount.py:212:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/bincount_ops.py:59: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/bincount_ops.py:39: in forward_mindspore_impl     out = net(self.input_x, self.weights) ../../share/utils.py:289: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1262: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1703: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1685: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp(), phase = 'train.1743266774424581888.281468119748576.0..' do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[3], dtype=UInt8, value= [116,  69,  67]), Tensor(shape=[3], dtype=Int8, value= [51,  95,  68])) kwargs = {}, key_id = '2814681197485761743266774424581888', key = 0 parameter_ids = '', raw_phase = 'train' full_function_name = 'WrapOp.1.187651209966688', echo_function_name = 'WrapOp'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         _init_auto_parallel_context(obj)         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             _clear_auto_parallel_context(obj)             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         gc.collect() >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: The current operator needs to be supplemented with an adapter, please check in `transform` directory. node is Default/ScalarGtop0 E        E        E        The Function Call Stack: (For framework developers) E        E       In file /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/function/math_func.py:501, 7~64/    if input.astype(mstype.float32).max().item() > minlength  1:/ E       In file /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/function/math_func.py:455~511/def bincount(input, weights=None, minlength=0):/ E       In file /home/jenkinsslave/workspace/1980b_green_mindspore_ascend_opensource/MindSporeTest/share/ops/functional/bincount_ops.py:18, 14~26/        out = ops.bincount(input_x, weights, self.minlength)/ E       In file /home/jenkinsslave/workspace/1980b_green_mindspore_ascend_opensource/MindSporeTest/share/ops/functional/bincount_ops.py:17~19, 4~18/    def construct(self, input_x, weights):/ E        E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:612 HandleKernelSelectFailure /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1954: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03t710bl5mi89%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000:51:05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e82c1ef9c5276b77e386cd&workspaceId=67e82c1e6ae691186d8c67b6    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-04-01T10:38:06+08:00,"gitee,foruda,foruda,foruda,foruda,rca/others,ctl/componenttest,rct/bugfix",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBXU2S,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,https://gitee.com/mindspore/mindspore/pulls/83565 修改引入," Appearance & Root Cause 问题：ops.bincount 910b graph模式报错RuntimeError: The current operator needs to be supplemented with an adapter, please check in `transform` directory. node is Default/ScalarGtop0 根因： !输入图片说明 此处比较前后均为scalar时走到ScalarGt算子。 ScalarGt只有CPU实现，开启不允许退避的环境变量后找不到算子了。 !输入图片说明 !输入图片说明  Fix Solution max操作后不取item()结果为Tensor，不走入ScalarGt算子， 保持和上次修改前逻辑一致。  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83958 PR合入后daily包回归  Selftest Report & DT Review 自测结果： !输入图片说明 是否需要补充 ST/UT：否  Introduction Analysis 引入类型：Bugfix修复引入 引入PR： https://gitee.com/mindspore/mindspore/pulls/83565 PR合入时间：2025/3/27 是否偶现：否","【回归版本号】：__commit_id__ = '[sha1]:843c0cc2,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
虞良斌,profiler data modification,,2025-03-31T21:28:27+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBXQV4
huangzhichao2023,deepseek3缺少测试用例," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > deepseek3缺少测试用例  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (`Ascend910B1`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**黄志超（根据实际修改）",2025-03-30T15:19:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBXCB1
虞良斌,Fixed dynamic profiling redundant warning log issue,,2025-03-29T18:49:37+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBX9JL
tanxinglian,[CT][MS][OPS][mint.nn.functional.conv2d][function][全量]mint.nn.functional.conv2d 910A存在精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.conv2d 910A存在精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_mint_n_f_conv2d_dyn_shape_3 test_mint_n_f_conv2d_padding_same_odd_float16_4d_12x12x28x49_random >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_mint_n_f_conv2d.py::test_dynamic_shape_mint_n_f_conv2d_dyn_shape_3 pytest s v  test_mint_n_f_conv2d.py::test_mint_n_f_conv2d_padding_same_odd_float16_4d_12x12x28x49_random  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       ()     ()     ()     def test_dynamic_shape_mint_n_f_conv2d_dyn_shape_3():         input_x = Tensor(shape=(None, None, None), dtype=mstype.float16)         weight = Tensor(shape=(None, None, None, None), dtype=mstype.float16)         bias = Tensor(shape=(None,), dtype=mstype.float16)         stride = mutable(input_data=1, dynamic_len=False)         padding = 'same'         dilation = mutable(input_data=(3, 4), dynamic_len=False)         groups = mutable(input_data=19, dynamic_len=False)         input_x1 = Tensor(np.random.randn(19, 20, 50), mstype.float16)         weight1 = Tensor(np.random.randn(76, 1, 4, 2), mstype.float16)         bias1 = Tensor(np.random.randn(76, ), mstype.float16)         stride1 = mutable(input_data=1, dynamic_len=False)         padding1 = 'same'         dilation1 = mutable(input_data=(3, 4), dynamic_len=False)         groups1 = mutable(input_data=19, dynamic_len=False)         attributes1 = {'stride': stride1, 'padding': padding1, 'dilation': dilation1, 'groups': groups1}         inputs1 = [input_x1, weight1, bias1]         input_x2 = Tensor(np.random.randn(3, 10, 13), mstype.float16)         weight2 = Tensor(np.random.randn(2, 3, 2, 3), mstype.float16)         bias2 = Tensor(np.random.randn(2, ), mstype.float16)         stride2 = mutable(input_data=1, dynamic_len=False)         padding2 = 'same'         dilation2 = mutable(input_data=(3, 2), dynamic_len=False)         groups2 = mutable(input_data=1, dynamic_len=False)         attributes2 = {'stride': stride2, 'padding': padding2, 'dilation': dilation2, 'groups': groups2}         inputs2 = [input_x2, weight2, bias2]         input_x3 = Tensor(np.random.randn(3, 3, 50), mstype.float16)         weight3 = Tensor(np.random.randn(1, 3, 2, 3), mstype.float16)         bias3 = Tensor(np.random.randn(1, ), mstype.float16)         stride3 = mutable(input_data=1, dynamic_len=False)         padding3 = 'same'         dilation3 = mutable(input_data=(1, 5), dynamic_len=False)         groups3 = mutable(input_data=1, dynamic_len=False)         attributes3 = {'stride': stride3, 'padding': padding3, 'dilation': dilation3, 'groups': groups3}         inputs3 = [input_x3, weight3, bias3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = Conv2dMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (input_x, weight, bias, stride, padding, dilation, groups) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_mint_n_f_conv2d.py:1126:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/conv2d_mint.py:340: in forward_dynamic_shape_cmp     allclose_nparray(a, b, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[ 0.04687303,  2.1588888 ,  2.0576582 , ..., 0.6429784 ,           0.34636706,  1.682324  ],         [0.0635...         [0.47335398,  0.2898569 , 1.7914011 , ..., 1.2131597 ,          0.07973671, 1.9519975 ]]], dtype=float32) data_me = array([[[ 0.04688,  2.158  ,  2.057  , ..., 0.6426 ,  0.3464 ,           1.683  ],         [0.0635 , 0.9473 , 5.57...         1.912  ],         [0.4734 ,  0.2898 , 1.791  , ..., 1.213  , 0.0797 ,          1.951  ]]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_mint_n_f_conv2d.py:425:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/conv2d_mint.py:193: in forward_cmp     allclose_nparray(out_cmp, out_mindspore, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[ 6.99089146e+00,  4.23183060e+00, 1.61583614e+00, ...,            2.26269007e01,  9.62609673e+00, 7.71942...310386e+00, 9.32385635e+00, ...,            2.73167515e+00, 8.36550236e+00, 2.95200014e+00]]]],       dtype=float32) data_me = array([[[[ 6.9922e+00,  4.2305e+00, 1.6162e+00, ...,  2.2656e01,            9.6250e+00, 7.7246e01],          [ 2.9...       [1.5492e+01,  2.3730e+00, 9.3203e+00, ...,  2.5117e+00,           9.0000e+00, 3.2656e+00]]]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[32.84552    17.736362   17.855343  ...   2.7316751  8.365502 E         2.9520001] E       data_me_error:[34.3    17.69   15.51  ...   2.512  9.     3.266] E       loss:[1.46698    0.04886246 2.3475304  ... 0.2199564  0.63449764 0.31362486] ../../share/utils.py:57: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03t710bl5mi89%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007:18:24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e69213e00c6b20d441be19&workspaceId=67e692106ae691186d864456 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e69211e00c6b20d441bc79&workspaceId=67e692106ae691186d864456    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-29T16:50:07+08:00,"gitee,foruda,foruda,rct/cann,mindspore-repo",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBX8WV,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,cann包升级引入，已提DTS单：https://dts.huawei.com/DTSPortal/ticket/DTS2025033103526,DTS2025033124507,Appearance & Root Cause 问题：CANN升级引入的bug 根因：见DTS单 Fix Solution CANN升级到CANN 8.1.RC1.B090 Fix Description & Test Suggestion CANN升级到CANN 8.1.RC1.B090 Selftest Report & DT Review !输入图片说明 !输入图片说明 是否需要补充 ST/UT：否 如果选择否，请补充理由 原因：非基本功能问题 Introduction Analysis 引入类型：CANN引入 引入PR：见DTS单 PR合入时间：见DTS单 问题是否偶现：否,cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250402_atlas/ !输入图片说明
tanxinglian,"[CT][MS][OPS][mint.nn.functional.interpolate][function][全量]interpolate报错RuntimeError: aclnnUpsampleNearest1dBackwardGetWorkspaceSize call failed, please check!"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > interpolate报错RuntimeError: aclnnUpsampleNearest1dBackwardGetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例： uint32/NCHW/uint32/NC1HWC0/.[THREAD:889755] E               TraceBack (most recent call last): E              Cannot find binary for op TransData.[THREAD:889755] E              Kernel GetWorkspace failed. opType: 5[THREAD:889755] E              TransDataSpecial ADD_TO_LAUNCHER_LIST_AICORE failed.[THREAD:889755] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/pyboost/customize/upsample_nearest1d_grad.cc:34 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/tensor.py:994: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb86ae691186d85d8b5&workspaceId=67e66bb7a1196417b0549ee7 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb76ae691186d85d896&workspaceId=67e66bb7a1196417b0549ee7 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03t710bl5mi89%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007:18:24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb76ae691186d85d889&workspaceId=67e66bb7a1196417b0549ee7 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb76ae691186d85d88d&workspaceId=67e66bb7a1196417b0549ee7    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-29T15:26:49+08:00,"gitee,foruda,foruda,foruda,foruda,rca/others,rct/oldrelease,ctl/componenttest,rct/cann,mindspore-repo,sig/ops,dts-szv",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBX8E9,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,升级run包引入问题，已和海思沟通，dts单号：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025032914704, Appearance & Root Cause 问题：反向算子跑不通 根因： 海思侧bug，dts单号：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025032914704  Fix Solution 更新run包  Fix Description & Test Suggestion 无需合入 测试建议：用最新cann包回归 https://cmc.rnd.huawei.com/cmcversion/index/releaseView?deltaId=11917143714825472&isSelect=Software。  Selftest Report & DT Review !输入图片说明 !输入图片说明 !输入图片说明 !输入图片说明 是否需要补充 ST/UT：否 原因：已有用例含糊  Introduction Analysis 引入类型：run包升级引入 引入PR：无 PR合入时间：年/月/日 问题是否偶现：否,cann包：http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250402_atlas !输入图片说明 !输入图片说明
Jupiter1021,Batch_size不一致导致相同数据在同一模型上输出不一致 ," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) vgg16模型，cifar10数据集，Batch_size为1和64时，相同数据在同一模型上输出不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore.dataset as ds import mindspore from mindspore import Tensor import torch import os import numpy as np from torch.utils.data import TensorDataset, DataLoader from mindspore import context import model_util as model_util  mindspore.set_context(mode=mindspore.GRAPH_MODE, device_target=""GPU"", device_id=0) os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID' os.environ['CUDA_VISIBLE_DEVICES'] = ""0"" torch.backends.cudnn.benchmark = True   cuDNN 衡量库里面的多个卷积算法速度，然后选择其中最快的那个卷积算法   vgg16 deeplabv3 deeplabv3plus openpose patchcore unet resnet50 textcnn ssimae model_name = ""vgg16""  cifar10 Pascal_VOC_deeplab openposecoco2017 ischanllge patchcoreMVTecAD dataset_name = ""cifar10"" batch_size = 1 device_target = ""GPU"" device = ""cuda"" device_id = 0 DEVICE = torch.device(device) attack = ""wanet"" data_size = {     'cifar10': (3, 224, 224), } def get_model_and_load_weight():     pt_model_filepath = f'/data2/CKPTS/' + model_name + '/' + model_name + '.pth'     ms_model_filepath = f'/data2/CKPTS/' + model_name + '/' + model_name + '.ckpt'     f = open('./config.txt', 'w')     config_path = r'../common/config/' + model_name + '.yaml'     f.write(config_path.lower())     f.close()     input_size = (batch_size,) + data_size[dataset_name]      获取模型并加载权重     ms_model, pt_model = model_util.get_model(model_name, device_target, device_id, input_size)      model = torch.nn.DataParallel(model)     loaded = torch.load(pt_model_filepath, map_location=device)     if isinstance(loaded, dict):         state_dict = loaded     else:         state_dict = loaded.state_dict()      state_dict = torch.load(pt_model_filepath, map_location=device)     pt_model.load_state_dict(state_dict=state_dict, strict=False)      model = torch.load(model_filepath,map_location=device)     pt_model.eval()     pt_model.to(DEVICE)     mindspore.load_checkpoint(ms_model_filepath, ms_model)     ms_model.set_train(False)   设置为推理模式     return ms_model, pt_model def collect_diff_data(poison=False):     ms_model, pt_model = get_model_and_load_weight()     print(""PT Model loaded successfully"")     print(""MS Model loaded successfully"")     data_path = ""./"" + attack + "".npz""     npz_data = np.load(data_path)     x_data = npz_data['x']   图像数据     y_data = npz_data['y']   标签数据     y_data = y_data.squeeze()     print(f""x_data shape: {x_data.shape}"")   (10000, 3, 224, 224)     print(f""y_data shape: {y_data.shape}"")   (10000,)      PyTorch数据加载     inputs_torch = torch.tensor(x_data, dtype=torch.float32).to(DEVICE)     labels_torch = torch.tensor(y_data, dtype=torch.long).to(DEVICE)     dataset_torch = TensorDataset(inputs_torch, labels_torch)     dataloader_torch = DataLoader(dataset_torch, batch_size=batch_size, shuffle=False)      MindSpore数据加载     dataset_mindspore = ds.NumpySlicesDataset({""inputs"": x_data, ""labels"": y_data}, shuffle=False)     dataloader_mindspore = dataset_mindspore.batch(batch_size)      定义存储不一致数据的数组     mismatch_data = []     mismatch_pytorch_results = []     mismatch_mindspore_results = []     mismatch_labels = []      定义一个列表来存储不一致样本的全局索引     mismatch_indices = []      初始化全局索引     global_index = 0     count = 0      批量推导和比较     for (batch_torch, batch_mindspore) in zip(dataloader_torch, dataloader_mindspore.create_dict_iterator()):          PyTorch推导         inputs_batch_torch, labels_batch_torch = batch_torch         with torch.no_grad():             outputs_torch = pt_model(inputs_batch_torch).argmax(dim=1)          MindSpore推导         inputs_batch_mindspore = Tensor(batch_mindspore[""inputs""], mindspore.float32)         labels_batch_mindspore = batch_mindspore[""labels""]         outputs_mindspore = ms_model(inputs_batch_mindspore).asnumpy().argmax(axis=1)          比较结果并存储         batch_indices = np.where(outputs_torch.cpu().numpy() != outputs_mindspore)[0]         if len(batch_indices) == 0 and count == 15:             print(""outputs_torch:"")             print(pt_model(inputs_batch_torch)[0])             print(""outputs_mindspore"")             print(ms_model(inputs_batch_mindspore).asnumpy()[0])         if len(batch_indices) > 0:             print(""outputs_torch:"")             print(pt_model(inputs_batch_torch)[batch_indices])             print(""outputs_mindspore"")             print(ms_model(inputs_batch_mindspore).asnumpy()[batch_indices])              保存不一致样本的全局索引             mismatch_indices.extend(batch_indices + global_index)             mismatch_data.extend(x_data[batch_indices + global_index])             mismatch_pytorch_results.extend(outputs_torch.cpu().to('cpu').numpy()[batch_indices])   确保输出在 CPU 上             mismatch_mindspore_results.extend(outputs_mindspore[batch_indices])             mismatch_labels.extend(y_data[batch_indices + global_index])          更新全局索引         global_index += len(batch_torch[0])         count += 1      输出不一致样本的全局索引     print(f""Indices of mismatched samples: {mismatch_indices}"")     print(f""Number of mismatched samples: {len(mismatch_data)}"")      输出不一致样本     for i in range(len(mismatch_data)):         print(f""Sample Index: {i}"")          print(f""Input Data: {mismatch_data[i]}"")         print(f""PyTorch Result: {mismatch_pytorch_results[i]}, MindSpore Result: {mismatch_mindspore_results[i]}"")         print(f""True Label: {mismatch_labels[i]}"") if __name__ == ""__main__"":     collect_diff_data() ``` wanet.npz中保存了64条数据，包括（3,224,224）的图像和对应的标签，batch_size为64和1时，索引为15的数据在被mindspore.dataset加载后其输出不一致 !输入图片说明 当batch_size为1时，mindspore和PyTorch框架下的分类一致，都分类到3 !输入图片说明 当batch_size为64时，mindspore和PyTorch框架下的分类不一致，PyTorch分类到3，mindspore分类到5",2025-03-29T12:49:10+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBX7KO,这种不一致是由于浮点数计算误差导致的。这种误差一般较小，在可接受范围内。 例子中的误差也在0.002左右。 这些误差通常与卷积计算或dropout(vgg16没有)有关，它们在计算过程中有一定的随机性。 在进行对比时，如果需要得到相对准确的结果，可以开启确定性计算 在mindspore中的设置如下： ``` import mindspore as ms ms.set_deterministic(True) ``` 在torch中的设置如下： ``` import torch   torch.backends.cudnn.deterministic = True   确保每次运行卷积操作时得到的结果都是一致的 torch.backends.cudnn.benchmark = False   可以关闭自适应算法选择 ```,这个输出是正确的，不同硬件有一定随机性
虞良斌,Replace with the security function already implemented in the bin,,2025-03-29T11:03:40+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBX6YU
nicozhang,"在容器里使用 8G 内存，mindspore 版本为 2.2.11, 会触发 OOM"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > 在容器里，使用 mindspore2.2.11 训练一个小模型，使用 8G 内存会触发 oom。如果加大内存，也通过训练。原来用的 1.7 的版本是可以的，使用2.2.11之后就不行了。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Ascend910B   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) !输入图片说明 !输入图片说明 详细过程，见文件 代码文件",2025-03-28T16:48:53+08:00,mindspore-assistant,closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBX336,这里的8G是device memory吗？可能正好就是不够了，这种应该是正常现象，不同的版本因为内部处理有改动，所以device memory的使用上有差异也是正常的，有些版本可能做了性能优化，为了提高性能会多占一些device memory，类似于空间换时间的意思，并且和不同的cann版本、昇腾驱动版本有关，或者底层算子的不同也有关联；或者说不同的mindspore版本，某些不同的默认配置参数，也会造成一定的device memory差异；, 能观察到的现象是在train的时候，提前会准备些数据。这个阶段会创建大量的 Python 进程，可能是每个进程会占用一部分内存，最后触发了OOM。目前是如果内存加大16G就行。,python进程占用的话，应该是host memory，就是内存，device memory的话是通常所说的显存;如果是数据处理时出现大量python进程占用内存，可能是数据加载器，或者数据的map处理方法使用了多进程，你可以把数据处理的worker数改小一点，或者明确设置python多进程为false，我记得map方法默认不设置的话走的多线程，但数据加载器默认会走多进程，这个早期版本和现在的版本可能有所不同，可以都明确指定一下看看
congcong,Tensor打印内容变更,,2025-03-28T14:55:56+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBX14T
tangmengcheng,profiler clean code,,2025-03-27T20:25:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBWUWT
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.index_fill_, Tasks 转测对象：Tensor.index_fill_ ,2025-03-27T14:11:21+08:00,"gitee,sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBWPJN
tangmengcheng,profiler memory时间转换单位不对,,2025-03-27T10:34:13+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBWN3E
徐微,【master】【OPS】【ops.where】【function】where 存在精度问题," MindSpore Where算子CPU与GPU行为不一致Bug报告  1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore中，`ops.where`算子在CPU和GPU设备上执行时产生不一致的结果。具体表现为当条件为True时，CPU正确返回负值，而GPU却将所有负值转换为0。此差异会导致在不同设备上运行相同模型产生不同结果，影响模型一致性和可靠性。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Testcase Name/ 用例名**: where_bug.py  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 准备测试环境，确保同时支持CPU和GPU后端 2. 测试脚本 ```python     import numpy as np     import mindspore as ms     from mindspore import ops     import os     import sys     import subprocess     import time     def test_where_bug(device=""CPU"", test_case=0):         ms.set_device(device)         ms.set_context(mode=ms.PYNATIVE_MODE)         test_cases = [             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1, 2, 3, 4, 5], ms.int32),                 ""desc"": ""基本测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1000000001, 1000000002, 1000000003, 1000000004, 1000000005], ms.int32),                 ""desc"": ""大数值测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1.5], ms.float32),                 ""y"": ms.Tensor([1.1, 2.2, 3.3, 4.4, 5.5], ms.float32),                 ""desc"": ""浮点数测试(float32)""             },         ]         if test_case >= len(test_cases):             test_case = 0         case = test_cases[test_case]         condition, x, y = case[""condition""], case[""x""], case[""y""]          执行操作         result = ops.where(condition, x, y)          保存结果         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         os.makedirs(results_dir, exist_ok=True)         file_name = f""{device.lower()}_case{test_case}_results.npy""         np.save(f'{results_dir}/{file_name}', result.asnumpy())         print(f""{device}结果: {result}"")         return result     def compare_results(test_case=0):         """"""比较CPU和GPU结果""""""         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         cpu_file = f'{results_dir}/cpu_case{test_case}_results.npy'         gpu_file = f'{results_dir}/gpu_case{test_case}_results.npy'         if not os.path.exists(cpu_file) or not os.path.exists(gpu_file):             print(f""错误: 结果文件不存在，请先运行测试"")             return         cpu_result = np.load(cpu_file)         gpu_result = np.load(gpu_file)         are_equal = np.array_equal(cpu_result, gpu_result)         print(f""CPU和GPU结果是否一致: {are_equal}"")         if not are_equal:             diff_indices = np.where(cpu_result != gpu_result)             diff_count = len(diff_indices[0])             total_count = cpu_result.size             diff_percent = 100 * diff_count / total_count             max_abs_diff = np.max(np.abs(cpu_result  gpu_result))             print(f""不匹配元素: {diff_count} / {total_count} ({diff_percent:.1f}%)"")             print(f""最大差值: {max_abs_diff}"")              完整展示结果             np.set_printoptions(suppress=True)   禁止科学计数法             print(f""CPU结果: {cpu_result}"")             print(f""GPU结果: {gpu_result}"")              显示差异索引和对应值             print(f""有差异的索引: {diff_indices[0]}"")             print(f""这些索引处的CPU值: {cpu_result[diff_indices]}"")             print(f""这些索引处的GPU值: {gpu_result[diff_indices]}"")     def run_all_tests():         """"""运行所有测试用例并比较结果""""""         test_cases = 3         print(""="" * 80)         print(""MindSpore Where操作在CPU和GPU上的结果比较"")         print(""="" * 80)         for case in range(test_cases):             print(f""\n测试用例 {case}:"")             print("""" * 60)              在CPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""CPU"", ""case"", str(case)],                          stdout=subprocess.PIPE)              在GPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""GPU"", ""case"", str(case)],                         stdout=subprocess.PIPE)              比较结果             compare_results(case)             print("""" * 60)     if __name__ == ""__main__"":         import argparse         parser = argparse.ArgumentParser(description='MindSpore Where操作Bug复现')         parser.add_argument('device', type=str, choices=['CPU', 'GPU'], default='CPU')         parser.add_argument('case', type=int, default=0)         parser.add_argument('runall', action='store_true',                          help='自动在CPU和GPU上运行所有测试用例并比较结果')         args = parser.parse_args()         if args.run_all:             run_all_tests()         else:             test_where_bug(args.device, args.case) ``` 2. 运行测试脚本，执行所有测试用例并比较结果:    ```bash    python /home/ms/ms_test/Bug_test/where_bug.py runall    ``` 3. 观察比较结果，特别关注负值在不同设备上的处理差异  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: CPU和GPU应产生一致的结果，特别是对于负值的处理应该相同，不应出现GPU自动将负值转为0的情况。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: ``` 测试用例 0:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [ 1 1  3 1 1] GPU结果: [1 0 3 0 0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 1:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [1000000001         1 1000000003         1         1] GPU结果: [1000000001          0 1000000003          0          0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 2:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1.5 CPU结果: [ 1.1 1.5  3.3 1.5 1.5] GPU结果: [1.1 0.  3.3 0.  0. ] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1.5 1.5 1.5] 这些索引处的GPU值: [0. 0. 0.]  ```  7.Special notes for this issue/备注 (Optional / 选填) 1. 问题特征总结:     仅在条件为`True`时且选择值为负值时出现     同时影响整数和浮点数数据类型     问题与广播机制相关，特别是负值标量被广播时 2. 可能的根本原因:     GPU实现中的符号位处理错误     CUDA内核在执行条件选择时可能截断了负值的符号位     掩码操作实现可能存在缺陷",2025-03-27T10:13:49+08:00,mindspore-assistant,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBWMQ7,  
default32423,[Fuzzer] Some KERNEL failure/Unexpected Error issues in MindSpore 2.5.0," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) I encountered several KERNEL failure/Unexpected Error issues in MindSpore 2.5.0. They all produce the following output: ""This exception is caused by an unexpected framework error. Please report this issue at https://gitee.com/mindspore/mindspore/issues for assistance."" These bugs could potentially be exploited to trigger a denialofservice attack. MindSpore should be able to catch these errors and provide graceful error info.  2.Environment / 环境信息 (Mandatory / 必填) Linux CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore 2.5.0  3.Related testcase / 关联用例 (Mandatory / 必填) None  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)  Bug 1: mindspore.mint. nansum Code: ``` import mindspore from mindspore import Tensor from mindspore.mint import nansum def test_bug():     inp = Tensor([])   Empty tensor     output = nansum(inp)     print(""Other error: No error raised when it should have"") if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2662342,7ff909b28640,python):2025032709:12:07.043.566 [mindspore/ccsrc/kernel/kernel.h:952] CheckShapeNull] For 'ReduceSum', the shape of input cannot contain zero, but got [const vector]{0} [ERROR] RUNTIME_FRAMEWORK(2662342,7ff9ebe5a740,python):2025032709:12:07.043.726 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed: The inner_size is zero.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/cpu/masked_fill_cpu_kernel.cc:80 Resize ```  Bug 2: mindspore.mint.scatter Code: ``` import numpy as np import mindspore as ms from mindspore import Tensor, mint def test_bug():     input_tensor = Tensor(np.zeros((5, 5)), dtype=ms.float32)     src_tensor = Tensor(np.array([[1, 2, 3]]), dtype=ms.float32)     index_tensor = Tensor(np.array([[6, 1]]), dtype=ms.int64)   Invalid indices      Trigger the bug condition     output = mint.scatter(input=input_tensor, dim=1, index=index_tensor, src=src_tensor) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [ERROR] KERNEL(2663056,7f446bb23640,python):2025032709:13:51.394.428 [mindspore/ops/kernel/cpu/scatter_cpu_kernel.cc:72] Resize] For 'Scatter', the shape of 'index' and the shape of 'src' should be same, but got index shape: [const vector]{1, 2}; src shape: [const vector]{1, 3}. [ERROR] RUNTIME_FRAMEWORK(2663056,7f454e6c0740,python):2025032709:13:51.394.878 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Scatter] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/common/pyboost/pyboost_utils.cc:386 LaunchKernel ```  Bug 3: mindspore.numpy.stack Code: ``` import subprocess import sys def test_bug():     from mindspore import numpy as np     try:         SIZE1 = 6500         SIZE2 = 4500         concat_list = []         concat_list.append(np.ones((SIZE1, 1024*512), dtype=np.uint8))         concat_list.append(np.ones((SIZE2, 1024*512), dtype=np.uint8))         result = np.stack(concat_list)         print(result.shape)     except Exception as e:         print(""Exception:"", e) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Exception: The int64_t value(887095296) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 4: mindspore.hal.contiguous_tensors_handle.slice_by_padding_shape Code: ``` import mindspore from mindspore.hal.contiguous_tensors_handle import slice_by_padding_shape def test_bug():     dummy_input = mindspore.Tensor([[1, 2], [3, 4]], mindspore.float32)     padding_start = mindspore.Tensor(1, dtype=mindspore.int32)     padding_end = mindspore.Tensor(1, dtype=mindspore.int32)     result = slice_by_padding_shape(dummy_input, padding_start, padding_end) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 9, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 7, in test_bug     result = slice_by_padding_shape(dummy_input, padding_start, padding_end)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The pointer[first_tensor>device_address()] is null.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:244 GetSliceByPaddingShapeHandle ```  Bug 5: mindspore.ops.argmax Code: ``` import numpy as np from mindspore import Tensor from mindspore import ops def test_bug():     empty_tensor = Tensor(np.empty((5, 5, 0), dtype=np.float32))     result = ops.argmax(empty_tensor) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2664438,7f6459474640,python):2025032709:19:35.344.470 [mindspore/ccsrc/kernel/kernel.h:952] CheckShapeNull] For 'Argmax', the shape of input cannot contain zero, but got [const vector]{0} [ERROR] RUNTIME_FRAMEWORK(2664438,7f653b7c6740,python):2025032709:19:35.350.468 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Default/Argmaxop0] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:574 CreateKernel ```  Bug 6: mindspore.amp.constexpr Code: ``` import mindspore as ms from mindspore.amp import constexpr def test_bug():          def constant_calculation(range_num):         out = 0         for i in range(range_num):             out += i           return out     .jit     def my_func(x):         new_shape = constant_calculation(100000)          return ms.ops.broadcast_to(x, (new_shape, ))     x = ms.Tensor([1])     my_func(x) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 17, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 15, in test_bug     my_func(x)   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1016, in staging_specialize     out = _MindsporeFunctionExecutor(func, hash_obj, dyn_args, process_obj, jit_config)(*args, **kwargs)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 190, in wrapper     results = fn(*arg, **kwargs)               ^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 638, in __call__     output = _pynative_executor.grad_jit(*new_inputs)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1568, in grad_jit     output = self._executor.grad_jit(*args)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The size_t value(4999950000) exceeds the maximum value of int.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:152 LongToInt ```  Bug 7: mindspore.numpy.cumsum Code: ``` import mindspore.numpy as np def test_bug():     t = np.ones(2**31, dtype=np.float16)      t[2**30:] = 1     cum_sum_result = np.cumsum(t) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [ERROR] RUNTIME_FRAMEWORK(2665060,7f8dd0e93740,python):2025032709:22:45.808.168 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed: The int64_t value(2147483648) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 8: mindspore.numpy.dstack Code: ``` import mindspore.numpy as np try:     SIZE1 = 6500     SIZE2 = 4500     concat_list = []      Each tensor has shape: (SIZE, 1024*512)     concat_list.append(np.ones((SIZE1, 1024*512), dtype=np.uint8))     concat_list.append(np.ones((SIZE2, 1024*512), dtype=np.uint8))     result = np.dstack(concat_list)      If dstack somehow succeeds (no segfault), we print the shape.     print(result.shape) except Exception as e:      If any Python exception is raised, print it (though segfault might end the process)     print(""Exception:"", e) ``` Output: ``` Exception: The int64_t value(887095296) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 9: mindspore.hal.contiguous_tensors_handle.cth.slice_by_padding_shape Code: ``` import mindspore import mindspore.hal.contiguous_tensors_handle as cth def test_bug():     x = mindspore.Tensor([[0, 1, 2], [3, 4, 5]], mindspore.float32)     padding_shape = (2, 2)      padded_tensor = cth.slice_by_padding_shape(x, *padding_shape) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 8, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 6, in test_bug     padded_tensor = cth.slice_by_padding_shape(x, *padding_shape)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The pointer[first_tensor>device_address()] is null.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:244 GetSliceByPaddingShapeHandle ```  Bug 10: mindspore.numpy.arange Code: ``` import mindspore.numpy as np import mindspore def test_bug():     symbolic_tensor = np.arange(0, mindspore.Tensor(shape=(None,), dtype=mindspore.int32))     output = np.ones_like(symbolic_tensor) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2665960,7f1de8d27640,python):2025032709:27:16.335.885 [mindspore/ccsrc/kernel/kernel.cc:650] Resize] Invalid shape:[const vector]{1}, kernel name:Sub Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 7, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 4, in test_bug     symbolic_tensor = np.arange(0, mindspore.Tensor(shape=(None,), dtype=mindspore.int32))                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 630, in arange     num = _ceil(stop  start)           ^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/primitive.py"", line 939, in __call__     return fn(*args, **kwargs)            ^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/utils_const.py"", line 517, in _ceil     return math.ceil(number)            ^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/tensor.py"", line 372, in __float__     data = self.asnumpy()            ^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/_stub_tensor.py"", line 50, in fun     return method(*arg, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/tensor.py"", line 1036, in asnumpy     return Tensor_.asnumpy(self)            ^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The int64_t value(1) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 11: mindspore.ops.vmap Code: ``` from mindspore.mint import arange import mindspore batch_arange = mindspore.ops.vmap(lambda start, end, step: arange(start, end, step)) start = mindspore.Tensor([1., 2., 3.]) end = mindspore.Tensor([25., 26., 27.]) step = mindspore.Tensor([1, 1, 1])   Specify a constant step  When using the batched operation, check if the bug condition is triggered batch_arange(start, end, step) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] UTILS(2666424,7fb27acc4740,python):2025032709:28:52.791.845 [mindspore/ccsrc/utils/comm_manager.cc:80] GetInstance] CommManager instance for CPU not found, return default instance. Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 8, in      batch_arange(start, end, step)   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1016, in staging_specialize     out = _MindsporeFunctionExecutor(func, hash_obj, dyn_args, process_obj, jit_config)(*args, **kwargs)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 190, in wrapper     results = fn(*arg, **kwargs)               ^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 631, in __call__     raise err   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 625, in __call__     phase = self.compile(self.fn.__name__, *args_list, **kwargs)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 729, in compile     is_compile = self._graph_executor.compile(self.fn, compile_args, kwargs, phase, True)                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TypeError: Parse Lambda Function Fail. Node type must be Lambda, but got Call. Please check lambda expression to make sure it is defined on a separate line.  For example, the code 'func = nn.ReLU() if y      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 11, in test_bug     gradient = vjp_fn(v)                ^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py"", line 968, in wrap_container     return _vjp_grad_op(fn_)(*inputs, sens)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/composite/base.py"", line 645, in after_grad     return grad_(fn_)(*args, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 190, in wrapper     results = fn(*arg, **kwargs)               ^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/composite/base.py"", line 618, in after_grad     out = _pynative_executor.grad(fn, grad_, weights, grad_position, *run_args)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1538, in grad     return self._executor.grad(grad, obj, weights, grad_position, *args)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: Failure info [The given sens gradient's size should be same as out of network!].   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/pynative/grad/function/func_grad.cc:1234 CheckSensShapeAndType ```  Bug 13: mindspore.numpy.ones_like Code: ``` import mindspore.numpy as np import mindspore.ops as ops import mindspore as ms def test_bug():     shape = (1024 * 256 + 1, 8192)     device = ms.context.get_context(""device_target"")      dtype = ms.float16      x = np.ones(shape, dtype=dtype)     y = np.tanh(x)     y_grad = np.ones_like(y)      y.backward(y_grad)  if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 14, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 10, in test_bug     y_grad = np.ones_like(y)               ^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 1092, in ones_like     return _x_like(a, dtype, shape, ones)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 1010, in _x_like     dtype_out = _get_dtype(prototype)                 ^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 996, in _get_dtype     return array_like.dtype            ^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/_stub_tensor.py"", line 100, in dtype     self.stub_dtype = self.stub.get_dtype()                       ^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The size_t value(2147491840) exceeds the maximum value of int.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:34 SizeToInt ```  Bug 14: mindspore.ops.argmax Code: ``` import numpy as np from mindspore import Tensor from mindspore import ops def test_bug():     g = Tensor(np.empty((0, 4), dtype=np.float32))     result = ops.argmax(g) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2668082,7f929cb74640,python):2025032709:37:35.898.328 [mindspore/ccsrc/kernel/kernel.h:952] CheckShapeNull] For 'Argmax', the shape of input cannot contain zero, but got [const vector]{0} [ERROR] RUNTIME_FRAMEWORK(2668082,7f937ef28740,python):2025032709:37:35.898.748 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Default/Argmaxop0] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:574 CreateKernel ```  Bug 15:  Code: ``` import mindspore from mindspore import nn, Tensor from mindspore import jacfwd import numpy as np class MyNet(nn.Cell):     def __init__(self, n_input, hidden_size):         super(MyNet, self).__init__()         self.layer = nn.LSTM(input_size=n_input, hidden_size=hidden_size)         self.layer_out = nn.Dense(hidden_size, 1)     def construct(self, x):         jacobian = jacfwd(self.RNN_forward)(x)         return jacobian     def RNN_forward(self, x):         output, _ = self.layer(x)         return self.layer_out(output) def test_bug():     try:         batch = 10         seq_len = 12         net = MyNet(n_input=3, hidden_size=20)         x = Tensor(np.random.rand(batch, seq_len, 3).astype(np.float32))         _ = net(x)         print(""No bug: forward pass completed without error"")     except Exception as e:         err_msg = str(e)         if ""some_error_keyword"" in err_msg:              pass         else:             print(f""Other error: {err_msg}"") if __name__ == ""__main__"":     test_bug() ``` Output: ``` Other error: Illegal primitive: Primitive LSTMGrad's bprop not defined.node:ValueNode fake_bprop, location:   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/jit/ps/validator.cc:84 ValidateOperatio ```  Bug 16:  Code: ``` from mindspore import jvp, Tensor import mindspore.nn as nn import numpy as np class Dummy:          def __torch_function__(cls, func, types, args=(), kwargs=None):         if kwargs is None:             kwargs = {}         if func is jvp:             return 1         return NotImplemented def test_bug():     try:         x = Dummy()          v = Dummy()          result = jvp(lambda x, y: (x + y, y), (x, x), (v, v))         if result[1] == 1:               pass         else:             pass     except Exception as e:         print(f""Other error: {str(e)}"") if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] UTILS(2669424,7f1180607740,python):2025032709:41:21.304.174 [mindspore/ccsrc/utils/comm_manager.cc:80] GetInstance] CommManager instance for CPU not found, return default instance. Other error: Parse Lambda Function Fail. Node type must be Lambda, but got Call. Please check lambda expression to make sure it is defined on a separate line.  For example, the code 'func = nn.ReLU() if y < 1 else lambda x: x + 1' rewritten as 'if y < 1:     func = nn.ReLU() else:     func = lambda x: x + 1 'will solve the problem.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/jit/ps/parse/parse.cc:570 ParseFuncGraph   The Traceback of Net Construct Code:   0 In file /export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py:774, 19~46             return _wrap_container_inner(*arg)                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~  1 In file /export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py:744~747, 8~37         if has_aux:  2 In file /export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py:747, 22~24             outputs = fn(*jvp_inputs)                       ^~  (See file '/export/d2/******/mindspore/rank_0/om/analyze_fail.ir' for more details. Get instructions about `analyze_fail.ir` at https://www.mindspore.cn/search?inputValue=analyze_fail.ir) ```  Bug 17: mindspore.ops.cdist Code: ``` import numpy as np from mindspore import Tensor, ops def test_bug():     x1 = Tensor(np.random.randn(0, 3, 4).astype(np.float32))   Shape (0, 3, 4)     x2 = Tensor(np.random.randn(1, 2, 4).astype(np.float32))   Shape (1, 2, 4)     actual = ops.cdist(x1, x2, p=2.0) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [ERROR] KERNEL(2669635,7fc653f74640,python):2025032709:43:09.932.604 [mindspore/ops/kernel/cpu/cdist_cpu_kernel.cc:77] Resize] invalid input shape, the batch shape of input0 must be the same as the shape of input1 ,but got 'input0_shape[0]': 0 and 'input1_shape[0]': 1, kernel_name_ Cdist [ERROR] RUNTIME_FRAMEWORK(2669635,7fc7362e9740,python):2025032709:43:09.933.050 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Default/Cdistop0] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:574 CreateKernel ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) MindSpore should be able to catch these errors and provide graceful error info.    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-27T09:57:33+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBWMCY
yangzhenzhang,modify ut for auto parallel interface,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any. 修改并行新接口的ut用例  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request. 原有用例不太规范，比如没有使用参数延后初始化，存在冗余代码等；  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-03-26T17:35:05+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBWIK2
tanxinglian,[CT][MS][OPS][ops.atleast_3d][function][全量]atleast_3d GE模式存在精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > atleast_3d GE模式存在精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_atleast_3d_float64_8d_4x4x4x3x3x7x5x8_random >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative):Graph >    Excute Mode(e.g., O0\O1\O2)：910A不设置 910B设置为O2 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_f_atleast_3d.py::test_f_atleast_3d_float64_8d_4x4x4x3x3x7x5x8_random  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```        def test_f_atleast_3d_float64_8d_4x4x4x3x3x7x5x8_random():         inputs = Tensor(np.random.randn(4, 4, 4, 3, 3, 7, 5, 8), mstype.float64)         fact = Atleast3dMock(             inputs=[inputs]) >       fact.forward_cmp() ../test_f_atleast_3d.py:442:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_3d_ops.py:129: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_3d_ops.py:103: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_3d_ops.py:100: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[ 2.94048584e01,  1.13336308e01, 3.25421547e01, ...,              1.44889729e+00, 1.31045364e+00,  7...2569e02, 6.89365756e01, 1.86348729e+00, ...,              1.81737331e+00, 9.07001391e01,  9.43350886e01]]]]]]]) data_me = array([[[[[[[ 1.31357033e+00,  1.53292253e01,  9.86229017e01, ...,               4.28676765e01, 2.27885664e+00, 7...6286e01,  2.95932361e01,  2.54707393e01, ...,               2.15095707e+00, 3.26449914e01,  3.97923877e01]]]]]]]) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[ 0.29404858  0.11333631 0.32542155 ... 1.81737331 0.90700139 E         0.94335089] E       data_me_error:[ 1.31357033  0.15329225  0.98622902 ...  2.15095707 0.32644991 E         0.39792388] E       loss:[1.01952175 0.03995595 1.31165056 ... 3.96833038 0.58055148 0.54542701] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productLine=2012%20Laboratories&taskId=8b3ba17d2ed4ffcf3bfce79440b6b48d029e4a43be789fc383ad6d91c173a746&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F&title=CT_mindspore_ascend910a_feature_full_master_124b164ee5_20250326%2009:40:33&productId=mindspore&cidaProjectId=c3a0a966ddcd43158ed878c2783678be&isMergedTask=true&testcaseid=67bacdd29b7077065374f5e0&workspaceId=67de910ef31fc3250cb57b42    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-26T10:40:12+08:00,"gitee,foruda,rca/others,rct/oldrelease,ctl/componenttest",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBWC88,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：atleast3d算子存在精度错误 根因： 非连续输入场景没有拦截，导致精度误差  Fix Solution GE不再支持非连续输入，用例需要你切换到kbk后端执行  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83634 PR合入后daily包回归 测试建议：需要切换执行后端为kbk  Selftest Report & DT Review 用例自测ok 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81245 PR合入时间：2025年/3月/7日 问题是否偶现：否,"GE不再支持非连续输入,已正确拦截，用例需适配 !输入图片说明 !输入图片说明"
tanxinglian,[CT][MS][OPS][ops.atleast_2d/atleast_1d][function][全量]atleast_2d/atleast_1d GE模式存在精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > atleast_2d/atleast_1d GE模式存在精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_atleast_2d_one_input test_f_atleast_2d_float64_8d_4x4x4x3x3x7x5x8_random test_f_atleast_1d_float64_8d_4x4x4x3x3x7x5x8_random >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：910A不设置 910B设置为O2 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_f_atleast_2d.py::test_f_atleast_2d_one_input pytest s v test_f_atleast_2d.py::test_f_atleast_2d_float64_8d_4x4x4x3x3x7x5x8_random pytest s v test_f_atleast_1d.py::test_f_atleast_1d_float64_8d_4x4x4x3x3x7x5x8_random  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       def test_f_atleast_2d_one_input():         x1 = Tensor(np.array(np.random.randn(2, 3)).astype(np.float32))         input_x = x1         fact = Atleast2dMock(inputs=[input_x]) >       fact.forward_cmp() ../test_f_atleast_2d.py:333:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_2d_ops.py:134: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_2d_ops.py:107: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_2d_ops.py:104: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0.710087  , 0.15930213, 0.9889787 ]], dtype=float32) data_me = array([[ 1.2614635 , 0.04235008, 1.9021045 ]], dtype=float32) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_f_atleast_2d.py:349:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_2d_ops.py:134: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_2d_ops.py:107: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_2d_ops.py:104: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[6.47150725e01,  5.55300267e01, 3.28036543e01, ...,               2.40420912e01, 3.99763457e02, 1...7864e01,  9.67802708e01, 1.09830324e+00, ...,              2.69247352e01,  1.40805548e01, 1.77464795e+00]]]]]]]) data_me = array([[[[[[[ 8.13775657e01,  8.72998526e01, 2.32492671e+00, ...,              3.59323163e01,  9.72418807e02, 1...1129e+00,  2.57996330e01, 1.27029780e+00, ...,              3.75397298e01, 8.99975487e01,  5.46112136e01]]]]]]]) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_f_atleast_1d.py:441:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_1d_ops.py:129: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_1d_ops.py:103: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_1d_ops.py:100: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[ 1.92223194e+00,  1.19662758e+00,  1.57134805e+00, ...,               5.36740821e01, 6.18361852e02,  1...3960e01, 1.17214672e01, 1.08765067e+00, ...,              2.25559525e01, 4.03151114e01,  1.52303502e01]]]]]]]) data_me = array([[[[[[[ 4.48446527e01,  1.95218101e+00,  8.26326072e01, ...,              8.63563393e01, 5.87472310e01, 1...5818e01,  1.75759792e+00, 4.45418779e01, ...,              4.74295572e01,  6.99296377e01,  1.11847999e02]]]]]]]) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[ 1.92223194  1.19662758  1.57134805 ... 0.22555952 0.40315111 E         0.1523035 ] E       data_me_error:[ 0.44844653  1.95218101  0.82632607 ... 0.47429557  0.69929638 E         0.0111848 ] E       loss:[1.47378541 0.75555342 0.74502198 ... 0.24873605 1.10244749 0.1411187 ] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007:58:12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67babc824503c84f0a0558a2&workspaceId=67dec2d0e00c6b20d42488d0 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03mb1082tjvbv/&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007%3A58%3A12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67babc7e4503c84f0a0557da&workspaceId=67dec2d0e00c6b20d42488d0 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03mb1082tjvbv/&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007%3A58%3A12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67bad65584dee72f16df2e9e&workspaceId=67de910ef31fc3250cb57b42    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-25T18:51:03+08:00,"gitee,foruda,rca/others,rct/oldrelease,ctl/componenttest",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBW7SZ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,问题：GE模式，atleast_2d/atleast_1d 当输入参数为\*Tensor时，计算结果错误。 定位：接口只调用了ExpandDIms算子增加维度，并未修改输入数据内容，dump算子输入输出数据发现，后端处理后给到算子输入错误（第二个输入与第一个输入重复，原始第二个输入丢失）。测试其它算子例如addn，当输入为\*Tensor时，计算结果同样错误，错误类型与atleast_2d一致。 原始输入： !输入图片说明 dump addn输入： !输入图片说明,问题根因：GE后端解耦 https://gitee.com/mindspore/mindspore/pulls/82691 引入，之前GE会自动把Tensor转成连续的，但是需要依赖aclnn算子，为了保证GE后端的独立性，解耦后，不再做Tensor非连续到连续的转换，而是换成Tensor是否连续的校验，对应的代码改动如下： !输入图片说明, Appearance & Root Cause 问题：atleast算子存在精度错误 根因： 非连续输入场景没有拦截，导致精度误差  Fix Solution GE不再支持非连续输入，用例需要你切换到kbk后端执行  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83634 PR合入后daily包回归 测试建议：需要切换执行后端为kbk  Selftest Report & DT Review 用例自测ok 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81245 PR合入时间：2025年/3月/7日 问题是否偶现：否,"GE不再支持非连续输入,已正确拦截，用例需适配 !输入图片说明 !输入图片说明 !输入图片说明 !输入图片说明"
虞良斌,Add scenario restrictions for offline parsing step_list,,2025-03-25T17:18:51+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBW6O3
tanxinglian,[CT][MS][OPS][ops.Adam/nn.Adam][function][全量][dvm]Adam O1模式偶现计算结果与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.Adam O1模式偶现计算结果与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_n_adam_forward_inputn_16_inputc_1024_outputc_16_bias_false_lr_0001_epoch_1_dtype_fp16 test_p_adam_input_6d_f32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O1 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O1 export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_n_adam.py::test_n_adam_forward_inputn_16_inputc_1024_outputc_16_bias_false_lr_0001_epoch_1_dtype_fp16 count 30 pytest s v  test_adam.py::test_p_adam_input_6d_f32 count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason=""SoftmaxCrossEntropyWithLogits does not support float16"")     (reason='tensorflow 不支持float16输入，输出为nan, id=I8T821')     def test_n_adam_forward_inputn_16_inputc_1024_outputc_16_bias_false_lr_0001_epoch_1_dtype_fp16(             amsgrad=False):         fact = AdamFactory(input_n=16, input_c=1024, output_c=16, has_bias=False, epoch=1, lr=1e3,                            beta1=0.9, beta2=0.999, eps=1e8, weight_decay=0.0, loss_scale=1.0,                            locking=False, nesterov=False, amsgrad=amsgrad, dtype=np.float16)         fact.loss = 0.01 >       fact.forward_cmp() ../test_n_adam.py:42:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/nn/adam_ops.py:143: in forward_cmp     allclose_nparray(out_tf, out_me, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,         nan, nan, nan],        [nan, nan, nan... nan],        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,         nan, nan, nan]], dtype=float16) data_me = array([[ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,          nan,  nan,  nan,  nan,  nan],      ...nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,          nan,  nan,  nan,  nan,  nan]], dtype=float16) rtol = 0.01, atol = 0.01     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_adam.py:181:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/primitive/adam_ops.py:112: in forward_cmp     allclose_nparray(exp_var, out_var[0], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[ 5.18   ,  5.36   ],            [ 5.754  ,  3.414  ]],           [[ 3.557  , 11.41   ],            ...    [  0.5723 ,  3.71   ]],           [[ 3.9    ,  4.684  ],            [  0.0703 ,  4.582  ]]]]]], dtype=float16) data_me = array([[[[[[ 5.18   ,  5.355  ],            [ 5.76   ,  3.412  ]],           [[ 3.557  , 11.41   ],            ...    [  0.5723 ,  3.71   ]],           [[ 3.9    ,  4.68   ],            [  0.07227,  4.582  ]]]]]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[5.754   0.11816 3.895   2.574   2.635   4.215   0.09766  0.5854 E         0.0703 ] E       data_me_error:[5.76    0.1211  3.887   2.57    2.639   4.207   0.0996   0.5806 E         0.07227] E       loss:[0.007812 0.00293  0.007812 0.003906 0.003906 0.007812 0.001953 0.004883 E        0.001953] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199040&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_dvm_20250322%2021:47:08&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67bea9c24503c84f0a137e34&workspaceId=67df83e7a3913b4f08c4a32a https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199040&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_dvm_20250322%2021:47:08&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67ba28957b13446a61503ef8&workspaceId=67e0a68a8dd14476536a316d    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-25T17:10:35+08:00,"gitee,foruda,ctl/componenttest,rct/bugfix,rca/codelogic",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBW6I7,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否," Appearance & Root Cause 问题：O1模式下，Adam算子偶现精度问题 根因： 1、 O1模式的算子实现中，手动使用结合律和交换律化简了一些表达式。这种化简在fp16下，部分场景会导致精度于tensorflow不一致。  Fix Solution 严格按照Adam论文中给出的公式进行计算  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83576 PR合入后daily包回归 测试建议：使用现有用例进行测试即可。  Selftest Report & DT Review ``` pytest v test_adam.py::test_p_adam_input_6d_f32 count 30 ======================================================================================================== test session starts ========================================================================================================= platform linux  Python 3.9.19, pytest8.3.1, pluggy1.5.0  /home/duxin/miniconda3/envs/py3.9/bin/python cachedir: .pytest_cache rootdir: /home/duxin/MindSporeTest/operations plugins: xdist3.6.1, repeat0.9.3 collected 30 items test_adam.py::test_p_adam_input_6d_f32[130] PASSED [ 3%] test_adam.py::test_p_adam_input_6d_f32[230] PASSED [ 6%] test_adam.py::test_p_adam_input_6d_f32[330] PASSED [ 10%] test_adam.py::test_p_adam_input_6d_f32[430] PASSED [ 13%] test_adam.py::test_p_adam_input_6d_f32[530] PASSED [ 16%] test_adam.py::test_p_adam_input_6d_f32[630] PASSED [ 20%] test_adam.py::test_p_adam_input_6d_f32[730] PASSED [ 23%] test_adam.py::test_p_adam_input_6d_f32[830] PASSED [ 26%] test_adam.py::test_p_adam_input_6d_f32[930] PASSED [ 30%] test_adam.py::test_p_adam_input_6d_f32[1030] PASSED [ 33%] test_adam.py::test_p_adam_input_6d_f32[1130] PASSED [ 36%] test_adam.py::test_p_adam_input_6d_f32[1230] PASSED [ 40%] test_adam.py::test_p_adam_input_6d_f32[1330] PASSED [ 43%] test_adam.py::test_p_adam_input_6d_f32[1430] PASSED [ 46%] test_adam.py::test_p_adam_input_6d_f32[1530] PASSED [ 50%] test_adam.py::test_p_adam_input_6d_f32[1630] PASSED [ 53%] test_adam.py::test_p_adam_input_6d_f32[1730] PASSED [ 56%] test_adam.py::test_p_adam_input_6d_f32[1830] PASSED [ 60%] test_adam.py::test_p_adam_input_6d_f32[1930] PASSED [ 63%] test_adam.py::test_p_adam_input_6d_f32[2030] PASSED [ 66%] test_adam.py::test_p_adam_input_6d_f32[2130] PASSED [ 70%] test_adam.py::test_p_adam_input_6d_f32[2230] PASSED [ 73%] test_adam.py::test_p_adam_input_6d_f32[2330] PASSED [ 76%] test_adam.py::test_p_adam_input_6d_f32[2430] PASSED [ 80%] test_adam.py::test_p_adam_input_6d_f32[2530] PASSED [ 83%] test_adam.py::test_p_adam_input_6d_f32[2630] PASSED [ 86%] test_adam.py::test_p_adam_input_6d_f32[2730] PASSED [ 90%] test_adam.py::test_p_adam_input_6d_f32[2830] PASSED [ 93%] test_adam.py::test_p_adam_input_6d_f32[2930] PASSED [ 96%] test_adam.py::test_p_adam_input_6d_f32[3030] PASSED [100%] ``` 是否需要补充 ST/UT：否（对现有ST用例进行修改）。 原因：已有ST用例，更改ST用例的输入数据构造方法，即可对该场景进行看护。  Introduction Analysis 引入类型：特性合入引入 引入PR：Not Applicable PR合入时间：2020/03/27 问题是否偶现：是",附：Tensorflow ApplyAdamKernel gpu kernel 计算逻辑： !输入图片说明,"【回归版本号】：__commit_id__ = '[sha1]:45e5acc8,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
tanxinglian,[CT][MS][OPS][mint.div][function][全量]mint.div ascend偶现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.div ascend偶现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_f_div_float64_6d_4x3x9x5x7x7_random_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910B：设置O0 910A:不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_mint_f_div.py::test_mint_f_div_float64_6d_4x3x9x5x7x7_random_broadcast count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_mint_f_div_float64_6d_4x3x9x5x7x7_random_broadcast():         input_x = Tensor(np.random.randn(4, 3, 9, 5, 7, 7), mstype.float64)         other = Tensor(np.random.randn(4, 3, 1, 5, 7, 7), mstype.float64)         rounding_mode = None         fact = DivMock(             attributes={'rounding_mode': rounding_mode},             inputs=[input_x, other])         fact.forward_cmp() >       fact.grad_cmp() ../test_mint_f_div.py:508:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/functional/div_mint.py:212: in grad_cmp     allclose_nparray(grad_pytorch[1], grad_mindspore[1], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[1.78287809e+00, 9.36672920e+00,  5.78629671e+02, ...,             1.66045571e+00,  4.02752162e+00,  2.8...322961e+01, 1.10456732e+03, 2.80809809e01, ...,             5.81548591e+00, 2.55709396e+00, 6.68863395e+00]]]]]]) data_me = array([[[[[[1.78287827e+00, 9.36672988e+00,  5.78629658e+02, ...,             1.66045559e+00,  4.02752160e+00,  2.8...322967e+01, 1.10456733e+03, 2.80809797e01, ...,             5.81548641e+00, 2.55709395e+00, 6.68863375e+00]]]]]]) rtol = 1e05, atol = 1e05     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0.21975757] E       data_me_error:[0.21973163] E       loss:[2.59418196e05] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199039&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910b_op_pynative_standalone_full_20250323%2000:20:07&isMergedTask=false&nodeDate=20250323&year=20242025&TestNow=true&testcaseid=67ba43cea052d7325367a917&workspaceId=67e03b336ae691186d6dbe23    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-25T16:56:58+08:00,"gitee,foruda,rct/oldrelease,ctl/componenttest,rca/algorithm",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBW699,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：偶现精度问题 根因： MindSpore与Pytorch对other反向的计算顺序不一致（数学上等价） ms计算顺序：`dy =  (dout / y * out)` pt计算顺序：`dy =  dout * ((x / y) / y )`  Fix Solution 计算顺序完全对齐Pytorch  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83814 PR合入后daily包回归 测试建议：无。  Selftest Report & DT Review !输入图片说明 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/64084 PR合入时间：2024年4月17日 问题是否偶现：是,"【回归版本号】：__commit_id__ = '[sha1]:119b7ec4,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
yanghaoran,MindSpore构建流水线切换python3.9适配问题修改,MindSpore构建流水线切换python3.9适配问题修改,2025-03-25T10:59:14+08:00,,open,0,2,https://gitee.com/mindspore/mindspore/issues/IBW17S,4c0e68cfc4367b707a3d57534c61ea88e209cc19 713ff45fa6c9225441c4b841f19729bbea7fa55a 51eaea5647500103288b9787990a77fd524a5594 3d6eda5ecb8fb9e10af913524bb951a9b26336bc bcdddfd54853ec687d8b0325c670782ca92e5e60 0fc9feadbfb1235ca0999ce6db86c73e4ed928e8 083b68c15ace2876d9fde9f991f1a4923c97cc5f 14c535f706c29ea14c108840aeb86e6af6305e80 479308fb55276f01feaa95394ee91e0f859db524 05608c8adf905aefc49cc340ab239c32a3e423b8 造福大众,8509f13f91a07b36f06e87dd94bb6f919a36fd2e ff719619e35391015a9a0366895b4783258aee85 最后两个，一共12个
虞良斌,Added some unit test cases for profiler,,2025-03-24T22:26:05+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBVY1I
虞良斌,Fixed issues related to profiler logs,,2025-03-24T20:05:14+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBVXEI
shiro-zzz,【AR】PyBoost接口适配tensor.unsqueeze_, Tasks 转测对象：tensor.unsqueeze_   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-03-24T19:11:44+08:00,"gitee,foruda,foruda,foruda,foruda,foruda,sig/ops,v2.1.0",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBVX03, torch.Tensor.unsqueeze_既是view算子又是inplace算子，而目前pyboost框架和KBK均并未考虑此种场景，故记录实现过程中遇到的问题如下： 1.KBK模式的view功能 25年Q1并未合入master交付，故暂不考虑KBK实现 2.Pyboost目前没有一个确定安全的方法，更改input的view。  目前分析的结论如下： 1.torch.Tensor.unsqueeze_已验证可以实现原地更新能力 !输入图片说明 !输入图片说明 2.torch.Tensor.unsqueeze_使用as_strided_实现，而as_strided_的实现如下： !输入图片说明 !输入图片说明 3.torch.Tensor.unsqueeze_的timeline如下，可以看到其无aclnn算子调用，也无流同步逻辑，这似乎表明torch认为更改view的行为是安全的。 !输入图片说明
tanxinglian,[CT][MS][OPS][ops.xlogy][function][全量]xlogy GE模式报错RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > xlogy GE模式报错RuntimeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_p_xlogy_input_3d_float64 test_f_xlogy_float64_6d_3x3x4x9x4x5_random_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_xlogy.py::test_p_xlogy_input_3d_float64 pytest s v test_f_xlogy.py::test_f_xlogy_float64_6d_3x3x4x9x4x5_random_broadcast  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason=""aclnn不支持"")     (reason=""aclnn不支持"")     (reason=""aclnn不支持"")     def test_p_xlogy_input_3d_float64():         input_x1 = np.random.randn(7, 6, 12).astype(np.float64)         input_x2 = np.random.randn(7, 6, 12).astype(np.float64)         dtype = np.float64         fact = XlogyMock(inputs=[input_x1, input_x2], dtype=dtype)         fact.forward_cmp() >       fact.grad_cmp() ../test_xlogy.py:185:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/primitive/xlogy_ops.py:107: in grad_cmp     input_grad_mindspore = self.grad_mindspore_impl() ../../share/ops/primitive/xlogy_ops.py:73: in grad_mindspore_impl     input_grad = grad_net(x1, x2, output_grad) ../../share/grad.py:39: in __call__     out = super().__call__(*inputs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1135: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1576: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1558: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = GradOfAllInputs(   (network): WrapOp() ) phase = 'train.1742640611478836224.140236752847152.2...', do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[7, 6, 12], dtype=Float64, value= [[[ 4.92374478e01, 1.21381368e+00,  5.47682373e01 ...  1.71437941e+...0e01],   [ 1.19023335e+00,  1.13959236e+00, 7.52813579e01 ...  4.80040582e01, 3.20836256e+00, 8.71049552e01]]])) kwargs = {}, key_id = '1402367528471521742640611478836224', key = 2 parameter_ids = '', raw_phase = 'train' full_function_name = 'GradOfAllInputs.2.94219103284192' echo_function_name = 'GradOfAllInputs'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         _init_auto_parallel_context(obj)         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             _clear_auto_parallel_context(obj)             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         gc.collect() >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: Compile graph kernel_graph2 failed. E        E        E        Ascend Error Message: E        E       EZ3002: [PID: 1068243] 2025032218:50:12.128.532 Optype [MaskedFill] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[Dynamic shape check]: data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}[Static shape check]:data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}.[THREAD:1071846] E               Possible Cause: The operator type is unsupported in the operator information library due to specification mismatch. E               Solution: Submit an issue to request for support at https://gitee.com/ascend, or remove this type of operators from your model. E               TraceBack (most recent call last): E               Optype [MaskedFill] of Ops kernel [aicpu_ascend_kernel] is unsupported. Reason: data_type DT_DOUBLE of input[0, x] is unsupported, op type[MaskedFill]..[THREAD:1071846] E               No supported Ops kernel and engine are found for [Gradients/Default/networkWrapOp/Grad_Xlogy/MaskedFillop0], optype [MaskedFill].[THREAD:1071846] E               Assert ((SelectEngine(node_ptr, exclude_engines, is_check_support_success, op_info)) == ge::SUCCESS) failed[FUNC:operator()][FILE:engine_place.cc][LINE:148][THREAD:1071846] E               RunAllSubgraphs failed, graph=kernel_graph2.[FUNC:RunAllSubgraphs][FILE:engine_place.cc][LINE:122][THREAD:1068243] E               [Call][PreRun] Failed, graph_id:3, session_id:0.[FUNC:CompileGraph][FILE:graph_manager.cc][LINE:4538][THREAD:1068243] E               [Compile][Graph]Compile graph failed, error code:1343225857, session_id:0, graph_id:3.[FUNC:CompileGraph][FILE:ge_api.cc][LINE:1279][THREAD:1068243] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/backend/ge_backend/executor/ge_graph_executor.cc:482 CompileGraph /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1958: RuntimeError ``` ```       (reason=""aclnn not support float64"")     (reason=""aclnn not support float64"")     (reason=""aclnn not support float64"")     def test_f_xlogy_float64_6d_3x3x4x9x4x5_random_broadcast():         input_x = Tensor(np.random.randn(3, 3, 4, 9, 4, 5), mstype.float64)         other = Tensor(np.random.randn(3, 1, 4, 9, 4, 5), mstype.float64)         fact = XlogyMock(             inputs=[input_x, other])         if context.get_context(""device_target"") == ""Ascend"":              标杆pytorch 1.12.0 及mindspore 在Acsend上出现nan             fact.forward_mindspore_impl() >           fact.grad_mindspore_impl() ../test_f_xlogy.py:518:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/xlogy_ops.py:142: in grad_mindspore_impl     grad = grad_net(self.input_x, self.other_x, out_grad_ms) ../../share/grad.py:39: in __call__     out = super().__call__(*inputs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1135: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1576: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1558: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = GradOfAllInputs(   (network): WrapOp() ) phase = 'train.1742598079894010624.140663141206992.2...', do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[3, 3, 4, 9, 4, 5], dtype=Float64, value= [[[[[[ 8.33213459e01, 1.99972164e+00, 1.29058858e+00,  2.77...02,  1.85621055e02],      [ 1.99988942e+00, 1.20096894e+00, 4.71020176e01,  9.31564313e01, 1.15255923e+00]]]]]])) kwargs = {}, key_id = '1406631412069921742598079894010624', key = 2 parameter_ids = '', raw_phase = 'train' full_function_name = 'GradOfAllInputs.2.94640366888464' echo_function_name = 'GradOfAllInputs'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         _init_auto_parallel_context(obj)         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             _clear_auto_parallel_context(obj)             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         gc.collect() >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: Compile graph kernel_graph2 failed. E        E        E        Ascend Error Message: E        E       EZ3002: [PID: 2003449] 2025032207:01:20.624.712 Optype [MaskedFill] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[Dynamic shape check]: data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}[Static shape check]:data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}.[THREAD:2009404] E               Possible Cause: The operator type is unsupported in the operator information library due to specification mismatch. E               Solution: Submit an issue to request for support at https://gitee.com/ascend, or remove this type of operators from your model. E               TraceBack (most recent call last): E               Optype [MaskedFill] of Ops kernel [aicpu_ascend_kernel] is unsupported. Reason: data_type DT_DOUBLE of input[0, x] is unsupported, op type[MaskedFill]..[THREAD:2009404] E               No supported Ops kernel and engine are found for [Gradients/Default/networkWrapOp/Grad_Xlogy/MaskedFillop0], optype [MaskedFill].[THREAD:2009404] E               Assert ((SelectEngine(node_ptr, exclude_engines, is_check_support_success, op_info)) == ge::SUCCESS) failed[FUNC:operator()][FILE:engine_place.cc][LINE:148][THREAD:2009404] E               RunAllSubgraphs failed, graph=kernel_graph2.[FUNC:RunAllSubgraphs][FILE:engine_place.cc][LINE:122][THREAD:2003449] E               [Call][PreRun] Failed, graph_id:3, session_id:0.[FUNC:CompileGraph][FILE:graph_manager.cc][LINE:4538][THREAD:2003449] E               [Compile][Graph]Compile graph failed, error code:1343225857, session_id:0, graph_id:3.[FUNC:CompileGraph][FILE:ge_api.cc][LINE:1279][THREAD:2003449] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/backend/ge_backend/executor/ge_graph_executor.cc:482 CompileGraph /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1958: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007:58:12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67ba374c4503c84f0a03a079&workspaceId=67de9aa3f31fc3250cb5941d https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007:58:12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67bade0c7b13446a6152933c&workspaceId=67ddf0e9e00c6b20d42232c3    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-24T18:33:38+08:00,"gitee,foruda",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBVWSW,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：接口变更，GE回退double类型支持 根因： 接口变更，GE回退double类型支持，测试仓用例未及时适配  Fix Solution 无需修复  Fix Description & Test Suggestion 无 测试建议：无  Selftest Report & DT Review 无 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：用例未适配 引入PR：无 PR合入时间：年/月/日 问题是否偶现：是/否,接口变更 适配用例 !输入图片说明
tanxinglian,[CT][MS][OPS][mint.fmod][function][全量]test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast报错计算结果类型与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast报错计算结果类型与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b:设置O0,910a:不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_mint_f_fmod.py::test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     ()     def test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast():         input_x = Tensor(np.random.randn(39, 1, 19, 1), mstype.float32)         other = Tensor(np.random.randn(39, 1, 1, 8), mstype.float64)         fact = FmodMock(             inputs=[input_x, other]) >       fact.forward_cmp() ../test_mint_f_fmod.py:592:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =      def forward_cmp(self):         out_mindspore = self.forward_mindspore_impl()         out_cmp = self.forward_pytorch_impl()          torch cpu 输入tensor uint8+ 数字float,输出类型是float32,ms 与pta 输出类型都是uint8         if self.ms_type not in (mstype.bfloat16,): >           assert out_cmp.dtype == out_mindspore.dtype E           AssertionError ../../share/mint/functional/fmod_mint.py:174: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199064&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250322%2005:48:44&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67dee355f31fc3250cb644e1&workspaceId=67dee353e00c6b20d424fec0&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-24T18:17:01+08:00,"foruda,rca/others,rct/oldrelease,ctl/componenttest",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBVWMS,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否," Appearance & Root Cause 问题：mint.fmod, tensor类型分别为float32和float64是输出类型不正确 根因：未正确的进行类型提升  Fix Solution 修改 InferType 实现  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83547 重写了InferType函数逻辑  Selftest Report & DT Review !输入图片说明 本地自验通过 是否需要补充ST/UT：否 原因：已有UT  Introduction Analysis 引入类型：Bugfix修复引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82978 PR合入时间：2025/3/18 问题是否偶现：否","【回归版本号】：__commit_id__ = '[sha1]:4459ab4c,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
tanxinglian,"[CT][MS][OPS][nn.proximaladagrad][function][全量]nn.proximaladagrad 910A pynative模式报错RuntimeError: The ge backend only support contiguous inputs, please check."," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > nn.proximaladagrad 910A pynative模式报错RuntimeError: The ge backend only support contiguous inputs, please check.  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_n_proximaladagrad_gatherv2_3x4x1_0x1_axis_1 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_n_proximaladagrad.py::test_n_proximaladagrad_gatherv2_3x4x1_0x1_axis_1  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```  ()     def test_n_proximaladagrad_gatherv2_3x4x1_0x1_axis_1():         fact = ProximalAdagradFactory((3, 4, 1), (0, 1), (2, 3), epoch=2,                                       accum=0.1, learning_rate=0.01, l1=0.0,                                       l2=0.0, use_locking=False, loss_scale=1.0,                                       weight_decay=0.0, axis=1, dtype1=np.float32, dtype2=np.int32) >       fact.forward_cmp() test_n_proximaladagrad.py:157: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/proximaladagrad_ops.py:114: in forward_cmp     out_me = self.forward_mindspore_impl() ../share/ops/nn/proximaladagrad_ops.py:84: in forward_mindspore_impl     train_network(inputs, label) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1146: in __call__     return self.construct(*args, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/wrap/cell_wrapper.py:429: in construct     return self._no_sens_impl(*inputs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/wrap/cell_wrapper.py:451: in _no_sens_impl     loss = F.depend(loss, self.optimizer(grads)) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1146: in __call__     return self.construct(*args, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:1193: in staging_specialize     out = ms_function_executor(*args, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:193: in wrapper     results = fn(*arg, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:647: in __call__     output = _pynative_executor.grad_jit(*new_inputs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self =  args = ((Tensor(shape=[3, 4, 1], dtype=Float32, value= [[[ 1.66666672e01],   [ 1.66666672e01],   [ 0.00000000e+00],   [ 0.0...0e+00],   [ 0.00000000e+00]],  [[ 1.66666672e01],   [ 1.66666672e01],   [ 0.00000000e+00],   [ 0.00000000e+00]]]),),)     def grad_jit(self, *args):         """"""         Building grad graph decorated by jit.         Args:             args (tuple): Function or cell decorated by jit input arguments.         Return:             output: The output object of function or cell decorated by jit.         """""" >       output = self._executor.grad_jit(*args) E       RuntimeError: The ge backend only support contiguous inputs, please check. E E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/backend/ge_backend/ge_backend.cc:98 CheckContiguousTensor E E        E        The Traceback of Net Construct Code: E        E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/proximal_ada_grad.py:204~222, 4~22 E            E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/proximal_ada_grad.py:212, 16~53 E               grads = self._grad_sparse_indices_deduplicate(grads) E                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/optimizer.py:520~524, 4~24 E           def _grad_sparse_indices_deduplicate(self, gradients): E           ^ E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/optimizer.py:523, 24~77 E                   gradients = self.map_(F.partial(_indices_deduplicate), gradients) E                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:1618: RuntimeError ``` 完整日志（通过附件上传）：    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-24T18:01:32+08:00,"gitee,foruda,rca/others,ctl/componenttest,rct/newfeature",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBVWFH,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 910A jit默认后端和图模式保持一致，从ms_backend（kbk）改为GE，由于后端解耦后新GE后端仅支持整图下沉和lazyinline，有部分在910A上使用pynative+jit的场景需要进行适配（框架+网络） Fix Solution 框架及网络ge不支持部分jit用kbkpao Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83405 PR合入后daily包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82147 PR合入时间：2025年/3月/14日 问题是否偶现：否,"【回归版本号】：__commit_id__ = '[sha1]:067a7b32,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
徐微,"【master】【OPS】【ops.where】【CPU,GPU】 Where算子CPU与GPU运行结果不一致"," MindSpore Where算子CPU与GPU行为不一致Bug报告  1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore中，`ops.where`算子在CPU和GPU设备上执行时产生不一致的结果。具体表现为当条件为True时，CPU正确返回负值，而GPU却将所有负值转换为0。此差异会导致在不同设备上运行相同模型产生不同结果，影响模型一致性和可靠性。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Testcase Name/ 用例名**: where_bug.py  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 准备测试环境，确保同时支持CPU和GPU后端 2. 测试脚本 ```python     import numpy as np     import mindspore as ms     from mindspore import ops     import os     import sys     import subprocess     import time     def test_where_bug(device=""CPU"", test_case=0):         ms.set_device(device)         ms.set_context(mode=ms.PYNATIVE_MODE)         test_cases = [             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1, 2, 3, 4, 5], ms.int32),                 ""desc"": ""基本测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1000000001, 1000000002, 1000000003, 1000000004, 1000000005], ms.int32),                 ""desc"": ""大数值测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1.5], ms.float32),                 ""y"": ms.Tensor([1.1, 2.2, 3.3, 4.4, 5.5], ms.float32),                 ""desc"": ""浮点数测试(float32)""             },         ]         if test_case >= len(test_cases):             test_case = 0         case = test_cases[test_case]         condition, x, y = case[""condition""], case[""x""], case[""y""]          执行操作         result = ops.where(condition, x, y)          保存结果         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         os.makedirs(results_dir, exist_ok=True)         file_name = f""{device.lower()}_case{test_case}_results.npy""         np.save(f'{results_dir}/{file_name}', result.asnumpy())         print(f""{device}结果: {result}"")         return result     def compare_results(test_case=0):         """"""比较CPU和GPU结果""""""         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         cpu_file = f'{results_dir}/cpu_case{test_case}_results.npy'         gpu_file = f'{results_dir}/gpu_case{test_case}_results.npy'         if not os.path.exists(cpu_file) or not os.path.exists(gpu_file):             print(f""错误: 结果文件不存在，请先运行测试"")             return         cpu_result = np.load(cpu_file)         gpu_result = np.load(gpu_file)         are_equal = np.array_equal(cpu_result, gpu_result)         print(f""CPU和GPU结果是否一致: {are_equal}"")         if not are_equal:             diff_indices = np.where(cpu_result != gpu_result)             diff_count = len(diff_indices[0])             total_count = cpu_result.size             diff_percent = 100 * diff_count / total_count             max_abs_diff = np.max(np.abs(cpu_result  gpu_result))             print(f""不匹配元素: {diff_count} / {total_count} ({diff_percent:.1f}%)"")             print(f""最大差值: {max_abs_diff}"")              完整展示结果             np.set_printoptions(suppress=True)   禁止科学计数法             print(f""CPU结果: {cpu_result}"")             print(f""GPU结果: {gpu_result}"")              显示差异索引和对应值             print(f""有差异的索引: {diff_indices[0]}"")             print(f""这些索引处的CPU值: {cpu_result[diff_indices]}"")             print(f""这些索引处的GPU值: {gpu_result[diff_indices]}"")     def run_all_tests():         """"""运行所有测试用例并比较结果""""""         test_cases = 3         print(""="" * 80)         print(""MindSpore Where操作在CPU和GPU上的结果比较"")         print(""="" * 80)         for case in range(test_cases):             print(f""\n测试用例 {case}:"")             print("""" * 60)              在CPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""CPU"", ""case"", str(case)],                          stdout=subprocess.PIPE)              在GPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""GPU"", ""case"", str(case)],                         stdout=subprocess.PIPE)              比较结果             compare_results(case)             print("""" * 60)     if __name__ == ""__main__"":         import argparse         parser = argparse.ArgumentParser(description='MindSpore Where操作Bug复现')         parser.add_argument('device', type=str, choices=['CPU', 'GPU'], default='CPU')         parser.add_argument('case', type=int, default=0)         parser.add_argument('runall', action='store_true',                          help='自动在CPU和GPU上运行所有测试用例并比较结果')         args = parser.parse_args()         if args.run_all:             run_all_tests()         else:             test_where_bug(args.device, args.case) ``` 2. 运行测试脚本，执行所有测试用例并比较结果:    ```bash    python /home/ms/ms_test/Bug_test/where_bug.py runall    ``` 3. 观察比较结果，特别关注负值在不同设备上的处理差异  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: CPU和GPU应产生一致的结果，特别是对于负值的处理应该相同，不应出现GPU自动将负值转为0的情况。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: ``` 测试用例 0:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [ 1 1  3 1 1] GPU结果: [1 0 3 0 0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 1:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [1000000001         1 1000000003         1         1] GPU结果: [1000000001          0 1000000003          0          0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 2:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1.5 CPU结果: [ 1.1 1.5  3.3 1.5 1.5] GPU结果: [1.1 0.  3.3 0.  0. ] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1.5 1.5 1.5] 这些索引处的GPU值: [0. 0. 0.]  ```  7.Special notes for this issue/备注 (Optional / 选填) 1. 问题特征总结:     仅在条件为`True`时且选择值为负值时出现     同时影响整数和浮点数数据类型     问题与广播机制相关，特别是负值标量被广播时 2. 可能的根本原因:     GPU实现中的符号位处理错误     CUDA内核在执行条件选择时可能截断了负值的符号位     掩码操作实现可能存在缺陷",2025-03-24T16:39:52+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBVUUB
魏琢艺,【master】ring_attention部分场景训练拉起失败," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 开data_broadcast_opt_level时，pp和RingAttention混开报错，训练报 the pointer[value] is null  2.Environment / 环境信息 (Mandatory / 必填) mindsporemaster，mindformersdev，python3.10  **Software Environment / 软件环境 (Mandatory / 必填)**:  3.Related testcase / 关联用例 (Mandatory / 必填) NA  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：llama3_8b，开2122并行，开启ring_atention，配置parallel_speed_up.json其中dataset_broadcast_opt_level=3 > 用例执行命令：bash scripts/msrun_launcher.sh ""run_mindformer.py config ../finetune_llama3_8b.yaml run_mode finetune use_parallel True auto_trans_ckpt False"" 8 9779 output/msrun_log False 7200  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常训练  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** 杨犇",2025-03-24T11:48:27+08:00,gitee,progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IBVQER,Appearance & Root Cause 问题：开data_broadcast_opt_level时，pp和RingAttention混开报错 根因：pp通信和数据broadcast保序pass只考虑了pp中的receive通信算子，没有考虑到RingAttention中的receive通信算子，误认为图中所有的receive算子都有MICRO属性，而ringattention创建的receive是没有这个属性的，所有在getvalue时候遇到了空指针。 Fix Solution 1、pp通信和数据broadcast保序pass中跳过除了pp外创建的Reveive通信算子。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83389 PR合入后daily包回归 测试建议：该问题可以通过特性用例防护，增加pp和RingAttention混开时开启data_broadcast_opt_level场景。 Selftest Report & DT Review 修复后报错不再出现，可以正常训练 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入commit：811bddb329d680bf578a2c47a1c9f2ddb2d02fea opt_dataset_reader 提交于 2024年09月04日 问题是否偶现：否
default32423,`Segmentation fault` in `mindspore.numpy.fft.hfftn` and `mindspore.numpy.fft.rfft2`," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) When running the following code snippet, segmentation fault occurs.  2.Environment / 环境信息 (Mandatory / 必填) Linux CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore 2.5.0  3.Related testcase / 关联用例 (Mandatory / 必填) None  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)  Bug 1 ``` import mindspore.numpy as np test_tensor = np.randint(0, 100, (2, 2), dtype=np.int32) np.fft.hfftn(test_tensor, axes=()) ```  Bug 2 ``` import mindspore from mindspore import Tensor from mindspore import numpy as mnp test_tensor = Tensor(mnp.randint(0, (1 << 15)  1, shape=(1, 1, 1, 1, 1), dtype=mindspore.int32)) mnp.fft.rfft2(test_tensor, axes=()) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) These two APIs should run without `Segmentation fault` to avoid a denial of service attack.  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) Segmentation fault    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-23T15:37:26+08:00,mindspore-assistant,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBVKM8,"import mindspore.numpy as np test_tensor = np.randint(0, 100, (2, 2), dtype = np.int32) np.fft.hfftn(test_tensor, axes=(0, 1)) 目前MindSpore的FFT类接口需要显式传递axes值，如上面的例子所示。"
虞良斌,Fix the state machine record_and_save to record_and_save action,,2025-03-22T20:04:31+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBVI3G
小五要加油,ubuntu22.04，N卡，配置mindspore环境问题, 操作系统：ubuntu22.04 显卡信息：4张T4显卡 nvidia显卡驱动：535.183.06 cuda版本：11.6 cudnn版本：8.5.0.96 gcc版本：11.4 python版本：3.11.11 Tensor版本：8.4.1.5 问题描述：在conda环境中下载mindsporedev之后，运行验证python程序报错：!输入图片说明,2025-03-21T18:12:45+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBVCJF,"尊敬的开发者，您好！ 根据错误信息：""RuntimeError: Unsupported device target GPU. This process only supports one of the 'CPU'""，这表明您安装的MindSpore版本是CPU版本，而不是GPU版本。 确认安装了GPU版本的MindSpore： ``` pip list | grep mindspore ``` 确保安装的是GPU版本，而不是CPU版本。",现在的dev版本在GPU运行的话，需要加上一个环境变量：export CUDA_HOME=/cuda，这个环境变量的路径随便写一个就行，就能绕过一些不必要的检测加载起来GPU后端；不过dev目前也不是正式版，目前官方发布过的GPU正式版本是2.2.14
luoxuewei,tolist接口中隐式类型转换告警处理以及clean code优化,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-21T14:17:38+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBV8FF
孙昊辰,internal add asdop fused_add_topk_div kernel,   Backgroud（背景信息）  deepseek kernel optimization   Origin（信息来源） 算子团队  Benefit / Necessity （价值/作用） improve op efficiency  Design（设计方案） add fused_add_topk_div kernel to internel,2025-03-21T10:26:53+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBV5NH
虞良斌,Fixed an issue where metadata data can be collected by profiler.stop method without schedule,,2025-03-20T21:30:19+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBV31U
虞良斌,Fixed the first step not dot bug in kbk mode,,2025-03-20T21:23:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBV30I
wangpingan,mirrorpad文档有误," 1. 【Document Link】/【文档链接】 https://www.mindspore.cn/docs/zhCN/master/api_python/ops/mindspore.ops.MirrorPad.htmlmindspore.ops.MirrorPad 2. 【Issues Section】/【问题文档片段】 'REFLECT' ：使用零填充输入Tensor。例如，向 [1, 2, 3, 4] 的两边分别填充2个元素，结果为 [3, 2, 1, 2, 3, 4, 3, 2]。 'SYMMETRIC' ：使用Tensor边缘上像素的值填充输入Tensor。例如，向 [1, 2, 3, 4] 的两边分别填充2个元素，结果为 [2, 1, 1, 2, 3, 4, 4, 3]。 3. 【Existing Issues】/【存在的问题】 REFLECT不是使用零填充 4. 【Expected Result】【预期结果】  Please fill in the expected result",2025-03-20T15:47:11+08:00,foruda,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBUZGA,!输入图片说明
chujinjin,非连续判断错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ``` import mindspore import numpy as np from mindspore import Tensor, ops input = Tensor(np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]), mindspore.float32) input_perm = (0, 2, 1) output = ops.transpose(input, input_perm) output.is_contiguous() False output output.is_contiguous() True ``` 打印后，连续状态被改变。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   全后端  **Software Environment / 软件环境 (Mandatory / 必填)**:   迭代版本新增问题样例：（根据实际修改和增删）   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-20T15:08:37+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUYO0,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
yangruoqi713,大模型推理组件代码告警清理,,2025-03-20T10:49:29+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBUUY7
yangruoqi713,DS推理解决方案开发仓代码合入,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-03-20T09:42:49+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBUTNG
zhouyaqiang0,inline不支持动态shape," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-20T09:15:01+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUT7D,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
caifubi,ADS网络执行卡住，堆栈在SplitTensor," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-20T09:14:08+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUT6I,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
tangmengcheng,profiler 采集侧与解析侧数据结构不对应,,2025-03-19T19:39:22+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBUQWD
moran,fix st large log,,2025-03-19T17:35:58+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBUPVC,/retest
zhangyinxia,clean code," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-19T16:01:35+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUNZ2,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
虞良斌,Change char * to string,,2025-03-18T22:33:53+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBUFTB
虞良斌,st use case rectification,,2025-03-18T21:06:57+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBUFI0
虞良斌,Delete the warning log that the operator is not connected in o2 mode in kernel_details,,2025-03-18T17:27:47+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBUDON
虞良斌,Delete the analyse method in profile.rst,,2025-03-18T15:40:49+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBUBI2
cccc1111,AddExt/AddScalar/SubExt/SubScalar增加静态图常量折叠, Tasks 转测对象：AddExt/AddScalar/SubExt/SubScalar对应的常量折叠 对标torch   Background  **1. 标杆情况**   标杆接口链接： 模仿标杆torch的常量折叠特性  **2. MindSpore算子情况**   当前支持数据类型 与torch保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  静态图模式下，不下发到Device侧进行运算  **2. 接口描述**   接口实现： 实现对于AddExt/AddScalar/SubExt/SubScalar对应的常量折叠特性，其中AddExt/SubExt通过python实现，AddScalar/SubScalar通过C++实现。  算子原语   不涉及,2025-03-17T22:12:56+08:00,"foruda,foruda,foruda,foruda,foruda,foruda,foruda,foruda,sig/ops,v2.1.0",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBU3B5,UT用例通过： !输入图片说明 !输入图片说明 !输入图片说明 !输入图片说明 ST用例通过，且常量折叠生效： !AddExt !AddScalar !SubExt !输入图片说明
李伟清,910B推理 deepseek量化模型时AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。,我使用910B推理 deepseek量化模型时一样碰到error：AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。 使用的镜像有两个： 2.0.T3.1800IA2py311openeuler24.03lts	 2.0.T3800IA2py311openeuler24.03lts 模型为：https://modelers.cn/models/State_Cloud/DeepSeekR1W8A8 !输入图片说明,2025-03-17T19:30:29+08:00,"mindspore-assistant,www,www",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBU2B9,看了下，上面链接里的模型，应该不是mindspore框架运行的，根据里面的示例代码应该是torch npu的，可以去昇腾社区的昇腾cann板块问一下： https://www.hiascend.com/forum/forum01061013859211750041.html torch npu的问题没有开单独板块，也可以提个工单咨询： https://www.hiascend.com/support 上面的错误提示，可能是显存或者内存不够导致主进程自动kill了，模型页面上有提到oom的情况
李伟清,910B推理 deepseek量化模型时AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。,我使用910B推理 deepseek量化模型时一样碰到error：AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。 使用的镜像有两个： 2.0.T3.1800IA2py311openeuler24.03lts	 2.0.T3800IA2py311openeuler24.03lts 模型为：https://modelers.cn/models/State_Cloud/DeepSeekR1W8A8 !输入图片说明,2025-03-17T19:30:28+08:00,"mindspore-assistant,www,www",progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IBU2B8,看了下，上面链接里的模型，应该不是mindspore框架运行的，根据里面的示例代码应该是torch npu的，可以去昇腾社区的昇腾cann板块问一下： https://www.hiascend.com/forum/forum01061013859211750041.html torch npu的问题没有开单独板块，也可以提个工单咨询： https://www.hiascend.com/support 上面的错误提示，可能是显存或者内存不够导致主进程自动kill了，模型页面上有提到oom的情况
虞良斌,Remove an older version of the parser code,,2025-03-17T19:25:58+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBU2AL
虞良斌,Modifying the communication operator name redos attack problem,,2025-03-17T17:09:58+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBU0OF
geyuhong,增加Cell.offload()接口,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-03-17T12:05:21+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBTVFK
RongRongStudio,msrun单机双卡运行在910A报错,"Ascend HDK 24.1.RC3 CANN 8.0.0 MindSpore 2.5.0 硬件910ProB 运行代码：https://github.com/mindsporelab/mindnlp/blob/master/llm/inference/llama3/run_llama3_distributed.py 运行命令：msrun worker_num=2 local_worker_num=2 master_port=8118 join=True bind_core=True run_llama3_distributed.py [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.470.315 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 15 source: 127.0.0.1:48616, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.470.397 [mindspore/ccsrc/distributed/rpc/tcp/tcp_client.cc:76] Connect] Failed to connect to the tcp server : 127.0.0.1:8118, retry to reconnect(1/1)... [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:58.704.571 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 15 source: 127.0.0.1:48618, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(85,ffff0a8ef120,python):2025031703:24:58.704.571 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48618 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:58.704.645 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 1 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.970.481 [mindspore/ccsrc/distributed/cluster/topology/compute_graph_node.cc:173] Register] Failed to connect to the meta server node url: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.970.509 [mindspore/ccsrc/distributed/cluster/topology/compute_graph_node.cc:363] ReconnectWithTimeoutWindow] Failed to register and try to reconnect to the meta server. [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:59.204.838 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 16 source: 127.0.0.1:48620, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:59.204.874 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 2 [WARNING] DISTRIBUTED(85,ffff0b90f120,python):2025031703:24:59.204.926 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48620 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.470.709 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 16 source: 127.0.0.1:48622, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff16ebf120,python):2025031703:24:59.470.730 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48622 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.470.745 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 1 [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:59.705.305 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(1/1200). [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.970.882 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 17 source: 127.0.0.1:48624, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff15e9f120,python):2025031703:24:59.970.891 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48624 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.970.905 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 2 [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:00.205.402 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(2/1200). [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:00.471.344 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(1/1200). [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:00.705.486 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(3/1200). [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:00.971.463 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:248] BuildCluster] Cluster is successfully initialized. [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:00.971.492 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:355] PostProcess] This node 1 rank id: 1 [WARNING] PS(92,ffff9e8e0c80,python):2025031703:25:00.971.561 [mindspore/ccsrc/ps/core/file_configuration.cc:24] Initialize] The file: is not exist. [WARNING] DEVICE(92,ffff9e8e0c80,python):2025031703:25:00.971.574 [mindspore/ccsrc/plugin/device/cpu/hal/hardware/ms_collective_node.cc:33] Start] Failed to initialize the configuration for this mccl collective node. [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:01.205.598 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:248] BuildCluster] Cluster is successfully initialized. [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:01.205.629 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:355] PostProcess] This node 0 rank id: 0 [WARNING] PS(85,ffff93320c80,python):2025031703:25:01.205.714 [mindspore/ccsrc/ps/core/file_configuration.cc:24] Initialize] The file: is not exist. [WARNING] DEVICE(85,ffff93320c80,python):2025031703:25:01.205.738 [mindspore/ccsrc/plugin/device/cpu/hal/hardware/ms_collective_node.cc:33] Start] Failed to initialize the configuration for this mccl collective node. [WARNING] PS(85,ffff93320c80,python):2025031703:25:01.207.379 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:188] Init] The port 8119 is already in use. So increase port to: 8119 [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:04.836.447 [mindspore/ccsrc/distributed/collective/collective_manager.cc:332] CreateCommunicationGroup] Start to create communication group: hccl_world_group [const vector]{0, 1}, async: 0, submit_now: 1 [WARNING] DISTRIBUTED(85,fffe867cf120,python):2025031703:25:04.839.950 [mindspore/ccsrc/distributed/collective/collective_manager.cc:777] CreateDeviceCommunicator] Begin initialize communication group on the device side: hccl_world_group [WARNING] DEVICE(85,fffe7bfff120,python):2025031703:25:04.840.252 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:141] InitializeByRootInfoConfig] Start to initialize communicator by HcclCommInitRootInfo for hccl_world_group, hcclBufferSize is 200 MB. hcclDeterministic is 0 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:07.428.996 [mindspore/ccsrc/distributed/collective/collective_manager.cc:332] CreateCommunicationGroup] Start to create communication group: hccl_world_group [const vector]{0, 1}, async: 0, submit_now: 1 [WARNING] DISTRIBUTED(92,fffe91fbf120,python):2025031703:25:07.430.103 [mindspore/ccsrc/distributed/collective/collective_manager.cc:777] CreateDeviceCommunicator] Begin initialize communication group on the device side: hccl_world_group [WARNING] DEVICE(92,fffe917af120,python):2025031703:25:07.430.410 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:141] InitializeByRootInfoConfig] Start to initialize communicator by HcclCommInitRootInfo for hccl_world_group, hcclBufferSize is 200 MB. hcclDeterministic is 0 [WARNING] DEVICE(85,fffe7bfff120,python):2025031703:25:08.332.284 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:152] InitializeByRootInfoConfig] End to initialize communicator by HcclCommInitRootInfo for hccl_world_group [WARNING] DISTRIBUTED(85,fffe867cf120,python):2025031703:25:08.332.561 [mindspore/ccsrc/distributed/collective/collective_manager.cc:788] CreateDeviceCommunicator] End initialize communication group on the device side: hccl_world_group [WARNING] DEVICE(92,fffe917af120,python):2025031703:25:08.503.765 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:152] InitializeByRootInfoConfig] End to initialize communicator by HcclCommInitRootInfo for hccl_world_group [WARNING] DISTRIBUTED(92,fffe91fbf120,python):2025031703:25:08.504.027 [mindspore/ccsrc/distributed/collective/collective_manager.cc:788] CreateDeviceCommunicator] End initialize communication group on the device side: hccl_world_group",2025-03-17T11:33:20+08:00,"mindspore-assistant,mp",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBTUWV,这个好像也没有报错呀？只是些警告，警告的原因是回路地址通信受阻，但重新尝试后还是成功了，受阻的原因可能有多种，服务器的账户权限、防火墙配置啥的，上述警告中还提到端口被占用的，端口占用可能是最主要的，可以检查一下,这边有篇文章，可以参考一下，调用方法和你的也是一样的： https://mp.weixin.qq.com/s?__biz=MzkxMTM2MjMzNg==&mid=2247630125&idx=1&sn=85cac4be8afbfad4f3a0aa7111b57943&chksm=c05b78a721760515aeecf50b1a6e4e588dd1f53496e48b26834beea4118130f24fc8bb2a4497&mpshare=1&scene=23&srcid=0218kieDg0yrzQhYrffB4PBC&sharer_shareinfo=78c1efb617b7dae27f91648b717a415d&sharer_shareinfo_first=2f073777e1f011aad7620386c1a794dbrd
caifubi,部分CPython接口有内存泄露，需要去除Py_INCREF," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-15T21:27:36+08:00,"gitee,user/IC",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBTN7L,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,下游单 DTS2025031459443,Appearance & Root Cause 问题：mindformers里面有网络显存不足。 根因：Tensor接口中有pyobject引用计数不正确，host Tensor泄露，导致Tensor上的显存没释放。 Fix Solution 1、修复Tensor接口的泄露问题。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83047 PR合入后daily包回归 测试建议：增加mindspore和mindformers的联合流水线。 Selftest Report & DT Review mindformer网络显存正常。 是否需要补充 ST/UT：否 原因：非基本功能问题，且属于显存泄露，不适合在CI level0看护。 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82518 PR合入时间：2025年3月8日 问题是否偶现：是/否
梅飞要,add mstx prof st,,2025-03-14T17:52:24+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBTHLH
虞良斌,Fixed the inconsistency between the profile api parameter list and the English version,,2025-03-14T17:09:19+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBTGUL
虞良斌,Fix bug CANN package does not support aclprofGetSupportedFeatures method,,2025-03-14T16:57:25+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBTGJJ
luoxuewei,"重构接口 tensor.is_complex, tensor.is_signed ","   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-14T15:59:23+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBTFH0
geyuhong,activation offload特性需要增补st用例,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-03-14T15:45:48+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBTF5Z
b_rookie,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/nn/mindspore.nn.KLDivLoss.html?highlight=%E6%95%A3%E5%BA%A6 2. 【Issues Section】/【问题文档片段】 >  KL散度计算不应该是Pxlog(P/Q)吗 3. 【Existing Issues】/【存在的问题】 正确性：  >  技术原理、功能、支持平台、参数类型、异常报错等描述和软件实现不一致；  >  原理图、架构图等存在错误；  >  命令、命令参数等错误；  >  代码片段错误；  >  命令无法完成对应功能；  >  界面错误，无法指导操作；  >  代码样例运行报错、运行结果不符； 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-03-14T15:40:10+08:00,www,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBTF2J,得分：2 类型：规范和低错类 活动链接（可查询积分）：https://www.mindspore.cn/feedback 欢迎您提交更多issue或PR，获得更多积分。
梅飞要,Optimise performance of mstx,,2025-03-14T14:57:37+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBTEF5
andy,Supplement the st cases,,2025-03-14T12:34:40+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBTCMR
虞良斌,Fix the profiler_level log print error,,2025-03-13T23:27:27+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBT8PN
caifubi,Empty算子输出仍然为StubTensor，需要进一步去除。," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-13T21:28:22+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBT88A,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
majun-bot,CVE202441996,"一、漏洞信息 漏洞编号：CVE202441996 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： Validating the order of the public keys in the DiffieHellman Key Agreement Protocol, when an approved safe prime is used, allows remote attackers (from the client side) to trigger unnecessarily expensive serverside DHE modularexponentiation calculations. The client may cause asymmetric resource consumption. The basic attack scenario is that the client must claim that it can only communicate with DHE, and the server must be configured to allow DHE and validate the order of the public key. 漏洞公开时间：20240826 14:15:04 漏洞创建时间：20250313 17:13:31 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202441996 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： DiffieHellman是DiffieHellman开源的一种密钥协商协议。该密钥协商协议允许Alice和Bob交换公钥值，并根据这些值和他们自己对应的私钥的知识，安全地计算共享密钥K，从而实现进一步的安全通信。仅知道交换的公钥值，窃听者无法计算共享密钥。DiffieHellman存在安全漏洞，该漏洞源于允许远程攻击者触发不必要的DHE模幂运算，可能造成不对称资源消耗。 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响",2025-03-13T17:13:32+08:00,"gitee,CVE/UNAFFECTED,kind/nobug",closed,0,7,https://gitee.com/mindspore/mindspore/issues/IBT5TU,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明:DiffieHellman是DiffieHellman开源的一种密钥协商协议。该密钥协商协议允许 Alice 和 Bob 交换公钥值，并根据这些值和他们自己对应的私钥的知识，安全地计算共享密钥K，从而实现进一步的安全通信。仅知道交换的公钥值，窃听者无法计算共享密钥。DiffieHellman存在安全漏洞，该漏洞源于允许远程攻击者触发不必要的DHE模幂运算，可能造成不对称资源消耗。 漏洞评分(mindspore评分): BaseScore:7.5 Vector:CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", Appearance & Root Cause 问题：DH密钥协商协议存在漏洞，使得远程攻击者可以触发不必要的DHE模幂运算，造成机器的资源消耗。 漏洞分析： 1、MindSpore使用的是ECDHE算法，不是DHE； 2、OpenSSL针对1.1.1k版本未提供相关patch；  Fix Solution 评审关单。后续开源工具会重新扫描漏洞并创建新的issue，若到时OpenSSL社区有提供漏洞patch，再进行修复。,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 里程碑未变更至测试领域 2. 未包含 补充建议 (Fix Description & Test Suggestion) 3. 未包含 自测结果 & 审核结果 (Selftest Report & DT Review) 4. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,暂无法修复，后续通过安全工具扫描持续跟踪
cccc1111,atanh_/arctanh_接入aclnn, Tasks 转测对象：tensor.atanh_/tensor.arctanh_ 对标torch.tensor.atanh_/arctanh_   Background !输入图片说明  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.Tensor.atanh_.htmltorch.Tensor.atanh_  标杆在Ascend支持数据类型： bfloat16/float16/float32/float64/complex64/complex128  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反双曲正切值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-13T11:32:59+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBT14D
cccc1111,atan2_/arctan2_接入aclnn, Tasks 转测对象：tensor.atan2_/tensor.arctan2_ 对标torch.tensor.atan2_/arctan2_   Background !输入图片说明  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.Tensor.atan2_.htmltorch.Tensor.atan2_  标杆在Ascend支持数据类型： bfloat16/float16/float32/float64/uint8/int8/int16/int32/int64/bool  **2. MindSpore算子情况**   当前支持数据类型 与torch_gpu保持一致，bfloat16/float16/float32/float64  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算两个Tensor的反正切值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-13T11:26:33+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBT10I
cccc1111,atan_/arctan_接入aclnn, Tasks 转测对象：tensor.atan_/tensor.arctan_ 对标torch.tensor.atan_/arctan_   Background !输入图片说明  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.Tensor.atan_.htmltorch.Tensor.atan_  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反正切值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-13T11:20:51+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBT0WX
majun-bot,CVE202527788,"一、漏洞信息 漏洞编号：CVE202527788 漏洞归属组件：JSON for Modern C++, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.10.1 CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： JSON is a JSON implementation for Ruby. Starting in version 2.10.0 and prior to version 2.10.2, a specially crafted document could cause an out of bound read, most likely resulting in a crash. Versions prior to 2.10.0 are not vulnerable. Version 2.10.2 fixes the problem. No known workarounds are available. 漏洞公开时间：20250312 22:15:16 漏洞创建时间：20250312 22:32:38 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202527788 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore： 0.0 &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-03-12T22:32:38+08:00,"CVE/UNFIXED,gitee,github",rejected,0,3,https://gitee.com/mindspore/mindspore/issues/IBSXFZ,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,该CVE漏洞确认为ruby/json的漏洞，并非nlomahnn/json漏洞，机器人误报，问题单reject https://github.com/ruby/json/commit/c56db31f800d5d508389793e69682f99749dbadf
虞良斌,Fix the output_path error bug in profiler_info.json,,2025-03-12T17:45:49+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBSVGD
caifubi,网络训练场景，fork数据进程执行卡住," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-11T18:51:22+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBSKUT,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
candyhong,The 'set_memory' can not be set repeatedly.,"   Describe the current behavior / 问题描述 (Mandatory / 必填) How to set_memory again without rerunning the script  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.10.12  OS platform and distribution (e.g., Linux Ubuntu 16.04): openEuler  GCC/Compiler version (if compiled from source): 11.4.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` >>> import mindspore as ms /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) >>> ms.runtime.set_memory(""10GB"", ""2GB"", ""28GB"", ""O1"") >>> ms.runtime.set_memory(""10GB"", ""2GB"", ""28GB"", ""O1"") Traceback (most recent call last):   File """", line 1, in    File ""/usr/local/lib/python3.10/distpackages/mindspore/_checkparam.py"", line 1367, in wrapper     return func(*args, **kwargs)   File ""/usr/local/lib/python3.10/distpackages/mindspore/runtime/memory.py"", line 54, in set_memory     raise RuntimeError(""The 'set_memory' can not be set repeatedly."") RuntimeError: The 'set_memory' can not be set repeatedly. ```  Describe the expected behavior / 预期结果 (Mandatory / 必填) I want to change max_size of memory without rerunning the script.  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-11T18:13:27+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBSKK9
虞良斌,Fix the bug that metadata data is exported by step,,2025-03-11T17:17:54+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBSJL1
shiro-zzz,【AR】使用AclnnGtScalar重构mint.greater/gt tensor.greater/gt, Tasks 转测对象：mint.greater/gt tensor.greater/gt   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-03-11T11:29:34+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBSEDA
shiro-zzz,【AR】PyBoost接口及ACLNN算子适配tensor.gt_, Tasks 转测对象：tensor.gt_   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-03-11T11:24:27+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBSE8S
虞良斌,Change the naming method of worker_name and support the output of the communication db,,2025-03-11T11:07:15+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBSDXV
梅飞要,fix err while create domain for default,,2025-03-10T21:33:03+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBSAAL
虞良斌,Change the position of the analyse method in the profile,,2025-03-10T19:46:55+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBS9RO
tangmengcheng,o2模式异常日志,,2025-03-10T19:08:17+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IBS9HB
虞良斌,aicore metrics supports memory access functionality to supplement st use cases,,2025-03-10T15:49:55+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBS6CO
zhouyaqiang0,静态图flops计算重计算虚高," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】*周亚强（根据实际修改）",2025-03-08T17:57:15+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBRTC2,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
zhouyaqiang0,静态图flops计算重计算虚高," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】*周亚强（根据实际修改）",2025-03-08T17:57:12+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBRTC1,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
孙昊辰,Cogvlm2和qwenvl VIT网络 Attention中的bmm报错,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  在测试Cogvlm2和qwenvl网络时，用例：  TestCogVLM2VideoPredict  test_predict.py::TestQwenVLPredict  报错，其中batchMatMul算子 weight 4维时，发生报错，定位原因为算子不应该走到internal实现中，从而导致weight维度校验报错。  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend 910B  **Software Environment / 软件环境 (Mandatory / 必填)**: mindspore  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : py310  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu aarch64  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填)  TestCogVLM2VideoPredict  test_predict.py::TestQwenVLPredict  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. Cogvlm2和qwenvl网络中测试问题用例：     TestCogVLM2VideoPredict     test_predict.py::TestQwenVLPredict 2. 单算子运行test/st/test_batch_matmul.py用例  Describe the expected behavior / 预期结果 (Mandatory / 必填)  bmm算子使用aclnn实现，4维weight shape不报错，结果正确。  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  !输入图片说明 报错 MatMul weight shape rank must be 2/3, but got 4  Special notes for this issue/备注 (Optional / 选填)",2025-03-08T17:41:22+08:00,gitee,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBRT9N,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：Cogvlm2和qwenvl VIT网络 Attention中的bmm报错 根因： 1、 bmm算子预期使用环境变量控制，默认关闭。但实际环境变量不能控制此算子的注册，导致实际为默认开启。 2、 在默认开启情况下，Attention中的bmm weight为4维 shape，当前算子不支持，导致报错。 Fix Solution 1、（当前）删除算子注册，目前不使能bmm算子。功能使用aclnn实现。 2、近期重新使能bmm算子，增加详细的不支持场景的限制。 3、新需求支持bmm weight 4维场景。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/82658 PR合入master分支 测试建议：该问题可以通过特性用例防护，增加****场景。 Selftest Report & DT Review pr合入master分支B050版本测试 牛君豪 30057732 未发现问题复现。 是否需要补充 ST/UT：否。 原因：解决问题单当前已取消注册bmm算子，使用aclnn实现。 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82323 PR合入时间：2025年/3月/4日 问题是否偶现：否
邵勃源,Pytorch的Parameter在pytorch.nn模块下，而mindspore的Parameter不在mindspore.nn下，而是mindspore.common模块下,Pytorch的Parameter在pytorch.nn模块下，而mindspore的Parameter不在mindspore.nn下，而是mindspore.common模块下 可能带来的问题： ·学习成本增加：对于开发者来说，如果熟悉了PyTorch的使用方式，再学习MindSpore时，需要重新适应MindSpore的模块结构和使用方式，增加了学习成本。同时，可能影响开发者在查找资料和解决问题时的效率。 ·代码迁移困难：如果需要将PyTorch的代码迁移到MindSpore，或者反之，这种模块归属的差异可能导致代码不能直接移植，需要对代码进行相应的调整。,2025-03-08T15:11:22+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRS13,感谢您的建议，这方面我们正在评估中！
邵勃源,Pytorch中有Tensor、LongTensor、FloatTensor等不同的张量类型，而Mindspore使用统一的Tensor类型,pytorch: !pytorch相关代码 mindspore： !mindspore相关代码 可能带来的问题： ·数据类型转换复杂：由于只有Tensor一种类型，开发者可能需要更仔细地管理数据类型，尤其是在需要特定数据类型的操作中，可能需要进行更多的数据类型转换。 ·调试难度增加：在PyTorch中，不同的张量类型可以明确地表示数据的类型，使得代码更具可读性。而在MindSpore中，开发者不能直接通过张量的类型来判断数据的类型，需要进一步检查张量的dtype属性，这可能会增加调试的复杂度。,2025-03-08T15:09:12+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRS0R,感谢您的建议，这方面我们正在仔细评估中！
邵勃源,MindSpore 的设备管理是通过上下文ms.context来实现的，而不是直接在 Tensor 对象中设置设备,"Pytorch中设备管理是直接在 Tensor 对象中设置设备，而MindSpore 的设备管理是通过上下文来实现的，因此，x.device 并不是一个有效的属性，需要使用 ms.context 模块来管理设备上下文。 例如，Pytorch代码中： ``` device_type = x.device.type device_type = device_type if isinstance(device_type, str) and device_type != ""mps"" else ""cpu"" ``` 而mindspore代码中： ``` device_type = ms.context.get_context(""device_target"") ``` 可能带来的问题： 1、设备切换复杂：在代码迁移进行测试的时候，如果需要在代码的不同部分切换设备，需要频繁地修改、查询上下文设置，而不是简单地在 Tensor 对象上进行操作，导致代码的维护和、修改成本增加，影响调试效率。基于此，当需要在不同设备之间进行数据传输或操作时，可能会增加跨设备操作的复杂性。 2、开发者无法直接通过 Tensor 对象的属性（如 x.device）来获取其所在的设备信息，需要通过上下文来查询，这增加了获取设备信息的复杂度。同时，使得代码的可读性和直观性降低，尤其是对于不熟悉 MindSpore 设备管理机制的开发者。",2025-03-08T15:02:01+08:00,"mindspore-assistant,www,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRRZN,可以试试mindspore的ops.set_device()方法，看看能否把算子设置到不同的设备上运行： https://www.mindspore.cn/docs/zhCN/r2.5.0/api_python/ops/mindspore.ops.Primitive.html?highlight=set_device !输入图片说明
zhengwenhui2025,矩阵 Trace（trace）算子 Kernel 未注册," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > `mindspore.mint.trace` 相关接口执行时报错 `The kernel TraceExt unregistered`，导致矩阵 `trace` 计算失败。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境 (Mandatory / 必填)**:   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 1. 运行 `test_trace.py` 相关部分代码（已提交 PR） ```python def test_trace_fixed_dtype_output_equality():     """"""     (1b) 固定 float32, 随机输入     """"""     print(""===== Trace fixed dtype output equality test ====="")     mat = np.random.randn(4,4).astype(np.float32)     ms_val = mint.trace(Tensor(mat, mstype.float32)).asnumpy()     pt_val = torch.trace(torch.tensor(mat, dtype=torch.float32)).item()     diff = abs(ms_val  pt_val)     print(""diff:"", diff)     assert diff  2. 观察执行日志，报错如下： >  > ``` > FAILED test_trace.py::test_trace_fixed_dtype_output_equality  RuntimeError: The kernel TraceExt unregistered. > FAILED test_trace.py::test_trace_fixed_shape_diff_params  RuntimeError: The kernel TraceExt unregistered. > ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > ​**【预期结果】**​: `mindspore.mint.trace` 执行正常，计算结果正确，误差符合预期。  5.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) > ​**日志关键内容**​: >  > ``` > RuntimeError: The kernel TraceExt unregistered. > ``` **【定位人】** 郑文慧",2025-03-08T00:28:02+08:00,"mindspore-assistant,foruda,intern",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBRPVU,是用的CPU上运行的吗？根据文档，mint下的api是只有昇腾才支持的，可能有些CPU或者GPU上也已经支持了，但应该还不全面，都还没注册： !输入图片说明,是的，在公共昇腾机器上重新测试了，没有问题，但其他三个接口在CPU上有算子，算是完善的锚点提示吧。
zhengwenhui2025,矩阵求逆（Inverse）算子 Kernel 未注册," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > `mindspore.mint.inverse` 相关接口执行时报错 `The kernel MatrixInverseExt unregistered`，导致矩阵求逆计算失败。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境 (Mandatory / 必填)**:   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 1. 运行 `test_inverse.py` 相关部分代码（已提交 PR） ```python def test_inverse_fixed_dtype_output_equality():     """"""     (1b) 固定dtype=float32, 随机输入, 对比两个框架输出 (误差 2. 观察执行日志，报错如下： >  > ``` > FAILED test_inverse.py::test_inverse_fixed_dtype_output_equality  RuntimeError: The kernel MatrixInverseExt unregistered. > FAILED test_inverse.py::test_inverse_fixed_shape_diff_params  RuntimeError: The kernel MatrixInverseExt unregistered. > ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > ​**【预期结果】**​: `mindspore.mint.inverse` 执行正常，计算结果正确，误差符合预期。  5.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) > ​**日志关键内容**​: >  > ``` > RuntimeError: The kernel MatrixInverseExt unregistered. > ``` **【定位人】** 郑文慧（根据实际修改）",2025-03-08T00:27:04+08:00,"mindspore-assistant,foruda,intern",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBRPVQ,情况应该和trace一样，mint下的api目前主要昇腾环境支持，其它环境可能有些支持了，但还不全面 !输入图片说明,如  所说，在昇腾处理器上重新测试后可以通过，此 Issue 用于提示补全平台算子。
zhengwenhui2025,LeakyReLU 算子 Kernel 未注册," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > `mindspore.mint.nn.functional.leaky_relu` 相关接口执行时报错 `The kernel LeakyReLUExt unregistered`，导致 LeakyReLU 计算失败。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  、  3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 1. 运行 `test_leaky_relu.py` 相关部分代码(已提交 PR) ```python def test_leaky_relu_fixed_dtype_output_equality():     """"""     (1b) 固定dtype=float32 随机输入，对比输出     """"""     print(""===== LeakyReLU fixed dtype output equality test ====="")     x_np = np.random.randn(4,4).astype(np.float32)     ms_in = Tensor(x_np, mstype.float32)     torch_in = torch.tensor(x_np, dtype=torch.float32)     out_ms = F_ms.leaky_relu(ms_in, 0.1).asnumpy()     out_pt = F_torch.leaky_relu(torch_in, 0.1).numpy()     diff = np.abs(out_ms  out_pt).max()     print(""Max diff:"", diff)     assert diff  1     print(""default=0.01:"", out_slope_default.asnumpy())     print(""0.2:"", out_slope_float.asnumpy())     print(""1:"", out_slope_int.asnumpy())     print(""True(=1):"", out_slope_bool.asnumpy())      string slope => error     try:         F_ms.leaky_relu(x, negative_slope=""0.1"")     except Exception as e:         print(""slope=string error:"", e) def test_leaky_relu_network_forward_backward():     """"""     (2b,2c) 使用LeakyReLU验证前向输出 & 反向梯度     """"""     print(""===== LeakyReLU forward/backward test ====="")      PyTorch     x_pt = torch.tensor([1.,0.,1.], requires_grad=True)     out_pt = F_torch.leaky_relu(x_pt, 0.2)     out_pt.sum().backward()     grad_pt = x_pt.grad.numpy()      MindSpore     x_ms = Tensor(np.array([1.,0.,1.], np.float32))     x_ms.requires_grad = True     def forward_fn(inp):         return F_ms.leaky_relu(inp, 0.2).sum()     grad_fn = ops.grad(forward_fn, grad_position=0)     grad_ms = grad_fn(x_ms).asnumpy()     print(""PyTorch grad:"", grad_pt)     print(""MindSpore grad:"", grad_ms) ``` > 2. 观察执行日志，报错如下： > > ``` > FAILED test_leaky_relu.py::test_leaky_relu_fixed_dtype_output_equality  RuntimeError: The kernel LeakyReLUExt unregistered. > FAILED test_leaky_relu.py::test_leaky_relu_fixed_shape_diff_params  RuntimeError: The kernel LeakyReLUExt unregistered. > FAILED test_leaky_relu.py::test_leaky_relu_network_forward_backward  RuntimeError: The kernel LeakyReLUExt unregistered. > ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**: `leaky_relu` 执行正常，计算结果正确，误差符合预期。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) > **日志关键内容**: > > ``` > RuntimeError: The kernel LeakyReLUExt unregistered. > ``` **【定位人】** 郑文慧",2025-03-08T00:24:16+08:00,"foruda,intern",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBRPVP,情况应该和trace一样，mint下的api目前主要昇腾环境支持，其它环境可能有些支持了，但还不全面 !输入图片说明,如  所说，在昇腾处理器上重新测试后可以通过，此 Issue 用于提示补全平台算子。
zhengwenhui2025,LayerNorm 算子 KernelMod 创建失败," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > `mindspore.mint.nn.functional.layer_norm` 相关接口执行时报错 `Create kernelmod for op LayerNormExt failed`，导致 LayerNorm 计算失败。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 1. 运行 `test_layer_norm.py` 部分相关代码（已提交 PR ） ```python def test_layernorm_fixed_dtype_output_equality():     """"""     (1b) 固定dtype=float32, 随机输入, 对比输出     """"""     print(""===== LayerNorm fixed dtype output equality test ====="")     x_np = np.random.randn(2,3,4).astype(np.float32)     w_np = np.random.randn(4).astype(np.float32)     b_np = np.random.randn(4).astype(np.float32)     ms_in = Tensor(x_np, mstype.float32)     ms_w = Tensor(w_np, mstype.float32)     ms_b = Tensor(b_np, mstype.float32)     out_ms = F_ms.layer_norm(ms_in, normalized_shape=(4,), weight=ms_w, bias=ms_b, eps=1e5).asnumpy()     x_torch = torch.tensor(x_np, dtype=torch.float32)     w_torch = torch.tensor(w_np, dtype=torch.float32)     b_torch = torch.tensor(b_np, dtype=torch.float32)     out_pt = F_torch.layer_norm(x_torch, normalized_shape=(4,), weight=w_torch, bias=b_torch, eps=1e5).numpy()     diff = np.abs(out_ms  out_pt).max()     print(""Max diff:"", diff)     assert diff  2. 观察执行日志，报错如下： > > ``` > FAILED test_layer_norm.py::test_layernorm_fixed_dtype_output_equality  RuntimeError: Create kernelmod for op LayerNormExt failed > FAILED test_layer_norm.py::test_layernorm_fixed_shape_diff_params  RuntimeError: Create kernelmod for op LayerNormExt failed > FAILED test_layer_norm.py::test_layernorm_network_forward_backward  RuntimeError: Create kernelmod for op LayerNormExt failed > ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**: `layer_norm` 执行正常，计算结果正确，误差符合预期。  5.Related log / screenshot / 日志  > **日志关键内容**: ``` FAILED test_layer_norm.py::test_layernorm_fixed_dtype_output_equality  RuntimeError: Create kernelmod for op LayerNormExt failed FAILED test_layer_norm.py::test_layernorm_fixed_shape_diff_params  RuntimeError: Create kernelmod for op LayerNormExt failed FAILED test_layer_norm.py::test_layernorm_network_forward_backward  RuntimeError: Create kernelmod for op LayerNormExt failed ``` **【定位人】** 郑文慧",2025-03-08T00:21:47+08:00,"foruda,intern",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBRPVO,情况应该和trace一样，mint下的api目前主要昇腾环境支持，其它环境可能有些支持了，但还不全面 !输入图片说明,如  所说，在昇腾处理器上重新测试后可以通过，此 Issue 用于提示补全平台算子。
zhangyupeng,mindspore2.2.0中mindspore.nn.Dense和对应的torch.nn.Linear在运行中有较大差异," 1.Describe the current behavior / mindspore2.2.0中mindspore.nn.Dense和对应的torch.nn.Linear在运行中有较大差异 两个框架在该模块中 输入数据的差异在输出后提高2~3个数量级  2.Environment / 环境信息 (Mandatory / 必填)   3.Related testcase / 关联用例 (Mandatory / 必填) !输入图片说明  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore.nn as mnn import torch import torch.nn as nn class BertConfig_pt:     def __init__(self, hidden_size=768, intermediate_size=3072):         self.hidden_size = hidden_size         self.intermediate_size = intermediate_size class BertIntermediate_pt(nn.Module):     def __init__(self, config):         super(BertIntermediate_pt, self).__init__()         self.dense = nn.Linear(config.hidden_size, config.intermediate_size)         self.intermediate_act_fn = nn.GELU()     def forward(self, hidden_states: torch.Tensor) > torch.Tensor:         hidden_states = self.dense(hidden_states)         hidden_states = self.intermediate_act_fn(hidden_states)         return hidden_states class BertConfig_ms:     def __init__(self, hidden_size=768, intermediate_size=3072):         self.hidden_size = hidden_size         self.intermediate_size = intermediate_size class BertIntermediate_ms(mnn.Cell):     def __init__(self, config):         super(BertIntermediate_ms, self).__init__()         self.dense = mnn.Linear(config.hidden_size, config.intermediate_size)         self.intermediate_act_fn = mnn.GELU()     def construct(self, hidden_states):         hidden_states = self.dense(hidden_states)         hidden_states = self.intermediate_act_fn(hidden_states)         return hidden_states config_ms = BertConfig_ms(hidden_size=768, intermediate_size=3072) intermediate_layer_ms = BertIntermediate_ms(config_ms) dense_layer_ms = intermediate_layer_ms.dense config_pt= BertConfig_pt(hidden_size=768, intermediate_size=3072) intermediate_layer_pt = BertIntermediate_pt(config_pt) dense_layer_pt = intermediate_layer_pt.dense input_pt = bert_compare.input_pt[""encoder.layer.2.intermediate.dense""] input_ms = bert_compare.input_ms[""encoder.layer.2.intermediate.dense""] if isinstance(input_pt, tuple):     input_pt = input_pt[0]   if isinstance(input_ms, tuple):     input_ms = input_ms[0]   output_pt = dense_layer_pt(input_pt) output_ms = dense_layer_ms(input_ms) print(""PT Output Tensor:"", output_pt.detach().cpu().numpy()) print(""MS Output Tensor:"", output_ms.asnumpy()) print(""Output DIFFERENCE:"", output_pt.detach().cpu().numpy()output_ms.asnumpy()) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 输入和输出的误差不会有太大差异  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-03-07T14:54:57+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRKXT,上述代码确定是MindSpore 2.2.0上运行的吗？2.2.0版本应该没有mindspore.nn.Linear这个算子，上述代码运行不起来的，mindspore.nn.Linear这个是后续版本中添加的，这边应该是要用mindspore.nn.Dense吧？ 不论mindspore.nn.Linear还是mindspore.nn.Dense，这里运行结果pt和ms不同，是因为初始化权重不同，ms和pt的默认权重初始化方法可能不一样，并且同一种初始化方法，比如kaimingNormal，也都是随机初始化的，所以对比结果肯定不一样，并且每次运行的结果差异都是不同的；如果要做对比，需要设置固定的权重
zhangyinxia,alltoallv算子添加add block_size属性," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 通过 block_size属性可以减少一次d2h数据拷贝，提升网络性能 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-07T14:52:25+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBRKWD,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
qiwenlun,Python Tensor和C++ Tensor重构,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any. 特性重构：Ascend上，每个tensor创建时间大概在10us20us左右，在C++运算后产生的 C++ Tensor传递到Python的时候，会重新生成以一个新的 Python Tensor（类深拷贝C++ Tensor）。本次重构主要消除这步copy，节省Python Tensor创建的操作，一次能节省开销 1020 us。  Origin（信息来源）  Explain which department/team made this request so that its priority can be given. 易用性增强  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request. 先前合入背景： 当前MindSpore Python Tensor继承C++ Tensor，并且拥有自己的属性(init/const_arg/virtual_flag/init_finished/device等)和方法，在Python侧使用的Tensor参与运算生成结果时，需要深拷贝一份C++Tensor。 重构之后的Python Tensor不会直接继承C++ Tensor，会继承一个TensorPy，TensorPy里面包含C++ Tensor（储存指针）。 因此，在C++运算接口中，拿到py::args/py::kwargs之后，需要cast成TensorPy再获取真实的C++ Tensor，或者从py::object中获取C++ Tensor指针对象。 本次合入改动： 本次合入在上面的基础上进行CPython改造，包括TensorPy的注册，以及TensorPy的方法属性的定义，改造完之后可以直接创建python内存块来存放TensorPy。TensorPy也由本身的智能指针改变为Cpython结构并持有TensorPy，TensorPy持有原本的C++Tensor指针，相比原先少了一步C++的make::share。并为StubTensor去除奠定基础。  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed Python Tensor和C++ Tensor重构设计文档,2025-03-07T14:51:56+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBRKW7
虞良斌,Develop branch code to synchronize to the master branch,,2025-03-06T21:41:34+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBRDP4
虞良斌,Communicate db output as deliverables,,2025-03-06T18:04:27+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBRC4U
r1chardf1d0,图算融合开关使用不恰当时，需给用户提示,,2025-03-06T17:14:36+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRB4K,暂无外部用户使用，使用不当由开发人员识别
r1chardf1d0,kernel packet资料描述需完善,,2025-03-06T17:13:24+08:00,gitee,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBRB3X,请您补充下您看到的kernel packet资料的具体网页链接，谢谢,https://gitee.com/mindspore/docs/blob/5f5cab30e9036757345f570fe567c37182a992f8/docs/mindspore/source_zh_cn/model_train/custom_program/fusion_pass.md  修正kernel packet相关描述
梅飞要,fix mstx err when push task in self queue,,2025-03-06T17:03:21+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBRAWP
FreezingTheFlame,mindspore.nn mindspore.mint.nn mindnlp.nn 提供了三种nn，我应该如何确定三种nn的使用情境？是否会冲突," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在mindspore以及mindnlp中，提供了多种nn接口，mindspore.nn,mindspore.mint.nn,mindnlp.nn，三种nn的接口实现各有不同，其中mindspore的两种nn应该如何区分使用？是否存在不适配的可能？可以混用吗？  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**: Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) !输入图片说明  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) 希望能在文档中描述清楚区别，并且尽可能统一mindspore中nn的两种接口实现",2025-03-06T16:41:44+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRAHJ,mindspore.nn是比较早的，基本各平台都支持；mindspore.mint.nn是新的版本中增加的，有可能获得更好的性能，但目前应该只有910环境才支持，部分好像910b才支持，并且可能在参数上也做了一些修改，这个在文档里有说明；mindnlp套件里的nn是对标hf的那个transformer库的，transformer库的模型基本是pytorch实现的，保持与pytorch的使用习惯一致，方便快速将transformer里的模型迁移过来； 至于能否混用，只要当前环境平台是能运行的，混用是没有问题的，如果碰到出错，应该是属于bug的范畴；但在mindnlp里面，能用mindnlp.nn的话就用这个，这样比较规范，也方便迁移模型，其它情况下，如果mindspore.mint.nn支持就用这个，有可能获得更高的性能
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.ge_, Tasks 转测对象：Tensor.ge_ ,2025-03-06T15:03:38+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBR8MB
DoctorHaibara,OctSqueeze 评估代码可能存在问题：解码过程直接使用了 GT 而非压缩比特流,"**描述：**   您好，   在 MindSpore 的 OctSqueeze 实现中，我在 `eval.py` 文件中的 `compression_decompression_simulation` 函数发现了一个潜在问题：当前解码过程似乎直接使用了 `gt` 作为输入，而不是从压缩比特流重建八叉树。    问题详情   在以下代码片段中： ```python occupancy_stream = nodes[""gt""].astype(np.int) recon_tree = Octree(max_range=max_range, precision=precision_oct) recon_tree, recon_points = deserialize_depth_first(iter(occupancy_stream), recon_tree.max_depth, recon_tree) ``` 变量 `occupancy_stream` 直接从 `nodes[""gt""]` 赋值，而 `nodes[""gt""]` 是原始占据 (occupancy) 真值。这意味着： 1. 代码在解码过程中并没有使用熵解码后的数据，而是直接使用了 Ground Truth (GT)。 2. 这样重建的八叉树并不能真实反映压缩后的重建情况，因为它绕过了实际的熵解码步骤。  预期行为   解码过程应该从压缩比特流中提取占据信息，而不是直接使用 `gt`。正确的流程应当基于编码后的数据进行解码，以便准确评估压缩性能。   请问官方是否可以确认这是否是一个 Bug，或者是否有特定原因这样实现？   **相关 Issue（GitHub）：**   我在 GitHub 上提交了类似的 Issue：https://github.com/mindsporeai/models/issues/16，但发现 MindSpore 团队在 Gitee 上较为活跃，因此在此同步反馈。   感谢您的时间和帮助！期待您的回复。  ",2025-03-06T14:53:54+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBR8ED
shiro-zzz,【AR】使用AclnnLeScalar重构mint.less_equal/le tensor.less_equal/le, Tasks 转测对象：mint.less_equal/le tensor.less_equal/le   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-03-06T13:46:03+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBR6QP
shiro-zzz,【AR】PyBoost接口及ACLNN算子适配tensor.lt_, Tasks 转测对象：tensor.lt_   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-03-06T13:42:11+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBR6OT
shiro-zzz,【AR】使用AclnnLtScalar重构mint.less/lt tensor.less/lt, Tasks 转测对象：mint.less/lt tensor.less/lt   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-03-06T13:27:11+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBR6KS
徐微,onnx模型转换mindir推理失败," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > 使用mindspore训练一个是涉及Conv2d和Add操作的模型，经过mindspore_lite转换为mindir，然后推理。报：Unsupported op  > node: :U496{[0]: ValueNode Conv2DFusion, [1]: :param_U494, [2]: :param_U493}  2.Environment / 环境信息 (Mandatory / 必填)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name** >   test_model_infer_mindir_cpu >  **Excute Mode ** >    Graph 模式 >    没有指定优化级别，默认为 O0 级别的优化  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) '''  import os import numpy as np import mindspore as ms from mindspore import nn, Tensor, context from mindspore_lite import converter, FmkType, ModelType import onnxruntime as ort   添加 ONNX Runtime 导入 class SimpleModel(nn.Cell):   def __init__(self): ​    super(SimpleModel, self).__init__() ​    self.conv = nn.Conv2d(1, 3, kernel_size=3, stride=1, pad_mode=""same"") ​    self.add = ms.ops.Add()   def construct(self, x): ​    x = self.conv(x) ​    x = self.add(x, x) ​    return x def infer_onnx(onnx_path, input_data):   """"""使用 ONNX Runtime 推理 ONNX 模型""""""   session = ort.InferenceSession(onnx_path)   input_name = session.get_inputs()[0].name   input_numpy = input_data.asnumpy() if isinstance(input_data, Tensor) else input_data   outputs = session.run(None, {input_name: input_numpy})   result = outputs[0]   print(f""ONNX模型推理成功，输出形状: {result.shape}"")   print(f""输出数据: \n{result.flatten()[:5]}..."")   return result def main():   ms.set_context(mode=context.GRAPH_MODE)   ms.set_device(""CPU"")   save_dir = ""./model""   os.makedirs(save_dir, exist_ok=True)   model = SimpleModel()   input_shape = (1, 1, 28, 28)   input_data = Tensor(np.random.randn(*input_shape).astype(np.float32))   onnx_path = os.path.join(save_dir, ""simple_model.onnx"")   ms.export(model, input_data, file_name=onnx_path, file_format='ONNX')   \ 推理 ONNX 模型   print(""\n===== 推理 ONNX 模型 ====="")   onnx_result = infer_onnx(onnx_path, input_data)   mindir_path = os.path.join(save_dir, ""simple_model"")   conv = converter.Converter()   conv.input_shape = {""x"": list(input_shape)}   conv.save_type = ModelType.MINDIR   conv.target_device_name = ""CPU""   conv.convert(FmkType.ONNX, onnx_path, mindir_path)   \ 3. 加载并推理MindIR模型   print(""\n===== 推理 MindIR 模型 ====="")   try: ​    graph = ms.load(f""{mindir_path}.mindir"") ​    model = nn.GraphCell(graph) ​     ​    output = model(input_data) ​     ​    print(f""MindIR模型推理成功，输出形状: {output.shape}"") ​    print(f""输出数据: \n{output.asnumpy().flatten()[:5]}..."") ​     ​    \ 比较两种模型的结果 ​    try: ​      is_equal = np.allclose(output.asnumpy(), onnx_result, rtol=1e3, atol=1e3) ​      if is_equal: ​        print(""\nONNX 和 MindIR 模型推理结果一致！"") ​      else: ​        max_diff = np.max(np.abs(output.asnumpy()  onnx_result)) ​        print(f""\nONNX 和 MindIR 模型推理结果不一致！最大差异: {max_diff}"") ​    except Exception as e: ​      print(f""比较结果时出错: {e}"") ​       except Exception as e: ​    print(f""MindIR 模型推理失败: {str(e)}"") ​     if __name__ == ""__main__"":   main() ''' > （1）python bug_report.py > >   (2)出现问题：node: :U8835_copy_U496{[0]: ValueNode Conv2DFusion, [1]: :param_U8833_copy_U494, [2]: :param_U8834_copy_U493}  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：ONNX模型推理成功，输出形状: (1, 3, 28, 28) >  输出数据:  [0.6475724  0.71996325  1.4186195   2.047796    0.2572536 ]...  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明 完整日志（通过附件上传）：",2025-03-05T16:55:52+08:00,mindspore-assistant,open,0,4,https://gitee.com/mindspore/mindspore/issues/IBQYZD,带Fusion的那些算子可能是图算融合后的算子，是不是开启了图算融合，然后CPU可能不支持这种融合算子？ mindspore可以直接导出mindir的，其实不用导出onnx然后再用lite去转，你直接导出mindir然后加载推理看看行不行；如果直接导出的可以，转来的不行的话，那可能是lite转换工具有点问题，或者加入了融合算子的规则导致CPU上不支持； 还有确保上下文里图算融合的开关enable_graph_kernel设置为False了，之前的版本默认这个就是False，但2.5.0的文档中，set_context方法里没有这个参数了，但实际代码运行时测试是可以设置的，不太确定它默认是开了还是关着的，保险起见你可以设置下False,"只是想通过这种方式检验mindspore框架存在的一些bug。我关闭了图算融合，但是还是出现了这个问题。 ``` from mindspore import JitConfig JitConfig = JitConfig(jit_level=""O0"") ```",[图片上传中…(imagezP4CFhpKIKuy3waQ20dj)]," 3. 加载并推理MindIR模型 print(""\n===== 推理 MindIR 模型 ====="") try: ​ graph = ms.load(f""{mindir_path}.mindir"") ​ model = nn.GraphCell(graph) 这部分的加载需要使用mindspore lite相关接口进行加载，没法使用mindspore相关接口进行加载，mindspore lite相关接口使用可以参考mindspore官网中mindspore lite推理部分"
mengxian,ops.maximum/minimum 与nan值比较未返回nan," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ops.maximum/minimum 与nan值比较未返回nan  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (Mac CPU)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) input = mindspore.tensor([float(""nan""), 3, 9]) other = mindspore.tensor([[4, 2, float(""nan"")],                           [3, 5, 10]]) output1 = mindspore.ops.maximum(input, other) output2 = mindspore.ops.minimum(input, other) print(output1) print(output2) [[ 4. 2. nan]  [3. 3. 10.]] [[ 4. 3. nan]  [3. 5.  9.]]  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 执行上述用例  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 预期与nan计算时返回nan  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) input = mindspore.tensor([float(""nan""), 3, 9]) other = mindspore.tensor([[4, 2, float(""nan"")],                           [3, 5, 10]]) output1 = mindspore.ops.maximum(input, other) output2 = mindspore.ops.minimum(input, other) print(output1) print(output2) [[ 4. 2. nan]  [3. 3. 10.]] [[ 4. 3. nan]  [3. 5.  9.]]    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**林鑫",2025-03-05T12:03:41+08:00,"www,www,foruda,usability",open,0,3,https://gitee.com/mindspore/mindspore/issues/IBQUOA,ops算子设计之初并未与竞品对齐，如要与竞品对齐，请用 mindspore.mint.maximum / mindspore.mint.minimum，本单关闭,!输入图片说明,与官方文档的功能描述不符，功能问题
mengxian,ops.cummin返回为list，实际应为tuple," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ops.cummin返回为list，实际应为tuple  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (Mac CPU)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) input = mindspore.tensor([[3, 4, 6, 10], [1, 6, 7, 9], [4, 3, 8, 7], [1, 3, 7, 9]]) mindspore.ops.cummin(x, axis=0)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 验证返回是否为tuple  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 返回为tuple  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) input = mindspore.tensor([[3, 4, 6, 10], [1, 6, 7, 9], [4, 3, 8, 7], [1, 3, 7, 9]]) mindspore.ops.cummin(x, axis=0) [Tensor(shape=[4, 4], dtype=Int64, value=  [[ 3,  4,  6, 10],   [ 1,  4,  6,  9],   [ 1,  3,  6,  7],   [ 1,  3,  6,  7]]),  Tensor(shape=[4, 4], dtype=Int32, value=  [[0, 0, 0, 0],   [1, 0, 0, 1],   [1, 2, 0, 2],   [3, 3, 0, 2]])]    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**林鑫",2025-03-05T11:03:20+08:00,usability,rejected,0,1,https://gitee.com/mindspore/mindspore/issues/IBQTSN,已修改，详见关联pr
虞良斌,worker_name Adds pid,,2025-03-05T10:26:41+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBQT3I
liuchuting,ops.bucketize连续计算时，值计算错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ops.bucketize连续计算时，值计算错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B2`/`CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >>> from mindspore import Tensor, ops >>> input = Tensor(np.array([[3, 6, 9], [3, 6, 9]])) >>> boundaries = list(np.array([1., 3., 5., 7., 9.])) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output) >>> output = ops.bucketize(input, boundaries)              >>> print(output) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 验证计算是否正确  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > 计算值正确  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-05T10:12:33+08:00,"gitee,usability",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBQSSK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
liuchuting,ops.bucketize连续计算时，值计算错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ops.bucketize连续计算时，值计算错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B2`/`CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >>> from mindspore import Tensor, ops >>> input = Tensor(np.array([[3, 6, 9], [3, 6, 9]])) >>> boundaries = list(np.array([1., 3., 5., 7., 9.])) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output) >>> output = ops.bucketize(input, boundaries)              >>> print(output) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 验证计算是否正确  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > 计算值正确  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**王少聪",2025-03-05T10:11:40+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IBQSS2
cccc1111,asinh_/arcsinh_接入aclnn, Tasks 转测对象：tensor.asinh_/tensor.arcsinh_ 对标torch.tensor.asinh_/arcsinh_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明 !输入图片说明 !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/complex64/complex128  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反双曲正弦值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-04T21:45:32+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQNH
cccc1111,asin_/arcsin_接入aclnn, Tasks 转测对象：tensor.asin_/tensor.arcsin_ 对标torch.tensor.asin_/arcsin_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明 !输入图片说明 !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反正弦值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-04T21:30:35+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQJZ
JavaZero,mul算子动态shape下不支持layout," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > qwen2.5 蒸馏sft  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)  dev  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) bash scripts/msrun_launcher.sh ""run_mindformer.py config research/qwen2_5/finetune_cjh.yaml run_mode finetune register_path research/qwen2_5"" 8  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) [ERROR] PARALLEL(414165,ffffb0990020,python):2025030414:58:26.705.263 [mindspore/ccsrc/frontend/parallel/ops_info/operator_info.cc:1545] InitWithTensorLayout] MulInfo2020: CheckInputLayout failed.  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-04T20:43:20+08:00,master,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQCM
虞良斌,aicore_metrics supports memory_access parameters br_feature_tools to master,,2025-03-04T19:39:30+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQ0J
caifubi,动态图执行结束后，如果进程还未退出，fronend_queue/bakcend_queue会一直残留并自旋,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-03-04T09:27:36+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQFXF
weixu2025,mint.baddbmm、mint.sort、mint.topk在Ascend平台上无法运算," 1. 问题描述 在对mint.baddbmm、mint.sort、mint.topk接口进行测试时，发现它们不能正常运行在Ascend平台上  2.环境信息 测试环境：启智社区 硬件：NPU: 1*Ascend 910(显存: 32GB), CPU: 24, 内存: 96GB 镜像：mindspore_2_5_py311_cann8（并非唯一不能正常运行的镜像，除此之外还包括多个镜像无法运行上述几个接口  **3.报错** 当测试mint.baddbmm接口时，直接运行文档里面的示例代码（链接：MindSpore） 代码为： ```python import numpy as np from mindspore import Tensor, mint input = Tensor(np.ones([1, 3, 3]).astype(np.float32)) batch1 = Tensor(np.ones([1, 3, 4]).astype(np.float32)) batch2 = Tensor(np.ones([1, 4, 3]).astype(np.float32)) output = mint.baddbmm(input, batch1, batch2) print(output) ``` 出现了报错： ```python  AttributeError                            Traceback (most recent call last) Cell In[7], line 8       5 batch1 = Tensor(np.ones([1,3,4]).astype(np.float32))       6 batch2 = Tensor(np.ones([1,4,3]).astype(np.float32)) > 8 output = mint.baddbmm(input, batch1, batch2)       9 print(output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/extend/math_func.py:73, in baddbmm(input, batch1, batch2, beta, alpha)      29 def baddbmm(input, batch1, batch2, beta=1, alpha=1):      30     r""""""      31     The result is the sum of the input and a batch matrixmatrix product of matrices in batch1 and batch2.      32     The formula is defined as follows:    (...)      71           [5. 5. 5.]]]      72     """""" > 73     return P.baddbmm(input, batch1, batch2, beta, alpha) AttributeError: module 'mindspore.ops.auto_generate' has no attribute 'baddbmm' ``` 但若将mint换为ops，即使用ops.baddbmm、ops.sort、ops.topk时，在NPU平台上正常运行。 除此之外，本地（Windows+CPU）也无法运行mint.baddbmm、mint.sort、mint.topk接口，而ops在本地可以正常运行。",2025-03-03T20:11:24+08:00,"mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBQDVF,这个会不会是环境问题？我在910上试了下上述代码是可以运行的，也是2.5.0版本： !输入图片说明 至于win+cpu上不能调用，应该是mint的这些方法目前只支持昇腾上使用，文档上有相关说明
luodan2024,mindspore.mint.isclose() 操作不支持梯度计算," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore.mint.isclose() 操作不支持梯度计算  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` def test_isclose_forward_back(mode):     """"""===使用mindspore和pytorch,固定输入和权重，测试正向推理结果和反向梯度===""""""     ms.set_context(mode=mode)     dtype_ms = ms.float64     dtype_torch = torch.float64     input_data_1 = [[0.1,0.2],[0.5,0.7],[0.11,0.32]]     input_data_2 = [[0.1,0.9],[0.5,0.2],[0.5,0.32]]     ms_input_1 = ms.Tensor(input_data_1,dtype_ms)     ms_input_2 = ms.Tensor(input_data_2,dtype_ms)     torch_input_1 = torch.tensor(input_data_1,dtype=dtype_torch,requires_grad=True)     torch_input_2 = torch.tensor(input_data_2,dtype=dtype_torch,requires_grad=True)     def forward_ms(input_1,input_2):         return ms.mint.isclose(input_1,input_2)     def forward_torch(input_1,input_2):         return torch.isclose(input_1,input_2)     测试正向推理结果     ms_result = forward_ms(ms_input_1,ms_input_2)     torch_result = forward_torch(torch_input_1,torch_input_2)     assert check_bool(ms_result.asnumpy(),np.asarray(torch_result.detach()))         测试反向传播梯度         try:         grad_fn = ms.value_and_grad(forward_ms,grad_position=(0,1))         _, ms_grad = grad_fn(ms_input_1,ms_input_2)         ms_grad_1 = ms_grad[0]         ms_grad_2 = ms_grad[1]         print(f""mindspore反向传播成功{ms_grad_1}{ms_grad_2}"")     except Exception as e:         print(""mindpore 反向传播失败:"", e) test_isclose_forward_back(ms.GRAPH_MODE) test_isclose_forward_back(ms.PYNATIVE_MODE) ```  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明 ",2025-03-03T18:15:58+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBQD2Q,"这个算子本身就不支持反向,torch也不支持",OK，经过确认，按此结论闭环
虞良斌,Synchronize the content of the master branch to the br_feature_tools branch,,2025-03-03T16:34:49+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBQBDD
weixu2025,mint.bmm  float16前向结果不匹配," 1. 问题描述 在对mindspore.mint.bmm该接口进行测试的时候，发现接口float16前向结果与pytorch不匹配 >              结果比较 >           assert np.allclose(ms_output.asnumpy(), pt_output.detach().numpy(), atol=1e5), ""Forward mismatch"" E           AssertionError: Forward mismatch E           assert False E            +  where False = (array(0.01775, dtype=float16), array(0.01772, dtype=float16), atol=1e05) E            +    where  = np.allclose E            +    and   array(0.01775, dtype=float16) = asnumpy() E            +      where asnumpy = Tensor(shape=[], dtype=Float16, value= 0.017746).asnumpy E            +    and   array(0.01772, dtype=float16) = () E            +      where  = tensor(0.0177, dtype=torch.float16).numpy E            +        where tensor(0.0177, dtype=torch.float16) = () E            +          where  = tensor(0.0177, dtype=torch.float16, grad_fn=).detach >  ``` AssertionError: Forward mismatch MS result: 0.01775 (float16) Torch result: 0.01772 (float16) ```  2.环境信息  **硬件环境**: Hardware (`Ascend910B`) ",2025-03-03T15:05:32+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ9KV,应该是底层硬件的差异造成的，910B1和torch使用的CPU或者GPU浮点数处理上会有差异，这里应该是cann算子处理上的差异，不在mindspore框架层面，不过float16在1e4的误差范围内的话，应该都属于是合理的
wang_ziqi,【AR】ops.svd支持Ascend后端,"  Background  **1. 标杆情况**   标杆接口链接： tf.linalg.svd(     tensor, full_matrices=False, compute_uv=True, name=None )  标杆支持数据类型：`Float32, Float64, Complex64, Complex128`   数据支持类型由于场景不同会发生变化，已实际场景为准  **2. MindSpore算子情况**   当前支持数据类型   ```   forward:    Ascend：Float32, Float64, Complex64, Complex128   CPU：Float32, Float64, Complex64, Complex128   GPU：Float32, Float64   backward:   Ascend：Float32   CPU：Float32, Float64   GPU：Float32, Float64   数据支持类型由于场景不同会发生变化，已实际场景为准   ```  三后端统一后算子支持（标杆支持+三后端并集） `Float32, Float64, Complex64, Complex128`  Introduction  **1. 功能介绍**  爱因斯坦求和  **2. 接口描述**   functional接口   mindspore/python/mindspore/ops/function/linalg_func.py   ```python   def svd(input, full_matrices=False, compute_uv=True):   ```  对应底层aclop算子 ```     REG_OP(Svd)         .INPUT(x, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .OUTPUT(sigma, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .OUTPUT(u, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .OUTPUT(v, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .ATTR(compute_uv, Bool, true)         .ATTR(full_matrices, Bool, false)         .OP_END_FACTORY_REG(Svd) ```",2025-03-03T09:53:30+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQ3XJ
吴逸群,香橙派,"mindspore2.5.0/mindspore2.4.10均出现上述问题，识别不到npu报错， Unsupported device target Ascend This process only supports one of the ['CPU']. Please check whether the Ascend environment is intalled and configure correctly, and check whether current mindspore wheel package was built with ""e Ascend"".  RuntimeError：Device Ascend not exist",2025-03-03T09:40:10+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ3PO,这种情况基本上是环境没配置好，cann或者昇腾驱动没匹配，或者缺钱昇腾相关的环境变量
majun-bot,CVE20251816,"一、漏洞信息 漏洞编号：CVE20251816 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： 4.3 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:L 漏洞简述： A vulnerability classified as problematic has been found in FFmpeg up to 6e26f57f672b05e7b8b052007a83aef99dc81ccb. This affects the function audio_element_obu of the file libavformat/iamf_parse.c of the component IAMF File Handler. The manipulation of the argument num_parameters leads to memory leak. It is possible to initiate the attack remotely. The exploit has been disclosed to the public and may be used. The identifier of the patch is 0526535cd58444dd264e810b2f3348b4d96cff3b. It is recommended to apply a patch to fix this issue. 漏洞公开时间：20250302 22:15:34 漏洞创建时间：20250302 23:10:45 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20251816 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 该漏洞的修复文件在5.1.4版本中没有，故不受影响 漏洞评分(MindSpore评分): &emsp;BaseScore： 4.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-03-02T23:10:46+08:00,"gitee,trac,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBQ2CX,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 该漏洞的修复文件在5.1.4版本中没有，故不受影响 漏洞评分(MindSpore评分):  BaseScore：4.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：FFmpeg漏洞CVE20251816 根因： 1、FFmpeg漏洞CVE20251816 Fix Solution 不修复，该漏洞的修复文件在5.1.4版本中没有，故不受影响 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不修复 Introduction Analysis 引入类型：其他，三方软件引入 引入PR：https://trac.ffmpeg.org/ticket/11475,不修复，该漏洞的修复文件在5.1.4版本中没有，故不受影响
weixu2025,mindspore.mint.minimum不支持Bool输入，但maximum支持Bool输入," 1. 问题描述 在对mindspore.mint.minimum该接口进行测试的时候，发现接口在不支持BFloat16数据类型的基础上，同时也不支持Bool型的输入。但执行相同的测试函数，mindspore.mint.maximum则是支持Bool输入的。 >torch.minimum not supported for torch.uint16 torch.minimum not supported for torch.uint32 torch.minimum not supported for torch.uint64 mint.minimum not supported for BFloat16 torch.minimum not supported for torch.bfloat16 mint.minimum not supported for Bool >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.测试代码（mint.minimum） ``` import pytest import numpy as np import mindspore as ms from mindspore import mint, Tensor, value_and_grad import torch dtype_ms = ms.float32 dtype_torch = torch.float32 input_data_x = [[1, 2], [3, 4], [5, 6]] input_data_y = [[6, 5], [4, 3], [2, 1]] ms_tensor_x = Tensor(input_data_x, dtype_ms) ms_tensor_y = Tensor(input_data_y, dtype_ms) torch_tensor_x = torch.tensor(input_data_x, dtype=dtype_torch) torch_tensor_y = torch.tensor(input_data_y, dtype=dtype_torch) .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_minimum_different_dtypes(mode):     """"""测试random输入不同dtype，对比两个框架的支持度""""""     ms.set_context(mode=mode)     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     for i in range(len(ms_dtypes)):         dtype_ms = ms_dtypes[i]         dtype_torch = torch_dtypes[i]         ms_tensor_x = Tensor(input_data_x, dtype_ms)         ms_tensor_y = Tensor(input_data_y, dtype_ms)         torch_tensor_x = torch.tensor(input_data_x, dtype=dtype_torch)         torch_tensor_y = torch.tensor(input_data_y, dtype=dtype_torch)         err = False         try:             ms_result = mint.minimum(ms_tensor_x, ms_tensor_y).asnumpy()         except Exception as e:             err = True             print(f""mint.minimum not supported for {dtype_ms}"")         try:             torch_result = torch.minimum(torch_tensor_x, torch_tensor_y).numpy()         except Exception as e:             err = True             print(f""torch.minimum not supported for {dtype_torch}"")         if not err:             if not np.allclose(ms_result, torch_result):                 print(f""mint.minimum is supported for {dtype_ms} but not working properly"") ```",2025-03-02T18:15:13+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ0ZV,在2.5版本中，mindspore.mint.minimum已支持BFloat16和Bool输入 在910B环境下MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
weixu2025,mindspore.mint.maximum希望支持BFloat16、UInt16, 1. 问题描述 在对mindspore.mint.maximum该接口进行测试的时候，发现接口不支持BFloat16、UInt16此数据类型，而Pytorch则是支持的。 > torch.maximum not supported for torch.uint16 torch.maximum not supported for torch.uint32 torch.maximum not supported for torch.uint64 mint.maximum not supported for BFloat16 torch.maximum not supported for torch.bfloat16 >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.价值 BFloat16其指数位数与FP32相同，表示的数据范围更广，在精度较低的情况下可用于提升训练速度。希望支持。,2025-03-02T17:37:53+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ0S9,目前，在2.5版本中，mindspore.mint.nn.functional.selu已支持BFloat16，尚未支持UInt16， 在910B环境下MindSpore与torchnpu对BFloat16的结果一致， 后续将会增加对UInt16的支持 !输入图片说明
weixu2025,mindspore.mint.less_equal希望支持BFloat16, 1. 问题描述 在对mindspore.mint.less该接口进行测试的时候，发现接口不支持BFloat16此数据类型，而Pytorch则是支持的。 > torch.lt not supported for torch.uint32 torch.lt not supported for torch.uint64 mint.less not supported for BFloat16 >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.价值 BFloat16其指数位数与FP32相同，表示的数据范围更广，在精度较低的情况下可用于提升训练速度。希望支持。,2025-03-01T20:13:40+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBPY5E,在2.5版本中，mindspore.mint.less_equal已支持BFloat16， 在910B环境下MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
j00647318,rollback batch valid length,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-01T18:55:21+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPXYT
caifubi,修复so找不到的问题 “ImportError: libmindspore_pyboost.so: cannot open shared object file: No such file or directory”,,2025-03-01T15:14:04+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPWKB
李尚憬,新版本mindspore模型转换," 问题 在新版mindpsore.export中.air格式已被弃用，而在香橙派中使用.onnx与.mindir格式转换成.om均会发生错误，仅.air格式能转换，请问这是bug还是转换命令有所不同  复现步骤 1.导出模型为.air/.onnx/.mindir ```  export_model.py import mindspore import numpy as np from mindspore import Tensor from src.deep_learning.networks import resnet152 net = resnet152() params = mindspore.load_checkpoint('medical_resnet_checkpoints.ckpt') mindspore.load_param_into_net(net, params) input_tensor = Tensor(np.ones([1, 3, 572， 572]).astype(np.float32)) mindspore.export(net, input_tensor, file_name='medical_resnet', file_format='AIR')  其它格式则将""AIR""换成""MINDIR""或""ONNX"" ``` 2.在香橙派中执行模型转换 ``` atc framework=1 model=./medical_resnet.air input_format=NCHW output=medical_resnet log=error soc_version=Ascend310B4  其他格式则将.air换成.onnx或.mindir ```  执行情况 1.从.air格式起转，执行正常 !输入图片说明 2.从.onnx格式起转，执行报错 !输入图片说明 3.从.mindir格式起转，执行报错 !输入图片说明",2025-03-01T13:34:17+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBPW36,也不算是bug，应该是cann里面的atc工具转换功能对第三方格式兼容完善程度还不够吧，air本身就是昇腾专用的，自然兼容最完善，onnx相对来说是一种通用格式，又是非昇腾官方的，兼容上确实相差多一些的，还有其它tf的pb或者caffe格式也一样，我以前用的时候也经常碰到第三方格式的转换不支持；至于mindir格式本身就不能转，atc工具不支持转mindir格式： !输入图片说明 atc转换命令使用上的差别，air不需要指定输入节点的信息，onnx通常需要指定输入节点的信息
虞良斌,mindspore dynamic profiling access dynolog,,2025-03-01T11:26:23+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPVLP
dairenjie,GMMV4文档错误, 1. 【Document Link】/【文档链接】 2. 【Issues Section】/【问题文档片段】 3. 【Existing Issues】/【存在的问题】 文档问题自提单 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-02-28T16:10:49+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPQY9
LiWanpeng,converter_lite转换Rank算子报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore生成带Rank的mindir模型转ms模型报错；以及返回是标量的算子也会报错,如Size算子.  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 无  4.Steps to reproduce the issue / 重现步骤 (1)生成的mindir模型代码: ``` import mindspore as ms import numpy as np from mindspore import nn, ops class test(nn.Cell):     def __init__(self):         super(test, self).__init__()         self.rank = ops.Rank()     def construct(self, x):         x = self.rank(x)         return x x = np.zeros((3, 3), dtype=np.float32) x_t = ms.Tensor(x) model = test() out = model(x_t) print(""out:"", out) ms.export(     model,     x_t,     file_name=""test"",     file_format=""MINDIR"", ) ``` (2)使用converter_lite工具转换命令: ./converter_lite fmk=MINDIR modelFile=test.mindir outputFile=test_rank  5.Describe the expected behavior / 预期结果  能够转换出test_rank.ms模型文件,并且该模型只有rank算子.  6.Related log / screenshot / 日志 / 截图 报错关键日志截图： !输入图片说明  ",2025-02-28T15:13:28+08:00,"gitee,mindspore-assistant",open,0,3,https://gitee.com/mindspore/mindspore/issues/IBPPF2,导出mindir，使用mslite的转换工具进行转换，目的是为了在手机cpu上推理还是在ascend卡上推理，推理硬件明确一下,是服务器的cpu还是手机cpu,服务器的cpu
weixu2025,mindspore.mint.less希望支持BFloat16, 1. 问题描述 在对mindspore.mint.less该接口进行测试的时候，发现接口不支持BFloat16此数据类型，而Pytorch则是支持的。 > torch.lt not supported for torch.uint32 torch.lt not supported for torch.uint64 mint.less not supported for BFloat16 >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.价值 BFloat16其指数位数与FP32相同，表示的数据范围更广，在精度较低的情况下可用于提升训练速度。希望支持。,2025-02-28T12:56:44+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBPNES,在2.5版本中，mindspore.mint.less已支持BFloat16，在910B环境下MindSpore与torchnpu结果一致 !输入图片说明
ffmh,reuse_data_ptr输入未同步导致显存波动," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) reuse_data_ptr输入未同步，在执行原地计算时申请新空间，导致显存波动 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改） **【引入分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-28T11:32:29+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPMUL
梅飞要,fix mstx warn log,,2025-02-27T19:27:15+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBPII6
虞良斌,Fix the log printing problem of online parsing function,,2025-02-27T15:27:23+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBPEEA
tanxinglian,[CT][MS][OPS][ops.trunc][function][全量][DVM]test_t_trunc_float32_3x9_nan O1模式下计算结果错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_t_trunc_float32_3x9_nan O1模式下计算结果错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_t_trunc_float32_3x9_nan >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O1  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export CONTEXT_JIT_LEVEL=O1 export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_t_trunc.py::test_t_trunc_float32_3x9_nan  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```  ()     def test_t_trunc_float32_3x9_nan():         x = Tensor(np.full((3, 9), np.nan), mstype.float16)         fact = TruncMock(             inputs=[x]) >       fact.forward_cmp() ../test_t_trunc.py:143:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/trunc_ops.py:117: in forward_cmp     allclose_nparray(out_cmp, out_mindspore, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[nan, nan, nan, nan, nan, nan, nan, nan, nan],        [nan, nan, nan, nan, nan, nan, nan, nan, nan],        [nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float16) data_me = array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-27T09:51:23+08:00,"gitee,foruda,rca/others,ctl/componenttest,rct/newfeature",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBP9R3, Appearance & Root Cause 问题：trunc f16 nan在O1下结果为0 根因：dvm实现trunc f16有问题  Fix Solution 修改dvm中trunc f16的实现   Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/82293 PR合入后daily包回归  Selftest Report & DT Review 自测通过 是否需要补充 ST/UT：否 原因：DVM仓增加测试用例覆盖  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/74497 特性引入原因：场景考虑不充分 PR合入时间：2025年/1月/2日 问题是否偶现：否,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,"【回归版本号】：__commit_id__ = '[sha1]:ba6873c3,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
majun-bot,CVE20246119,"一、漏洞信息 漏洞编号：CVE20246119 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N 漏洞简述： Issue summary: Applications performing certificate name checks (e.g., TLS clients checking server certificates) may attempt to read an invalid memory address resulting in abnormal termination of the application process. Impact summary: Abnormal termination of an application can a cause a denial of service. Applications performing certificate name checks (e.g., TLS clients checking server certificates) may attempt to read an invalid memory address when comparing the expected name with an `otherName` subject alternative name of an X.509 certificate. This may result in an exception that terminates the application program. Note that basic certificate chain validation (signatures, dates, ...) is not affected, the denial of service can occur only when the application also specifies an expected DNS name, Email address or IP address. TLS servers rarely solicit client certificates, and even when they do, they generally don't perform a name check against a reference identifier (expected identity), but rather extract the presented identity after checking the certificate chain.  So TLS servers are generally not affected and the severity of the issue is Moderate. The FIPS modules in 3.3, 3.2, 3.1 and 3.0 are not affected by this issue. 漏洞公开时间：20240904 00:15:07 漏洞创建时间：20250227 01:12:53 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20246119 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 执行证书名称检查的应用程序（例如，TLS客户端检查服务器证书）可能会尝试读取无效的内存地址，导致应用程序进程异常终止。影响摘要：应用程序的异常终止可能会导致拒绝服务。执行证书名称检查的应用程序（例如，检查服务器证书的TLS客户端）在将预期名称与X.509证书的“otherName”主题替代名称进行比较时，可能会尝试读取无效的内存地址。这可能会导致终止应用程序的异常。请注意，基本证书链验证（签名、日期等）不受影响，只有当应用程序还指定了预期的DNS名称、电子邮件地址或IP地址时，才会发生拒绝服务。TLS服务器很少请求客户端证书，即使请求了，它们通常也不会对引用标识符（预期身份）执行名称检查，而是在检查证书链后提取呈现的身份。因此，TLS服务器通常不受影响，问题的严重程度为中等。3.3、3.2、3.1和3.0中的FIPS模块不受此问题的影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响",2025-02-27T01:12:54+08:00,"gitee,CVE/UNAFFECTED,seclists",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBP8ME,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142"," CVE20246119 在当前软件仓下已经创建过对应的ISSUE, 请不要重复创建",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明:执行证书名称检查的应用程序（例如，TLS客户端检查服务器证书）可能会尝试读取无效的内存地址，导致应用程序进程异常终止。影响摘要：应用程序的异常终止可能会导致拒绝服务。执行证书名称检查的应用程序（例如，检查服务器证书的TLS客户端）在将预期名称与X.509证书的“otherName”主题替代名称进行比较时，可能会尝试读取无效的内存地址。这可能会导致终止应用程序的异常。请注意，基本证书链验证（签名、日期等）不受影响，只有当应用程序还指定了预期的DNS名称、电子邮件地址或IP地址时，才会发生拒绝服务。TLS服务器很少请求客户端证书，即使请求了，它们通常也不会对引用标识符（预期身份）执行名称检查，而是在检查证书链后提取呈现的身份。因此，TLS服务器通常不受影响，问题的严重程度为中等。3.3、3.2、3.1和3.0中的FIPS模块不受此问题的影响。 漏洞评分(mindspore评分): BaseScore:7.5 Vector:CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", Appearance & Root Cause 工具误报，当前mindspore使用的openssl版本为1.1.1k，该漏洞只影响3.0及以上版本，因此不需要修复。 详情见：https://seclists.org/osssec/2024/q3/240  Fix Solution mindspore不受影响，无需修复。
luoxuewei,tensor.__int__接口重构,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  tensor.__int__接口重构，提高执行性能  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-26T21:53:35+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP85D
cccc1111,le_接入aclnn, Tasks 转测对象：tensor.le_ 对标torch.tensor.le_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/bool  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  比较Tensor A中的元素是否小于Tensor B中的元素  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-02-26T19:28:57+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP7C6
tanxinglian,[CT][MS][OPS][Tensor.max][function][全量]test_dynamic_shape_t_max_dyn_rank_2 910A 计算结果与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_dynamic_shape_t_max_dyn_rank_2 910A 计算结果与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_t_max_dyn_rank_2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE > （2）cd MindSporeTest/operations > （3）pytest s v test_t_max.py::test_dynamic_shape_t_max_dyn_rank_2  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     (reason='not support')     (reason='not support')     (reason='not support')     def test_dynamic_shape_t_max_dyn_rank_2():         x = Tensor(None, dtype=mstype.float32)         dim = mutable(input_data=2, dynamic_len=False)         keepdim = mutable(input_data=False, dynamic_len=False)         x1 = Tensor(np.random.randn(1, 22), mstype.float32)         dim1 = mutable(input_data=2, dynamic_len=False)         keepdim1 = mutable(input_data=False, dynamic_len=False)         attributes1 = {'dim': dim1, 'keepdim': keepdim1}         inputs1 = [x1]         x2 = Tensor(np.random.randn(9, 1, 24, 1, 50, 1, 1), mstype.float32)         dim2 = mutable(input_data=5, dynamic_len=False)         keepdim2 = mutable(input_data=False, dynamic_len=False)         attributes2 = {'dim': dim2, 'keepdim': keepdim2}         inputs2 = [x2]         x3 = Tensor(np.random.randn(16, ), mstype.float32)         dim3 = mutable(input_data=1, dynamic_len=False)         keepdim3 = mutable(input_data=False, dynamic_len=False)         attributes3 = {'dim': dim3, 'keepdim': keepdim3}         inputs3 = [x3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = MaxMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (x, dim, keepdim) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_t_max.py:641:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/max_t_ops.py:296: in forward_dynamic_shape_cmp     allclose_nparray(a[1], b[1], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[ 7.]],           [[21.]],           [[ 4.]],           [[17.]],           [[ 3.]],           [[ 4.]],...           [[13.]],           [[ 4.]],           [[13.]],           [[ 1.]],           [[12.]]]]]], dtype=float32) data_me = array([[[[[[ 0]],           [[ 0]],           [[ 0]],           [[ 0]],           [[ 0]],           [[ 0]],     ...[[ 5]],           [[13]],           [[ 4]],           [[13]],           [[ 1]],           [[12]]]]]], dtype=int64) rtol = 0.0001, atol = 0.0001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T17:12:40+08:00,"gitee,foruda,rca/codelogic,rct/cann,ctl/testcismoke,mindspore-repo",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBP5TM,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：max算子在910A上出现精度异常 根因： 1、cann包中aclnnMAXDIM接口有精度问题 同时用torch_npu做了复现 !输入图片说明 Fix Solution 1、待cann修复对应问题 Fix Description & Test Suggestion cann包更新至最新版本，问题解决 http://mindsporerepo.csi.rnd.huawei.com//productrepo/HiAI/Milan_C21/20250307_atlas/ 测试建议：该问题可以通过特性用例防护，增加****场景。 Selftest Report & DT Review !输入图片说明 是否需要补充 ST/UT：否 原因：本身就是CI看护用例 Introduction Analysis 引入类型：cann包引入 引入PR：cann包引入，pr未知 PR合入时间：年/月/日 问题是否偶现：是/否,"【回归版本号】：__commit_id__ = '[sha1]:e137bd4a,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明"
tanxinglian,[CT][MS][OPS][mint.argmax][function][全量]mint.argmax 910A 计算结果与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.argmax 910A 计算结果与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_mint_f_argmax_dyn_rank_1 test_dynamic_shape_mint_f_argmax_dyn_rank_2 test_dynamic_shape_mint_f_argmax_dyn_shape_2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_f_argmax.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_dynamic_shape_mint_f_argmax_dyn_rank_1():         input_x = Tensor(None, dtype=mstype.float32)         dim = mutable(input_data=1, dynamic_len=False)         keepdim = mutable(input_data=False, dynamic_len=False)         input1 = Tensor(np.random.randn(8, 5), mstype.float32)         dim1 = mutable(input_data=1, dynamic_len=False)         keepdim1 = mutable(input_data=False, dynamic_len=False)         attributes1 = {'dim': dim1, 'keepdim': keepdim1}         inputs1 = [input1]         input2 = Tensor(np.random.randn(3, 4, 7, 7, 7, 5, 9, 5), mstype.float32)         dim2 = mutable(input_data=3, dynamic_len=False)         keepdim2 = mutable(input_data=False, dynamic_len=False)         attributes2 = {'dim': dim2, 'keepdim': keepdim2}         inputs2 = [input2]         input3 = Tensor(np.random.randn(9, ), mstype.float32)         dim3 = mutable(input_data=1, dynamic_len=False)         keepdim3 = mutable(input_data=False, dynamic_len=False)         attributes3 = {'dim': dim3, 'keepdim': keepdim3}         inputs3 = [input3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = ArgmaxMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (input_x, dim, keepdim) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_mint_f_argmax.py:533:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/functional/argmax_mint.py:116: in forward_dynamic_shape_cmp     allclose_nparray(a, b, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[5., 4., 0., 1., 3.],             [5., 0., 5., 4., 0.],             [4., 0., 5., 6., 0.],             ...,...         [0., 2., 0., 6., 4.],             [1., 6., 4., 2., 5.],             [4., 2., 3., 0., 5.]]]]]]], dtype=float32) data_me = array([[[[[[[0, 0, 0, 0, 0],             [0, 0, 0, 0, 0],             [0, 0, 0, 0, 0],             ...,             [0...         ...,             [0, 2, 0, 6, 4],             [1, 6, 4, 2, 5],             [4, 2, 3, 0, 5]]]]]]], dtype=int64) rtol = 0.0001, atol = 0.0001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:57:39+08:00,"foruda,rct/cann,mindspore-repo,productrepo/HiAI",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBP4MK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,CANN 升级 CANN包引入，具体是opp kernel组件，是否偶现：否 DTS单：DTS2025021114075,Appearance & Root Cause 问题：mint.argmax算子精度问题 根因： CANN包升级引入，升级CANN包可以解决 Fix Solution 升级CANN包 Fix Description & Test Suggestion 无 Selftest Report & DT Review 无 Introduction Analysis 引入类型：CANN升级 问题是否偶现：否 CANN 包引入，具体是opp kernel组件，是否偶现：否 DTS单：DTS2025021114075,"【回归版本号】：__commit_id__ = '[sha1]:e460364b,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com//productrepo/HiAI/Milan_C21/20250307_atlas/ !输入图片说明"
tanxinglian,"[CT][MS][OPS][ops.deformable_conv2d][function][全量]ops.deformable_conv2d ascend报错RuntimeError: Launch kernel failed, name:Default/DeformableOffsetsop0"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.deformable_conv2d ascend报错RuntimeError: Launch kernel failed, name:Default/DeformableOffsetsop0  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_deformable_conv2d_input_float16 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_f_deformable_conv2d.py::test_f_deformable_conv2d_input_float16  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ``` ../test_f_deformable_conv2d.py::test_f_deformable_conv2d_input_float16 [WARNING] ME(609796:140099693287232,MainProcess):2025022304:18:53.419.956 [mindspore/context.py:1335] For 'context.set_context', the parameter 'device_target' will be deprecated and removed in a future version. Please use the api mindspore.set_device() instead. [WARNING] ME(609796:140099693287232,MainProcess):2025022304:18:53.421.360 [mindspore/context.py:1335] For 'context.set_context', the parameter 'device_target' will be deprecated and removed in a future version. Please use the api mindspore.set_device() instead. [ERROR] KERNEL(609796,7f6b5a6de700,python3.10):2025022304:18:58.497.174 [mindspore/ccsrc/plugin/device/ascend/kernel/acl/acl_kernel_mod.cc:260] Launch] Kernel launch failed, msg: Acl compile and execute failed, op_type_:DeformableOffsets   Ascend Error Message:  EZ9999: Inner Error! EZ9999: [PID: 609796] 2025022304:18:58.496.135 Input_offsets h/w should be same as h/w after convolution, but now offset: [h:12, w:2]. conv_out: [h:63, w:2].[FUNC:DeformableOffsetsInferShape][FILE:deformable_offsets.cc][LINE:138][THREAD:611077]         TraceBack (most recent call last):        InferShape failed, node type DeformableOffsets, name DeformableOffsets1, errorcode 4294967295[FUNC:InferShape][FILE:infer_shape.cc][LINE:173][THREAD:611077]        [Exec][Op]Execute op failed. op type = DeformableOffsets, ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161][THREAD:611077] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/acl_ir/acl_utils.cc:395 Run [ERROR] DEVICE(609796,7f6b5a6de700,python3.10):2025022304:18:58.497.218 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge_kernel_executor.cc:1321] LaunchKernel] Launch kernel failed, kernel full name: Default/DeformableOffsetsop0 FAILED =================================== FAILURES =================================== ____________________ test_f_deformable_conv2d_input_float16 ____________________          def test_f_deformable_conv2d_input_float16():         strides = (1, 1, 1, 1)         padding = (0, 0, 0, 0)         dilations = (1, 1, 1, 1)         batch, cin, x_h, x_w = 1, 64, 3, 6         cout, kh, kw = 1, 2, 2         fact = DeformableConv2DFactory(batch, cin, cout, x_h, x_w, kh, kw, strides,                                        padding, dilations, dtype=np.float16) >       fact.forward_cmp() ../test_f_deformable_conv2d.py:62:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/deformable_conv2d_ops.py:295: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/deformable_conv2d_ops.py:179: in forward_mindspore_impl     out = net(x, w, offsets, bias) ../../share/utils.py:290: in __call__     _pynative_executor.sync() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =      def sync(self):         """"""         SyncStream.         Return:             None.         """""" >       self._executor.sync() E       RuntimeError: Launch kernel failed, name:Default/DeformableOffsetsop0 E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/runtime/pynative/op_runner.cc:648 LaunchKernels /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1578: RuntimeError =============================== warnings summary =============================== ../../../../../../miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/_op_impl/_custom_op/batchnorm_fold2.py:57 ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67b8706784dee72f16d75add&workspaceId=67ba33c7a052d732536727e8    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:21:04+08:00,"gitee,foruda,rca/others,ctl/componenttest,rct/cann,mindspore-repo",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBP3Q4,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：升级Milan_C21/20250206包后，deformable_conv2d用例执行失败 根因： 1、 CANN包升级引入，opp包，必现。 2、 据CANN算子责任人分析，1月16号有人提交了对NHWC格式实现，2月6号代码回退了该代码，取2月7号以后的cann包就没这个问题了。 Fix Solution 升级CANN，使用2月7号之后的CANN包。当前使用0219的CANN验证用例，执行通过。 Fix Description & Test Suggestion 使用2月7号之后的CANN包回归用例。 测试建议：回归当前用例。 Selftest Report & DT Review 使用0219的CANN验证用例，执行通过。 是否需要补充 ST/UT：否 如果选择否，请补充理由 原因：非MS问题，当前用例足以看护。 Introduction Analysis 引入类型：Milan_C21/20250206 CANN包引入 PR合入时间：年/月/日 问题是否偶现：是/否,"【回归版本号】：__commit_id__ = '[sha1]:ba6873c3,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包 http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明"
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.__xor__(^), Tasks 转测对象：Tensor.\_\_xor\_\_(符号^) ,2025-02-26T16:19:29+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP3PG
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.__or__(|), Tasks 转测对象：Tensor.\_\_or\_\_(符号,2025-02-26T16:16:32+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP3O1
tanxinglian,[CT][MS][OPS][mint.nn.functional.interpolate][function][全量]mint.nn.functional.interpolate 910A pynative模式报错RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.interpolate 910A pynative模式报错RuntimeError: aclnnUpsampleBilinear2dBackwardGetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_f_interpolate_dyn_rank_bilinear test_dynamic_shape_f_interpolate_dyn_shape_bilinear test_mint_n_f_interpolate_bilinear_float16 test_mint_n_f_interpolate_bilinear_float32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_n_f_interpolate.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       ()     ()     ()     def test_mint_n_f_interpolate_bilinear_float16():         input_x = Tensor(np.random.randn(3, 6, 7, 4), mstype.float16)         size = 3         scale_factor = None         mode = 'bilinear'         align_corners = True         recompute_scale_factor = False         antialias = False         fact = InterpolateMock(             attributes={'size': size, 'scale_factor': scale_factor, 'mode': mode,                         'align_corners': align_corners,                         'recompute_scale_factor': recompute_scale_factor, 'antialias': antialias},             inputs=[input_x])         fact.forward_cmp() >       fact.grad_cmp() ../test_mint_n_f_interpolate.py:466:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/interpolate_mint.py:140: in grad_cmp     grad_mindspore = self.grad_mindspore_impl() ../../share/mint/nn_functional/interpolate_mint.py:83: in grad_mindspore_impl     return grad.asnumpy() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = Tensor(shape=[3, 6, 7, 4], dtype=Float16, value= [[[[ 1.2471e+00,  5.2734e01,  2.2012e+00, 6.5283e01],    [ 1.6494e...],    [ 1.9609e+00,  1.4092e+00, 5.1660e01, 3.2104e01],    [ 7.1875e01,  3.9673e01,  0.0000e+00,  0.0000e+00]]]])     def asnumpy(self):         """"""         Convert tensor to numpy array. Returns self tensor as a NumPy ndarray. This tensor and the returned ndarray         share the same underlying storage. Changes to self tensor will be reflected in the ndarray.         Returns:             A numpy ndarray which shares the same underlying storage with the tensor.         Examples:             >>> from mindspore import Tensor             >>> import numpy as np             >>> x = Tensor(np.array([1, 2], dtype=np.float32))             >>> y = x.asnumpy()             >>> y[0] = 11             >>> print(x)             [11.  2.]             >>> print(y)             [11.  2.]         """"""         if self.has_init:             self.init_data() >       return TensorPy_.asnumpy(self) E       RuntimeError: aclnnUpsampleBilinear2dBackwardGetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 413614] 2025022401:14:57.359.393 out tensor's shape[[3,6,7,4]] is not equal with inferOut shape[[3,6,3,3]].[THREAD:415737] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/pyboost/customize/upsample_bilinear2d_grad.cc:36 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/tensor.py:1047: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bb5876a052d732536a3f38&workspaceId=67bb586884dee72f16e054f6    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:12:59+08:00,"gitee,foruda,foruda,rct/cann,mindspore-repo,dts-szv",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBP3MH,cann问题，已有dts单跟踪：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025021721028,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,"Appearance & Root Cause aclnn接口里有个判断写错了，导致没走到正确的分支,直接校验输入输出shape CANN问题单 DTS2025021721028 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：当前已有用例",【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 解决方案 (Fix Solution) 2. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,"Appearance & Root Cause 910A pynative模式报错在aclnn算子上 Fix Solution CANN问题单：aclnn接口里有个判断写错了，导致没走到正确的分支,直接校验输入输出shape DTS2025021721028 Fix Solution cann已修复 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：当前已有用例","【回归版本号】：__commit_id__ = '[sha1]:d0baee5f,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明 !输入图片说明"
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.__and__(&), Tasks 转测对象：Tensor.\_\_and\_\_(符号&) ,2025-02-26T16:10:48+08:00,"v2.1.0,sig/ops,gitee",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP3LA
tanxinglian,[CT][MS][OPS][ops.xlogy][function][全量]ops.xlogy 报错TypeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.xlogy 报错TypeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_functional_xlogy_input_2d_x_float16_y_bool test_functional_xlogy_input_2d_x_float32_y_number_float test_functional_xlogy_input_2d_x_number_int_y_float32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_f_xlogy.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      def test_functional_xlogy_input_2d_x_float16_y_bool():         inputx_shape = (5, 15)         inputy = True         inputx = Tensor(np.abs(np.random.randn(*inputx_shape).astype(np.float16)))         xlogy = ms.ops.operations.Xlogy() >       xlogy(inputx, inputy) ../test_f_xlogy.py:240:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = Prim[Xlogy] input = Tensor(shape=[5, 15], dtype=Float16, value= [[ 4.2480e01,  1.6533e+00,  9.5605e01 ...  5.8643e01,  7.0166e01,  4.5...33e01,  9.3555e01,  6.0840e01],  [ 8.8818e01,  5.7373e01,  7.6965e02 ...  4.7363e01,  1.8640e01,  6.8164e01]]) other = True     def __call__(self, input, other):          Add for jit context.         if jit_context() and jit_context().compiled:             return None >       res = _convert_stub(pyboost_xlogy(self, [input, other])) E       TypeError: Failed calling Xlogy with ""Xlogy()(input=Tensor, other=bool)"". E       The valid calling should be:  E       ""Xlogy()(input=, other=)"". E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1217 PrintTypeCastError /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/auto_generate/gen_ops_prim.py:19899: TypeError =============================== warnings summary =============================== ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866710&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250223%2003:32:06&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bade0c7b13446a61529342&workspaceId=67bade059b707706537521ae    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:00:53+08:00,"gitee,rca/others,ctl/componenttest,rct/bugfix",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBP3CR,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,去掉隐式类型转换导致，走给冬冬,已提交接口变更申请议题，预计周二评审+修改资料+走单。,Appearance & Root Cause 问题：Xlogy算子原语直调时输入标量会报错TypeError 根因： 1、 原语已去除type_cast，不再支持非Tensor输入。相关变更上库只处理了对外ops、Tensor、mint接口，未处理Xlogy原语资料。 Fix Solution 1. Xlogy原语资料，补充Xlogy算子功能变更评审。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83453 已合入master分支，PR合入后daily包回归 测试建议：通过MindSporeTest算子用例看护即可，出错用例为functional接口用例，不需要直接调用原语。 Selftest Report & DT Review 无，看护上层ops、Tensor、mint接口即可。 是否需要补充 ST/UT：否 修改MindSporeTest仓用例。 Introduction Analysis 引入类型：Bugfix 修复引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81625 PR合入时间：2025/2/19 问题是否偶现：否,原语已去除type_cast，不再支持非Tensor输入，接口变更邮件已发，需适配用例 相关资料已修改
Yuan,基于原有代码将resnet50改成resnet34," ``` from mindspore import load_checkpoint, load_param_into_net def make_layer(last_out_channel, block: Type[Union[ResidualBlockBase, ResidualBlock]],                channel: int, block_nums: int, stride: int = 1):     down_sample = None   shortcuts分支     if stride != 1 or last_out_channel != channel * block.expansion:         down_sample = nn.SequentialCell([             nn.Conv2d(last_out_channel, channel * block.expansion,                       kernel_size=1, stride=stride, weight_init=weight_init),             nn.BatchNorm2d(channel * block.expansion, gamma_init=gamma_init)         ])     layers = []     layers.append(block(last_out_channel, channel, stride=stride, down_sample=down_sample))     in_channel = channel * block.expansion      堆叠残差网络     for _ in range(1, block_nums):         layers.append(block(in_channel, channel))     return nn.SequentialCell(layers) class ResNet(nn.Cell):     def __init__(self, block: Type[Union[ResidualBlockBase, ResidualBlock]],                  layer_nums: List[int], num_classes: int, input_channel: int) > None:         super(ResNet, self).__init__()         self.relu = nn.ReLU()         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, weight_init=weight_init)         self.norm = nn.BatchNorm2d(64)         self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, pad_mode='same')         self.layer1 = make_layer(64, block, 64, layer_nums[0])         self.layer2 = make_layer(64 * block.expansion, block, 128, layer_nums[1], stride=2)         self.layer3 = make_layer(128 * block.expansion, block, 256, layer_nums[2], stride=2)         self.layer4 = make_layer(256 * block.expansion, block, 512, layer_nums[3], stride=2)         self.avg_pool = nn.AvgPool2d()         self.flatten = nn.Flatten()         self.fc = nn.Dense(in_channels=input_channel, out_channels=num_classes)     def construct(self, x):         x = self.conv1(x)         x = self.norm(x)         x = self.relu(x)         x = self.max_pool(x)         x = self.layer1(x)         x = self.layer2(x)         x = self.layer3(x)         x = self.layer4(x)         x = self.avg_pool(x)         x = self.flatten(x)         x = self.fc(x)         return x def _resnet(model_url: str, block: Type[Union[ResidualBlockBase, ResidualBlock]],             layers: List[int], num_classes: int, pretrained: bool, pretrained_ckpt: str,             input_channel: int):     model = ResNet(block, layers, num_classes, input_channel)     if pretrained:         download(url=model_url, path=pretrained_ckpt, replace=True)         param_dict = load_checkpoint(pretrained_ckpt)         load_param_into_net(model, param_dict)     return model def resnet34(num_classes: int = 1000, pretrained: bool = False):     """"""ResNet34模型""""""     resnet34_url = ""https://mindsporewebsite.obs.cnnorth4.myhuaweicloud.com/notebook/models/application/resnet34_224_new.ckpt""     resnet34_ckpt = ""./LoadPretrainedModel/resnet34_224_new.ckpt""     return _resnet(resnet34_url, ResidualBlockBase, [3, 4, 6, 3], num_classes,                    pretrained, resnet34_ckpt, 512) ``` 主要改动点     1 残差块类型：     ResNet34 使用 ResidualBlockBase，而 ResNet50 使用 ResidualBlock     2 每层残差块的数量：     ResNet34 的层结构为 [3, 4, 6, 3] （和resnet50一样）     3 全连接层的输入通道数：     ResNet34 的最后输出通道数为 512，因此 input_channel 参数设置为 512     4 预训练模型的 URL：     需要修改为 ResNet34 的预训练权重链接     5 函数名称：     新增了 resnet34 函数，用于创建 ResNet34 模型",2025-02-26T15:43:44+08:00,"gitee,gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBP2YU,如果对教程有什么好的修改的话，可以在doc仓库提pr，审核通过后会合入的，官网也就会跟着更新了： https://gitee.com/mindspore/docs resnet系列的模型官方models仓库里有，如果还需要增加其它的话，也可以参考下models的链接： https://gitee.com/mindspore/models/tree/master/official/cv/ResNet
孙昊辰,add 310p internal restriction when check group_list parameter,"   Describe the current behavior / 问题描述 (Mandatory / 必填) add 310p internal restriction when check group_list parameter  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend 910B  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.5.1  Python version (e.g., Python 3.7.5) :Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):Ubuntu  GCC/Compiler version (if compiled from source): 7.3.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填) test_grouped_matmul.py  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 整网测试grouped matmul算子  Describe the expected behavior / 预期结果 (Mandatory / 必填)  报错 group_list's last element must be equal to 4  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  group_list's last element must be equal to 4  Special notes for this issue/备注 (Optional / 选填)",2025-02-26T15:02:38+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP1Z9
Yuan,建议," https://www.mindspore.cn/tutorials/zhCN/master/cv/resnet50.html 教程中提到： !输入图片说明 我按照提示中的两种情况，稍微补充了一点代码：  '''         如果:         （1）如果主分支与shortcuts输出的特征矩阵shape不相同，如输出channel是输入channel的一倍时，shortcuts上需要使用数量与输出channel相等，大小为1*1的卷积核进行卷积操作；（2）若输出的图像较输入图像缩小一倍，则要设置shortcuts中卷积操作中的stride为2，主分支第二层卷积操作的stride也需设置为2。         ''' 则需要修改下采样操作‘self.down_sample = down_sample’ ```          （1）         if stride != 1 or in_channel != out_channel:             self.down_sample = nn.SequentialCell([                 nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride),                 nn.BatchNorm2d(out_channel)             ])         else:             self.down_sample = None ``` （2）时： 需要修改用于主分支第一层的conv1：stride=2 ```          （2）          定义用于主分支第一层 和shortcuts 用的conv1         self.conv1 = nn.Conv2d(in_channel, out_channel,                                kernel_size=3, stride=2,                                weight_init=weight_init)          shortcut2：kernel_size=1, stride=2         if stride != 1 or in_channel != out_channel:             self.down_sample = nn.SequentialCell([                 nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=2),                 nn.BatchNorm2d(out_channel)             ])         else:             self.down_sample = None ``` 注意： shortcuts 分支应使用 1x1 卷积调整通道数和尺寸，而非 3x3。3x3 卷积会引入不必要的参数和计算量，且与标准残差块设计（如 ResNet）不符。 不知道会不会使教程更加完善",2025-02-26T11:02:40+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOYW5,可以去mindspore文档教程的仓库反馈一下，如果采纳了你的修改建议的话，可以直接提PR审核通过合入后官网上就直接更新上的修改点了 https://gitee.com/mindspore/docs
reeered,mindspore.mint.nn.functional.selu在Graph Mode下使用时编译出错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.selu在Graph Mode下使用时编译出错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python import mindspore as ms import mindspore.mint.nn.functional as F_mint import numpy as np from mindspore import Tensor class SeLUNet(ms.nn.Cell):     def __init__(self):         super().__init__()     def construct(self, x):         return F_mint.selu(x) if __name__ == '__main__':     ms.set_context(mode=ms.GRAPH_MODE, device_target='Ascend')     x_np = np.random.randn(2, 3).astype(np.float32)     net = SeLUNet()         y = net(Tensor(x_np)) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 编译出错  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.194.944 [mindspore/ccsrc/transform/graph_ir/convert.cc:4323] ConvertCNode] Cannot get adapter for Default/SeLUExtop0 [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.101 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_3{[0]: ValueNode PrimFunc_SeLUExt, [1]: param_x}. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.117 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: ValueNode Return. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.420 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_4{[0]: ValueNode Return, [1]: CNode_3}. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.444 [mindspore/ccsrc/transform/graph_ir/convert.cc:1147] GenerateCheckpointGraph] Generate checkpoint graph failed, found error code 4. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.456 [mindspore/ccsrc/transform/graph_ir/convert.cc:1149] GenerateCheckpointGraph] 1 Operator(s) cannot be converted: [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.467 [mindspore/ccsrc/transform/graph_ir/convert.cc:1157] GenerateCheckpointGraph] Unsupported op type list: SeLUExt [ERROR] DEVICE(1569,ffffb4809010,python):2025022511:38:06.195.484 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_utils.cc:420] AddDFGraph] Convert df graph failed, err:4 [ERROR] DEVICE(1569,ffffb4809010,python):2025022511:38:06.195.524 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:1429] BuildDFGraph] GenConvertor failed [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.566 [mindspore/ccsrc/transform/graph_ir/graph_runner.cc:527] GetWrapper] Get graph form DfGraphManager failed! Traceback (most recent call last):   File ""/tmp/code/OpenI_Cloudbrain_Example/test/test_selu_net.py"", line 18, in      y = net(Tensor(x_np))   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 732, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1150, in compile_and_run     self.compile(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1133, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py"", line 1897, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) RuntimeError: Compile graph kernel_graph0 failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:598 CompileGraph",2025-02-25T19:40:22+08:00,"mindspore-assistant,foruda,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOUKG,我这边测试了一下这个问题，感觉是2.5.0版本的nn.Cell的construct方法走静态图的问题，但用mindspore.jit的方式走静态图的话，就能成功运行： !输入图片说明 !输入图片说明
tanxinglian,"[CT][MS][OPS][tensor.uniform][function][全量]tensor.uniform 报错RuntimeError: aclnnInplaceUniformGetWorkspaceSize call failed, please check!"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > tensor.uniform 报错RuntimeError: aclnnInplaceUniformGetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_t_uniform_bool__8d_5x8x7x3x7x4x9x7_random_forward >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b:O0 910A：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_t_uniform.py::test_t_uniform_bool__8d_5x8x7x3x7x4x9x7_random_forward  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='aclnn算子没有开发CPU')     (reason='aclnn算子没有开发GPU')     (reason='aclnn算子没有开发GE流程')     def test_t_uniform_bool__8d_5x8x7x3x7x4x9x7_random_forward():         x = Tensor(np.random.randn(5, 8, 7, 3, 7, 4, 9, 7), mstype.bool_)         from_ = False         to = False         generator = None         fact = UniformMock(             attributes={'generator': generator},             inputs=[x, from_, to]) >       fact.forward_cmp() ../test_t_uniform.py:215:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/tensor/uniform_ops.py:133: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/tensor/uniform_ops.py:69: in forward_mindspore_impl     out = net(self.x, self.from_, self.to) ../../share/utils.py:290: in __call__     _pynative_executor.sync() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =      def sync(self):         """"""         SyncStream.         Return:             None.         """""" >       self._executor.sync() E       RuntimeError: aclnnInplaceUniformGetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 2124973] 2025022313:11:35.987.946 self not implemented for DT_BOOL, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BFLOAT16,].[THREAD:2127345] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/pyboost/customize/uniform_ext.cc:73 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1578: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bab13f9b7077065374b784&workspaceId=67bab133a052d7325368d29d&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T19:33:40+08:00,"gitee,rct/cann",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBOUHX,Appearance & Root Cause CANN从8.0更换到8.1之后，tensor.uniform 报错不支持bool类型输入， 经与CANN开发对齐， 当前版本8.1.RC1已删除对bool类型支持。 CANN问题单 DTS2025010742839 Fix Description & Test Suggestion 测试建议：修改测试用例，使用最新版本的CANN包回归（8.1.rc1之后） Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：CANN升级 引入PR：https://gitee.com/ascend/canndev/pulls/61484 PR合入时间：2025年/1月/22日 问题是否偶现：否,cann因DTS2025010742839去掉支持bool类型 需适配用例
reeered,mindspore.mint.nn.functional.mish在Graph Mode下使用时编译出错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.mish在Graph Mode下使用时编译出错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python import mindspore as ms import mindspore.mint.nn.functional as F_mint import numpy as np from mindspore import Tensor class MishNet(ms.nn.Cell):     def __init__(self):         super().__init__()     def construct(self, x):         return F_mint.mish(x) if __name__ == '__main__':     ms.set_context(mode=ms.GRAPH_MODE, device_target='Ascend')     x_np = np.random.randn(2, 3).astype(np.float32)     net = MishNet()         y = net(Tensor(x_np)) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 编译出错  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.440 [mindspore/ccsrc/transform/graph_ir/convert.cc:4323] ConvertCNode] Cannot get adapter for Default/MishExtop0 [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.551 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_3{[0]: ValueNode PrimFunc_MishExt, [1]: param_x}. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.569 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: ValueNode Return. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.883 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_4{[0]: ValueNode Return, [1]: CNode_3}. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.907 [mindspore/ccsrc/transform/graph_ir/convert.cc:1147] GenerateCheckpointGraph] Generate checkpoint graph failed, found error code 4. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.940 [mindspore/ccsrc/transform/graph_ir/convert.cc:1149] GenerateCheckpointGraph] 1 Operator(s) cannot be converted: [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.957 [mindspore/ccsrc/transform/graph_ir/convert.cc:1157] GenerateCheckpointGraph] Unsupported op type list: MishExt [ERROR] DEVICE(1901,ffff84760010,python):2025022310:33:44.779.979 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_utils.cc:420] AddDFGraph] Convert df graph failed, err:4 [ERROR] DEVICE(1901,ffff84760010,python):2025022310:33:44.780.021 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:1429] BuildDFGraph] GenConvertor failed [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.780.059 [mindspore/ccsrc/transform/graph_ir/graph_runner.cc:527] GetWrapper] Get graph form DfGraphManager failed! Traceback (most recent call last):   File ""/tmp/code/OpenI_Cloudbrain_Example/test/test_mish_net.py"", line 18, in      y = net(Tensor(x_np))   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 732, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1150, in compile_and_run     self.compile(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1133, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py"", line 1897, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) RuntimeError: Compile graph kernel_graph0 failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:598 CompileGraph",2025-02-25T19:27:05+08:00,"mindspore-assistant,foruda,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOUGA,这个问题也是和selu那个一样，走nn.Cell的construct方法的静态图就报错，但走ms.jit就可以运行 !输入图片说明 !输入图片说明
郑炼鑫,【接口测试任务26】接口mindspore.mint.nn.Fold存在的若干问题(同.mint.nn.Unfold)," 1. Describe the current behavior / 问题描述  **问题1：在图模式（GRAPH_MODE）下不支持运行（该问题在评论区中更正解答）**  **问题描述**：     `mindspore.mint.nn.Fold`在`GRAPH_MODE`下无法运行，提示底层算子不支持，而其他测试（如`Unfold`）也提到类似问题，表明`mint`模块可能普遍不支持图模式。  **预期结果**：     `mindspore.mint.nn.Fold`应在`GRAPH_MODE`下正常运行，与`torch.nn.Fold`保持一致，支持Ascend硬件加速，并在图模式下提供优化性能。  **实际结果**：     在`GRAPH_MODE`且`device_target=""Ascend""`时，`mint.nn.Fold`触发运行时错误，提示底层算子`Col2ImExt`不支持图模式编译，而`torch.nn.Fold`正常运行。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn    设置图模式和Ascend设备   context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"")    输入数据 (1, 8, 4)，适配Fold参数   input_np = np.ones((1, 8, 4), dtype=np.float32)   input_ms = Tensor(input_np, dtype=ms.float32)   input_torch = torch.tensor(input_np, dtype=torch.float32)    测试mint.nn.Fold   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = fold_mint(input_ms)       print(""MindSpore mint.nn.Fold 输出:"", output_mint.shape)   except Exception as e:       print(f""MindSpore mint.nn.Fold 错误: {type(e).__name__}: {str(e)[:100]}"")    PyTorch对比   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = fold_torch(input_torch)   print(""PyTorch nn.Fold 输出:"", output_torch.shape)   ```  **代码运行结果**：   ```   MindSpore mint.nn.Fold 错误: RuntimeError: Unsupported op type: Col2ImExt in Graph mode on Ascend   PyTorch nn.Fold 输出: torch.Size([1, 2, 4, 4])   ```  **底层原因可能是什么**：     `mint.nn.Fold`依赖Ascend的`Col2ImExt`算子，而在`GRAPH_MODE`下，MindSpore的Graph Engine（GE）需要为该算子提供适配器支持。由于`Col2ImExt`在GE中未完整实现或未注册，导致编译失败。`mint`模块可能设计时优先适配`PYNATIVE_MODE`，未充分考虑图模式需求。  **针对前面提到的原因给出分析和建议**：      **分析**：       图模式是MindSpore的优化执行模式，广泛用于训练场景。`mint.nn.Fold`不支持此模式，限制了其在生产环境中的应用。相比之下，`torch.nn.Fold`基于通用计算路径（如CPU/GPU）无需类似硬件适配问题。`mint`模块的图模式不支持可能与其优化目标（轻量化、硬件加速）有关，但未明确文档化，增加了用户误用风险。      **建议**：       1. 在官方文档中明确标注`mint.nn.Fold`不支持`GRAPH_MODE`，避免用户误用。       2. 为`Col2ImExt`提供GE适配器支持，或在图模式下回退到通用实现（如基于基础算子组合），确保一致性。       3. 若不支持为有意设计，建议优化错误提示（如“Graph mode not supported for mint.nn.Fold”），提升用户体验。   **问题2：对Float64类型伪支持，延迟报错**  **问题描述**：     `mindspore.mint.nn.Fold`对`Float64`类型表现出伪支持，前向计算未报错，但访问输出时抛出错误，与`torch.nn.Fold`支持`Float64`的行为不一致。  **预期结果**：     `mint.nn.Fold`应明确支持`Float64`类型并输出正确结果，或在调用时立即抛出类型不支持的异常，与`torch.nn.Fold`的明确支持行为对齐。  **实际结果**：     `mint.nn.Fold`在构造和前向计算时未报错，但调用`asnumpy()`访问输出时抛出底层ACL异常（`aclnnIm2colBackwardGetWorkspaceSize call failed`），表明伪支持`Float64`。而`torch.nn.Fold`正常支持`Float64`。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 8, 4), dtype=np.float64)    MindSpore mint.nn.Fold   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       input_ms = Tensor(input_np, dtype=ms.float64)       output_mint = fold_mint(input_ms)       print(f""MindSpore mint.nn.Fold 输出形状: {output_mint.shape}, dtype: {output_mint.dtype}"")       print(f""output_mint: {output_mint.asnumpy()}"")   except Exception as e:       print(f""MindSpore mint.nn.Fold 错误: {type(e).__name__}: {str(e)[:50]}"")    PyTorch nn.Fold   input_torch = torch.tensor(input_np, dtype=torch.float64)   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = fold_torch(input_torch)   print(f""PyTorch nn.Fold 输出形状: {output_torch.shape}, dtype: {output_torch.dtype}"")   print(f""output_torch: {output_torch.numpy()[:2]}"")   ```  **代码运行结果**：   ```   MindSpore mint.nn.Fold 输出形状: (1, 2, 4, 4), dtype: Float64   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 输出形状: torch.Size([1, 2, 4, 4]), dtype: torch.float64   output_torch: [[[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]]]   ```  **底层原因可能是什么**：     `mint.nn.Fold`依赖Ascend的ACL接口（如`aclnnIm2colBackward`），其底层实现未适配`Float64`，但MindSpore前端未提前校验类型兼容性，导致错误延迟到执行阶段触发。Ascend硬件（如AICore）可能优化为支持`float16`和`float32`，对`Float64`支持有限。  **针对前面提到的原因给出分析和建议**：      **分析**：       `Float64`在深度学习中较少使用，但作为标准浮点类型，PyTorch提供完整支持。`mint.nn.Fold`的伪支持现象表明其类型检查不足，可能因硬件加速优先级（`float32`/`float16`）而忽略`Float64`，但未明确拒绝，导致潜在隐患。延迟报错增加了调试难度。      **建议**：       1. 在接口层添加类型检查，提前抛出`TypeError`（如“Float64 not supported”）。       2. 若有意不支持`Float64`，应在文档中明确说明，并与`torch.nn.Fold`的行为差异进行标注。       3. 若计划支持，需完善ACL层对`Float64`的适配，确保计算完整性。   **问题3：对Int/UInt/Bool类型伪支持，延迟报错**  **问题描述**：     `mindspore.mint.nn.Fold`对`Int`、`UInt`和`Bool`类型表现出伪支持，前向计算未报错，但访问输出时抛出错误，与`torch.nn.Fold`明确拒绝此类类型的行为不一致。  **预期结果**：     `mint.nn.Fold`应明确不支持`Int`、`UInt`和`Bool`类型，在调用时立即抛出类型错误，与`torch.nn.Fold`一致（后者报错“not implemented for [type]”）。  **实际结果**：     对于`Int`、`UInt`和`Bool`类型，`mint.nn.Fold`构造和前向计算成功，但访问输出时抛出底层ACL错误（`aclnnIm2colBackwardGetWorkspaceSize call failed`），表明伪支持。`torch.nn.Fold`直接报错不支持此类类型。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 8, 4))   dtypes = [(ms.int32, torch.int32), (ms.uint8, torch.uint8), (ms.bool_, torch.bool)]   for ms_dtype, torch_dtype in dtypes:       print(f""\n测试类型: {ms_dtype}, {torch_dtype}"")        MindSpore mint.nn.Fold       fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))       try:           input_ms = Tensor(input_np, dtype=ms_dtype)           output_mint = fold_mint(input_ms)           print(f""MindSpore mint.nn.Fold 形状: {output_mint.shape}, dtype: {output_mint.dtype}"")           print(output_mint.asnumpy())       except Exception as e:           print(f""MindSpore mint.nn.Fold 错误: {type(e).__name__}: {str(e)[:50]}"")        PyTorch nn.Fold       try:           input_torch = torch.tensor(input_np, dtype=torch_dtype)           fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))           output_torch = fold_torch(input_torch)       except Exception as e:           print(f""PyTorch nn.Fold 不支持 {torch_dtype}: {type(e).__name__}: {str(e)[:50]}"")   ```  **代码运行结果**：   ```   测试类型: Int32, torch.int32   MindSpore mint.nn.Fold 形状: (1, 2, 4, 4), dtype: Int32   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 不支持 torch.int32: RuntimeError: ""col2im_out_cpu"" not implemented for 'Int'   测试类型: UInt8, torch.uint8   MindSpore mint.nn.Fold 形状: (1, 2, 4, 4), dtype: UInt8   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 不支持 torch.uint8: RuntimeError: ""col2im_out_cpu"" not implemented for 'Byte'   测试类型: Bool, torch.bool   MindSpore mint.nn.Fold 形状: (1, 2, 4, 4), dtype: Bool   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 不支持 torch.bool: RuntimeError: ""col2im_out_cpu"" not implemented for 'Bool'   ```  **底层原因可能是什么**：     `mint.nn.Fold`的前端未对输入类型进行严格校验，允许非浮点类型（如`Int32`、`UInt8`、`Bool`）进入ACL计算流程，但Ascend的`aclnnIm2colBackward`不支持这些类型，导致延迟错误。`Fold`操作本质上是浮点计算，整数和布尔类型无意义。  **针对前面提到的原因给出分析和建议**：      **分析**：       `Int`、`UInt`和`Bool`类型在`Fold`操作中无实际意义，PyTorch在前端明确拒绝，`mint.nn.Fold`却未进行类型校验，导致伪支持。这种行为可能误导用户认为这些类型可用，实际执行时却失败，影响鲁棒性。      **建议**：       1. 在接口层添加类型校验，限制输入为`float32`或`float16`（如`if dtype not in [ms.float32, ms.float16]: raise TypeError`）。       2. 提高错误信息清晰度，明确提示不支持的类型（如“Int32 not supported by mint.nn.Fold”）。       3. 参考PyTorch实现，提前终止非浮点类型计算，减少调试成本。   **问题4：对非法输入维度校验滞后**  **问题描述**：     `mindspore.mint.nn.Fold`在面对非法维度输入（如0维、1维、5维张量）时，前向计算未立即报错，仅在访问输出时触发异常，校验滞后。  **预期结果**：     对于非法维度输入（`Fold`要求输入为2D或3D张量），`mint.nn.Fold`应在调用时立即抛出维度错误，与`torch.nn.Fold`一致（后者报错“Expected 2D or 3D tensor”）。  **实际结果**：     `mint.nn.Fold`在构造和前向计算时未报错，仅在访问输出（如`asnumpy()`）时抛出维度校验错误（如“For primitive[Col2ImExt], the input rank must be in [2,3]”），表明校验滞后。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   test_cases = [       (""0维"", Tensor(42.0, ms.float32), torch.tensor(42.0)),       (""1维"", Tensor(np.ones(6), ms.float32), torch.ones(6)),       (""5维"", Tensor(np.ones((1, 2, 3, 4, 5)), ms.float32), torch.ones(1, 2, 3, 4, 5)),   ]   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   for desc, ms_input, torch_input in test_cases:       print(f""\n测试场景: 输入为 {desc} 张量"")       try:           output_mint = fold_mint(ms_input)           print(f""MindSpore mint.nn.Fold 形状: {output_mint.shape}"")           output_mint.asnumpy()       except Exception as e:           print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")       try:           output_torch = fold_torch(torch_input)       except Exception as e:           print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   测试场景: 输入为 0维 张量   MindSpore 错误: ValueError: For primitive[Col2ImExt], the input rank must be in [2,3], but got 0.   PyTorch 错误: RuntimeError: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and nonzero dimensio   测试场景: 输入为 1维 张量   MindSpore 错误: ValueError: For primitive[Col2ImExt], the input rank must be in [2,3], but got 1.   PyTorch 错误: RuntimeError: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and nonzero dimensio   测试场景: 输入为 5维 张量   MindSpore 错误: ValueError: For primitive[Col2ImExt], the input rank must be in [2,3], but got 5.   PyTorch 错误: RuntimeError: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and nonzero dimensio   ```  **底层原因可能是什么**：     `mint.nn.Fold`的维度校验逻辑嵌入在底层算子`Col2ImExt`中，而非Python接口层，导致错误延迟暴露。`Fold`操作要求输入为2D（无批次）或3D（有批次）张量，MindSpore未在前端执行校验。  **针对前面提到的原因给出分析和建议**：      **分析**：       `Fold`操作的输入维度要求明确（2D/3D），PyTorch在调用时立即检查维度并报错，而`mint.nn.Fold`将校验推迟到执行阶段，降低了鲁棒性并增加了调试难度。这种滞后校验与其他`mint`接口（如`Unfold`）行为一致，可能为框架设计缺陷。      **建议**：       1. 在接口层添加维度校验（如`if input.ndim not in [2, 3]: raise ValueError`）。       2. 提供更具体的错误提示（如“Expected 2D or 3D tensor, got X dimensions”），参考PyTorch风格。       3. 优化异常处理流程，确保校验前置，提升用户体验。   **问题5：错误信息不够明确**  **问题描述**：     `mindspore.mint.nn.Fold`在面对不支持的类型（如`Int32`）或非法输入时，抛出的错误信息为底层ACL通用提示（如`aclnnIm2colBackwardGetWorkspaceSize call failed`），未指明具体原因，缺乏针对性。  **预期结果**：     对于不支持的类型或非法输入，`mint.nn.Fold`应提供具体且具指导性的错误信息（如“Type Int32 not supported”或“Input dimension mismatch”），与`torch.nn.Fold`的清晰提示（如“not implemented for 'Int'”）对齐。  **实际结果**：     `mint.nn.Fold`抛出的错误为底层ACL通用信息（如`aclnnIm2colBackwardGetWorkspaceSize call failed`），未明确指出类型或输入问题，`torch.nn.Fold`则直接提示具体原因。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 8, 4), dtype=np.int32)   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = fold_mint(Tensor(input_np, ms.int32))       output_mint.asnumpy()   except Exception as e:       print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_torch = fold_torch(torch.tensor(input_np, dtype=torch.int32))   except Exception as e:       print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   MindSpore 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, please check!   PyTorch 错误: RuntimeError: ""col2im_out_cpu"" not implemented for 'Int'   ```  **底层原因可能是什么**：     MindSpore的错误处理链未将ACL层的具体错误码映射到用户友好的提示，直接暴露底层失败信息。`aclnnIm2colBackward`可能因类型不支持而失败，但未在Python层解析具体原因。  **针对前面提到的原因给出分析和建议**：      **分析**：       PyTorch的错误信息明确指向类型问题（“not implemented for 'Int'”），便于用户定位，而`mint.nn.Fold`的通用提示（“call failed”）缺乏上下文，用户难以判断是类型、维度还是其他问题导致失败。这种模糊性在`mint`模块中反复出现，影响开发效率。      **建议**：       1. 在Python层捕获ACL错误并解析（如`if ""aclnnIm2colBackward"" in str(e): raise TypeError(""Unsupported dtype"")`）。       2. 优化错误信息，提供类型或参数的具体上下文（如“Int32 not supported by mint.nn.Fold”）。       3. 参考PyTorch的异常处理机制，改进错误提示的针对性和指导性。   2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```   3. Related testcase / 关联用例  **Testcase Name / 用例名**:      null  **Excute Mode / 执行模式**:      Excute Mode: PyNative     4. Steps to reproduce the issue / 重现步骤 1. 配置MindSpore环境：    ```bash    pip install mindspore==2.4.10    ``` 2. 运行测试脚本：    ```bash    python test_mint_nn_Fold.py    ``` 3. 检查每种问题的输出日志，验证问题复现。   5. Describe the expected behavior / 预期结果  **【预期结果】**：     1. `mint.nn.Fold`在`GRAPH_MODE`下正常运行，支持Ascend硬件加速。     2. 明确支持或拒绝`Float64`，并在调用时抛出异常。     3. 对`Int`/`UInt`/`Bool`类型提前报错，不伪支持。     4. 对非法维度输入立即抛出维度错误。     5. 提供具体、清晰的错误信息，指向问题根源。   6. Related log / screenshot / 日志 / 截图  **报错关键日志截图**：    **问题1**： !输入图片说明  **问题2**： !输入图片说明  **问题3**： !输入图片说明  **问题4**： !输入图片说明  **问题5**： !输入图片说明   7. Special notes for this issue / 备注  **【定位人】**：ZhFuGui    **【优先级建议】**：      问题1（图模式不支持）：P1（影响训练场景）      问题2（Float64伪支持）：P2（类型支持一致性）      问题3（Int/UInt/Bool伪支持）：P2（潜在隐患）      问题4（维度校验滞后）：P1（鲁棒性问题）      问题5（错误信息不明确）：P3（开发体验）  ",2025-02-25T19:25:58+08:00,mindspore-assistant,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOUG3
郑炼鑫,【接口测试任务26】接口mindspore.mint.nn.Unfold存在的若干问题," 1. Describe the current behavior / 问题描述  **问题1：在图模式（GRAPH_MODE）下不支持运行（该问题在评论区中更正解答）**  **预期结果**：     `mindspore.mint.nn.Unfold`应在`GRAPH_MODE`下正常运行，与`mindspore.nn.Unfold`和`torch.nn.Unfold`保持一致，支持Ascend硬件加速。  **实际结果**：     在`GRAPH_MODE`且`device_target=""Ascend""`时，`mint.nn.Unfold`触发运行时错误，提示底层算子`Im2ColExt`不支持图模式编译，而`nn.Unfold`和PyTorch版本正常运行。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn    设置图模式和Ascend设备   context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"")    输入数据   input_np = np.ones((1, 2, 6, 6), dtype=np.float32)   input_ms = Tensor(input_np, dtype=ms.float32)    测试mint.nn.Unfold   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = unfold_mint(input_ms)       print(""MindSpore mint.nn.Unfold 输出:"", output_mint.shape)   except Exception as e:       print(f""MindSpore mint.nn.Unfold 错误: {type(e).__name__}: {str(e)[:100]}"")    对比nn.Unfold   unfold_ms = ms.nn.Unfold(ksizes=[1, 2, 2, 1], strides=[1, 2, 2, 1], rates=[1, 1, 1, 1], padding=""valid"")   output_ms = unfold_ms(input_ms)   print(""MindSpore nn.Unfold 输出:"", output_ms.shape)    PyTorch对比   input_torch = torch.tensor(input_np, dtype=torch.float32)   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = unfold_torch(input_torch)   print(""PyTorch nn.Unfold 输出:"", output_torch.shape)   ```  **代码运行结果**：   ```   MindSpore mint.nn.Unfold 错误: RuntimeError: Unsupported op type: Im2ColExt in Graph mode on Ascend   MindSpore nn.Unfold 输出: (1, 8, 9)   PyTorch nn.Unfold 输出: torch.Size([1, 8, 9])   ```  **底层原因可能是什么**：     `mint.nn.Unfold`依赖Ascend的`Im2ColExt`算子，而在`GRAPH_MODE`下，MindSpore的Graph Engine（GE）需要为该算子提供适配器支持。由于`Im2ColExt`在GE中未完整实现或未注册，导致编译失败。  **分析和建议**：      **分析**：此问题可能源于`mint`模块的优化设计仅针对`PYNATIVE_MODE`，未充分适配图模式下的Ascend硬件加速路径。相比之下，`nn.Unfold`使用更通用的算子实现（如基础的`ExtractImagePatches`），绕过了此限制。      **建议**：       1. 在文档中明确标注`mint.nn.Unfold`不支持`GRAPH_MODE`，避免用户误用。       2. 为`Im2ColExt`提供GE适配器支持，或在图模式下回退到通用实现，确保一致性。       3. 向开发者确认是否为有意设计，若是，应优化用户提示信息（如“Graph mode not supported”）。   **问题2：对Float64类型伪支持，延迟报错**  **预期结果**：     `mint.nn.Unfold`应明确支持`Float64`类型并输出正确结果，或在调用时立即抛出类型不支持的异常，与`torch.nn.Unfold`一致。  **实际结果**：     `mint.nn.Unfold`在构造和前向计算时未报错，但访问输出（如`asnumpy()`）时抛出底层ACL异常，表明伪支持`Float64`。而`nn.Unfold`不支持`Float64`，`torch.nn.Unfold`则正常支持。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.nn as nn   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 2, 6, 6), dtype=np.float64)    MindSpore nn.Unfold   unfold_ms = nn.Unfold(ksizes=[1, 2, 2, 1], strides=[1, 2, 2, 1], rates=[1, 1, 1, 1], padding=""valid"")   try:       output_ms = unfold_ms(Tensor(input_np, dtype=ms.float64))       print(f""MindSpore nn.Unfold 输出: {output_ms.shape}"")   except Exception as e:       print(f""MindSpore nn.Unfold 错误: {type(e).__name__}: {str(e)[:50]}"")    MindSpore mint.nn.Unfold   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       input_ms = Tensor(input_np, dtype=ms.float64)       output_mint = unfold_mint(input_ms)       print(f""MindSpore mint.nn.Unfold 输出形状: {output_mint.shape}, dtype: {output_mint.dtype}"")       print(f""output_mint: {output_mint.asnumpy()}"")   except Exception as e:       print(f""MindSpore mint.nn.Unfold 错误: {type(e).__name__}: {str(e)[:50]}"")    PyTorch nn.Unfold   input_torch = torch.tensor(input_np, dtype=torch.float64)   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = unfold_torch(input_torch)   print(f""PyTorch nn.Unfold 输出形状: {output_torch.shape}, dtype: {output_torch.dtype}"")   ```  **代码运行结果**：   ```   MindSpore nn.Unfold 错误: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 输出形状: (1, 8, 9), dtype: Float64   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 输出形状: torch.Size([1, 8, 9]), dtype: torch.float64   ```  **底层原因可能是什么**：     `mint.nn.Unfold`依赖Ascend的ACL接口（如`aclnnIm2col`），其底层实现未适配`Float64`，但MindSpore前端未提前校验类型兼容性，导致错误延迟到执行阶段触发。  **分析和建议**：      **分析**：`Float64`在深度学习中较少使用，Ascend硬件（如AICore）可能优化为支持`float16`和`float32`，未完整实现`Float64`的ACL支持。`torch.nn.Unfold`基于通用路径（如CPU/GPU）支持`Float64`，而`mint`模块未明确拒绝此类型，留下隐患。      **建议**：       1. 在接口层添加类型检查，提前抛出`TypeError`（如“Float64 not supported”）。       2. 若有意不支持`Float64`，应在文档中明确说明。       3. 若计划支持，需完善ACL层对`Float64`的适配。   **问题3：对Int/UInt/Bool类型伪支持，延迟报错**  **预期结果**：     `mint.nn.Unfold`应明确不支持`Int`、`UInt`和`Bool`类型，在调用时立即抛出类型错误，与`torch.nn.Unfold`一致（后者明确报错“not implemented for [type]”）。  **实际结果**：     对于`Int`、`UInt`和`Bool`类型，`mint.nn.Unfold`构造和前向计算成功，但访问输出时抛出底层ACL错误，表明伪支持。`nn.Unfold`直接报错，`torch.nn.Unfold`也不支持此类类型。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.nn as nn   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 2, 6, 6))   dtypes = [(ms.int32, torch.int32), (ms.uint8, torch.uint8), (ms.bool_, torch.bool)]   for ms_dtype, torch_dtype in dtypes:       print(f""\n测试类型: {ms_dtype}, {torch_dtype}"")        MindSpore nn.Unfold       unfold_ms = nn.Unfold(ksizes=[1, 2, 2, 1], strides=[1, 2, 2, 1], rates=[1, 1, 1, 1], padding=""valid"")       try:           output_ms = unfold_ms(Tensor(input_np, dtype=ms_dtype))       except Exception as e:           print(f""MindSpore nn.Unfold 不支持 {ms_dtype}: {type(e).__name__}: {str(e)[:50]}"")        MindSpore mint.nn.Unfold       unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))       try:           input_ms = Tensor(input_np, dtype=ms_dtype)           output_mint = unfold_mint(input_ms)           print(f""MindSpore mint.nn.Unfold 形状: {output_mint.shape}, dtype: {output_mint.dtype}"")           print(output_mint.asnumpy())       except Exception as e:           print(f""MindSpore mint.nn.Unfold 错误: {type(e).__name__}: {str(e)[:50]}"")        PyTorch nn.Unfold       try:           input_torch = torch.tensor(input_np, dtype=torch_dtype)           unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))           output_torch = unfold_torch(input_torch)       except Exception as e:           print(f""PyTorch nn.Unfold 不支持 {torch_dtype}: {type(e).__name__}: {str(e)[:50]}"")   ```  **代码运行结果**：   ```   测试类型: Int32, torch.int32   MindSpore nn.Unfold 不支持 Int32: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 形状: (1, 8, 9), dtype: Int32   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 不支持 torch.int32: RuntimeError: ""im2col_out_cpu"" not implemented for 'Int'   测试类型: UInt8, torch.uint8   MindSpore nn.Unfold 不支持 UInt8: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 形状: (1, 8, 9), dtype: UInt8   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 不支持 torch.uint8: RuntimeError: ""im2col_out_cpu"" not implemented for 'Byte'   测试类型: Bool, torch.bool   MindSpore nn.Unfold 不支持 Bool: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 形状: (1, 8, 9), dtype: Bool   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 不支持 torch.bool: RuntimeError: ""im2col_out_cpu"" not implemented for 'Bool'   ```  **底层原因可能是什么**：     `mint.nn.Unfold`的前端未对输入类型进行严格校验，允许非浮点类型（如`Int32`、`UInt8`、`Bool`）进入ACL计算流程，但Ascend的`aclnnIm2col`不支持这些类型，导致延迟错误。  **分析和建议**：      **分析**：此类类型在卷积操作（如`Unfold`）中无意义，PyTorch在前端明确拒绝，`nn.Unfold`也有类型检查，而`mint`模块缺乏类似机制，导致伪支持现象。      **建议**：       1. 在接口层添加类型校验，限制输入为`float32`或`float16`（如`if dtype not in [ms.float32, ms.float16]: raise TypeError`）。       2. 提高错误信息清晰度，明确提示不支持的类型（如“Int32 not supported”）。       3. 参考PyTorch实现，提前终止非浮点类型计算。   **问题4：非法输入维度校验滞后**  **预期结果**：     对于非法维度输入（如0维、1维、2维、5维张量），`mint.nn.Unfold`应在调用时立即抛出维度错误，与`torch.nn.Unfold`一致（后者明确报错“Dimension out of range”或“Expected 3D/4D tensor”）。  **实际结果**：     `mint.nn.Unfold`在构造和前向计算时未报错，仅在访问输出时抛出维度校验错误，表明校验滞后。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   test_cases = [       (""0维"", Tensor(42.0, ms.float32), torch.tensor(42.0)),       (""1维"", Tensor(np.ones(6), ms.float32), torch.ones(6)),       (""2维"", Tensor(np.ones((2, 6)), ms.float32), torch.ones(2, 6)),       (""5维"", Tensor(np.ones((1, 2, 3, 4, 5)), ms.float32), torch.ones(1, 2, 3, 4, 5)),   ]   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   for desc, ms_input, torch_input in test_cases:       print(f""\n测试场景: 输入为 {desc} 张量"")       try:           output_mint = unfold_mint(ms_input)           print(f""MindSpore mint.nn.Unfold 形状: {output_mint.shape}"")           output_mint.asnumpy()       except Exception as e:           print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")       try:           output_torch = unfold_torch(torch_input)       except Exception as e:           print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   测试场景: 输入为 0维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 0   PyTorch 错误: IndexError: Dimension specified as 1 but tensor has no dimensions   测试场景: 输入为 1维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 1   PyTorch 错误: IndexError: Dimension out of range (expected to be in range of [1, 0], but got 1)   测试场景: 输入为 2维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 2   PyTorch 错误: IndexError: Dimension out of range (expected to be in range of [2, 1], but got 2)   测试场景: 输入为 5维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 5   PyTorch 错误: RuntimeError: Expected 3D or 4D (batch mode) tensor with possibly 0 batch size and other   ```  **底层原因可能是什么**：     `mint.nn.Unfold`的维度校验逻辑嵌入在底层算子`Im2ColExt`中，而非Python接口层，导致错误延迟暴露。  **分析和建议**：      **分析**：`Unfold`操作要求输入为4D张量（NCHW格式），PyTorch在调用时立即检查维度，而`mint`模块将校验推迟到执行阶段，增加了调试难度。      **建议**：       1. 在接口层添加维度校验（如`if input.ndim != 4: raise ValueError`）。       2. 模仿PyTorch的错误提示，提供更具体的维度要求说明（如“Expected 4D tensor, got X”）。       3. 优化异常处理流程，确保校验前置。   **问题5：输入维度过小时延迟报错**  **预期结果**：     当输入空间维度小于`kernel_size`（如`(2, 2)`输入搭配`(3, 3)`核），`mint.nn.Unfold`应立即抛出错误，提示输出维度无效。  **实际结果**：     `mint.nn.Unfold`未在调用时报错，仅在访问输出时抛出错误，提示计算出的滑动窗口数组形状为`(0, 0)`。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 1, 2, 2), dtype=np.float32)   unfold_mint = mint_nn.Unfold(kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(0, 0))   try:       output_mint = unfold_mint(Tensor(input_np, ms.float32))       print(f""MindSpore mint.nn.Unfold 形状: {output_mint.shape}"")       output_mint.asnumpy()   except Exception as e:       print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")   unfold_torch = tnn.Unfold(kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(0, 0))   try:       output_torch = unfold_torch(torch.tensor(input_np))   except Exception as e:       print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   MindSpore 错误: ValueError: For Im2ColExt, given input with spatial size (2, 2), kernel_size=(3,   PyTorch 错误: RuntimeError: Given input with spatial size (2, 2), kernel_size=(3, 3), dilation=(1,   ```  **底层原因可能是什么**：     `Im2ColExt`算子在计算输出形状时未提前校验输入与核大小的兼容性，仅在执行时发现输出维度非法。  **分析和建议**：      **分析**：PyTorch在调用时即计算并验证输出形状，`mint`模块则延迟到执行阶段，降低了鲁棒性。      **建议**：       1. 在接口层计算预期输出形状并验证（如`if out_h <= 0 or out_w <= 0: raise ValueError`）。       2. 提供更清晰的错误提示（如“Input size (H,W) too small for kernel_size”）。   **问题6：错误信息不够明确**  **预期结果**：     对于不支持的类型或非法输入，`mint.nn.Unfold`应提供具体且具指导性的错误信息（如“Type Int32 not supported”）。  **实际结果**：     抛出的错误信息为底层ACL通用提示（如`aclnnIm2colGetWorkspaceSize call failed`），未指明具体原因，缺乏针对性。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 1, 6, 6), dtype=np.int32)   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = unfold_mint(Tensor(input_np, ms.int32))       output_mint.asnumpy()   except Exception as e:       print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_torch = unfold_torch(torch.tensor(input_np, dtype=torch.int32))   except Exception as e:       print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   MindSpore 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed, please check!   PyTorch 错误: RuntimeError: ""im2col_out_cpu"" not implemented for 'Int'   ```  **底层原因可能是什么**：     MindSpore的错误处理链未将ACL层的具体错误码映射到用户友好的提示，直接暴露底层失败信息。  **分析和建议**：      **分析**：PyTorch的错误信息明确指出类型不支持，`mint`模块则仅提示调用失败，用户难以定位问题根源。      **建议**：       1. 在Python层捕获ACL错误并解析（如`if ""aclnnIm2col"" in str(e): raise TypeError(""Unsupported dtype"")`）。       2. 优化错误信息，提供类型或参数的具体上下文。       3. 参考PyTorch的异常处理机制，提升开发体验。   2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```   3. Related testcase / 关联用例  **Testcase Name / 用例名**:      null  **Excute Mode / 执行模式**:      Excute Mode: PyNative     4. Steps to reproduce the issue / 重现步骤 1. 配置MindSpore环境：    ```bash    pip install mindspore==2.4.10    ``` 2. 运行测试脚本：    ```bash    python test_nn_Unfold.py    ``` 3. 检查每种问题的输出日志，验证问题复现。   5. Describe the expected behavior / 预期结果  **【预期结果】**：     1. `mint.nn.Unfold`在`GRAPH_MODE`下正常运行，支持Ascend硬件加速。     2. 明确支持或拒绝`Float64`，并在调用时抛出异常。     3. 对`Int`/`UInt`/`Bool`类型提前报错，不伪支持。     4. 对非法维度输入立即抛出维度错误。     5. 输入维度过小时提前校验并报错。     6. 提供具体、清晰的错误信息，指向问题根源。   6. Related log / screenshot / 日志 / 截图  **问题1**：  !image  **问题2**：  !image  **问题3**：  !image  **问题4**：  !image  **问题5**：  !image  **问题6**：  !输入图片说明   7. Special notes for this issue / 备注  **【优先级建议】**：      问题1（图模式不支持）：P1（影响训练场景）      问题2（Float64伪支持）：P2（类型支持一致性）      问题3（Int/UInt/Bool伪支持）：P2（潜在隐患）      问题4（维度校验滞后）：P1（鲁棒性问题）      问题5（维度过小延迟报错）：P1（鲁棒性问题）      问题6（错误信息不明确）：P3（开发体验）  ",2025-02-25T18:30:11+08:00,mindspore-assistant,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOU14
郑炼鑫,【接口测试任务26】接口mindspore.mint.nn.L1Loss存在的若干问题," 1.Describe the current behavior / 问题描述   **问题1：GRAPH_MODE下Ascend平台不支持（已在评论区更正）**  **预期结果**：     在`GRAPH_MODE` + `device_target=""Ascend""`配置下，`mindspore.mint.nn.L1Loss`应与`nn.L1Loss`和PyTorch实现一致，支持正常训练和推理。  **实际结果**：     触发底层算子适配错误：`Unsupported op type: L1LossExt`，导致计算图编译失败。  **复现代码**： ```python import mindspore as ms from mindspore import nn, Tensor, context import mindspore.mint.nn as mint_nn context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"")  构造输入数据 pred = Tensor([1.0, 2.0, 3.0], ms.float32) target = Tensor([1.1, 2.0, 2.9], ms.float32) try:     loss_fn = mint_nn.L1Loss()     loss = loss_fn(pred, target)     print(""计算结果："", loss.asnumpy()) except Exception as e:     print(""GRAPH_MODE下错误信息：\n"", str(e)) ```  **代码运行结果**： ``` [ERROR] GE_ADPT(xxxxx): ConvertCNode] Cannot get adapter for Default/L1LossExtop0 GRAPH_MODE下错误信息：  RuntimeError: MindSpore error: The return value of the function[...] is empty... ```  **底层根因分析**：     `mint.nn.L1Loss`底层依赖的`L1LossExt`算子未在Ascend平台的Graph Engine中注册适配器，导致图模式编译失败。  **改进建议**：     1. 在CANN层为`L1LossExt`算子添加Ascend适配器     2. 或在接口层自动回退到基础算子实现（如`Abs`+`ReduceMean`）   **问题2：不支持float64精度且无明确提示**  **预期结果**：     输入`float64`类型数据时，应支持计算或抛出明确的类型不支持异常。  **实际结果**：     静默将计算精度降级为`float32`，导致输出精度与PyTorch存在差异。  **复现代码**： ```python import numpy as np import torch import mindspore as ms  构造相同输入 np_data = np.array([1.0, 2.0, 3.0], dtype=np.float64) pt_input = torch.tensor(np_data, dtype=torch.float64) ms_input = Tensor(np_data, ms.float64)  PyTorch计算 pt_loss = torch.nn.L1Loss()(pt_input, pt_input) print(f""PyTorch输出（float64）：{pt_loss.item():.17f}"")   0.00000000000000000  MindSpore计算 ms_loss = mint_nn.L1Loss()(ms_input, ms_input) print(f""MindSpore输出（float64）：{ms_loss.asnumpy()[()]:.17f}"")   0.00000000000000024 ```  **代码运行结果**： ``` PyTorch输出（float64）：0.3333333333333333 MindSpore输出（float64）：0.3333333432674408 ```  **底层根因分析**：     Ascend 910B硬件对`float64`支持不完善，MindSpore在算子层自动降级到`float32`计算。  **改进建议**：     1. 在文档中明确标注`mint.nn.L1Loss`的精度限制     2. 在接口层添加类型检查警告   **问题3：布尔类型输入报错信息不明确**  **预期结果**：     输入布尔类型时，应提示""不支持布尔类型张量计算L1损失""。  **实际结果**：     抛出模糊的ACL底层错误：`aclnnL1LossGetWorkspaceSize call failed`。  **复现代码**： ```python pred_bool = Tensor([True, False], ms.bool_) target_bool = Tensor([False, True], ms.bool_) try:     loss = mint_nn.L1Loss()(pred_bool, target_bool) except RuntimeError as e:     print(""MindSpore错误信息："", str(e))  PyTorch对比测试 try:     torch_loss = torch.nn.L1Loss()(torch.tensor([True, False]),                                   torch.tensor([False, True])) except RuntimeError as e:     print(""\nPyTorch错误信息："", str(e)) ```  **代码运行结果**： ``` MindSpore错误信息： aclnnL1LossGetWorkspaceSize call failed, please check!... PyTorch错误信息： Subtraction, the `` operator, with two bool tensors is not supported... ```  **底层根因分析**：     `mint.nn.L1Loss`未在Python层拦截非法类型，直接传递布尔张量给底层ACL算子。  **改进建议**：     在接口层添加类型校验逻辑： ```python if input.dtype == mstype.Bool_ or target.dtype == mstype.Bool_:     raise TypeError(""Bool inputs are not supported for L1Loss"") ```   **问题4：整数类型伪支持**  **预期结果**：     输入整数类型（如`int8`）时应明确报错或输出有意义结果。  **实际结果**：     计算正常完成但输出全零，未触发任何异常。  **复现代码**： ```python pred_int = Tensor([1, 2], ms.int8) target_int = Tensor([3, 4], ms.int8)  MindSpore计算 loss = mint_nn.L1Loss()(pred_int, target_int) print(""MindSpore int8输出："", loss.asnumpy())   输出0  PyTorch对比 try:     torch.nn.L1Loss()(torch.tensor([1,2], dtype=torch.int8),                      torch.tensor([3,4], dtype=torch.int8)) except Exception as e:     print(""\nPyTorch异常："", str(e)) ```  **代码运行结果**： ``` MindSpore int8输出： [0,0] 全零tensor PyTorch异常： expected scalar type Float but found Char ```  **底层根因分析**：     `mint.nn.L1Loss`未正确处理整数类型输入，未实现类型转换或校验逻辑。  **改进建议**：     1. 在接口层强制要求浮点类型输入     2. 或自动执行类型转换并添加警告   2.Environment / 环境信息  **Hardware Environment / 硬件环境** ",2025-02-25T18:09:21+08:00,"gitee,mindspore-assistant,foruda,foruda",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBOTUU,关于你这边提到的第一个问题静态图下不支持，其实这里是另外一个问题，而并不是静态图下不支持，实际静态图下是支持的，如果执行的代码不在nn.Cell的construct方法中，需要用jit标签包起来，才会走静态图，否则依旧走的是动态图，可以尝试一下，打上jit标签是可以运行的；这边的错误应该是使用了上下文的全局静态图配置，但单独调用某些api走动态图的动静结合的模式下出现了错误： !输入图片说明 !输入图片说明,是的，用jit标签标志了之后正常输出结果，感谢指正！
reeered,"mindspore.mint.nn.functional.selu不支持Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.selu不支持Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.selu(x_torch)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.selu(x_ms).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Float64, BFloat16",2025-02-25T18:00:56+08:00,"mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTRD,目前，在2.5版本中，mindspore.mint.nn.functional.selu已支持BFloat16，尚未支持Float64， 在910B环境下MindSpore与torchnpu对BFloat16，Float16，Float32的结果一致， 后续将会增加对CPU和Float64的支持。 !输入图片说明
reeered,"mindspore.mint.nn.functional.relu不支持Int16, Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.relu不支持Int16, Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.relu(x_torch)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.relu(x_ms).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Int16, Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Int16, Float64, BFloat16",2025-02-25T18:00:02+08:00,"mindspore-assistant,www",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTQZ,mindspore.mint.nn.functional.relu底层调用了aclnnReLU，而aclnnRelu在910A上不支持int16、float64和bfloat16的输入，可以参考昇腾文档：https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/81RC1alpha001/apiref/aolapi/context/aclnnRelu&aclnnInplaceRelu.md
reeered,"mindspore.mint.nn.functional.prelu 不支持Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.prelu 不支持Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         weight_np = np.array([0.25], dtype=np.float32)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.prelu(x_torch, torch.tensor(weight_np, dtype=torch_dtype))         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.prelu(x_ms, Tensor(weight_np)).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Float64, BFloat16",2025-02-25T17:57:44+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTPY,"prelu的情况感觉和Mish算子一样，cann层首先没有支持float64,框架层也不好接入；然后反向没有支持bfloat16,光前向接入bfloat16的话，训练就直接报错了 !输入图片说明"
reeered,"mindspore.mint.nn.functional.mish不支持Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.mish不支持Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.mish(x_torch)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.mish(x_ms).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Float64, BFloat16",2025-02-25T17:55:51+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTPC,"根据atlas训练系列产品（即910A）的cann算子文档，Mish算子确实不支持float1=64,mindspore框架层也就没法接入了；Mish算子前向虽然支持BFloat16，但反向的MishGrad cann算子也不支持BFloat16，我猜测可能框架层考虑到，如果前向接入了BFloat16，就会导致推理前向能走通，但涉及到训练反向就会报错了，所以也不太好只接入前向，估计要等cann算子前向和反向都完善后才方便接入 !输入图片说明"
reeered,mindspore.mint.nn.functional.log_softmax 不支持BFloat16类型输入," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.log_softmax 不支持BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.log_softmax(x_torch, dim=1)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.log_softmax(x_ms, dim=1).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持BFloat16",2025-02-25T17:51:32+08:00,"mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTLX,目前，mindspore 2.5.0版本在Ascend环境中，mindspore.mint.nn.functional.log_softmax已支持BFloat16类型输入， 后续将会增加对CPU的支持 !输入图片说明
tanxinglian,[CT][MS][OPS][ops.ctc_loss][function][全量]ops.ctc_loss 910A（arm机器） pynative模式出现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.ctc_loss 910A（arm机器） pynative模式出现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_ctc_loss_float32_log_probs_2x1x3_array >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_f_ctc_loss.py::test_f_ctc_loss_float32_log_probs_2x1x3_array  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```        def test_f_ctc_loss_float32_log_probs_2x1x3_array():         log_probs = Tensor(np.array([[[0.3, 0.6, 0.6]], [[0.9, 0.4, 0.2]]]).astype(np.float32))         targets = Tensor(np.array([[0, 1]]), mstype.int32)         input_x_lengths = Tensor(np.array([2]), mstype.int32)         target_lengths = Tensor(np.array([1]), mstype.int32)         blank = 0         reduction = 'mean'         zero_infinity = True         fact = CtcLossMock(             attributes={'blank': blank, 'reduction': reduction, 'zero_infinity': zero_infinity},             inputs=[log_probs, targets, input_x_lengths, target_lengths])         fact.forward_cmp() >       fact.grad_cmp() ../test_f_ctc_loss.py:105:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/ctc_loss_ops.py:172: in grad_cmp     allclose_nparray(grad_pytorch[0], grad_mindspore[0], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0.26783472, 1.3949243 , 1.3949243 ]], dtype=float32) data_me = array([[1.0333853, 1.3949243, 1.3949243]], dtype=float32) rtol = 0.0001, atol = 0.0001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T17:23:30+08:00,"foruda,foruda,rct/cann,mindspore-repo,dts-szv",closed,0,9,https://gitee.com/mindspore/mindspore/issues/IBOT3R,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,test_n_ctcloss_length_tuple910A偶现精度问题 开发确认为同一个问题 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2347502646397501593&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250302%2011:00:34&isMergedTask=false&nodeDate=20250302&year=20242025&TestNow=true&testcaseid=67bade576c3f49211ec43260&workspaceId=67c412454503c84f0a2771d1,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 解决方案 (Fix Solution) 2. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,Appearance & Root Cause ctc_loss反向精度问题 根因： CANN引入 CANN问题单 https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025021136835 Fix Solution 1.取最新CANN包 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN（0307）包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis CANN引入,"test_f_ctc_loss_float32_log_probs_2x1x3_array已验证无问题 【回归版本号】：__commit_id__ = '[sha1]:e460364b,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明",test_n_ctcloss_length_tuple 910A（arm机器） pynative模式还有精度问题 走回开发继续定位 !输入图片说明,确认为CANN引入，CANN问题单：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025032416172,Appearance & Root Cause ctc_loss反向精度问题 根因： CANN引入 CANN问题单 https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025021136835 Fix Solution 1.取最新CANN包 http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250411_atlas/ Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN（0411）包回归 Selftest Report & DT Review !输入图片说明 !输入图片说明 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis CANN引入,cann包：http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250414_atlas/ !输入图片说明 !输入图片说明
tanxinglian,[CT][MS][OPS][mint.nn.functional.avg_pool2d][function][全量]mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题，其他910A机器未出现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_n_f_avg_pool2d_float32_2d_discontinuous_tensor >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_n_f_avg_pool2d.py::test_mint_n_f_avg_pool2d_float32_2d_discontinuous_tensor  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='not support')     (reason='not support')     ()     def test_mint_n_f_avg_pool2d_float32_2d_discontinuous_tensor():         input_x = get_discontinuous_tensor(shape=(5, 5, 28, 38), dim=(2, 1, 3, 0))         kernel_size = 2         stride = (2, 4)         padding = 0         ceil_mode = False         count_include_pad = False         divisor_override = 50         fact = AvgPool2dMock(             attributes={'kernel_size': kernel_size, 'stride': stride, 'padding': padding,                         'ceil_mode': ceil_mode, 'count_include_pad': count_include_pad,                         'divisor_override': divisor_override},             inputs=[input_x]) >       fact.forward_cmp() ../test_mint_n_f_avg_pool2d.py:1110:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/avg_pool2d_mint.py:155: in forward_cmp     allclose_nparray(out_cmp, out_mindspore, 0.001, 0.001) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[0.0317289 ],          [0.04237107],          [0.05222388],          ...,          [0.0534819 ],          [0....     [0.0433775 ],          ...,          [0.03954761],          [0.04958919],          [0.05123113]]]], dtype=float32) data_me = array([[[[0.03173828],          [0.        ],          [0.        ],          ...,          [0.05349731],          [0....     [0.        ],          ...,          [0.03955078],          [0.        ],          [0.        ]]]], dtype=float32) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T17:17:18+08:00,"gitee,foruda,rct/cann,mindspore-repo,mindspore-pkg",closed,0,13,https://gitee.com/mindspore/mindspore/issues/IBOSYW,根据责任人转单 !输入图片说明,算子责任人更新，走给雷可鹏 00842044,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,算子功能不支持数据类型，未修改到CPU后端，测试用例有问题,问题单分析有问题，非不支持类型，与CPU后端无关，走回开发继续分析,Appearance & Root Cause 问题：mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题 根因：pynative场景下数据有丢失 Fix Solution 使用最新版的MindSpore的master分支进行测试 Fix Description & Test Suggestion 测试建议：该问题可以通过特性用例防护，增加****场景。 Selftest Report & DT Review 目前前后端耗时在12分钟以内。 是否需要补充 ST/UT：否  原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx PR合入时间：年/月/日 问题是否偶现：是/否,4.3号包http://mindsporepkg.csi.rnd.huawei.com/OpenSource/Daily/Version/202504/0403/mindspore/master_20250403010018_119b7ec4bdd7922b51cc1615345eafd9a14a99e6/unified/ 验证失败 走回开发 !输入图片说明,4月2日cann包条件下该用例pass,DTS2025041127810,910PremiumA 硬件，非连续输入场景存在精度问题： DTS2025041127810,DTS2025041203827,Appearance & Root Cause 问题：mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题 根因：avg_pool2d底层调用的conv2d算子，conv2d的tiling写的有问题，修改已合入 Fix Solution 取CANN 8.1.RC1.B102可解决 Fix Description & Test Suggestion 测试建议：已解决 Selftest Report & DT Review 目前前后端耗时在12分钟以内。 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：CANN引入 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx PR合入时间：年/月/日 问题是否偶现：是/否,cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250414_atlas/ 已验证通过 !输入图片说明
郑炼鑫,【接口测试任务26】接口mindspore.mint.searchsorted存在的若干问题," 1.Describe the current behavior / 问题描述  **问题1：side参数校验缺失**  **预期结果**：     当传入非法`side`参数（如`'invalid'`、`'left '`（含空格）、`'middle'`）时，接口应触发`ValueError`并提示参数范围限制。  **实际结果**：     MindSpore未进行参数校验，静默采用`side='left'`模式计算，未抛出任何异常。  **复现代码**：   ```python   import mindspore as ms   from mindspore import Tensor   import mindspore.mint as mint    测试非法side参数   test_cases = [       (""invalid_side"", ""invalid""),       (""space_in_side"", ""left ""),       (""numeric_side"", 123),       (""unknown_value"", ""middle"")   ]   for case_name, side_val in test_cases:       try:           sorted_seq = Tensor([1, 3, 5], ms.int32)           values = Tensor([2], ms.int32)           result = mint.searchsorted(sorted_seq, values, side=side_val)           print(f""Case '{case_name}': 无报错，输出={result.asnumpy()}"")       except Exception as e:           print(f""Case '{case_name}': 捕获异常  {type(e).__name__}: {str(e)[:60]}"")    PyTorch对比测试   import torch   try:       torch_result = torch.searchsorted(torch.tensor([1,3,5]),                                        torch.tensor([2]),                                        side=""middle"")   except Exception as e:       print(f""\nPyTorch对比异常：{type(e).__name__}: {str(e)}"")   ```  **代码运行结果**：   ```   Case 'invalid_side': 无报错，输出=[1]   Case 'space_in_side': 无报错，输出=[1]   Case 'numeric_side': 无报错，输出=[1]   Case 'unknown_value': 无报错，输出=[1]   PyTorch对比异常：RuntimeError: torch.searchsorted(): side can only be 'left' or 'right' but got middle   ```  **底层根因**：     `mindspore/mint/ops/searchsorted.py`中未对`side`参数进行有效性校验，直接传递给底层算子。  **改进建议**：     在Python接口层添加参数校验逻辑：   ```python     def searchsorted(*, side=None):          新增参数校验         if side not in ('left', 'right'):             raise ValueError(f""参数 `side` 必须是 'left' 或 'right'，但输入的是 '{side}'"")         if not is_sorted(sorted_array):             raise ValueError(""输入数组必须已排序"")         indices = []         for value in values:             low, high = 0, len(sorted_array)             while low  INT32_MAX) {       MS_LOG(ERROR) << ""Input size exceeds INT32_MAX when out_int32=True"";       return KERNEL_STATUS_PARAM_INVALID;   }   ```   **问题4：空输入兼容性差**  **预期结果**：     空输入应返回空Tensor或符合数学定义的零值，与PyTorch行为对齐。  **实际结果**：     MindSpore抛出维度校验错误，中断执行。  **复现代码**：   ```python    空sorted_sequence测试   empty_sorted = Tensor([], ms.float32)   values = Tensor([1.0, 2.0], ms.float32)   try:       result = mint.searchsorted(empty_sorted, values)   except ValueError as e:       print(f""MindSpore空输入错误：{str(e)}\n"")    PyTorch空输入处理   pt_empty = torch.tensor([], dtype=torch.float32)   pt_values = torch.tensor([1.0, 2.0])   pt_result = torch.searchsorted(pt_empty, pt_values)   print(f""PyTorch空输入结果：{pt_result}"")   ```  **代码运行结果**：   ```   MindSpore空输入错误：input_data can not contain zero dimension...   PyTorch空输入结果：tensor([0, 0])   ```  **底层根因**：     `mindspore/ops/operations/other_ops.cc`中`CheckInputs`函数对空Tensor的严格校验策略。  **改进建议**：     修改空输入处理逻辑，允许空Tensor并返回全零结果：   ```cpp   if (sorted_seq_size == 0) {       // 返回与values形状相同的零Tensor       return Fill(0, values_shape);   }   ```   **问题5：输入错误数据类型校验时机滞后导致错误反馈延迟**  **预期结果**：     当高维输入维度不匹配（如3D sorted_sequence + 1D values）或类型不合法如uint时，应在接口调用时立即触发错误。  **实际结果**：     接口调用阶段未报错，前向计算正常构图，错误延迟至结果访问或执行阶段触发。  **复现代码**：   ```python    3D sorted_sequence + 1D values   sorted_seq = Tensor(np.random.rand(2, 3, 4), ms.float32)   shape (2,3,4)   values = Tensor([0.5], ms.float32)   shape (1,)   try:       result = mint.searchsorted(sorted_seq, values)       print(""前向计算完成，结果形状："", result.shape)   输出 (2,3,4)，未触发错误       result.asnumpy()   执行时触发维度校验错误   except ValueError as e:       print(f""维度校验错误：{str(e)}"")    PyTorch对比代码   pt_sorted = torch.rand(2,3,4)   pt_values = torch.tensor([0.5])   try:       pt_result = torch.searchsorted(pt_sorted, pt_values)   接口调用时立即报错   except RuntimeError as e:       print(f""\nPyTorch维度错误：{str(e)}"")   ```  **代码运行结果**：   ```     前向计算完成，结果形状： (2,3,4)     维度校验错误：For 'SearchSorted', the 'sorted_sequence' must be 1 dimensional or all dimensions except the last dimension of 'sorted_sequence' must be the same as all dimensions except the last dimension of 'values'...     PyTorch维度错误：boundaries tensor should be 1 dimension or the first N1 dimensions of boundaries tensor and input value tensor must match...   ```  **底层根因**：     MindSpore采用静态图架构（基于GE Graph），算子的维度校验逻辑嵌入在图编译阶段，而非前向接口调用时。用户调用Python接口时仅完成计算图构建，具体校验被延迟至图编译或执行阶段。而PyTorch作为动态图框架，在Python层即时执行算子逻辑，校验过程与接口调用同步触发。  **改进建议**：     在Python接口层添加显式的前置校验逻辑，模拟动态图框架的即时错误反馈机制：   1. **接口层维度检查**：在算子入口函数中增加形状匹配校验，若`sorted_sequence`非1D且前N1维与`values`不匹配，立即抛出异常。   2. **类型校验前移**：对`uint`等非法类型的检查从后端前移至Python层。   示例实现：   ```python   def searchsorted(sorted_sequence, values, ...):        前置维度校验       if sorted_sequence.ndim != 1 and sorted_sequence.shape[:1] != values.shape[:1]:           raise ValueError(               f""维度不匹配：sorted_sequence（{sorted_sequence.shape}）""               f""与values（{values.shape}）的前N1维必须相同"")        类型校验（示例）       if sorted_sequence.dtype not in [mstype.float32, mstype.float64]:           raise TypeError(""sorted_sequence仅支持float32/float64类型"")        后续构图逻辑...   ```   2.Environment / 环境信息  **Hardware Environment / 硬件环境** ",2025-02-25T17:07:50+08:00,mindspore-assistant,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOSUH
tanxinglian,[CT][MS][OPS][nn.rmseloss][function][全量]rmseloss ascend pynative模式bool类型校验丢失 ," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > rmseloss ascend pynative模式bool类型校验丢失   2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_n_rmseloss_input_3x7x2x9_dtype_error_bool >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 export CONTEXT_JIT_LEVEL=O0 > （2）cd MindSporeTest/operations > （3）pytest s v test_n_rmseloss.py::test_n_rmseloss_input_3x7x2x9_dtype_error_bool   5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功 预期报错TypeError: For primitive[Sub], the input argument[x] must be a type of {Tensor[BFloat16], Tensor[Float16], Tensor[Float32], Tensor[Float64], Tensor[Int16], Tensor[Int32], Tensor[Int64], Tensor[Int8], Tensor[UInt16], Tensor[UInt32], Tensor[UInt64], Tensor[UInt8]}, but got Tensor[Bool].  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       def test_n_rmseloss_input_3x7x2x9_dtype_error_bool():         logits = Tensor(np.random.randn(3, 7, 2, 9).astype(np.bool_))         label = Tensor(np.random.randn(3, 7, 2, 9).astype(np.bool_))         fact = RMSELossMock(inputs=[logits, label]) >       with pytest.raises((RuntimeError, TypeError, ValueError)): E       Failed: DID NOT RAISE (, , ) ../test_n_rmseloss.py:195: Failed =============================== warnings summary ==== ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bb21c384dee72f16dfcfaf&workspaceId=67bb21bf68393c7aa584f463&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T15:50:01+08:00,gitee,closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBORII,rmseloss小算子拼接中的sub算子报错 问题引入pr: https://gitee.com/mindspore/mindspore/pulls/81323 现象：pynative下sub算子数据类型不支持bool的拦截不生效，图模式正常 转给问题引入人进一步定位根因,‘’ 操作，动态图情况下走subext，subext与torch的sub对齐，支持bool类型，故动态图情况下不再报错。对于静态图，pr修改不影响原有‘’逻辑，还是走sub，sub对于bool类型进行拦截，故还会报错。由于并没有要求动静统一，所以这里建议测试修改测试用例。,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未对此问题进行问题分析 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：动态图bool类型输入未报错 根因： 1、 ‘’操作，动态图情况下走subext，subext与torch_npu的sub对齐，支持bool类型，故没有拦截报错。 Fix Solution 1、测试修改用例，bool类型不拦截 Fix Description & Test Suggestion 无 测试建议：修改bool报错用例。 Selftest Report & DT Review 用例修改后，不再报错 原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81323 PR合入时间：2025年/02月/12日 问题是否偶现：是/否,适配用例 ascend pynative模式bool类型已支持
luoxuewei,重构tensor.__index__接口,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  重构tensor.__index__接口  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-25T14:14:59+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOPM6
candyhong,PyBoost接口及ACLNN算子接入signbit, Tasks 转测对象：mint.signbit         Tensor.signbit  Tasks   PyBoost接口   动态Shape   静态图KernelByKernel   ACLNN算子：   aclnnSignbit  可参考下面例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-02-25T10:30:36+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOMSW
fangfangssj,mint.nn.functional.max_pool2d前向传播有精度问题," 1.Describe the current behavior / 问题描述  mint.nn.functional.max_pool2d前向传播有精度问题,在动态图和静态图上均有误差，且每个元素误差基本相同，但动态图和静态图误差不相同。  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_max_pool2d.py::test_max_pool2d_forward_backward  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_max_pool2d_forward_backward(mode):     ms.set_context(mode=mode)      PyTorch模型定义     class SimpleModel(torch.nn.Module):         def __init__(self):             super(SimpleModel, self).__init__()             self.conv = torch.nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1)             self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)         def forward(self, x):             x = self.conv(x)             x = self.pool(x)             return x      MindSpore模型定义     class SimpleModelMS(mnn.Cell):         def __init__(self):             super(SimpleModelMS, self).__init__()             self.conv = mnn.Conv2d(1, 1, kernel_size=3, stride=1, pad_mode=""pad"", padding=1)             self.pool = mnn.MaxPool2d(kernel_size=2, stride=2)         def construct(self, x):             x = self.conv(x)             x = self.pool(x)             return x      创建固定输入和权重     input_data_np = np.random.randn(1, 1, 8, 8).astype(np.float32)     weight_np = np.random.randn(1, 1, 3, 3).astype(np.float32)     bias_np = np.random.randn(1).astype(np.float32)      PyTorch模型设置     model_torch = SimpleModel()     model_torch.conv.weight.data = torch.tensor(weight_np)       model_torch.conv.bias.data = torch.tensor(bias_np)     input_torch = torch.tensor(input_data_np, requires_grad=True)      MindSpore模型设置     model_ms = SimpleModelMS()      初始化权重和偏置     model_ms.conv.weight = Tensor(weight_np)   初始化卷积层的权重     model_ms.conv.bias = Tensor(bias_np)   初始化卷积层的偏置     input_ms = Tensor(input_data_np, dtype=ms.float32)      正向传播     output_torch = model_torch(input_torch)     output_ms = model_ms(input_ms).asnumpy()      比较正向传播结果     diff = np.abs(output_torch.detach().numpy()  output_ms)     if np.all(diff  **【预期结果】**：不应该与torch有明显的误差  6.Related log / screenshot / 日志 / 截图 输出的张量为mindspore与torch间每个元素的误差 !输入图片说明",2025-02-25T00:38:13+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOL2D,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 !输入图片说明
fangfangssj,mint.nn.functional.max_pool2d希望支持int8，int16，int32，int64，uint8，float64，bfloat16, Backgroud（背景信息） 测试mint.nn.functional.max_pool2d这个api的时候，发现CANN后端不支持int8，int16，int32，int64，uint8，float64，bfloat16的数据类型。 torch却均支持。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch,2025-02-25T00:33:36+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOL2A,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.__mod__(%)/Tensor.__rmod__(%), Tasks 转测对象：Tensor.\_\_mod\_\_(符号%)/Tensor.\_\_rmod\_\_(符号%) ,2025-02-24T23:07:34+08:00,"gitee,v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOKS8
fangfangssj,mint.nn.functional.gelu在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.gelu在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_gelu.py::test_gelu_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_gelu_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.float64, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.gelu(ms_input)             torch_output = torch.nn.functional.gelu(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-24T21:57:37+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOKLL,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
fengyuebo2025,【开源实习】mindspore.mint接口测试任务17——tanh与pytorch的输出对比（对输入为inf、inf）," 1.Describe the current behavior / 问题描述  当输入为inf、inf时，mindspore输出1和1，pytorch均输出nan  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_tanh.py::test_any_wrong_input  4.Steps to reproduce the issue / 重现步骤  ``` import mindspore as ms import torch data=[float('inf'),float('inf')] ms_inp=ms.Tensor(data) torch_inp=torch.tensor(data) ms_res=ms.mint.tanh(ms_inp) torch_res=torch.tanh(torch_inp) print(f""ms_res:{ms_res},torch_res:{torch_res}"") ```  5.Describe the expected behavior / 预期结果  ms_res:[nan nan],torch_res:tensor([ 1., 1.]) 报错关键日志截图： !输入图片说明",2025-02-24T21:53:24+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOKJX
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log_softmax梯度误差," 1.Describe the current behavior / 问题描述  当输入数据类型为float16时，反向传播梯度误差大于1e3；目前测试遇到的最大误差为0.0078125  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log_softmax.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x,dim):     return torch.nn.functional.log_softmax(x,dim=dim) def forward_ms(x,dim):     return ms.mint.special.log_softmax(x,dim=dim) input_data = [[ 1.512695],  [ 3.158203],  [ 3.693359]] ms_inp=ms.Tensor(input_data,ms.float16) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float16) torch_res=forward_pt(torch_inp,dim=0) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) ms_res, gradient_ms = grad_fn(ms_inp,dim=0) ms_inp_grad=gradient_ms print(f""torch梯度结果为{torch_inp_grad}"") print(f""mindspore梯度结果为{ms_inp_grad}"") print(f""梯度的绝对误差为{abs(ms_inp_grad.asnumpy()torch_inp_grad.numpy())}"") ```  5.Describe the expected behavior / 预期结果  torch梯度结果为tensor([[ 0.8008],         [0.0348],         [0.7661]], dtype=torch.float16) mindspore梯度结果为[[ 0.800293]  [0.033752]  [0.766113]] 梯度的绝对误差为[[ 0.000488]  [ 0.001007]  [ 0.000000]] 报错关键日志截图： !输入图片说明",2025-02-24T18:08:00+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOJ7L
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log_softmax梯度无法print," 1.Describe the current behavior / 问题描述  当数据类型为float64时，梯度无法print  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log_softmax.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x,dim):     return torch.nn.functional.log_softmax(x,dim=dim) def forward_ms(x,dim):     return ms.mint.special.log_softmax(x,dim=dim) input_data = [[3,1]] ms_inp=ms.Tensor(input_data,ms.float64) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float64) torch_res=forward_pt(torch_inp,dim=0) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) ms_res, gradient_ms = grad_fn(ms_inp,dim=0) ms_inp_grad=gradient_ms print(f""torch梯度结果为{torch_inp_grad}"") print(f""mindspore梯度结果为{ms_inp_grad}"") ```  5.Describe the expected behavior / 预期结果  print(f""mindspore梯度结果为{ms_inp_grad}"")句报错 报错关键日志截图： !输入图片说明",2025-02-24T18:06:09+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOJ7D,这个出错的原因其实并不是因为print，而是反向算子出错了，反向出错的原因是因为log_softmax的反向算子还不支持float64，如果改成float32就可以运行；还有可能你看到的报错堆栈信息是定位到了print这一行，那是因为动态图模式下是异步执行的原因，导致堆栈信息不准确，设置下同步模式，ms.set_context(pynative_synchronize=True)，就能看到准确的堆栈信息了 !输入图片说明
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log_softmax误差大于1e3," 1.Describe the current behavior / 问题描述  当输入数据类型为float16时，误差大于1e3  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log_softmax.py::test_any_random_input_fixed_dtype  4.Steps to reproduce the issue / 重现步骤  ``` import mindspore as ms import torch import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) data=[[ 9.26562],  [ 0.91504],  [ 1.16895],  [ 9.33594],  [ 8.31250]] ms_inp=ms.Tensor(data,ms.float16) torch_inp=torch.tensor(data,dtype=torch.float16) ms_res=ms.mint.special.log_softmax(ms_inp,dim=0) torch_res=torch.nn.functional.log_softmax(torch_inp,dim=0) diff=ms_res.asnumpy()torch_res.numpy() print(f""ms_res:{ms_res}\ntorch_res:{torch_res}\ndiff:{diff}"") ```  5.Describe the expected behavior / 预期结果  ms_res:[[0.899902]  [9.250000]  [8.992188]  [0.829590]  [1.852539]] torch_res:tensor([[0.8999],         [9.2500],         [9.0000],         [0.8296],         [1.8525]], dtype=torch.float16) diff:[[ 0.000000]  [ 0.000000]  [ 0.007812]  [ 0.000000]  [ 0.000000]] 报错关键日志截图： !输入图片说明",2025-02-24T18:03:54+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOJ6T
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——sinc梯度误差," 1.Describe the current behavior / 问题描述  当数据类型为float16时，梯度误差大于1e3；如输入3.525391时，梯度误差是0.002136。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_round.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x):     return torch.special.sinc(x) def forward_ms(x):     return ms.mint.special.sinc(x) input_data = [[3.525391]] ms_inp=ms.Tensor(input_data,ms.float16) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float16) torch_res=forward_pt(torch_inp) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) ms_res, gradient_ms = grad_fn(ms_inp) ms_inp_grad=gradient_ms print(f""torch梯度结果为{torch_inp_grad},mindspore梯度结果为{ms_inp_grad},梯度的绝对误差为{abs(ms_inp_grad.item()torch_inp_grad.item())}"") ```  5.Describe the expected behavior / 预期结果  torch梯度结果为tensor([[0.0489]], dtype=torch.float16),mindspore梯度结果为[[ 0.046753]],梯度的绝对误差为0.00213623046875 报错关键日志截图： !输入图片说明",2025-02-24T18:01:31+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOJ68,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 补充说明：当数据类型为float32时，结果一致。
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——round与pytorch的输出差异," 1.Describe the current behavior / 问题描述  当输入是nan、inf、inf时，mindspore输出2.1474836e+09、2.1474836e+09、 2.1474836e+09，而pytorch输出nan、inf、inf  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_round.py::test_any_wrong_input  4.Steps to reproduce the issue / 重现步骤  ``` import mindspore as ms import torch data=[float('nan'),float('inf'),float('inf')] ms_inp=ms.Tensor(data) torch_inp=torch.tensor(data) ms_res=ms.mint.special.round(ms_inp) torch_res=torch.round(torch_inp) print(f""ms_res:{ms_res},torch_res:{torch_res}"") ```  5.Describe the expected behavior / 预期结果  ms_res:[ 2.1474836e+09  2.1474836e+09 2.1474836e+09],torch_res:tensor([nan, inf, inf]) 报错关键日志截图： !输入图片说明",2025-02-24T17:59:20+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOJ5L,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log1p输入小于1的负数时结果错误," 1.Describe the current behavior / 问题描述  当输入为inf时，mindspore输出inf，pytorch输出nan；当输入为小于1的负数时，mindspore不会报错，且结果为正数，pytorch输出nan。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log1p.py::test_any_wrong_input  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms data=[float('inf'),1,2,2000,20000] ms_inp=ms.Tensor(data) torch_inp=torch.tensor(data) ms_res=ms.mint.special.log1p(ms_inp) torch_res=torch.log1p(torch_inp) print(f""ms_res:{ms_res}\ntorch_res:{torch_res}"") ```  5.Describe the expected behavior / 预期结果  ms_res:[           inf 3.4028235e+38  0.0000000e+00  7.6004024e+00   9.9034376e+00] torch_res:tensor([nan, inf, nan, nan, nan]) 报错关键日志截图： !输入图片说明",2025-02-24T17:54:51+08:00,"gitee,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOJ44,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log1p与pytorch的输出差异," 1.Describe the current behavior / 问题描述  当输入数据类型为float16，且接近1时，mindspore输出65504.00000，pytorch输出inf；当输入数据类型为float32，且接近1时，mindspore输出3.4028235e+38，pytorch输出inf  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log1p.py::test_any_wrong_input  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms data=0.9999999999999999999999999999 ms_inp=ms.Tensor(data,ms.float16) torch_inp=torch.tensor(data,dtype=torch.float16) ms_res=ms.mint.special.log1p(ms_inp) torch_res=torch.log1p(torch_inp) print(f""ms_res:{ms_res}\ntorch_res:{torch_res}"") data=0.9999999999999999999999999999 ms_inp=ms.Tensor(data,ms.float32) torch_inp=torch.tensor(data,dtype=torch.float32) ms_res=ms.mint.special.log1p(ms_inp) torch_res=torch.log1p(torch_inp) print(f""ms_res:{ms_res}\ntorch_res:{torch_res}"") ```  5.Describe the expected behavior / 预期结果  ms_res:65500.0 torch_res:inf ms_res:3.4028235e+38 torch_res:inf 报错关键日志截图： !输入图片说明",2025-02-24T17:48:28+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIZS,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
houbosen2025, mint.nn.erfc希望支持bfloat16,issue编写  1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.erfc需要支持bfloat16  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > > 2. 计算测试，以float32 > >    1. 测试组，小数点后5位不同，算测试通过 > >       input_data: [ 0.55593791  0.44808426 2.71790637 0.53732477 0.45158543] >       ms_result: [0.43174636 0.5263032  1.9998777  1.5526736  1.4769242 ] >       torch_result: [0.4317416  0.52628523 1.9998788  1.5526809  1.4769417 ] > >    2. 测试组，小数点后5位不同 > >       input_data: [ 0.53237093 0.99921068  0.81374149  0.05919775 0.15359628] >       ms_result: [0.45152628 1.8423889  0.24979174 0.93325967 1.1719722 ] >       torch_result: [0.4515183  1.8423729  0.24981277 0.93328047 1.1719615 ] > > 3. 参数输入 > >    无参数设置，均通过 > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220163118648  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:43:43+08:00,"gitee,mindspore-assistant,foruda,intern",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBOIVU,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.erfc已支持bfloat16，且与torchnpu结果一致 !输入图片说明,单独测试，显示mint.nn.erfc已支持bfloat16 !输入图片说明
houbosen2025,mint.nn.erf 希望支持bfloat16,issue编写  1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.erf需要支持bfloat16  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > > 2. 计算测试，以float32 > >    1. 测试组，小数点后5位不同，算测试通过 > >       input_data: [0.37975368 0.34422294 1.42222966 1.04481118  0.95105012] >       ms_result: [0.4087475  0.37358218 0.9556926  0.860494    0.8213899 ] >       torch_result: [0.408769   0.37360325 0.95571023 0.8604813   0.8213707 ] > >    2. 测试组，小数点后5位不同 >       input_data: [ 2.22057531 1.10386126 0.54387706  0.14834316  1.51924453] >       ms_result: [ 0.99830514 0.8815062  0.5581943   0.16617936  0.96830803] >       torch_result: [ 0.99831253 0.88149875 0.5582007   0.16616759  0.96832895] > > 3. 参数输入 > >    无参数设置，均通过 > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220162940207  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:42:11+08:00,"gitee,mindspore-assistant,foruda,intern",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIUL,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.erf 已支持BFloat16， !输入图片说明
fengyuebo2025,【开源实习】mindspore.mint接口测试任务17——tan精度问题," 1.Describe the current behavior / 问题描述  当输入类型为float32时，绝对误差可能大于1e3；目前测试中遇到的最大误差为0.046875，最小是0.001953125  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_tan.py::test_any_random_input_fixed_dtype  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x):     return torch.tan(x) def forward_ms(x):     return ms.mint.tan(x) input_data = [[1.570737]] ms_inp=ms.Tensor(input_data,ms.float32) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float32) torch_res=forward_pt(torch_inp) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) ms_res, gradient_ms = grad_fn(ms_inp) ms_inp_grad=gradient_ms print(f""torch结果为{torch_res},mindspore结果为{ms_res},绝对误差为{ms_res.item()torch_res.item()}"") ```  5.Describe the expected behavior / 预期结果  torch结果为tensor( [[16857.0059]]，grad_fn=) ,mindspore结果为[[16857.003906]] ,绝对误差为0.001953125 报错关键日志截图： !输入图片说明",2025-02-24T17:41:11+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOITK,"使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 需要注意的是 复现情况1：数值范围01,100组，结果与torchnpu结果一致 复现情况2：数值为1.570737（接近90°），此时与torchnpu结果相差0.0019，因为接近90°时数值计算会不稳定，是否作为bug请根据需要。"
houbosen2025,mint.nn.divide希望在API ref编写支持类型，且希望支持UInt16，UInt32，UInt64，BFloat16,issue编写  1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.divide 在API表未编写支持类型，但是不支持UInt16，UInt32，UInt64，BFloat16，但是torch是支持UInt16，UInt32，UInt64的 这个issue同div  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > >  > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220162719866  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:40:26+08:00,"gitee,mindspore-assistant,intern",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIT8,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.divide已支持BFloat16，后续将支持UInt16，UInt32，UInt64
houbosen2025,mint.nn.div希望在API ref编写支持类型，且希望支持UInt16，UInt32，UInt64，BFloat1, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.div 在API表未编写支持类型，但是不支持UInt16，UInt32，UInt64，BFloat16，但是torch是支持UInt16，UInt32，UInt64的  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > >  > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220162719866  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:37:19+08:00,"gitee,mindspore-assistant,intern",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIQK,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.div已支持BFloat16，后续将支持UInt16，UInt32，UInt64
林芃芃,`mindspore.mint.repeat_interleave`不支持空张量，与 PyTorch 行为不一致，文档没有明确说明," 1.Describe the current behavior / 问题描述 任务链接 `mindspore.mint.repeat_interleave`不支持空张量，与 PyTorch 行为不一致，可能会影响用户迁移代码。  错误信息虽然清晰，但这个限制应该在文档中明确说明  可能会影响一些边界情况的处理  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例  **Testcase Name**: >  test_repeat_interleave.py::test_edge_cases  测试边界条件  **Execute Mode**: >  Graph Mode  4.Steps to reproduce the issue / 重现步骤 1. 创建测试代码`test_repeat_interleave.py`： ```python import numpy as np import pytest import mindspore import torch from mindspore import Tensor from mindspore import mint def test_edge_cases():     """"""测试边界条件""""""      测试空张量     empty_input = Tensor(np.array([]), mindspore.float32)     try:         output = mint.repeat_interleave(empty_input, repeats=2, dim=0)         print(f""Empty tensor output shape: {output.shape}"")     except Exception as e:         print(f""Empty tensor raised: {type(e).__name__}: {str(e)}"")      测试repeats=0的情况     input_data = np.array([[1, 2], [3, 4]])     ms_input = Tensor(input_data, mindspore.float32)     try:         output = mint.repeat_interleave(ms_input, repeats=0, dim=0)         print(f""Zero repeats output shape: {output.shape}"")     except Exception as e:         print(f""Zero repeats raised: {type(e).__name__}: {str(e)}"")      测试repeats为很大的数     try:         output = mint.repeat_interleave(ms_input, repeats=1000000, dim=0)         print(f""Large repeats output shape: {output.shape}"")     except Exception as e:         print(f""Large repeats raised: {type(e).__name__}: {str(e)}"") ``` 2. 运行测试用例： ```bash pytest test_repeat_interleave.py v ``` 3. 观察测试日志中的错误信息和精度差异报告  5.Describe the expected behavior / 预期结果  测试用例应该通过，不会抛出异常  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-24T16:41:08+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOHK1
虞良斌,tensorboard_trace_handler The interface parameter of the document is added,,2025-02-24T15:51:02+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBOGIK
fangfangssj,mint.nn.SELU在910b上静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.SELU在910b上静态图无法计算  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_Mish.py::test_Mish_all_dtypes  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_SELU_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 SELU 函数             ms_SELU = mint.nn.SELU()             ms_output = ms_SELU(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 SELU 函数             torch_SELU = torch.nn.SELU()             torch_output = torch_SELU(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-24T00:25:25+08:00,"gitee,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8JG,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 报错如下： !输入图片说明
fangfangssj,"mint.nn.Mish 希望支持float64,bfloat16"," Backgroud（背景信息） 测试mint.nn.Mish这个api的时候，发现CANN后端不支持float64,bfloat16的数据类型。 torch却支持float64,bfloat16  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch",2025-02-24T00:19:56+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8J8,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
fangfangssj,mint.nn.PReLU使用float32输入时静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.PReLU使用float32输入时静态图无法计算，支持的dtype包括DT_FLOAT32，但错误显示输入为DT_INT8，可能是框架内部类型转换错误。 框架内部类型映射错误：在MindSpore中，可能存在将float32错误映射为int8的bug  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_PReLU.py::test_PReLU_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_Mish_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32     dtypes = [ms.float16, ms.float32]     torch_dtypes = [torch.float16, torch.float32]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_Mish = mint.nn.Mish()             ms_output = ms_Mish(ms_input)             torch_Mish = torch.nn.Mish()             torch_output = torch_Mish(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-24T00:15:35+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8J3,"提供的复现代码有多处错误，更正后代码如下： ``` import pytest import torch import torch_npu import mindspore import numpy as np import mindspore as ms from mindspore import mint, Tensor .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_Mish_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32     dtypes = [ms.float32,ms.float16 ]  ms.float16     torch_dtypes = [torch.float32,torch.float16 ]  torch.float16     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(1):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             prelu = mint.nn.PReLU()             ms_output = prelu(ms_input)             torch_prelu = torch.nn.PReLU(dtype=torch_dtype)             torch_output = torch_prelu(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.detach().numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."")> 这里输入引用文本 ``` 目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.PReLU已支持float32，与torchnpu结果一致 !输入图片说明"
fangfangssj,mint.nn.Mish在910b上静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.Mish在910b上静态图无法计算  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_Mish.py::test_Mish_all_dtypes  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_Mish_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 Mish 函数             ms_Mish = mint.nn.Mish()             ms_output = ms_Mish(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 Mish 函数             torch_Mish = torch.nn.Mish()             torch_output = torch_Mish(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-24T00:01:46+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8I5,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 报错截图如下： !输入图片说明
fangfangssj,mint.nn.LogSoftmax使用float16输入时静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.ReLU使用float16输入时静态图无法计算，支持的dtype包括DT_FLOAT16，但错误显示输入为DT_INT8，可能是框架内部类型转换错误。 框架内部类型映射错误：在MindSpore中，可能存在将float16错误映射为int8的bug  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_LogSoftmax.py::test_LogSoftmax_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_LogSoftmax_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_LogSoftmax = mint.nn.LogSoftmax()             ms_output = ms_LogSoftmax(ms_input)             torch_LogSoftmax = torch.nn.LogSoftmax()             torch_output = torch_LogSoftmax(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-23T23:44:07+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8GW,目前，mindspore 2.5.0版本在910b环境中，mint.nn.LogSoftmax输入float16数据，可以在静态图中计算，且结果与torchnpu结果一致，通过测试 !输入图片说明
fangfangssj,mint.nn.LogSoftmax在910b上float32运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.LogSoftmax在910b上float32运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_LogSoftmax.py::test_LogSoftmax_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_LogSoftmax_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_LogSoftmax = mint.nn.LogSoftmax()             ms_output = ms_LogSoftmax(ms_input)             torch_LogSoftmax = torch.nn.LogSoftmax()             torch_output = torch_LogSoftmax(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float32运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-23T23:40:23+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8GO,目前，mindspore 2.5.0版本在910b环境中，mint.nn.LogSoftmax输入float32数据，结果与torchnpu结果一致，通过测试 !输入图片说明
fangfangssj,mint.nn.ReLU使用float16输入时静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.ReLU使用float16输入时静态图无法计算，支持的dtype包括DT_FLOAT16，但错误显示输入为DT_INT16，可能是框架内部类型转换错误。 框架内部类型映射错误：在MindSpore中，可能存在将float16错误映射为int16的bug  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_ReLU.py::test_ReLU_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_ReLU_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_relu = mint.nn.ReLU()             ms_output = ms_relu(ms_input)             torch_relu = torch.nn.ReLU()             torch_output = torch_relu(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-23T22:38:47+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBO871,在910B机器上执行mint.nn.ReLU单算子脚本，未复现该报错。并且跑静态图不仅需要配置上下文环境变量，还需要有对应结构，例如construct函数或者使用，否则即使配置上下文为GRAPH模式，运行时依旧会走PYNATIVE模式。
林芃芃,mindspore.mint.hardswish 接口数据类型支持不一致及类型转换异常问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 实习任务 在测试MindSpore的Hardswish接口时发现两个问题： 1. 接口实现与文档描述的数据类型支持不一致 2. 在处理float32类型输入时出现异常的类型转换（被错误转换为int32类型）  文档与实现不一致 1. 文档说明：     仅在输入不是tensor时报TypeError     仅在输入既不是int也不是float类型时报TypeError     暗示支持所有int和float类型的tensor输入 2. 实际实现：     错误信息显示仅支持[DT_FLOAT, DT_FLOAT16, DT_BFLOAT16]     与文档描述的支持范围不符  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    test_hardswish.py::test_diffrent_dtype >    test_hardswish.py::test_random_values >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode: Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建测试文件`test_hardswish.py` ```python import numpy as np import pytest import mindspore as ms from mindspore import Tensor import mindspore.mint as mint import torch import logging  配置日志记录 logging.basicConfig(     level=logging.INFO,     format='%(asctime)s  %(levelname)s  %(message)s',     handlers=[         logging.FileHandler('logs/test_hardswish.log', encoding='utf8'),         logging.StreamHandler()     ] ) class TestHardswish:     """"""测试 Hardswish 激活函数""""""     def setup_method(self):         """"""初始化测试环境""""""         self.ms_hardswish = mint.nn.Hardswish()         self.torch_hardswish = torch.nn.Hardswish()     def test_different_dtypes(self):         """"""测试不同数据类型的支持度""""""         dtypes = [             (np.float16, torch.float16, ms.float16),             (np.float32, torch.float32, ms.float32),             (np.int32, torch.int32, ms.int32),             (np.int64, torch.int64, ms.int64),         ]         for np_dtype, torch_dtype, ms_dtype in dtypes:             x = np.random.uniform(3, 3, size=(2, 3)).astype(np_dtype)             logging.info(f""\n测试数据类型: {np_dtype}"")             try:                 x_torch = torch.tensor(x, dtype=torch_dtype)                 y_torch = self.torch_hardswish(x_torch)                 torch_support = True                 logging.info(f""PyTorch支持{torch_dtype}"")             except Exception as e:                 torch_support = False                 logging.info(f""PyTorch不支持{torch_dtype}, 错误: {str(e)}"")             try:                 x_ms = Tensor(x, dtype=ms_dtype)                 y_ms = self.ms_hardswish(x_ms)                 ms_support = True                 logging.info(f""MindSpore支持{ms_dtype}"")             except Exception as e:                 ms_support = False                 logging.info(f""MindSpore不支持{ms_dtype}, 错误: {str(e)}"")             if torch_support and ms_support:                  检查结果误差                 diff = np.abs(y_ms.asnumpy()  y_torch.detach().numpy())                 max_diff = np.max(diff)                 logging.info(f""最大误差: {max_diff}"")                 assert max_diff < 1e3, f""误差{max_diff}超过阈值1e3""     def test_random_values(self):         """"""测试随机输入值的一致性""""""         x = np.random.uniform(3, 3, size=(4, 5)).astype(np.float32)         x_torch = torch.tensor(x, requires_grad=True)         x_ms = Tensor(x, dtype=ms.float32)         y_torch = self.torch_hardswish(x_torch)         y_ms = self.ms_hardswish(x_ms)          检查前向传播结果         diff = np.abs(y_ms.asnumpy()  y_torch.detach().numpy())         max_diff = np.max(diff)         logging.info(f""\n随机输入前向传播最大误差: {max_diff}"")         assert max_diff < 1e3, f""前向传播误差{max_diff}超过阈值1e3""          检查反向传播         y_torch.sum().backward()         grad_torch = x_torch.grad.numpy()         grad_ms = ms.grad(self.ms_hardswish)(x_ms).asnumpy()         grad_diff = np.abs(grad_ms  grad_torch)         max_grad_diff = np.max(grad_diff)         logging.info(f""随机输入反向传播最大误差: {max_grad_diff}"")         assert max_grad_diff < 1e3, f""反向传播误差{max_grad_diff}超过阈值1e3"" if __name__ == ""__main__"":     pytest.main([""v"", ""test_hardswish.py""]) ``` 2. 运行测试 ```bash pytest test_hardswish.py v ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 1. 接口应支持文档描述的所有int和float类型 2. 对于float32类型输入：     应保持类型不变     正确执行Hardswish操作并返回结果  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明  Hardswish 操作不支持 `DT_INT32` 数据类型，只支持 `DT_FLOAT`、`DT_FLOAT16` 和 `DT_BFLOAT16`   Ascend 硬件在处理 Hardswish 操作时出现了问题",2025-02-23T14:08:22+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO6KJ,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
fengyuebo2025,【开源实习】mindspore.mint接口测试任务17tan梯度问题2," 1.Describe the current behavior / 问题描述  当输入类型为float32时，反向传播的梯度误差大于1e3（输入数据1.570685）  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_tan.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x):     return torch.tan(x) def forward_ms(x):     return ms.mint.tan(x) input_data = [[1.570685]] ms_inp=ms.Tensor(input_data,ms.float32) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float32) torch_res=forward_pt(torch_inp) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) _, gradient_ms = grad_fn(ms_inp) ms_inp_grad=gradient_ms print(f""torch梯度为{torch_inp_grad},mindspore梯度为{ms_inp_grad},梯度的绝对误差为{ms_inp_grad.item()torch_inp_grad.item()}"") ```  5.Describe the expected behavior / 预期结果  torch梯度为tensor([[80728544. ]]) ,mindspore梯度为[[ 80728576 .0000]],梯度的绝对误差为32.0 报错关键日志截图： !输入图片说明",2025-02-23T13:53:38+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO6J1,这应该是cann算子底层处理的误差了，应该不是mindspore框架层面能控制的，不过我觉得想80728544这种量级的数据，误差32应该也是正常范围，通常像0.1到0.9这种范围的浮点数，就是小于1小数点后一位的浮点数，误差在1e4以内是正常的，然后随着数值增大，误差通常也会放大，到8位数的话，误差个两位数其实也正常
fengyuebo2025,【开源实习】mindspore.mint接口测试任务17tan梯度问题1," 1.Describe the current behavior / 问题描述  当输入类型为float16，且梯度很大时，mindspore计算的是65504（float16最大值），pytorch计算的是inf（输入数据1.56934）  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_tan.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np def forward_pt(x):     return torch.tan(x) def forward_ms(x):     return ms.mint.tan(x) input_data = [[1.56934]] ms_inp=ms.Tensor(input_data,ms.float16) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float16) torch_res=forward_pt(torch_inp) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) _, gradient_ms = grad_fn(ms_inp) ms_inp_grad=gradient_ms print(f""torch梯度为{torch_inp_grad},mindspore梯度为{ms_inp_grad}"") ```  5.Describe the expected behavior / 预期结果  torch梯度为tensor([[inf]]，dtype=torch.float16),mindspore梯度为[[65504.]] 报错关键日志截图： !输入图片说明",2025-02-23T13:51:04+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO6IU,这个可能是910b上某些算子的一个机制，上溢保护，在超过数据类型所能表达的范围时，如果不做处理就是inf无限大，后续基于inf的计算可能就会出现nan的情况，上溢保护就是会在溢出时赋一个极限值
fengyuebo2025,【开源实习】mindspore.mint接口测试任务17sub," 1.Describe the current behavior / 问题描述  在input和other为int，alpha为bool、float等，做sub运算时，如果不输出结果不会抛出错误（即mindspore做sub运算时，很多时候输入数据类型错误，但运算时不会报错，只有再次print结果时才会报错）  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_sub.py::test_any_different_para  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np input_data = [1] other_data = [0] ms_input=ms.Tensor(input_data) ms_other=ms.Tensor(other_data) torch_input=torch.tensor(input_data) torch_other=torch.tensor(other_data) ms_res=None try:   ms_res=ms.mint.sub(ms_input,ms_other,alpha=0.1) except Exception as e:   print(e) print(ms_res) 注释掉该句就不会报错 ```  5.Describe the expected behavior / 预期结果  执行print(ms_res)报错ValueError，如果不执行该句则不会报错。 报错关键日志截图： !输入图片说明",2025-02-23T13:41:32+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO6GF,这个问题其实是因为动态图模式下默认异步执行的原因，导致报错信息的堆栈可能不准确，或者如你所述的那样在没有print的时候不报错，实际上是因为异步执行， 在调用那个api之后的那一瞬间，可能已经直行到下一行代码了，但内部算子可能都还没有执行，所以也就没有马上看到报错信息，而当进行print，或者其它方式使用该api输出的结果时，就必须强制执行内部的算子了，也就报错了，这样就造成了在print那一步才开始报错的情况，动态图的异步是为了提升动态图的执行性能，这个应该属于正常现象，目前确实是这个机制，如果需要准确的报错位置，或者说准确的报错堆栈信息的话，可以在上下文中设置同步：mindspore.set_context(pynative_synchronize =True)
fengyuebo2025,【开源实习】mindspore.mint接口测试任务17sqrt," 1.Describe the current behavior / 问题描述  当输入为负数时，sqrt开根结果为正数，而pytorch结果是nan。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_sqrt.py::test_any_wrong_input  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np ms_dtypes = [ms.int8] torch_dtypes = [torch.int8] input_data = [4] for i in range(len(ms_dtypes)):   ms_type=ms_dtypes[i]   torch_type=torch_dtypes[i]   ms_input=ms.Tensor(input_data,ms_type)   torch_input=torch.tensor(input_data,dtype=torch_type)   ms_res=None   torch_res=None   ms_res=ms.mint.sqrt(ms_input)   print(f""ms_res:{ms_res}"")   torch_res=torch.sqrt(torch_input)   print(f""torch_res:{torch_res}"") ```  5.Describe the expected behavior / 预期结果  ms_res:[2.] torch_res:tensor([nan]) 报错关键日志截图： !输入图片说明",2025-02-23T13:36:45+08:00,"gitee,mindspore-assistant,foruda",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBO6GB,"我这边测试了一下，在数据类型为float16,float32，int8，int32时确实有这个问题，不过在int64和float64的情况下，返回是nan: !输入图片说明 感觉是内部对部分数据类型的负数情况没处理好，可能是cann算子的底层的一些问题",!输入图片说明 在MindSpore 2.6版本，910B设备上，没有问题。
majun-bot,CVE20251594,"一、漏洞信息 漏洞编号：CVE20251594 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A vulnerability, which was classified as critical, was found in FFmpeg up to 7.1. This affects the function ff_aac_search_for_tns of the file libavcodec/aacenc_tns.c of the component AAC Encoder. The manipulation leads to stackbased buffer overflow. It is possible to initiate the attack remotely. The exploit has been disclosed to the public and may be used. 漏洞公开时间：N/A 漏洞创建时间：20250223 06:40:03 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20251594 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 在FFmpeg7.1及以下版本中发现一个漏洞，该漏洞被归类为严重漏洞。该漏洞影响组件AACEncoder的文件libavcodec/aacenc_tns.c中的ff_aac_search_for_tns函数。该操作会导致基于堆栈的缓冲区溢出。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-23T06:40:03+08:00,"gitee,foruda,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,8,https://gitee.com/mindspore/mindspore/issues/IBO5SF,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142"," , , , , ,huawei , , ,he91 , , , ,git , , , , , , , , , , , , , , , , , , , , , , , , , , , ,yfei , , , , ,  **issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  MindSpore评分: (评分和向量) 受影响版本排查(受影响/不受影响):  1.master: 2.v1.10: 3.v1.9.0: 4.v2.0.0: 5.v2.1.0: 6.v2.2.0: 7.v2.2.10: 8.v2.3.0: 9.v2.4.0: 10.v2.4.10:  issue处理具体操作请参考:  https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明 => 没有正确填写," CVE信息从NVD同步失败, 请稍后重试, 或者数据源不存在.",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 在 FFmpeg 7.1 及以下版本中发现一个漏洞，该漏洞被归类为严重漏洞。该漏洞影响组件 AAC Encoder 的文件 libavcodec/aacenc_tns.c 中的 ff_aac_search_for_tns 函数。该操作会导致基于堆栈的缓冲区溢出。 漏洞评分(MindSpore评分):  BaseScore：6.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",开发已合入相关修复代码 !输入图片说明
baimz,[ST][MS][冒烟]llama2_7b网络multilora_embed mindie服务化和带框架单batch推理报错aclnnGroupedMatmulV3GetWorkspaceSize call failed," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > llama2_7b网络multilora_embed mindie服务化和带框架单batch推理报错aclnnGroupedMatmulV3GetWorkspaceSize call failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001 test_ms_llama2_7b_mindie_infer_multilora_embed_fp16_910b4_1p_0001 test_ms_llama2_7b_mindie_infer_multilora_perf_fp16_910b4_2p_0001 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd /configs/llama2/ > （3）python run_mindformer.py config /home/jenkins0/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_910b4_1p_0001/configs/llama2/predict_llama2_7b_slora.yaml predict_data 'I love Beijing, because' 'I believe the meaning for life is' 'Owning a dog as pet can be' 'I love to watch movies, because'  use_parallel=False adapter_id 'adapter1' > /home/jenkins0/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_910b4_1p_0001/llama2_7b_multilora.log 2>&1 & > （4）验证网络推理是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：网络推理是否正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) ``` Traceback (most recent call last):   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/tools/cloud_adapter/cloud_monitor.py"", line 34, in wrapper     result = run_func(*args, **kwargs)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/run_mindformer.py"", line 76, in main     trainer.predict(predict_checkpoint=config.load_checkpoint, input_data=config.input_data,   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/_checkparam.py"", line 1367, in wrapper     return func(*args, **kwargs)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/trainer/trainer.py"", line 792, in predict     output_result = self.trainer.predict(   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/trainer/causal_language_modeling/causal_language_modeling.py"", line 346, in predict     return self.predict_process(config=config,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/trainer/base_trainer.py"", line 1239, in predict_process     output_results = self.pipeline_task(input_data, top_k=top_k)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/base_pipeline.py"", line 149, in __call__     outputs = self.run_multi(inputs, batch_size, preprocess_params, forward_params, postprocess_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/text_generation_pipeline.py"", line 183, in run_multi     outputs.extend(self.run_single(item, preprocess_params,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/base_pipeline.py"", line 237, in run_single     model_outputs = self.forward(model_inputs, **forward_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/base_pipeline.py"", line 303, in forward     return self._forward(model_inputs, **forward_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/text_generation_pipeline.py"", line 199, in _forward     result = self.network.generate(input_ids, **forward_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 913, in generate     infer_output, is_finished = self.infer(input_ids=input_ids,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 1053, in infer     res, current_index = self.forward(input_ids=input_ids,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 1177, in forward     res = self._incremental_infer(   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 355, in _incremental_infer     res = self(   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 731, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 1152, in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1960, in __call__     return self.run(obj, *args, phase=phase)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 2011, in run     return self._exec_pip(obj, *args, phase=phase_real)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 191, in wrapper     results = fn(*arg, **kwargs)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1991, in _exec_pip     return self._graph_executor(args, phase) RuntimeError: aclnnGroupedMatmulV3GetWorkspaceSize call failed, please check! ```    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** 戴仁杰（根据实际修改） **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） ** ** 1. 特性合入引入 ** ** ** **引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx ** ** ** **特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/…… ** ** ** **PR 合入时间：2025/1/6 ** ** ** **是否偶现：是/否 ** ** 2. Bugfix 修复引入 ** ** ** **引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx ** ** PR 合入时间：2025/1/6 ** ** 是否偶现：是/否 ** ** 3. 测试新增测试场景/测试漏测/用例未适配 ** ** ** **测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. …… ** ** 用例如果有新增，则补充 用例新增时间：2025/1/6 ** ** 是否偶现：是/否 ** ** 4. 环境问题 ** ** ** **具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因 ** ** 是否偶现：是/否 ** ** 5. CANN 升级 ** ** ** **CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-22T16:07:13+08:00,"gitee,foruda,rca/others,kind/bug,dts-szv,rct/cann,ctl/solutiontest",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBO3N8,"multilora benchmark的性能也劣化了，generate speed is 278.2349, less than 280.0，上次是14号pass的结果：generate speed:290.9644 is up to 280.0，开发定位是同一问题，关联用例：test_ms_llama2_7b_mindie_infer_multilora_perf_fp16_910b4_2p_0001",问题进展： 使用0219的cann包错误复现，而使用1231的cann包正常推理且精度对齐，暂定位为cann包问题 !输入图片说明,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,确认为算子问题，产品线同事已提单：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025030506797,"Appearance & Root Cause 问题：slora推理时，sloraembedding出现groupedmatmul算子报错 根因： 1、 groupedmatmul约束限制存在问题，导致x的shape为[1,1]时会错认为转置。 Fix Solution 1、修改groupedmatmul算子。 Fix Description & Test Suggestion 测试建议：正常推理测试。 Selftest Report & DT Review 正常推理无报错，精度对齐。 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：算子约束问题 问题是否偶现：否",回归版本：MilanASL V100R001C21SPC001B203 master_20250325085444_498d8e6d48 回归步骤：参考issue复现步骤 基本功能：问题已解决 !输入图片说明 测试结论：回归通过 回归人员：白梦真 回归时间：20250328
luoxuewei,重构 tensor.tolist() 接口,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-22T14:02:06+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBO2UL
yuanqi,新增Morph算子,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any. 新增Morph算子，在并行之后，自动微分之前展开，满足静态图分布式自动并行模式下非规整通信诉求。  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-02-22T11:28:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBO25W
emf,RNN模型情感分类训练异常,官网教程RNN模型情感分类训练异常 ms2.5 CANN8 910A,2025-02-22T11:01:59+08:00,"gitee,mindspore-assistant,foruda,foruda,foruda,repo",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBO1UV,补充在X86 CPU 也有此问题,在910a环境下测试了一遍，使用2.5.0正式版和2.5.0的dev版本，dev版本是通过pip install mindsporedev安装的，运行结果精度没有什么问题： !输入图片说明 !输入图片说明 CPU上这个版本跑下来也能正常运行： !输入图片说明,用这个16号的包测试了一下，运行情况也正常： https://repo.mindspore.cn/mindspore/mindspore/version/202502/20250216/master_20250216220016_cdfeacb0d4ba3837a0be41918e5166bb73313a98_newest/unified/aarch64/mindspore2.5.0cp39cp39linux_aarch64.whl !输入图片说明,这个教程经过验证是正常的？能提供一下详细截图吗？
emf,图像分类resnet50精度有问题,官网教程图像分类和迁移学习这两个用例在ms2.5版本910Agraph模式下精度不够，不正常；,2025-02-22T11:00:29+08:00,"gitee,mindspore-assistant,foruda,foruda,repo",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBO1UL,在910a环境下测试了一遍，使用2.5.0正式版和2.5.0的dev版本，dev版本是通过pip install mindsporedev安装的，运行结果精度没有什么问题： !输入图片说明 !输入图片说明,用这个16号的包测试了一下，运行情况也正常： https://repo.mindspore.cn/mindspore/mindspore/version/202502/20250216/master_20250216220016_cdfeacb0d4ba3837a0be41918e5166bb73313a98_newest/unified/aarch64/mindspore2.5.0cp39cp39linux_aarch64.whl !输入图片说明
梅飞要,fix domain range end is null err,,2025-02-22T10:10:33+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBO1I2
虞良斌,"profiler on NPU alone, profile_memory error message",,2025-02-22T09:41:58+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBO1BW
majun-bot,CVE20250838,"一、漏洞信息 漏洞编号：CVE20250838 漏洞归属组件：abseilcpp, https://gitee.com/mindspore/mindspore 漏洞归属的版本：2.0210324e+07 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： There exists a heap buffer overflow vulnerable in Abseilcpp. The sized constructors, reserve(), and rehash() methods of absl::{flat,node}hash{set,map} did not impose an upper bound on their size argument. As a result, it was possible for a caller to pass a very large size that would cause an integer overflow when computing the size of the container's backing store, and a subsequent outofbounds memory write. Subsequent accesses to the container might also access outofbounds memory. We recommend upgrading past commit 5a0e2cb5e3958dd90bb8569a2766622cb74d90c1 漏洞公开时间：N/A 漏洞创建时间：20250222 00:43:54 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20250838 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 5.9 &emsp;Vector： CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-22T00:43:55+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,24,https://gitee.com/mindspore/mindspore/issues/IBO0VI,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142"," , , , , ,huawei , , ,he91 , , , ,git , , , , , , , , , , , , , , , , , , , , , , , , , , , ,yfei , , , , ,  **issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  MindSpore评分: (评分和向量) 受影响版本排查(受影响/不受影响):  1.master: 2.v1.10: 3.v1.9.0: 4.v2.0.0: 5.v2.1.0: 6.v2.2.0: 7.v2.2.10: 8.v2.3.0: 9.v2.4.0: 10.v2.4.10:  issue处理具体操作请参考:  https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明 => 没有正确填写," CVE信息从NVD同步成功, 稍后请重新加载页面.",影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 MindSpore评分： CVSS V3.0分值： BaseScore：0.0 None Vector：CVSS：3.0/ 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明 => 没有正确填写,影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 MindSpore评分： CVSS V3.0分值： BaseScore：5.9 MEDIUM Vector：CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,影响性分析说明 => 没有正确填写," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 MindSpore评分： CVSS V3.0分值： BaseScore：5.9 MEDIUM Vector：CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明 => 没有正确填写,影响性分析说明: 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 漏洞评分(mindspore评分): BaseScore: 5.9 MEDIUM Vector: CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**","经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明: 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 漏洞评分(mindspore评分): BaseScore: 5.9 MEDIUM Vector: CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,该漏洞修复方案在20210324.2版本中不兼容，故不受影响。
tangmengcheng,profiler level docs,,2025-02-21T20:01:18+08:00,gitee,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IBO033
吴逸群,香橙派npu利用率上不去,"环境：香橙派20T 24G cann 8.0 mindspore 2.4.10 训练设置参数：ms.setcontext(device_target=""Ascend"", mode=ms.GRAPH_MODE, jit_config={jit_level"".""O2""}, ascend_config{""precision_mode"".""allow_mix_presion""}) 使用过程中，训练的时候，npu利用率持续很低，不超过40%，请问如何设置mindspore参数可以提升？",2025-02-21T17:24:30+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNYT0,ai core的利用率和模型本身有很大关联， 有些模型架构相对利用率更低一些，和模型里调用的算子也有关联，和数据预处理也有关系，数据预处理的占用时间长了，利用率也会下降；香橙派上又有一些特殊情况，CPU较弱、数据传输带宽相比于910都要弱，导致跑很多模型的性能瓶颈都不在ai core的算力上，而是在数据带宽上，或者CPU上，所以利用率通常比较低，并且和香橙派310b的算子实现也有关系，如果算子实现更高效，利用率也会更高一些
吴逸群,LSTM+RCF案例的ops.logsumexp参数有变动没有适配,脚本地址：https://www.mindspore.cn/tutorials/zhCN/master/nlp/sequence_labeling.html 环境：910A mindspore版本 2.4.0 python版本 3.10 ops.logsumexp 接口中axis参数变更为了dim 教程未适配，报错“logsumexp() got an unexpeted keyword argument 'axis'”,2025-02-21T17:06:40+08:00,"gitee,mindspore-assistant,foruda",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBNYGK,目前测试下来，2.4.0和2.5.0版本的这个参数并没有变化，还是axis，并且2.4.0和2.5.0的文档上写的也还是axis，不应该有这个报错 !输入图片说明 这个错误提示完全是python层面的api方法的参数报错，和910A环境应该也无关；会不会是环境里装了别的什么库，然后对ops包下的某些api打了补丁，导致调用了不是原生mindspore原生的那个logsumexp？,经过再次测试确认了，已发布的2.5.0正式版的参数确实还是axis，但daily包的dev版本，确实换成dim了，上面的报错应该是用的dev版本 !输入图片说明
tanxinglian,"[CT][MS][OPS][mint.nn.functional.gelu][function][冒烟]mint.nn.functional.gelu报错TypeError: Failed calling gelu with ""gelu(Tensor, string)""."," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.gelu报错TypeError: Failed calling gelu with ""gelu(Tensor, string)"".  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_n_f_gelu_input_x_0d_float32_tanh >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0  910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_n_f_gelu.py::test_mint_n_f_gelu_input_x_0d_float32_tanh  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_mint_n_f_gelu_input_x_0d_float32_tanh():         input_x = Tensor(np.random.randn(), mstype.float32)         approximate = 'tanh'         fact = GeluMock(             attributes={'approximate': approximate},             inputs=[input_x]) >       fact.forward_cmp() ../test_mint_n_f_gelu.py:55:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/gelu_mint.py:126: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/mint/nn_functional/gelu_mint.py:55: in forward_mindspore_impl     out = net(self.input_x, self.approximate) ../../share/utils.py:288: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:742: in __call__     return self.construct(*args, **kwargs) ../../share/mint/nn_functional/gelu_mint.py:21: in construct     out = self.op(input_x, approximate) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  args = (Tensor(shape=[], dtype=Float32, value= 0.380577), 'tanh'), kwargs = {}     def gelu(*args, **kwargs):         r""""""         gelu(input, *, approximate='none') > Tensor         Gaussian Error Linear Units activation function.         GeLU is described in the paper `Gaussian Error Linear Units (GELUs) `_.         And also please refer to `BERT: Pretraining of Deep Bidirectional Transformers for Language Understanding         `_.         When `approximate` argument is `none`, GELU is defined as follows:         .. math::             GELU(x_i) = x_i*P(X >> import mindspore             >>> from mindspore import Tensor, mint             >>> input = Tensor(np.array([[1.0, 4.0, 8.0], [2.0, 5.0, 9.0]]), mindspore.float32)             >>> result = mint.nn.functional.gelu(x)             >>> print(result)             [[1.58655241e01  3.99987316e+00 0.00000000e+00]              [ 1.95449972e+00 1.41860323e06  9.0000000e+00]]             >>> result = mint.nn.functional.gelu(input, approximate=""tanh"")             >>> print(result)             [[1.58808023e01  3.99992990e+00 3.10779147e21]              [ 1.95459759e+00 2.29180174e07  9.0000000e+00]]         """""" >       return _gelu_instance(*args, **kwargs) E       TypeError: Failed calling gelu with ""gelu(Tensor, string)"". E       The valid calling should be: E       ""gelu(input=, *, approximate=)"" E        E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/pipeline/pynative/op_function/converter.h:141 Parse /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/functional_overload.py:1097: TypeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2321152541017505848&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03sk108qs1pcn%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_smoke_20250221%2003:36:50&isMergedTask=false&nodeDate=20250221&year=20242025&TestNow=true&testcaseid=67b780896c3f49211eb7a7ce&workspaceId=67b780864503c84f0af96220&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-21T15:13:02+08:00,"gitee,foruda,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBNWH3, Root Causes && Fix Solution 问题：入参不合法 根因： 接口变更，对齐torch2.1，该参数为关键字参数 !输入图片说明 已发送接口变更邮件，测试仓由测试进行适配  Appearance & Root Cause 问题：用例未适配 根因： 1、直接合入master转测，转测邮件发送较晚，导致测试未感知该变化并适配用例 Fix Solution 1、测试仓适配接口变更 Fix Description & Test Suggestion 无需合入，适配测试仓代码即可 测试建议：接口调用对齐torch Selftest Report & DT Review 无 是否需要补充 ST/UT：否 无需补充 原因：非问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81218 PR合入时间：2025年2月19日 问题是否偶现：否,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未对此问题进行问题分析 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,接口变更，对齐torch2.1，该参数为关键字参数，适配用例
Mrtutu,适配msprof HCCL字段变更,,2025-02-21T10:51:53+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBNTD7
林芃芃,mindspore.mint.nn.GroupNorm 接口存在边界值处理问题、错误检测延迟及错误信息不一致," 1.Describe the current behavior / 问题描述 实习任务 在测试`mindspore.mint.nn.GroupNorm`接口时，发现以下关键问题：  **边界值处理问题**：极大值输入导致计算异常，未抛出预期的异常，并返回全零结果。  **错误检测延迟**：MindSpore 的 `mint.nn.GroupNorm` 在 PyNative 和 Graph 模式下均未在初始化时验证输入通道数与 `num_channels` 的匹配性，错误延迟到执行阶段触发。  **错误消息不一致**：描述：MindSpore 的错误信息与预期不符，且不同错误用例的消息风格不统一，包含过多内部细节。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    test_groupnorm_edge_cases: 测试GroupNorm边界情况的准确性 >    test_groupnorm_error_messages: 测试GroupNorm错误信息的准确性 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode: Graph >    Excute Mode: PyNative  4.Steps to reproduce the issue / 重现步骤 1. 创建测试代码`test_groupnorm.py`： ```python import os import torch import torch.nn as nn import numpy as np import pytest import mindspore as ms from mindspore import Tensor import mindspore.mint as mint def compare_outputs(ms_output, torch_output, rtol=1e3, atol=1e3):     """"""比较MindSpore和PyTorch输出是否在误差范围内""""""     return np.allclose(ms_output.asnumpy(), torch_output.detach().numpy(), rtol=rtol, atol=atol) class TestGroupNorm:     def test_groupnorm_edge_cases(self):         """"""测试边界情况""""""         num_channels = 6          输入值边界情况         edge_inputs = [             (""极小值"", np.full((2, 6, 4, 4), 1e7, dtype=np.float32)),             (""极大值"", np.full((2, 6, 4, 4), 1e7, dtype=np.float32)),             (""全零"", np.zeros((2, 6, 4, 4), dtype=np.float32)),             (""全负值"", np.full((2, 6, 4, 4), 1e7, dtype=np.float32)),             (""最小维度"", np.full((2, 6, 1, 1), 1e7, dtype=np.float32))         ]          测试不同分组数和参数配置         for name, x_np in edge_inputs:             x_ms = Tensor(x_np, dtype=ms.float32)             x_torch = torch.tensor(x_np, dtype=torch.float32)             for num_groups in [1, 2, 3, 6]:                 if num_channels % num_groups == 0:                     for affine in [True, False]:                         for eps in [1e5, 1e10, 1e2]:   默认值、极小值、较大值                              MindSpore                             ms_groupnorm = mint.nn.GroupNorm(                                 num_groups=num_groups,                                 num_channels=num_channels,                                 eps=eps,                                 affine=affine,                                 dtype=ms.float32                             )                             ms_output = ms_groupnorm(x_ms)                              PyTorch                             torch_groupnorm = nn.GroupNorm(                                 num_groups=num_groups,                                 num_channels=num_channels,                                 eps=eps,                                 affine=affine                             )                             torch_output = torch_groupnorm(x_torch)                              检查 NaN 或 Inf                             ms_has_nan = np.any(np.isnan(ms_output.asnumpy()))                             ms_has_inf = np.any(np.isinf(ms_output.asnumpy()))                             torch_has_nan = np.any(np.isnan(torch_output.detach().numpy()))                             torch_has_inf = np.any(np.isinf(torch_output.detach().numpy()))                             assert not ms_has_nan and not ms_has_inf, f""MindSpore 输出包含 NaN 或 Inf: {name}, num_groups={num_groups}, affine={affine}, eps={eps}""                             assert not torch_has_nan and not torch_has_inf, f""PyTorch 输出包含 NaN 或 Inf: {name}, num_groups={num_groups}, affine={affine}, eps={eps}""                             assert compare_outputs(ms_output, torch_output), f""输出不匹配: {name}, num_groups={num_groups}, affine={affine}, eps={eps}""                             print(f""\n{name} 输入, num_groups={num_groups}, affine={affine}, eps={eps} 测试通过"")     def test_groupnorm_error_messages(self):         """"""测试错误信息的准确性和一致性""""""         error_cases = [             {                 'shape': (2, 4, 4, 4),   错误的channel数                 'num_groups': 2,                 'num_channels': 6,                 'error_type': ValueError,                 'error_msg': ""输入张量的通道数与指定的通道数不匹配""             },             {                 'shape': (2, 6, 4, 4),                 'num_groups': 4,   不能被channel数整除的group数                 'num_channels': 6,                 'error_type': ValueError,                 'error_msg': ""通道数必须能被组数整除""             },             {                 'shape': (2, 6),   维度不足                 'num_groups': 2,                 'num_channels': 6,                 'error_type': ValueError,                 'error_msg': ""输入张量的维度必须大于等于3""             }         ]         for i, case in enumerate(error_cases):             print(f""\n测试错误用例 {i+1}: {case['shape']}, num_groups={case['num_groups']}, num_channels={case['num_channels']}"")              MindSpore             x_np = np.random.randn(*case['shape']).astype(np.float32)             x_ms = Tensor(x_np, dtype=ms.float32)             ms_groupnorm = mint.nn.GroupNorm(                 num_groups=case['num_groups'],                 num_channels=case['num_channels'],                 dtype=ms.float32             )             try:                 ms_output = ms_groupnorm(x_ms)                 print(f""MindSpore 未抛出异常，输出范围: {ms_output.asnumpy().min()} ~ {ms_output.asnumpy().max()}"")             except Exception as e:                 print(f""MindSpore 抛出异常: {type(e).__name__}: {str(e)}"")                 assert isinstance(e, case['error_type']), f""错误类型不匹配: 期望 {case['error_type']}, 实际 {type(e)}""                 assert case['error_msg'] in str(e), f""错误信息不匹配: 期望包含 '{case['error_msg']}', 实际 '{str(e)}'""              PyTorch             x_torch = torch.tensor(x_np, dtype=torch.float32)             torch_groupnorm = nn.GroupNorm(                 num_groups=case['num_groups'],                 num_channels=case['num_channels']             )             try:                 torch_output = torch_groupnorm(x_torch)                 print(f""PyTorch 未抛出异常，输出范围: {torch_output.detach().numpy().min()} ~ {torch_output.detach().numpy().max()}"")             except Exception as e:                 print(f""PyTorch 抛出异常: {type(e).__name__}: {str(e)}"")                 assert isinstance(e, case['error_type']), f""PyTorch错误类型不匹配: 期望 {case['error_type']}, 实际 {type(e)}"" if __name__ == ""__main__"":     ms.set_context(mode=ms.PYNATIVE_MODE)     pytest.main([""v"", ""test_groupnorm.py""]) ``` 2. 运行测试代码： ```python pytest test_groupnorm.py v ``` 3. 观察测试日志中的错误信息  5.Describe the expected behavior / 预期结果  边界值测试用例 对于极大值输入（1e7），MindSpore 应输出与 PyTorch 一致的结果（例如 105.1445 或 4096.0，取决于 eps），反映正确的归一化和仿射变换。  错误信息测试用例 1. **通道数不匹配用例**：     **输入**：shape=(2, 4, 4, 4), num_groups=2, num_channels=6     **预期**：       抛出ValueError异常       错误信息包含""输入张量的通道数与指定的通道数不匹配"" 2. **组数不能被通道数整除用例**：     **输入**：shape=(2, 6, 4, 4), num_groups=4, num_channels=6     **预期**：       抛出ValueError异常       错误信息包含""通道数必须能被组数整除"" 3. **输入维度不足用例**：     **输入**：shape=(2, 6), num_groups=2, num_channels=6     **预期**：       抛出ValueError异常       错误信息包含""输入张量的维度必须大于等于3""  6.Related log / screenshot / 日志 / 截图 !输入图片说明  **边界值处理问题**      在 `""极大值""` 输入（`1e7`）的情况下，MindSpore 输出全零，而 PyTorch 输出 `105.1445`，两者的结果完全不匹配。          输入全为 `1e7`，均值和方差应接近零（方差接近于 0），加上 `eps=1e05`，分母应为 `sqrt(1e05)`，输出应为标量乘以 `gamma` 加 `beta`，而不是全零。      MindSpore 的全零输出表明其可能在处理极大值时存在数值截断或错误计算。      这表明 MindSpore 的 `mint.nn.GroupNorm` 在边界值（极大值）处理上存在问题，可能在数值计算或归一化逻辑中引入了不正确的行为。  **错误处理机制不完整，某些情况下没有抛出预期的异常**      在 `""极大值""` 测试中，MindSpore 未抛出任何异常，而是返回了全零输出，这与预期行为（应与 PyTorch 一致）不符。      理论上，如果归一化计算因数值问题（如分母接近零）而失效，MindSpore 应抛出异常或警告，而不是静默返回错误结果。       `test_groupnorm_error_messages` 显示，MindSpore 在通道数不匹配时抛出了 `ValueError`，但在边界值场景下未检测到问题。      这表明 MindSpore 的错误处理机制不完整。在极大值输入导致计算异常时，它未抛出预期异常，而是返回了不正确的结果（全零）。 !输入图片说明  **部分错误在执行阶段才被发现，而不是在初始化或参数验证阶段**      对于 `shape=(2, 4, 4, 4), num_channels=6`，MindSpore 在构造 `ms_groupnorm` 时没有抛出异常，而是在执行 `ms_groupnorm(x_ms)` 并尝试获取结果（`asnumpy()`）时才抛出 `ValueError`。      错误发生在 `stub_sync` 中，表明 MindSpore 使用了延迟计算（可能是图模式下的特性），直到实际执行时才验证参数。     这表明 MindSpore 的 `mint.nn.GroupNorm` 将部分错误检测推迟到了执行阶段，而不是在初始化或参数设置时提前验证。  **错误类型和消息不统一，相同的错误可能产生不同的错误信息**      当前用例的错误信息是：         ```         For GroupNorm, shape of weight and bias should be equal to input_x's channel dimension: 4, bug got shape: [const vector]{6}.         ```      这与预期的 `""输入张量的通道数与指定的通道数不匹配""` 不同，且措辞更偏向于内部实现（提到 `weight` 和 `bias`）。      如果对比其他用例（例如 `num_groups=4, num_channels=6`），MindSpore 可能抛出 `""For GroupNorm, the 'num_channels' must be divided by 'num_groups'""`，这与当前错误信息也不一致。     MindSpore 的错误消息在不同情况下不统一。对于相同的逻辑错误（参数不匹配），错误信息可能因上下文不同而变化（例如通道数不匹配 vs. 整除性问题）。这与 PyTorch 的错误信息（更简洁且一致）相比，显得不够统一。",2025-02-21T01:27:47+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNRAT,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
tanxinglian,[CT][MS][OPS][mint.scatter_add][function][全量]test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 910b偶现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 910b偶现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_f_scatter_add.py::test_dynamic_shape_mint_f_scatter_add_dyn_shape_2  disablewarnings count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```        (reason='aclnn算子没有开发CPU')     (reason='aclnn算子没有开发GPU')     (reason='aclnn算子没有开发GE流程')     def test_dynamic_shape_mint_f_scatter_add_dyn_shape_2():         input_x = Tensor(shape=(None, None, None, None, None, None, None), dtype=mstype.float16)         dim = mutable(input_data=4, dynamic_len=False)         index = Tensor(shape=(None, None, None, None, None, None, None), dtype=mstype.int32)         src = Tensor(shape=(None, None, None, None, None, None, None), dtype=mstype.float16)         input_x1 = Tensor(np.random.randn(2, 3, 3, 5, 1, 2, 4), mstype.float16)         dim1 = mutable(4)         index1 = Tensor(np.random.randint(0, [2, 3, 3, 5, 1, 2, 4][4]  1,                                           (2, 3, 3, 5, 1, 2, 4)), mstype.int32)         src1 = Tensor(np.random.randn(2, 3, 3, 5, 1, 2, 4), mstype.float16)         attributes1 = {'dim': dim1}         inputs1 = [input_x1, index1, src1]         input_x2 = Tensor(np.random.randn(5, 3, 9, 6, 3, 3, 2), mstype.float16)         dim2 = mutable(2)         index2 = Tensor(np.random.randint(0, [5, 3, 9, 6, 3, 3, 2][2]  1,                                           (5, 3, 9, 6, 3, 3, 2)), mstype.int32)         src2 = Tensor(np.random.randn(5, 3, 9, 6, 3, 3, 2), mstype.float16)         attributes2 = {'dim': dim2}         inputs2 = [input_x2, index2, src2]         input_x3 = Tensor(np.random.randn(8, 5, 9, 9, 9, 5, 7), mstype.float16)         dim3 = mutable(6)         index3 = Tensor(np.random.randint(0, [8, 5, 9, 9, 9, 5, 7][6]  1,                                           (8, 5, 9, 9, 9, 5, 7)), mstype.int32)         src3 = Tensor(np.random.randn(8, 5, 9, 9, 9, 5, 7), mstype.float16)         attributes3 = {'dim': dim3}         inputs3 = [input_x3, index3, src3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = ScatterAddMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (input_x, dim, index, src) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_mint_f_scatter_add.py:687:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/functional/scatter_add_mint.py:280: in forward_dynamic_shape_cmp     allclose_nparray(a, b, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[3.6182e01, 1.0654e+00, 1.4590e+00,  2.8784e01],             [1.7344e+00, 2.1035e+00, 2.9956e01, ... 2.0203e01, 7.8320e01],             [1.5254e+00,  5.6641e01, 1.8291e+00, 1.5283e+00]]]]]]],       dtype=float16) data_me = array([[[[[[[3.6182e01, 1.0654e+00, 1.4590e+00,  2.8784e01],             [1.7344e+00, 2.1035e+00, 2.9956e01, ... 2.0203e01, 7.8320e01],             [1.5254e+00,  5.6641e01, 1.8291e+00, 1.5283e+00]]]]]]],       dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0.0713] E       data_me_error:[0.0698] E       loss:[0.001465] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2305979040019775616&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03qp108bf8sh6%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250216%2005:23:08&isMergedTask=false&nodeDate=20250216&year=20242025&TestNow=true&testcaseid=67b1b9ddee88407fc8dce0e1&workspaceId=67b1b9d4a052d73253495445&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T17:32:35+08:00,"gitee,foruda",closed,0,7,https://gitee.com/mindspore/mindspore/issues/IBNP5E,现象：1220 CANN包没有问题，两种模式连跑100次不复现，怀疑是CANN最近更新引入的问题。,切换到0206 CANN包后，连跑24次没有复现问题，运行速度极慢，耗时将近一个小时，暂时无法复现问题。 !输入图片说明,"在测试环境上复现了, 同样的seed，放到222环境上不复现问题,识别到的差异是torch版本不一致，测试环境是1.12， 我们的是2.1",222 torch版本降低之后，复现问题： !输入图片说明 230测试环境： !输入图片说明 可以发现低版本精度问题一致，因此可以判断，该问题为torch版本过低导致的问题。 ps. 使用的seed为37639,将seed固定37639，分别跑torch高低版本，对比之后发现torch高低版本之间有差异： !输入图片说明 高版本torch 2.10： !输入图片说明 低版本torch 1.11: !输入图片说明 因此，本问题单精度问题确定为torch版本差异导致的。走回给测试。, Appearance & Root Cause 问题：test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 910b偶现精度问题 根因：验收的时候标杆用的torch 1.12版本，有偶现问题  Fix Solution 升级torch版本到2.1或者提升loss或者更换固定seed看护  Fix Description & Test Suggestion 如上  Selftest Report & DT Review 升级到torch 2.1，连跑100次pass: !输入图片说明  Introduction Analysis 引入类型：特性合入 特性引入原因：准备交付件的时候，只需所有用例一起跑一次，因为是精度问题（概率7%左右）没有暴露出来 引入pr: https://gitee.com/mindspore/mindspore/pulls/68411 pr合入时间：2025年2月19日 问题是否偶现：是,torch 2.1和1.12的输出结果有差异 torch升级到2.1.0 100次可以通过，待升级torch版本 !输入图片说明
tanxinglian,[CT][MS][OPS][tensor.baddbmm][function][冒烟]tensor.baddbmm报错TypeError和RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > tensor.baddbmm报错TypeError和RuntimeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_tensor_baddbmm_input_dtype_float32_3d >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0  910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v  test_f_baddbmm.py::test_tensor_baddbmm_input_dtype_float32_3d  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      def test_tensor_baddbmm_input_dtype_float32_3d():         input_list = []         x0 = Tensor(np.random.randn(128, 16, 16).astype(np.float32))         input_list.append(x0)         x1 = Tensor(np.random.randn(128, 16, 8).astype(np.float32))         input_list.append(x1)         x2 = Tensor(np.random.randn(128, 8, 16).astype(np.float32))         input_list.append(x2)         attributes = {'alpha': 8, 'beta': 40}         fact = BaddbmmMock(attributes=attributes, inputs=input_list)          910A 海思底层不支持fp32，会转成fp16运算         if MSContext.get_instance().get_ascend_soc_version() == 'ascend910':             fact.loss = 2e2 >       fact.forward_tensor_cmp() ../test_f_baddbmm.py:427:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/baddbmm_ops.py:110: in forward_tensor_cmp     out_mindspore = self.forward_mindspore_tensor_impl() ../../share/ops/functional/baddbmm_ops.py:98: in forward_mindspore_tensor_impl     out = net(self.input, self.batch1, self.batch2, self.beta, self.alpha) ../../share/utils.py:288: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:742: in __call__     return self.construct(*args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = WrapOp inputs = Tensor(shape=[128, 16, 16], dtype=Float32, value= [[[1.30350626e+00, 2.11461234e+00, 9.46608067e01 ... 1.31597543...15e+00],   [ 2.36984327e01, 7.63088405e01, 5.07046223e01 ... 4.80446875e01, 1.28654742e+00, 1.04887199e+00]]]) batch1 = Tensor(shape=[128, 16, 8], dtype=Float32, value= [[[1.52393794e+00,  1.07605040e+00, 8.56987119e01 ...  5.67518234e...04e01],   [8.72560591e02,  6.82220161e02,  7.46518001e02 ...  5.74400067e01, 8.68605971e01, 2.31278896e01]]]) batch2 = Tensor(shape=[128, 8, 16], dtype=Float32, value= [[[1.61519969e+00, 1.13037705e01, 4.08966541e01 ...  2.69104302e...85e+00],   [ 1.66387343e+00,  3.22911054e01,  5.48864603e01 ...  1.11430407e+00, 3.46323162e01,  6.69651628e02]]]) beta = 40, alpha = 8     def construct(self, inputs, batch1, batch2, beta, alpha): >       return inputs.baddbmm(batch1, batch2, beta, alpha) E       TypeError: Failed calling baddbmm with ""baddbmm(Tensor, Tensor, int, int)"". E       The valid calling should be: E       ""Tensor.baddbmm(batch1=, batch2=, *, beta=, alpha=)"" E       ""Tensor.baddbmm(batch1=, batch2=, *, beta=, alpha=)"" E        E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/pipeline/pynative/op_function/converter.h:141 Parse ../../share/ops/functional/baddbmm_ops.py:29: TypeError ``` ```       def test_tensor_baddbmm_input_dtype_float32_3d():         input_list = []         x0 = Tensor(np.random.randn(128, 16, 16).astype(np.float32))         input_list.append(x0)         x1 = Tensor(np.random.randn(128, 16, 8).astype(np.float32))         input_list.append(x1)         x2 = Tensor(np.random.randn(128, 8, 16).astype(np.float32))         input_list.append(x2)         attributes = {'alpha': 8, 'beta': 40}         fact = BaddbmmMock(attributes=attributes, inputs=input_list)          910A 海思底层不支持fp32，会转成fp16运算         if MSContext.get_instance().get_ascend_soc_version() == 'ascend910':             fact.loss = 2e2 >       fact.forward_tensor_cmp() ../test_f_baddbmm.py:427:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/baddbmm_ops.py:110: in forward_tensor_cmp     out_mindspore = self.forward_mindspore_tensor_impl() ../../share/ops/functional/baddbmm_ops.py:98: in forward_mindspore_tensor_impl     out = net(self.input, self.batch1, self.batch2, self.beta, self.alpha) ../../share/utils.py:288: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:731: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1149: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1132: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp, phase = 'train.1740014680927771392.281467199518448.0.....' do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[128, 16, 16], dtype=Float32, value= [[[4.93089229e01,  1.14876276e03,  1.68564007e01 ...  1.5353988...   [ 2.58607864e01,  5.18578470e01, 3.37702758e03 ...  1.46455872e+00, 1.25289917e+00, 3.99672180e01]]]), 40, 8) kwargs = {}, key_id = '2814671995184481740014680927771392', key = 0 parameter_ids = '', raw_phase = 'train' full_function_name = 'WrapOp.1.187650717963712', echo_function_name = 'WrapOp'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict) >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: Function:baddbmm_2 takes 3 positional arguments, but 3 were given. E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/core/ir/func_graph_extends.cc:83 GenerateVarParams E        E        E        The Traceback of Net Construct Code: E        E        0 In file /home/jenkinsslave/workspace/mindspore_ascend_opensource/MindSporeTest/share/ops/functional/baddbmm_ops.py:29, 15~58 E               return inputs.baddbmm(batch1, batch2, beta, alpha) E                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ E        (See file '/home/jenkinsslave/workspace/mindspore_ascend_opensource/MindSporeTest/operations/cida_test_tensor_baddbmm_input_dtype_float32_3d/rank_0/om/analyze_fail.ir' for more details. Get instructions about `analyze_fail.ir` at https://www.mindspore.cn/search?inputValue=analyze_fail.ir) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1918: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2317863798643359800&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_smoke_20250220%2000:56:03&isMergedTask=false&nodeDate=20250220&year=20242025&TestNow=true&testcaseid=67acacaa6c3f49211e92392e&workspaceId=67b60a3a4503c84f0af44949&sub=tab1 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2319273132049825799&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_smoke_reRun8115_20250220%2010:24:02&isMergedTask=false&nodeDate=20250220&year=20242025&TestNow=true&testcaseid=67ac9b676c3f49211e91ed8a&workspaceId=67b685ef6c3f49211eb4a37c    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T16:18:08+08:00,"gitee,foruda,rct/refactor,rca/inf/msg,ctl/testcismoke",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBNNU2, **Appearance & Root Cause**  现象：测试仓的Tensor.baddbmm算子用例报错 根因：Tensor.baddbmm算子进行了接口变更，beta和alpha参数变更为关键字参数 !输入图片说明  **Fix Solution**  使用关键字参数给Tensor.baddbmm算子进行传参。, **问题引入分析：** 用例未适配 原因：mindspore.Tensor.baddbmm接口变更，将beta和alpha变更为关键字参数，而开发未发邮件通知测试。 是否偶现：否,接口变更邮件已补发，需适配用例 !输入图片说明
LiWanpeng,mindir模型导入导出问题," 1.Describe the current behavior / 问题描述 1. mindir模型导入后重新组网后再导出会导致原有的权重丢失。 2. mindir模型导入后重新组网后再导出时，现有网络必须要保持原有mindir模型的算子实例不变，否则权重参数无法正确加载。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  无  4.Steps to reproduce the issue / 重现步骤  (1) 先生成CNN.mindir,源代码如下: ```  CNN.py import mindspore as ms import mindspore.ops as ops import numpy as np from mindspore import context, nn from mindspore.train.serialization import export context.set_context(mode=context.PYNATIVE_MODE, device_target=""CPU"") one_channel = True class SimpleCNN(ms.nn.Cell):     def __init__(self):         super().__init__()         if one_channel:             self.conv1 = nn.Conv2d(1, 32, kernel_size=3, has_bias=True)         else:             self.conv1 = nn.Conv2d(3, 32, kernel_size=3, has_bias=True)         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, has_bias=True)         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, has_bias=True)         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)         self.flatten = nn.Flatten()         self.dense1 = nn.Dense(32768, 64)         self.dense2 = nn.Dense(64, 5)         self.relu = nn.ReLU()     def construct(self, x):         x = self.relu(self.conv1(x))         x = self.pool1(x)         x = self.relu(self.conv2(x))         x = self.pool2(x)         x = self.relu(self.conv3(x))         x = self.pool3(x)         x = self.flatten(x)         x = self.relu(self.dense1(x))         x = self.dense2(x)         return x my_model = SimpleCNN() inputs = ms.Tensor(np.random.randn(1, 1, 128, 128).astype(np.float32)) context.set_context(mode=context.GRAPH_MODE) export(my_model, inputs, file_name=""CNN"", file_format=""MINDIR"") ``` 该代码生成的CNN.midir转成ms模型,模型图部分截图如下: !输入图片说明 (2)使用nn.GraphCell(ms.load(file_name=""CNN.mindir""))接口加载模型后再导出成SAR_CNN.mindir,源码如下: ``` import mindspore as ms import mindspore.ops as ops import numpy as np from mindspore import context, nn from mindspore.train.serialization import export context.set_context(mode=context.PYNATIVE_MODE, device_target=""CPU"") one_channel = True class SimpleCNN(ms.nn.Cell):     def __init__(self):         super().__init__()         if one_channel:             self.conv1 = nn.Conv2d(1, 32, kernel_size=3, has_bias=True)         else:             self.conv1 = nn.Conv2d(3, 32, kernel_size=3, has_bias=True)         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, has_bias=True)         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, has_bias=True)         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)         self.flatten = nn.Flatten()         self.dense1 = nn.Dense(32768, 64)         self.dense2 = nn.Dense(64, 5)         self.relu = nn.ReLU()         self.cnn = nn.GraphCell(ms.load(file_name=""CNN.mindir""))     def construct(self, x):         x = self.cnn(x)         return x my_model = SimpleCNN() inputs = ms.Tensor(np.random.randn(1, 1, 128, 128).astype(np.float32)) context.set_context(mode=context.GRAPH_MODE) export(my_model, inputs, file_name=""SAR_CNN"", file_format=""MINDIR"") ``` 该代码生成的SAR_CNN.midir转成ms模型,该模型和CNN.ms是一样的,  5.Describe the expected behavior / 预期结果 第二次生成的SAR_CNN.ms模型的Conv2DFusion算子的权重要和第一次生成的CNN.ms模型的Conv2DFusion算子的权重一致.  6.Related log / screenshot / 日志 / 截图 CNN.ms模型的第一个算子Conv2DFusion的权重如下图: !输入图片说明 SAR_CNN.ms模型的第一个算子Conv2DFusion的权重如下图: !输入图片说明",2025-02-20T16:00:32+08:00,"mindspore-assistant,foruda,www,www",progressing,0,8,https://gitee.com/mindspore/mindspore/issues/IBNNJX,Hi 。用例这里SAR_CNN.mindir是用新的SimpleCNN实例导出的，导出到SAR_CNN.mindir的权重，是从新的SimpleCNN实例里取的，而不是从GraphCell里面取的。我们不支持GraphCell实例里的权重跟父Cell实例里的权重去匹配，所以会出现用例里的这个问题。我们不推荐load(mindir)之后再对其网络结构进行改造，如果想改造网络结构，可以定义网络，保存ckpt并加载。,这个是用mindspore导出onnx的模型吗？,我看上面有描述.ms的模型，这个是要在哪里执行这个模型？相关信息麻烦提供详细点，从描述里没看出来，这个是要跑在什么硬件上以及这个导出的模型格式是啥,"不是,都是mindspore生成的midir模型,然后转ms模型",在cpu执行,"使用过这种方法解决,确实可行","(2)使用nn.GraphCell(ms.load(file_name=""CNN.mindir""))接口加载模型后再导出成SAR_CNN.mindir,源码如下: 这部分代码逻辑是为了干嘛？为什么已经导出mindir了，然后重新加载mindir；这个目前是不支持的； mindir的加载完之后直接进行推理即可，如果是服务器上cpu的推理，建议使用mindspore lite的推理方式，详细的可以参考mindspore官网教程： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/mindir/converter_tool.html https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/mindir/benchmark_tool.html 使用.mindir模型推理，.ms的模型一般适用于端上等算力有限场景","CNN.mindir模型是训练好的神经网络模型, 我们需要在CNN.mindir模型基础上添加一个新的分支, 转换成新的SAR_CNN.ms模型后会有两个图,其中CNN.ms模型的部分跑在是服务器上cpu的推理, 另一个图跑在我们的设备中.如下图:左边的是nn.GraphCell(ms.load(file_name=""CNN.mindir""))生成的,右边是我们在CNN.mindir基础上加的, 假如我们没有CNN.py源码,只有CNN.mindir模型,我们如何生成下图的情况, 并且不能改变CNN.ms模型各个算子的权重? !输入图片说明"
tanxinglian,[CT][MS][OPS][ops.embedding][function][全量]embedding 910A GE模式下有偶现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > embedding 910A GE模式下有偶现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_embedding_int64_0d__random_forward >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v  test_f_embedding.py::test_f_embedding_int64_0d__random_forward count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='not support,ver=2.3')     (reason='not support,ver=2.3')     def test_f_embedding_int64_0d__random_forward():         input_x = Tensor(np.random.randint(0, 6, ()), mstype.int64)         weight = Parameter(Tensor(np.random.randn(7, 4), mstype.float16), name='weight')         padding_idx = 4         max_norm = 0.4         norm_type = 0.4         scale_grad_by_freq = True         fact = EmbeddingMock(             attributes={'padding_idx': padding_idx, 'max_norm': max_norm, 'norm_type': norm_type,                         'scale_grad_by_freq': scale_grad_by_freq},             inputs=[input_x, weight])         fact.forward_cmp() >       fact.grad_cmp() ../test_f_embedding.py:91:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/embedding_ops.py:134: in grad_cmp     allclose_nparray(grad_pytorch, grad_mindspore, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]], dtype=float32) data_me = array([[ 0.    ,  0.    ,  0.    ,  0.    ],        [ 0.    ,  0.    ,  0.    ,  0.    ],        [ 0.    ,  0.    ,  0...  ,  0.    ],        [ 0.    ,  0.    ,  0.    ,  0.    ],        [ 0.    ,  0.    ,  0.    ,  0.    ]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0. 0. 0. 0.] E       data_me_error:[0.1635 0.3716  2.475  0.3943] E       loss:[0.16345215 0.37158203 2.4746094  0.3942871 ] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2305979040019775638&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03qp108bf8sh6%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250216%2010:57:17&isMergedTask=false&nodeDate=20250216&year=20242025&TestNow=true&testcaseid=67b20fb384dee72f16c059a6&workspaceId=67b23f817b13446a6133e808    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T15:32:49+08:00,"gitee,gitee,foruda,ctl/componenttest,rct/newfeature,rca/codelogic",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBNN3B, **Appearance & Root Cause**  问题：910A GE模式下，ops.embedding的测试仓用例test_f_embedding_int64_0d__random_forward反向过程中在特定输入下必现精度问题 根因：在ge模式下，当ops.embedding的输入参数padding_idx为负数时，没有像pynative模式和kbk模式的反向算子EmbeddingDenseBackward一样将padding_idx转换成对应的正数，导致反向输出与torch不一致。  **Fix Solution**  对GE模式的反向过程增加pass代码，在pass代码中判断padding_idx是否为负数，若padding_idx为负数则将其转换成对应的正数。  **Fix Description & Test Suggestion**  https://gitee.com/mindspore/mindspore/pulls/82083 PR合入后daily包回归 测试建议：安装了PR合入后的daily包，在910A GE模式下跑test_f_embedding_int64_0d__random_forward用例。  **Selftest Report & DT Review**  修改后，910A GE模式下跑test_f_embedding_int64_0d__random_forward用例可以通过 是否需要补充 ST/UT：否 原因：为测试仓的GE模式问题，不需要不充st和ut用例  **Introduction Analysis**  引入类型：特性合入引入 特性引入原因：ops.embedding的GE模式没有跟pynative和kbk模式对齐，未对padding_idx为负数的场景做适配。 引入PR：https://gitee.com/mindspore/mindspore/pulls/66585 PR合入时间：2024年/3月/29日 问题是否偶现：否,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 自测结果 & 审核结果 (Selftest Report & DT Review) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,"【回归版本号】：__commit_id__ = '[sha1]:ba6873c3,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
LiWanpeng,"mindsporelite 多线程跑模型,子图没有输入时程序死循环"," 1.Describe the current behavior / 问题描述 mindsporelite多线程推理模型,同时存在CPU设备和自定义设备时,模型中存在子图没有输入的情况下,程序进入等待状态,没有跑出结果.  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 ( 无  4.Steps to reproduce the issue / 重现步骤  (1)写一个自定义算子,该算子在自定义设备上运行. ```  complexabs.py import mindspore as ms import numpy as np from mindspore import nn from mindspore.common import dtype as mstype class ComplexAbs(nn.Cell):     def __init__(self):         super(ComplexAbs, self).__init__()         self.op_type = ""Custom_FT_ComplexAbs""         self.op = ms.ops.Custom(             self.kernel,             out_shape=self.infer_shape,             out_dtype=self.infer_dtype,             func_type=""pyfunc"",         )         self.op.add_prim_attr(""type"", self.op_type)     def infer_dtype(self, input):         if input == mstype.TensorType(mstype.complex64):             return ms.float32         elif input == mstype.TensorType(mstype.complex128):             return ms.float64         else:             raise ValueError(""Unsupported data type {}"".format(input))     def infer_shape(self, input):         return input     def kernel(self, input):         out = np.absolute(input)         return out     def construct(self, input):         output = self.op(input)         return output ``` (2)生成模型,该模型自由两个算子,一个CPU的Greater算子,一个是自定义设备的Custom_FT_ComplexAbs算子. ``` import mindspore as ms import numpy as np from mindspore import nn, ops import mindradar as mr class test(nn.Cell):     def __init__(self, LFM):         super(test, self).__init__()         self.LFM = ms.Tensor(LFM)         self.greater = ops.Greater()         self.complexabs = mr.ComplexAbs()     def construct(self, x):         y = self.complexabs(self.LFM)         x = ops.greater(x, y)         return x x = np.ones((3, 3), dtype=np.float32) x_t = ms.Tensor(x) LFM = np.ones((3), dtype=np.complex64) LFM_t = ms.Tensor(LFM) model = test(LFM) out = model(x_t) print(""out:"", out) ms.export(     model,     x_t,     file_name=""test"",     file_format=""MINDIR"", ) ``` 生成的test.mindir模型转ms模型,同时存在CPU设备和自定义设备时,mindsporelite将该模型分成两个子图,Greater算子是一个子图, Custom_FT_ComplexAbs算子是一个子图,其中Custom_FT_ComplexAbs算子的子图没有输入,只有常量. !输入图片说明  5.Describe the expected behavior / 预期结果 mindsporelite推理该模型能够正常结束.  6.Related log / screenshot / 日志 / 截图 mindsporelite多线程推理该模型时, 程序在mindspore/lite/src/litert/mindrt_executor.cc的MindrtRun函数collect.Wait();等待状态.",2025-02-20T15:05:30+08:00,"mindspore-assistant,foruda",progressing,0,2,https://gitee.com/mindspore/mindspore/issues/IBNMJM,"生成的test.mindir模型转ms模型,同时存在CPU设备和自定义设备时,mindsporelite将该模型分成两个子图,Greater算子是一个子图, Custom_FT_ComplexAbs算子是一个子图,其中Custom_FT_ComplexAbs算子的子图没有输入,只有常量. 描述清楚点，什么是自定义设备？还有就是没有子图吧，截图里面没有看到子图","`自定义设备是我们自己添加的一个设备,类似与GPU/opencl设备,你们可以将Custom_FT_ComplexAbs算子注册在GPU/opencl设备中, 然后在mindspore lite跑该模型,会在调试信息看到它们属于两个图,如下: 其中MT7004SubGraph0,是将Custom_FT_ComplexAbs算子划分到自定义设备 ` !输入图片说明"
虞良斌,Fixed bugs about printing synchronous and asynchronous parsing logs,,2025-02-20T15:04:19+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBNMIX
tanxinglian,[CT][MS][OPS][mint.nn.functional.gelu][function][全量]mint.nn.functional.gelu bf16偶现精度不达标," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.gelu bf16偶现精度不达标  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_n_f_gelu_bfloat16_2d_128x2_random_forward_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations export CONTEXT_JIT_LEVEL=O0 > （3）pytest s v  test_mint_n_f_gelu.py::test_mint_n_f_gelu_bfloat16_2d_128x2_random_forward_broadcast count 200  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： 200次出现10次精度不达标 ```      ()     (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_mint_n_f_gelu_bfloat16_2d_128x2_random_forward_broadcast():         input_x = Tensor(np.random.randint(768, 367, (128, 2)), mstype.bfloat16)         approximate = 'tanh'         fact = GeluMock(             attributes={'approximate': approximate},             inputs=[input_x])         fact.forward_cmp() >       fact.grad_cmp() ../test_mint_n_f_gelu.py:443:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/gelu_mint.py:133: in grad_cmp     allclose_nparray(grad_pytorch, grad_mindspore, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[ 1.421875  ,  0.04516602],        [ 0.47851562, 0.        ],        [ 0.        , 1.28125   ],        [ 0.02...      [ 0.        , 0.        ],        [ 0.203125  , 0.41796875],        [0.        , 0.        ]], dtype=float32) data_me = array([[ 1.4218750e+00,  4.5166016e02],        [ 4.7851562e01, 0.0000000e+00],        [ 0.0000000e+00, 1.2812500e+...+00, 0.0000000e+00],        [ 2.0312500e01, 4.1796875e01],        [0.0000000e+00, 0.0000000e+00]], dtype=float32) rtol = 0.004, atol = 0.004     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0.01696777 1.2109375 ] E       data_me_error:[0.01049805 1.1953125 ] E       loss:[0.00646973 0.015625  ] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2305979040019775615&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03qp108bf8sh6%2F&title=CT_mindspore_ascend910b_op_pynative_standalone_full_20250216%2014:40:00&isMergedTask=false&nodeDate=20250216&year=20242025&TestNow=true&testcaseid=67b4e1f84503c84f0af03d6f&workspaceId=67b4e1f7a052d7325353f5fa&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T14:58:58+08:00,"gitee,sig/ops,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBNMGH, Appearance & Root Cause 问题：精度问题 根因： 测试环境标杆为torch1.12，开发环境标杆为torch2.1，torch高低版本存在差异导致偶现精度问题，接口预期对标标杆为torch2.1  Fix Solution 无需修复  Fix Description & Test Suggestion 无 测试建议：使用torch2.1作为标杆  Selftest Report & DT Review 无 是否需要补充 ST/UT：否 原因：非问题  Introduction Analysis 引入类型：环境问题 引入PR：无 PR合入时间：无 问题是否偶现：是,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未对此问题进行问题分析 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,测试环境标杆为torch1.12，开发环境标杆为torch2.1，torch高低版本存在差异导致偶现精度问题，接口预期对标标杆为torch2.1 标杆升为torch2.1，执行200次成功 !输入图片说明
LiWanpeng,cast 算子对复数数据类型的转换不准确," 1.Describe the current behavior / 问题描述 cast算子在对数据类型为 Complex128 的数据强制类型转换成 Complex64 或 Complex64 转 Complex128 时，输出的复数虚部全为 0.  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  无  4.Steps to reproduce the issue / 重现步骤 ``` import mindspore as ms import numpy as np from mindspore import ops cast = ops.Cast() x = np.exp(3j * np.pi * np.arange(10) / 10).reshape(2, 5).astype(np.complex128) t = ms.Tensor(x) print('t:\n', t.type) y = cast(t, ms.complex64) print('y:\n', y.type) x1 = np.exp(3j * np.pi * np.arange(10) / 10).reshape(2, 5).astype(np.complex64) t1 = ms.Tensor(x1) print('t1:\n', t1.type) y1 = cast(t1, ms.complex128) print('y1:\n', y1.type) ```  5.Describe the expected behavior / 预期结果  > **【预期结果】**：cast算子对complex64转complex128 或者complex128转complex64时,虚部结果不为0.  6.Related log / screenshot / 日志 / 截图 !错误结果  ",2025-02-20T09:32:31+08:00,"gitee,mindspore-assistant",progressing,0,2,https://gitee.com/mindspore/mindspore/issues/IBNI23,  ,您好，该问题在MindSpore最新master分支代码已经修复：https://gitee.com/mindspore/mindspore/pulls/81748
fangfangssj,mint.nn.functional.dropout在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mint.nn.functional.dropout在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_dropout.py::test_dropout_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_dropout_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10, 3).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              生成权重和偏置             weight_data = np.random.randn(2, 3).astype(np.float32)             ms_weight = ms.tensor(weight_data, dtype)             torch_weight = torch.tensor(weight_data, dtype=torch_dtype)             bias_data = np.random.randn(2).astype(np.float32)             ms_bias = ms.tensor(bias_data, dtype)             torch_bias = torch.tensor(bias_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.dropout(ms_input, ms_weight, ms_bias)             torch_output = torch.nn.functional.dropout(torch_input, torch_weight, torch_bias)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T23:28:33+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGXF,"1. 对比910B mindspore精度需要安装torch_npu，请根据当前环境信息安装对应版本torch_npu 2. dropout为随机数算子，进行精度对比时需要控制mindspore与torch初始状态一致，不传入generator状态时建议使用manul_seed接口设置默认generator的初始状态 样例修改后可通过 ``` import pytest import torch, torch_npu import numpy as np import mindspore as ms from mindspore import mint .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_dropout_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]      dropout是随机数算子，如要进行精度对比，需要配置seed使得torch和mindspore初始状态一致     ms.manual_seed(0)     torch.manual_seed(0)     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10, 3).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)              torch tensor放置到npu上，             torch_input = torch.tensor(input_data, dtype=torch_dtype).npu()              设置丢弃概率             p = 0.5              计算输出             ms_output = mint.nn.functional.dropout(ms_input, p)             torch_output = torch.nn.functional.dropout(torch_input, p)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).cpu().numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.cpu().numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```"
fangfangssj,mint.nn.functional.dropout在910b上静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.functional.dropout在910b上静态图无法计算  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_dropout.py::test_dropout_all_dtypes  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_dropout_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5, 3).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 dropout 函数             ms_output = mint.nn.functional.dropout(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)             print(e)         try:              调用 dropout 函数             torch_output = torch.nn.functional.dropout(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T23:17:20+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGWH,!输入图片说明 执行该用例未复现ISSUE描述的问题，请排查环境是否安装正确，mindspore与CANN版本是否配套，或更新至最新的发布版本观察问题是否复现。
fangfangssj,mint.nn.functional.dropout希望支持float64, Backgroud（背景信息） 测试mint.nn.functional.dropout这个api的时候，发现CANN后端不支持float64，但torch却支持。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch。,2025-02-19T23:16:06+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGWG,"受CANN功能限制，当前仅支持bfloat16、float16以及float32数据类型 torch + npu亦不支持float64精度类型，可使用如下脚本进行验证： ``` import torch, torch_npu x = torch.ones(5, 5).to(torch.float64).npu() torch.nn.functional.dropout(x) ```"
fangfangssj,mint.nn.functional.linear在910b上float32运算有较大精度误差," 1.Describe the current behavior / 问题描述  mint.nn.functional.linear在910b上float32运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_linear.py::test_linear_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_linear_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10, 3).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              生成权重和偏置             weight_data = np.random.randn(2, 3).astype(np.float32)             ms_weight = ms.tensor(weight_data, dtype)             torch_weight = torch.tensor(weight_data, dtype=torch_dtype)             bias_data = np.random.randn(2).astype(np.float32)             ms_bias = ms.tensor(bias_data, dtype)             torch_bias = torch.tensor(bias_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.linear(ms_input, ms_weight, ms_bias)             torch_output = torch.nn.functional.linear(torch_input, torch_weight, torch_bias)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float32运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T22:58:01+08:00,gitee,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGU7,bfloat16数据类型由于浮点精度差异，误差标准为4e3，可使用该精度标准执行用例
fangfangssj,mint.nn.functional.linear希望支持int8，int16，int32，int64，uint8，float64，complex64，complex128, Backgroud（背景信息） 测试mint.nn.functional.linear这个api的时候，发现CANN后端不支持int8，int16，int32，int64，uint8，float64，complex64，complex128的数据类型。 torch却均支持。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch，复数在科学计算等方面具有广泛的应用，框架的原生支持有助于mindspore用于ai4s方向,2025-02-19T22:50:23+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGTD,受底层CANN限制，暂不支持整型输入和复数型输入，torch_npu也未支持该数据类型
fangfangssj,mint.nn.functional.tanh在910b上float32运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.tanh在910b上float32运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_tanh.py::test_tanh_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_tanh_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.tanh(ms_input)             torch_output = torch.nn.functional.tanh(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float32运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T22:21:29+08:00,"gitee,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGQ1,使用mindspore 2.5.0版本在Ascend环境中未复现了开发者描述的问题，且提供的测试代码中数据类型未对应。 修改为正确代码后通过测试，与torchnpu结果一致 !输入图片说明
fangfangssj,"mint.nn.functional.tanh希望支持float64,complex64,complex128"," Backgroud（背景信息） 测试mint.nn.functional.tanh这个api的时候，发现CANN后端不支持float64,complex64,complex128的数据类型。 torch却支持float64,complex64,complex128。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch，复数在科学计算等方面具有广泛的应用，框架的原生支持有助于mindspore用于ai4s方向",2025-02-19T22:14:07+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGNO,"在910b环境中，torchnpu2.4.0和mindspore 2.5.0一致，均不支持float64,complex64,complex128，但是torchGPU是支持的。 后续mindspore将会增加支持"
虞良斌,Added the profiling compatibility check module,,2025-02-19T17:35:41+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBNF3F
b_rookie,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/nn/mindspore.nn.Dense.html?highlight=densemindspore.nn.Dense 2. 【Issues Section】/【问题文档片段】 > bias_init weight_init应该写清楚支持哪些初始化方式，不然用户怎么知道写什么 3. 【Issues Section】/【问题文档片段】 易用性：  >  关键步骤错误或缺失，无法指导用户完成任务；  >  缺少主要功能描述、关键词解释、必要前提条件、注意事项等；  >  描述内容存在歧义指代不明、上下文矛盾；  >  逻辑不清晰，该分类、分项、分步骤的没有给出； 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-02-19T17:27:13+08:00,"gitee,www",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNEW2,得分：2 类型：易用性 活动链接（可查询积分）：https://www.mindspore.cn/feedback 欢迎您提交更多issue或PR，获得更多积分。
xiedejin1,【AR】Tensor.remainder_  Ascend后端 未接入KBK," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > Tensor.remainder_ 算子Ascend后端正向目前不支持 KBK  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B`/`Mac CPU`)    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * 见日志 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 执行测试仓用例  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 功能达标  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  7.Special notes for this issue/备注 (Optional / 选填)",2025-02-19T16:17:45+08:00,"gitee,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBNDNV
jiangchenglin3,Sharding Propagation mint op,**What type of PR is this?** /kind refactor **What does this PR do / why do we need it**: Refactor strategy propagation for broadcast operator **Which issue(s) this PR fixes**:  Fixes  **Code review checklist 【代码检视checklist说明】**: +  [ ] 是否进行返回值校验 (禁止使用void屏蔽安全函数、自研函数返回值，C++标准库函数确认无问题可以屏蔽) +  [ ] 是否遵守 ***SOLID原则 / 迪米特法则*** +  [ ] 是否具备UT测试用例看护 && 测试用例为有效用例 (若新特性无测试用例看护请说明原因) +  [ ] 是否为对外接口变更 +  [ ] 是否涉及官网文档修改   ,2025-02-19T15:27:01+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBNCNR
wqx,使用2.5.0版本导出mindir出现2GB容量的限制,尝试在2.5.0昇腾环境尝试了把DeepSeekR1DistillQwen1.5B导出为MINDIR格式，但出现了不能超过2GB的限制： !输入图片说明 尝试在GPU环境也有一样的情况： !输入图片说明 模型确定是能够静态图推理的；这个模型大小差不多3.5GB，我以前就导出过14GB左右的chatglm2 6b模型的mindir文件，这某个版本的bug吗？还是使用上有什么限制，或者需要设置什么？文档上也只说了onnx和air格式才有2GB的限制，没说mindir有这个限制： !输入图片说明,2025-02-19T14:47:35+08:00,"gitee,mindspore-assistant",open,0,4,https://gitee.com/mindspore/mindspore/issues/IBNC0V,这个报错是在三方库 Protobuf 。 mindir是基于protocol buffers实现的，所以会有2GB的限制, 只要使用protocol buffers作为序列化格式，就会收到单条消息最大2GB的限制,那我以前用mindformers套件里的chatglm6b模型导出过mindir，那个模型导出后总大小有12GB以上，那个是怎么做到的呢？当然他那个导出后不是一个mindir文件，而是有一个比较小的mindir文件，然后里面还有一个文件夹，里面有多个文件，好像是mindir具体的权重数据文件？当时用的导出方法是完全一样的，不知道当时是怎么导出来的？,"找出占用大量空间的常量的tensor 把他们定义为parameter 就可以了, 你用的大模型没有包含大常量tensor，一般情况是没有这种大常量的。网络模型一般就几十M就算是比较大的模型了；例如38B，是只参数parmater的规模；"
majun-bot,CVE202525469,"一、漏洞信息 漏洞编号：CVE202525469 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg gitmaster before commit d5873b was discovered to contain a memory leak in the component libavutil/iamf.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:54:03 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202525469 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:54:03+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBN86X,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：6.5 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。
majun-bot,CVE202525471,"一、漏洞信息 漏洞编号：CVE202525471 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg git master before commit fd1772 was discovered to contain a NULL pointer dereference via the component libavformat/mov.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:53:58 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202525471 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 4.3 &emsp;Vector： CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:53:58+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBN86W,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：4.3 MEDIUM  Vector：CVSS:3.1/AV:A/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。
majun-bot,CVE202522921,"一、漏洞信息 漏洞编号：CVE202522921 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg gitmaster,N113007g8d24a28d06 was discovered to contain a segmentation violation via the component /libavcodec/jpeg2000dec.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:53:47 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202522921 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 发现FFmpeggitmaster,N113007g8d24a28d06通过组件/libavcodec/jpeg2000dec.c包含分段违规。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:53:48+08:00,"gitee,foruda,ctl/componenttest,rca/others,rct/oldrelease,CVE/FIXED",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBN86O,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142","影响性分析说明： 发现 FFmpeg gitmaster,N113007g8d24a28d06 通过组件 /libavcodec/jpeg2000dec.c 包含分段违规。 漏洞评分(MindSpore评分):  BaseScore：6.5 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响","经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",开发已合入修复代码 !输入图片说明
majun-bot,CVE202525473,"一、漏洞信息 漏洞编号：CVE202525473 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg git master before commit c08d30 was discovered to contain a NULL pointer dereference via the component libavformat/mov.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:53:44 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202525473 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 发现提交c08d30之前的FFmpeggitmaster通过组件libavformat/mov.c包含一个空指针取消引用。 漏洞评分(MindSpore评分): &emsp;BaseScore： 5.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:53:45+08:00,"gitee,foruda,ctl/componenttest,rca/others,rct/oldrelease,CVE/FIXED",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBN86M,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 发现提交 c08d30 之前的 FFmpeg git master 通过组件 libavformat/mov.c 包含一个空指针取消引用。 漏洞评分(MindSpore评分):  BaseScore：5.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",开发已合入修复代码 !输入图片说明
majun-bot,CVE202525468,"一、漏洞信息 漏洞编号：CVE202525468 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg gitmaster before commit d5873b was discovered to contain a memory leak in the component libavutil/mem.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:53:34 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202525468 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞官网定义为无效漏洞，不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:53:34+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBN86E,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞官网定义为无效漏洞，不受影响。 漏洞评分(MindSpore评分):  BaseScore：6.5 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",该漏洞官网定义为无效漏洞，不受影响。
majun-bot,CVE202522919,"一、漏洞信息 漏洞编号：CVE202522919 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A reachable assertion in FFmpeg gitmaster commit N113007g8d24a28d06 allows attackers to cause a Denial of Service (DoS) via opening a crafted AAC file. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:51:18 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202522919 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： FFmpeggitmaster提交N113007g8d24a28d06中的可达断言允许攻击者通过打开精心设计的AAC文件来引发拒绝服务(DoS)。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:51:19+08:00,"gitee,foruda,ctl/componenttest,rca/others,rct/oldrelease,CVE/FIXED",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBN84K,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： FFmpeg gitmaster 提交 N113007g8d24a28d06 中的可达断言允许攻击者通过打开精心设计的 AAC 文件来引发拒绝服务 (DoS)。 漏洞评分(MindSpore评分):  BaseScore：6.5 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",开发已合入相关修复代码 !输入图片说明
Mrtutu,动态profiling参数校验问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 动态profiling参数校验问题 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-19T09:40:09+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBN7Z1
fangfangssj,mint.nn.functional.softshrink希望支持float64, Backgroud（背景信息） 测试mint.nn.functional.softshrink这个api的时候，发现CANN后端不支持float64，但torch却支持。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch。,2025-02-19T01:23:29+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN71C
fangfangssj,mint.nn.functional.softplus在静态图下前向传播报错," 1.Describe the current behavior / 问题描述  mint.nn.functional.softplus在静态图下前向传播报错。  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_softplus.py::test_forward_backward  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_forward_backward(mode):     ms.set_context(mode=mode)     class SimpleModel(nn.Module):         def __init__(self):             super(SimpleModel, self).__init__()             self.linear = nn.Linear(3, 3)   输入维度为3，输出维度也为3         def forward(self, x):             return torch.nn.functional.softplus(self.linear(x))     class SimpleModelMS(mnn.Cell):         def __init__(self):             super(SimpleModelMS, self).__init__()             self.linear = mnn.Dense(3, 3)   输入维度为3，输出维度也为3         def construct(self, x):             return mint.nn.functional.softplus(self.linear(x))      创建固定输入和权重     input_data_np = np.array([[1.5, 2.3, 3.6], [1.2, 0.4, 0.9]], dtype=np.float32)     weight_np = np.random.randn(3, 3).astype(np.float32)     bias_np = np.random.randn(3).astype(np.float32)      PyTorch模型设置     model_torch = SimpleModel()     model_torch.linear.weight.data = torch.tensor(weight_np)       model_torch.linear.bias.data = torch.tensor(bias_np)     input_torch = torch.tensor(input_data_np, requires_grad=True)      MindSpore模型设置     model_ms = SimpleModelMS()     model_ms.linear.weight.set_data(Tensor(weight_np))   不需要转置     model_ms.linear.bias.set_data(Tensor(bias_np))     input_ms = Tensor(input_data_np, dtype=ms.float32)      正向传播     output_torch = model_torch(input_torch)     output_ms = model_ms(input_ms).asnumpy()      比较正向传播结果     diff = np.abs(output_torch.detach().numpy()  output_ms)     if np.all(diff  **【预期结果】**：应该可以支持静态图运行  6.Related log / screenshot / 日志 / 截图 !输入图片说明 def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):函数中报错 !框架内部报错",2025-02-19T01:20:56+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN71A
fangfangssj,mint.nn.functional.softplus希望支持float64, Backgroud（背景信息） 测试mint.nn.functional.softplus这个api的时候，发现CANN后端不支持float64，但torch却支持。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch。,2025-02-19T01:15:42+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN718
fangfangssj,mint.nn.functional.softmax在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.softmax在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_softmax.py::test_softmax_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_softmax_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.float64, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.softmax(ms_input)             torch_output = torch.nn.functional.softmax(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T01:08:06+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN713
fangfangssj,"mint.nn.functional.silu希望支持float64,complex64,complex128"," Backgroud（背景信息） 测试mint.nn.functional.silu这个api的时候，发现CANN后端不支持float64,complex64,complex128的数据类型。 torch却支持float64,complex64,complex128。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch，复数在科学计算等方面具有广泛的应用，框架的原生支持有助于mindspore用于ai4s方向",2025-02-19T00:57:12+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN70X,"受CANN功能限制，当前并未支持float64,complex64,complex128， torch + npu亦不支持，可使用如下脚本进行验证： ``` import torch, torch_npu x = torch.tensor([1.0, 0.0, 1.0], dtype=torch.float64).npu() torch.nn.functional.silu(x) ```"
fangfangssj,mint.nn.functional.sigmoid在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.sigmoid在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_sigmoid.py::test_sigmoid_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_sigmoid_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.float64, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.sigmoid(ms_input)             torch_output = torch.nn.functional.sigmoid(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T00:44:27+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN70M,在910B环境下，复现以上问题，MindSpore 2.5.0版本与torchnpu结果一致，未出现精度问题。
fangfangssj,mint.nn.functional.sigmoid支持的数据类型描述不符,1. 【Document Link】/【文档链接】 https://www.mindspore.cn/docs/zhCN/r2.4.0/api_python/mint/mindspore.mint.nn.functional.silu.html 2. 【Issues Section】/【问题文档片段】 !输入图片说明 3. 【Existing Issues】/【存在的问题】 文档中对api支持参数的数据类型描述不全，异常的描述有问题。测试后发现api还支持bfloat16 4. 【Expected Result】【预期结果】 增加对应类型的数据类型描述,2025-02-19T00:36:12+08:00,"gitee,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBN70D,无明显问题，可补充 TypeError  input 不是Tensor,标题与文档链接不符
fangfangssj,import mindspore后再import torch出现报错," 1.Describe the current behavior / 问题描述  import mindspore后再import torch出现报错，但在import torch后再import mindspore不会报错。  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 import mindspore import torch  4.Steps to reproduce the issue / 重现步骤 import mindspore import torch  5.Describe the expected behavior / 预期结果 > **【预期结果】**：两者不同的import顺序均不报错  6.Related log / screenshot / 日志 / 截图 完整日志： Traceback (most recent call last):   File ""/tmp/code/mindsporetest/test/test.py"", line 2, in      import torch   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/torch/__init__.py"", line 237, in      from torch._C import *   noqa: F403 ImportError: /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/torch/lib/../../torch.libs/libgomp74ff64e9.so.1.0.0: cannot allocate memory in static TLS block",2025-02-19T00:21:13+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN6ZM, 解决库依赖问题的环境变量设置 export LD_PRELOAD=$LD_PRELOAD:/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/torch/lib/ ../ ../torch.libs/libgomp74ff64e9.so.1.0.0
baishanyang,[MS] InplacePutGrad求反向函数位置规整,,2025-02-18T20:35:44+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN6AM
虞良斌,Fixed single npu profiler error,,2025-02-18T14:56:06+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBN1WN
fengyuebo2025,【开源实习】mindspore.mint接口测试任务9atan2," 1.Describe the current behavior / 问题描述  在测试接口mint.atna2的反向传播梯度时，GRAPH_MODE模式下compile graph failed，但在PYNATIVE_MODE模式下可以正常运行。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_atan2.py::test_any_random_input_fixed_dtype  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms def test_any_forward_back(mode):     """"""使用Pytorch和MindSpore, 固定输入和权重, 测试正向推理结果和反向梯度""""""     ms.set_context(mode=mode)     dtype_ms = ms.float32     dtype_torch = torch.float32     input_data = [[0.1,0.2],[0.33,0.44],[0,0.5]]     other_data = [[0.4,0.1],[0.1,0.4],[0.5,0]]     torch_inp = torch.tensor(input_data, dtype=dtype_torch, requires_grad=True)     torch_oth = torch.tensor(other_data, dtype=dtype_torch, requires_grad=True)     ms_inp=ms.Tensor(input_data, dtype_ms)     ms_oth=ms.Tensor(other_data, dtype_ms)     def forward_pt(x,y):         return torch.atan2(x,y)     def forward_ms(x,y):          return x+y         return ms.mint.atan2(x,y)     5.1测试正向推理结果是否小于1e3     torch_res=forward_pt(torch_inp,torch_oth)     ms_res=forward_ms(ms_inp,ms_oth)     5.2测试反向传播梯度     torch_res.backward(torch.ones_like(torch_res))     torch_inp_grad=torch_inp.grad     torch_oth_grad=torch_oth.grad     grad_fn = ms.value_and_grad(forward_ms,grad_position=(0,1))     _, gradient_ms = grad_fn(ms_inp,ms_oth)     ms_inp_grad=gradient_ms[0]     ms_oth_grad=gradient_ms[1] test_any_forward_back(ms.GRAPH_MODE) ```  5.Describe the expected behavior / 预期结果  _, gradient_ms = grad_fn(ms_inp,ms_oth)处报错，RuntimeError: Compile graph kernel_graph0 failed. 报错关键日志截图： !输入图片说明",2025-02-18T14:46:58+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN1SX,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
fengyuebo2025,【开源实习】mindspore.mint接口测试任务9," 1.Describe the current behavior / 问题描述  在输入为float16类型时，mint.atan2接口的输出有时和torch.atan2接口输出差值大于1e3；且目前测试时，绝对误差值均为0.001953。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_atan2.py::test_any_random_input_fixed_dtype  4.Steps to reproduce the issue / 重现步骤  ``` import mindspore as ms import torch inp= [0.24023] oth= [0.59326] ms_i=ms.Tensor(inp,ms.float16) ms_o=ms.Tensor(oth,ms.float16) pt_i=torch.tensor(inp,dtype=torch.float16) pt_o=torch.tensor(oth,dtype=torch.float16) r1=ms.mint.atan2(ms_i,ms_o) r2=torch.atan2(pt_i,pt_o) print(f""mindspore输出为{r1},pytorch输出为{r2},绝对误差为{r1.asnumpy()r2.numpy()}"") ```  5.Describe the expected behavior / 预期结果  mindspore输出为[2.756],pytorch输出为tensor([2.7578], dtype=torch.float16),绝对误差为[0.001953] 报错关键日志截图： !输入图片说明",2025-02-18T14:40:49+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN1P8,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致，未出现精度问题。 !输入图片说明
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.remainder_(%=), Tasks 转测对象：Tensor.remainder_(符号%=) ,2025-02-18T12:50:59+08:00,"gitee,v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN0F1
虞良斌,feature aicore_metrics supports memory_access parameters,,2025-02-17T21:24:24+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBMWF9
俞涵,【DOC】mindspore.tensor接口入参中英文不一致、mindspore.Tensor中英文参数数量不一致以及英文入参丢失, 1. 【Document Link】/【文档链接】 https://gitee.com/mindspore/mindspore/blob/master/docs/api/api_python/mindspore/mindspore.Tensor.rst https://gitee.com/mindspore/mindspore/blob/master/docs/api/api_python/mindspore/mindspore.func_tensor.rst https://gitee.com/mindspore/mindspore/blob/master/mindspore/python/mindspore/common/tensor.py 2. 【Issues Section】/【问题文档片段】 !输入图片说明 !输入图片说明 3. 【Existing Issues】/【存在的问题】 mindspore.tensor接口入参中英文不一致、mindspore.Tensor中英文参数数量不一致以及英文入参丢失 4. 【Expected Result】【预期结果】 使mindspore.tensor和mindspore.Tensor接口的中英文注释一致；mindspore.Tensor英文接口注释单独手写rst文件，请参考 https://pytorch.org/docs/stable/_sources/tensors.rst.txt  Please fill in the expected result,2025-02-17T19:32:02+08:00,"gitee,foruda,ctl/componenttest,rca/others,rct/refactor,mindspore-cla/yes,sig/doc",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBMVT7, Appearance & Root Cause  问题：     重构Tensor，优化Tensor入参internal字段以及__init__函数，未同步修改资料  根因：     internal虽是内部字段，但被写到对外资料里面了，优化后得同步修改  Fix Solution 1、资料同步修改  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/82225 PR合入后daily包回归  测试建议：     重新检视资料  Selftest Report & DT Review  是否需要补充 ST/UT：否 原因：资料  Selftest Report !输入图片说明  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81238 PR合入时间：2025/2/15 问题是否偶现：否
虞良斌,edit the profile interface docs,,2025-02-17T17:51:33+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBMUWU
majun-bot,CVE20251373,"一、漏洞信息 漏洞编号：CVE20251373 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A vulnerability was found in FFmpeg up to 7.1. It has been rated as problematic. Affected by this issue is the function mov_read_trak of the file libavformat/mov.c of the component MOV Parser. The manipulation leads to null pointer dereference. Local access is required to approach this attack. The exploit has been disclosed to the public and may be used. The patch is identified as 43be8d07281caca2e88bfd8ee2333633e1fb1a13. It is recommended to apply a patch to fix this issue. 漏洞公开时间：N/A 漏洞创建时间：20250217 12:43:39 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20251373 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞的修复方案与ffmpeg5.1.4版本不兼容，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 3.3 &emsp;Vector： CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-17T12:43:40+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBMQ56,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞的修复方案与ffmpeg5.1.4版本不兼容，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：3.3 LOW  Vector：CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,该漏洞的修复方案与ffmpeg5.1.4版本不兼容，故不受影响。
林芃芃,mint.hardshrink接口类型检查机制不完善，内部类型转换逻辑有bug，对不同shape的输入处理不一致," 1.Issue Description / 问题描述 MindSpore的Hardshrink接口在数据类型处理方面存在2个问题： 1. 类型检查不一致：     文档声明在Ascend平台仅支持float16、float32、bfloat16     实际测试中int32类型输入未被正确拒绝     错误消息与预期不符 2. 类型转换异常：     输入float16类型数据被意外转换为int32     相同的float16类型在不同场景下表现不一致  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例 >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    test_hardshrink_invalid_input: 测试int32类型输入未被正确拒绝 >    test_hardshrink_sequence: 测试序列数据的处理 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode: Graph  4.Steps to reproduce the issue / 重现步骤 1.创建测试代码`test_hardshrink.py`: ```python import numpy as np import pytest import torch import mindspore as ms from mindspore import Tensor import mindspore.mint as mint class TestHardshrink:     """"""Hardshrink算子测试类""""""     def test_hardshrink_invalid_input(self):         """"""测试无效输入的处理""""""         ms_hardshrink = mint.nn.Hardshrink(lambd=0.5)          测试不支持的数据类型         with pytest.raises(TypeError, match=""For primitive.*must be a type of.*Float""):             x_ms = Tensor(np.array([1.0]), dtype=ms.int32)             ms_hardshrink(x_ms)          测试空输入         with pytest.raises(ValueError, match=""Input tensor cannot be empty""):             x_ms = Tensor(np.array([]), dtype=ms.float32)             ms_hardshrink(x_ms)          测试维度为0的输入         with pytest.raises(ValueError, match=""Input tensor must have at least one dimension""):             x_ms = Tensor(np.array([[]]), dtype=ms.float32)             ms_hardshrink(x_ms)          测试负的lambda值         with pytest.raises(ValueError, match=""Lambda value must be nonnegative""):             mint.nn.Hardshrink(lambd=0.5)         print(""无效输入测试通过"")     def test_hardshrink_sequence(self):         """"""测试序列数据的处理""""""          生成序列数据         seq_length = 10         batch_size = 2         hidden_size = 16         np.random.seed(42)         x_np = np.random.uniform(2, 2, size=(batch_size, seq_length, hidden_size)).astype(np.float16)          MindSpore实现         x_ms = Tensor(x_np, dtype=ms.float16)         ms_hardshrink = mint.nn.Hardshrink(lambd=0.5)         y_ms = ms_hardshrink(x_ms)          PyTorch实现         x_torch = torch.tensor(x_np, dtype=torch.float16)         torch_hardshrink = torch.nn.Hardshrink(lambd=0.5)         y_torch = torch_hardshrink(x_torch)          比较结果         np.testing.assert_allclose(             y_ms.asnumpy(),             y_torch.detach().numpy(),             rtol=1e3,             atol=1e3         )         print(""序列数据测试通过"") ``` 2. 执行测试 ```bash pytest test_hardshrink.py v ```  5.Describe the expected behavior / 预期结果 1. 类型检查行为：     严格按照文档说明，只接受float16、float32、bfloat16类型     对不支持的类型（如int32）应立即报错     错误消息应准确描述问题 2. 类型转换行为：     保持输入类型不变，不进行隐式转换     在所有场景下对相同类型有一致的处理  6.Related log / screenshot / 日志 / 截图 类型转换错误信息： ``` TypeError: For primitive[HShrink], the input argument[input_x] must be a type of {BFloat16, Float16, Float32}, but got Int32.   C++ Call Stack: (For framework developers)  mindspore/core/utils/check_convert_utils.cc:1062 CheckSubClass ``` !输入图片说明",2025-02-17T07:08:17+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBMLRU
朱俞桦,【开源实习】mindspore.mint接口测试任务10," 1.Describe the current behavior / 问题描述  在float16、bfloat16的dtype设置下，进行mint.cross计算时分别会出现以下两种情况： 1. dtype为float16时，计算结果与torch误差有可能大于1e3 !输入图片说明 2. dtype为bfloat16时，mint.cross计算会报运行时错误： !输入图片说明  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  >  **Testcase Name/ 用例名 **: >    Testcase Name: test_cross_fixed_dtype_random_input() >  **Excute Mode / 执行模式 **: >    Excute Mode(Graph): * >    Excute Mode(O2)：*  4.Steps to reproduce the issue / 重现步骤  > （1）`pip install upgrade mindspore==2.4.0` > （2）`pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 indexurl https://download.pytorch.org/whl/cpu i https://pypi.tuna.tsinghua.edu.cn/simple` > （3）运行如下代码： ``` import mindspore import numpy as np from mindspore import mint import mindspore as ms from mindspore import Tensor, mint, ops import mindspore.nn as mnn import numpy as np import torch import torch.nn as nn  设置随机种子 seed = 42 torch.manual_seed(seed) mindspore.set_seed(seed)  设置上下文，指定设备为 Ascend ms.set_context(device_target=""Ascend"", device_id=0)  ''' b) 测试固定dtype，random输入值，对比两个框架输出是否相等（误差范围为小于1e3） ''' def test_cross_fixed_dtype_random_input():      固定dtype     dtypes = [         mindspore.int8, mindspore.int16, mindspore.int32, mindspore.int64,         mindspore.uint8,          mindspore.float16,  这里会出现计算结果相对误差大于1e3的情况         mindspore.float32, mindspore.float64,         mindspore.bfloat16,  这里会出现运行时报错         mindspore.complex64, mindspore.complex128     ]     torch_dtypes = [         torch.int8, torch.int16, torch.int32, torch.int64,         torch.uint8,          torch.float16,          torch.float32, torch.float64,         torch.bfloat16,          torch.complex64, torch.complex128     ]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):          print(dtype, torch_dtype)         for _ in range(100):             input_data = np.abs(np.random.randn(2, 3)).astype(np.float32)             other_data = np.abs(np.random.randn(2, 3)).astype(np.float32)             ms_input = Tensor(input_data, dtype)             ms_other = Tensor(other_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)             torch_other = torch.tensor(other_data, dtype=torch_dtype)             ms_output = mint.cross(ms_input, ms_other)             torch_output = torch.cross(torch_input, torch_other)              对比输出             if dtype == mindspore.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") test_cross_fixed_dtype_random_input() ```  5.Describe the expected behavior / 预期结果  > **【预期结果】**：两个框架输出误差范围为小于1e3，且支持所有dtype  6.Related log / screenshot / 日志 / 截图  报错关键日志截图： !输入图片说明 !输入图片说明 完整日志： 1. dtype为float16时 ```  AssertionError                            Traceback (most recent call last) Cell In[46], line 1 > 1 test_cross_fixed_dtype_random_input() Cell In[45], line 113     111             np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)     112         else: > 113             np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     115 print(""MindSpore and PyTorch outputs are equal within tolerance."")     [... skipping hidden 1 frame] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/testing/_private/utils.py:844, in assert_array_compare(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)     840         err_msg += '\n' + '\n'.join(remarks)     841         msg = build_err_msg([ox, oy], err_msg,     842                             verbose=verbose, header=header,     843                             names=('x', 'y'), precision=precision) > 844         raise AssertionError(msg)     845 except ValueError:     846     import traceback AssertionError:  Not equal to tolerance rtol=0.001, atol=0 Mismatched elements: 1 / 6 (16.7%) Max absolute difference: 0.0004883 Max relative difference: 0.003845  x: array([[ 1.277  , 0.6504 , 0.02371],        [0.2893 ,  0.2426 ,  0.02124]], dtype=float16)  y: array([[ 1.277  , 0.65   , 0.0238 ],        [0.2893 ,  0.2424 ,  0.02124]], dtype=float16) ``` 2. dtype为bfloat16时 ```  RuntimeError                              Traceback (most recent call last) Cell In[44], line 1 > 1 test_cross_fixed_dtype_random_input() Cell In[43], line 111     109  对比输出     110 if dtype == mindspore.bfloat16: > 111     np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)     112 else:     113     np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py:49, in _stub_method..fun(*arg, **kwargs)      47 stub = arg[0]      48 arg = (stub.stub_sync(),) + arg[1:] > 49 return method(*arg, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/tensor.py:1070, in Tensor.asnumpy(self)    1068 if self.has_init:    1069     self.init_data() > 1070 return Tensor_.asnumpy(self) RuntimeError: aclnnLinalgCrossGetWorkspaceSize call failed, please check!   Ascend Error Message:  EZ1001: 2025021622:52:14.763.073 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,DT_INT8,DT_INT16,DT_INT32,DT_INT64,DT_COMPLEX64,DT_COMPLEX128,DT_UINT8,].[THREAD:28251] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/ascend/pyboost/customize/cross.cc:54 operator() ```",2025-02-16T22:58:40+08:00,mindspore-assistant,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBMLH6,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致，未出现精度问题。
林芃芃,`mindspore.mint.cumsum` 在处理 int8 类型数据时存在溢出问题," 1.Describe the current behavior / 问题描述 任务链接 `mint.cumsum` 在处理 int8 类型数据时存在溢出问题  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例  **Testcase Name**: >  test_cumsum.py::test_int8_overflow  **Execute Mode**: >  Graph Mode  4.Steps to reproduce the issue / 重现步骤 1. 准备测试环境： ```python import numpy as np import pytest import mindspore import torch from mindspore import Tensor from mindspore import mint def test_int8_overflow():     """"""测试int8类型的溢出情况""""""     print(""\n=== 测试int8类型溢出 ==="")      测试用例1: 正数溢出     data1 = np.array([64, 64, 64], dtype=np.int8)   累加后会超过127      测试用例2: 负数溢出     data2 = np.array([64, 64, 64], dtype=np.int8)   累加后会小于128      测试用例3: 边界值     data3 = np.array([127, 1, 1], dtype=np.int8)   从最大值开始累加     test_cases = [         (data1, ""正数溢出""),         (data2, ""负数溢出""),         (data3, ""边界值"")     ]     results = {}     for data, case_name in test_cases:         print(f""\n测试{case_name}:"")         print(f""输入数据: {data}"")          PyTorch测试         torch_input = torch.tensor(data, dtype=torch.int8)         torch_output = torch.cumsum(torch_input, dim=0)          MindSpore测试         ms_input = Tensor(data, dtype=ms.int8)         ms_output = mint.cumsum(ms_input, dim=0)          计算结果         torch_result = torch_output.numpy()         ms_result = ms_output.asnumpy()         print(f""PyTorch结果: {torch_result}"")         print(f""MindSpore结果: {ms_result}"")          检查是否一致         is_equal = np.array_equal(torch_result, ms_result)         results[case_name] = {             'torch_output': torch_result,             'ms_output': ms_result,             'is_equal': is_equal         } ``` 2. 运行测试用例： ```bash pytest test_cumsum.py v ```  5.Describe the expected behavior / 预期结果 通过测试用例，确保 MindSpore 的`mint.cumsum`函数在处理 int8 类型的数据时，不会出现溢出。  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-14T21:11:46+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBMF65,int8 类型能表达的最大值就是127。当累加运算结果超过127后，产生溢出是正常现象。 MindSpore 当前行为是与torch_npu对齐的，与pytorch_cpu是不一致的，并非是问题。 若用户的应用场景会产生溢出值，建议使用int32/int64输入数据类型。
zhangyinxia,手册修改," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） 1、input格式调整 2、中文手册补充 3、中英文映射表补充 > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-14T15:28:21+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBMBWK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
虞良斌,Add the profile interface st use case,,2025-02-14T14:15:54+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBMAO1
caifubi,某些环境编译GPU会缺少符号undefined symbol: _ZN9mindspore6kernel7pyboost9OpFactoryINS1_15GroupedMatmulV4EE3GetEv,,2025-02-14T10:51:18+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBM8US
虞良斌,Iteration one of the code br_feature_tools branch synchronizes the master branch,,2025-02-12T17:36:54+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBLVI9
b_rookie,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/mindspore.JitConfig.html?highlight=jit_level 2. 【Issues Section】/【问题文档片段】 > jit_level和静态图、动态图模式有关吗？这里应该指明 3. 【Issues Section】/【问题文档片段】 易用性：  >  关键步骤错误或缺失，无法指导用户完成任务；  >  缺少主要功能描述、关键词解释、必要前提条件、注意事项等；  >  描述内容存在歧义指代不明、上下文矛盾；  >  逻辑不清晰，该分类、分项、分步骤的没有给出； 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-02-12T14:54:32+08:00,"gitee,www",open,0,6,https://gitee.com/mindspore/mindspore/issues/IBLSSF,"jit_level是默认在静态图模式使用的，正如链接中介绍的：""编译时所使用的JitConfig配置项""。所以不需要在jit_level介绍中指明静态图或动态图。","> jit_level是默认在静态图模式使用的，正如链接中介绍的：""编译时所使用的JitConfig配置项""。所以不需要在jit_level介绍中指明静态图或动态图。  动态图也会有编译，这里并不能看出是针对静态图模式", K jit表示即时编译Just In Time，对应的就是静态图模式。动态图是不编译图的，按照解释执行的方式。,>  K jit表示即时编译Just In Time，对应的就是静态图模式。动态图是不编译图的，按照解释执行的方式。  动态图模式也可以用jit装饰器，这些技术细节用户并不能理清楚，动态图模式静态图模式一堆开关，在这里应该写清楚，提高易用性, 动态图模式是可用使用jit装饰器，但是jit里面跑的是静态图模式，这些在官网都可以查阅的,得分：2 类型：易用性 活动链接（可查询积分）：https://www.mindspore.cn/feedback 欢迎您提交更多issue或PR，获得更多积分。
majun-bot,CVE202412797,"一、漏洞信息 漏洞编号：CVE202412797 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 6.3 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 漏洞简述： Issue summary: Clients using RFC7250 Raw Public Keys (RPKs) to authenticate a server may fail to notice that the server was not authenticated, because handshakes don't abort as expected when the SSL_VERIFY_PEER verification mode is set. Impact summary: TLS and DTLS connections using raw public keys may be vulnerable to maninmiddle attacks when server authentication failure is not detected by clients. RPKs are disabled by default in both TLS clients and TLS servers.  The issue only arises when TLS clients explicitly enable RPK use by the server, and the server, likewise, enables sending of an RPK instead of an X.509 certificate chain.  The affected clients are those that then rely on the handshake to fail when the server's RPK fails to match one of the expected public keys, by setting the verification mode to SSL_VERIFY_PEER. Clients that enable serverside raw public keys can still find out that raw public key verification failed by calling SSL_get_verify_result(), and those that do, and take appropriate action, are not affected.  This issue was introduced in the initial implementation of RPK support in OpenSSL 3.2. The FIPS modules in 3.4, 3.3, 3.2, 3.1 and 3.0 are not affected by this issue. 漏洞公开时间：20250212 00:15:38 漏洞创建时间：20250212 00:23:50 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202412797 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 使用RFC7250原始公钥（RPK）对服务器进行身份验证的客户端可能无法注意到服务器未通过身份验证，因为在设置SSL_VERIFY_PEER验证模式时，握手不会按预期中止。影响摘要：当客户端未检测到服务器身份验证失败时，使用原始公钥的TLS和DTLS连接可能容易受到中间人攻击。默认情况下，TLS客户端和TLS服务器都禁用RPK。只有当TLS客户端明确允许服务器使用RPK，并且服务器同样允许发送RPK而不是X.509证书链时，才会出现问题。受影响的客户端是那些在服务器的RPK与预期的公钥之一不匹配时，通过将验证模式设置为SSL_VERIFY_PEER，依赖握手失败的客户端。启用服务器端原始公钥的客户端仍然可以通过调用SSL_get_verify_result（）来发现原始公钥验证失败，而那些启用并采取适当行动的客户端不会受到影响。这个问题是在OpenSSL3.2中RPK支持的初始实现中引入的。3.4、3.3、3.2、3.1和3.0中的FIPS模块不受此问题的影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响",2025-02-12T00:23:50+08:00,"openssl-library,gitee,CVE/UNAFFECTED",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBLNBX,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明:使用RFC7250原始公钥（RPK）对服务器进行身份验证的客户端可能无法注意到服务器未通过身份验证，因为在设置SSL_VERIFY_PEER验证模式时，握手不会按预期中止。影响摘要：当客户端未检测到服务器身份验证失败时，使用原始公钥的TLS和DTLS连接可能容易受到中间人攻击。默认情况下，TLS客户端和TLS服务器都禁用RPK。只有当TLS客户端明确允许服务器使用RPK，并且服务器同样允许发送RPK而不是X.509证书链时，才会出现问题。受影响的客户端是那些在服务器的RPK与预期的公钥之一不匹配时，通过将验证模式设置为SSL_VERIFY_PEER，依赖握手失败的客户端。启用服务器端原始公钥的客户端仍然可以通过调用SSL_get_verify_result（）来发现原始公钥验证失败，而那些启用并采取适当行动的客户端不会受到影响。这个问题是在OpenSSL 3.2中RPK支持的初始实现中引入的。3.4、3.3、3.2、3.1和3.0中的FIPS模块不受此问题的影响。 漏洞评分(mindspore评分): BaseScore:6.3 Vector:CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", Appearance & Root Cause 工具误报，当前mindspore使用的openssl版本为1.1.1k，该漏洞只影响3.2及以上版本，因此不需要修复。 详情见：https://openssllibrary.org/news/secadv/20250211.txt  Fix Solution mindspore不受影响，无需修复。
jalenlee,"Ascend910B在Ubuntu22.04上执行chartglm26b ptuning报错, 同样的配置在Ubuntu20.04上正常执行","Ascend910B在Ubuntu22.04上执行chartglm26b ptuning报错, 同样的配置在Ubuntu20.04上正常执行 环境:  Ascend 910b OS:Ubuntu 22.04 driver: Ascendhdk910bnpudriver_24.1.rc1_linuxaarch64.run 固件: Ascendhdk910bnpufirmware_7.1.0.6.220.run docker ascend: Ascenddockerruntime_6.0.RC1_linuxaarch64.run  镜像:  swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.0_mindspore2.2.11:aarch_20240125 Mindformers版本: 1.0.0 !Mindformers版本 执行chartglm26b ptuning微调时报错:    C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/kernel/opapi/aclnn/tile_aclnn_kernel.h:37 RunOp Traceback (most recent call last):   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/run_mindformer.py"", line 365, in      main(config_)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/tools/cloud_adapter/cloud_monitor.py"", line 44, in wrapper     raise exc   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/tools/cloud_adapter/cloud_monitor.py"", line 34, in wrapper     result = run_func(*args, **kwargs)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/run_mindformer.py"", line 143, in main     create_task_trainer(config)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/run_mindformer.py"", line 85, in create_task_trainer     trainer.train(config, is_full_config=True)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/trainer/causal_language_modeling/causal_language_modeling.py"", line 97, in train     self.training_process(   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/trainer/base_trainer.py"", line 734, in training_process     model.train(config.runner_config.epochs, dataset,   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 1290, in train     _train_wrapper(epoch,   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 119, in wrapper     func(self, *args, **kwargs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 815, in _train     self._train_dataset_sink_process(epoch, train_dataset, list_callback,   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 902, in _train_dataset_sink_process     outputs = train_network(*inputs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 703, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 1074, in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1860, in __call__     return self.run(obj, *args, phase=phase)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1911, in run     return self._exec_pip(obj, *args, phase=phase_real)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 185, in wrapper     results = fn(*arg, **kwargs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1891, in _exec_pip     return self._graph_executor(args, phase) RuntimeError: Call aclnnRepeat failed, detail:EZ9903: 2025021107:56:36.166.797 rtKernelLaunchWithHandleV2 failed: 507035[THREAD:8007]         Solution: In this scenario, collect the plog when the fault occurs and locate the fault based on the plog.         TraceBack (most recent call last):         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 1, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x2a00564840, mte error info: 0x160305559d, ifu error info: 0x78a6837abfac0, ccu error info: 0x9289844c3f03727b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x305559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:2, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 2, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x721a37e4be, mte error info: 0x160303559d, ifu error info: 0x2c83313078ec0, ccu error info: 0x7f84821e3ab63e3f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x303559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:3, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 3, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x20149747da, mte error info: 0x160301559d, ifu error info: 0x16b1079a41080, ccu error info: 0xc6eb7b31464ef6b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:4, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 4, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x4015b1c410, mte error info: 0x160301559d, ifu error info: 0x10889be15ec80, ccu error info: 0x9c202769282711f9, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:5, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 5, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x6013a0a12d, mte error info: 0x160301559d, ifu error info: 0x441165f72800, ccu error info: 0xdd7469d01c7bfd7b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:6, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 7, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x321e372d21, mte error info: 0x160301559d, ifu error info: 0x146b0b625f280, ccu error info: 0x57e820dc38214ea0, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:8, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 9, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x630057e008, mte error info: 0x160305459d, ifu error info: 0x310c303a0b000, ccu error info: 0x84112e0d391720bf, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x305459d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:10, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 10, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x6915c59205, mte error info: 0x160301559d, ifu error info: 0x68ee9f6b8cfc0, ccu error info: 0xe285e407cb3346d, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:11, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 11, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x610915508c, mte error info: 0x160303559d, ifu error info: 0x101c831ea46c0, ccu error info: 0x822e3cb258a3909f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x303559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 12, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x3303054c00, mte error info: 0x160307559d, ifu error info: 0x3103792b8f340, ccu error info: 0xc4d5f3ff7bc7476f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x307559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:13, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 13, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x5305c40c6c, mte error info: 0x160307559d, ifu error info: 0x3f73f7ca59180, ccu error info: 0x3e0e7e7d173805b1, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x307559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:14, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 47, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x730b9f9a19, mte error info: 0x160301559d, ifu error info: 0x3f3ad3bb7bac0, ccu error info: 0x5f42008c7896e01f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:0, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         Kernel task happen error, retCode=0x31, [vector core exception].[FUNC:PreCheckTaskErr][FILE:davinic_kernel_task.cc][LINE:1220][THREAD:7565]         AIV Kernel happen error, retCode=0x31.[FUNC:GetError][FILE:stream.cc][LINE:1082][THREAD:7565]         Aicore kernel execute failed, device_id=0, stream_id=2, report_stream_id=2, task_id=4, flip_num=0, fault kernel_name=GatherV2_618279a26921567d421037acce4dee5b_high_precision_900015010, fault kernel info ext=none, program id=12, hash=18024093464264554721.[FUNC:GetError][FILE:stream.cc][LINE:1082][THREAD:8007]         [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1082][THREAD:8007]         Failed to submit kernel task, retCode=0x715005e.[FUNC:LaunchKernelSubmit][FILE:context.cc][LINE:677][THREAD:8007]         kernel launch submit failed.[FUNC:LaunchKernelWithHandle][FILE:context.cc][LINE:893][THREAD:8007]         rtKernelLaunchWithHandleV2 execute failed, reason=[vector core exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53][THREAD:8007]         rtKernelLaunchWithHandleV2 failed: 507035[THREAD:8007]         OpExecCache run fail.[THREAD:8007]   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/kernel/opapi/aclnn/tile_aclnn_kernel.h:37 RunOp [WARNING] MD(7400,ffff8d6b2020,python):2025021107:57:36.468.869 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:163] ~DataQueueOp] channel_name: 93a21600e84d11efa4f2b04fa6440df3; have_sent: 101; host_queue: 1, 1, 0, 0, 1, 1, 0, 0, 1, 1; device_queue: 91, 92, 93, 94, 95, 96, 97, 98, 99, 99;       push_first_start_time > push_first_end_time 2025021107:55:36.203.430 > 2025021107:55:36.204.534             push_start_time > push_end_time 2025021107:55:36.549.759 > 2025021107:55:36.550.217 2025021107:55:36.550.425 > 2025021107:55:36.550.885 2025021107:55:36.552.788 > 2025021107:55:36.553.246 2025021107:55:36.555.619 > 2025021107:55:36.556.062 2025021107:55:36.561.950 > 2025021107:55:36.562.565 2025021107:55:36.562.806 > 2025021107:55:36.563.257 2025021107:55:36.563.459 > 2025021107:55:36.564.052 2025021107:55:36.573.849 > 2025021107:55:36.574.219 2025021107:55:36.574.377 > 2025021107:55:36.574.762 2025021107:56:31.438.491 > 2025021107:56:31.439.006 For more details, please refer to the FAQ at https://www.mindspore.cn/docs/en/master/faq/data_processing.html. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.474.548 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_manager.cc:257] SyncStream] Call runtime aclrtSynchronizeStreamWithTimeout error. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.474.757 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:578] SyncStream] Sync default stream failed. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.474.790 [mindspore/ccsrc/runtime/device/kernel_runtime_manager.cc:134] WaitTaskFinishOnDevice] SyncStream failed [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.475.005 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_manager.cc:257] SyncStream] Call runtime aclrtSynchronizeStreamWithTimeout error. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.475.041 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_manager.cc:270] SyncAllStreams] SyncStream for stream id 0 failed. [ERROR] ME(7400,ffff8d6b2020,python):2025021107:57:36.475.067 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:490] WaitTaskFinishOnDevice] SyncStream failed",2025-02-11T16:09:33+08:00,"gitee,foruda,foruda,www,www,help,bugs,mirrors,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBLK30,看错误提示可能是驱动和cann、mindspore不匹配造成的；确定环境都一样，一个能跑一个不能跑吗？还有cann版本是多少？ 根据你上面列出的各个版本，匹配上是可能有问题的；上面写的mindspore是2.2.11版本，这个对应的cann版本是7.0，而对应的驱动应该是23.*开头的；而你上面的驱动版本是24.1.rc1，这个驱动对应了cann8.0开始的版本，mindspore版本也需要2.3以后的 !输入图片说明 !输入图片说明,"=======================答复: 环境说明============================ VERSION=”20.04.5 LTS (Focal Fossa)” Ascendhdk910bnpudriver_24.1.rc1_linuxaarch64.run Ascendhdk910bnpufirmware_7.1.0.6.220.run Ascenddockerruntime_6.0.RC1_linuxaarch64.run Mindformers 1.0.0 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.0_mindspore2.2.11:aarch_20240125 Get component version(7.1.0.6.220) succeed for deviceId(7), componentType(27).         {""device_id"":7, ""component"":hlink2, ""version"":7.1.0.6.220} } root:~ npusmi info ++  root:~ cat /etc/osrelease NAME=""Ubuntu"" VERSION=""20.04.5 LTS (Focal Fossa)"" ID=ubuntu ID_LIKE=debian PRETTY_NAME=""Ubuntu 20.04.5 LTS"" VERSION_ID=""20.04"" HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" VERSION_CODENAME=focal UBUNTU_CODENAME=focal 使用这个组合是可以运行的 使用镜像启动: swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.0_mindspore2.2.11:aarch_20240125这个镜像中的版本:  !容器内 Ubuntu22上还尝试过这两个镜像, toolkit是8.0的, 报错是一样的 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.2_mindspore2.3:20240722 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.1_mindspore2.3rc2:2024051 ==================问题====================== 问题1. gitee上看Mindformers1.2已经没有了chatglm26b的ptuning微调文档说明, 是否已经不支持? 问题2. 看镜像站上最旧的一个os是ubuntu22的镜像http://mirrors.cncentral221.ovaijisuan.com/detail/138.html, 匹配的是mindformers1.2, 微调是否跟os有关系?ubuntu22是否支持chatglm26b的ptuningw微调?"
caifubi,add cpu/gpu kernel launch profile,,2025-02-11T14:55:50+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBLINB
hedongdong,【AR】算子Tensor接口重载Tensor.roll," Tasks 转测对象：Tensor.roll   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.roll  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  Roll the tensor input along the given dims.  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` roll:      op_yaml: roll_op.yaml       py_method: tensor_roll  callback to python function ""def tensor_roll""       Ascend: pyboost       CPU: py_method       GPU: py_method       interface: tensor      op_yaml: deprecated/roll_method.yaml       py_method: tensor_roll  callback to python function ""def tensor_roll""       Ascend: py_method       CPU: py_method       GPU: py_method       interface: tensor ```  算子原语 ``` roll:   args:     input:       dtype: tensor     shifts:       dtype: tuple[int]       prim_init: True       type_cast:  int, list[int]     dims:       dtype: tuple[int]       default: None       prim_init: True       type_cast:  int, list[int]   returns:     output:       dtype: tensor ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-02-11T14:48:57+08:00,"gitee,sig/ops",progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBLIK1
ezreal,mindspore是否适配了沐曦GPU, mindspore是否适配了沐曦GPU,2025-02-11T11:28:29+08:00,"gitee,foruda,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBLGDG,目前没看到官方有说支持沐曦GPU，已提供的是支持cuda的GPU运行版本，但网上有说沐曦GPU也兼容cuda，如果是这个情况，理论上是有可能跑起来的，因为框架层其实是直接调用cuda的，然后由cuda去和GPU交互，实际能不能跑要看沐曦GPU和cuda的兼容情况了，如果说mindspore里调用的某个cuda api在沐曦GPU上兼容没完成，那就运行不了了 !输入图片说明
孙昊辰,support 3d batch matmul in internal kernal,   Backgroud（背景信息）  deepseek branch  support 3d batch matmul in internal kernal  Origin（信息来源）  算子团队  Benefit / Necessity （价值/作用）  提高算子效率  Design（设计方案）  support 3d batch matmul in internal kernal,2025-02-11T10:52:34+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBLFQ2
孙昊辰,"支持MOEGroupedMatMul（fp16,int8）算子及TransData融合","   Backgroud（背景信息）  支持MOEGroupedMatMul（fp16,int8）算子及TransData融合  Origin（信息来源）  算子团队  Benefit / Necessity （价值/作用）  盘古72B性能优化  Design（设计方案）  详见需求设计",2025-02-10T09:58:49+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBL4OS
xiaoyao,impl compile cache in msrun o2 mode,,2025-02-10T09:27:52+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBL43M
guyueyuan,mindspore.mint.distributed.init_process_group训练时cpu与npu运行参数异常,"  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode graph  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 普通的训练测试代码 ``` import os import numpy as np import mindspore as ms import mindspore.nn as nn from mindspore import ops from mindspore import set_context import mindspore.dataset as ds import mindspore.mint.distributed as ms_dist  定义一个简单的MLP网络 class SimpleMLP(nn.Cell):     def __init__(self):         super(SimpleMLP, self).__init__()         self.flatten = nn.Flatten()         self.layer1 = nn.Dense(28*28, 256)         self.relu1 = nn.ReLU()         self.layer2 = nn.Dense(256, 64)         self.relu2 = nn.ReLU()         self.layer3 = nn.Dense(64, 10)     def construct(self, x):         x = self.flatten(x)         x = self.relu1(self.layer1(x))         x = self.relu2(self.layer2(x))         return self.layer3(x) def create_dataset(batch_size):      创建随机数据用于测试     data = np.random.randn(1000, 28, 28).astype(np.float32)     label = np.random.randint(0, 10, (1000,)).astype(np.int32)     dataset = ds.NumpySlicesDataset(         {""data"": data, ""label"": label},          shuffle=True     )     dataset = dataset.batch(batch_size)     return dataset def main():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""Ascend"")      使用mint接口初始化分布式环境     ms_dist.init_process_group(         backend='hccl',   Ascend使用hccl后端         world_size=2,     总进程数     )     rank_id = ms_dist.get_rank()     rank_size = ms_dist.get_world_size()     print(f""当前进程 rank_id: {rank_id}, 总进程数 rank_size: {rank_size}"")      创建数据集     dataset = create_dataset(batch_size=32)      创建网络、损失函数和优化器     network = SimpleMLP()     loss_fn = nn.CrossEntropyLoss()     optimizer = nn.Adam(network.trainable_params())     def forward_fn(data, label):         logits = network(data)         loss = loss_fn(logits, label)         return loss     grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters)     def train_step(data, label):         loss, grads = grad_fn(data, label)         optimizer(grads)         return loss     try:          训练循环         epochs = 5         for epoch in range(epochs):             total_loss = 0             steps = 0             for data in dataset.create_dict_iterator():                 loss = train_step(data[""data""], data[""label""])                 total_loss += loss                 steps += 1                 print(f""Epoch: {epoch}, Step: {steps}, Loss: {loss}"")             print(f""Epoch: {epoch}, 平均损失: {total_loss/steps}"")     finally:          清理分布式环境         ms_dist.destroy_process_group()         print(""分布式环境已清理"") if __name__ == ""__main__"":     main() ```  Describe the expected behavior / 预期结果 (Mandatory / 必填) npu内存和aicore参数正常  Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 可以看见基本上都是cpu在主跑，目前测试在昇思大模型平台和启智社区，皆出现此异常 !输入图片说明 !输入图片说明  Special notes for this issue/备注 (Optional / 选填) !输入图片说明",2025-02-08T19:28:08+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKZQN
daheyinyin,数据类型转换为uint32时，在不同设备结果不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  将负数转换为Uint32时，Ascend和CPU上的结果不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore as ms import torch x = [[1, 6], [7.9, 3.2]] ms_tensor = ms.tensor(x, dtype=ms.uint32) torch_tensor = torch.tensor(x, dtype=torch.uint32) print(ms_tensor, torch_tensor) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：不同设备结果一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： linux Ascend，与torch结果不同 !输入图片说明 windows运行结果,与torch一致 !windows运行结果    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-08T15:44:34+08:00,"gitee,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBKX66,补充，Ascend环境是启智平台的910A,经分析， 该问题是平台架构X86和aarch64不同导致的，将副店类型负数直接转换为无符号整数会返回无法预期的结果
hedongdong,【AR】算子Tensor接口重载Tensor.xlogy及ops接口重载ops.xlogy," Tasks 转测对象：Tensor.xlogy / ops.xlogy   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.xlogy  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  !输入图片说明  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` xlogy:    op_yaml: xlogy_scalar_other_op.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: pyboost     CPU: py_method     GPU: py_method     interface: tensor, function    op_yaml: xlogy_scalar_self_op.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: pyboost     CPU: py_method     GPU: py_method     interface: function    op_yaml: xlogy_op.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: pyboost     CPU: pyboost     GPU: pyboost     interface: tensor, function    op_yaml: deprecated/xlogy_method.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: py_method     CPU: py_method     GPU: py_method     interface: tensor ```  算子原语 ``` xlogy:   args:     input:       dtype: tensor       type_cast: number     other:       dtype: tensor       type_cast: number   args_signature:     dtype_group: (input, other)   returns:     out:       dtype: tensor ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-02-08T11:46:00+08:00,sig/ops,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBKUDP
hedongdong,【AR】算子Tensor接口重载Tensor.logaddexp," Tasks 转测对象：Tensor.logaddexp   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.logaddexp  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  !输入图片说明  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` logaddexp:    op_yaml: logaddexp_op.yaml     py_method: deprecated_tensor_logaddexp  callback to python function ""def deprecated_tensor_logaddexp""     Ascend: pyboost     CPU: py_method     GPU: py_method     interface: tensor    op_yaml: deprecated/logaddexp_method.yaml     py_method: deprecated_tensor_logaddexp  callback to python function ""def deprecated_tensor_logaddexp""     Ascend: py_method     CPU: py_method     GPU: py_method     interface: tensor ```  算子原语 ``` logaddexp:   args:     input:       dtype: tensor     other:       dtype: tensor   args_signature:     dtype_group: (input, other)   returns:     output:       dtype: tensor ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-02-08T11:41:42+08:00,sig/ops,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBKUAR
guyueyuan,mindspore.mint.distributed.init_process_group启动内存异常问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore.mint.distributed.init_process_group初始化拉起分布式环境的时候，内存占用异常  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Ascend: 2*Ascend910proA  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: /mode graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore as ms from mindspore import set_context from mindspore.mint.distributed import init_process_group, destroy_process_group set_context(device_target=""Ascend"",mode=ms.GRAPH_MODE) init_process_group(backend='hccl',world_size=2) print(""环境初始化完成"") destroy_process_group() print(""销毁通信组"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 初始化阶段内存占用应该比较少，至少不会像我测试这样这么高  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 !输入图片说明 !输入图片说明 报错关键日志截图： !输入图片说明  7.Special notes for this issue/备注 (Optional / 选填) 环境信息截图： !输入图片说明 !输入图片说明",2025-02-08T11:35:54+08:00,"foruda,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBKU7P,换了个环境，也是一样的问题 !输入图片说明,去掉mode=ms.GRAPH_MODE试试，图模式会固定分配一块静态内存。
guyueyuan,mindspore.mint.distributed.init_process_group启动内存异常问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore.mint.distributed.init_process_group初始化拉起分布式环境的时候，内存占用异常  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Ascend: 2*Ascend910proA  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: /mode graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore as ms from mindspore import set_context from mindspore.mint.distributed import init_process_group, destroy_process_group set_context(device_target=""Ascend"",mode=ms.GRAPH_MODE) init_process_group(backend='hccl',world_size=2) print(""环境初始化完成"") destroy_process_group() print(""销毁通信组"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 初始化阶段内存占用应该比较少，至少不会像我测试这样这么高  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 !输入图片说明 !输入图片说明 报错关键日志截图： !输入图片说明  7.Special notes for this issue/备注 (Optional / 选填) 环境信息截图： !输入图片说明 !输入图片说明",2025-02-08T11:35:52+08:00,"gitee,mindspore-assistant",rejected,0,1,https://gitee.com/mindspore/mindspore/issues/IBKU7O,https://gitee.com/mindspore/mindspore/issues/IBKU7P?from=projectissue 重复提单， 详见这个issue
虞良斌,profiler adds the _ExperimentalConfig and profile interfaces,,2025-02-07T18:19:29+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBKQNA
cccc1111,index_put接入aclnn, Tasks 转测对象：tensor.index_put 对标torch.tensor.index_put   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/bool  **2. MindSpore算子情况**   当前支持数据类型 index_put在Ascend后端PyNative模式下支持数据类型与torch_npu保持一致 index_put在Ascend后端KBK/GE与CPU后端与之前保持一致（复用IndexPut原语）  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  根据指定的索引位置，将新的值赋给张量中的对应元素。  **2. 接口描述**   接口重载： tensor.index_put: !输入图片说明 !输入图片说明 !输入图片说明 对于Ascend后端，PyNative模式会走新增IndexPutExt原语，对于KBK/GE与CPU后端走原有逻辑。 Ascend的PyNative模式： !输入图片说明 Ascend的KBK模式： !输入图片说明 Ascend的GE模式： !输入图片说明 CPU的PyNative模式 !输入图片说明 CPU的KBK模式： !输入图片说明 CPU的GE模式： !输入图片说明  算子原语   自动生成对应原语,2025-02-07T15:13:51+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKNNU
wqx,尝试用在香橙派上推理DeepSeekR1DistillQwen1.5B碰到的一些问题,"目前在香橙派ai pro 20t 24G测试了DeepSeekR1DistillQwen1.5B，用的mindspore 2.3.1， 2.4.1和2.4.10，使用的mindnlp版本是master分支和0.4.0版本，都没能成功运行，cann版本都是根据文档装的，2.3.1用的是8.0rc2,2.4.1和2.4.10用的是8.0rc3； 测试代码如下： !输入图片说明 出错情况总结如下： 如果是在fp32模式下运行，都是加载权重出错： !输入图片说明 !输入图片说明 如果是在fp16模式下运行，其中2.4.1和2.4.10都是报了aclnn相关错误： !输入图片说明 如果是2.3.1的话，是报了内存相关错误，这个错误我在910b上也见到过，通常是显存不足的情况下会报： !输入图片说明 但照理说这个1.5b的模型，fp16运行应该不会显存不足，我在我的4090，以及线上910b上测试结果都是占用8G不到的显存 在2.3.1上也测试了qwen0.5b，也是返回这个memory相关的错误",2025-02-07T12:05:35+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBKLMF,最终验证下来是mindspore或者cann版本在香橙派ai pro上不适配的问题，使用cann 8.0.RC3 alpha 002，mindspore使用2.4.0或者以上正式发布的版本都可以
zhangyinxia,通信算子性能内存调优,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-07T11:35:13+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKL8G
luoxuewei,pyboost流程中op_run_info数据结构优化," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填)    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**luoxuewei（根据实际修改）",2025-02-07T09:51:05+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKJHI
Alicya,"运行mistral7b,报 RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > 使用华为云北京四910A对应镜像运行mistral7b,报 RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(mistral7Bv0.1): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）在华为云提供的镜像中搭好必要环境 > （2）根据github中提供的关于mistral的readme文档（https://github.com/lvyufeng/mistralmindspore/tree/12109d82ae9ff0fa854a5ebccba9ff62325e8fd7）下载和运行mistral7Bv0.1 > （3）运行报错  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：mistral7Bv0.1运行正常 !预期结果  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 在使用北京四 910A的对应镜像的时候运行会有一个警告和RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm报错（见图1.1和图1.2），搜了一下然后在mian.py中添加了行代码用自动并行模式还是报错RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm（见图1.3和图1.4） 报错关键日志截图： !图1.1 !图1.2 !图1.3 !图1.4 完整日志（通过附件上传）： 没保存    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-06T13:34:59+08:00,"mindspore-assistant,github",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBKDIR,这个是比较早的代码实现了，看样子是早期的实现代码和框架环境的兼容问题，或者用的框架版本比较早，触发了以前版本的某个bug；mistral模型的代码现在建议使用mindnlp套件里的实现： https://github.com/mindsporelab/mindnlp/tree/master/mindnlp/transformers/models/mistral 并且昇腾910环境mindspore建议用较新的版本，尽量不要低于2.3.1，这要启动速度快，体验好； 华为云贵阳一区，或者启智社区都有比较新的mindspore版本的昇腾环境，可以试试
xiedejin1,【AR】//= Ascend后端 在910B上 e2e 性能不达标," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > floor_divide_(符号//=) PyNative正向e2e性能在910B Ascend后端上不达标  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B`/`Mac CPU`)    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative 单脚本测试用例： ```python import mindspore import numpy as np from mindspore import Tensor, mint from mindspore.common.api import _pynative_executor from mindspore._c_expression import _framework_profiler_step_start, _framework_profiler_step_end import time np.random.seed(23) input = Tensor(np.random.uniform(low=10000, high=10000, size=(10, 10)).astype(np.float32)) other = Tensor(np.random.uniform(low=0.998, high=1.002, size=(10, 10)).astype(np.float32)) for _ in range(1000):     input //= other _pynative_executor.sync() _framework_profiler_step_start() start = time.time() for _ in range(1000):     input //= other _pynative_executor.sync() end = time.time() _framework_profiler_step_end() print(f""ms cost: {(endstart)*1000} us"") ```  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 使用脚本执行性能测试用例  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 性能达标  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 见评论区  7.Special notes for this issue/备注 (Optional / 选填)",2025-02-05T17:16:47+08:00,"gitee,foruda,sig/ops",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBK7UB,在910B上，PyNative Ascend后端e2e不达标 !输入图片说明 !输入图片说明
Mike Cheung,ops.Receive document issue," 1. 【Document Link】/【文档链接】 https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.Receive.html 2. 【Issues Section】/【问题文档片段】 sr_tag (int) – A required integer identifying the send/recv message tag. The message will will be send by the Send op with the same ""sr_tag"". 3. 【Existing Issues】/【存在的问题】 double `will` and it should be `come from the Send op` instead of `send by xxx` 4. 【Expected Result】【预期结果】  Please fill in the expected result",2025-02-05T15:51:28+08:00,"foruda,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBK6RJ,"In the revised document, the relevant description has been changed to: ""This operator will receive the tensor sent by the Send operator with the same sr_tag tag."" !screenshot"
虞良斌,Fixed the free time time calculation error in step trace time,,2025-02-05T10:59:40+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBK4A0
虞良斌,Supplementary communication supports the step function st use case,,2025-02-05T10:13:32+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBK34H
majun-bot,CVE20250977,"一、漏洞信息 漏洞编号：CVE20250977 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： In `openssl` versions before `0.10.70`, `ssl::select_next_proto` can return a slice pointing into the `server` argument's buffer but with a lifetime bound to the `client` argument. In situations where the `server` buffer's lifetime is shorter than the `client` buffer's, this can cause a use after free. This could cause the server to crash or to return arbitrary memory contents to the client. `openssl` 0.10.70 fixes the signature of `ssl::select_next_proto` to properly constrain the output buffer's lifetime to that of both input buffers. In standard usage of `ssl::select_next_proto` in the callback passed to `SslContextBuilder::set_alpn_select_callback`, code is only affected if the `server` buffer is constructed *within* the callback. For example: Not vulnerable  the server buffer has a `'static` lifetime: ```rust builder.set_alpn_select_callback( {     let server_protos = b""\x02h2"".to_vec();     ssl::select_next_proto(&server_protos, client_protos).ok_or_else(AlpnError::NOACK) }); ``` 漏洞公开时间：N/A 漏洞创建时间：20250203 18:20:28 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20250977 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 此漏洞只影响rust版本的OpenSSL，而MindSpore未使用该版本，因此不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 9.8 &emsp;Vector： CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-03T18:20:29+08:00,"gitee,CVE/UNAFFECTED",closed,0,10,https://gitee.com/mindspore/mindspore/issues/IBJZNE,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明: 测试评论，忽略 漏洞评分(mindspore评分): BaseScore: 2.2 Vector: xxxxxx 受影响版本排查(受影响/不受影响): 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:受影响 7.r2.3:受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明: 测试评论，忽略 漏洞评分(mindspore评分): BaseScore: 2.2 Vector: xxxxxx 受影响版本排查(受影响/不受影响): 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:受影响 7.r2.3:受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", 忽略上述评论，请重新评论,影响性分析说明: 此漏洞只影响rust版本的OpenSSL，而MindSpore未使用该版本，因此不受影响。 漏洞评分(mindspore评分): BaseScore:9.8 Vector:CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：工具误报，此为rust版本的openssl漏洞，mindspore不涉及 根因：工具误报  Fix Solution 无需修复  Fix Description & Test Suggestion 无需修复 测试建议：无  Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：开源三方件漏洞，已有相关开源仓看护；  Introduction Analysis 引入类型：工具误报 引入PR：不涉及 问题是否偶现：否
majun-bot,CVE202445339,"一、漏洞信息 漏洞编号：CVE202445339 漏洞归属组件：glog, https://gitee.com/mindspore/mindspore 漏洞归属的版本：0.4.0 CVSS分值： &emsp;BaseScore： 7.1 High &emsp;Vector： CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N 漏洞简述： When logs are written to a widelywritable directory (the default), an unprivileged attacker may predict a privileged process's log file path and precreate a symbolic link to a sensitive file in its place. When that privileged process runs, it will follow the planted symlink and overwrite that sensitive file. To fix that, glog now causes the program to exit (with status code 2) when it finds that the configured log file already exists. 漏洞公开时间：20250128 10:15:28 漏洞创建时间：20250128 11:25:22 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202445339 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 该漏洞属于golang/glog，mindspore使用的google/glog是基于c++语言的，属于误报 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.1 &emsp;Vector： CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-28T11:25:23+08:00,"gitee,CVE/UNAFFECTED",closed,0,7,https://gitee.com/mindspore/mindspore/issues/IBJUYY,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,该漏洞属于golang/glog，mindspore使用的google/glog是基于c++语言的，不是一个东西，不受影响,影响性分析说明: 该漏洞属于golang/glog，mindspore使用的google/glog是基于c++语言的，属于误报 漏洞评分(mindspore评分): 3.0 BaseScore:  7.1 High Vector: CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N 受影响版本排查(受影响/不受影响): 不受影响,受影响版本排查 => 分支: [r2.2 r2.3 master r1.10 r1.9 r2.0 r2.1] 没有分析或未按正确格式填写,影响性分析说明: 该漏洞属于golang/glog，mindspore使用的google/glog是基于c++语言的，属于误报 漏洞评分(mindspore评分): 3.0 BaseScore:  7.1 High Vector: CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N 受影响版本排查(受影响/不受影响):  1.master: 不受影响 2.r1.10: 不受影响 3.r1.9: 不受影响 4.r2.0: 不受影响 5.r2.1: 不受影响 6.r2.2: 不受影响 7.r2.3: 不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**"
b_rookie,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/mint/mindspore.mint.split.html?highlight=split 2. 【Issues Section】/【问题文档片段】 > split_size_or_sections这参数名能简化一下吗？和ops的split能对齐吗 3. 【Issues Section】/【问题文档片段】 易用性：  >  关键步骤错误或缺失，无法指导用户完成任务；  >  缺少主要功能描述、关键词解释、必要前提条件、注意事项等；  >  描述内容存在歧义指代不明、上下文矛盾；  >  逻辑不清晰，该分类、分项、分步骤的没有给出； 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-01-26T15:31:02+08:00,gitee,progressing,0,3,https://gitee.com/mindspore/mindspore/issues/IBJSDP,你好，这个主要是跟业界主流用法一致。,说明：非文档问题，不在文档反馈活动中计分。,这个样例代码真是制杖，长度为9切成3x3，谁知道这个3是样本长度还是个数？
b_rookie,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/ops/mindspore.ops.Split.html?highlight=split 2. 【Issues Section】/【问题文档片段】 > output_num这里是每块的大小还是总数啊，请描述清楚，以及如果不能整除会怎样 3. 【Issues Section】/【问题文档片段】 易用性：  >  关键步骤错误或缺失，无法指导用户完成任务；  >  缺少主要功能描述、关键词解释、必要前提条件、注意事项等；  >  描述内容存在歧义指代不明、上下文矛盾；  >  逻辑不清晰，该分类、分项、分步骤的没有给出； 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-01-26T15:21:10+08:00,"gitee,www",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBJSC4,得分：2 类型：易用性 活动链接（可查询积分）：https://www.mindspore.cn/feedback 欢迎您提交更多issue或PR，获得更多积分。
虞良斌,Fixed profile_memory parameter description in profiler,,2025-01-24T17:27:52+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBJOD5
Guan_nauG,mindsporelite转换模型，不支持TensorScatterUpdate," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > 用mindspore_lite将mindyolo训练得到的mindir模型转为ms模型时，报错显示不支持TensorScatterUpdate算子  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）将ckpt模型导出为mindir  python deploy/export.py config ../configs/yolov5/yolov5s.yaml weight ../weights/EMA_yolov5s_500.ckpt per_batch_size 1 file_format MINDIR device_target CPU > （2）验证导出的mindir模型能否正常推理 python deploy/mslite_predict.py mindir_path ./weights/yolov5s_500.mindir conf_thres 0.45 iou_thres 0.45 config ./configs/yolov5/yolov5s.yaml image_path XXXimages/val/00006050.jpg !mindir推理结果 > （3）将mindir模型用mindsporelite转为ms模型，未转换成功 converter_lite fmk=MINDIR modelFile=./EMA_yolov5s500e.mindir outputFile=./250121 inputDataFormat=NCHW  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：成功导出ms模型，且可正常推理  5.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志部分： [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\legacy_optimizer\graph\dropout_node_remove_pass.cc:35] IsolateDropoutNode] Only support node who has no more than one input and two output [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\legacy_optimizer\graph\dropout_node_remove_pass.cc:106] Run] IsolateDropoutNode failed, subGraph: , node: Default/modelModel/modelCellList/24YOLOv5Head/TensorScatterUpdateop4, error: 1 [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\optimizer.cc:78] Run] Run GraphPass failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\graphdef_transform.cc:93] Transform] Run unused_op_remove_optimizer graphPasses Failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter_metagraph.cc:102] Build] Transform meta graph failed!ret = 1 [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1259] SaveGraph] Convert to meta graph failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1212] HandleGraphCommon] Save graph failed: 1 Common error code. [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1152] Convert] Handle graph failed: 1 Common error code. [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1344] RunConverter] Convert model failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:60] PrintOps] =========================================== [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:61] PrintOps] UNSUPPORTED OP LIST: [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:63] PrintOps] FMKTYPE: , OP TYPE: TensorScatterUpdate [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:65] PrintOps] =========================================== [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\cxx_api\converter.cc:374] Convert] Convert model failed, ret=Common error code. ERROR [mindspore\lite\tools\converter\converter_lite\main.cc:104] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code.",2025-01-24T16:10:02+08:00,"gitee,mindspore-assistant",progressing,0,5,https://gitee.com/mindspore/mindspore/issues/IBJNP4,"在yolov5_head.py中将以下部分 y[..., 0:2] = (y[..., 0:2] * 2.0  0.5 + grid_tensor) * self.stride[i]  xy y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  wh z += (y.view(bs, 1, self.no),) 更改为： xy = (y[..., 0:2] * 2.0  0.5 + grid_tensor) * self.stride[i] wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i] y = ops.concat([xy, wh, y[..., 4:]], axis=1) z += (y.view(bs, 1, self.no),) 经export.py得到mindir模型，再用mindspore_lite,可得到能使用的ms模型。 但推理时，不包括前处理和后处理，从传入输入后开始计时，得到模型输出用了400ms左右，请问如何优化，谢谢",请问你的环境信息具体是什么，可否补充一下？,"您好，补充环境信息：(1)模型训练的时候用的是ascend910b, mindspore2.3.0    cann8.0.rc1    py3.9    euler2.10.7    aarch64 (2)用mindsporelite2.4.10将mindir模型转为了ms (3)端侧调用ms模型用的是CPU",算子解析不支持，需要适配,已转需求，内部开发中；
虞良斌,The stage and bubble parameters are distinguished by step,,2025-01-24T15:15:22+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBJN78
陈盼妙,[CT][MS][门禁]test_print_string.py::test_run_op_print failed in gate," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) test_print_string.py::test_run_op_print failed in gate  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:     3.Related testcase / 关联用例 (Mandatory / 必填) [gate failed]tests/st/dynamic_shape test_print_string.py::test_run_op_print			  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：跑pass  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) master 80722 machenggui 20250120 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/MindSpore_Gitee_Gate/runs/375826/nodes/133/log 80775 huangbingjian 20250122 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/MindSpore_Gitee_Gate/runs/376016/nodes/219/log 80834 liubuyu 20250123 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/MindSpore_Gitee_Gate/runs/376194/nodes/623/log ``` [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] test_print_string.py F [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] =================================== FAILURES =================================== [20250122T02:11:05.500Z] ______________________________ test_run_op_print _______________________________ [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]     (plat_marks=['platform_ascend'], level_mark='level0', card_mark='onecard', essential_mark='essential') [20250122T02:11:05.500Z]     def test_run_op_print(): [20250122T02:11:05.500Z]         """""" [20250122T02:11:05.500Z]         Feature: Test print string by calling _run_op method. [20250122T02:11:05.500Z]         Description: Test print string by calling _run_op method. [20250122T02:11:05.500Z]         Expectation: No exception and result is correct. [20250122T02:11:05.500Z]         """""" [20250122T02:11:05.500Z]         ms.set_context(mode=ms.PYNATIVE_MODE) [20250122T02:11:05.500Z]         class Net(nn.Cell): [20250122T02:11:05.500Z]             def __init__(self): [20250122T02:11:05.500Z]                 super().__init__() [20250122T02:11:05.500Z]                 self.print = P.Print() [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]             def construct(self, x): [20250122T02:11:05.500Z]                 _run_op(self.print, ""Print"", (""TensorStart"", x, ""TheEnd"")) [20250122T02:11:05.500Z]                 return x [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]         cap = Capture() [20250122T02:11:05.500Z]         with capture(cap): [20250122T02:11:05.500Z]             input_x = Tensor([1, 2, 3]) [20250122T02:11:05.500Z]             net = Net() [20250122T02:11:05.500Z]             out = net(input_x) [20250122T02:11:05.500Z]             np.testing.assert_array_equal(out.asnumpy(), np.array([1, 2, 3], dtype=np.int32)) [20250122T02:11:05.500Z]             sys.stdout.flush() [20250122T02:11:05.500Z]             time.sleep(0.1) [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]         patterns = ['TensorStart', [20250122T02:11:05.500Z]                     'Tensor(shape=[3], dtype=Int64, value=[1 2 3])', [20250122T02:11:05.500Z]                     'TheEnd'] [20250122T02:11:05.500Z] >       check_output(cap.output, patterns) [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] test_print_string.py:238:  [20250122T02:11:05.500Z] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] output = '' [20250122T02:11:05.500Z] patterns = ['TensorStart', 'Tensor(shape=[3], dtype=Int64, value=[1 2 3])', 'TheEnd'] [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z]     def check_output(output, patterns): [20250122T02:11:05.500Z] >       assert output, ""Capture output failed!"" [20250122T02:11:05.500Z] E       AssertionError: Capture output failed! [20250122T02:11:05.500Z] E       assert '' [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] test_print_string.py:65: AssertionError [20250122T02:11:05.500Z] =============================== warnings summary =============================== [20250122T02:11:05.500Z] /home/****/.local/lib/python3.7/sitepackages/mindspore/ops/_op_impl/_custom_op/batchnorm_fold2.py:57 [20250122T02:11:05.500Z]   /home/****/.local/lib/python3.7/sitepackages/mindspore/ops/_op_impl/_custom ```  7.Special notes for this issue/备注 (Optional / 选填)",2025-01-24T11:53:55+08:00,"kind/developertest,rct/oldrelease,rca/others,ctl/personalbuild",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBJM2P, Appearance & Root Cause 问题：print用例小概率性是吧 根因：用例中需要捕获输出到stdout上的日志，由于sleep时间较短，导致有时捕获不到stdout输出  Fix Solution 修改用例，调大用例中的sleep时间  Fix Description & Test Suggestion 修改用例，调大用例中的sleep时间 测试建议：该用例为门禁用例，测试无需再看护  Selftest Report & DT Review 修改的用例为门禁用例，门禁pass后自动合入 是否需要补充 ST/UT：否； 原因：当前用例已经是st用例,回归通过
Albert,文档反馈MindSpore,1. 【Document Link】/【文档链接】 > https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/Tensor/mindspore.Tensor.numel.html?highlight=numelmindspore.Tensor.numel 2. 【Issues Section】/【问题文档片段】 > numel接口错误，实际运行下来非文档描述行为 !输入图片说明 3. 【Issues Section】/【问题文档片段】 易用性：  >  关键步骤错误或缺失，无法指导用户完成任务；  >  缺少主要功能描述、关键词解释、必要前提条件、注意事项等；  >  描述内容存在歧义指代不明、上下文矛盾；  >  逻辑不清晰，该分类、分项、分步骤的没有给出； 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-01-23T22:38:39+08:00,,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBJK8E,说明：非文档问题，不在文档反馈活动中计分。,经验证，运行结果与文档一致
xiaopeng,[MS][Tensor.tanh_] 910B上Tensor.tanh_性能与torch的e2e性能有差距,Tensor.tanh_为原地更新算子，原地更新算子的e2e比值小于1.4即达标，目前在910B环境的10*10、100*100、1000*100这三种shape的输入e2e比值都大于1.4 !输入图片说明 鉴于其他Tensor的原地更新算子也有910B机器e2e与torch性能有差距，所以等待框架修复该问题,2025-01-23T19:43:57+08:00,"gitee,sig/ops,attr/performance,rct/newfeature,rca/codelogic,demo",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBJJRP
虞良斌,Dynamic graph scenario communication supports step differentiation,,2025-01-23T17:44:18+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBJJ7I
虞良斌,Dynamic profiling supports memory collection,,2025-01-23T17:15:23+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBJIVB
wangsir,mindocr进行图片检测和识别时报错,执行命令如下： python3 infer.py \     input_images_dir=/home/wyj/ocr/images \     det_model_path=/root/mindspore/weight/dbnet.mindir \     det_model_name_or_config=/root/mindspore/mindocr/configs/det/dbnet/db_r50_icdar15.yaml \     rec_model_path=/root/mindspore/weight/crnn.mindir \     rec_model_name_or_config=/root/mindspore/mindocr/configs/rec/crnn/crnn_resnet34.yaml \     res_save_dir=det_rec \     vis_pipeline_save_dir=det_rec 其中检测和识别模型分别是从官网下载的mindir模型，已经通过converter工具将其转为lite.mindir，执行报错提示如下： !输入图片说明 软硬件信息： mindocr 0.2.0 mindspore 2.4.1 mindspore_lite 2.4.1 CANN 8.0.RC3 NPU 310P3,2025-01-23T15:00:59+08:00,"foruda,mindspore-assistant",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBJHAE,这个错误应该和mslite或者说cann环境没有啥关系，是python代码层面的逻辑出错了，是在截图中最后那行代码中的dict中通过key取value时，key出错了，你可以通过在那里打印日志看看，是不是使用的key不在dict中,报错的那个python文件的名称叫rec_postprecess.py，推理应该是成功了，是后处理的时候python逻辑出错，一般名字带postprecess的python文件就是后处理的,"!输入图片说明 看了下代码，确实是indices数组的值6623在字典character里没有对应的key,但是怎么解决呢？这个问题","尊敬的开发者您好，我们尝试复现但是失败，主要没有你那张报错的图片。不过看了一下你用的mindocr版本是v0.2.0，版本太老了，0.3.0的时候离线推理就重构过了，也没有那行报错的代码。建议他用下高版本的ocr，配套的ms和ms_lite也是2.4.1的； !输入图片说明.png"") 而且返回值也没用到这个raw_chars，调试用，一直没删？"
xiedejin1,【AR】PyBoost接口及Aclnn算子适配Tensor.floor_divide_, Tasks 转测对象：Tensor.floor_divide_(符号//=) ,2025-01-23T14:22:03+08:00,"gitee,sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBJGV8
hedongdong,【AR】算子Tensor接口重载Tensor.logsumexp," Tasks 转测对象：Tensor.logsumexp   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.logsumexp  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  !输入图片说明  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` logsumexp:      op_yaml: logsumexp_op.yaml       py_method: deprecated_tensor_logsumexp  callback to python function ""def deprecated_tensor_logsumexp""       Ascend: pyboost       CPU: py_method       GPU: py_method       interface: tensor      op_yaml: deprecated/logsumexp_method.yaml       py_method: deprecated_tensor_logsumexp  callback to python function ""def deprecated_tensor_logsumexp""       Ascend: py_method       CPU: py_method       GPU: py_method       interface: tensor ```  算子原语 ``` logsumexp:     args:         input:             dtype: tensor         dim:             dtype: tuple[int]             type_cast: int, list[int]         keepdim:             dtype: bool             default: False     returns:         output:             dtype: tensor     class:         name: LogSumExp ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-01-23T11:30:15+08:00,sig/ops,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBJFUV
mengyuanli,magic number clean," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 告警清理。魔鬼数字消除。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-23T09:34:04+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBJEMN
tangmengcheng,profiler info新增cann version,,2025-01-22T17:04:46+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IBJCDD
wangsir,使用mindsporelite 将社区下载的MindIR模型文件转换为Lite MindIR模型文件报错,!输入图片说明 !输入图片说明 !输入图片说明 mindocr 0.2.0 mindspore 2.4.1 mindspore_lite 2.4.1 CANN 8.0.RC3 NPU 310P3,2025-01-22T17:00:53+08:00,mindspore-assistant,closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBJCBP,你这是转的哪个模型，我去试试看；有些模型确实是转不了的，有算子上的不支持，比如yolov5能转成功，v7我这边也转不了，有不支持的算子；也可以尝试下直接用mslite加载你下载的那个mindir，有些模型也是能直接加载的，转成Lite MindIR的话，就是做了些lite的调优，可能启动会快一些,不过你这边报了卷积算子的错误，卷积应该是没问题的，有可能是310P的环境搭建上的问题，导致卷积算子找不到；你的310P的kernels算子包有没有装，以及cann的环境变量是否都OK了,怎么验证你说的环境问题是否OK?,"可以跑个官方确认能跑的简单模型看看就行，或者我一般就安装个对应版本的mindspore试一下： import mindspore as ms ms.set_context(device_target='Ascend') t = ms.Tensor([1, 2, 3]).astype(ms.float16) t.mean() 跑个类似上面简单的代码试试，通常这个代码都是支持的，如果能跑，说明环境环境搭建没问题，ms.set_context(device_target='Ascend')这个执行成功，说明昇腾后端加载没问题，cann环境变量的配置都是OK的，不过有些环境下可能求平均这种简单的操作也走不通，那应该是该环境确实没适配好mindspore的在线推理，确保kernels安装包已经装了就行了",我重新安装了一下cann和kernel可以了，感谢
蛋蛋de忧桑,mint.arctan2、mint.asin、mint.asinh、mint.atan在图模式下报错,"  Describe the current behavior / 问题描述 (Mandatory / 必填) mint.arctan2、mint.asin、mint.asinh、mint.atan四个接口在mindspore.GRAPH_MODE静态图模式时运行出错。 RuntimeError: Compile graph kernel_graph0 failed. 但是同样的环境，mint.arctanh可以成功运行。  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Ascend: 1*ascendsnt9b1|ARM: 24核 192GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version : Mindspore 2.4.0  Python version : Python 3.9.10  OS platform and distribution : Linux version 4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch64  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode graph  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) Bug复现代码： ```python import mindspore as ms from mindspore import mint, Tensor, value_and_grad import numpy as np ms.set_context(mode=ms.GRAPH_MODE) input_data = np.array([0, 1]) other_data = np.array([1, 1]) ms_input = Tensor(input_data, ms.float32) ms_other = Tensor(other_data, ms.float32) def forward_ms(x, y):     return mint.arctan2(x, y)  Gradients for MindSpore grad_fn = value_and_grad(forward_ms) output_ms, gradient_ms = grad_fn(ms_input, ms_other)  打印输出和梯度 print(""MindSpore output:"", output_ms) print(""MindSpore gradient:"", gradient_ms) ``` 其余接口复现代码类似，仅仅修改forward_ms中调用的函数。 mint.arctanh正常运行代码： ```python import mindspore as ms from mindspore import mint, Tensor, value_and_grad import numpy as np ms.set_context(mode=ms.GRAPH_MODE) input_data = np.array([0, 0.5]) ms_input = Tensor(input_data, ms.float32) def forward_ms(x):     return mint.arctanh(x)  Gradients for MindSpore grad_fn = value_and_grad(forward_ms) output_ms, gradient_ms = grad_fn(ms_input)  打印输出和梯度 print(""MindSpore output:"", output_ms) print(""MindSpore gradient:"", gradient_ms) ``` 环境相同，但是mint.arctanh可以正常运行。  Describe the expected behavior / 预期结果 (Mandatory / 必填) 代码可以正常运行  Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !正常运行截图 !报错截图1 !报错截图2  Special notes for this issue/备注 (Optional / 选填) 环境信息 !环境信息",2025-01-22T16:31:46+08:00,"foruda,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBJBX8,试了下上面的arctan2的代码，其实是可以跑的，出错可能和环境设置有关，执行下unset RANK_TABLE_FILE后再试试看； !输入图片说明 上述代码中其实走的仍然是动态图的模式，设置了ms.set_context(mode=ms.GRAPH_MODE)后，是让nn.Cell对象或者其子类的construct方法中的代码走静态图，如果不在construct中，依旧是动态图模式，需要用mindspore.jit包起来的代码才是走静态图，比如在forward_ms加上mindspore.jit标注；上面的错误可能是在未执行unset RANK_TABLE_FILE把RANK_TABLE_FILE环境变量去掉的情况下，触发了动静结合模式下的啥bug,可以的，执行了unset RANK_TABLE_FILE之后再运行没有报错
weiwei123,test custom param," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-22T15:28:45+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBJB8M,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
b_rookie,ops.einsum为什么不支持CPU ASCEND,   Backgroud（背景信息） einsum是常见的算子，但是现在只支持GPU，请支持CPU ASCEND端  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-01-22T14:06:52+08:00,"gitee,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBJA92,请使用 mint.einsum 这个支持了Ascend， 但CPU仍不支持,> 请使用 mint.einsum 这个支持了Ascend， 但CPU仍不支持  mint也是比较新的版本才有，老版本没有，从算子完备性来说，ops应该支持
majun-bot,CVE202413176,"一、漏洞信息 漏洞编号：CVE202413176 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 4.1 Medium &emsp;Vector： CVSS:3.1/AV:P/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L 漏洞简述： Issue summary: A timing sidechannel which could potentially allow recovering the private key exists in the ECDSA signature computation. Impact summary: A timing sidechannel in ECDSA signature computations could allow recovering the private key by an attacker. However, measuring the timing would require either local access to the signing application or a very fast network connection with low latency. There is a timing signal of around 300 nanoseconds when the top word of the inverted ECDSA nonce value is zero. This can happen with significant probability only for some of the supported elliptic curves. In particular the NIST P521 curve is affected. To be able to measure this leak, the attacker process must either be located in the same physical computer or must have a very fast network connection with low latency. For that reason the severity of this vulnerability is Low. The FIPS modules in 3.4, 3.3, 3.2, 3.1 and 3.0 are affected by this issue. 漏洞公开时间：20250120 22:15:26 漏洞创建时间：20250120 22:40:04 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202413176 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： ECDSA签名计算中的计时侧通道可能允许攻击者恢复私钥。 漏洞评分(MindSpore评分): &emsp;BaseScore： 4.7 &emsp;Vector： CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-20T22:40:05+08:00,"gitee,v2.1.0,v2.3.0,v2.2.0,v1.10,ci-pipeline-passed,v2.0.0,CVE/FIXED",closed,0,15,https://gitee.com/mindspore/mindspore/issues/IBIZYY,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142","mindspore依赖于open Euler开源仓发布的openssl1.1.1k版本，当前open Euler开源仓未修复该漏洞,没有提供对应的修复patch，所以无法从open Euler开源仓获取不到漏洞对应的patch,且开源社区patch的下载需要企业会员账户，所以无法下载开源社区的patch文件，因此暂时无法修复。之前相关漏洞修复都是依赖open Euler开源仓的提供的patch修复；",影响性分析说明 => 没有正确填写,影响性分析说明 => 没有正确填写,Appearance & Root Cause Openssl 1.1.1k版本存在CVE202413176漏洞，影响：ECDSA签名计算中存在一个可能允许恢复私钥的定时侧通道。 Fix Solution 使用openssl官方发布的补丁进行修复 Fix Description & Test Suggestion 配置openssl官方发布的漏洞补丁 Selftest Report & DT Review 开发本地自验ok,影响性分析说明 => 没有正确填写,影响性分析说明: ECDSA签名计算中的计时侧通道可能允许攻击者恢复私钥。 漏洞评分(mindspore评分): 4.7 BaseScore: 4.7 Medium Vector: CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N 受影响版本排查(受影响/不受影响): 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",修复PR：https://gitee.com/mindspore/mindspore/pulls/80947,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,分支 [r2.3] 未检测到关联PR合入，无法关闭issue，关联PR合入后再重试,影响性分析说明: ECDSA签名计算中的计时侧通道可能允许攻击者恢复私钥。 漏洞评分(mindspore评分): 4.7 BaseScore: 4.7 Medium Vector: CVSS:3.1/AV:L/AC:H/PR:L/UI:N/S:U/C:H/I:N/A:N 受影响版本排查(受影响/不受影响): 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",已修复合入，回归通过,Appearance & Root Cause 问题：Openssl 1.1.1k版本存在CVE202413176漏洞，影响：ECDSA签名计算中存在一个可能允许恢复私钥的定时侧通道。 根因：mindspore依赖组件Openssl 1.1.1k版本，而该版本存在CVE202413176漏洞 Fix Solution 使用openssl官方发布的补丁进行修复 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/80947 PR合入主线 Selftest Report & DT Review 是否需要补充ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：mindspore依赖的组件Openssl 1.1.1k版本中存在CVE202413176漏洞 引入PR：不涉及 PR合入时间：不涉及 问题是否偶现：否
fengtingyan,双机推理MatmulAllReduceAddRmsNorm算子报错, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 双机推理MatmulAllReduceAddRmsNorm算子报错不支持rank size16 报错：[图片上传中…(imagesSNyaWxEo96M06ZV5VM5)]  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）配置mindie双机config.json，配置yaml > （2）cd mindieservice/bin/ > （3）验证服务化是否正常拉起,2025-01-20T20:57:46+08:00,,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBIZJO
majun-bot,CVE20249880,"一、漏洞信息 漏洞编号：CVE20249880 漏洞归属组件：pandas, https://gitee.com/mindspore/mindspore 漏洞归属的版本：>= 1.0.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： credit：Aftersnows Vulnerability Research Institute Below is an Example of Command Execution Caused by the pandas.DataFrame.query Function, Which Developers Can Use for Debugging and Identifying Issues import pandas as pd df = pd.DataFrame({'a': [1, 2, 3], 'b': ['error_details', 'confidential_info', 'normal']}) query = '.core.frame.com.builtins.__import__(""os"").system(""""""ping google.com """""")' try:     engine = ""python""     result = df.query(query,local_dict={},engine=""python"",).index except Exception as e:     print(f'Error: {e}') Pandas DataFrame query Function Intended Usage and Potential for Command Execution The pandas.DataFrame.query function is intended to allow querying the columns of a DataFrame using a boolean expression. However, if an attacker constructs a malicious query, they can potentially bypass validation mechanisms and trigger a command execution vulnerability. .core.frame.com.builtins.__import__(""os"").system(""""""ping google.com """""" 漏洞公开时间：N/A 漏洞创建时间：20250120 15:45:07 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20249880 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 5.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-20T15:45:07+08:00,"gitee,CVE/UNAFFECTED,rct/oldrelease,rca/others,ctl/componenttest",closed,0,10,https://gitee.com/mindspore/mindspore/issues/IBIW96,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：N/A None  Vector：N/A 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：N/A None  Vector：N/A 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分):  BaseScore： 5.3 Medium  Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：pandas漏洞 根因： pandas漏洞 Fix Solution 不涉及，该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 Fix Description & Test Suggestion 不涉及，该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 Selftest Report & DT Review 不涉及 Introduction Analysis 引入类型：三方件pandas引入 引入PR：未知 PR合入时间：未知,该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。
zhangshucheng,ms_kernels_internal  log adapter  to ms's log,,2025-01-20T11:27:44+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBITX6
吴逸群,在docker中使用mindyolo训练失败, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 我想要在docker中使用mindyolo，但是使用中出现了很奇怪的问题，具体描述如下： 我有2个华为服务器，一个是atlas 800T，另一个是atlas 800I 服务器，我在这两个服务器都安装了asecnd_docker，之后，我下载了官方的ascend_mindspore镜像，并使用如下指令run了一个容器： docker run it name lkx_mindspore2 ipc=host network host device=/dev/davinci0 device=/dev/davinci1 device=/dev/davinci2 device=/dev/davinci3 device=/dev/davinci_manager device=/dev/devmm_svm device=/dev/hisi_hdc v /usr/local/dcmi:/usr/local/dcmi v /usr/local/bin/npusmi:/usr/local/bin/npusmi v /usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64/common v /usr/local/Ascend/driver/lib64/driver:/usr/local/Ascend/driver/lib64/driver v /etc/ascend_install.info:/etc/ascend_install.info v /etc/vnpu.cfg:/etc/vnpu.cfg v /usr/local/Ascend/driver/version.info:/usr/local/Ascend/driver/version.info v /home/lkx:/home/lkx entrypoint=/bin/bash 930poc:py310_cannRC3_mindieT65_torch_npu_dev20240929 我使用的是mindyolo0.4官方仓库的代码 （https://github.com/mindsporelab/mindyolo），yaml等配置都没错，然后我在容器中开始训练就会出现下图的结果，就是训练过程不报错，但是模型无法训练（我用npusmi info查看了，AI core占用率一直为0%），同样的环境和代码拿到宿主机环境里面训练就不会出现任何问题。我在atlas 800T和800I上试了至少10几个官方的ascend_mindspore镜像，换了很多mindspore和mindyolo版本，都是这样的现象。我在容器中直接用mindspore训练yolo又不会出问题。  2.Environment / 环境信息 (Mandatory / 必填) atlas 800T 训练服务器 atlas 800I 推理服务器 !输入图片说明,2025-01-20T10:40:56+08:00,"foruda,www,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBIT8D,MindSpore 安装的run check能跑通，可以显示mindspore版本号和successful（在宿主机和容器里面都可以跑通）。 cann版本号如下： !输入图片说明 我上面这个图片用的是atlas 800I，但是我在atlas 800T上面也试了（cann版本一致），也一样只能在宿主机上运行，不能在docker容器里面使用。,解答：启动命令有变化，详细参照指南：https://www.hiascend.com/developer/ascendhub/detail/9de02a1a179b4018a4bf8e50c6c2339e
ErjieWu,NVIDIA卡安装mindsporedev GPU版失败, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) NVIDIA的GPU安装Mindsporedev后测试安装结果报错，CPU版本可正常运行，GPU版本报错如下（包含一些配置信息）： !输入图片说明 安装流程根据官网的安装教程，对应masterGPU CUDA 11.6Linuxx86_64Python3.9pip。已经检查过cuda、cudnn动态链接库的位置无误并加入环境变量（包括cuda的stubs），libmindspore_gpu.so.11.6也存在在对应位置。libge_runner.so不清楚位置以及是否NVIDIA卡是否需要。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`) ,2025-01-20T09:42:05+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBIS7K,执行以下export CUDA_HOME=/cuda这个环境变量再运行试试看，2.3以上的GPU版本可能都需要这个操作，CUDA_HOME的路径随便写一个就行，就能绕过一些检测运行起来,解决了，谢谢！
cccc1111,Sub_补充反向实现与__isub__ / =重载, Tasks 转测对象：tensor.sub_/__isub__/= 对标torch.tensor.sub_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/complex64/complex128/bool  **2. MindSpore算子情况**   当前支持数据类型 sub_ PyNative正反向支持的类型与PTA保持一致 __isub__与=支持类型保持不变  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  与other相减，alpha表示对于other的缩放系数  **2. 接口描述**   接口重载： sub_: !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语 （1）对于tensor.sub_，原始支持Ascend后端正向PyNative模式。目前Ascend后端，正反向PyNative都支持，KBK/GE在input/other情况下，走deprecated，input/other/alpha情况下，会报错。在CPU后端，PyNative模式，走py_bind，KBK/GE在input/other情况下，走deprecated，input/other/alpha情况下，走py_bind。GPU与CPU情况一致。 （2）对于__isub__，原始支持input/other三后端三模式。目前Ascend后端，支持input/other的PyNative模式正反向，KBK/GE走deprecated（与原始流程一致）。CPU后端，PyNative模式支持，走py_bind（与原始流程一致），KBK/GE走deprecated（与原始流程一致）。GPU后端，与CPU后端情况一致。 （3）对于=，原始支持Ascend/CPU/GPU，PyNative/KBK/GE。目前，Ascend后端，正反向PyNative支持，KBK与GE支持，静态图走下图逻辑。CPU后端，正反向PyNative走py_bind（与原始流程一致），KBK与GE支持，静态图走下图逻辑。GPU后端，与CPU后端情况一致。 !输入图片说明,2025-01-19T22:28:35+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBIR3J
shiro-zzz,【AR】PyBoost接口及ACLNN算子适配tensor.mul_ 并重载*=, Tasks 转测对象：tensor.masked_fill_   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-01-18T23:12:11+08:00,"gitee,sig/ops,v2.1.0",progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBIOTQ
wqx,goldenstick的样例代码结果为nan,https://www.mindspore.cn/golden_stick/docs/zhCN/r0.5.0/ptq/round_to_nearest.html 请问下这个示例代码中使用mindspore的哪个版本运行的？目前我测试下来，在2.3.1和2.3.0昇腾环境下，mindformers和gs的版本都是文档里写的1.2.0和0.5.0，然后fp16和量化模型的示例代码的运行评估结果loss和评估指标都是nan: !输入图片说明,2025-01-18T16:10:21+08:00,"gitee,foruda,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBINGH,量化后运行的结果如图： !输入图片说明,round_to_nearest已经废弃，请使用ptq算法代替：https://gitee.com/mindspore/goldenstick/blob/master/mindspore_gs/ptq/ptq/README_CN.md
虞良斌,[docs]Fixed the dynamic profiling case bug,,2025-01-17T10:47:23+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBIEYT
majun-bot,CVE20250518,"一、漏洞信息 漏洞编号：CVE20250518 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector：  漏洞简述： Unchecked Return Value, Outofbounds Read vulnerability in FFmpeg allows Read Sensitive Constants Within an Executable. This vulnerability is associated with program files  https://github.Com/FFmpeg/FFmpeg/blob/master/libavfilter/af_pan.C . This issue affects FFmpeg: 7.1. Issue was fixed:  https://github.com/FFmpeg/FFmpeg/commit/b5b6391d64807578ab872dc58fb8aa621dcfc38a  https://github.com/FFmpeg/FFmpeg/commit/b5b6391d64807578ab872dc58fb8aa621dcfc38a This issue was discovered by: Simcha Kosman 漏洞公开时间：00010101 08:05:43 漏洞创建时间：20250117 04:01:35 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20250518 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞是FFmpeg中未经检查的返回值、越界读取漏洞允许读取可执行文件中的敏感常量，属于libavfilter中的漏洞，Minddata中未使用到libavfilter，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 4.8 &emsp;Vector： CVSS:4.0/AV:N/AC:L/AT:N/PR:L/UI:A/VC:L/VI:N/VA:N/SC:L/SI:N/SA:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-17T04:01:36+08:00,"gitee,CVE/UNAFFECTED,rct/oldrelease,rca/others,ctl/componenttest",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBID73,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞是FFmpeg 中未经检查的返回值、越界读取漏洞允许读取可执行文件中的敏感常量，属于libavfilter中的漏洞，Minddata中未使用到libavfilter，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：4.8 MEDIUM  Vector：CVSS:4.0/AV:N/AC:L/AT:N/PR:L/UI:A/VC:L/VI:N/VA:N/SC:L/SI:N/SA:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Minddata中未使用到libavfilter，故不受影响。
wtcheng,新增并行解码st用例," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-16T17:06:29+08:00,gitee,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBIAPL,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
TuDouNi,ge解耦,,2025-01-16T11:25:00+08:00,gitee,open,0,6,https://gitee.com/mindspore/mindspore/issues/IBI5B4,https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/81424 ,https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/81087 ,https://gitee.com/mindspore/mindspore/pulls/82267包含了https://gitee.com/mindspore/mindspore/pulls/82196,https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/82313,https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/82691,https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/82967
tridu33,现有并行代码计算cpu数量的时候考虑的代码逻辑考虑不够周密，推荐修改一下异常边界情况,"这里是因为Ascend910卡版本问题，需要`.bashrc`中提前设置环境变量`LD_PRELOAD=$LD_PRELOAD:/home/tridu33/.conda/envs/openmindpt/lib/python3.9/sitepackages/scikit_learn.libs/libgompd22c30c5.so.1.0.0:/home/tridu33/.conda/envs/openmindpt/lib/python3.9/sitepackages/torch.libs/libgomp6e1a1d1b.so.1.0.0`才能启动mindspore相关cpp依赖库。 但是 https://gitee.com/mindspore/mindspore/blob/master/mindspore/python/mindspore/parallel/cluster/process_entity/_api.pyL273  这行代码直接判断 ```python             cpu_num = subprocess.getoutput(""cat /proc/cpuinfowc l""线程返回结果是字符串  ```bash ""ERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\nERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\nERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\nERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n192"" ``` 所以推荐补充这个异常情况的边界问题，进行相应的修改",2025-01-16T10:44:47+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBI4NV,解决方案就是上述描述中的改法
hmy2022,【加急】【问题汇总】使用mindspore中MindSpore Golden Stick进行量化，分别使用 2种配置文件有2种不同的错误。,"部署平台：Modelarts 区域：西南贵阳一 公共镜像：mindspore_2.3.0cann_8.0.rc2py_3.9euler_2.10.7aarch64snt9b 实例规格：Ascend: 1*ascendsnt9b1|ARM: 24核 192GB 创建实例后，从将官网下载的已经编译好的包导入。 !输入图片说明 分别安装mindspore 2.3.1/mindformer1.2.0/MindSpore Golden Stick 0.5.0 匹配官网文档中的环境配置。官网文档为https://www.mindspore.cn/golden_stick/docs/zhCN/r0.5.0/ptq/round_to_nearest.html !输入图片说明 然后按照教程准备workspace,ckpt文件是从教程中的链接下载。 配置config文件，在gitee源码中分别找到2种配置文件模板分别进行测试。 路径如下： !输入图片说明 !输入图片说明 图一运行后会报无法找到量化层的错误（已经进行推理测试，推理脚本可以正常运行） 图二运行后会运行无输出，等待45分钟无果。 图一配置文件为： ``` config  seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: './workspace/llama2_7b.ckpt' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'predict'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 1   sink_mode: True   sink_size: 2   gradient_accumulation_steps: 8  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr sechdule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: False   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 1   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: False   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMonitor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   max_call_depth: 10000   max_device_memory: ""28GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 4096     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""float16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float32""     rotary_dtype: ""float16""     param_init_type: ""float16""     use_past: True     scaling_factor: 1.0  The scale factor of seq length     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     use_flash_attention: True  FA can accelerate training or finetune     block_size: 16     num_blocks: 1024     is_dynamic: True     qkv_concat: False     offset: 0     checkpoint_name_or_path: """"     repetition_penalty: 1     max_decode_length: 512     top_k: 3     top_p: 1     do_sample: False   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer     vocab_file: './workspace/tokenizer.model'   type: LlamaProcessor  metric metric:   type: EmF1Metric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform."" ``` 报错为： ```  Quantizeing network... 20250115 21:08:01,128  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 4096, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250115 21:08:01,130  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250115 21:08:01,131  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250115 21:08:01,132  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. 20250115 21:08:01,134  mindformers[mindformers/models/llama/llama.py:386]  INFO  Set dynamic input for llama. [ERROR] KERNEL(48504,fffc237fe1e0,python):2025011521:08:35.340.595 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:70] Build] Internal Op 'Gather' is initialized FAILED. [ERROR] KERNEL(48504,fffc237fe1e0,python):2025011521:08:35.340.646 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:165] Resize] op Gather build kernel failed [ERROR] KERNEL(48504,fffc22ffd1e0,python):2025011521:08:43.931.679 [mindspore/ccsrc/kernel/kernel.cc:538] SyncDataFromDeviceToHost] Not malloc device memory yet, sync data from device to host side failed, size: 16 [ERROR] RUNTIME_FRAMEWORK(48504,fffc227fc1e0,python):2025011521:08:43.936.487 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(48504,fffc227fc1e0,python):2025011521:08:43.936.741 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(48504,fffc21ffb1e0,python):2025011521:08:43.936.760 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(48504,fffc21ffb1e0,python):2025011521:08:43.936.896 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod  RuntimeError                              Traceback (most recent call last) Cell In[1], line 68      66 print(' Quantizeing network...', flush=True)      67 start = time.time() > 68 network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config)      69 logger.info(f'Quant Network cost time is {time.time()  start} s.')      70 print(' Saving checkpoint...', flush=True) Cell In[1], line 45, in quant_network(net, mode, backend, **kwargs)      43     raise ValueError(""Please provide mfconfig for calibrating."")      44 network_helper = MFLlama2Helper(mfconfig) > 45 net = ptq.apply(net, network_helper)      46 logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')      47 start_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/round_to_nearest/round_to_nearest.py:194, in RoundToNearest.apply(self, network, network_helper)     192     if network_helper:     193         bs = network_helper.get_spec(""batch_size"") if network_helper.get_spec(""batch_size"") else 1 > 194         network_helper.generate(network, input_ids=np.ones([bs, 1], dtype=np.int32))     195 else:     196     warn_str = ""No layer found in network is suitable for quantization, please check network and "" \     197                ""opname_blacklist."" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/network_helpers/mf_net_helpers.py:60, in MFNetworkHelper.generate(self, mf_network, input_ids, max_new_tokens, **kwargs)      58 top_p = self.mf_config.model.model_config.top_p      59 top_k = self.mf_config.model.model_config.top_k > 60 return mf_network.generate(input_ids, do_sample=do_sample, max_length=seq, max_new_tokens=max_new_tokens,      61                            top_p=top_p, top_k=top_k) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:848, in GenerationMixin.generate(self, input_ids, generation_config, logits_processor, streamer, seed, **kwargs)     844     else:     845         block_tables, slot_mapping = self.block_mgr.assemble_pa_inc_inputs(valid_length_each_example,     846                                                                            is_finished) > 848 infer_output, is_finished = self.infer(input_ids=input_ids,     849                                        valid_length_each_example=valid_length_each_example,     850                                        generation_config=generation_config,     851                                        logits_processor=logits_processor,     852                                        logits_warper=logits_warper,     853                                        block_tables=block_tables,     854                                        slot_mapping=slot_mapping,     855                                        prefill=prefill,     856                                        is_finished=is_finished,     857                                        encoder_mask=encoder_mask,     858                                        encoder_output=encoder_output,     859                                        target_mask=target_mask,     860                                        **model_kwargs)     861 if generation_config.return_dict_in_generate:     862     target_list = infer_output[""target_list""] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:986, in GenerationMixin.infer(self, input_ids, valid_length_each_example, generation_config, logits_processor, logits_warper, block_tables, slot_mapping, prefill, is_finished, encoder_mask, encoder_output, target_mask, **model_kwargs)     983 start_time = time.time()     985 input_ids = np.array(input_ids) > 986 res, current_index = self.forward(input_ids=input_ids,     987                                   valid_length_each_example=valid_length_each_example,     988                                   block_tables=block_tables,     989                                   slot_mapping=slot_mapping,     990                                   prefill=prefill,     991                                   use_past=generation_config.use_past,     992                                   encoder_mask=encoder_mask,     993                                   encoder_output=encoder_output,     994                                   target_mask=target_mask,     995                                   **model_kwargs)     997 forward_time = time.time()  start_time     998 sample_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:1100, in GenerationMixin.forward(self, input_ids, valid_length_each_example, block_tables, slot_mapping, prefill, use_past, encoder_mask, encoder_output, target_mask, **model_kwargs)    1097 model_kwargs[""current_index""] = current_index    1099 if use_past: > 1100     res = self._incremental_infer(    1101         model_inputs=model_inputs,    1102         prefill=prefill,    1103         current_index=current_index,    1104         valid_length_each_example=valid_length_each_example,    1105         block_tables=block_tables,    1106         slot_mapping=slot_mapping    1107     )    1108 else:    1109     res = self(**model_inputs)   pylint: disable=E1102 File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:313, in GenerationMixin._incremental_infer(self, model_inputs, prefill, current_index, valid_length_each_example, block_tables, slot_mapping)     311     model_inputs[""slot_mapping""] = Tensor.from_numpy(slot_mapping)     312  pylint: disable=E1102 > 313 res = self(     314     **model_inputs,     315 )     316 ms.hal.synchronize()     317 self.phase = ""increment"" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:703, in Cell.__call__(self, *args, **kwargs)     700         logger.warning(f""For 'Cell', it's not support hook function in graph mode. If you want to use hook ""     701                        f""function, please use context.set_context to set pynative mode."")     702     self._self_check() > 703     out = self.compile_and_run(*args, **kwargs)     704     return out     706  Run in PyNative mode. File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:1074, in Cell.compile_and_run(self, *args, **kwargs)    1072 self.add_flags(ge_sync_data=False)    1073 new_args = _get_args_for_run(self, args, kwargs, self._compile_args) > 1074 return _cell_graph_executor(self, *new_args, phase=self.phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1860, in _CellGraphExecutor.__call__(self, obj, phase, *args)    1858 if context.get_context(""precompile_only"") or _is_role_sched():    1859     return None > 1860 return self.run(obj, *args, phase=phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1911, in _CellGraphExecutor.run(self, obj, phase, *args)    1909 phase_real = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key    1910 if self.has_compiled(phase_real): > 1911     return self._exec_pip(obj, *args, phase=phase_real)    1912 raise KeyError('{} graph is not exist.'.format(phase_real)) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:185, in _wrap_func..wrapper(*arg, **kwargs)     183 (fn)     184 def wrapper(*arg, **kwargs): > 185     results = fn(*arg, **kwargs)     186     return _convert_python_data(results) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1891, in _CellGraphExecutor._exec_pip(self, obj, phase, *args)    1889 fn = obj.construct    1890 obj.__parse_method__ = fn.__name__ > 1891 return self._graph_executor(args, phase) RuntimeError: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod ``` 图二配置文件为： ``` seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: './workspace/llama2_7b.ckpt' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'train'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 6   sink_mode: True   sink_size: 2  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr sechdule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: True   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 4   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: True   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMointor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   graph_kernel_flags: ""disable_expand_ops=Softmax,Dropout enable_parallel_fusion=true reduce_fuse_depth=8 enable_auto_tensor_inplace=true""   max_call_depth: 10000   max_device_memory: ""28GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 1024     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""bfloat16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float16""     rotary_dtype: ""float32""     param_init_type: ""float16""     use_past: True     pretrain_seqlen: 4096  seqlen of the pretrain checkpoint: 2048 for llama and 4096 for llama2     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     compute_in_2d: True     use_flash_attention: False  FA can accelerate training or finetune     offset: 0     use_past_shard: False     checkpoint_name_or_path: """"     repetition_penalty: 1     max_decode_length: 700     top_k: 3     top_p: 1     do_sample: False     max_new_tokens: 20   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer     vocab_file: './workspace/tokenizer.model'   type: LlamaProcessor  metric metric:   type: PerplexityMetric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform."" ``` 报错为，运行到此即卡住，等待45分钟无果： ``` /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal)  Creating network... 20250115 20:20:41,243  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. [WARNING] DEVICE(3433,ffff83f0c0b0,python):2025011520:20:44.575.380 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:96] Initialize] Reserved memory size for other components(1610612736) is less than recommend size(1958250496), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory' [WARNING] CORE(3433,ffff83f0c0b0,python):2025011520:20:44.575.480 [mindspore/core/utils/ms_context.cc:531] GetJitLevel] Set jit level to O2 for rank table startup method. 20250115 20:20:48,554  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250115 20:20:48,558  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN [WARNING] ME(3433:281472895336624,MainProcess):2025011520:20:48.569.873 [mindspore/ops/primitive.py:204] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored.  If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL) 20250115 20:20:55,088  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False [WARNING] ME(3433:281472895336624,MainProcess):2025011520:20:55.917.33 [mindspore/common/parameter.py:805] This interface may be deleted in the future. 20250115 20:20:59,695  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:04,247  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:08,791  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:13,370  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:17,969  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:22,585  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:27,078  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:31,681  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:36,254  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:23:19,060  mindformers[mindformers/models/modeling_utils.py:1531]  INFO  model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None. 20250115 20:23:19,062  mindformers[mindformers/models/modeling_utils.py:599]  INFO  Set jit config for jit level:O0 and infer boost:on. 20250115 20:23:19,064  mindformers[mindformers/models/llama/llama.py:350]  INFO  Predict run mode:False [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.643.779 [mindspore/train/serialization.py:214] The type of model.layers.0.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.646.001 [mindspore/train/serialization.py:214] The type of model.layers.0.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.652.441 [mindspore/train/serialization.py:214] The type of model.layers.1.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.654.311 [mindspore/train/serialization.py:214] The type of model.layers.1.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.660.409 [mindspore/train/serialization.py:214] The type of model.layers.2.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.661.957 [mindspore/train/serialization.py:214] The type of model.layers.2.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.668.053 [mindspore/train/serialization.py:214] The type of model.layers.3.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.669.683 [mindspore/train/serialization.py:214] The type of model.layers.3.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.676.145 [mindspore/train/serialization.py:214] The type of model.layers.4.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.677.484 [mindspore/train/serialization.py:214] The type of model.layers.4.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.683.567 [mindspore/train/serialization.py:214] The type of model.layers.5.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.685.208 [mindspore/train/serialization.py:214] The type of model.layers.5.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.691.514 [mindspore/train/serialization.py:214] The type of model.layers.6.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.692.708 [mindspore/train/serialization.py:214] The type of model.layers.6.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.698.961 [mindspore/train/serialization.py:214] The type of model.layers.7.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.700.901 [mindspore/train/serialization.py:214] The type of model.layers.7.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.707.462 [mindspore/train/serialization.py:214] The type of model.layers.8.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.708.905 [mindspore/train/serialization.py:214] The type of model.layers.8.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.715.230 [mindspore/train/serialization.py:214] The type of model.layers.9.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.716.455 [mindspore/train/serialization.py:214] The type of model.layers.9.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.722.973 [mindspore/train/serialization.py:214] The type of model.layers.10.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.724.214 [mindspore/train/serialization.py:214] The type of model.layers.10.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.730.835 [mindspore/train/serialization.py:214] The type of model.layers.11.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.732.327 [mindspore/train/serialization.py:214] The type of model.layers.11.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.739.029 [mindspore/train/serialization.py:214] The type of model.layers.12.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. ... [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.889.925 [mindspore/train/serialization.py:214] The type of model.layers.31.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.896.275 [mindspore/train/serialization.py:214] The type of model.norm_out.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.903.864 [mindspore/train/serialization.py:1560] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.905.452 [mindspore/train/serialization.py:1564] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded. Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...  Quantizeing network... 20250115 20:24:14,303  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 1024, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250115 20:24:14,306  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250115 20:24:14,307  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250115 20:24:14,309  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. ```",2025-01-16T09:47:47+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBI3TU,mindsporeassistant,错误已经定位，同样的代码使用终端脚本即可运行，使用notebook运行会报以上错误。
cccc1111,Div_补充反向实现与/=重载, Tasks 转测对象：tensor.div_ 与 /= 对标torch.tensor.div_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/complex64/complex128/bool  **2. MindSpore算子情况**   当前支持数据类型 tensor.div_ Ascend后端支持数据类型与torch_npu保持一致，CPU/GPU后端支持数据类型为div_op支持类型 /= Ascend后端PyNative支持数据类型与torch_npu保持一致，KBK/GE与之前保持一致。CPU/GPU的PyNative支持数据类型为div_op支持类型，KBK/GE与之前保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  与other相除，rounding_mode表示对于结果的取整操作  **2. 接口描述**   ops接口   mint/tensor接口： Div_: !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语 （1）对于tensor.div_，原始支持Ascend后端正向PyNative模式。目前Ascend后端，正反向PyNative支持，KBK与GE不支持。CPU/GPU后端走div_op。 （2）对于/=，原始支持Ascend/CPU/GPU，PyNative/KBK/GE。目前，Ascend后端，正反向PyNative支持（支持的类型变少），KBK与GE支持（不走当前div_.yaml）。CPU后端，正反向PyNative支持（支持的类型一致），KBK与GE支持。GPU后端，正反向PyNative支持（支持类型一致），KBK与GE支持。,2025-01-15T16:05:22+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBHZNE
hmy2022,[mindforemer1.2.0][mindspore2.3.1[MindSpore Golden Stick 0.5.0]使用RoundToNearest量化Llama2网络出现找不到要量化的层的报错。急急急！求大佬看看！！救救孩子,"服务器使用Modelart服务器 使用官方镜像：mindspore_2.3.0cann_8.0.rc2py_3.9euler_2.10.7aarch64snt9b 进入镜像后手动升级mindspore_2.3.1 实例规格为：Ascend: 1*ascendsnt9b1|ARM: 24核 192GB 整体报错如下： `WARNING] ME(1603:281473745211568,MainProcess):2025011422:54:49.250.432 [mindspore/context.py:1208] For 'context.set_context' in Ascend backend, the backend is already initialized, please set it before the definition of any Tensor and Parameter, and the instantiation and execution of any operation and net, otherwise the settings may not take effect.  20250114 22:54:49,253  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. 20250114 22:54:49,260  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250114 22:54:49,261  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN 20250114 22:54:53,939  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:54:56,641  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:54:59,341  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:02,046  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:04,742  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:07,457  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:10,145  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:12,859  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:15,543  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:18,253  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:56:19,256  mindformers[mindformers/models/modeling_utils.py:1531]  INFO  model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None. 20250114 22:56:19,259  mindformers[mindformers/models/modeling_utils.py:599]  INFO  Set jit config for jit level:O0 and infer boost:on. 20250114 22:56:19,260  mindformers[mindformers/models/llama/llama.py:350]  INFO  Predict run mode:False [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.627.357 [mindspore/train/serialization.py:214] The type of model.layers.0.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.629.663 [mindspore/train/serialization.py:214] The type of model.layers.0.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.636.347 [mindspore/train/serialization.py:214] The type of model.layers.1.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.637.642 [mindspore/train/serialization.py:214] The type of model.layers.1.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.643.761 [mindspore/train/serialization.py:214] The type of model.layers.2.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.645.132 [mindspore/train/serialization.py:214] The type of model.layers.2.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.651.315 [mindspore/train/serialization.py:214] The type of model.layers.3.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.652.885 [mindspore/train/serialization.py:214] The type of model.layers.3.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.658.972 [mindspore/train/serialization.py:214] The type of model.layers.4.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.660.397 [mindspore/train/serialization.py:214] The type of model.layers.4.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.667.128 [mindspore/train/serialization.py:214] The type of model.layers.5.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.668.244 [mindspore/train/serialization.py:214] The type of model.layers.5.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.674.960 [mindspore/train/serialization.py:214] The type of model.layers.6.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.676.102 [mindspore/train/serialization.py:214] The type of model.layers.6.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.682.704 [mindspore/train/serialization.py:214] The type of model.layers.7.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.683.979 [mindspore/train/serialization.py:214] The type of model.layers.7.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.690.539 [mindspore/train/serialization.py:214] The type of model.layers.8.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.691.673 [mindspore/train/serialization.py:214] The type of model.layers.8.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.698.256 [mindspore/train/serialization.py:214] The type of model.layers.9.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.699.377 [mindspore/train/serialization.py:214] The type of model.layers.9.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.705.350 [mindspore/train/serialization.py:214] The type of model.layers.10.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.706.861 [mindspore/train/serialization.py:214] The type of model.layers.10.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.712.884 [mindspore/train/serialization.py:214] The type of model.layers.11.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.714.298 [mindspore/train/serialization.py:214] The type of model.layers.11.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.721.315 [mindspore/train/serialization.py:214] The type of model.layers.12.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.722.441 [mindspore/train/serialization.py:214] The type of model.layers.12.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.728.591 [mindspore/train/serialization.py:214] The type of model.layers.13.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.729.868 [mindspore/train/serialization.py:214] The type of model.layers.13.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.737.254 [mindspore/train/serialization.py:214] The type of model.layers.14.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.738.395 [mindspore/train/serialization.py:214] The type of model.layers.14.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.744.603 [mindspore/train/serialization.py:214] The type of model.layers.15.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.746.005 [mindspore/train/serialization.py:214] The type of model.layers.15.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.752.645 [mindspore/train/serialization.py:214] The type of model.layers.16.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.753.873 [mindspore/train/serialization.py:214] The type of model.layers.16.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.760.451 [mindspore/train/serialization.py:214] The type of model.layers.17.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.761.635 [mindspore/train/serialization.py:214] The type of model.layers.17.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.768.596 [mindspore/train/serialization.py:214] The type of model.layers.18.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.769.707 [mindspore/train/serialization.py:214] The type of model.layers.18.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.775.768 [mindspore/train/serialization.py:214] The type of model.layers.19.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.777.286 [mindspore/train/serialization.py:214] The type of model.layers.19.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.783.091 [mindspore/train/serialization.py:214] The type of model.layers.20.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.784.769 [mindspore/train/serialization.py:214] The type of model.layers.20.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.790.762 [mindspore/train/serialization.py:214] The type of model.layers.21.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.792.270 [mindspore/train/serialization.py:214] The type of model.layers.21.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.798.116 [mindspore/train/serialization.py:214] The type of model.layers.22.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.799.636 [mindspore/train/serialization.py:214] The type of model.layers.22.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.805.575 [mindspore/train/serialization.py:214] The type of model.layers.23.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.807.081 [mindspore/train/serialization.py:214] The type of model.layers.23.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.814.069 [mindspore/train/serialization.py:214] The type of model.layers.24.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.815.241 [mindspore/train/serialization.py:214] The type of model.layers.24.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.820.905 [mindspore/train/serialization.py:214] The type of model.layers.25.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.822.717 [mindspore/train/serialization.py:214] The type of model.layers.25.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.828.665 [mindspore/train/serialization.py:214] The type of model.layers.26.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.830.339 [mindspore/train/serialization.py:214] The type of model.layers.26.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.836.761 [mindspore/train/serialization.py:214] The type of model.layers.27.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.838.244 [mindspore/train/serialization.py:214] The type of model.layers.27.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.843.825 [mindspore/train/serialization.py:214] The type of model.layers.28.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.845.606 [mindspore/train/serialization.py:214] The type of model.layers.28.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.851.154 [mindspore/train/serialization.py:214] The type of model.layers.29.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.852.395 [mindspore/train/serialization.py:214] The type of model.layers.29.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.858.770 [mindspore/train/serialization.py:214] The type of model.layers.30.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.859.966 [mindspore/train/serialization.py:214] The type of model.layers.30.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.866.195 [mindspore/train/serialization.py:214] The type of model.layers.31.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.867.576 [mindspore/train/serialization.py:214] The type of model.layers.31.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.873.532 [mindspore/train/serialization.py:214] The type of model.norm_out.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.880.971 [mindspore/train/serialization.py:1560] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.881.720 [mindspore/train/serialization.py:1564] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded.  Quantizeing network... 20250114 22:57:16,308  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 4096, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250114 22:57:16,311  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250114 22:57:16,313  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250114 22:57:16,314  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. 20250114 22:57:16,316  mindformers[mindformers/models/llama/llama.py:386]  INFO  Set dynamic input for llama. [ERROR] KERNEL(1603,fffc1e7f61e0,python):2025011422:57:48.163.234 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:70] Build] Internal Op 'Gather' is initialized FAILED. [ERROR] KERNEL(1603,fffc1e7f61e0,python):2025011422:57:48.163.281 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:165] Resize] op Gather build kernel failed [ERROR] KERNEL(1603,fffc1dff51e0,python):2025011422:57:56.093.849 [mindspore/ccsrc/kernel/kernel.cc:538] SyncDataFromDeviceToHost] Not malloc device memory yet, sync data from device to host side failed, size: 16 [ERROR] RUNTIME_FRAMEWORK(1603,fff6e0c571e0,python):2025011422:57:56.098.461 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(1603,fff6e0c571e0,python):2025011422:57:56.098.691 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(1603,fff6e0c571e0,python):2025011422:57:56.098.782 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(1603,fff6d3fff1e0,python):2025011422:57:56.098.867 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod  RuntimeError                              Traceback (most recent call last) Cell In[3], line 68      66 print(' Quantizeing network...', flush=True)      67 start = time.time() > 68 network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config)      69 logger.info(f'Quant Network cost time is {time.time()  start} s.')      70 print(' Saving checkpoint...', flush=True) Cell In[3], line 45, in quant_network(net, mode, backend, **kwargs)      43     raise ValueError(""Please provide mfconfig for calibrating."")      44 network_helper = MFLlama2Helper(mfconfig) > 45 net = ptq.apply(net, network_helper)      46 logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')      47 start_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/round_to_nearest/round_to_nearest.py:194, in RoundToNearest.apply(self, network, network_helper)     192     if network_helper:     193         bs = network_helper.get_spec(""batch_size"") if network_helper.get_spec(""batch_size"") else 1 > 194         network_helper.generate(network, input_ids=np.ones([bs, 1], dtype=np.int32))     195 else:     196     warn_str = ""No layer found in network is suitable for quantization, please check network and "" \     197                ""opname_blacklist."" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/network_helpers/mf_net_helpers.py:60, in MFNetworkHelper.generate(self, mf_network, input_ids, max_new_tokens, **kwargs)      58 top_p = self.mf_config.model.model_config.top_p      59 top_k = self.mf_config.model.model_config.top_k > 60 return mf_network.generate(input_ids, do_sample=do_sample, max_length=seq, max_new_tokens=max_new_tokens,      61                            top_p=top_p, top_k=top_k) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:848, in GenerationMixin.generate(self, input_ids, generation_config, logits_processor, streamer, seed, **kwargs)     844     else:     845         block_tables, slot_mapping = self.block_mgr.assemble_pa_inc_inputs(valid_length_each_example,     846                                                                            is_finished) > 848 infer_output, is_finished = self.infer(input_ids=input_ids,     849                                        valid_length_each_example=valid_length_each_example,     850                                        generation_config=generation_config,     851                                        logits_processor=logits_processor,     852                                        logits_warper=logits_warper,     853                                        block_tables=block_tables,     854                                        slot_mapping=slot_mapping,     855                                        prefill=prefill,     856                                        is_finished=is_finished,     857                                        encoder_mask=encoder_mask,     858                                        encoder_output=encoder_output,     859                                        target_mask=target_mask,     860                                        **model_kwargs)     861 if generation_config.return_dict_in_generate:     862     target_list = infer_output[""target_list""] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:986, in GenerationMixin.infer(self, input_ids, valid_length_each_example, generation_config, logits_processor, logits_warper, block_tables, slot_mapping, prefill, is_finished, encoder_mask, encoder_output, target_mask, **model_kwargs)     983 start_time = time.time()     985 input_ids = np.array(input_ids) > 986 res, current_index = self.forward(input_ids=input_ids,     987                                   valid_length_each_example=valid_length_each_example,     988                                   block_tables=block_tables,     989                                   slot_mapping=slot_mapping,     990                                   prefill=prefill,     991                                   use_past=generation_config.use_past,     992                                   encoder_mask=encoder_mask,     993                                   encoder_output=encoder_output,     994                                   target_mask=target_mask,     995                                   **model_kwargs)     997 forward_time = time.time()  start_time     998 sample_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:1100, in GenerationMixin.forward(self, input_ids, valid_length_each_example, block_tables, slot_mapping, prefill, use_past, encoder_mask, encoder_output, target_mask, **model_kwargs)    1097 model_kwargs[""current_index""] = current_index    1099 if use_past: > 1100     res = self._incremental_infer(    1101         model_inputs=model_inputs,    1102         prefill=prefill,    1103         current_index=current_index,    1104         valid_length_each_example=valid_length_each_example,    1105         block_tables=block_tables,    1106         slot_mapping=slot_mapping    1107     )    1108 else:    1109     res = self(**model_inputs)   pylint: disable=E1102 File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:313, in GenerationMixin._incremental_infer(self, model_inputs, prefill, current_index, valid_length_each_example, block_tables, slot_mapping)     311     model_inputs[""slot_mapping""] = Tensor.from_numpy(slot_mapping)     312  pylint: disable=E1102 > 313 res = self(     314     **model_inputs,     315 )     316 ms.hal.synchronize()     317 self.phase = ""increment"" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:703, in Cell.__call__(self, *args, **kwargs)     700         logger.warning(f""For 'Cell', it's not support hook function in graph mode. If you want to use hook ""     701                        f""function, please use context.set_context to set pynative mode."")     702     self._self_check() > 703     out = self.compile_and_run(*args, **kwargs)     704     return out     706  Run in PyNative mode. File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:1074, in Cell.compile_and_run(self, *args, **kwargs)    1072 self.add_flags(ge_sync_data=False)    1073 new_args = _get_args_for_run(self, args, kwargs, self._compile_args) > 1074 return _cell_graph_executor(self, *new_args, phase=self.phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1860, in _CellGraphExecutor.__call__(self, obj, phase, *args)    1858 if context.get_context(""precompile_only"") or _is_role_sched():    1859     return None > 1860 return self.run(obj, *args, phase=phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1911, in _CellGraphExecutor.run(self, obj, phase, *args)    1909 phase_real = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key    1910 if self.has_compiled(phase_real): > 1911     return self._exec_pip(obj, *args, phase=phase_real)    1912 raise KeyError('{} graph is not exist.'.format(phase_real)) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:185, in _wrap_func..wrapper(*arg, **kwargs)     183 (fn)     184 def wrapper(*arg, **kwargs): > 185     results = fn(*arg, **kwargs)     186     return _convert_python_data(results) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1891, in _CellGraphExecutor._exec_pip(self, obj, phase, *args)    1889 fn = obj.construct    1890 obj.__parse_method__ = fn.__name__ > 1891 return self._graph_executor(args, phase) RuntimeError: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod ` 运行代码为： ``` import os import time import mindspore as ms from mindformers import LlamaForCausalLM, MindFormerConfig, LlamaConfig, init_context from mindspore_gs.ptq import PTQMode, PTQConfig from mindspore_gs.common import BackendTarget, logger from mindspore_gs.ptq import RoundToNearest as RTN from mindspore_gs.ptq.network_helpers.mf_net_helpers import MFLlama2Helper class Llama2Network:     """"""Llama2Network.""""""          def create_mfconfig(config_path):         """"""Create mindformers config for llama2 network for example.""""""         config = MindFormerConfig(config_path)         config.model.model_config = LlamaConfig(**config.model.model_config)         init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel)         return config          def create_network(mindformers_config):         network = LlamaForCausalLM(mindformers_config.model.model_config)         network.set_train(False)         network.phase = 'predict'         return network def quant_network(net: LlamaForCausalLM, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, **kwargs):     """"""Quant llama2 model to w8a16 with RTN algorithm.""""""     start_time = time.time()     if mode == PTQMode.QUANTIZE:         logger.info(""Use RTN algo to quant network and weight."")     else:         logger.info(""Use RTN algo to quant network."")     cfg = PTQConfig(mode=mode, backend=backend, opname_blacklist=[""lm_head""])     ptq = RTN(config=cfg)     logger.info(f'Create PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     mfconfig = kwargs.get(""mfconfig"", None)     if not mfconfig:         raise ValueError(""Please provide mfconfig for calibrating."")     network_helper = MFLlama2Helper(mfconfig)     net = ptq.apply(net, network_helper)     logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     net.phase = ""quant_convert""     net = ptq.convert(net)     logger.info(f'Convert to real quantize cost time is {time.time()  start_time} s.')     return net start = time.time() print(' Creating network...', flush=True) net_mgr: Llama2Network = Llama2Network() config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") network = net_mgr.create_network(config) logger.info(f'Create Network cost time is {time.time()  start} s.') start = time.time() ckpt_path = config.load_checkpoint logger.info(f'Loading ckpt :{ckpt_path}.') ms.load_checkpoint(ckpt_path, network) ms.ms_memory_recycle() logger.info(f'Load ckpt cost time is {time.time()  start} s.') print(' Quantizeing network...', flush=True) start = time.time() network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config) logger.info(f'Quant Network cost time is {time.time()  start} s.') print(' Saving checkpoint...', flush=True) start = time.time() save_ckpt_path = os.path.join(config.output_dir, ""w8a16_ckpt"") save_path = os.path.join(save_ckpt_path, f""rank_0"") os.makedirs(save_path, exist_ok=True) ms.save_checkpoint(network.parameters_dict(), os.path.join(save_path, ""w8a16.ckpt""),                    choice_func=lambda x: ""key_cache"" not in x and ""value_cache"" not in x) logger.info(f'Save checkpoint cost time is {time.time()  start} s.') print(f' Checkpoint saved to {save_path}...', flush=True) ``` 配置文件为： ``` seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: './workspace/llama2_7b.ckpt' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'predict'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 1   sink_mode: True   sink_size: 2   gradient_accumulation_steps: 8  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr sechdule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 1   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: False   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 1   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: False   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMonitor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   max_call_depth: 10000   max_device_memory: ""28GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 4096     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""float16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float32""     rotary_dtype: ""float16""     param_init_type: ""float16""     use_past: True     scaling_factor: 1.0  The scale factor of seq length     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     use_flash_attention: True  FA can accelerate training or finetune     block_size: 16     num_blocks: 1024     is_dynamic: True     qkv_concat: False     offset: 0     checkpoint_name_or_path: """"     repetition_penalty: 1     max_decode_length: 512     top_k: 3     top_p: 1     do_sample: False   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer     vocab_file: './workspace/tokenizer.model'   type: LlamaProcessor  metric metric:   type: EmF1Metric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform.""```",2025-01-14T23:08:15+08:00,"foruda,www,www,www,www,www,www",progressing,0,12,https://gitee.com/mindspore/mindspore/issues/IBHTTR,mindsporeassistant,算法：RTN 8bit权重量化 报错阶段：量化统计权重minmax阶段 报错层：llama2网络开头的词表embedding层 根据日志可以发现报错发生在词表embedding层，尚未进入量化统计层，该报错时理论上与量化无关。请确保当前配置下可以进行该网络的浮点推理，再使用量化算法。,!使用推理脚本是可以正常推理的 使用推理脚本是可以正常推理的,"使用官方的包，mindspore2.3.1，mindformers1.2.0，mindspore_gs0.5.0，无法复现问题，运行代码ok： ``` $ python run.py [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:10.219.000 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:10.219.000 [mindspore/run_check/_check_version.py:469] Can not find driver so(need by mindsporeascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install  Creating network... [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.925.000 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.925.000 [mindspore/run_check/_check_version.py:469] Can not find driver so(need by mindsporeascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.926.000 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.926.000 [mindspore/run_check/_check_version.py:469] Can not find driver so(need by mindsporeascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install 20250116 14:05:15,927  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. [WARNING] DEVICE(1902031,ffffb838faf0,python):2025011614:05:16.140.448 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:96] Initialize] Reserved memory size for other components(1610612736) is less than recommend size(1956155136), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory' 20250116 14:05:20,204  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250116 14:05:20,204  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:20.227.000 [mindspore/ops/primitive.py:204] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL) 20250116 14:05:24,522  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:24.523.000 [mindspore/common/parameter.py:805] This interface may be deleted in the future. 20250116 14:05:27,275  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:30,022  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:32,708  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:35,407  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:38,193  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:41,018  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:43,815  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:46,466  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:49,185  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:06:51,880  mindformers[mindformers/models/modeling_utils.py:1531]  INFO  model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None. 20250116 14:06:51,881  mindformers[mindformers/models/modeling_utils.py:599]  INFO  Set jit config for jit level:O0 and infer boost:on. 20250116 14:06:51,881  mindformers[mindformers/models/llama/llama.py:350]  INFO  Predict run mode:False  Quantizeing network... 20250116 14:06:53,828  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 4096, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250116 14:06:53,828  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250116 14:06:53,829  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250116 14:06:53,829  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. 20250116 14:06:53,830  mindformers[mindformers/models/llama/llama.py:386]  INFO  Set dynamic input for llama. 20250116 14:07:35,466  mindformers[mindformers/generation/text_generator.py:908]  INFO  total time: 41.63577461242676 s; generated tokens: 1 tokens; generate speed: 0.024017807025536558 tokens/s 20250116 14:07:35,477  mindformers[mindformers/modules/block_tables.py:129]  INFO  Clear block table cache engines.  Saving checkpoint...  Checkpoint saved to ./output/w8a16_ckpt/rank_0... ```",请问使用配置文件是什么呢，是裸机开发还是ModelArt开发呢,用了你提供的配置文件，去除了ckpt的加载 裸机开发,用modelart不知道为什么就会失败，如果是裸机手头只有310b的应该是肯定量化不了吧,不太了解modelart是啥。 310P机器确实没有验证过算法是否能运行，理论上会有两个问题 1）性能较差，算法耗时较长 2）如果最终部署环境不是310P，在310P上校准会有误差，导致精度损失较大,modelart是华为云的服务器，我是想量化后的模型放到310上跑下。那也就是说即使我在910b上量化完，想在香橙派的310端侧部署也会精度损失很大吗,会有精度损失，但也不一定会造成致命精度退化,这个问题可以抓取一些日志再分析下： 1. env  grep INTERNAL 3. export GLOG_v=1 后重新抓一把日志,错误已经定位，同样的代码使用终端脚本即可运行，使用notebook运行会报以上错误。
虞良斌,Fixed a bug that read profiler_info.json for offline parsing,,2025-01-14T19:25:13+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBHT1B
xiedejin1,【AR】PyBoost接口及Aclnn算子适配@=(tensor.__imatmul__), Tasks 转测对象：@=(tensor.\_\_imatmul\_\_) ,2025-01-14T14:39:18+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBHPEJ
虞良斌,[docs]Dynamic profiling config configuration adds aicore_metrics parameter conversion,,2025-01-14T09:42:57+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBHLPN
hmy2022,急求大佬回复，根据官方教程进行RoundToNearest后量化出现以下set_context()报错，使用modelarts昇腾平台单卡。,"代码为 `import os import time import mindspore as ms from mindformers import LlamaForCausalLM, MindFormerConfig, LlamaConfig, init_context from mindspore_gs.ptq import PTQMode, PTQConfig from mindspore_gs.common import BackendTarget, logger from mindspore_gs.ptq import RoundToNearest as RTN from mindspore_gs.ptq.network_helpers.mf_net_helpers import MFLlama2Helper class Llama2Network:     """"""Llama2Network.""""""          def create_mfconfig(config_path):         """"""Create mindformers config for llama2 network for example.""""""         config = MindFormerConfig(config_path)         config.model.model_config = LlamaConfig(**config.model.model_config)         init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel)         return config          def create_network(mindformers_config):         network = LlamaForCausalLM(mindformers_config.model.model_config)         network.set_train(False)         network.phase = 'predict'         return network def quant_network(net: LlamaForCausalLM, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, **kwargs):     """"""Quant llama2 model to w8a16 with RTN algorithm.""""""     start_time = time.time()     if mode == PTQMode.QUANTIZE:         logger.info(""Use RTN algo to quant network and weight."")     else:         logger.info(""Use RTN algo to quant network."")     cfg = PTQConfig(mode=mode, backend=backend, opname_blacklist=[""lm_head""])     ptq = RTN(config=cfg)     logger.info(f'Create PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     mfconfig = kwargs.get(""mfconfig"", None)     if not mfconfig:         raise ValueError(""Please provide mfconfig for calibrating."")     network_helper = MFLlama2Helper(mfconfig)     net = ptq.apply(net, network_helper)     logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     net.phase = ""quant_convert""     net = ptq.convert(net)     logger.info(f'Convert to real quantize cost time is {time.time()  start_time} s.')     return net start = time.time() print(' Creating network...', flush=True) net_mgr: Llama2Network = Llama2Network() config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") network = net_mgr.create_network(config) logger.info(f'Create Network cost time is {time.time()  start} s.') start = time.time() ckpt_path = config.load_checkpoint logger.info(f'Loading ckpt :{ckpt_path}.') ms.load_checkpoint(ckpt_path, network) ms.ms_memory_recycle() logger.info(f'Load ckpt cost time is {time.time()  start} s.') print(' Quantizeing network...', flush=True) start = time.time() network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config) logger.info(f'Quant Network cost time is {time.time()  start} s.') print(' Saving checkpoint...', flush=True) start = time.time() save_ckpt_path = os.path.join(config.output_dir, ""w8a16_ckpt"") save_path = os.path.join(save_ckpt_path, f""rank_0"") os.makedirs(save_path, exist_ok=True) ms.save_checkpoint(network.parameters_dict(), os.path.join(save_path, ""w8a16.ckpt""),                    choice_func=lambda x: ""key_cache"" not in x and ""value_cache"" not in x) logger.info(f'Save checkpoint cost time is {time.time()  start} s.') print(f' Checkpoint saved to {save_path}...', flush=True) ` 报错为： ```  TypeError                                 Traceback (most recent call last) Cell In[8], line 58      56 print(' Creating network...', flush=True)      57 net_mgr: Llama2Network = Llama2Network() > 58 config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"")      59 network = net_mgr.create_network(config)      60 logger.info(f'Create Network cost time is {time.time()  start} s.') Cell In[8], line 20, in Llama2Network.create_mfconfig(config_path)      18 config = MindFormerConfig(config_path)      19 config.model.model_config = LlamaConfig(**config.model.model_config) > 20 init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel)      21 return config File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/core/context/build_context.py:139, in init_context(use_parallel, context_config, parallel_config)     136 rank_id = 0     137 context_config['mode'] = MODE.get(context_config.get('mode')) > 139 context.set_context(max_device_memory=context_config.get('max_device_memory'),     140                     mode=context_config.get('mode'))     141 del context_config['mode']     142 del context_config['max_device_memory'] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/_checkparam.py:1352, in args_type_check..type_check..wrapper(*args, **kwargs)    1350         if value is not None and not isinstance(value, bound_types[name]):    1351             raise TypeError(f""The parameter '{name}' must be {bound_types[name]}, but got {type(value)}"") > 1352 return func(*args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/context.py:1803, in set_context(**kwargs)    1801     continue    1802 if key in ctx.setters: > 1803     ctx.setterskey    1804     continue    1805 if hasattr(ctx, key): File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/context.py:545, in _Context.set_max_device_memory(self, max_device_memory)     543 if max_device_memory_value == 0:     544     raise ValueError(""For 'context.set_context', the argument 'max_device_memory' should not be \""0GB\""."") > 545 self.set_param(ms_ctx_param.max_device_memory, max_device_memory_value) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/context.py:187, in _Context.set_param(self, param, value)     186 def set_param(self, param, value): > 187     self._context_handle.set_param(param, value) TypeError: For 'set_context', the parameter max_device_memory can not be set repeatedly, origin value [58] has been in effect. Maybe 'mindspore.communication.init()' has been called before 'set_context()'.   C++ Call Stack: (For framework developers)  mindspore/core/utils/ms_context.cc:405 CheckReadStatus ```",2025-01-13T16:33:49+08:00,"foruda,www",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBHGN7,mindsporeassistant,请先补充下具体昇腾服务器的信息，MindSpore mindformers和CANN的版本？ 谢谢,https://www.mindspore.cn/golden_stick/docs/zhCN/r0.5.0/ptq/round_to_nearest.html根据这个链接的代码进行实验的。 MindSpore mindformers版本为1.2.0 mindspore_2.3.0cann_8.0.rc2py_3.9,请确认在!输入图片说明之前没有调用mindspore的set_context接口,问题已解决，如果前面运行到set_context之后，需要清空Npu缓存，清空之后错误就解决。
LiangZhibo,PIJIt UT用例补齐,,2025-01-13T14:50:58+08:00,gitee,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBHF3F
Albert,masked_scatter接口不支持bfloat16类型数据, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) masked_scatter接口传入bfloat16数据报错，官方文档并未说明不支持bfloat16格式数据 !输入图片说明  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例： ,2025-01-13T14:17:05+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBHEGL,"当前算子本身应该也不支持，说是是个老接口，还没做aclnn的适配，之前老接口是不承诺支持bf16, 若有使用场景，可以提需求；"
李永昌,mindspore lite bgererankerbase 推理结果nan值bug,"mindspore lite bgererankerbase 推理结果nan值bug 目的：把bgebasezh，bgererankerbase部署到昇腾910B 步骤： 1. huggingface模型权重转换为onnx 备注：BAAI/bgererankerbase在huggingface仓库中已经开源onnx权重 Python代码方式 ```bash from transformers import AutoModel, AutoTokenizer import torch.onnx  加载模型和分词器 model_name = ""xxx/bgebasezh"" model = AutoModel.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name)  创建一个示例输入 dummy_input = tokenizer(""示例句子"", return_tensors=""pt"")  导出模型为ONNX格式 torch.onnx.export(     model,     args=(dummy_input[""input_ids""], dummy_input[""attention_mask""]),     f=""bgebasezh.onnx"",     input_names=[""input_ids"", ""attention_mask""],     output_names=[""output""],     dynamic_axes={         ""input_ids"": {0: ""batch_size"", 1: ""sequence_length""},         ""attention_mask"": {0: ""batch_size"", 1: ""sequence_length""},     },     opset_version=17, ) ``` 命令行方式 ```bash export HF_ENDPOINT=https://hfmirror.com optimumcli export onnx model BAAI/bgebasezh bgebasezhonnx ``` 2.把onnx权重转换为MINDIR格式的模型权重 2.1和2.2都一样的输出nan值 2.1 使用配置文件convert.ini ```bash  创建配置文件convert.ini [acl_build_options] input_format=""ND"" input_shape=""input_ids:1,1;attention_mask:1,1"" ``` ```bash PACKAGE_ROOT_PATH=./mindsporelite2.4.0linuxaarch64 export PATH=${PACKAGE_ROOT_PATH}/tools/converter/converter:$PATH export LD_LIBRARY_PATH=${PACKAGE_ROOT_PATH}/tools/converter/lib:${LD_LIBRARY_PATH} converter_lite fmk=ONNX \     modelFile=xxx/bgererankerbase/onnx/model.onnx \     outputFile=xxx/bgererankerbase/onnx/modelwoshape \     saveType=MINDIR \     optimize=ascend_oriented     configFile=convert.ini ``` 2.2不用配置文件，默认配置 ```bash PACKAGE_ROOT_PATH=./mindsporelite2.4.0linuxaarch64 export PATH=${PACKAGE_ROOT_PATH}/tools/converter/converter:$PATH export LD_LIBRARY_PATH=${PACKAGE_ROOT_PATH}/tools/converter/lib:${LD_LIBRARY_PATH} converter_lite fmk=ONNX \     modelFile=xxx/bgererankerbase/onnx/model.onnx \     outputFile=xxx/bgererankerbase/onnx/modelwoshape \     saveType=MINDIR \     optimize=ascend_oriented ``` 3.910B推理 推理代码 ```python import torch import torch_npu from transformers import AutoTokenizer import mindspore_lite as mslite def mslite_init_model(model_path):     context = mslite.Context()     context.target = [""ascend""]     context.ascend.device_id = 0     context.cpu.thread_num = 1     context.cpu.thread_affinity_mode=2      build model from file     model = mslite.Model()     model.build_from_file(model_path, mslite.ModelType.MINDIR, context)     return model def mslite_infer(model, input_data):     ms_inp = list(input_data.values())     inputs = model.get_inputs()     shapes = [ms_inp[0].shape, ms_inp[1].shape]     model.resize(inputs, shapes)     for i, _input in enumerate(inputs):         _input.set_data_from_numpy(ms_inp[i])     outputs = model.predict(inputs)     print(f'mslite_infer:\n{outputs}\n{type(outputs)}')     print(f'mslite_infer:\n{outputs[0]}\n{type(outputs[0])}')     print(f'mslite_infer:\n{outputs[0].get_data_to_numpy()}\n{outputs[0].get_data_to_numpy().shape}')     return outputs[0].get_data_to_numpy() def main():     pt_path = 'xxx/bgererankerbase'     ms_path = 'xxx/bgererankerbase/onnx/model.mindir'     device = torch.device('npu:0')     pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]     tokenizer = AutoTokenizer.from_pretrained(pt_path)     encoded_input = tokenizer(pairs, padding=True, truncation=True, max_length=512, return_tensors=""np"")     mslite infer     input_ids = encoded_input['input_ids'].astype(""int32"")     attention_mask = encoded_input['attention_mask'].astype(""int32"")     mslite_input_data = {""input_ids"": input_ids,""attention_mask"":attention_mask}     mslite_model = mslite_init_model(ms_path)     mslite_output = mslite_infer(mslite_model, mslite_input_data)     print(""mslite_output shape:"", mslite_output.shape) if __name__ == ""__main__"":    torch_npu.npu.config.allow_internal_format = False     torch.npu.set_compile_mode(jit_compile=False)    main() ``` 输出结果 !输入图片说明 reranker model输出的10个句子的重排序分数为nan值，请问该如何解决？（bgebase0zh安装什么步骤，正确输出。） 硬件个系统详情： !输入图片说明 !输入图片说明 !输入图片说明",2025-01-13T14:16:41+08:00,mindspore-assistant,closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBHEGE,FA面对输入较大的场景会输出NAN，可以配置饱和模式让输出正常：export MS_ASCEND_CHECK_OVERFLOW_MODE=SATURATION_MODE,非常感谢你的回复。我还有3个问题： 1. FA是什么（全写）？ 2. SATURATION_MODE具体值设置多少？ 3. 有相关的文档吗？能分享一下嘛，非常期待你的回复。,1、FA是FlashAttention的缩写，是一种用于优化 Transformer 模型中注意力机制的技术（详细原理可自行搜索了解）。 2、SATURATION_MODE无具体值，就是指饱和模式，MS_ASCEND_CHECK_OVERFLOW_MODE默认是非饱和模式，解决输出NAN的问题可以在推理前设置下宏，具体命令是：export MS_ASCEND_CHECK_OVERFLOW_MODE=SATURATION_MODE（仅在服务器型号Atlas 800I A2上支持）。
LiangZhibo,PIJIT删除二阶段代码,,2025-01-13T10:07:53+08:00,gitee,open,0,2,https://gitee.com/mindspore/mindspore/issues/IBHBM9,需要排查sepcial_func_infer内使用的infer func是否必要。,目前GraphBuilder类太大了，需要进一步抽象，进行功能拆分。
hmy2022,【mindformers1.2.0】【mindspore2.3.1】单卡使用MindSpore Golden Stick0.5.0文档中的RoundToNearest后量化算法出现以下报错,"运行代码为： > > > import os > import time >  > import mindspore as ms > from mindformers import LlamaForCausalLM, MindFormerConfig, LlamaConfig, init_context > from mindspore_gs.ptq import PTQMode, PTQConfig > from mindspore_gs.common import BackendTarget, logger > from mindspore_gs.ptq import RoundToNearest as RTN > from mindspore_gs.ptq.network_helpers.mf_net_helpers import MFLlama2Helper >  >  > class Llama2Network: >     """"""Llama2Network."""""" >      >     def create_mfconfig(config_path): >         """"""Create mindformers config for llama2 network for example."""""" >          >         config = MindFormerConfig(config_path) >         config.model.model_config = LlamaConfig(**config.model.model_config) >         init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel) >         return config >  >      >     def create_network(mindformers_config): >         network = LlamaForCausalLM(mindformers_config.model.model_config) >         network.set_train(False) >         network.phase = 'predict' >         return network >  >  > def quant_network(net: LlamaForCausalLM, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, **kwargs): >     """"""Quant llama2 model to w8a16 with RTN algorithm."""""" >     start_time = time.time() >     if mode == PTQMode.QUANTIZE: >         logger.info(""Use RTN algo to quant network and weight."") >     else: >         logger.info(""Use RTN algo to quant network."") >     cfg = PTQConfig(mode=mode, backend=backend, opname_blacklist=[""lm_head""]) >     ptq = RTN(config=cfg) >     logger.info(f'Create PTQ cost time is {time.time()  start_time} s.') >     start_time = time.time() >     mfconfig = kwargs.get(""mfconfig"", None) >     if not mfconfig: >         raise ValueError(""Please provide mfconfig for calibrating."") >     network_helper = MFLlama2Helper(mfconfig) >     net = ptq.apply(net, network_helper) >     logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.') >     start_time = time.time() >     net.phase = ""quant_convert"" >     net = ptq.convert(net) >     logger.info(f'Convert to real quantize cost time is {time.time()  start_time} s.') >     return net >  >  > start = time.time() > print(' Creating network...', flush=True) > net_mgr: Llama2Network = Llama2Network() > config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") > network = net_mgr.create_network(config) > logger.info(f'Create Network cost time is {time.time()  start} s.') > start = time.time() > ckpt_path = config.load_checkpoint > logger.info(f'Loading ckpt :{ckpt_path}.') > ms.load_checkpoint(ckpt_path, network) > ms.ms_memory_recycle() > logger.info(f'Load ckpt cost time is {time.time()  start} s.') > print(' Quantizeing network...', flush=True) > start = time.time() > network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config) > logger.info(f'Quant Network cost time is {time.time()  start} s.') > print(' Saving checkpoint...', flush=True) > start = time.time() > save_ckpt_path = os.path.join(config.output_dir, ""w8a16_ckpt"") > save_path = os.path.join(save_ckpt_path, f""rank_0"") > os.makedirs(save_path, exist_ok=True) > ms.save_checkpoint(network.parameters_dict(), os.path.join(save_path, ""w8a16.ckpt""), >                    choice_func=lambda x: ""key_cache"" not in x and ""value_cache"" not in x) > logger.info(f'Save checkpoint cost time is {time.time()  start} s.') > print(f' Checkpoint saved to {save_path}...', flush=True) 配置文件为： seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: '' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'predict'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 1   sink_mode: True   sink_size: 2   gradient_accumulation_steps: 8  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr schedule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: False   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 1   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: False   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMonitor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   max_call_depth: 10000   max_device_memory: ""29GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 4096     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""float16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float32""     rotary_dtype: ""float16""     param_init_type: ""float16""     use_past: True     scaling_factor: 1.0  The scale factor of seq length     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     use_flash_attention: True  FA can accelerate training or finetune     block_size: 16     num_blocks: 1024     is_dynamic: True     qkv_concat: False     offset: 0     checkpoint_name_or_path: ""llama2_7b""     repetition_penalty: 1     max_decode_length: 512     top_k: 3     top_p: 1     do_sample: False   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer   type: LlamaProcessor  metric metric:   type: EmF1Metric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform."" 报错为：  Creating network... 20250113 08:18:34,790  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. 20250113 08:18:34,795  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250113 08:18:34,797  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN  TypeError                                 Traceback (most recent call last) Cell In[2], line 59      57 net_mgr: Llama2Network = Llama2Network()      58 config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") > 59 network = net_mgr.create_network(config)      60 logger.info(f'Create Network cost time is {time.time()  start} s.')      61 start = time.time() Cell In[2], line 25, in Llama2Network.create_network(mindformers_config)      23       24 def create_network(mindformers_config): > 25     network = LlamaForCausalLM(mindformers_config.model.model_config)      26     network.set_train(False)      27     network.phase = 'predict' File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/version_control.py:98, in get_lazy_inline..decorator(*args, **kwargs)      95 if stand_alone:      96     logger.info(""The Lazy Inline compilation acceleration feature does not support singlecard mode.""      97                 ""This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect."") > 98     func(*args, **kwargs)      99     return     101 if not pipline_parallel and os.getenv(""ENABLE_LAZY_INLINE_NO_PIPELINE"", ""0"") == ""0"": File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:300, in LlamaForCausalLM.__init__(self, config)     298 self.gather = P.Gather(1)     299 self.sub_batch_valid_len = P.Sub() > 300 self.model = LlamaModel(config=config)     301 self.lm_head = Linear(in_channels=config.hidden_size,     302                       out_channels=config.vocab_size,     303                       has_bias=False,     304                       compute_dtype=config.compute_dtype,     305                       param_init_type=config.param_init_type,     306                       weight_init=""normal"")   meta default: xavier_normal     308 mp = config.parallel_config.model_parallel File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:145, in LlamaModel.__init__(self, config)     122     layer = LLamaDecodeLayerInterleave(config.batch_size,     123                                        config.seq_length,     124                                        layer_id,    (...)     142                                        fine_grain_interleave=config.fine_grain_interleave,     143                                        parallel_config=config.parallel_config)     144 else: > 145     layer = LLamaDecodeLayer(layer_id,     146                              dim=config.hidden_size,     147                              n_heads=config.num_heads,     148                              n_kv_heads=config.n_kv_heads,     149                              intermediate_size=config.intermediate_size,     150                              multiple_of=config.multiple_of,     151                              ffn_dim_multiplier=config.ffn_dim_multiplier,     152                              norm_eps=config.rms_norm_eps,     153                              qkv_has_bias=config.qkv_has_bias,     154                              qkv_concat=config.qkv_concat,     155                              compute_dtype=config.compute_dtype,     156                              layernorm_compute_dtype=config.layernorm_compute_type,     157                              softmax_compute_dtype=config.softmax_compute_type,     158                              rotary_dtype=config.rotary_dtype,     159                              param_init_type=config.param_init_type,     160                              use_past=config.use_past,     161                              use_flash_attention=config.use_flash_attention,     162                              use_attn_mask_compression=config.use_attn_mask_compression,     163                              block_size=config.block_size,     164                              num_blocks=config.num_blocks,     165                              is_dynamic=config.is_dynamic,     166                              use_rope_slice=config.use_rope_slice,     167                              moe_config=config.moe_config,     168                              parallel_config=config.parallel_config)     169 set_layer_stage_recompute(layer, layer_id, config.offset, config.parallel_config, config.num_layers)     170 self.layers.append(layer) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/version_control.py:64, in get_predict_lazy_inline..decorator(*args, **kwargs)      62     logger.info(""Predict enable lazy inline."")      63 else: > 64     func(*args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_transformer.py:486, in LLamaDecodeLayer.__init__(self, layer_id, dim, n_heads, n_kv_heads, intermediate_size, multiple_of, ffn_dim_multiplier, norm_eps, qkv_concat, compute_dtype, layernorm_compute_dtype, softmax_compute_dtype, rotary_dtype, param_init_type, qkv_has_bias, use_past, is_dynamic, use_rope_slice, moe_config, use_flash_attention, use_attn_mask_compression, block_size, num_blocks, parallel_config)     484 self.reshape = P.Reshape()     485 self.add = P.Add() > 486 self.ffn_norm = LlamaRMSNorm(self.hidden_size, norm_eps, compute_type=layernorm_compute_dtype)     487 self.attention_norm = LlamaRMSNorm(self.hidden_size, norm_eps, compute_type=layernorm_compute_dtype)     488 self.attention = LLamaAttention(dim=dim,     489                                 n_heads=n_heads,     490                                 n_kv_heads=n_kv_heads,    (...)     503                                 num_blocks=num_blocks,     504                                 parallel_config=parallel_config) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:175, in LlamaRMSNorm.__init__(self, dim, eps, compute_type)     173     self.cast = P.Cast()     174     self.rcast = P.Cast() > 175     self.cast.recompute()     176 else:     177     self.cast = P.Cast() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/primitive.py:482, in Primitive.recompute(self, mode)     438 """"""     439 Set the primitive recomputed. If a primitive set recomputed feeds into some backward nodes     440 for computing gradient, rather than storing the intermediate activation computed in forward    (...)     479     [0. 0.5]     480 """"""     481 if context.get_context(""mode"") == context.PYNATIVE_MODE: > 482     raise TypeError(""Recompute is not supported in pynative mode currently."")     483 Validator.check_bool(mode)     484 self.add_prim_attr(""recompute"", mode) TypeError: Recompute is not supported in pynative mode currently.",2025-01-13T08:26:58+08:00,"gitee,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBHAF5,mindsporeassistant,mindsporeassistant
wuweikang,add mixtral dry run test case,,2025-01-11T11:10:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBH57Z
zwiori,MindSpore资料文档优化,资料doc优化 1、目录结构优化 2、方法函数功能归类 3、API正确性及example优化,2025-01-10T17:46:21+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBH2US
wuweikang,code check for parallel,,2025-01-09T21:34:29+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGUIZ
虞良斌,Dynamic profiling config configuration adds aicore_metrics parameter conversion,,2025-01-09T19:45:14+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGU1W
人间勿晚,虚拟试衣项目mindspore框架推理实现权重参数不匹配,"本项目基于Diffuser进行虚拟试衣推理，当前进展为：已将模型实现涉及的pytorch算子代码全部替换成Mindspore算子，同时两个预训练模型权重由.bin转换成mindone里Diffuser所需的.safetensor文件，基于Diffuser训练的unet和ref模型权重也从.pt转换为Mindspore可读取的.ckpt文件，本质上已从pytorch全部替换成Mindspore。但是现在遇到如下问题： Traceback (most recent call last):   File ""/home/mauser/work/refchange/ref_vton_tryon_to16.py"", line 280, in      tryoner = TDViton(device='npu')   File ""/home/mauser/work/refchange/ref_vton_tryon_to16.py"", line 49, in __init__     load_param_into_net(self.unet, unet_params)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/train/serialization.py"", line 1556, in load_param_into_net     _load_dismatch_prefix_params(net, parameter_dict, param_not_load, strict_load)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/train/serialization.py"", line 1664, in _load_dismatch_prefix_params     _update_param(param, new_param, strict_load)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/train/serialization.py"", line 166, in _update_param     raise RuntimeError(msg) RuntimeError: For 'load_param_into_net', 0.resnets.0.norm1.weight in the argument 'net' should have the same shape as 0.resnets.0.norm1.weight in the argument 'parameter_dict'. But got its shape (2560,) in the argument 'net' and shape (320,) in the argument 'parameter_dict'.May you need to check whether the checkpoint you loaded is correct or the batch size and so on in the 'net' and 'parameter_dict' are same. 显示部分权重参数在net读取和权重文件读取的值不匹配，请问该如何解决呢？是权重文件读取问题还是模型实现问题？模型实现问题的话可能是mindspore实现的时候，一些层发生了改变，或者某些参数设置不对，该如何进一步调试呢？",2025-01-09T14:13:48+08:00,github,closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBGOWA,使用的版本为mindspore_2.3.0cann_8.0.rc2py_3.9euler_2.10.7aarch64snt9b,根据权重加载时报错的那个权重key名称，找一下你的mindspore代码里该权重对应的算子或者单独parameter的shape，然后和原版pytorch的代码对比下，看看有没有差异，如果没差异，那可能是转换出错了，权重名没匹配好；,您好我想问一下，torch的ModuleList是按名字匹配的权重，mindspore的CellList也是按照名字吗？就是和顺序无关,权重转化可以参考这个链接里的代码：https://github.com/mindsporelab/mindone/blob/master/examples/stable_diffusion_v2/tools/model_conversion/README.md
tridu33,高维向量并行示例代码执行失败RuntimeError: Failure:operator MatMul init failed,"官方示例 https://gitee.com/mindspore/docs/blob/master/docs/sample_code/high_dimension_tensor_parallel/high_dimension_tensor_parallel.py 执行报错，感觉是官网教程切分的示例代码有问题 ```bash [ERROR] PARALLEL(3788398,ffffb4bbf8c0,python):2025010919:20:21.434.454 [mindspore/ccsrc/frontend/parallel/ops_info/matmul_info.cc:509] Check3DTPInputLayout] For 3D MatMul/Batch MatMul, the input layout for the last two dimensions should be like:   ((z,x),y), (x,(y,z))  when transpose_b is 'true'; or  (y,(z,x)), ((y,z),x)  when transpose_a is 'true'; or  ((z,x),y), ((y,z),x)  in the other situation. But now they are: ([const vector]{1}, [const vector]{1, 0}), ([const vector]{1}, [const vector]{0}). [ERROR] PARALLEL(3788398,ffffb4bbf8c0,python):2025010919:20:21.434.530 [mindspore/ccsrc/frontend/parallel/ops_info/operator_info.cc:1514] InitWithTensorLayout] MatMulInfo11: CheckInputLayout failed. Traceback (most recent call last):   File ""/home/usersshared/demos/docs4mindspore/docs/sample_code/high_dimension_tensor_parallel/high_dimension_tensor_parallel.py"", line 56, in      output = net(input_data)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 703, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1071, in compile_and_run     self.compile(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1054, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/mindspore/common/api.py"", line 1819, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) RuntimeError: Failure:operator MatMul init failed   The Function Call Stack: (For framework developers)  In file /home/usersshared/demos/docs4mindspore/docs/sample_code/high_dimension_tensor_parallel/high_dimension_tensor_parallel.py:42, 12~44/        x = self.matmul1(x, self.fc1_weight)/ In file /home/usersshared/demos/docs4mindspore/docs/sample_code/high_dimension_tensor_parallel/high_dimension_tensor_parallel.py:41~44, 4~47/    def construct(self, x):/   C++ Call Stack: (For framework developers)  mindspore/ccsrc/frontend/parallel/step_parallel.cc:2038 ExtractStrategyAndInit   The Traceback of Net Construct Code:   In file /home/usersshared/demos/docs4mindspore/docs/sample_code/high_dimension_tensor_parallel/high_dimension_tensor_parallel.py:41~44, 4~47     def construct(self, x):  In file /home/usersshared/demos/docs4mindspore/docs/sample_code/high_dimension_tensor_parallel/high_dimension_tensor_parallel.py:42, 12~44         x = self.matmul1(x, self.fc1_weight)             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ```",2025-01-09T11:32:40+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBGNLT,ms2.3才有这个错误，2.4.1没有这个报错了
cccc1111,Add/Sub在Ascend侧对接aclnn算子, Tasks 转测对象：mint.add/tensor.add/mint.sub/tensor.sub 对标torch.add/torch.sub   Background  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.add.htmltorch.add  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/complex64/complex128/bool  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 与torch_npu保持一致  Introduction  **1. 功能介绍**  与other相加减，alpha为放大缩小系数  **2. 接口描述**   ops接口   mint/tensor接口： Add: !输入图片说明 Sub: !输入图片说明  算子原语   自动生成对应原语 （1）在Tensor/Scalar场景中，Scalar为complex场景，因为框架数据类型原因，没有对齐 （2）在Tensor/Tensor场景中，Tensor为标量Tensor场景，InferType没有对齐 对于add： （1）Ascend后端： PyNative模式，匹配add_scalar_op与add_ext_op； KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op； GE模式，input/other输入，匹配deprecated， input/other/alpha输入，匹配add_scalar_op与add_ext_op报错； （2）CPU后端： PyNative模式，匹配add_scalar_op与add_ext_op； KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op; GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op报错； （3）GPU后端： PyNative模式，匹配add_scalar_op与add_ext_op; KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op; GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op报错； 对于__add__: 同add，与之前保持一致 对于 +： 同add，与之前保持一致 对于sub： （1）Ascend后端： PyNative模式，匹配sub_scalar_op与sub_ext_op； KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op; GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op报错； （2）CPU后端 PyNative模式，匹配sub_scalar_op与sub_ext_op; KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op； GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op报错； （3）GPU后端 PyNative模式，匹配sub_scalar_op与sub_ext_op; KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op； GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op报错； 对于__sub__: 同sub，与之前保持一致 对于 ： 同sub，与之前保持一致,2025-01-08T22:15:42+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBGKMX
hmy2022,【MindSpore Golden Stick】【SmoothQuant】请问目前想通过MindSpore Golden Stick来PTQ量化ChatGLM36b可以吗，我看好像没有适配的类。,本人模型量化小白，想请教下如果通过MindSpore Golden Stick来SmoothQuant量化ChatGLM36b，很急，求大佬解答。,2025-01-08T21:51:10+08:00,mindspore-assistant,closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBGKK3,mindsporeassistant,确实没有增加chatglm的支持，需要加一行代码将chatglm的decoder类注册一下： ptq_config = PTQConfig(xxx) ptq = PTQ(ptq_config)  **ptq.decoder_layer_types.append(ChatGLM2Block)**  ptq.apply(network) ptq.convert(network),请问，我如果想通过MindSpore Golden Stick来PTQ量化ChatGLM36b，有大概的代码架构可以提供给我吗，感谢大佬,目前教程中很多API我看都在我使用的0.5.0分支中没有，所以使用下来比较混乱，如果能提供一个框架真的万分感谢。
liguozheng,8卡16G V100训练报 Memory not enough," 报错如下： WARNING] MD(474008,7f4c6d7fe700,python):2025010809:27:59.089.071 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_o 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameterof obtaining samples in the userdefined generator function. [WARNING] PRE_ACT(474008,7f4dc5fff700,python):2025010809:28:00.513.098 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.513.306 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.513.463 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.514.322 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc5fff700,python):2025010809:28:00.515.428 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcde4b700,python):2025010809:28:00.515.536 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.515.706 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.516.580 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc5fff700,python):2025010809:28:00.517.660 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcde4b700,python):2025010809:28:00.517.930 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.518.016 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.228 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.518.388 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.526 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.680 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.880 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.519.016 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.520.767 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcde4b700,python):2025010809:28:00.521.354 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[25165824]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.521.856 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. pid: 474008 20250108 09:27:00.008152 Traceback (most recent call last):   File ""/home/lgz/v100/kunpeng/nowcastnet/framework_test/test/main.py"", line 134, in      train(config_flatten, logger)   File ""/home/lgz/v100/kunpeng/nowcastnet/framework_test/test/main.py"", line 87, in train     evo_trainer.train()   File ""/home/lgz/v100/kunpeng/nowcastnet/framework_test/common/framework/nowcastnet/solver.py"", line 606, in train     evo_res = self.evo_solver(inputs, labels)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/nn/cell.py"", line 680, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/nn/cell.py"", line 1023, in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 1589, in __call__     return self.run(obj, *args, phase=phase)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 1628, in run     return self._exec_pip(obj, *args, phase=phase_real)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 121, in wrapper     results = fn(*arg, **kwargs)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 1608, in _exec_pip     return self._graph_executor(args, phase) RuntimeError:    Memory not enough:  Device(id:0) memory isn't enough and alloc failed, kernel name: Gradients/Default/networkEvolutionLoss/evo_modelEvolutionNet/gradStrided   C++ Call Stack: (For framework developers)",2025-01-08T18:36:37+08:00,"gitee,foruda,www,mindspore-assistant",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBGJOL,具体跑的什么模型，多大规格的，batchsize是多少，用的什么并行方式？最好提供代码看一下；目前错误的信息就是说显存不够,https://gitee.com/mindspore/mindscience/tree/r0.6/MindEarth/applications/nowcasting/Nowcastnet 我用这个试了下，也可以复现,你这边单卡能跑不？可以先试试单卡；我用里面默认的训练配置，8G显存都能跑： !输入图片说明 看看你这边单卡会不会有显存不足的问题，有的话，可能是环境配置的原因,"问题已经解决 代码需要增加 init(""nccl"")初始化 https://www.mindspore.cn/docs/programming_guide/zhCN/r1.6/distributed_training_gpu.html 或者通过mpirun的方式尝试"
luoyang,dataset iterator don’t need to validate empty tensor,"   Task Description dataset iterator don’t need to validate empty tensor, 因为算子已经支持了空tensor输入，202411支持的",2025-01-08T17:54:14+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGJAU
looop5,DVM MatMul融合算子dry run core dump,"dry run执行core dump ``` class Net(Cell):     def __init__(self):         super(Net, self).__init__()     def construct(self, para1_Parameter_9338, para2_Parameter_9339, para3_Parameter_9342):         y0 = ops.MatMul(transpose_a=False, transpose_b=True)(para1_Parameter_9338, para2_Parameter_9339)         y1 = ops.Cast()(y0, mindspore.float32)         y2 = ops.Cast()(para3_Parameter_9342, mindspore.float32)         y3 = ops.Add()(y1, y2)         y4 = ops.Cast()(y3, mindspore.bfloat16)         return y4 ```",2025-01-08T17:05:34+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBGIB9,根因分析：dry run的时候会跳过dvm编译，dvm matmul kernel有些变量没初始化，析构的时候又去访问了这些没初始化的变量，就core dump了。 解决方法：析构函数里需要对指针判空。 已补充st用例run_matmul。 自验通过。
zhangshucheng,"Add ""optional"" to optional parameters", 1. 【Document Link】/【文档链接】 !输入图片说明 !输入图片说明 2. 【Issues Section】/【问题文档片段】 3. 【Existing Issues】/【存在的问题】 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-01-08T16:31:02+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGHR6
zhangbuxue,add args introduction for Tensor expand," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-08T15:08:41+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGGJT
wtcheng,logsumexp 算子Tensor接口和ops接口入参不一致说明, 1. 【Document Link】/【文档链接】 2. 【Issues Section】/【问题文档片段】 3. 【Existing Issues】/【存在的问题】 4. 【Expected Result】【预期结果】  Please fill in the expected result,2025-01-08T11:43:30+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGEQS
tridu33,910服务器上执行案例ascend310_single_op_sample执行报错,"正确编译 https://gitee.com/mindspore/docs/tree/master/docs/sample_code/ascend310_single_op_sample 后执行报错： ```bash (openmindms) tridu33master:~/workspace/mindsporedocssamplecodes/ascend310_single_op_sample$ ./tensor_add_sample /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) 3 5 7 9 double free or corruption (out) Aborted (core dumped) (openmindms) tridu33master:~/workspace/mindsporedocssamplecodes/ascend310_single_op_sample$ Process ForkServerProcess9: Process ForkServerProcess8: Process ForkServerProcess7: Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run() Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs) Process ForkServerProcess6: Process ForkServerProcess5:   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get() Process ForkServerProcess2: Process ForkServerProcess3: Process ForkServerProcess4:   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv() Traceback (most recent call last):   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs) EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get() EOFError   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError EOFError Traceback (most recent call last): Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv() Traceback (most recent call last): Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get() Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File """", line 2, in get EOFError   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4) EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError EOFError EOFError /home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown   warnings.warn('resource_tracker: There appear to be %d ' ```",2025-01-08T10:37:12+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBGDP9,这个是早期的mindspore版本，在310上的使用mindspore的C++ API直接加载mindir文件推理的示例代码，根据官方文档可知，这种方式目前新版本已经不在支持维护了，并且之前的版本也是在310上支持这种方式，就是以前200DK开发板的那种环境（不是200I DK A2），而不是910（也不是310b或者310p）
hmy2022,[mindspore][MindSpore Golden Stick]想要在mindspore框架下使用量化工具，镜像只能自己做吗,想使用以下mindspore2.3.1对应版本搭配   !输入图片说明,2025-01-08T10:37:00+08:00,www,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBGDP3,"系统版本限制应该没那么大，可能是官方只在ubuntu18上做过测试，所以推荐18,其它的20或者22大概率也能跑，早期的mindspore版本官方也是只说了ubuntu18系统，因为当时主要在18上做过测试所以推荐18，但试下来20也能跑；可能如果自己要从源码编译整个框架才会有那么严格的系统版本要求", 用这个昇腾基础镜像 加上金箍棒 有ubuntu版本，https://www.hiascend.com/developer/ascendhub/detail/9de02a1a179b4018a4bf8e50c6c2339e 版本也都写得很详细
zhangyinxia,Continuous optimization for comm op,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-01-08T10:12:31+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGD9W
shenwei41,[MD] 2025question,   Task Description 2025日常问题： 1. 日常告警 2. 代码回合 3. 代码检视,2025-01-08T09:45:08+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBGCX2
mengyuanli,xlogy tensor 接口语义不清晰," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) xlogy(y) 与参考接口中的 other 入参是统一参数，需要补充说明。 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-07T14:25:19+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBG73N
虞良斌,Change warm_up to warmup in the schedule,,2025-01-07T14:22:30+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBG727
mengqinghe,nn.CellList部分遍历参数名被篡改," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) nn.CellList() 中的网络层，在执行中用 for 循环对其进行部分遍历（非完整遍历），则执行后网络层的名称被篡改，从而导致 load ckpt 时无法匹配。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name: 不涉及 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode: PyNative >    Excute Mode：不涉及  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 复现 bug 的代码 ``` import mindspore as ms from mindspore import nn, ops class Model_ok(nn.Cell):     def __init__(self):         super().__init__()         self.layers = self.build_layers()     def build_layers(self):         layers = nn.CellList()         for i in range(5):             layers.append(nn.Conv2d(20, 20, 3))         return layers     def construct(self, x):         for layer in self.layers:             x = layer(x)         return x class Model_bug(Model_ok):      在 Model_ok 的基础上做一些修改，就会出现参数名被篡改的 bug     def construct(self, x):         for layer in self.layers[:1]:             x = layer(x)          ... (perhaps do something with x here)         x = self.layers1         return x def test_model(model):      模型调用前，打印模型参数名，参数名正常     print('param names:', model.parameters_dict().keys())     x = ops.rand([1, 20, 5, 5])     y = model(x)      模型调用后，再打印模型参数名，发现 Model_bug 中的参数名会被篡改     print('param names:', model.parameters_dict().keys()) if __name__ == '__main__':     test_model(Model_ok())     test_model(Model_bug()) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：四次打印的网络层名称都一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**王海宁（根据实际修改）",2025-01-07T10:44:43+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBG4SN,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
李尚蔚,llama3.1 70b动态shape lora微调重排冗余allgathersplit算子未去除," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) llama3.1 70b动态shape lora微调重排冗余allgathersplit算子未去除  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   .*w2' profile: True parallel_config:   data_parallel: 4   model_parallel: 1   pipeline_stage: 8 ``` （2） ``` bash ../scripts/msrun_launcher.sh ""llama3_1/run_llama3_1.py \  config llama3_1/finetune_llama3_1_8b.yaml \  load_checkpoint ./ms_trans \  auto_trans_ckpt False \  run_mode finetune \  train_data ./test.json"" ``` （3）使用mindstudio insight分析profiling  5.Describe the expected behavior / 预期结果 (Mandatory / 必填)  **【预期结果】**：DP域仅前向开始前存在allgather算子  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) PP域send算子后split算子在等待DP域allgather算子 !PP域send算子后split算子在等待DP域allgather算子    7.Special notes for this issue/备注 (Optional / 选填) 【定位人】刘崇鸣",2025-01-07T09:47:54+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBG3V2
majun-bot,CVE20236604,"一、漏洞信息 漏洞编号：CVE20236604 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector：  漏洞简述： A flaw was found in FFmpeg. This vulnerability allows unexpected additional CPU load and storage consumption, potentially leading to degraded performance or denial of service via the demuxing of arbitrary data as XBINformatted data without proper format validation. 漏洞公开时间：00010101 08:05:43 漏洞创建时间：20250107 04:03:41 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20236604 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞社区暂时没有修复方案，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 5.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-07T04:03:42+08:00,"gitee,CVE/UNAFFECTED,rct/oldrelease,rca/others,ctl/componenttest",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBG2PE,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞社区暂时没有修复方案，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：5.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明： 该漏洞社区暂时没有修复方案，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：5.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",该漏洞社区暂时没有修复方案，故不受影响。
张汉权,cann哪个版本和mindspore2.5.0适配？,cann哪个版本和mindspore2.5.0适配？我是员工已经下了cann8.0.0和mindspore2.5.0下来，但是报了一个 Load dynamic library: libmindspore_ascend.so.2 failed. libge_runner.so: cannot open shared object file: No such file or directory，问了几个人都说是编的有问题，或者安排一个人给帮忙安装一下也行,2025-01-06T20:17:00+08:00,"foruda,foruda,foruda,mindspore-assistant,repo",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBG1WM,2.5.0目前还没正式发布呢，你这边用的应该是每日dev版本，开发流水线上应该是每天都会打一个包的，每日版保不准有什么bug，目前因为还没正式发布，所以官网也没对应的文档说明与cann的对应关系，一般来说会用最新版本的cann，这cann版本可能也还没发布，可以的话，建议还是用已发布的2.4.1正式版； 或者你可以就下载个已发布的最新版本的cann 8.0.0.alpha003试试看： !输入图片说明 看上面的错误情况，大概率还是cann、驱动版本没匹配好，或者环境变量设置有误的原因；我这边测试了下，用1月1号的2.5.0包，在华为云modelarts的8.0.RC1环境里运行，还是能够跑的，这个环境我是用来跑2.3.1的，里面的cann包和2.5.0不是完美匹配的，但测试下来基本的运行没有问题，你可以参考一下： !输入图片说明 我这边通过环境变量把警告信息屏蔽掉了，如果不屏蔽的话，因为cann和mindspore不完美匹配，会有一大堆警告的，不过从警告里也可以看到，2.5.0所需要的昇腾软件包版本是7.5或者7.6，你可以去昇腾那边问一下，这个版本的软件包对应的cann是什么版本呢： !输入图片说明 说回来，尽管2.5.0在cann 8.0RC1能运行，但一方面不是正式版，且没有完美匹配版本，保不准会出什么错；你这边下载到mindspore每日包和我的可能也不是同一天的，所以情况也可能有差别,谢谢，我目前用的是https://repo.mindspore.cn/mindspore/mindspore/version/202412/20241227/master_20241227010019_d0e4d9b30db7a01da2ae55cc8aed59d68dd3c5ef_newest/unified/这个链接里面的2.5.0，cann用的是8.0.0的，那会报这个错的原因到底是哪里不适配呢？runtime那边的人也说不适配，不过我原来装了一个mindspore2.3.1版本的，原来的cann是8.0.RC2，我查了latest里面也是这个版本的这里面会不会有冲突呢？我的理解是新装的cann是不是没有起作用？,哦，谢谢我已经解决这个问题了,新装的cann有没有起作用看你环境变量的设置方式了，每次安装cann时，默认他会有个单独的cann目录，就是以cann的版本号命名的，然后会更新一个latest目录，这个目录其实是个软连接，连接到对应的cann版本目录，如果配置cann的环境变量时都是指向latest的话，新装一个就直接生效了； 但也有些情况可能导致出错，就是某个cann版本的环境变量有变化的话，或者新装的cann和物理机上的驱动不匹配的话，就可能出错；
橙橙橙,创建 tensor 时负数转成无符号整数(如uint32等)行为与pytorch不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 创建 tensor 时输入超过二维，负数转成无符号整数(如uint32等)行为与pytorch不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:    Hardware (e.g.`Ascend910B1`/`Mac CPU`): Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 代码： ```python import mindspore as ms import torch x = [[1, 6], [7.9, 3.2]] ms_tensor = ms.tensor(x, dtype=ms.uint32) torch_tensor = torch.tensor(x, dtype=torch.uint32) print(ms_tensor, torch_tensor) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常跑通  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-01-06T18:49:26+08:00,gitee,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBG1GY,这是由于不同的转换策略造成的，后续可能会进行改进
橙橙橙,mint.acos 不支持输入 uint16 和 uint32 类型," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.acos 不支持 uint16 和 uint32, 而 torch.acos 是支持的。mint.acosh 也是这样。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:    Hardware (e.g.`Ascend910B1`/`Mac CPU`): Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 代码： ```python import mindspore as ms from mindspore import mint import torch x = [0.74, 0.04, 0.30, 0.56],[0.7, 0.3, 0.8, 0.2],[1.0, 0.9, 0.11, 0.5] ms_tensor = ms.tensor(x, dtype=ms.uint32) torch_tensor = torch.tensor(x, dtype=torch.uint32) ms_result = mint.acos(ms_tensor).asnumpy() torch_result = torch.acos(torch_tensor).numpy() print(ms_tensor, torch_tensor) print(torch_result)  print(ms_result, torch_result) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常跑通  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-01-06T18:44:49+08:00,"foruda,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBG1FR,这个应该是目前的cann算子还不支持，mint里的api目前都是针对昇腾环境的，框架层肯定也没发支持了； cann算子手册里的acos算子： !输入图片说明 uint16 和 uint32 类型估计要等最新的cann版本支持后，然后最新的mindspore分支代码才能接入
lubingjie66,使用单卡推理llama3.18B时出现The config for soc_verison: Ascend910ProA does not exist.,!输入图片说明 请问这个问题应该怎么解决？,2025-01-06T16:56:37+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBFZOL,执行的命令如下： bash scripts/examples/llama3/run_llama3_predict.sh single \  research/llama3_1/llama3_1_8b/predict_llama3_1_8b.yaml \  path/to/llama3_1_8b.ckpt \  path/to/tokenizer.model,这个是不支持当前硬件设备，建议使用atlas 800T A2 系列
liubuyu,ascend后端支持进程级断点续训,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-01-06T16:52:56+08:00,"gitee,gitee,www,wiki,dbox",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBFZN3,"方案设计： https://wiki.huawei.com/domains/83650/wiki/141984/WIKI202502065859426 DT用例： 当前特性至少双机，功能无法在门禁看护，进提供ut等测试用例，见方案设计2.7章节 [图片上传中…(imageztT7vxQb7RqYuTfCRjGs)] 需求列表： https://dbox.huawei.com/dashboard?pid=OR%3Awt.pdmlink.PDMLinkProduct%3A22045263215&oid=22045310781,22046387564,22050447354,22050448322,100066216895,100404828007,100865042799,100865043663,100866058137,100866058645 用例列表： https://gitee.com/mindspore/mindspore/pulls/81208/files 代码检视：见pr 代码行号：0.9k 资料：https://gitee.com/mindspore/docs/pulls/15991 遗留DI:叠加故障，预计228确认并解决https://e.gitee.com/mind_spore/issues/list?issue=IBNE6C 归档：https://dbox.huawei.com/dashboard?pid=OR%3Awt.pdmlink.PDMLinkProduct%3A22045263215&oid=22045310781,22046387564,22050447354,22050448322,100066216895,100404828007,100865042799,100865043663,100866058137,100866058645",https://www.hiascend.com/document/detail/zh/mindxdl/600/clusterscheduling/ref/mindiottp/mindiotft001.html
橙橙橙,mint.rand 在图模式下报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.rand 在图模式下报错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:    Hardware (e.g.`Ascend910B1`/`Mac CPU`): Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 代码： ```python import mindspore as ms from mindspore import mint ms.set_context(pynative_synchronize=True) ms.set_context(mode=ms.GRAPH_MODE) print(mint.rand(4)) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常跑通  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-01-05T21:43:21+08:00,"foruda,foruda,mindspore-assistant",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBFRKL,走静态图的话，建议把对应的代码用mindspore.jit包一下，这样是能运行的： !输入图片说明 !输入图片说明 如果运行的代码不在nn.Cell类或者其子类的construct方法中的话，就算是在上下文中设置了静态图，走的也是动态图模式，需要用jit包起来才是真的走了静态图，这也是mindspore动静结合的一种方式；不过这边可能有动静结合模式下调用mint一些方法的bug，之前也看到有提问说不少mint的方法不用jit包起来的情况下会出错； 还有ms.set_context(pynative_synchronize=True)这个方法是开启动态图的同步，方便定位动态图下的错误，对于静态图是无效的,谢谢你，我加上 jit 之后还是报错了。 !输入图片说明 !输入图片说明,这个代码加上jit之后在2.3.1上是可以运行的，这个错误可能是环境的设置上的问题，执行下 unset RANK_TABLE_FILE 命令再运行看看,执行完 unset RANK_TABLE_FILE 就没有报错了，请教下这个是什么问题呢,具体的报错机制和原因我也不太清楚，这个设置其实和错误本身应该没有直接关联，但会影响到默认运行的动静图模式，你这边用的是华为云贵阳一区的modelarts镜像吧，里面的镜像默认是配置了RANK_TABLE_FILE，你可以echo $RANK_TABLE_FILE看一下，可能正好就是这种模式下触发了某些bug
majun-bot,CVE202436613,"一、漏洞信息 漏洞编号：CVE202436613 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector：  漏洞简述： FFmpeg n6.1.1 has a vulnerability in the DXA demuxer of the libavformat library allowing for an integer overflow, potentially resulting in a denialofservice (DoS) condition or other undefined behavior. 漏洞公开时间：00010101 08:05:43 漏洞创建时间：20250104 03:52:36 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202436613 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： FFmpegn6.1.1在libavformat库的DXA解复用器中存在一个漏洞，允许整数溢出，可能导致拒绝服务(DoS)条件或其他未定义的行为。 受影响分支已经合入patch。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.2 &emsp;Vector： CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-04T03:52:36+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/FIXED",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBFLK1,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： FFmpeg n6.1.1 在 libavformat 库的 DXA 解复用器中存在一个漏洞，允许整数溢出，可能导致拒绝服务 (DoS) 条件或其他未定义的行为。 受影响分支已经合入patch。 漏洞评分(MindSpore评分):  BaseScore：6.2 MEDIUM  Vector：CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",受影响分支已经合入patch
majun-bot,CVE202435365,"一、漏洞信息 漏洞编号：CVE202435365 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector：  漏洞简述： FFmpeg version n6.1.1 has a doublefree vulnerability in the fftools/ffmpeg_mux_init.c component of FFmpeg, specifically within the new_stream_audio function. 漏洞公开时间：00010101 08:05:43 漏洞创建时间：20250104 03:52:32 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202435365 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞涉及的修改文件为fftools/ffmpeg_mux_init.c，Mindspore使用的FFmpeg为5.1.4版本，该版本没有这个fftools/ffmpeg_mux_init.c文件，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 8.8 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-04T03:52:33+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBFLJZ,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞涉及的修改文件为fftools/ffmpeg_mux_init.c，Mindspore使用的FFmpeg为5.1.4版本，该版本没有这个fftools/ffmpeg_mux_init.c文件，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：8.8 HIGH  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明： 该漏洞涉及的修改文件为fftools/ffmpeg_mux_init.c，Mindspore使用的FFmpeg为5.1.4版本，该版本没有这个fftools/ffmpeg_mux_init.c文件，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：8.8 HIGH  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Mindspore使用的FFmpeg为5.1.4版本，该版本没有这个fftools/ffmpeg_mux_init.c文件，故不受影响。
wmc,mindspore_lite转换mindyolo的mindir模型时make_list算子不支持, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore_lite转换mindyolo的mindir模型失败  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**: CPU环境：Intel(R) Xeon(R) Platinum 8369B CPU @ 2.70GHz  **Software Environment / 软件环境 (Mandatory / 必填)**:   4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export LITE_HOME=/mnt/workspace/mindyolo/deploy/mindsporelite2.2.14linuxx64 > （2）export LD_LIBRARY_PATH=$LITE_HOME/runtime/lib:$LITE_HOME/tools/converter/lib:$LD_LIBRARY_PATH > （3）export PATH=$LITE_HOME/tools/converter/converter:$LITE_HOME/tools/benchmark:$PATH > （4）./converter_lite fmk=MINDIR modelFile=./ckp/yoloxs124_30.mindir  outputFile=yoloxs124_30  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错： 1. 我将SilU替换为EdgeSiLU后，silu不支持的报错消失了，但是似乎不支持make_list! !输入图片说明 2.另外我将SilU替换为EdgeSiLU后，尝试将cpkt转换为onnx格式时，同样会报错不支持make_list算子，报错如下： !输入图片说明,2025-01-03T16:07:41+08:00,"gitee,mindspore-assistant",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBFI4G,mindsporelite目前仅支持2.2.14、2.3.0和2.3.1，其他版本未经过完整的验证；请安装一致对应版本的ascenddrive、firmware和ascendtoolkit，再次尝试，谢谢！,三个版本的mindsporelite都尝试过了，都是上面的报错,看日志这是在导出onnx模型时报的错，请问是在导出onnx模型吗？ 不是的话python脚本麻烦附一下
shiro-zzz,【AR】PyBoost接口及ACLNN算子适配AvgPool3d, Tasks 转测对象：ops.rotated_iou   可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB,2025-01-03T11:40:55+08:00,"gitee,v2.1.0,sig/ops",progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBFF0B
wqx,从2.3.0 rc2版本开始，导出onnx出现之前版本没有的bug,"使用一下代码导出onnx格式： ``` import mindspore.nn as nn import mindspore.ops as ops import mindspore import numpy as np from mindspore.common.initializer import Normal from  mindspore import context class MyNet(nn.Cell):     def __init__(self):         super().__init__()     def construct(self, x):         x = 2 * ops.matmul(x.transpose(0, 2, 1), x)         y = (x ** 2).sum(axis=1, keepdims=True)         return y if __name__ == '__main__':     mindspore.set_context(mode=context.GRAPH_MODE)     mynet = MyNet()     input = mindspore.Tensor(shape=(2, 6, 30), dtype=mindspore.float32, init=Normal())     mindspore.export(mynet, input, file_name=""test_model"", file_format='ONNX') ``` 在2.2.0,2.2.14和2.3.0 rc1版本中测试都是正常的，但从2.3.0 rc2开始，之后的版本，包括目前1月1日的每日版本，全都出现错误： !输入图片说明",2025-01-03T11:36:46+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBFEY1,由于后续版本算子切换为aclnn，所以onnx需要重新适配，有需要的模型我们会做适配。
zhuguodong,[Lite]端侧训练模块代码中的memcpy/memset替换为安全C函数,,2025-01-02T21:36:06+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBFBPL
youwu88,安装mindspore检查是否安装成功出错,"安装完成，执行检查命令，报如下错误 python c ""import mindspore;mindspore.set_device(device_target='CPU');mindspore.run_check()"" MindSpore version:  2.5.0.dev20241215 MindSpore running check failed. Not found auto grad functions for op 240   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/functions/auto_grad_reg.h:42 mindspore::kernel::pyboost::AutoGradFactory::GetGradFunction",2025-01-02T17:40:57+08:00,"mindspore-assistant,foruda,repo,repo",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBFA6O,这个是dev的版本，非正式版，可能会有些额外的错误，装个正式版试试呢;或者可能你用的这个12月15号的每日dev版本正好有问题，我试了下今年1月1号的每日版，是可以通过你上述的检测代码的，你可以试试： !输入图片说明 aarch64包： https://repo.mindspore.cn/mindspore/mindspore/version/202501/20250101/master_20250101220019_0367495ef4df12ac112db03e6128abe708bba2c1_newest/unified/aarch64/mindspore2.5.0cp39cp39linux_aarch64.whl x86包： https://repo.mindspore.cn/mindspore/mindspore/version/202501/20250101/master_20250101220019_0367495ef4df12ac112db03e6128abe708bba2c1_newest/unified/x86_64/mindspore2.5.0cp39cp39linux_x86_64.whl 安装这个包之前，先把你原来的卸载掉，因为这个包名直接是mindspore，你用的那个包名可能是mindsporedev，不手动卸载的话，会导致两个包同时存在，可能会出问题
mengyuanli,GMM 310P nz weight自动转换逻辑被重构误删," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) GMM 310P nz weight没有自动转换 原本转换逻辑在https://gitee.com/mindspore/mindspore/pulls/74073/中实现， 经过https://gitee.com/mindspore/mindspore/pulls/74745重构，该部分逻辑被误删 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-02T15:04:34+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBF6PM