mindformers,wangxiaoke,【CAAI】MindFormers中缺乏掩码语言模型的封装," 1.Describe the current behavior / 尝试手动封装掩码语言模型，但是在运行过程中遇到如下问题： Traceback (most recent call last):   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 567, in      main()   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 528, in main     _,relation_best_hit1,relation_best_hit3,relation_best_hit10,len_dataset,relation_best_mrr = trainer.train()   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 434, in train     test_loss, test_hit1, test_hit3, test_hit10, len_dataset, mrr = self.evaluate(epoch_idx, 'Test')   File ""D:\KGC\project\yf\ATAP_code\atap\main.py"", line 199, in evaluate     current_loss, current_hit1, current_hit3, current_hit10, current_mrr = self.model(   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\cell.py"", line 720, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\cell.py"", line 1138, in compile_and_run     self.compile(*args, **kwargs)   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\cell.py"", line 1121, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\common\api.py"", line 1840, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) TypeError:   Kernel select failed:  Select CPU operator[Gather] fail! Unsupported data type! The supported data types are input[UInt8 Int32 Int64 Int64], output[UInt8]; input[UInt16 Int32 Int64 Int64], output[UInt16]; input[UInt32 Int32 Int64 Int64], output[UInt32]; input[UInt64 Int32 Int64 Int64], output[UInt64]; input[Int8 Int32 Int64 Int64], output[Int8]; input[Int16 Int32 Int64 Int64], output[Int16]; input[Int32 Int32 Int64 Int64], output[Int32]; input[Int64 Int32 Int64 Int64], output[Int64]; input[Float16 Int32 Int64 Int64], output[Float16]; input[Float32 Int32 Int64 Int64], output[Float32]; input[Float64 Int32 Int64 Int64], output[Float64]; input[Bool Int32 Int64 Int64], output[Bool]; input[Complex64 Int32 Int64 Int64], output[Complex64]; input[Complex128 Int32 Int64 Int64], output[Complex128]; , but get input[Float32 Float32 Int64 Int64 ] and output[Float32 ]   The Function Call Stack: (For framework developers)  In file C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\layer\embedding.py:155, 33~79/            output_for_reshape = self.gather(self.embedding_table, flat_ids, 0)/ In file C:\ProgramData\anaconda3\envs\InteractE\lib\sitepackages\mindspore\nn\layer\embedding.py:145~158, 4~21/    def construct(self, ids):/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:63, 21~36/        raw_embeds = self.embeddings(queries_for_embedding)/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:55~81, 4~25/    def embed_input(self, queries):/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:169, 24~40/        inputs_embeds = self.embed_input(padded_queries)/ In file D:\KGC\project\yf\ATAP_code\atap\p_tuning\modeling.py:139~246, 4~39/    def construct(self, token_ids, x_hs, x_ts, evaluate_type, epoch, return_candidates=False):/ node: :output_for_reshape{[0]: ValueNode PrimFunc_Gather, [1]: :CNode_87{[0]: ValueNode Load, [1]: param_embeddings.embedding_table, [2]: ValueNode U}, [2]: :flat_ids{[0]: ValueNode PrimFunc_Reshape, [1]: CNode_88, [2]: ValueNode (1)}, [3]: ValueNode 0, [4]: ValueNode 0}   C++ Call Stack: (For framework developers)  mindspore\ccsrc\plugin\device\cpu\hal\hardware\cpu_device_context.cc:517 mindspore::device::cpu::CPUKernelExecutor::SetOperatorInfo",2025-05-08T18:27:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC6E9Q
overflow,majun-bot,CVE20223786,"一、漏洞信息 漏洞编号：CVE20223786 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A buffer overrun can be triggered in X.509 certificate verification, specifically in name constraint checking. Note that this occurs after certificate chain signature verification and requires either a CA to have signed a malicious certificate or for an application to continue certificate verification despite failure to construct a path to a trusted issuer. An attacker can craft a malicious email address in a certificate to overflow an arbitrary number of bytes containing the `.' character (decimal 46) on the stack. This buffer overflow could result in a crash (causing a denial of service). In a TLS client, this can be triggered by connecting to a malicious server. In a TLS server, this can be triggered if the server requests client authentication and a malicious client connects. 漏洞公开时间：20221102 02:15:11 漏洞创建时间：20250506 01:45:35 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20223786 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-06T01:45:36+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5J94,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
yi,majun-bot,CVE20232650,"一、漏洞信息 漏洞编号：CVE20232650 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 6.5 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 漏洞简述： Issue summary: Processing some specially crafted ASN.1 object identifiers or data containing them may be very slow. Impact summary: Applications that use OBJ_obj2txt() directly, or use any of the OpenSSL subsystems OCSP, PKCS7/SMIME, CMS, CMP/CRMF or TS with no message size limit may experience notable to very long delays when processing those messages, which may lead to a Denial of Service. An OBJECT IDENTIFIER is composed of a series of numbers  subidentifiers  most of which have no size limit.  OBJ_obj2txt() may be used to translate an ASN.1 OBJECT IDENTIFIER given in DER encoding form (using the OpenSSL type ASN1_OBJECT) to its canonical numeric text form, which are the subidentifiers of the OBJECT IDENTIFIER in decimal form, separated by periods. When one of the subidentifiers in the OBJECT IDENTIFIER is very large (these are sizes that are seen as absurdly large, taking up tens or hundreds of KiBs), the translation to a decimal number in text may take a very long time.  The time complexity is O(n^2) with 'n' being the size of the subidentifiers in bytes (*). With OpenSSL 3.0, support to fetch cryptographic algorithms using names / identifiers in string form was introduced.  This includes using OBJECT IDENTIFIERs in canonical numeric text form as identifiers for fetching algorithms. Such OBJECT IDENTIFIERs may be received through the ASN.1 structure AlgorithmIdentifier, which is commonly used in multiple protocols to specify what cryptographic algorithm should be used to sign or verify, encrypt or decrypt, or digest passed data. Applications that call OBJ_obj2txt() directly with untrusted data are affected, with any version of OpenSSL.  If the use is for the mere purpose of display, the severity is considered low. In OpenSSL 3.0 and newer, this affects the subsystems OCSP, PKCS7/SMIME, CMS, CMP/CRMF or TS.  It also impacts anything that processes X.509 certificates, including simple things like verifying its signature. The impact on TLS is relatively low, because all versions of OpenSSL have a 100KiB limit on the peer's certificate chain.  Additionally, this only impacts clients, or servers that have explicitly enabled client authentication. In OpenSSL 1.1.1 and 1.0.2, this only affects displaying diverse objects, such as X.509 certificates.  This is assumed to not happen in such a way that it would cause a Denial of Service, so these versions are considered not affected by this issue in such a way that it would be cause for concern, and the severity is therefore considered low. 漏洞公开时间：20230530 22:15:09 漏洞创建时间：20250503 00:24:58 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20232650 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-05-03T00:24:58+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC5DBO,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,hbhdlxx08,权重量化转化工具转换操作，无法找到 hool.json 文件,"1.问题现象截图： !输入图片说明 !输入图片说明 2.操作指引： bash convert_quant_weight.sh src /data/QwQ32B/ dst /data/QwQ32Bw8a8/ type qwen_w8a8 3.硬件信息：910B1 https://gitee.com/ascend/msit/tree/master/msmodelslim 量化操作 4.详细报错 FileNotFoundError: The file is expected to exist, but it does not.   Please check the input path: /usr/local/Ascent/atbmodels/examples/models/gwenn/examples/convert/model_slim/hool.json",2025-04-28T19:54:00+08:00,"www,gitee",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC4QG6,hool.json文件？是不是应该hccl.json? 看你提供的那个码云链接，这里的量化转换好像不是mindspore框架这边的，是用了昇腾直接提供的一些工具，昇腾工具的相关问题可以直接去昇腾论坛的cann板块提问： https://www.hiascend.com/forum/forum01061013859211750041.html?filterCondition=1&topicClassId=0607101389987648003 或者如果用了上面码云仓库的相关工具，可以直接在上述码云仓库的issue里提问： https://gitee.com/ascend/msit/tree/master/msmodelslim 那边应该有专门负责这块的研发团队来解答问题
ascend,zhangyinxia,tcp_store接口设置key在1G左右会core,"   Describe the current behavior / 问题描述 (Mandatory / 必填) tcp_store接口设置key在1G左右会core ` def test_tcp_store_004():     this_rank = get_rank()     store = TCPStore()     if this_rank == 0:         store.set('A' * 1024 * 1024 * 1024, 'B' * 1024 * 1024 * 1024)     barrier()     out_get_key_3 = store.get('A' * 1024 * 1024 * 1024)     assert out_get_key_3 == b'B' * 1024 * 1024 * 1024 `  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-27T15:55:06+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4DB3
mindformers,hbhdlxx08,mindie跑GLM4ms一直显示The meta server node can not be finalized because there are still 2 alive nodes.,1.问题现象截图： !输入图片说明 执行bash run_mindie.sh modelname GLMZ132B0414 modelpath /data/GLMZ132B0414 maxprefillbatchsize 4会出现该现象 2.操作指引： https://mp.weixin.qq.com/s/VBrsu6r3GM8nxMe5XK93YA 3.硬件信息：910B1 4.docker镜像：swr.cncentral221.ovaijisuan.com/mindformers/mindspore_glm_z1:20250414,2025-04-27T14:56:40+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC4C86,可能是进程没杀干净，请清空缓存再试
pynative mode,张泰来,mindspore.mint.logical_xor算子反向传播未定义," 1.问题描述 mindspore.mint.logical_xor接口不支持反向传播   2.环境信息  **硬件环境**:   3.重现步骤  (1) 测试代码 ```python import torch import mindspore as ms import numpy as np from mindspore import value_and_grad import pytest from mindspore import ops .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_forward_backward(mode):     """"""     (2) 测试两个框架的正向推理结果和反向梯度精度差异     """"""     ms.set_context(mode=mode, device_target='Ascend')     data_lst1 = [[1.1, 1.2, 1.3, 1.4], [1.5, 1.6, 1.7, 1.8]]     data_lst2 = [[1.1, 0, 1.3, 0], [0, 1.6, 0, 1.8]]     input_ms1 = ms.tensor(data_lst1, dtype=ms.float64)     input_ms2 = ms.tensor(data_lst2, dtype=ms.float64)     input_pt1 = torch.tensor(data_lst1, dtype=torch.float64, requires_grad=True)     input_pt2 = torch.tensor(data_lst2, dtype=torch.float64, requires_grad=True)     def func_pt(x, y):         output1 = x * torch.logical_xor(x, y)         return output1.sum()     def func_ms(x, y):         output1 = x * ms.mint.logical_xor(x, y)         return output1.sum()     output_pt = func_pt(input_pt1, input_pt2)     output_pt.backward()     gradient_pt1 = input_pt1.grad     gradient_pt2 = input_pt2.grad     grad_func = value_and_grad(func_ms, grad_position=(0,1))     output_ms, gradient_ms = grad_func(input_ms1, input_ms2)     gradient_ms1 = gradient_ms[0]     gradient_ms2 = gradient_ms[1]      print(""output:"", output_pt, output_ms)      print(""gradient"", gradient_pt1, gradient_ms)     assert np.allclose(output_ms.numpy(), output_pt.detach().numpy(), rtol=1e3)     assert np.allclose(gradient_pt1.numpy(), gradient_ms1.numpy(), rtol=1e3)     assert np.allclose(gradient_pt2.numpy(), gradient_ms2.numpy(), rtol=1e3) ``` 将以上代码保存为test_logical_xor.py文件 （2）执行代码 在终端内进入test_logical_xor.py所在的目录下，输入pytest sv test_logical_xor.py命令即可查看测试结果  4.预期结果 > **【预期结果】**：使用了mindspore.mint.logical_xor接口的函数可以正常进行反向传播，且函数的反向传播的梯度与pytorch框架下对应的反向传播梯度的相对误差小于1e3  5.报错信息展示 完整报错信息如下： ```python ______________________________________________________________________________ test_forward_backward[0] ______________________________________________________________________________ mode = 0     .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE])     def test_forward_backward(mode):         """"""         (2) 测试两个框架的正向推理结果和反向梯度精度差异         """"""         ms.set_context(mode=mode, device_target='Ascend')         data_lst1 = [[1.1, 1.2, 1.3, 1.4], [1.5, 1.6, 1.7, 1.8]]         data_lst2 = [[1.1, 0, 1.3, 0], [0, 1.6, 0, 1.8]]         input_ms1 = ms.tensor(data_lst1, dtype=ms.float64)         input_ms2 = ms.tensor(data_lst2, dtype=ms.float64)         input_pt1 = torch.tensor(data_lst1, dtype=torch.float64, requires_grad=True)         input_pt2 = torch.tensor(data_lst2, dtype=torch.float64, requires_grad=True)         def func_pt(x, y):             output1 = x * torch.logical_xor(x, y)             return output1.sum()         def func_ms(x, y):             output1 = x * ms.mint.logical_xor(x, y)             return output1.sum()         output_pt = func_pt(input_pt1, input_pt2)         output_pt.backward()         gradient_pt1 = input_pt1.grad         gradient_pt2 = input_pt2.grad         grad_func = value_and_grad(func_ms, grad_position=(0,1)) >       output_ms, gradient_ms = grad_func(input_ms1, input_ms2) test_logical_xor.py:309:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:960: in staging_specialize     out = _MindsporeFunctionExecutor(func, hash_obj, dyn_args, process_obj, jit_config)(*args, **kwargs) ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:188: in wrapper     results = fn(*arg, **kwargs) ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:582: in __call__     raise err ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:579: in __call__     phase = self.compile(self.fn.__name__, *args_list, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = , method_name = 'after_grad' args = (Tensor(shape=[2, 4], dtype=Float64, value= [[ 1.10000000e+00,  1.20000000e+00,  1.30000000e+00,  1.40000000e+00],  [ ...000000e+00,  1.30000000e+00,  0.00000000e+00],  [ 0.00000000e+00,  1.60000000e+00,  0.00000000e+00,  1.80000000e+00]])) kwargs = {} compile_args = (Tensor(shape=[2, 4], dtype=Float64, value= [[ 1.10000000e+00,  1.20000000e+00,  1.30000000e+00,  1.40000000e+00],  [ ...000000e+00,  1.30000000e+00,  0.00000000e+00],  [ 0.00000000e+00,  1.60000000e+00,  0.00000000e+00,  1.80000000e+00]])) key_id = '1876507875570161745726118521118976' generate_name = 'mindspore.ops.composite.base.after_grad./home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py.599.1745726118521118976' echo_function_name = 'function ""after_grad"" at the file ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py"", line 599' full_function_name = 'mindspore.ops.composite.base.after_grad./home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py.599' create_time = '1745726118521118976', key = 0, parameter_ids = '' phase = 'mindspore.ops.composite.base.after_grad./home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/composite/base.py.599.1745726118521118976.0' jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...}     def compile(self, method_name, *args, **kwargs):         """"""Returns pipeline for the given args.""""""          Check whether hook function registered on Cell object.         if self.obj and hasattr(self.obj, ""_hook_fn_registered""):             if self.obj._hook_fn_registered():                 logger.warning(f""For 'Cell', it's not support hook function when using 'jit' decorator. ""                                f""If you want to use hook function, please use context.set_context to set ""                                f""pynative mode and remove 'jit' decorator."")          Chose dynamic shape tensors or actual input tensors as compile args.         compile_args = self._generate_compile_args(args)         key_id = self._get_key_id()         compile_args = get_auto_dynamic_shape_args_with_check_input_signature(compile_args, key_id,                                                                               self.input_signature)          Restore the mutable attr for every arg.         compile_args = _restore_mutable_attr(args, compile_args)         self._compile_args = compile_args         generate_name, echo_function_name = self._get_generate_name()          The full Function name         full_function_name = generate_name         create_time = ''          Add key with obj         if self.obj is not None:             if self.obj.__module__ != self.fn.__module__:                 logger.info(                     f'The module of `self.obj`: `{self.obj.__module__}` is not same with the module of `self.fn`: '                     f'`{self.fn.__module__}`')             self.obj.__parse_method__ = method_name             if isinstance(self.obj, ms.nn.Cell):                 generate_name = generate_name + '.' + str(self.obj.create_time)                 create_time = str(self.obj.create_time)             else:                 generate_name = generate_name + '.' + str(self._create_time)                 create_time = str(self._create_time)             generate_name = generate_name + '.' + str(id(self.obj))             full_function_name = generate_name         else:              Different instance of same class may use same memory(means same obj_id) at diff times.              To avoid unexpected phase matched, add create_time to generate_name.             generate_name = generate_name + '.' + str(self._create_time)             create_time = str(self._create_time)         self.enable_tuple_broaden = False         if hasattr(self.obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = self.obj.enable_tuple_broaden         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(self.fn, compile_args, kwargs, self.enable_tuple_broaden)         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             key = str(key) + '.' + parameter_ids         phase = generate_name + '.' + str(key)         update_auto_dynamic_shape_phase_with_check_input_signature(compile_args, key_id, phase, self.input_signature)         if phase in ms_compile_cache:              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             return phase         _check_recompile(self.obj, compile_args, kwargs, full_function_name, create_time, echo_function_name)          If enable compile cache, get the dependency files list and set to graph executor.         self._set_compile_cache_dep_files()         if self.jit_config_dict:             self._graph_executor.set_jit_config(self.jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         if self.obj is None:              Set an attribute to fn as an identifier.             if isinstance(self.fn, types.MethodType):                 setattr(self.fn.__func__, ""__jit_function__"", True)             else:                 setattr(self.fn, ""__jit_function__"", True) >           is_compile = self._graph_executor.compile(self.fn, compile_args, kwargs, phase, True) E           RuntimeError: Illegal primitive: Primitive LogicalXor's bprop not defined.node:ValueNode fake_bprop, location: E            E            E            Framework Unexpected Exception Raised: E            E           This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help. E            E            E            C++ Call Stack: (For framework developers) E            E           mindspore/ccsrc/pipeline/jit/ps/validator.cc:83 ValidateOperation ../../../../anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:674: RuntimeError ```  6.备注 **【定位人】** 张泰来",2025-04-27T12:01:12+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4AFQ
deepseek,wuweikang,add accuracy and memory testcase for deepseek v3,,2025-04-27T11:47:34+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC4A8K
ascend,zhanghanLeo,DTS2025042511021  PA error.,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-26T16:53:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC451M
bfloat16,zhajiangtao2025,mindspore.mint.all 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.all 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_all.py::test_all_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_all_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 all 函数             ms_output = mint.all(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 all 函数             torch_output = torch.all(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-24T13:56:25+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M70
bfloat16,zhajiangtao2025,mindspore.mint.argmin 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.argmin 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_argmin.py::test_argmin_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_argmin_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 argmin 函数             ms_output = mint.argmin(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 argmin 函数             torch_output = torch.argmin(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-04-24T13:55:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M6J
bfloat16,zhajiangtao2025,mindspore.mint.argmax 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.argmax 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_argmax.py::test_argmax_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_argmax_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 argmax 函数             ms_output = mint.argmax(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 argmax 函数             torch_output = torch.argmax(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-04-24T13:53:48+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M5S
bfloat16,zhajiangtao2025,mindspore.mint.xlogy 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！精度不对齐！框架支持度不对齐！," 1.Describe the current behavior / 问题描述 > mindspore.mint.xlogy 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！精度不对齐！框架支持度不对齐！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_xlogy.py::test_xlogy_all_dtypes test_xlogy.py::test_xlogy_fixed_dtype_random_input test_xlogy.py::test_xlogy_different_input_types  4.Steps to reproduce the issue / 重现步骤  ``` ''' 1.对应Pytorch 的相应接口进行测试： a) 测试random输入不同dtype，对比两个框架的支持度 ''' .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_xlogy_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 xlogy 函数             ms_output = mint.xlogy(ms_input,ms.tensor([2.0] * len(input_data),ms_dtype))              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 xlogy 函数             torch_output = torch.xlogy(torch_input,torch.tensor([2.0] * len(input_data)))              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ''' b) 测试固定dtype，random输入值，对比两个框架输出是否相等（误差范围为小于1e3） ''' .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_xlogy_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.xlogy(ms_input,ms.tensor([2.0] * len(input_data),dtype))             torch_output = torch.xlogy(torch_input,torch.tensor([2.0] * len(input_data),dtype=torch_dtype))              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ''' c) 测试固定shape，固定输入值，不同输入参数（string/bool等类型），两个框架的支持度(测试的函数没有输入参数，因此这里测试不同的输入类型) ''' .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_xlogy_different_input_types(mode):     ms.set_context(mode=mode)      固定 shape 为 (3,)     shape = (3,)      定义不同的输入类型     input_data = [1.1, 2.5, 1.5]   基础数据     input_types = {         ""list"": input_data,   Python list         ""np.array"": np.array(input_data, dtype=np.float32),   NumPy array         ""mindspore.tensor"": ms.tensor(input_data, ms.float32),   MindSpore mindspore.tensor         ""torch.tensor"": torch.tensor(input_data, dtype=torch.float32),   PyTorch tensor         ""tuple"": tuple(input_data),   Python tuple         ""string"": ""1.1, 2.5, 1.5"",   String     }      初始化支持和不支持的列表     ms_supported_types = []     ms_unsupported_types = []     torch_supported_types = []     torch_unsupported_types = []      遍历所有输入类型     for input_name, input_value in input_types.items():         try:              测试 MindSpore             ms_output = mint.xlogy(input_value,ms.tensor([2.0] * len(input_data),ms_dtype))              shape 与预期一致             assert ms_output.shape == shape             ms_supported_types.append(input_name)         except Exception as e:             ms_unsupported_types.append(input_name)         try:              测试 PyTorch             torch_output = torch.xlogy(input_value,torch.tensor([2.0] * len(input_data)))              shape 与预期一致             assert torch_output.shape == shape             torch_supported_types.append(input_name)         except Exception as e:             torch_unsupported_types.append(input_name)      打印支持和不支持的输入类型     print(f""MindSpore supported input types: {ms_supported_types}"")     print(f""MindSpore unsupported input types: {ms_unsupported_types}"")     print(f""PyTorch supported input types: {torch_supported_types}"")     print(f""PyTorch unsupported input types: {torch_unsupported_types}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int8, mindspore.int16, mindspore.int32, mindspore.int64, mindspore.uint8, mindspore.float16, mindspore.float32, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.float64, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] MindSpore supported input types: [] MindSpore unsupported input types: ['list', 'np.array', 'mindspore.tensor', 'torch.tensor', 'tuple', 'string'] PyTorch supported input types: ['torch.tensor'] PyTorch unsupported input types: ['list', 'np.array', 'mindspore.tensor', 'tuple', 'string'] args = (.compare at 0xfffe84d65ee0>, array([0.37695312, 0.11328125,  0.02844238, 0.69140...0.69140625,  0.51171875,        0.35351562, 0.15820312, 0.6875    , 1.7734375 , 0.1328125 ],       dtype=float32)) kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=0.001, atol=0', 'verbose': True}     (func)     def inner(*args, **kwds):         with self._recreate_cm(): >           return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 6 / 10 (60%) E           Max absolute difference: 0.00390625 E           Max relative difference: 0.00763359 E            x: array([0.376953, 0.113281,  0.028442, 0.691406,  0.515625, 0.355469, E                  0.158203, 0.691406, 1.773438, 0.132812], dtype=float32) E            y: array([0.375   , 0.112793,  0.02832 , 0.691406,  0.511719, 0.353516, E                  0.158203, 0.6875  , 1.773438, 0.132812], dtype=float32) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  args = (.compare at 0xfffe84d07160>, array([0.421875  , 0.09521484,  0.6640625 ,  0.14453...0.14355469,  0.21289062,        0.7578125 , 0.609375  ,  1.2421875 , 0.5078125 ,  1.1484375 ],       dtype=float32)) kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=0.001, atol=0', 'verbose': True}     (func)     def inner(*args, **kwds):         with self._recreate_cm(): >           return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 3 / 10 (30%) E           Max absolute difference: 0.00390625 E           Max relative difference: 0.00680272 E            x: array([0.421875, 0.095215,  0.664062,  0.144531,  0.213867, 0.757812, E                  0.609375,  1.242188, 0.507812,  1.148438], dtype=float32) E            y: array([0.421875, 0.095215,  0.660156,  0.143555,  0.212891, 0.757812, E                  0.609375,  1.242188, 0.507812,  1.148438], dtype=float32) ../../anaconda3/envs/MindSpore/lib/python3.9/contextlib.py:79: AssertionError  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image !image",2025-04-24T13:51:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M4V
bfloat16,zhajiangtao2025,mindspore.mint.trunc 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.trunc 静态图与动态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_trunc.py::test_trunc_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_trunc_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 trunc 函数             ms_output = mint.trunc(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 trunc 函数             torch_output = torch.trunc(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128] .MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-24T13:46:28+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3M0Q
ascend,wangyibo,bugfix msadapter st_test,"   Describe the current behavior / 问题描述 (Mandatory / 必填) 因端口问题导致的通信初始化失败。  !输入图片说明  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-24T11:38:15+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC3L45
yi,majun-bot,CVE20233446,"一、漏洞信息 漏洞编号：CVE20233446 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： Issue summary: Checking excessively long DH keys or parameters may be very slow. Impact summary: Applications that use the functions DH_check(), DH_check_ex() or EVP_PKEY_param_check() to check a DH key or DH parameters may experience long delays. Where the key or parameters that are being checked have been obtained from an untrusted source this may lead to a Denial of Service. The function DH_check() performs various checks on DH parameters. One of those checks confirms that the modulus ('p' parameter) is not too large. Trying to use a very large modulus is slow and OpenSSL will not normally use a modulus which is over 10,000 bits in length. However the DH_check() function checks numerous aspects of the key or parameters that have been supplied. Some of those checks use the supplied modulus value even if it has already been found to be too large. An application that calls DH_check() and supplies a key or parameters obtained from an untrusted source could be vulernable to a Denial of Service attack. The function DH_check() is itself called by a number of other OpenSSL functions. An application calling any of those other functions may similarly be affected. The other functions affected by this are DH_check_ex() and EVP_PKEY_param_check(). Also vulnerable are the OpenSSL dhparam and pkeyparam command line applications when using the 'check' option. The OpenSSL SSL/TLS implementation is not affected by this issue. The OpenSSL 3.0 and 3.1 FIPS providers are not affected by this issue. 漏洞公开时间：20230719 20:15:10 漏洞创建时间：20250424 02:18:31 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20233446 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 漏洞评分(MindSpore评分): &emsp;BaseScore：  &emsp;Vector：  受影响版本排查(受影响/不受影响)： 1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:",2025-04-24T02:18:31+08:00,"CVE/UNFIXED,gitee",open,0,2,https://gitee.com/mindspore/mindspore/issues/IC3I3L,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
bfloat16,zhajiangtao2025,mindspore.mint.rsqrt 静态图与动态图下，mindspore与torch精度不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.rsqrt 静态图与动态图下，mindspore与torch精度不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_rsqrt.py::test_rsqrt_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_rsqrt_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.rsqrt(ms_input)             torch_output = torch.rsqrt(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： test_rsqrt.py:112:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ args = (.compare at 0xfffe99071790>, array([      nan,       nan, 4.9375   ,       nan, 1.1...rray([    nan,     nan, 4.9375 ,     nan, 1.15625,     nan,     nan,            nan,     nan,     nan], dtype=float32)) kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=0.001, atol=0', 'verbose': True}     (func)     def inner(*args, **kwds):         with self._recreate_cm(): >           return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 1 / 10 (10%) E           Max absolute difference: 0.0078125 E           Max relative difference: 0.00675676 E            x: array([     nan,      nan, 4.9375  ,      nan, 1.164062,      nan, E                       nan,      nan,      nan,      nan], dtype=float32) E            y: array([    nan,     nan, 4.9375 ,     nan, 1.15625,     nan,     nan, E                      nan,     nan,     nan], dtype=float32) ../../anaconda3/envs/MindSpore/lib/python3.9/contextlib.py:79: AssertionError            return func(*args, **kwds) E           AssertionError:  E           Not equal to tolerance rtol=0.001, atol=0 E            E           Mismatched elements: 1 / 10 (10%) E           Max absolute difference: 0.0078125 E           Max relative difference: 0.004329 E            x: array([     nan,      nan, 1.023438, 2.1875  , 1.796875,      nan, E                       nan, 0.746094,      nan, 0.777344], dtype=float32) E            y: array([     nan,      nan, 1.023438, 2.1875  , 1.804688,      nan, E                       nan, 0.746094,      nan, 0.777344], dtype=float32) ../../anaconda3/envs/MindSpore/lib/python3.9/contextlib.py:79: AssertionError  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:27:41+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GTM
bfloat16,zhajiangtao2025,mindspore.mint.round 动态图下，mindspore与torch支持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.round 动态图下，mindspore与torch支持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_round.py::test_round_different_input_types  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_round_different_input_types(mode):     ms.set_context(mode=mode)      固定 shape 为 (3,)     shape = (3,)      定义不同的输入类型     input_data = [1.1, 2.5, 1.5]   基础数据     input_types = {         ""list"": input_data,   Python list         ""np.array"": np.array(input_data, dtype=np.float32),   NumPy array         ""mindspore.tensor"": ms.tensor(input_data, ms.float32),   MindSpore mindspore.tensor         ""torch.tensor"": torch.tensor(input_data, dtype=torch.float32),   PyTorch tensor         ""tuple"": tuple(input_data),   Python tuple         ""string"": ""1.1, 2.5, 1.5"",   String     }      初始化支持和不支持的列表     ms_supported_types = []     ms_unsupported_types = []     torch_supported_types = []     torch_unsupported_types = []      遍历所有输入类型     for input_name, input_value in input_types.items():         try:              测试 MindSpore             ms_output = mint.round(input_value)              shape 与预期一致             assert ms_output.shape == shape             ms_supported_types.append(input_name)         except Exception as e:             ms_unsupported_types.append(input_name)         try:              测试 PyTorch             torch_output = torch.round(input_value)              shape 与预期一致             assert torch_output.shape == shape             torch_supported_types.append(input_name)         except Exception as e:             torch_unsupported_types.append(input_name)      打印支持和不支持的输入类型     print(f""MindSpore supported input types: {ms_supported_types}"")     print(f""MindSpore unsupported input types: {ms_unsupported_types}"")     print(f""PyTorch supported input types: {torch_supported_types}"")     print(f""PyTorch unsupported input types: {torch_unsupported_types}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：.MindSpore supported dtypes: [mindspore.int32, mindspore.int64, mindspore.float16, mindspore.float32, mindspore.float64, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int8, mindspore.int16, mindspore.uint8, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16] PyTorch unsupported dtypes: [torch.complex64, torch.complex128]  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:24:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GTA
bfloat16,zhajiangtao2025,mindspore.mint.roll 静态图下，mindspore与torch⽀持的数据类型不对⻬！," 1.Describe the current behavior / 问题描述 > mindspore.mint.roll 静态图下，mindspore与torch⽀持的数据类型不对⻬！  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  test_roll.py::test_roll_all_dtypes  4.Steps to reproduce the issue / 重现步骤  ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_roll_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 roll 函数             ms_output = mint.roll(ms_input,shifts=0)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 roll 函数             torch_output = torch.roll(torch_input,shifts=0)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**： MindSpore supported dtypes: [mindspore.int8, mindspore.int32, mindspore.int64, mindspore.uint8, mindspore.float16, mindspore.float32, mindspore.bfloat16] MindSpore unsupported dtypes: [mindspore.int16, mindspore.float64, mindspore.complex64, mindspore.complex128] PyTorch supported dtypes: [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.complex64, torch.complex128] PyTorch unsupported dtypes: []  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image",2025-04-23T19:11:51+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC3GQX
transformer,emf,transformer案例训练报错,环境：启智社区910 B2，CANN8，ms2.5.0镜像 训练报错 !输入图片说明,2025-04-23T16:30:36+08:00,"foruda,ms-release,pypi",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC3EEF,使用启智910b环境的cann8_0_0beta_mindspore2_5镜像运行，主要有以下几个问题： 1.由于是notebook运行的，所以默认使用的是MindSpore这个虚拟环境，这个虚拟环境里的mindspore配置有点问题，镜像里的cann是8.0，但mindspore版本是2.3，这样不匹配，需要安装2.5.0，且使用pip install mindspore可能无法更新，需要指定版本，或者使用官网的命令： pip install https://msrelease.obs.cnnorth4.myhuaweicloud.com/2.5.0/MindSpore/unified/aarch64/mindspore2.5.0cp39cp39linux_aarch64.whl trustedhost msrelease.obs.cnnorth4.myhuaweicloud.com i https://pypi.tuna.tsinghua.edu.cn/simple 2.升级到2.5后，其它的te等依赖包需要重新安装，否则会出现ge错误： pip uninstall sympy te topi hccl y pip install sympy pip install /usr/local/Ascend/ascendtoolkit/latest/lib64/te*py3noneany.whl pip install /usr/local/Ascend/ascendtoolkit/latest/lib64/hccl*py3noneany.whl 3.由于该镜像的notebook环境中，环境变量有点问题，没有正确加载昇腾后端的环境变量，不能加载昇腾后端，且用户应该无法修改这个设置，只能由启智社区去处理，所以notebook环境目前跑不了昇腾后端，只能用CPU去运行； 通过上面1和2的配置，可以在终端里运行transformer的示例代码： !输入图片说明
ascend,zhangbuxue,精度故障不重启快恢偶现卡死问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-04-22T15:15:29+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC31NI
ascend,wangyibo,msadapter st_test init failed random,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  msadapter的模型用例偶现的初始化失败问题。 !输入图片说明  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-21T14:06:01+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC2OW1
bfloat16,zhuhuachao2024,mindspore.mint.nn.functional.grid_sample函数不支持bfloat16，但使用时在执行命令时不报错，却会导致后续命令报错," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.grid_sample函数不支持bfloat16，但执行命令时不报错，却会导致后续命令报错  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F def test_bfloat16():     batch_size = 2     channels = 3     height = 8     width = 8     grid_height = 6     grid_width = 6     np_input = np.random.randn(batch_size, channels, height, width).astype(np.float32)     np_grid = np.random.uniform(1, 1, (batch_size, grid_height, grid_width, 2)).astype(np.float32)     ms_dtype=ms.bfloat16     try:          首先尝试 mint.nn.functional.grid_sample         ms_input = Tensor(np_input, dtype=ms_dtype)         ms_grid = Tensor(np_grid, dtype=ms_dtype)         ms_output = mint_F.grid_sample(ms_input, ms_grid, mode='bilinear', padding_mode='zeros', align_corners=False)         print(f""MindSpore 输出 ({'mint API' if ms_using_mint else '替代实现'}): shape={ms_output.shape}"")         ms_support = ""支持""     except Exception as e:         print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")         ms_support = ""不支持""     input_shape = (2, 1, 8, 8),       单通道     grid_shape = (2, 6, 6, 2)     print(f""\n测试输入尺寸: 输入={input_shape}, 网格={grid_shape}"")      生成随机输入     np_input = np.random.randn(*input_shape).astype(np.float32)     np_grid = np.random.uniform(1, 1, grid_shape).astype(np.float32)      MindSpore     ms_input = Tensor(np_input, dtype=ms.float32)     ms_grid = Tensor(np_grid, dtype=ms.float32)     ms_output = mint_F.grid_sample(ms_input, ms_grid, mode='bilinear', padding_mode='zeros', align_corners=False)     print(f""MindSpore 输出: shape={ms_output.shape}"")     mindspore_np = mindspore_out.asnumpy()  这里报错 ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：在执行函数行报错  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:20:46+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NU4
bfloat16,zhuhuachao2024,mindspore.mint.nn.functional.mse_loss函数不支持float64输入类型," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.mse_loss函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16，但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      首先尝试 mint.nn.functional.mse_loss     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.mse_loss(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出 : {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")     ms_support = ""不支持"" ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:09:43+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NRX
bfloat16,zhuhuachao2024,mindspore.mint.nn.functional.l1_loss函数不支持float64输入类型," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.l1_loss函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16，但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      MindSpore     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.l1_loss(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出: {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")     ms_support = ""不支持"" ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 !输入图片说明  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T12:07:11+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NRQ
bfloat16,zhuhuachao2024,mindspore.mint.nn.functional.binary_cross_entropy_with_logits函数不支持float64输入类型," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.binary_cross_entropy_with_logits函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16 （和文档一致），但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      MindSpore     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.binary_cross_entropy_with_logits(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出: {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {type(e).__name__}: {str(e)}"")     ms_support = ""不支持"" ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 TypeError: For primitive[BCEWithLogitsLoss], the input argument[input] must be a type of {BFloat16, Float16, Float32}, but got Float64.  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T11:59:02+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NPZ
bfloat16,zhuhuachao2024,mindspore.mint.nn.functional.binary_cross_entropy函数不支持float64类型输入," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.binary_cross_entropy函数的支持输入类型不足： pytorch  float16, float32, float64，bfloat16 mindspore  float16, float32, bfloat16 （和文档一致），但不支持float64  2.Environment / 环境信息   3.Steps to reproduce the issue / 重现步骤 ``` import numpy as np import torch import torch.nn.functional as F import mindspore as ms from mindspore import Tensor import mindspore.mint.nn.functional as mint_F shape = (3, 4) np_input = np.random.randn(*shape).astype(np.float32) np_target = np.random.randn(*shape).astype(np.float32) ms_dtype = ms.float64 try:      MindSpore     ms_input = Tensor(np_input, dtype=ms_dtype)     ms_target = Tensor(np_target, dtype=ms_dtype)     ms_output = mint_F.binary_cross_entropy(ms_input, ms_target, reduction='mean')     print(f""MindSpore 输出: {ms_output.asnumpy().item()}, shape: {ms_output.shape}"")     ms_support = ""支持"" except Exception as e:     print(f""MindSpore 错误: {str(e)}"")     ms_support = ""不支持"" print(f""PyTorch: {pt_support}, MindSpore: {ms_support}"") ```  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：输出正确结果  5.报错信息 For Primitive[BinaryCrossEntorpy], the type of the input must be [Float16, Float32, BFloat16], but got Float64!  6.Special notes for this issue/备注  **【定位人】**朱华超",2025-04-21T11:55:16+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC2NOR
pynative mode,tinymonster123,[GPU]uint8→int8类型下等价模型Max操作输出不一致（Where/Max/Cast链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（涉及uint8→int8的Cast、Where、Max等操作）推理结果出现不一致。理论上两个模型输出应完全一致，但实际Max结果有0.2%的元素不匹配，最大差异高达251。而Less操作输出完全一致，表明问题出现在Max操作在Cast前后的位置差异导致的整型数据流异常。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个数学上等价的模型：       T1Model 执行顺序：`Where → Max → Cast → Min → Less`       T2Model 执行顺序：`Where → Cast → Min → Less → Max` 2. 使用相同的 uint8/int8 输入数据进行推理：      ```python    import numpy as np    import mindspore as ms    import mindspore.nn as nn    import mindspore.ops as ops    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")    np.random.seed(42)     创建输入数据    mask = ms.Tensor(np.random.choice([True, False], size=(5, 14, 1, 14, 57)))    val1 = ms.Tensor(np.random.randint(0, 255, size=(57,), dtype=np.uint8))    val2 = ms.Tensor(np.random.randint(0, 255, size=(1, 1, 57), dtype=np.uint8))     执行两种模型    t1_max, t1_less = T1Model()(mask, val1, val2)    t2_max, t2_less = T2Model()(mask, val1, val2)    ``` 3. 比较结果，典型输出:    ```    == T1模型输出 ==    Max结果  形状: (5, 14, 1, 14, 57) 数据类型: UInt8    部分值 (前5个元素): [135  75 133 120  34]    统计信息  最小值: 0 最大值: 253    == T2模型输出 ==    Max结果  形状: (5, 14, 1, 14, 57) 数据类型: UInt8    部分值 (前5个元素): [135  75 133 120  34]    统计信息  最小值: 0 最大值: 253    == Max算子结果比较 ==    不匹配元素数量: 92 / 55860 (0.2%)    最大绝对差异: 251    最大差异位置(0, 0, 0, 9, 42): T1=0, T2=5    == Less算子结果比较 ==    Less输出完全一致    ``` 4. 理论上两个模型输出应完全一致，但实际Max结果有0.2%的元素不匹配，最大差异高达251。而Less结果完全一致，表明问题出现在Max操作的位置不同导致的整型数据流异常。 ```python import numpy as np import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.cast = ops.Cast()     def construct(self, v5_0, v6_0, v7_0):          v5_0: b[5, 14, 1, 14, 57], v6_0: u8[57], v7_0: u8[1, 1, 57]         v8_0 = ops.where(v5_0, v6_0, v7_0)            core.Where         v3_0 = ops.maximum(v8_0, v8_0)                core.Max         v1_0 = self.cast(v8_0, ms.int8)               Cast to int8         v2_0 = ops.minimum(v1_0, v1_0)                core.Min         v4_0 = ops.less(v2_0, v1_0)                   core.Less          返回多个结果方便分析         return v3_0, v4_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.cast = ops.Cast()     def construct(self, v2_0, v1_0, v0_0):          v2_0: b[5, 14, 1, 14, 57], v1_0: u8[57], v0_0: u8[1, 1, 57]           v3_0 = ops.where(v2_0, v1_0, v0_0)            core.Where         v4_0 = self.cast(v3_0, ms.int8)               Cast to int8         v5_0 = ops.minimum(v4_0, v4_0)                core.Min           v6_0 = ops.less(v5_0, v4_0)                   core.Less         v8_0 = ops.maximum(v3_0, v3_0)                core.Max          返回多个结果方便分析         return v8_0, v6_0 def reproduce_bug():      设置环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1 = T1Model()     t2 = T2Model()      根据图创建输入  严格按照DOT文件中的形状和类型     np.random.seed(42)     shape1 = (5, 14, 1, 14, 57)     shape2 = (57,)     shape3 = (1, 1, 57)      T1输入     v5_0_t1 = ms.Tensor(np.random.choice([True, False], size=shape1))     v6_0_t1 = ms.Tensor(np.random.randint(0, 255, shape2, dtype=np.uint8))     v7_0_t1 = ms.Tensor(np.random.randint(0, 255, shape3, dtype=np.uint8))      T2输入  保持相同输入以便比较     v2_0_t2 = v5_0_t1   布尔掩码     v1_0_t2 = v6_0_t1   uint8[57]     v0_0_t2 = v7_0_t1   uint8[1, 1, 57]      执行模型     t1_v3_0, t1_v4_0 = t1(v5_0_t1, v6_0_t1, v7_0_t1)     t2_v8_0, t2_v6_0 = t2(v2_0_t2, v1_0_t2, v0_0_t2)      打印T1和T2的输出     print(""\n== T1模型输出 =="")     print(""Max结果  形状:"", t1_v3_0.shape, ""数据类型:"", t1_v3_0.dtype)     print(""部分值 (前5个元素):"", t1_v3_0.asnumpy().flatten()[:5])     print(""统计信息  最小值:"", np.min(t1_v3_0.asnumpy()), ""最大值:"", np.max(t1_v3_0.asnumpy()))     print(""\n== T2模型输出 =="")     print(""Max结果  形状:"", t2_v8_0.shape, ""数据类型:"", t2_v8_0.dtype)     print(""部分值 (前5个元素):"", t2_v8_0.asnumpy().flatten()[:5])     print(""统计信息  最小值:"", np.min(t2_v8_0.asnumpy()), ""最大值:"", np.max(t2_v8_0.asnumpy()))      比较对应的输出结果     print(""\n== Max算子结果比较 =="")     print(""形状: T1:"", t1_v3_0.shape, ""T2:"", t2_v8_0.shape)     if np.array_equal(t1_v3_0.asnumpy(), t2_v8_0.asnumpy()):         print(""Max输出完全一致"")     else:         mismatched = (t1_v3_0.asnumpy() != t2_v8_0.asnumpy())         mismatched_count = np.sum(mismatched)         total_elements = t1_v3_0.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.1f}%)"")          计算差异         abs_diff = np.abs(t1_v3_0.asnumpy()  t2_v8_0.asnumpy())         max_diff = np.max(abs_diff)         print(f""最大绝对差异: {max_diff}"")          找出差异最大的位置         flat_idx = np.argmax(abs_diff.flatten())         idx = np.unravel_index(flat_idx, abs_diff.shape)         print(f""最大差异位置{idx}: T1={t1_v3_0.asnumpy()[idx]}, T2={t2_v8_0.asnumpy()[idx]}"")     print(""\n== Less算子结果比较 =="")     print(""形状: T1:"", t1_v4_0.shape, ""T2:"", t2_v6_0.shape)     if np.array_equal(t1_v4_0.asnumpy(), t2_v6_0.asnumpy()):         print(""Less输出完全一致"")      else:         bool_mismatched = (t1_v4_0.asnumpy() != t2_v6_0.asnumpy())         bool_mismatched_count = np.sum(bool_mismatched)         bool_total = t1_v4_0.size         bool_mismatch_percentage = 100.0 * bool_mismatched_count / bool_total         print(f""不匹配元素数量: {bool_mismatched_count} / {bool_total} ({bool_mismatch_percentage:.1f}%)"")          显示部分不匹配的布尔值         indices = np.where(bool_mismatched)         for i in range(min(3, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={t1_v4_0.asnumpy()[idx]}, T2={t2_v6_0.asnumpy()[idx]}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:53:13+08:00,"foruda,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G5M,"这里的问题应该不是max或者cast的问题，也不是那些api的执行顺序导致的，问题应该是出现在mindspore.ops.where上面，这个方法确实有点问题，用以下代码就能验证： import mindspore as ms import mindspore.ops as ops import numpy as np np.random.seed(42) shape1 = (5, 14, 1, 14, 57) shape2 = (57,) shape3 = (1, 1, 57) t1 = ms.Tensor(np.random.choice([True, False], size=shape1)) t2 = ms.Tensor(np.random.randint(0, 255, shape2, dtype=np.uint8)) t3 = ms.Tensor(np.random.randint(0, 255, shape3, dtype=np.uint8)) r1 = ops.where(t1, t2, t3) r2 = ops.where(t1, t2, t3) (r1==r2).sum() 执行两次where，输入一模一样的，但是输出却不完全相同，(r1==r2).sum()的值也小于总数55860，说明有元素不相同，执行多次，出现不同元素的个数还会有差异： !输入图片说明 更进一步分析，我觉得可能是where里面进行广播时出现了问题，因为如果三个参数condition, x, y都写成一样的shape，就不需要执行广播逻辑，而这样的结果就是正确的，如下示例代码所示： import mindspore as ms import mindspore.ops as ops import numpy as np np.random.seed(42) shape1 = (5, 14, 1, 14, 57) shape2 = (5, 14, 1, 14,57) shape3 = (5, 14, 1, 14, 57) t1 = ms.Tensor(np.random.choice([True, False], size=shape1)) t2 = ms.Tensor(np.random.randint(0, 255, shape2, dtype=np.uint8)) t3 = ms.Tensor(np.random.randint(0, 255, shape3, dtype=np.uint8)) r1 = ops.where(t1, t2, t3) r2 = ops.where(t1, t2, t3) (r1==r2).sum() !输入图片说明 这样的话执行多次，结果都是正确的"
pynative mode,tinymonster123,[GPU]uint8类型下等价模型整型张量输出不一致（Where/Max/Clip链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在 MindSpore GPU 模式下，两个数学上等价的 uint8 模型（链路：Where → Max → Clip）推理输出出现不一致。 典型运行结果： 不匹配元素数量: 66 / 58056 (0.10%) 最大绝对差异: 252 差异示例位置和值: (0,0,0,0,16) T1=1, T2=5 理论上两个模型输出应完全一致，但实际有 0.10% 元素不匹配，最大差异高达 252。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个数学等价的模型：       T1Model 执行顺序：`Ceil → Where → MatMul`       T2Model 执行顺序：`Where → Ceil → MatMul`   2. 生成相同的 float16 输入并推理 3. 打印并比较结果，典型输出如下（部分）：   ``` 输出形状: T1输出: (59, 24, 1, 1, 41) T2输出: (59, 24, 1, 1, 41) 不匹配元素数量: 66 / 58056 (0.10%) 最大绝对差异: 252 差异最大的3个元素位置和值: 位置(0, 0, 0, 0, 16): T1=1, T2=5, 差异=252 位置(0, 0, 0, 0, 15): T1=1, T2=7, 差异=250 位置(0, 13, 0, 0, 9): T1=249, T2=1, 差异=248 ``` 4. 理论上二者应输出完全一致，但实际有 0.10% 元素不匹配，且最大差异高达 252。 ```python import numpy as np import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          严格按照图中的常量初始化 v2_0 (u8[1, 1, 1])         self.const = ms.Tensor(np.ones((1, 1, 1), dtype=np.uint8))          创建其他必要的算子         self.clip_min = 0         self.clip_max = 255   uint8范围     def construct(self, v5_0, v1_0):          严格按照图中算子顺序执行          v5_0: u8[41], v1_0: b[59, 24, 1, 1, 41]          v6_0 = MSClip(v5_0)         v6_0 = ops.clip_by_value(v5_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v3_0 = Reshape(v6_0)         v3_0 = ops.reshape(v6_0, v6_0.shape)   按原形状reshape，实际可能不改变          v7_0 = Clip(v6_0)         v7_0 = ops.clip_by_value(v6_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v4_0 = Where(v1_0, v2_0, v6_0)         v4_0 = ops.where(v1_0, self.const, v6_0)          v0_0 = Max(v4_0, v2_0)         v0_0 = ops.maximum(v4_0, self.const)         return v0_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          严格按照图中的常量初始化 v0_0 (u8[1, 1, 1])         self.const = ms.Tensor(np.ones((1, 1, 1), dtype=np.uint8))          创建其他必要的算子         self.clip_min = 0         self.clip_max = 255   uint8范围     def construct(self, v1_0, v3_0):          严格按照图中算子顺序执行          v1_0: u8[41], v3_0: b[59, 24, 1, 1, 41]          v2_0 = MSClip(v1_0)         v2_0 = ops.clip_by_value(v1_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v4_0 = Where(v3_0, v0_0, v2_0)         v4_0 = ops.where(v3_0, self.const, v2_0)          v5_0 = Max(v4_0, v0_0)         v5_0 = ops.maximum(v4_0, self.const)          v7_0 = Clip(v2_0)         v7_0 = ops.clip_by_value(v2_0, ms.Tensor(self.clip_min, ms.uint8),                                  ms.Tensor(self.clip_max, ms.uint8))          v9_0 = Reshape(v2_0)         v9_0 = ops.reshape(v2_0, v2_0.shape)   按原形状reshape，实际可能不改变         return v5_0 def reproduce_bug():      设置环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1 = T1Model()     t2 = T2Model()      严格按照图中的数据类型和形状创建输入      T1输入: v5_0 (u8[41]), v1_0 (b[59, 24, 1, 1, 41])      T2输入: v1_0 (u8[41]), v3_0 (b[59, 24, 1, 1, 41])     v5_0_t1 = ms.Tensor(np.random.randint(0, 255, (41), dtype=np.uint8))     v1_0_t1 = ms.Tensor(np.random.choice([True, False], size=(59, 24, 1, 1, 41)))     v1_0_t2 = ms.Tensor(np.random.randint(0, 255, (41), dtype=np.uint8))     v3_0_t2 = ms.Tensor(np.random.choice([True, False], size=(59, 24, 1, 1, 41)))      执行模型     t1_output = t1(v5_0_t1, v1_0_t1)     t2_output = t2(v1_0_t2, v3_0_t2)      输出形状     print(""\n输出形状:"")     print(""T1输出:"", t1_output.shape)     print(""T2输出:"", t2_output.shape)      由于输入随机，我们不能直接比较输出      但可以尝试用相同的输入比较      使相同的输入     v1_0_t2 = v5_0_t1.copy()   让T2的v1_0等于T1的v5_0     v3_0_t2 = v1_0_t1.copy()   让T2的v3_0等于T1的v1_0      重新执行     t1_output = t1(v5_0_t1, v1_0_t1)     t2_output = t2(v1_0_t2, v3_0_t2)      比较输出     if np.array_equal(t1_output.asnumpy(), t2_output.asnumpy()):         print(""\n输出完全一致"")     else:         mismatched = (t1_output.asnumpy() != t2_output.asnumpy())         mismatched_count = np.sum(mismatched)         total_elements = t1_output.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""\n不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.1f}%)"")          计算差异         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         max_diff = np.max(abs_diff)         print(f""最大绝对差异: {max_diff}"")          显示差异最大的部分         if total_elements > 3:             print(""\n差异最大的3个元素位置和值:"")             flat_indices = np.argsort(abs_diff.flatten())[3:]             for flat_idx in reversed(flat_indices):                 indices = np.unravel_index(flat_idx, abs_diff.shape)                 print(f""位置{indices}: T1={t1_output.asnumpy()[indices]}, ""                       f""T2={t2_output.asnumpy()[indices]}, ""                       f""差异={abs_diff[indices]}"")         else:             print(""\n所有元素的差异:"")             for idx in np.ndindex(t1_output.shape):                 print(f""位置{idx}: T1={t1_output.asnumpy()[idx]}, ""                       f""T2={t2_output.asnumpy()[idx]}, ""                       f""差异={abs_diff[idx]}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:47:57+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G5D,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
pynative mode,tinymonster123,[GPU]int8→uint8类型下等价模型整型张量输出不一致（Xor/Where/Cast链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（涉及int8→uint8的Cast、Xor、Where等操作）推理结果出现不一致。具体表现为：部分元素输出不同，最大差异高达255，1.92%的元素不匹配。该问题在整型张量数据流经Xor、Where、Cast链路时出现，理论上应完全一致。尤其是负值转换为uint8时，差异尤为明显。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个等价模型 T1Model 和 T2Model      * T1Model 执行流程：        1) ops.cast(bool1, ms.uint8) + ops.cast(bool2, ms.uint8)        2) ops.bitwise_xor(uint8_1, uint8_2)        3) ops.cast(xor_result, ms.bool_)        4) ops.squeeze(input_int8, axis=1)        5) ops.where(bool_result, const_int8, squeezed)        6) ops.squeeze(where_result, axis=1)        7) ops.cast(squeeze_result, ms.uint8)      * T2Model 执行流程（算子顺序相同，输入参数顺序略有差异）：        1) ops.squeeze(input_int8, axis=1)        2) ops.cast(bool1, ms.uint8) + ops.cast(bool2, ms.uint8)        3) ops.bitwise_xor(uint8_1, uint8_2)        4) ops.cast(xor_result, ms.bool_)        5) ops.where(bool_result, const_int8, squeezed)        6) ops.squeeze(where_result, axis=1)        7) ops.cast(squeeze_result, ms.uint8)   2. 生成随机的 int8 和 bool 输入数据      ```python    import numpy as np    import mindspore as ms     生成不同类型的输入     特殊边界值测试    v0_0 = ms.Tensor(np.array([[127], [0], [127]] * 17 + [[1]], dtype=np.int8).reshape(52, 1, 1))    v2_0 = ms.Tensor(True, dtype=ms.bool_)    v3_0 = ms.Tensor(True, dtype=ms.bool_)    v4_0 = ms.Tensor(128, dtype=ms.int8)   int8最小值    v7_0 = ms.Tensor(False, dtype=ms.bool_)    ``` 3. 在 MindSpore GPU + PyNative 模式下运行推理      ```python    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")     初始化并实例化模型    t1 = T1Model()    t2 = T2Model()     运行两模型（注意参数顺序不同）    t1_output = t1(v0_0, v2_0, v4_0, v7_0)    t2_output = t2(v0_0, v4_0, v3_0, v2_0)    ``` 4. 对比两模型输出，统计差异      ```python    import numpy as np    t1_output_np = t1_output.asnumpy()    t2_output_np = t2_output.asnumpy()    diff = np.abs(t1_output_np  t2_output_np)    total = diff.size    mismatches = np.sum(t1_output_np != t2_output_np)    max_diff = np.max(diff)    print(f""不匹配元素: {mismatches} / {total} ({100*mismatches/total:.2f}%)"")    print(f""最大绝对差异: {max_diff}"")     分析负值转换影响    negative_mask = (v0_0.asnumpy()  max_diff_overall:             max_diff_overall = current_max_diff             best_t1_output = t1_output             best_t2_output = t2_output             best_inputs = (v0_0, v2_0, v3_0, v4_0, v7_0)             print(f""   找到更大差异: {current_max_diff}"")      使用最佳或最后一轮输出     if best_t1_output is None:         print(""\n未发现显著差异，使用最后一轮测试结果"")         t1_output = last_t1_output         t2_output = last_t2_output         inputs = last_inputs     else:         print(f""\n发现最大差异: {max_diff_overall}"")         t1_output = best_t1_output         t2_output = best_t2_output         inputs = best_inputs         v0_0, v2_0, v3_0, v4_0, v7_0 = inputs         print(f""最大差异的输入:"")         print(f""  v2_0 (T1布尔值): {v2_0.asnumpy().item()}"")         print(f""  v7_0 (T1布尔值): {v7_0.asnumpy().item()}"")         print(f""  v3_0 (T2布尔值): {v3_0.asnumpy().item()}"")         print(f""  v4_0 (T1整数/T2布尔值): {v4_0.asnumpy().item()}"")     print(""\n输出形状:"")     print(""T1 output:"", t1_output.shape)     print(""T2 output:"", t2_output.shape)      输出统计信息     t1_output_np = t1_output.asnumpy()     t2_output_np = t2_output.asnumpy()     print(""\nT1模型输出统计:"")     print(f""最小值: {np.min(t1_output_np)}, 最大值: {np.max(t1_output_np)}, 平均值: {np.mean(t1_output_np)}"")     print(""\nT2模型输出统计:"")     print(f""最小值: {np.min(t2_output_np)}, 最大值: {np.max(t2_output_np)}, 平均值: {np.mean(t2_output_np)}"")      检查数据类型     print(f""\n输出数据类型: T1={t1_output.dtype}, T2={t2_output.dtype}"")      检查输出是否一致     if np.array_equal(t1_output_np, t2_output_np):         print(""\n输出完全一致"")     else:         mismatched = (t1_output_np != t2_output_np)         mismatched_count = np.sum(mismatched)         total_elements = t1_output_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(             f""\n不匹配元素: {mismatched_count} / {total_elements} ({mismatch_percentage:.2f}%)""         )          显示差异最大的前5个元素         flat_diff = abs_diff.flatten()         max_indices = np.argsort(flat_diff)[min(5, len(flat_diff)):][::1]         print(""\n差异最大的元素:"")         for idx in max_indices:             idx_tuple = np.unravel_index(idx, t1_output.shape)             t1_val = t1_output_np[idx_tuple]             t2_val = t2_output_np[idx_tuple]             diff = flat_diff[idx]             print(f""位置{idx_tuple}: T1={t1_val}, T2={t2_val}, 差异={diff}"")          分析int8负值转uint8的影响         negative_mask = (inputs[0].asnumpy() < 0)         if np.any(negative_mask):             print(""\n负值转换为uint8的影响分析:"")             print(f""负值数量: {np.sum(negative_mask)}"")             print(f""负值对应位置的差异平均值: {np.mean(abs_diff.flatten()[negative_mask.flatten()])}"") if __name__ == ""__main__"":     reproduce_bug_796() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 关键日志： ``` 使用GPU执行测试 开始测试... 运行测试 1/20...    最大差异: 0    找到更大差异: 0 运行测试 2/20...    最大差异: 0 运行测试 3/20...    最大差异: 0 运行测试 4/20...    最大差异: 255    找到更大差异: 255 运行测试 5/20...    最大差异: 126 运行测试 6/20...    最大差异: 0 运行测试 7/20...    最大差异: 255 运行测试 8/20...    最大差异: 231 运行测试 9/20...    最大差异: 255 运行测试 10/20...    最大差异: 124 运行测试 11/20...    最大差异: 255 运行测试 12/20...    最大差异: 0 运行测试 13/20...    最大差异: 255 运行测试 14/20...    最大差异: 255 运行测试 15/20...    最大差异: 255 运行测试 16/20...    最大差异: 255 运行测试 17/20...    最大差异: 255 运行测试 18/20...    最大差异: 255 运行测试 19/20...    最大差异: 255 运行测试 20/20...    最大差异: 255 发现最大差异: 255 最大差异的输入:   v2_0 (T1布尔值): True   v7_0 (T1布尔值): False   v3_0 (T2布尔值): True   v4_0 (T1整数/T2布尔值): 128 输出形状: T1 output: (52,) T2 output: (52,) T1模型输出统计: 最小值: 0, 最大值: 128, 平均值: 2.4615384615384617 T2模型输出统计: 最小值: 0, 最大值: 129, 平均值: 2.480769230769231 输出数据类型: T1=UInt8, T2=UInt8 不匹配元素: 1 / 52 (1.92%) 差异最大的元素: 位置(1,): T1=0, T2=0, 差异=255 位置(48,): T1=0, T2=0, 差异=255 位置(18,): T1=0, T2=0, 差异=255 位置(35,): T1=0, T2=0, 差异=255 位置(44,): T1=0, T2=0, 差异=255 负值转换为uint8的影响分析: 负值数量: 17 负值对应位置的差异平均值: 156.76470588235293 ```",2025-04-19T20:44:22+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IC2G51
pynative mode,tinymonster123,[GPU]float32类型下等价模型NaN值分布不一致（Where/Mul/Reduce/Max链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（均为float32类型）推理结果出现极端不一致。具体表现为：``98.15%``的元素值不匹配，且最大差异高达``195.55``。该问题在``Where→Add→Mul→ReduceMin→Max``与``Where→Add→Concat→Concat→Split→Split→Mul→ReduceMin→Max``两个等价计算链路之间产生，理论上这两种路径应完全一致。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建两个数学上等价的模型T1Model和T2Model，均包含Where、Add、Mul、ReduceMin、Max等核心算子，执行顺序如下：     T1Model执行顺序：Where → Add → Mul → ReduceMin → Max       T2Model执行顺序：Where → Add → Concat → Concat → Split → Split → Mul → ReduceMin → Max   2. 使用相同的float32输入数据，推理后直接输出两个模型的全部结果。 3. 对比输出，发现大部分元素不一致，最大绝对差异极大。例如：    ```    T1模型输出:    [ 5.0183954  18.028572    9.2797575   3.9463394 13.759254 ... ]    T2模型输出:    [ 5.0183954  18.028572    9.2797575   3.9463394 13.759254 ... ]    ``` 4. 统计不一致情况，例如：     不匹配元素数量: 46746 / 47628 (98.15%)     最大绝对差异: 195.55     最大差异位置如(0, 23, 0, 37, 13): T1=9.99, T2=185.56 5. 结论：理论上两个模型输出应完全一致，但实际推理结果绝大多数元素不一致，且最大差异极大。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          严格按照graph.dot1定义常量         self.cond = ms.Tensor(np.ones((1, 1, 1, 1, 1), dtype=bool))      v3_0         self.const1 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v8_0         self.const2 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v6_0          创建算子实例  严格按照graph.dot不使用keep_dims         self.reduce_min = ops.ReduceMin()   dim=1, 默认keep_dims=False     def construct(self, x):          准备图中的输入         v9_0 = x[:, :, :, :1, :1]                               [1, 54, 1, 1, 1]         v4_0 = ops.reshape(x[:, :1, :, :, :], (1, 1, 1, 63, 14))   [1, 1, 1, 63, 14]         v6_0 = self.const2                                      [1, 1, 1]          按照T1的dot图顺序执行算子          node 10: Where         v10_0 = ops.where(self.cond, self.const1, v9_0)         [1, 54, 1, 1, 1]          node 7: Add  注意顺序是v10_0, v6_0         v7_0 = ops.add(v10_0, v6_0)                            [1, 54, 1, 1, 1]          node 5: Mul  注意顺序是v7_0, v4_0         v5_0 = ops.mul(v7_0, v4_0)                             [1, 54, 1, 63, 14]          node 1: ReduceMin         v1_0 = self.reduce_min(v5_0, 1)                        [1, 1, 63, 14]          node 2: MSMax         v2_0 = ops.maximum(v1_0, v5_0)                         [1, 54, 1, 63, 14]         return v2_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          严格按照dot图定义常量         self.cond = ms.Tensor(np.ones((1, 1, 1, 1, 1), dtype=bool))      v2_0         self.const1 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v1_0         self.const2 = ms.Tensor(np.ones((1, 1, 1), dtype=np.float32))    v6_0          创建算子实例  严格按照graph.dot不使用keep_dims         self.reduce_min = ops.ReduceMin()   dim=1, 默认keep_dims=False     def construct(self, x):          准备图中的所有输入  严格按照graph.dot中的描述         v0_0 = x[:, :, :, :1, :1]                               [1, 54, 1, 1, 1]         v4_0 = ops.reshape(x[:, :1, :, :, :], (1, 1, 1, 63, 14))   [1, 1, 1, 63, 14]         v6_0 = self.const2                                      [1, 1, 1]          node 3: Where         v3_0 = ops.where(self.cond, self.const1, v0_0)          [1, 54, 1, 1, 1]          node 5: Mul  并行分支1         v5_0 = ops.mul(v4_0, v3_0)                              [1, 54, 1, 63, 14]          node 7: Add  注意顺序是v6_0, v3_0         v7_0 = ops.add(v6_0, v3_0)                              [1, 54, 1, 1, 1]          node 8: Concat  必须确保输入形状正确         v8_0 = ops.concat((v7_0, v7_0), axis=0)                 [2, 54, 1, 1, 1]          node 9: Mul  并行分支2         v9_0 = ops.mul(v4_0, v7_0)                              [1, 54, 1, 63, 14]          node 10: Concat         v10_0 = ops.concat((v9_0, v9_0), axis=0)                [2, 54, 1, 63, 14]          node 11: Concat         v11_0 = ops.concat((v10_0, v10_0), axis=0)              [4, 54, 1, 63, 14]          node 12: Mul  并行分支3         v12_0 = ops.mul(v6_0, v4_0)                             [1, 1, 1, 63, 14]          node 13: Concat         v13_0 = ops.concat((v8_0, v8_0), axis=0)                [4, 54, 1, 1, 1]          node 14: Split  切片代替Split2以保证形状正确         v14_0 = v13_0[:2]                                       [2, 54, 1, 1, 1]          node 15: Split  切片代替Split2以保证形状正确         v15_0 = v14_0[:1]                                       [1, 54, 1, 1, 1]          node 16: Mul  注意顺序是v4_0, v15_0         v16_0 = ops.mul(v4_0, v15_0)                            [1, 54, 1, 63, 14]          node 17: ReduceMin  不使用keep_dims，与dot图一致         v17_0 = self.reduce_min(v16_0, 1)                       [1, 1, 63, 14]          node 18: MSMax         v18_0 = ops.maximum(v17_0, v16_0)                       [1, 54, 1, 63, 14]         return v18_0 def reproduce_bug():     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")     np.random.seed(42)      创建输入     x = ms.Tensor(np.random.uniform(10, 10, (1, 54, 1, 63, 14)).astype(np.float32))     t1 = T1Model()     t2 = T2Model()     t1_out = t1(x)     t2_out = t2(x)     print(""\n输出形状:"")     print(""T1输出:"", t1_out.shape)     print(""T2输出:"", t2_out.shape)     print(""\nT1模型输出(部分):"")     print(t1_out.asnumpy().flatten()[:5])     print(""\nT2模型输出(部分):"")     print(t2_out.asnumpy().flatten()[:5])     t1_np = t1_out.asnumpy()     t2_np = t2_out.asnumpy()      确保形状相同再比较     if t1_np.shape != t2_np.shape:         print(f""\n警告：输出形状不同! T1: {t1_np.shape}, T2: {t2_np.shape}"")         return     if np.allclose(t1_np, t2_np, rtol=1e3, atol=1e3):         print(""\n输出完全一致"")     else:         mismatched = ~np.isclose(t1_np, t2_np, rtol=1e3, atol=1e3)         mismatched_count = np.sum(mismatched)         total_elements = t1_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""\n不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.2f}%)"")         abs_diff = np.abs(t1_np  t2_np)         max_diff = np.max(abs_diff)         print(f""最大绝对差异: {max_diff}"")         flat_idx = np.argmax(abs_diff)         idx = np.unravel_index(flat_idx, abs_diff.shape)         print(f""\n最大差异位置{idx}: T1={t1_np[idx]:.4e}, T2={t2_np[idx]:.4e}, 差异={abs_diff[idx]:.4e}"")         indices = np.where(mismatched)         print(""\n部分不匹配元素:"")         for i in range(min(3, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={t1_np[idx]:.4e}, T2={t2_np[idx]:.4e}, 差异={abs_diff[idx]:.4e}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（float32张量理论上无数值异常，NaN/Inf分布应严格一致）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:40:38+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G44,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： IC2G5M:[GPU]uint8→int8类型下等价模型Max操作输出不一致（Where/Max/Cast链路） 可参考我在该issue中的说明
pynative mode,tinymonster123,[GPU]float32类型下等价模型LeakyReLU操作输出极端不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的float32模型（T1Model和T2Model）在执行完全相同的算子链路（Where、SquaredDifference、Min、LeakyReLU、Tril）时，推理结果出现明显不一致。具体表现为：  Min操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  LeakyReLU操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  Tril操作：272个输出元素中有21个不匹配（7.72%），最大绝对差异为1.0。例如位置(1, 0)：T1=1.0，T2=0.0，差异=1.0。 这些不一致在理论上不应出现，等价模型在同一输入下应输出完全一致的结果。代码已输出全部结果，并详细统计了不匹配元素数量、比例和最大差异及其具体位置。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 我创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果：  T1Model执行顺序：Where → SquaredDifference → Min → LeakyReLU → Tril  T2Model执行顺序：Where → SquaredDifference → LeakyReLU → Tril → Min 2. 使用相同的float32输入数据和常量，发现输出结果有明显差异：  Min操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  LeakyReLU操作：272个输出元素中有177个不匹配（65.07%），最大绝对差异为1.0。例如位置(0, 2)：T1=1.0，T2=0.0，差异=1.0。  Tril操作：272个输出元素中有21个不匹配（7.72%），最大绝对差异为1.0。例如位置(1, 0)：T1=1.0，T2=0.0，差异=1.0。 这些不一致在理论上不应出现，等价模型在同一输入下应输出完全一致的结果。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn squared_difference = ops.SquaredDifference() class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          初始化常量         self.condition = ms.Tensor(np.random.choice([True, False], size=(8, 34)))         self.scalar_val = ms.Tensor(np.array([0.5], dtype=np.float32))         self.vector_val = ms.Tensor(np.random.uniform(size=(34)).astype(np.float32))     def construct(self, x):          先Where操作         where_out = ops.where(self.condition, self.scalar_val, self.vector_val)          平方差计算         squared_diff = squared_difference(where_out, x)          先进行Min操作         min_out = ops.minimum(x, squared_diff)          再进行LeakyReLU和Tril操作         leaky_relu_out = ops.leaky_relu(squared_diff)         tril_out = ops.tril(leaky_relu_out)          返回三个关键结果以便比较         return min_out, leaky_relu_out, tril_out class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          使用与T1Model相同的常量         self.condition = ms.Tensor(np.random.choice([True, False], size=(8, 34)))         self.scalar_val = ms.Tensor(np.array([0.5], dtype=np.float32))         self.vector_val = ms.Tensor(np.random.uniform(size=(34)).astype(np.float32))     def construct(self, x):          先Where操作         where_out = ops.where(self.condition, self.scalar_val, self.vector_val)          平方差计算         squared_diff = squared_difference(where_out, x)          先进行LeakyReLU和Tril操作         leaky_relu_out = ops.leaky_relu(squared_diff)         tril_out = ops.tril(leaky_relu_out)          后进行Min操作         min_out = ops.minimum(x, squared_diff)          返回三个关键结果以便比较         return min_out, leaky_relu_out, tril_out def reproduce_bug():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     np.random.seed(42)   确保可重复性     t1_model = T1Model()     t2_model = T2Model()      创建输入（使用可能触发问题的值）     x = ms.Tensor(np.array([[1.0]]).astype(np.float32))      运行模型     t1_min, t1_leaky, t1_tril = t1_model(x)     t2_min, t2_leaky, t2_tril = t2_model(x)      输出Min操作结果比较     print(""\n====== Min操作比较 ======"")     t1_min_np = t1_min.asnumpy()     t2_min_np = t2_min.asnumpy()     min_diff = np.abs(t1_min_np  t2_min_np)     min_max_diff = np.max(min_diff)     print(f""Min操作最大差异: {min_max_diff}"")     if min_max_diff > 0.001:         min_mismatched = np.abs(t1_min_np  t2_min_np) > 0.001         min_mismatched_count = np.sum(min_mismatched)         min_total_elements = t1_min_np.size         min_mismatch_percentage = 100.0 * min_mismatched_count / min_total_elements         print(f""Min操作不匹配元素: {min_mismatched_count} / {min_total_elements} ({min_mismatch_percentage:.2f}%)"")          找到最大差异的位置并显示         flat_idx = np.argmax(min_diff)         idx = np.unravel_index(flat_idx, min_diff.shape)         print(             f""Min操作最大差异位置{idx}: T1={t1_min_np[idx]}, T2={t2_min_np[idx]}, 差异={min_diff[idx]}""         )     else:         print(""Min操作输出一致"")      输出LeakyReLU操作结果比较     print(""\n====== LeakyReLU操作比较 ======"")     t1_leaky_np = t1_leaky.asnumpy()     t2_leaky_np = t2_leaky.asnumpy()     leaky_diff = np.abs(t1_leaky_np  t2_leaky_np)     leaky_max_diff = np.max(leaky_diff)     print(f""LeakyReLU操作最大差异: {leaky_max_diff}"")     if leaky_max_diff > 0.001:         leaky_mismatched = np.abs(t1_leaky_np  t2_leaky_np) > 0.001         leaky_mismatched_count = np.sum(leaky_mismatched)         leaky_total_elements = t1_leaky_np.size         leaky_mismatch_percentage = 100.0 * leaky_mismatched_count / leaky_total_elements         print(f""LeakyReLU操作不匹配元素: {leaky_mismatched_count} / {leaky_total_elements} ({leaky_mismatch_percentage:.2f}%)"")          找到最大差异的位置并显示         flat_idx = np.argmax(leaky_diff)         idx = np.unravel_index(flat_idx, leaky_diff.shape)         print(             f""LeakyReLU操作最大差异位置{idx}: T1={t1_leaky_np[idx]}, T2={t2_leaky_np[idx]}, 差异={leaky_diff[idx]}""         )     else:         print(""LeakyReLU操作输出一致"")      输出Tril操作结果比较     print(""\n====== Tril操作比较 ======"")     t1_tril_np = t1_tril.asnumpy()     t2_tril_np = t2_tril.asnumpy()     tril_diff = np.abs(t1_tril_np  t2_tril_np)     tril_max_diff = np.max(tril_diff)     print(f""Tril操作最大差异: {tril_max_diff}"")     if tril_max_diff > 0.001:         tril_mismatched = np.abs(t1_tril_np  t2_tril_np) > 0.001         tril_mismatched_count = np.sum(tril_mismatched)         tril_total_elements = t1_tril_np.size         tril_mismatch_percentage = 100.0 * tril_mismatched_count / tril_total_elements         print(f""Tril操作不匹配元素: {tril_mismatched_count} / {tril_total_elements} ({tril_mismatch_percentage:.2f}%)"")          找到最大差异的位置并显示         flat_idx = np.argmax(tril_diff)         idx = np.unravel_index(flat_idx, tril_diff.shape)         print(             f""Tril操作最大差异位置{idx}: T1={t1_tril_np[idx]}, T2={t2_tril_np[idx]}, 差异={tril_diff[idx]}""         )     else:         print(""Tril操作输出一致"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（float32张量理论上无数值异常）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:36:33+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G32,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
pynative mode,tinymonster123,[GPU]int8→int16类型下等价模型整型张量输出不一致（Where/Max/Cast链路）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个完全相同的int8→int16类型模型产生了不一致的输出结果。具体表现为：  在执行相同的 Where → Max → Cast 算子链路时，部分区域的值完全不一致  在总计27,664个元素中，有349个不匹配（1.26%）  最大绝对差异高达125（例如位置(0, 0, 27, 0)处：T1=0, T2=108）  特别是T1模型在部分区域输出全为0，而T2模型在相同位置有正负不同的值（如79和108） 这一现象在运算中理论上完全不应该发生。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 我创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果： T1Model执行顺序: Where → Max → Cast(to int16) T2Model执行顺序: Where → Max → Cast(to int16) 这两个模型逻辑完全等价，使用相同的int8输入和条件，但在GPU上运行时出现了明显的输出不一致：  在总计27,664个元素中，有349个不匹配（1.26%）  最大绝对差异达到125  具体不匹配元素示例：    位置(0, 0, 27, 0): T1=0, T2=108, 差异=108    位置(0, 0, 26, 18): T1=0, T2=79, 差异=79    位置(0, 0, 27, 2): T1=0, T2=79, 差异=79    位置(0, 0, 27, 3): T1=0, T2=79, 差异=79 特别是，T1模型输出在特定区域全为0，而T2模型在相同区域出现了正负不同的int16值，这在整型运算中应该是完全不可能的现象。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          初始化常量         self.const_false = ms.Tensor(np.array(0, dtype=np.int8))         self.const_true = ms.Tensor(np.array(127, dtype=np.int8))   int8最大值     def construct(self, x, condition):          核心算子链路：Where → Max → Cast         where_out = ops.where(condition, self.const_true, self.const_false)   i8[1,52,19]         max_out = ops.maximum(x, where_out)                                  i8[1,28,52,19]          cast_out = ops.cast(max_out, ms.int16)                               i16[1,28,52,19]         return cast_out class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          初始化常量         self.const_false = ms.Tensor(np.array(0, dtype=np.int8))         self.const_true = ms.Tensor(np.array(127, dtype=np.int8))   int8最大值     def construct(self, x, condition):          相同的核心算子链路：Where → Max → Cast         where_out = ops.where(condition, self.const_true, self.const_false)   i8[1,52,19]         max_out = ops.maximum(x, where_out)                                  i8[1,28,52,19]         cast_out = ops.cast(max_out, ms.int16)                               i16[1,28,52,19]         return cast_out def reproduce_bug():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1_model = T1Model()     t2_model = T2Model()      创建输入，确保可以触发问题      创建 unsqueeze 用的张量     x = ms.Tensor(np.random.randint(128, 127, (1, 28, 1)).astype(np.int8))     x_unsqueeze = ops.unsqueeze(x, 3)   变为[1,28,1,1]      创建用于 where 的条件     condition = ms.Tensor(np.random.choice([True, False], size=(1, 52, 19)))      运行模型     t1_output = t1_model(x_unsqueeze, condition)     t2_output = t2_model(x_unsqueeze, condition)      打印输出形状     print(""\n输出形状:"")     print(""T1输出:"", t1_output.shape)     print(""T2输出:"", t2_output.shape)      打印部分输出值     print(""\nT1模型输出(部分):"")     print(t1_output.asnumpy()[0, 0, :5, :5])     print(""\nT2模型输出(部分):"")     print(t2_output.asnumpy()[0, 0, :5, :5])      分析不一致     t1_np = t1_output.asnumpy()     t2_np = t2_output.asnumpy()     if np.array_equal(t1_np, t2_np):         print(""\n输出完全一致"")     else:         mismatched = (t1_np != t2_np)         mismatched_count = np.sum(mismatched)         total_elements = t1_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(f""\n不匹配元素数量: {mismatched_count} / {total_elements} ({mismatch_percentage:.2f}%)"")          计算差异         diff = np.abs(t1_np  t2_np)         max_diff = np.max(diff)         print(f""最大绝对差异: {max_diff}"")          显示几个不匹配元素         indices = np.where(mismatched)         print(""\n部分不匹配元素:"")         for i in range(min(5, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={t1_np[idx]}, T2={t2_np[idx]}, 差异={abs(int(t1_np[idx])int(t2_np[idx]))}"") if __name__ == ""__main__"":     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:31:23+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G2R,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
pynative mode,tinymonster123,[GPU]int16类型下等价模型整型张量输出不一致（Min/Add操作）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（均为int16类型）推理结果出现不一致。具体表现为：部分元素输出不同，最大差异高达89，50%的元素不匹配。该问题在Min和Add操作的整型张量上出现，理论上应完全一致。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个等价模型 T1Model 和 T2Model      * T1Model 执行流程：        1) ops.where(bool_input, constant1, constant2)        2) ops.split(where_result, 2, axis=0)        3) ops.minimum(split[0], split[1])        4) ops.add(constant2, split[0])        5) ops.gt(constant1, where_result)      * T2Model 执行流程（算子顺序相同、图中连线顺序略有差异）：        1) ops.where(bool_input, constant1, constant2)        2) ops.split(where_result, 2, axis=0)        3) ops.minimum(split[0], split[1])        4) ops.add(constant2, split[0])        5) ops.gt(constant1, where_result)   2. 生成随机的 bool 输入数据和 int16 常量      ```python    import numpy as np    import mindspore as ms     以下是一种特别容易触发问题的输入模式    bool_array = np.zeros(22, dtype=bool)    bool_array[::2] = True   偶数位置为True    bool_input = ms.Tensor(bool_array)     常量初始化    scalar_val = np.random.randint(100, 100)    array_val = np.random.randint(100, 100, 1)    const1 = ms.Tensor(np.array([array_val], dtype=np.int16))   i16[1]    const2 = ms.Tensor(np.array(scalar_val, dtype=np.int16))    i16[]    ``` 3. 在 MindSpore GPU + PyNative 模式下运行推理      ```python    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")     初始化并共享常量    t1 = T1Model()    t2 = T2Model()    t1.v5_0 = const2; t1.v4_0 = const1    t2.v0_0 = const2; t2.v1_0 = const1     运行两模型    t1_min, t1_add = t1(bool_input)    t2_min, t2_add = t2(bool_input)    ``` 4. 对比两模型输出，统计差异      ```python    import numpy as np     比较Minimum操作结果    t1_min_np = t1_min.asnumpy()    t2_min_np = t2_min.asnumpy()    diff_min = np.abs(t1_min_np  t2_min_np)    total_min = t1_min_np.size    mismatches_min = np.count_nonzero(t1_min_np != t2_min_np)    max_diff_min = np.max(diff_min) if diff_min.size > 0 else 0     比较Add操作结果    t1_add_np = t1_add.asnumpy()    t2_add_np = t2_add.asnumpy()    diff_add = np.abs(t1_add_np  t2_add_np)    total_add = t1_add_np.size    mismatches_add = np.count_nonzero(t1_add_np != t2_add_np)    max_diff_add = np.max(diff_add) if diff_add.size > 0 else 0    print(f""Minimum操作不匹配元素: {mismatches_min} / {total_min} ({100*mismatches_min/total_min:.2f}%)"")    print(f""Minimum操作最大绝对差异: {max_diff_min}"")    print(f""Add操作不匹配元素: {mismatches_add} / {total_add} ({100*mismatches_add/total_add:.2f}%)"")    print(f""Add操作最大绝对差异: {max_diff_add}"")     示例输出：     Minimum操作不匹配元素: 1 / 2 (50.00%)     Minimum操作最大绝对差异: 89     Add操作不匹配元素: 1 / 2 (50.00%)     Add操作最大绝对差异: 89          具体元素差异：     位置(1,): Minimum操作 T1=89, T2=0, 差异=89     位置(1,): Add操作 T1=78, T2=11, 差异=89    ``` ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          常量初始化         self.v5_0 = ms.Tensor(np.array(5, dtype=np.int16))   i16[]         self.v4_0 = ms.Tensor(np.array([10], dtype=np.int16))   i16[1]     def construct(self, v3_0):          v3_0是布尔数组 b[22]          Where操作         v6_0 = ops.where(v3_0, self.v4_0, self.v5_0)   i16[22]          Greater操作         v7_0 = ops.gt(self.v4_0, v6_0)   b[22]          Split2操作         splits = ops.split(v6_0, 2, axis=0)   分成2等份         v1_0 = splits[0]   i16[11]         v1_1 = splits[1]   i16[11]          Add操作         v0_0 = ops.add(self.v5_0, v1_0)   i16[]          Min操作         v2_0 = ops.minimum(v1_0, v1_1)   i16[]          返回两个关键结果以便比较         return v2_0, v0_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          常量初始化         self.v0_0 = ms.Tensor(np.array(5, dtype=np.int16))   i16[]         self.v1_0 = ms.Tensor(np.array([10], dtype=np.int16))   i16[1]     def construct(self, v2_0):          v2_0是布尔数组 b[22]          Where操作         v3_0 = ops.where(v2_0, self.v1_0, self.v0_0)   i16[22]          Split2操作         splits = ops.split(v3_0, 2, axis=0)   分成2等份         v4_0 = splits[0]   i16[11]         v4_1 = splits[1]   i16[11]          Min操作         v5_0 = ops.minimum(v4_0, v4_1)   i16[]          Add操作         v7_0 = ops.add(self.v0_0, v4_0)   i16[]          Greater操作         v9_0 = ops.gt(self.v1_0, v3_0)   b[22]          返回两个关键结果以便比较         return v5_0, v7_0 def reproduce_bug_93():      设置 MindSpore 上下文     ms.set_context(mode=ms.PYNATIVE_MODE)     try:         ms.set_device(""GPU"")   尝试使用GPU         print(""使用GPU执行测试"")     except:         print(""GPU不可用，使用CPU执行测试"")      创建两个模型     t1_model = T1Model()     t2_model = T2Model()      设置随机种子以便复现     np.random.seed(42)     max_diff_overall_min = 1   对minimum操作的结果差异     max_diff_overall_add = 1   对add操作的结果差异     best_t1_outputs = None     best_t2_outputs = None     last_t1_outputs = None     last_t2_outputs = None     best_input = None      测试不同的输入场景     print(""开始测试..."")     for i in range(20):         print(f""运行测试 {i+1}/20..."")          生成不同的布尔数组输入         if i % 5 == 0:   全真             v3_0 = ms.Tensor(np.ones(22, dtype=bool))         elif i % 5 == 1:   全假             v3_0 = ms.Tensor(np.zeros(22, dtype=bool))         elif i % 5 == 2:   随机             v3_0 = ms.Tensor(np.random.choice([True, False], size=22))         elif i % 5 == 3:   前半真后半假             bool_array = np.zeros(22, dtype=bool)             bool_array[:11] = True             v3_0 = ms.Tensor(bool_array)         else:   交替真假             bool_array = np.zeros(22, dtype=bool)             bool_array[::2] = True   偶数位置为True             v3_0 = ms.Tensor(bool_array)          每隔几次更新常量值         if i % 4 == 0:              更新模型中的常量             scalar_val = np.random.randint(100, 100)             array_val = np.random.randint(100, 100, 1)             t1_model.v5_0 = ms.Tensor(np.array(scalar_val, dtype=np.int16))             t1_model.v4_0 = ms.Tensor(np.array(array_val, dtype=np.int16))             t2_model.v0_0 = ms.Tensor(np.array(scalar_val, dtype=np.int16))             t2_model.v1_0 = ms.Tensor(np.array(array_val, dtype=np.int16))          运行模型         t1_min, t1_add = t1_model(v3_0)         t2_min, t2_add = t2_model(v3_0)          保存最后一轮的输出         last_t1_outputs = (t1_min, t1_add)         last_t2_outputs = (t2_min, t2_add)          计算minimum操作的差异         abs_diff_min = np.abs(t1_min.asnumpy()  t2_min.asnumpy())         current_max_diff_min = np.max(abs_diff_min) if abs_diff_min.size > 0 else 0          计算add操作的差异         abs_diff_add = np.abs(t1_add.asnumpy()  t2_add.asnumpy())         current_max_diff_add = np.max(abs_diff_add) if abs_diff_add.size > 0 else 0         print(f""   最大差异 (Min操作): {current_max_diff_min}"")         print(f""   最大差异 (Add操作): {current_max_diff_add}"")          记录最大差异         if current_max_diff_min > max_diff_overall_min:             max_diff_overall_min = current_max_diff_min             best_t1_outputs = (t1_min, t1_add)             best_t2_outputs = (t2_min, t2_add)             best_input = v3_0             print(f""   找到更大差异 (Min操作): {current_max_diff_min}"")         if current_max_diff_add > max_diff_overall_add:             max_diff_overall_add = current_max_diff_add             if best_t1_outputs is None:                 best_t1_outputs = (t1_min, t1_add)                 best_t2_outputs = (t2_min, t2_add)                 best_input = v3_0             print(f""   找到更大差异 (Add操作): {current_max_diff_add}"")      使用最佳或最后一轮输出     if best_t1_outputs is None:         print(""\n未发现显著差异，使用最后一轮测试结果"")         t1_min, t1_add = last_t1_outputs         t2_min, t2_add = last_t2_outputs     else:         print(f""\n发现最大差异:"")         print(f""   Min操作: {max_diff_overall_min}"")         print(f""   Add操作: {max_diff_overall_add}"")         t1_min, t1_add = best_t1_outputs         t2_min, t2_add = best_t2_outputs         print(f""最大差异的输入: {best_input}"")     print(""\n====== Minimum操作比较 ======"")     print(""\n输出形状:"")     print(""T1 Min操作输出:"", t1_min.shape)     print(""T2 Min操作输出:"", t2_min.shape)      输出统计信息     t1_min_np = t1_min.asnumpy()     t2_min_np = t2_min.asnumpy()     print(""\nT1模型 Minimum操作输出:"")     print(t1_min_np)     print(""\nT2模型 Minimum操作输出:"")     print(t2_min_np)     print(""\nT1模型 Minimum操作统计:"")     if t1_min_np.size > 0:         print(             f""最小值: {np.min(t1_min_np)}, 最大值: {np.max(t1_min_np)}, 平均值: {np.mean(t1_min_np)}""         )     print(""\nT2模型 Minimum操作统计:"")     if t2_min_np.size > 0:         print(             f""最小值: {np.min(t2_min_np)}, 最大值: {np.max(t2_min_np)}, 平均值: {np.mean(t2_min_np)}""         )     abs_diff_min = np.abs(t1_min_np  t2_min_np)      检查输出是否一致     if np.array_equal(t1_min_np, t2_min_np):         print(""\nMinimum操作输出完全一致"")     else:         mismatched = t1_min_np != t2_min_np         mismatched_count = np.sum(mismatched)         total_elements = t1_min_np.size         mismatch_percentage = (             100.0 * mismatched_count / total_elements if total_elements > 0 else 0         )         print(             ""\nMinimum操作不匹配元素数量: {} / {} ({:.2f}%)"".format(                 mismatched_count, total_elements, mismatch_percentage             )         )         if total_elements > 0:             print(f""\nMinimum操作差异最大值: {np.max(abs_diff_min)}"")              显示差异最大的前5个元素             flat_diff_min = abs_diff_min.flatten()             max_indices_min = np.argsort(flat_diff_min)[5:][::1]             print(""\n差异最大的元素(Minimum操作):"")             for idx in max_indices_min:                 multi_idx = np.unravel_index(idx, t1_min.shape)                 t1_val = t1_min_np[multi_idx]                 t2_val = t2_min_np[multi_idx]                 diff = flat_diff_min[idx]                 print(f""位置{multi_idx}: T1={t1_val}, T2={t2_val}, 差异={diff}"")     print(""\n====== Add操作比较 ======"")     print(""\n输出形状:"")     print(""T1 Add操作输出:"", t1_add.shape)     print(""T2 Add操作输出:"", t2_add.shape)      输出统计信息     t1_add_np = t1_add.asnumpy()     t2_add_np = t2_add.asnumpy()     print(""\nT1模型 Add操作输出:"")     print(t1_add_np)     print(""\nT2模型 Add操作输出:"")     print(t2_add_np)     print(""\nT1模型 Add操作统计:"")     if t1_add_np.size > 0:         print(             f""最小值: {np.min(t1_add_np)}, 最大值: {np.max(t1_add_np)}, 平均值: {np.mean(t1_add_np)}""         )     print(""\nT2模型 Add操作统计:"")     if t2_add_np.size > 0:         print(             f""最小值: {np.min(t2_add_np)}, 最大值: {np.max(t2_add_np)}, 平均值: {np.mean(t2_add_np)}""         )     abs_diff_add = np.abs(t1_add_np  t2_add_np)      检查输出是否一致     if np.array_equal(t1_add_np, t2_add_np):         print(""\nAdd操作输出完全一致"")     else:         mismatched = t1_add_np != t2_add_np         mismatched_count = np.sum(mismatched)         total_elements = t1_add_np.size         mismatch_percentage = (             100.0 * mismatched_count / total_elements if total_elements > 0 else 0         )         print(             ""\nAdd操作不匹配元素数量: {} / {} ({:.2f}%)"".format(                 mismatched_count, total_elements, mismatch_percentage             )         )         if total_elements > 0:             print(f""\nAdd操作差异最大值: {np.max(abs_diff_add)}"")              显示差异最大的前5个元素             flat_diff_add = abs_diff_add.flatten()             max_indices_add = np.argsort(flat_diff_add)[5:][::1]             print(""\n差异最大的元素(Add操作):"")             for idx in max_indices_add:                 multi_idx = np.unravel_index(idx, t1_add.shape)                 t1_val = t1_add_np[multi_idx]                 t2_val = t2_add_np[multi_idx]                 diff = flat_diff_add[idx]                 print(f""位置{multi_idx}: T1={t1_val}, T2={t2_val}, 差异={diff}"") if __name__ == ""__main__"":     reproduce_bug_93() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（整型张量理论上无数值误差）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 关键日志： ``` 使用GPU执行测试 开始测试... 运行测试 1/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0    找到更大差异 (Min操作): 0    找到更大差异 (Add操作): 0 运行测试 2/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 3/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 4/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 5/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 6/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 7/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 8/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 9/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 10/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 11/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 12/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 13/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 14/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 15/20...    最大差异 (Min操作): 89    最大差异 (Add操作): 89    找到更大差异 (Min操作): 89    找到更大差异 (Add操作): 89 运行测试 16/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 17/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 18/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 19/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 运行测试 20/20...    最大差异 (Min操作): 0    最大差异 (Add操作): 0 发现最大差异:    Min操作: 89    Add操作: 89 最大差异的输入: [ True False  True False  True False  True False  True False  True False   True False  True False  True False  True False  True False] ====== Minimum操作比较 ====== 输出形状: T1 Min操作输出: (2,) T2 Min操作输出: (2,) T1模型 Minimum操作输出: [48  89] T2模型 Minimum操作输出: [48   0] T1模型 Minimum操作统计: 最小值: 48, 最大值: 89, 平均值: 20.5 T2模型 Minimum操作统计: 最小值: 48, 最大值: 0, 平均值: 24.0 Minimum操作不匹配元素数量: 1 / 2 (50.00%) Minimum操作差异最大值: 89 差异最大的元素(Minimum操作): 位置(1,): T1=89, T2=0, 差异=89 位置(0,): T1=48, T2=48, 差异=0 ====== Add操作比较 ====== 输出形状: T1 Add操作输出: (2,) T2 Add操作输出: (2,) T1模型 Add操作输出: [59  78] T2模型 Add操作输出: [59 11] T1模型 Add操作统计: 最小值: 59, 最大值: 78, 平均值: 9.5 T2模型 Add操作统计: 最小值: 59, 最大值: 11, 平均值: 35.0 Add操作不匹配元素数量: 1 / 2 (50.00%) Add操作差异最大值: 89 差异最大的元素(Add操作): 位置(1,): T1=78, T2=11, 差异=89 位置(0,): T1=59, T2=59, 差异=0 ```",2025-04-19T20:26:07+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IC2G2I
pynative mode,tinymonster123,[GPU]等价模型在float32下输出极端不一致（出现巨大数值异常）," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上等价的模型（均为float32类型）推理结果出现极端不一致。具体表现为：绝大多数元素输出不同，最大差异高达8.3e+34，99.94%的元素不匹配，部分输出甚至出现极大异常值（如8.3e+34）。该问题在张量全为float32数据时出现，理论上应完全一致。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 定义两个等价模型 T1Model 和 T2Model      * T1Model 执行流程：        1) ops.reshape(常量, (40, 45))        2) ops.where(input_bool, reshaped, 常量)        3) ops.floor(where_result)        4) ops.add(floor_result, where_result)      * T2Model 执行流程（核心算子等价、辅助操作不同）：        1) ops.reshape(常量, (40, 45))        2) ops.where(input_bool, reshaped, 常量)        3) ops.floor(where_result)        4) ops.add(where_result, floor_result)        5) 其他辅助操作（concat, transpose等）   2. 生成随机的 float32 输入数据和常量      ```python    import numpy as np    import mindspore as ms     两个常量    const1 = ms.Tensor(np.random.uniform(1, 1, (1800)).astype(np.float32))    const2 = ms.Tensor(np.array([[[0.5]]], dtype=np.float32))     布尔输入    input_bool = ms.Tensor(np.random.choice([True, False]))    ``` 3. 在 MindSpore GPU + PyNative 模式下运行推理      ```python    ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""GPU"")     初始化并共享常量    t1 = T1Model()    t2 = T2Model()    t1.v0_0 = const1; t1.v5_0 = const2    t2.v1_0 = const1; t2.v0_0 = const2     运行两模型    out1 = t1(input_bool)    out2 = t2(input_bool)    ``` 4. 对比两模型输出，统计差异      ```python    import numpy as np    y1 = out1.asnumpy()    y2 = out2.asnumpy()    diff = np.abs(y1  y2)    total = diff.size    mismatched = ~np.isclose(y1, y2, rtol=1e5, atol=1e5)    mismatched_count = np.sum(mismatched)    max_diff = np.max(diff)    print(f""不匹配元素: {mismatched_count} / {total} ({100*mismatched_count/total:.2f}%)"")    print(f""最大绝对差异: {max_diff}"")     示例输出：     不匹配元素: 1799 / 1800 (99.94%)     最大绝对差异: 8.307675964007756e+34     位置(0, 34, 6): T1=19.06, T2=8.31e+34, 差异=8.31e+34    ``` ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()          常量初始化         self.v0_0 = ms.Tensor(np.random.uniform(1, 1, (1800)).astype(np.float32))         self.v5_0 = ms.Tensor(np.array([[[0.5]]], dtype=np.float32))     def construct(self, v3_0):          v3_0是布尔标量          Reshape操作         v7_0 = ops.reshape(self.v0_0, (40, 45))          Where操作         v6_0 = ops.where(v3_0, v7_0, self.v5_0)          Add操作         v4_0 = ops.add(v6_0, self.v5_0)          Floor操作         v1_0 = ops.floor(v6_0)          Add操作         v2_0 = ops.add(v1_0, v6_0)         return v2_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()          常量初始化         self.v0_0 = ms.Tensor(np.array([[[0.5]]], dtype=np.float32))         self.v1_0 = ms.Tensor(np.random.uniform(1, 1, (1800)).astype(np.float32))     def construct(self, v3_0):          v3_0是布尔标量          Reshape操作         v2_0 = ops.reshape(self.v1_0, (40, 45))          Where操作         v4_0 = ops.where(v3_0, v2_0, self.v0_0)          Floor操作         v5_0 = ops.floor(v4_0)          Add操作         v6_0 = ops.add(v4_0, v5_0)          其余操作（Concat、Transpose等）         v7_0 = ops.concat((v6_0, v6_0), axis=0)         v8_0 = ops.add(self.v0_0, v4_0)         v9_0 = ops.transpose(v6_0, (1, 0, 2))         v10_0 = ops.transpose(v4_0, (1, 0, 2))          这些操作不影响主要输出，但为了完整性添加         v20_0 = ops.add(             ops.transpose(ops.transpose(v5_0, (1, 0, 2)), (1, 0, 2)),             ops.transpose(ops.transpose(v4_0, (1, 0, 2)), (1, 0, 2)),         )         return v6_0   返回主要结果 def reproduce_bug_89():      设置 MindSpore 上下文     ms.set_context(mode=ms.PYNATIVE_MODE)     try:         ms.set_device(""GPU"")   尝试使用GPU         print(""使用GPU执行测试"")     except:         print(""GPU不可用，使用CPU执行测试"")      创建两个模型     t1_model = T1Model()     t2_model = T2Model()      设置随机种子以便复现     np.random.seed(42)     max_diff_overall = 1     best_t1_output = None     best_t2_output = None     last_t1_output = None     last_t2_output = None     last_diff = None     best_input = None      测试不同的输入场景     print(""开始测试..."")     for i in range(20):         print(f""运行测试 {i+1}/20..."")          每次使用不同的布尔输入和随机常量         if i % 4 == 0:             v3_0 = ms.Tensor(True)         elif i % 4 == 1:             v3_0 = ms.Tensor(False)         elif i % 4 == 2:             v3_0 = ms.Tensor(np.random.choice([True, False]))         else:   重新初始化不同的常量值             v3_0 = ms.Tensor(np.random.choice([True, False]))              更新模型中的常量             t1_model.v0_0 = ms.Tensor(                 np.random.uniform(10, 10, (1800)).astype(np.float32)             )             t1_model.v5_0 = ms.Tensor(                 np.array([[[np.random.uniform(1, 1)]]], dtype=np.float32)             )             t2_model.v0_0 = t1_model.v5_0             t2_model.v1_0 = t1_model.v0_0          运行模型         t1_output = t1_model(v3_0)         t2_output = t2_model(v3_0)          保存最后一轮的输出         last_t1_output = t1_output         last_t2_output = t2_output          计算差异         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         current_max_diff = np.max(abs_diff)         last_diff = abs_diff         print(f""   最大差异: {current_max_diff}"")         if current_max_diff > max_diff_overall:             max_diff_overall = current_max_diff             best_t1_output = t1_output             best_t2_output = t2_output             best_input = v3_0             print(f""   找到更大差异: {current_max_diff}"")      使用最佳或最后一轮输出     if best_t1_output is None:         print(""\n未发现显著差异，使用最后一轮测试结果"")         t1_output = last_t1_output         t2_output = last_t2_output         abs_diff = last_diff     else:         print(f""\n发现最大差异: {max_diff_overall}"")         t1_output = best_t1_output         t2_output = best_t2_output         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         print(f""最大差异的输入: {best_input}"")     print(""\n输出形状:"")     print(""T1 output:"", t1_output.shape)     print(""T2 output:"", t2_output.shape)      输出统计信息     t1_output_np = t1_output.asnumpy()     t2_output_np = t2_output.asnumpy()     print(""\nT1模型全部输出:"")     print(t1_output_np)     print(""\nT2模型全部输出:"")     print(t2_output_np)     print(""\nT1模型输出统计:"")     print(         f""最小值: {np.min(t1_output_np)}, 最大值: {np.max(t1_output_np)}, 平均值: {np.mean(t1_output_np)}""     )     print(""\nT2模型输出统计:"")     print(         f""最小值: {np.min(t2_output_np)}, 最大值: {np.max(t2_output_np)}, 平均值: {np.mean(t2_output_np)}""     )      检查NaN和Inf值     t1_nan_count = np.isnan(t1_output_np).sum()     t2_nan_count = np.isnan(t2_output_np).sum()     t1_inf_count = np.isinf(t1_output_np).sum()     t2_inf_count = np.isinf(t2_output_np).sum()     print(f""\nNaN值统计: T1={t1_nan_count}, T2={t2_nan_count}"")     print(f""Inf值统计: T1={t1_inf_count}, T2={t2_inf_count}"")      检查输出是否一致     if np.allclose(t1_output_np, t2_output_np, rtol=1e5, atol=1e5):         print(""\n输出完全一致（在容差范围内）"")     else:         mismatched = ~np.isclose(t1_output_np, t2_output_np, rtol=1e5, atol=1e5)         mismatched_count = np.sum(mismatched)         total_elements = t1_output_np.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(             ""\n不匹配元素数量: {} / {} ({:.2f}%)"".format(                 mismatched_count, total_elements, mismatch_percentage             )         )          显示差异最大的前5个元素         flat_diff = abs_diff.flatten()         max_indices = np.argsort(flat_diff)[5:][::1]         print(""\n差异最大的元素:"")         for idx in max_indices:             multi_idx = np.unravel_index(idx, t1_output.shape)             t1_val = t1_output_np[multi_idx]             t2_val = t2_output_np[multi_idx]             diff = flat_diff[idx]             print(f""位置{multi_idx}: T1={t1_val}, T2={t2_val}, 差异={diff}"") if __name__ == ""__main__"":     reproduce_bug_89() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致（float32张量理论上无数值异常）。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 关键日志： ``` 使用GPU执行测试 开始测试... 运行测试 1/20...    最大差异: 1.887099027633667    找到更大差异: 1.887099027633667 运行测试 2/20...    最大差异: 0.0 运行测试 3/20...    最大差异: 1.887099027633667 运行测试 4/20...    最大差异: 0.0 运行测试 5/20...    最大差异: 0.0 运行测试 6/20...    最大差异: 0.9988986253738403 运行测试 7/20...    最大差异: 0.0 运行测试 8/20...    最大差异: 0.9992785453796387 运行测试 9/20...    最大差异: 0.0 运行测试 10/20...    最大差异: 0.0 运行测试 11/20...    最大差异: 0.0 运行测试 12/20...    最大差异: 0.0 运行测试 13/20...    最大差异: 2.076918991001939e+34    找到更大差异: 2.076918991001939e+34 运行测试 14/20...    最大差异: 1.401298464324817e45 运行测试 15/20...    最大差异: 0.0 运行测试 16/20...    最大差异: 0.0 运行测试 17/20...    最大差异: 0.0 运行测试 18/20...    最大差异: 0.0 运行测试 19/20...    最大差异: 0.0 运行测试 20/20...    最大差异: 8.307675964007756e+34    找到更大差异: 8.307675964007756e+34 发现最大差异: 8.307675964007756e+34 最大差异的输入: False 输出形状: T1 output: (1, 40, 45) T2 output: (1, 40, 45) T1模型全部输出: [[[  0.15907274  7.580059     0.52188027 ... 15.48713     9.2054405    11.224964  ]   [11.729143    3.7771134    8.080629   ...  1.5113018   7.324468      2.586268  ]   [ 14.780012     2.3860998    4.634448   ...  1.6547801  15.865764      4.9911203 ]   ...   [  4.4634485  17.511433     0.07383522 ...   0.34235862  16.161674     12.087488  ]   [17.683403     6.8514557    2.4379506  ...   2.619372     8.597782     3.781342  ]   [  4.584384     6.9862585    8.222437   ...  16.679749   13.328407     9.944683  ]]] T2模型全部输出: [[[ 1.5907274e01 8.0000000e+01 8.0000000e+01 ... 1.6000000e+01    6.4000000e+01 8.0000000e+01]   [ 4.0000000e+01  1.6000000e+01  3.2000000e+01 ... 5.6000000e+01    4.0000000e+01 5.6000000e+01]   [7.2000000e+01 6.4000000e+01 8.0000000e+00 ...  5.6000000e+01     8.0000000e+00  2.4000000e+01]   ...   [ 0.0000000e+00 4.1698099e+34  0.0000000e+00 ...  0.0000000e+00     0.0000000e+00  0.0000000e+00]   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00     0.0000000e+00  0.0000000e+00]   [ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  4.0000000e+00    3.2000000e+01 1.2000000e+01]]] T1模型输出统计: 最小值: 19.995180130004883, 最大值: 18.989213943481445, 平均值: 0.6718649864196777 T2模型输出统计: 最小值: 8.307675964007756e+34, 最大值: 72.0, 平均值: 1.3863872322400244e+32 NaN值统计: T1=0, T2=0 Inf值统计: T1=0, T2=0 不匹配元素数量: 1799 / 1800 (99.94%) 差异最大的元素: 位置(0, 34, 6): T1=19.060710906982422, T2=8.307675964007756e+34, 差异=8.307675964007756e+34 位置(0, 34, 8): T1=10.265897750854492, T2=8.307674973655724e+34, 差异=8.307674973655724e+34 位置(0, 36, 44): T1=3.3512566089630127, T2=4.169809884390738e+34, 差异=4.169809884390738e+34 位置(0, 37, 1): T1=17.511432647705078, T2=4.169809884390738e+34, 差异=4.169809884390738e+34 位置(0, 9, 18): T1=18.924489974975586, T2=80.0, 差异=98.92449188232422 ```",2025-04-19T20:24:05+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IC2G2F
pynative mode,tinymonster123,[GPU]int16类型下等价模型整型张量输出不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，两个数学上完全等价的int16类型模型在执行完全相同的算子链路（``argmax → maximum → equal → less → where``）时，输出结果出现严重不一致。具体表现为：  输入和常量均包含int16边界值（32768, 32767）  两模型输出形状一致，但有68.08%的元素不匹配  最大绝对差异高达32767  例如，位置(0, 0, 0, 43, 0) T1输出为0，T2输出为32767；位置(0, 0, 0, 43, 1) T1输出为100，T2输出为32768 理论上两个模型输出应完全一致，但实际有大量整型数值差异，且差异值覆盖int16全范围。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建两个模型 T1Model 和 T2Model，均执行算子序列：argmax → maximum → equal → less → where。 2. 输入张量和常量均为 int16，且包含边界值（32768, 32767）。 3. 观察到两个模型的输出结果存在严重差异： ``` 输出形状: (1, 48, 1, 61, 6) T1输出(部分): [[32768      0  32767]  [32768      0  32767]  [32768      0  32767]] T2输出(部分): [[32768      0  32767]  [32768      0  32767]  [32768      0  32767]] 不匹配元素: 11960/17568 (68.08%) 最大绝对差异: 32767 部分不匹配元素: 位置(0, 0, 0, 42, 5): T1=100, T2=0, 差异=100 位置(0, 0, 0, 43, 0): T1=0, T2=32767, 差异=32767 位置(0, 0, 0, 43, 1): T1=100, T2=32768, 差异=32868 位置(0, 0, 0, 43, 2): T1=32767, T2=0, 差异=32767 位置(0, 0, 0, 43, 3): T1=1000, T2=32767, 差异=31767 ``` 4. 预期结果是两个模型的输出应完全一致。 ```python import numpy as np import mindspore as ms import mindspore.ops as ops import mindspore.nn as nn class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.constant = None   共享常量     def construct(self, x):          严格按照t1/model/graph.dot顺序执行          v3_0 > input x: i16[1, 48, 1, 1, 6]          v4_0 > constant: i16[1, 61, 1]         _ = ops.argmax(x, dim=1)                     ArgMax 操作: v3_0 > v6_0         maxed = ops.maximum(x, self.constant)        Max 操作: (v3_0, v4_0) > v5_0 [1, 48, 1, 61, 6]         _ = ops.equal(maxed, maxed)                  Equal 操作: (v5_0, v5_0) > v2_0         less = ops.less(maxed, maxed)                Less 操作: (v5_0, v5_0) > v1_0         out = ops.where(less, self.constant, self.constant)   Where操作: (v1_0, v4_0, v4_0) > v0_0         return out class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.constant = None   共享常量     def construct(self, x):          严格按照t2/model/graph.dot顺序执行          v0_0 > input x: i16[1, 48, 1, 1, 6]          v3_0 > constant: i16[1, 61, 1]         _ = ops.argmax(x, dim=1)                     ArgMax 操作: v0_0 > v1_0         maxed = ops.maximum(x, self.constant)        Max 操作: (v0_0, v3_0) > v4_0 [1, 48, 1, 61, 6]         _ = ops.equal(maxed, maxed)                  Equal 操作: (v4_0, v4_0) > v5_0         less = ops.less(maxed, maxed)                Less 操作: (v4_0, v4_0) > v7_0         out = ops.where(less, self.constant, self.constant)   Where操作: (v7_0, v3_0, v3_0) > v8_0         return out def main():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")      创建模型     t1 = T1Model()     t2 = T2Model()      严格按照graph.dot设置常量      i16[1, 61, 1]     const = ms.Tensor(np.array([32768, 0, 32767] * 20 + [0]).reshape(1, 61, 1).astype(np.int16))     t1.constant = const     t2.constant = const      严格按照graph.dot创建输入      i16[1, 48, 1, 1, 6]     input_data = []     for i in range(48):          创建有边界值的输入以更好地测试问题         input_data.extend([32768, 100, 0, 100, 32767, 1000])     x = ms.Tensor(np.array(input_data).reshape(1, 48, 1, 1, 6).astype(np.int16))      运行模型     y1 = t1(x)     y2 = t2(x)      结果分析     y1_np = y1.asnumpy()     y2_np = y2.asnumpy()      打印输出形状     print(""\n输出形状:"")     print(""T1输出:"", y1.shape)     print(""T2输出:"", y2.shape)      打印部分结果（第一层切片）     print(""\nT1模型输出(部分):"")     print(y1_np[0, 0, 0, :3, :3])     print(""\nT2模型输出(部分):"")     print(y2_np[0, 0, 0, :3, :3])      分析不一致     mismatched = (y1_np != y2_np)     mismatched_count = np.sum(mismatched)     total = y1_np.size     if mismatched_count > 0:         print(f""\n不匹配元素: {mismatched_count}/{total} ({100*mismatched_count/total:.2f}%)"")          计算差异         diff = np.abs(y1_np  y2_np)         max_diff = np.max(diff)         print(f""最大绝对差异: {max_diff}"")          输出前5个有差异的元素         indices = np.where(mismatched)         print(""\n部分不匹配元素:"")         for i in range(min(5, len(indices[0]))):             idx = tuple(ind[i] for ind in indices)             print(f""位置{idx}: T1={y1_np[idx]}, T2={y2_np[idx]}, 差异={abs(int(y1_np[idx])int(y2_np[idx]))}"")     else:         print(""\n输出完全一致"") if __name__ == ""__main__"":     main() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应完全一致。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明",2025-04-19T20:21:49+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC2G2B,该问题中用到了mindspore.ops.where，根本原因应该是where的问题，进一步说可能是where中进行广播时数据出了差错，情况应该与此issue中的问题一致： https://gitee.com/mindspore/mindspore/issues/IC2G5M?from=projectissue 可参考我在该issue中的说明
ascend,XuefengJin,"device_target (str)  要运行的目标设备，仅支持 ""Ascend"" 、 ""GPU"" 和 ""CPU""。","https://www.mindspore.cn/docs/zhCN/master/api_python/mindspore/mindspore.set_device.htmlmindspore.set_device device_target (str)  要运行的目标设备，仅支持 ""Ascend"" 、 ""GPU"" 和 ""CPU""。 如果是第三方设备，怎么办，挂靠到ascend/gpu/cpu下面",2025-04-19T11:22:07+08:00,,progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IC2DGN,第三方设备感觉新增device_target更好一点，然后通过device_context实现硬件相关接口，包括第三方设备的算子kernelmod和实现，通过指定device_target选择指定的三方设备和算子
memory leak,majun-bot,CVE20241394,"一、漏洞信息 漏洞编号：CVE20241394 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： A memory leak flaw was found in Golang in the RSA encrypting/decrypting code, which might lead to a resource exhaustion vulnerability using attackercontrolled inputs​. The memory leak happens in github.com/golangfips/openssl/openssl/rsa.goL113. The objects leaked are pkey​ and ctx​. That function uses named return parameters to free pkey​ and ctx​ if there is an error initializing the context or setting the different properties. All return statements related to error cases follow the ""return nil, nil, fail(...)"" pattern, meaning that pkey​ and ctx​ will be nil inside the deferred function that should free them. 漏洞公开时间：20240321 21:00:08 漏洞创建时间：20250418 10:55:20 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20241394 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 在RSA加密/解密代码中的Golang中发现了一个内存泄漏漏洞，这可能会导致使用攻击者控制的输入的资源耗尽漏洞。内存泄漏发生在github.com/Golangfips/openssl/openssl/RSA.goL113中。泄漏的对象是pkey和ctx。如果初始化上下文或设置不同属性时出错，该函数将使用命名返回参数释放pkey和ctx。所有与错误情况相关的return语句都遵循“returnnil，nil，fail（…）”模式，这意味着pkey和ctx在应该释放它们的deferred函数内将为nil。 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响",2025-04-18T10:55:21+08:00,"gitee,github,CVE/UNAFFECTED",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IC24N0,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明:在RSA加密/解密代码中的Golang中发现了一个内存泄漏漏洞，这可能会导致使用攻击者控制的输入的资源耗尽漏洞。内存泄漏发生在github.com/Golang fips/openssl/openssl/RSA.goL113中。泄漏的对象是pkey和ctx。如果初始化上下文或设置不同属性时出错，该函数将使用命名返回参数释放pkey和ctx。所有与错误情况相关的return语句都遵循“return nil，nil，fail（…）”模式，这意味着pkey和ctx在应该释放它们的deferred函数内将为nil。 漏洞评分(mindspore评分): BaseScore: 7.5 Vector:CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", Appearance & Root Cause 漏洞：CVE20241394 归属组件应为 golangfips， 非openssl代码漏洞，此漏洞单漏洞归属组件有误（patch链接：https://github.com/golangfips/openssl/commit/85d31d0d257ce842c8a1e63c4d230ae850348136） mindspore 未引入golangfips组件，因此不涉及 CVE20241394 漏洞  Fix Solution mindspore不受影响，无需修复。
deepseek,zhanghanLeo,cherrypick some code from br_infer_deepseek_os to master,,2025-04-17T22:39:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC21M6
deepseek,zhanghanLeo,update ms_kernels_internal.tar.gz and ms_kernels_dependency.tar.gz for br_infer_deepseek_os,,2025-04-17T18:00:07+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC201E
mindir,何鑫,"Atlas 800T a2 B3通过Mindyolo训练模型后转onnx/mindir，无法转成ms ，报错,同时mindir无法实现推理","  1.Describe the current behavior / 问题描述 (Mandatory / 必填) 910 B3 通过Mindyolo训练模型后转onnx/mindir，无法转成ms ，报错,同时mindir无法实现推理  2.Environment / 环境信息 (Mandatory / 必填)   样例：   4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) Mindspore安装参考：https://www.mindspore.cn/install/ 端侧模型转换参考：https://mindspore.cn/lite/docs/zhCN/r2.5.0/converter/vonverter_tool.html mindsporelite安装参考：mindspore.cn/versions/cn 代码一尝试Modelmaster： https://gitee.com/mindspore/models/blob/master/official/cv/YOLOv5/README_CN.md%E6%95%B0%E6%8D%AE%E9%9B%86 代码二尝试mindyolo:github.com/mindsporelab/mindyolo/tree/v0.5.0  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 将训练得到的ckpt文件，导出为Onnx/mindir后，通过mindsporelite2.3.1linuxaarch64/tools/converter/.converter_lite 虚拟环境下执行：./converter_lite fmk=ONNX modelFile=/home/hwx1410890/ms/mindspore/mindsporelite2.5.0linuxaarch64/tools/converter/converter/yolov5.onnx outputFile=model         上述示例代码得到的是model.mindir,期望得到.ms文件，并部署鸿蒙端  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !报错日志 !报错日志 !报错日志    7.Special notes for this issue/备注 (Optional / 选填) 已尝试Mindsporelite2.2.14/2.3.0/2.3.1/2.5.0/（这三个版本是mindyolo官方给出的已经验证过的可支持的版本），均未成功转换和推理 **【定位人】**吴逸群（根据实际修改）",2025-04-17T10:58:59+08:00,"www,www,www,foruda",open,0,15,https://gitee.com/mindspore/mindspore/issues/IC1TE9,!输入图片说明 官方仓库里说的是这三个版本验证过mindir的推理，没有提到ms格式和2.5.0版本，ms的兼容比较有限，2.5可能也有问题； 我之前试过2.2.14版本在昇腾环境下的mindir推理是没问题的，cann版本是7.0，cann版本需要匹配，否则肯定出错；2.3我没亲自试过，不确定具体情况 至于其它操作，比如导出onnx然后再转om推理，2.2.14环境下我也试过，部分模型可以，有些模型调用的算子不支持直接导出onnx，可能需要等价替换，比如silu算子； 导出mindir再转om推理，我在2.2.14环境下试下来基本没问题，不过这个不是官方已正式发布版本的功能，喜欢倒腾的话可以试试； 至于转ms格式我没在昇腾环境试过，ms是端侧推理的格式，昇腾环境官方推荐使用云测推理方式，也就是mindir的格式推理，如果使用端侧的话，确实会有很多不支持的，端侧相比云测，支持的算子也要少很多；,!模型转换,!版本适配、 2.2.14/2.3.0/2.3.1跟Mindyolo的代码版本都不匹配啊,其实用个最接近的版本就可以了，比如0.3用2.2.14，或者用mindyolo 0.4在mindspore 2.2.14上跑也是可以的，就是有些api的参数变了不兼容，手动改一下变的那些地方适配下就可以了,"端侧转换工具生成的是.ms格式，一般就是在手机或者嵌入式设备上用的；云测转换工具生成的就是mindir,服务器环境，或者只要是昇腾的环境，都推荐用云测","2.3是怎么通的？ (ms1) hwx1410890:~/ms1/mindyolo$ python train.py /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/hwx1410890/.local/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) Traceback (most recent call last):   File ""/home/hwx1410890/ms1/mindyolo/train.py"", line 336, in      train(args)   File ""/home/hwx1410890/ms1/mindyolo/train.py"", line 94, in train     set_default(args)   File ""/home/hwx1410890/ms1/mindyolo/mindyolo/utils/utils.py"", line 25, in set_default     ms.set_recursion_limit(args.max_call_depth) AttributeError: module 'mindspore' has no attribute 'set_recursion_limit' !报错 代码是Mindyolov0.4,!AttributeError: module 'mindspore' has no attribute 'set_recursion_limit'",那为什么在GPU服务器上转ms可以,LSB Version:    :core4.1amd64:core4.1noarch Distributor ID: CentOS Description:    CentOS Linux release 7.9.2009 (Core) Release:        7.9.2009 Codename:       Core 这个GPU有区分？一个默认mindir一个默认Ms？,应该是你GPU服务器上安装了端侧的那个工具包吧？我自己的GPU环境一样可以转mindir,"是分端侧工具和云测工具包的，端侧就是转成ms的，云测工具包转mindir;但你要安装哪个都是可以安装的，通常转成来的ms文件就是在端侧推理，比如手机上推理；云测工具转出来的mindir,通常就是在昇腾环境，或者其它服务器上推理",默认值我不太清楚，我自己的GPU环境装的云测工具，默认转的就是mindir,这个api 2.5.0才有的，可能里面不同分支的代码混了吧，跑不起来直接删掉也没问题，不影响具体的模型逻辑,通过文档可以看到，云测和端侧的工具是两个包，长得有点像，转换工具的用法基本也差不多，可能容易搞混： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/use/downloads.html !输入图片说明 这个是云测转换的工具文档： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/mindir/converter_tool.html !输入图片说明 这个是端侧转换工具的文档： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/converter/converter_tool.html !输入图片说明,"将训练得到的ckpt文件，导出为Onnx/mindir后，通过mindsporelite2.3.1linuxaarch64/tools/converter/.converter_lite 虚拟环境下执行：./converter_lite fmk=ONNX modelFile=/home/hwx1410890/ms/mindspore/mindsporelite2.5.0linuxaarch64/tools/converter/converter/yolov5.onnx outputFile=model 上述示例代码得到的是model.mindir,期望得到.ms文件，并部署鸿蒙端 针对这个问题，可以参考mindspore lite官网教程解决，参考链接：https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/converter/converter_tool.html 此外，还需要注意mindspore lite版本包下载的来源，需要下载端上版本进行模型转换，不要使用云上版本进行模型转换；端上版本会默认生成ms的模型，云上版本默认生成.midnir的模型，详细的可以参考上面提供的mindspore的官网链接","onnx>ms (ms) hwx1410890:~/ms/minds/mindsporelite2.5.0linuxaarch64/tools/converter/converter$ ./converter_lite fmk=ONNX modelFile=model.onnx outputFile=model ERROR [mindspore/lite/src/common/file_utils.cc:230] RealPath] file path not exists: model.onnx [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.203 [mindspore/lite/tools/common/protobuf_utils.cc:82] ReadProtoFromBinaryFile] Binary proto file path model.onnx is not valid [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.240 [mindspore/lite/tools/converter/parser/onnx/onnx_model_parser.cc:717] InitOriginModel] Read onnx model file failed, model path: model.onnx [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.261 [mindspore/lite/tools/converter/parser/onnx/onnx_model_parser.cc:665] Parse] init origin model failed. [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.282 [mindspore/lite/tools/converter/converter_funcgraph.cc:106] Load3rdModelToFuncgraph] Get funcGraph failed for fmk: 2 [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.295 [mindspore/lite/tools/converter/converter_funcgraph.cc:186] Build] Load model file failed! [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.306 [mindspore/lite/tools/converter/converter.cc:1196] HandleGraphCommon] Build func graph failed [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.324 [mindspore/lite/tools/converter/converter.cc:1152] Convert] Handle graph failed: 1 Common error code. [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.337 [mindspore/lite/tools/converter/converter.cc:1344] RunConverter] Convert model failed [ERROR] LITE(571447,ffff78329010,converter_lite):2025041814:10:27.271.351 [mindspore/lite/tools/converter/cxx_api/converter.cc:374] Convert] Convert model failed, ret=Common error code. ERROR [mindspore/lite/tools/converter/converter_lite/main.cc:104] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code. (ms) hwx1410890:~/ms/minds/mindsporelite2.5.0linuxaarch64/tools/converter/converter$ ./converter_lite fmk=ONNX modelFile=yolov5.onnx outputFile=model [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.341.855 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.341.917 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.342.116 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.350.698 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.350.732 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.350.816 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.374.281 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.374.316 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.374.400 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.274 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.307 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.542 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.381.557 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.389.387 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.389.420 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.389.504 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.340 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.372 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.450 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.396.500 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.404.308 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.404.341 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.404.423 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.242 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.275 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.352 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.411.367 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.419.178 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.419.211 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.419.294 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.102 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.135 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.210 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.426.224 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.434.027 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.434.072 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.434.214 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.062 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.096 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.187 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.441.202 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.448.966 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.448.998 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.449.079 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.455.891 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.456.018 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.456.099 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.456.113 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.463.884 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.463.917 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.463.999 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.854 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.888 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.965 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.470.980 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.478.752 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.478.782 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.478.905 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.747 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.780 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.858 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.485.872 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.493.674 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.493.707 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.493.789 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.602 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.636 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.712 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.500.726 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.508.519 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.508.553 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.508.635 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.476 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.508 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.584 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.515.599 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.523.385 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.523.417 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.523.499 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.355 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.391 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.467 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.530.482 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.538.258 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.538.289 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.538.371 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.192 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.522 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.603 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.545.617 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.553.377 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.553.664 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.553.750 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.563 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.596 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.673 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.560.687 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.568.473 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.568.505 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.568.587 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.442 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.474 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.550 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.575.564 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.583.687 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.584.005 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.584.092 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.625.472 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.625.507 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.625.569 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.278 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.332 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.375 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.728.389 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.326 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.397 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.439 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.812.456 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.898.684 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.898.757 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.898.799 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.899.014 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.216 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.356 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.397 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:38.972.412 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.498 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.817 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.859 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.045.874 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.118.998 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.119.035 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.119.073 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.119.158 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.253 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.288 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.326 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.192.341 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.469 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.504 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.541 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.265.742 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.338.968 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.339.004 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.339.042 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.339.056 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.278 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.423 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.462 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.412.476 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.383 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.461 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.505 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.495.521 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.280 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.319 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.531 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.569.545 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.189 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.227 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.266 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.643.281 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.716.998 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.717.037 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.717.077 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.717.092 [mindspore/lite/tools/optimizer/const_fold/constant_folding_fusion.h:48] Run] Do constant fold failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.750.702 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.750.739 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.750.774 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.004 [mindspore/lite/tools/optimizer/graph/node_infershape.cc:294] InferShapeByNNACL] InferShapeByNNACL for op: 12Conv failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.042 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:314] InferProcess] node infer shape failed, node is 12Conv [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.078 [mindspore/lite/tools/optimizer/graph/infershape_pass.cc:189] Run] infer shape failed. [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.838 [mindspore/lite/tools/common/graph_util.cc:145] GetShapeVectorAndIdxFromCNode] Shape is empty 299Concat [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.906 [mindspore/lite/tools/common/graph_util.cc:145] GetShapeVectorAndIdxFromCNode] Shape is empty 323Concat [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.773.927 [mindspore/lite/tools/common/graph_util.cc:145] GetShapeVectorAndIdxFromCNode] Shape is empty 347Concat [WARNING] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.246 [mindspore/lite/tools/converter/legacy_optimizer/graph/infershape_pass.cc:633] InferSubgraph] InferShape failed, name: 12Conv, type: Conv2DFusion [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.321 [mindspore/lite/tools/converter/legacy_optimizer/graph/infershape_pass.cc:650] Run] InferSubgraph index: 0 failed, ret: 500 [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.583 [mindspore/lite/tools/converter/optimizer.cc:78] Run] Run GraphPass failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.597 [mindspore/lite/tools/converter/graphdef_transform.cc:71] QuantTransform] Run quant_node_optimizer graphPasses Failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.809.667 [mindspore/lite/tools/converter/converter_metagraph.cc:102] Build] Transform meta graph failed!ret = 500 [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.321 [mindspore/lite/tools/converter/converter.cc:1259] SaveGraph] Convert to meta graph failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.364 [mindspore/lite/tools/converter/converter.cc:1212] HandleGraphCommon] Save graph failed: 1 Common error code. [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.385 [mindspore/lite/tools/converter/converter.cc:1152] Convert] Handle graph failed: 1 Common error code. [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.399 [mindspore/lite/tools/converter/converter.cc:1344] RunConverter] Convert model failed [ERROR] LITE(571498,ffff9e3f9010,converter_lite):2025041814:10:39.812.423 [mindspore/lite/tools/converter/cxx_api/converter.cc:374] Convert] Convert model failed, ret=Common error code. ERROR [mindspore/lite/tools/converter/converter_lite/main.cc:104] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code. MINDIR>ms !报错"
deepseek,zhanghanLeo,将br_infer_hopeop代码cherrypick到br_infer_deepseek_os,,2025-04-15T22:01:41+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC1FSQ
ascend,caifubi,开memtracker进程卡死,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-15T20:25:51+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IC1F98
ascend,wangyibo,msadapter用例报错,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  msadapter用例报错  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-15T17:45:53+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IC1E1L
ascend,looop5,dvm动态图精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-04-15T10:21:18+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IC16PU,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
overflow,majun-bot,CVE20253277,"一、漏洞信息 漏洞编号：CVE20253277 漏洞归属组件：sqlite, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.36.0 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： An integer overflow can be triggered in SQLite’s `concat_ws()` function. The resulting, truncated integer is then used to allocate a buffer. When SQLite then writes the resulting string to the buffer, it uses the original, untruncated size and thus a wild Heap Buffer overflow of size ~4GB can be triggered. This can result in arbitrary code execution. 漏洞公开时间：20250415 01:15:27 漏洞创建时间：20250415 01:27:40 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20253277 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： SQLite的`concat_ws()`函数中可能触发整数溢出。截断后的整数随后会用于分配缓冲区。当SQLite将结果字符串写入缓冲区时，它会使用原始的、未截断的大小，从而触发大小约为4GB的堆缓冲区溢出。这可能导致任意代码执行。 其他分支生命周期结束。不在合入。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.9 &emsp;Vector： CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:L/VA:L/SC:L/SI:L/SA:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-04-15T01:27:41+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/FIXED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IC14UM,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： SQLite 的 `concat_ws()` 函数中可能触发整数溢出。截断后的整数随后会用于分配缓冲区。当 SQLite 将结果字符串写入缓冲区时，它会使用原始的、未截断的大小，从而触发大小约为 4GB 的堆缓冲区溢出。这可能导致任意代码执行。 其他分支生命周期结束。不在合入。2.3分支上的sqlite为3.36.0，该漏洞在这个版本不存在。 漏洞评分(MindSpore评分):  BaseScore：6.9 MEDIUM  Vector：CVSS:4.0/AV:N/AC:L/AT:N/PR:N/UI:N/VC:L/VI:L/VA:L/SC:L/SI:L/SA:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：sqlite软件漏洞 根因： SQLite 的 `concat_ws()` 函数中可能触发整数溢出。截断后的整数随后会用于分配缓冲区。当 SQLite 将结果字符串写入缓冲区时，它会使用原始的、未截断的大小，从而触发大小约为 4GB 的堆缓冲区溢出。这可能导致任意代码执行。 Fix Solution 已经修复：https://gitee.com/mindspore/mindspore/pulls/84285 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不涉及 Introduction Analysis 引入类型：其他，三方库漏洞 引入PR：无 PR合入时间：无 问题是否偶现：否,开发已修复问题：https://gitee.com/mindspore/mindspore/pulls/84285 ，关闭问题单
mindspore lite,gupengcheng0401,mindspore lite交叉编译开源25b ANDROID NDK报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > x86_64机器，CPU环境master分支交叉编译开源25b版本ANDROID NDK报错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：mindspore lite交叉编译成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image !报错截图 !报错相对loss误差 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】gupengcheng0401（根据实际修改）",2025-04-08T23:02:54+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBZJXG
pynative mode,徐微,[GPU]float16精度下where算子与内存布局交互导致(等价模型)计算不一致,"   1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下使用float16数据类型时，两个数学上等价的模型仅因where算子操作顺序和内存布局差异而产生完全不同的结果。 具体来说，当where算子与标量广播结合使用，且涉及不同的内存布局（如通过concat+split操作改变）时，会产生高达56.7%的元素不匹配，有些区域计算结果完全不同（如全变为0）。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果： ```python import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops import numpy as np class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.v2_0 = ms.Tensor(np.array([1.0], dtype=np.float16))     def construct(self, v3_0, v1_0):         v7_0 = ops.squeeze(self.v2_0)              core.Squeeze(dim=0)         v8_0 = ops.relu(v3_0)                      core.ReLU         v0_0 = ops.tan(v7_0)                       core.Tan         v6_0 = ops.transpose(v8_0, (0, 2, 1))      core.Transpose         v4_0 = ops.where(v1_0, v6_0, v7_0)         core.Where         v5_0 = ops.reshape(v4_0, v4_0.shape)       core.Reshape         return v5_0   返回v5_0作为最终输出 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.v5_0 = ms.Tensor(np.array([1.0], dtype=np.float16))     def construct(self, v0_0, v10_0):         v1_0 = ops.relu(v0_0)                       core.ReLU         v2_0 = ops.transpose(v1_0, (0, 2, 1))       core.Transpose         v3_0 = ops.concat((v2_0, v2_0), axis=1)     Concat {'axis'= 1}         v4_0 = ops.concat((v3_0, v3_0), axis=1)     Concat {'axis'= 1}         v6_0 = ops.squeeze(self.v5_0)               core.Squeeze(dim=0)         v7_0 = ops.tan(v6_0)                        core.Tan         v9_0, _ = ops.split(v3_0, v3_0.shape[1] // 2, axis=1)           v11_0 = ops.where(v10_0, v9_0, v6_0)        core.Where         v12_0 = ops.reshape(v11_0, v11_0.shape)     core.Reshape         return v12_0   返回v12_0作为最终输出 def reproduce_bug():     t1_model = T1Model()     t2_model = T2Model()     np.random.seed(42)     small_shape = (1, 5, 6)     v3_0_t1 = ms.Tensor(np.random.uniform(100, 100, small_shape).astype(np.float16))     v1_0_t1 = ms.Tensor(np.random.choice([True, False], size=(1, 1, 5)))     v0_0_t2 = v3_0_t1     v10_0_t2 = v1_0_t1     max_diff_overall = 0     max_run = 5       for run in range(max_run):         if run > 0:             v3_0_t1 = ms.Tensor(np.random.uniform(100, 100, small_shape).astype(np.float16))             v1_0_t1 = ms.Tensor(np.random.choice([True, False], size=(1, 1, 5)))             v0_0_t2 = v3_0_t1             v10_0_t2 = v1_0_t1         t1_output = t1_model(v3_0_t1, v1_0_t1)         t2_output = t2_model(v0_0_t2, v10_0_t2)         abs_diff = np.abs(t1_output.asnumpy()  t2_output.asnumpy())         current_max_diff = np.max(abs_diff)         if current_max_diff > max_diff_overall:             max_diff_overall = current_max_diff             best_t1_output = t1_output             best_t2_output = t2_output             best_input = v3_0_t1             best_mask = v1_0_t1     t1_output = best_t1_output     t2_output = best_t2_output     print(""\n输出形状:"")     print(""T1 v5_0:"", t1_output.shape)     print(""T2 v12_0:"", t2_output.shape)      打印完整输出值     print(""\nT1模型输出:"")     print(t1_output.asnumpy()[0])     print(""\nT2模型输出:"")     print(t2_output.asnumpy()[0])     if np.allclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0):         print(""\n输出一致"")     else:         mismatched = ~np.isclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0)         mismatched_count = np.sum(mismatched)         total_elements = t1_output.size         mismatch_percentage = 100.0 * mismatched_count / total_elements         print(""\n不匹配元素数量: {} / {} ({:.1f}%)"".format(             mismatched_count, total_elements, mismatch_percentage)) if __name__ == ""__main__"":     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")   使用GPU设备以便复现     reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应该一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: !输入图片说明",2025-04-08T22:36:45+08:00,,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBZJV8,应该是where算子的问题，GPU上我测试下来， 2.2.14是正确的，从2.3版本开始就有问题了；前段时间调试mindnlp里面的whisper模型，用的2.5.0的版本，发现在香橙派的310b上，两个地方调用where算子的结果都不对
yi,majun-bot,CVE202531498,"一、漏洞信息 漏洞编号：CVE202531498 漏洞归属组件：cares, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1_19_1 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： cares is an asynchronous resolver library. From 1.32.3 through 1.34.4, there is a useafterfree in read_answers() when process_answer() may reenqueue a query either due to a DNS Cookie Failure or when the upstream server does not properly support EDNS, or possibly on TCP queries if the remote closed the connection immediately after a response. If there was an issue trying to put that new transaction on the wire, it would close the connection handle, but read_answers() was still expecting the connection handle to be available to possibly dequeue other responses. In theory a remote attacker might be able to trigger this by flooding the target with ICMP UNREACHABLE packets if they also control the upstream nameserver and can return a result with one of those conditions, this has been untested. Otherwise only a local attacker might be able to change system behavior to make send()/write() return a failure condition. This vulnerability is fixed in 1.34.5. 漏洞公开时间：20250408 22:15:35 漏洞创建时间：20250408 22:31:34 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202531498 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 改漏洞是1.32.3到1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 8.3 &emsp;Vector： CVSS:4.0/AV:N/AC:H/AT:N/PR:N/UI:N/VC:L/VI:L/VA:H/SC:N/SI:N/SA:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-04-08T22:31:34+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBZJTC,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明: 改漏洞是1.32.3 到 1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。 漏洞评分(mindspore评分): BaseScore: 8.3 HIGH Vector:CVSS:4.0/AV:N/AC:H/AT:N/PR:N/UI:N/VC:L/VI:L/VA:H/SC:N/SI:N/SA:N 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：cares漏洞 根因： 改漏洞是1.32.3 到 1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。 Fix Solution 不涉及 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不涉及 Introduction Analysis 引入类型：其他，三方库漏洞 引入PR：无 PR合入时间：无 问题是否偶现：否,改漏洞是1.32.3 到 1.34.4引起的，mindspore依赖的cares版本为1.19.1，故不受影响。
pynative mode,徐微,[master][GPU] float16精度下不同操作顺序（等价模型）导致计算结果不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore GPU模式下，使用float16数据类型时，发现两个等价的计算图仅因操作顺序不同而产生显著不同的结果。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 我创建了两个模型T1Model和T2Model，它们在数学上应该产生完全相同的结果：     T1Model执行顺序: 先ceil再where再matmul     T2Model执行顺序: 先where再ceil再matmul    使用相同的float16输入数据，发现输出结果有明显差异：     40个输出元素中有14个不匹配（35%）     最大绝对差异达到1.5     特别是T1模型的第二行全为0，而T2模型的第二行与第一行完全相同 ```python import mindspore as ms import mindspore.nn as nn import mindspore.ops as ops import numpy as np  T1和T2为等价模型，输出结果应该一致  T1Model执行顺序: 先ceil再where再matmul  T2Model执行顺序: 先where再ceil再matmul class T1Model(nn.Cell):     def __init__(self):         super(T1Model, self).__init__()         self.v7_0 = ms.Tensor(np.array([[True]], dtype=bool))         self.v8_0 = ms.Tensor(np.ones((2, 1), dtype=np.float16) * 1.5)         self.v9_0 = ms.Tensor(np.ones(2, dtype=np.float16) * 1.5)      def construct(self, v0_0):           v6_0 = ops.ceil(v0_0)           v10_0 = ops.where(self.v7_0, self.v8_0, self.v9_0)         v5_0 = ops.matmul(v6_0, v10_0)         v1_0 = ops.transpose(v5_0, (1, 0))          v3_0 = ops.clip_by_value(v1_0, 1.5, 1.5)         return v3_0 class T2Model(nn.Cell):     def __init__(self):         super(T2Model, self).__init__()         self.v0_0 = ms.Tensor(np.ones(2, dtype=np.float16) * 1.5)          self.v1_0 = ms.Tensor(np.ones((2, 1), dtype=np.float16) * 1.5)          self.v2_0 = ms.Tensor(np.array([[True]], dtype=bool))       def construct(self, v4_0):           v3_0 = ops.where(self.v2_0, self.v1_0, self.v0_0)          v5_0 = ops.ceil(v4_0)           v6_0 = ops.matmul(v5_0, v3_0)           v7_0 = ops.transpose(v6_0, (1, 0))          v13_0 = ops.clip_by_value(v7_0, 1.5, 1.5)           return v13_0 def reproduce_bug():     np.random.seed(42)     t1_model = T1Model()     t2_model = T2Model()     input_shape = (20, 2)     input_data = np.random.uniform(2, 2, input_shape).astype(np.float16)     v0_0_t1 = ms.Tensor(input_data)     v4_0_t2 = ms.Tensor(input_data.copy())     t1_output = t1_model(v0_0_t1)     t2_output = t2_model(v4_0_t2)     print(""T1模型输出 (v3_0):"", t1_output.asnumpy())     print(""T2模型输出 (v13_0):"", t2_output.asnumpy())     if not np.allclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0):         print(""发现不一致! T1和T2模型的输出不同"")         mismatched = ~np.isclose(t1_output.asnumpy(), t2_output.asnumpy(), rtol=0.01, atol=0)         print(""不匹配元素数量: {} / {} ({:.1f}%)"".format(             np.sum(mismatched), t1_output.size, 100 * np.sum(mismatched) / t1_output.size))         print(""最大绝对差异:"", np.max(np.abs(t1_output.asnumpy()  t2_output.asnumpy())))     return t1_output, t2_output if __name__ == ""__main__"":     ms.set_context(mode=ms.PYNATIVE_MODE)     ms.set_device(""GPU"")     t1_output, t2_output = reproduce_bug() ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: T1和T2模型推理的结果应该一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: !输入图片说明",2025-04-08T20:31:39+08:00,repo,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBZJ9B,测试下来应该是正好3月16号的包有这个bug，最新的4月8号的包已经修复这个问题了，你可以试一下： https://repo.mindspore.cn/mindspore/mindspore/version/202504/20250408/master_20250408193412_63fe3cd9b52d7726eaa1068edb0d557e0d1cb93a/unified/x86_64/mindspore2.6.0cp310cp310linux_x86_64.whl 更早一些的版本，比如2.2.14， 2.4.10也都是正常的
overflow,majun-bot,CVE202529087,"一、漏洞信息 漏洞编号：CVE202529087 漏洞归属组件：sqlite, https://gitee.com/mindspore/mindspore 漏洞归属的版本：3.36.0 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： Sqlite 3.49.0 is susceptible to integer overflow through the concat function. 漏洞公开时间：20250408 04:15:20 漏洞创建时间：20250408 13:10:03 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202529087 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞没有修复方案，不受影响 漏洞评分(MindSpore评分): &emsp;BaseScore： 0.0 &emsp;Vector： N/A 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-04-08T13:10:03+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,10,https://gitee.com/mindspore/mindspore/issues/IBZC2B,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: x.x(浮点格式) Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明: 该漏洞没有修复方案，不受影响 漏洞评分(mindspore评分): BaseScore:N/A Vector:N/A 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明: 该漏洞没有修复方案，不受影响 漏洞评分(mindspore评分): BaseScore:0 Vector:N/A 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明: 该漏洞没有修复方案，不受影响 漏洞评分(mindspore评分): BaseScore:0.0 Vector:N/A 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：sqlite漏洞 根因： Sqlite 3.49.0 容易通过 concat 函数发生整数溢出。 Fix Solution 不修复，无修复方案 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 是否需要补充 ST/UT：否 不涉及 原因：不涉及 Introduction Analysis 引入类型：其他，三方库漏洞 引入PR：无 PR合入时间：无 问题是否偶现：否,不修复，无修复方案，关闭问题单
ascend,TuDouNi,lite where算子fp16报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-04-07T14:08:15+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBZ09Q,【回归指南】 请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 / Bugfix修复引入 / 测试新增测试场景 / 测试漏测 / 用例未适配 / 环境问题 / CANN升级 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
mindir,Zhenghai Zhang,[MSLITE]使用delegate时tensor引用计数存在bug,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  使用delegate时tensor引用计数存在bug  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device /CPU/NPU/  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.3.1  Python version (e.g., Python 3.7.5) :3.8.0  OS platform and distribution (e.g., Linux Ubuntu 16.04):18.04  GCC/Compiler version (if compiled from source): 7.5.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  无  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 首先构造一个网络，导出成mindir。 ``` import mindspore as ms from mindspore import Tensor, nn, ops import numpy as np input_x = np.array([[1, 2, 3], [4, 5, 6], [1, 2, 3]]).astype(np.float32) input_y = np.array([[7, 8, 9], [10, 11, 12], [1, 2, 3]]).astype(np.float32) class Net(nn.Cell):     def __init__(self):         super().__init__()         self.addn = ops.AddN()         self.matmul = ops.MatMul()     def construct(self, x, y):         z = self.addn([x, y])         w = self.matmul(x, z)         h = self.matmul(y, z)         res = self.addn([w, h])         return res net = Net() x_tensor = ms.Tensor(input_x) y_tensor = ms.Tensor(input_y) out = net(x_tensor, y_tensor) ms.export(net, x_tensor, y_tensor, file_name=""pnna_model"", file_format='MINDIR') print(out) ``` 2. 再将mindir文件转换成ms文件，可视化ms如下图： !输入图片说明 3. 使用mindspore lite进行推理，推理时设置addn算子使用delegate模式代理，matmul使用cpu运行。下面是运行时的log信息： ``` DEBUG [mindspore/lite/src/litert/scheduler.cc:459] Schedule] schedule kernels success. DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph0,  type:0 DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : CpuFP32SubGraph0,  type:1 DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop1] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop0] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph1,  type:0 ``` 经过schedule之后会划分成3个子图，其中PNNASubGraph的arch == kDelegate，打印出每个kernel的引用计数发现，delegate子图PNNASubGraph0输出tensor：Default/AddNop0的引用计数为1，显然不正确，应该为2才对，否则当CpuFP32SubGraph0子图运行完第一个Default/MatMulop1 kernel时就会将该kernel的输入tensor Default/AddNop0进行释放，从而导致结果错误。 !输入图片说明  Describe the expected behavior / 预期结果 (Mandatory / 必填) delegate子图PNNASubGraph0输出tensor：Default/AddNop0的引用计数为2,结果正确。  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  DEBUG [mindspore/lite/src/litert/scheduler.cc:459] Schedule] schedule kernels success. DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph0,  type:0 DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : CpuFP32SubGraph0,  type:1 DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop1] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:467] Schedule] kernel: [Default/MatMulop0] TypeId(43); OpType(MatMulFusion); format(1); arch(0) DEBUG [mindspore/lite/src/litert/scheduler.cc:461] Schedule] [subgraph] : PNNASubGraph1,  type:0 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph0 in_kernels size: 0 out_kernels size: 2 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: Default/MatMulop1 in_kernels size: 1 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: Default/MatMulop0 in_kernels size: 1 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph1 in_kernels size: 2 out_kernels size: 0 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph0 in_kernels size: 0 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: CpuFP32SubGraph0 in_kernels size: 1 out_kernels size: 1 DEBUG [mindspore/lite/src/litert/kernel_exec_util.cc:265] FindAllInoutKernels] kernel: PNNASubGraph1 in_kernels size: 1 out_kernels size: 0 DEBUG [mindspore/lite/src/litert/lite_session.cc:781] PrepareKernels] kernel size: 3 DEBUG [mindspore/lite/src/litert/lite_session.cc:849] SetTensorInitRefCount] kernel name: PNNASubGraph0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name PNNASubGraph0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/AddNop0 IsGraphOutput: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name PNNASubGraph0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/AddNop0 schema::Format: NHWC DataType: 43 Category: 0 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1 DEBUG [mindspore/lite/src/litert/lite_session.cc:849] SetTensorInitRefCount] kernel name: CpuFP32SubGraph0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name Default/MatMulop1 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/MatMulop1 IsGraphOutput: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name Default/MatMulop1 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/MatMulop1 schema::Format: NHWC DataType: 43 Category: 0 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name Default/MatMulop0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/MatMulop0 IsGraphOutput: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name Default/MatMulop0 out kernel size: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/MatMulop0 schema::Format: NHWC DataType: 43 Category: 0 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1 DEBUG [mindspore/lite/src/litert/lite_session.cc:854] SetTensorInitRefCount] IsIsolatedSubGraph: 0 DEBUG [mindspore/lite/src/litert/lite_session.cc:849] SetTensorInitRefCount] kernel name: PNNASubGraph1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:40] InitOutTensorInitRefCount] kernel name PNNASubGraph1 out kernel size: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:44] InitOutTensorInitRefCount] out tensor Default/AddNop1 IsGraphOutput: 1 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:45] InitOutTensorInitRefCount] kernel name PNNASubGraph1 out kernel size: 0 DEBUG [mindspore/lite/src/executor/kernel_exec.cc:55] InitOutTensorInitRefCount] out tensor Tensor name: Default/AddNop1 schema::Format: NHWC DataType: 43 Category: 4 Shape: 3 3 Data:Data of tensor is nullptr init_ref_count: 1  Special notes for this issue/备注 (Optional / 选填)",2025-04-07T10:42:05+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBYXO7
ascend,zhangyinxia,fix barrier op,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-04-03T09:08:27+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBYEZJ
ascend,tanxinglian,"[CT][MS][OPS][ops.prompt_flash_attention][function][全量]prompt_flash_attention ascend后端报错RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check!"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > prompt_flash_attention ascend后端报错RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2 test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：O0 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v  test_f_prompt_flash_attention.py::test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2 pytest s v test_f_prompt_flash_attention.py::test_f_prompt_flash_attention_gqa_opt_b16  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```  ()     (reason='只支持910B')     (reason='只支持910B')     def test_f_prompt_flash_attention_opt_bsh_knd_5_5_16_s_1_pse_shift2():         n, kv_n, d = (25, 5, 16)         s, kv_s = (3, 3)         layout = 'BNSD'         causal = False         enable_gpu = False         pre_tokens, next_tokens = 2147483647, 0         if enable_gpu and (not causal):              allMask 全0             pre_tokens, next_tokens = 65535, 65535         s = s * 1024         kv_s = kv_s * 1024         actual_seq_lengths = [s, s]         actual_seq_lengths_kv = [kv_s, kv_s]         pse_shift = np.random.randn(2, n, s, kv_s).astype(np.float16)         deq_scale1_np = np.array([1.7])         quant_scale1_np = np.array([1.7])         deq_scale2_np = np.array([1.3])         quant_scale2_np = None         quant_offset2_np = None         quant_params = (             deq_scale1_np, quant_scale1_np, deq_scale2_np, quant_scale2_np, quant_offset2_np)         args = PFAParam(b=2, n=n, q_s=s, kv_s=kv_s, d=d, pre_tokens=pre_tokens, next_tokens=next_tokens,                         data_format=layout,                         actual_seq_lengths=actual_seq_lengths,                         atten_mask_shape=[s, kv_s],                         actual_seq_lengths_kv=actual_seq_lengths_kv,                         quant_params=quant_params,                         num_key_value_heads=kv_n, sparse_mode=0,                         np_type=np.int8, ms_type=mindspore.int8, pse_shift=pse_shift)         fact = PromptFlashAttentionFactory(args, causal=causal) >       fact.forward_cmp() ../test_f_prompt_flash_attention.py:1516:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/prompt_flash_attention_ops.py:1314: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/prompt_flash_attention_ops.py:1114: in forward_mindspore_impl     out = net(query, key, value, attn_mask, acs, acs_kv, ../../share/utils.py:289: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1262: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1706: in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1997: in __call__     return self.run(obj, *args, phase=phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2048: in run     return self._exec_pip(obj, *args, phase=phase_real) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:189: in wrapper     results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp() phase = 'train.1743291204253196288.281468505601456.0....................' args = (Tensor(shape=[2, 25, 3072, 16], dtype=Int8, value= [[[[0, 0, 0 ... 0, 0, 0],    [0, 0, 0 ... 0, 0, 0],    [0, 0, 0 .....alse]]), Tensor(shape=[2], dtype=Int64, value= [3072, 3072]), Tensor(shape=[2], dtype=Int64, value= [3072, 3072]), ...) fn =           def _exec_pip(self, obj, *args, phase=''):         """"""Execute the generated pipeline.""""""         fn = obj.construct         obj.__parse_method__ = fn.__name__ >       return self._graph_executor(args, phase) E       RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 742227] 2025033007:33:26.563.765 PromptFlashAttention LaunchAicore failed.[THREAD:759874] E               TraceBack (most recent call last): E               tensor key shape (128) do not equal to tensor value shape(448) in dim 3[FUNC:CheckKeyValueParamsConsistency][FILE:prompt_flash_attention_tiling.cpp][LINE:940][THREAD:759874] E               key value consistency check failed![FUNC:RunBigKernelTilingWithParams][FILE:prompt_flash_attention_tiling.cpp][LINE:2820][THREAD:759874] E               Tiling failed[THREAD:759874] E               Tiling Failed.[THREAD:759874] E               Kernel GetWorkspace failed. opType: 4[THREAD:759874] E               PromptFlashAttention LaunchAicore failed.[THREAD:759874] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/opapi/aclnn/prompt_flash_attention_aclnn_kernel.h:50 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2028: RuntimeError ``` ```      ()     (reason='只支持910B')     (reason='只支持910B')     def test_f_prompt_flash_attention_gqa_opt_b16():         pre_tokens, next_tokens = 748647, 10         causal = False         enable_gpu = False         layout = 'BNSD'         if enable_gpu and (not causal):              allMask 全0             pre_tokens, next_tokens = 65535, 65535         n, kv_n, d = (10, 5, 16)         s, kv_s = (2, 2)         s = s * 1024         kv_s = kv_s * 1024         actual_seq_lengths = []         actual_seq_lengths_kv = []         for _ in range(16):             value = np.random.randint(1, s)             actual_seq_lengths.append(value)             actual_seq_lengths_kv.append(value)         args = PFAParam(b=16, n=n, q_s=s, kv_s=kv_s, d=d, pre_tokens=pre_tokens,                         next_tokens=next_tokens,                         data_format=layout,                         actual_seq_lengths=actual_seq_lengths,                         actual_seq_lengths_kv=actual_seq_lengths_kv,                         num_key_value_heads=kv_n, sparse_mode=0, atten_mask_shape=[s, kv_s],                         np_type=np.float32, ms_type=mindspore.float16)         fact = PromptFlashAttentionFactory(args, causal=causal) >       fact.forward_cmp() ../test_f_prompt_flash_attention.py:993:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/prompt_flash_attention_ops.py:1314: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/prompt_flash_attention_ops.py:1114: in forward_mindspore_impl     out = net(query, key, value, attn_mask, acs, acs_kv, ../../share/utils.py:289: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1262: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1706: in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1997: in __call__     return self.run(obj, *args, phase=phase) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2048: in run     return self._exec_pip(obj, *args, phase=phase_real) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:189: in wrapper     results = fn(*arg, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp() phase = 'train.1743290378095004672.281467745319120.0....................' args = (Tensor(shape=[16, 10, 2048, 16], dtype=Float16, value= [[[[6.7578e01,  2.1387e01,  4.3762e02 ...  9.8633e02, 7.... dtype=Int64, value= [ 492,  662, 1717, 1260, 1691, 1271,  822, 1324, 1688, 1505,   49, 1526, 1237,  434, 1491, 1589])) fn =           def _exec_pip(self, obj, *args, phase=''):         """"""Execute the generated pipeline.""""""         fn = obj.construct         obj.__parse_method__ = fn.__name__ >       return self._graph_executor(args, phase) E       RuntimeError: aclnnPromptFlashAttentionV3GetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 636302] 2025033007:19:40.136.807 PromptFlashAttention LaunchAicore failed.[THREAD:640624] E               TraceBack (most recent call last): E               tensor key shape (112) do not equal to tensor value shape(192) in dim 3[FUNC:CheckKeyValueParamsConsistency][FILE:prompt_flash_attention_tiling.cpp][LINE:940][THREAD:640624] E               key value consistency check failed![FUNC:RunBigKernelTilingWithParams][FILE:prompt_flash_attention_tiling.cpp][LINE:2820][THREAD:640624] E               Tiling failed[THREAD:640624] E               Tiling Failed.[THREAD:640624] E               Kernel GetWorkspace failed. opType: 4[THREAD:640624] E               PromptFlashAttention LaunchAicore failed.[THREAD:640624] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/opapi/aclnn/prompt_flash_attention_aclnn_kernel.h:50 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:2028: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e8869af31fc3250cda2eba&workspaceId=67e8869a5050f12edd53280f https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e8869af31fc3250cda2f3f&workspaceId=67e8869a5050f12edd53280f    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-04-01T11:25:29+08:00,"gitee,foruda,rct/cann",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBXV11,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 修改了PromptFlashAttention算子的Infer流程，没有考虑key和value保持一致的情况 CANN问题单： 暂无，最新商发版本已解决（Milan_C21/20250402_atlas已解决） !输入图片说明 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 解决方案 (Fix Solution) 2. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,cann包：Milan_C21/20250402_atlas !输入图片说明
ascend,tanxinglian,[CT][MS][OPS][ops.triuindices][function][全量]triuindices ascend后端计算结果错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > triuindices ascend后端计算结果错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_p_triuindices_matrix_shape_1_1 test_f_triuindices_matrix_shape_1_1 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O0 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_triuindices.py::test_p_triuindices_matrix_shape_1_1 pytest s v test_f_triu_indices.py::test_f_triuindices_matrix_shape_1_1  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       def test_p_triuindices_matrix_shape_1_1():         fact = TriuIndicesMock(attributes={""row"": 1, ""col"": 1}) >       fact.forward_cmp() ../test_triuindices.py:97:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/primitive/triuindices_ops.py:53: in forward_cmp     allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0],        [0]], dtype=int32) data_me = array([[1],        [1]], dtype=int32), rtol = 0, atol = 0     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_f_triu_indices.py:92:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/triuindices_ops.py:56: in forward_cmp     allclose_nparray(out_pytorch, out_mindspore, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0],        [0]], dtype=int32) data_me = array([[1],        [1]], dtype=int32), rtol = 0, atol = 0     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0 0] E       data_me_error:[1 1] E       loss:[1 1] ../../share/utils.py:57: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e5dca68dd14476537e7e86&workspaceId=67e9bb29a1196417b05f5d64 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000%3A51%3A05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e5dca68dd14476537e7ec2&workspaceId=67e82c1e6ae691186d8c67b6    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-04-01T11:12:26+08:00,"gitee,foruda,foruda,rct/oldrelease,ctl/componenttest,rca/algorithm",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBXURK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,新包仍无规律重现问题 !输入图片说明," Appearance & Root Cause 问题：triuindices ascend后端计算结果错误，对于1*1的矩阵，预期返回下标[0, 0]，实际返回下标[1, 1]。 根因：该算子是MS的AICPU算子，其没有输入，直接输出下标。分析代码发现，mindspore实现的triuindices和trilindices套用同一套infer逻辑，两者没有做出区分。两个算子实际计算的逻辑有差别，导致triuindices计算错误。  Fix Solution triuindices中对于offset的处理需要增加一个offset1操作。  Fix Description & Test Suggestion 修复pr：https://gitee.com/mindspore/mindspore/pulls/84014 使用该pr合入后的每日构建包回归。 测试建议：算子开发需要自验充分，尽可能排除偶现问题，避免浪费大家时间  Selftest Report & DT Review 用例通过。 是否需要补充 ST/UT：否 如果选择否，请补充理由 原因：非基本功能问题  Introduction Analysis 引入类型：旧版本算子遗留问题 引入PR：不涉及 PR合入时间：不涉及 问题是否偶现：否","新版本执行一天未再复现 【回归版本号】：__commit_id__ = '[sha1]:1abfba19,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][ops.bincount][function][全量]bincount 910b graph模式报错RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > bincount 910b graph模式报错RuntimeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_bincount_input_1d_uint8_weights_1d_int8 test_f_bincount_input_1d_int64_weights_1d_float64 test_f_bincount_input_1d_int64_weights_1d_float16 test_f_bincount_input_1d_int32_weights_1d_int16 test_f_bincount_input_1d_int32_weights_1d_float32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O0 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_f_bincount.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='GE does not support dynamic shape')     def test_f_bincount_input_1d_uint8_weights_1d_int8():         input_x = Tensor(np.random.randint(0, 128, (3,)), mstype.uint8)         weights = Tensor(np.random.randint(128, 127, (3,)), mstype.int8)         minlength = 7         fact = BincountMock(             attributes={'minlength': minlength},             inputs=[input_x, weights]) >       fact.forward_cmp() ../test_f_bincount.py:212:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/bincount_ops.py:59: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/bincount_ops.py:39: in forward_mindspore_impl     out = net(self.input_x, self.weights) ../../share/utils.py:289: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1262: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1703: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1685: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp(), phase = 'train.1743266774424581888.281468119748576.0..' do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[3], dtype=UInt8, value= [116,  69,  67]), Tensor(shape=[3], dtype=Int8, value= [51,  95,  68])) kwargs = {}, key_id = '2814681197485761743266774424581888', key = 0 parameter_ids = '', raw_phase = 'train' full_function_name = 'WrapOp.1.187651209966688', echo_function_name = 'WrapOp'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         _init_auto_parallel_context(obj)         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             _clear_auto_parallel_context(obj)             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         gc.collect() >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: The current operator needs to be supplemented with an adapter, please check in `transform` directory. node is Default/ScalarGtop0 E        E        E        The Function Call Stack: (For framework developers) E        E       In file /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/function/math_func.py:501, 7~64/    if input.astype(mstype.float32).max().item() > minlength  1:/ E       In file /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/function/math_func.py:455~511/def bincount(input, weights=None, minlength=0):/ E       In file /home/jenkinsslave/workspace/1980b_green_mindspore_ascend_opensource/MindSporeTest/share/ops/functional/bincount_ops.py:18, 14~26/        out = ops.bincount(input_x, weights, self.minlength)/ E       In file /home/jenkinsslave/workspace/1980b_green_mindspore_ascend_opensource/MindSporeTest/share/ops/functional/bincount_ops.py:17~19, 4~18/    def construct(self, input_x, weights):/ E        E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/plugin/device/ascend/hal/device/kernel_select_ascend.cc:612 HandleKernelSelectFailure /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1954: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902206&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03t710bl5mi89%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250329%2000:51:05&isMergedTask=false&nodeDate=20250329&year=20242025&TestNow=true&testcaseid=67e82c1ef9c5276b77e386cd&workspaceId=67e82c1e6ae691186d8c67b6    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-04-01T10:38:06+08:00,"gitee,foruda,foruda,foruda,foruda,rca/others,ctl/componenttest,rct/bugfix",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBXU2S,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,https://gitee.com/mindspore/mindspore/pulls/83565 修改引入," Appearance & Root Cause 问题：ops.bincount 910b graph模式报错RuntimeError: The current operator needs to be supplemented with an adapter, please check in `transform` directory. node is Default/ScalarGtop0 根因： !输入图片说明 此处比较前后均为scalar时走到ScalarGt算子。 ScalarGt只有CPU实现，开启不允许退避的环境变量后找不到算子了。 !输入图片说明 !输入图片说明  Fix Solution max操作后不取item()结果为Tensor，不走入ScalarGt算子， 保持和上次修改前逻辑一致。  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83958 PR合入后daily包回归  Selftest Report & DT Review 自测结果： !输入图片说明 是否需要补充 ST/UT：否  Introduction Analysis 引入类型：Bugfix修复引入 引入PR： https://gitee.com/mindspore/mindspore/pulls/83565 PR合入时间：2025/3/27 是否偶现：否","【回归版本号】：__commit_id__ = '[sha1]:843c0cc2,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
ascend,huangzhichao2023,deepseek3缺少测试用例," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > deepseek3缺少测试用例  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (`Ascend910B1`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**黄志超（根据实际修改）",2025-03-30T15:19:20+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBXCB1
ascend,tanxinglian,[CT][MS][OPS][mint.nn.functional.conv2d][function][全量]mint.nn.functional.conv2d 910A存在精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.conv2d 910A存在精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_mint_n_f_conv2d_dyn_shape_3 test_mint_n_f_conv2d_padding_same_odd_float16_4d_12x12x28x49_random >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend source /usr/local/Ascend/ascendtoolkit/set_env.sh export PYTHONPATH=${PYTHONPATH%:} export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_mint_n_f_conv2d.py::test_dynamic_shape_mint_n_f_conv2d_dyn_shape_3 pytest s v  test_mint_n_f_conv2d.py::test_mint_n_f_conv2d_padding_same_odd_float16_4d_12x12x28x49_random  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       ()     ()     ()     def test_dynamic_shape_mint_n_f_conv2d_dyn_shape_3():         input_x = Tensor(shape=(None, None, None), dtype=mstype.float16)         weight = Tensor(shape=(None, None, None, None), dtype=mstype.float16)         bias = Tensor(shape=(None,), dtype=mstype.float16)         stride = mutable(input_data=1, dynamic_len=False)         padding = 'same'         dilation = mutable(input_data=(3, 4), dynamic_len=False)         groups = mutable(input_data=19, dynamic_len=False)         input_x1 = Tensor(np.random.randn(19, 20, 50), mstype.float16)         weight1 = Tensor(np.random.randn(76, 1, 4, 2), mstype.float16)         bias1 = Tensor(np.random.randn(76, ), mstype.float16)         stride1 = mutable(input_data=1, dynamic_len=False)         padding1 = 'same'         dilation1 = mutable(input_data=(3, 4), dynamic_len=False)         groups1 = mutable(input_data=19, dynamic_len=False)         attributes1 = {'stride': stride1, 'padding': padding1, 'dilation': dilation1, 'groups': groups1}         inputs1 = [input_x1, weight1, bias1]         input_x2 = Tensor(np.random.randn(3, 10, 13), mstype.float16)         weight2 = Tensor(np.random.randn(2, 3, 2, 3), mstype.float16)         bias2 = Tensor(np.random.randn(2, ), mstype.float16)         stride2 = mutable(input_data=1, dynamic_len=False)         padding2 = 'same'         dilation2 = mutable(input_data=(3, 2), dynamic_len=False)         groups2 = mutable(input_data=1, dynamic_len=False)         attributes2 = {'stride': stride2, 'padding': padding2, 'dilation': dilation2, 'groups': groups2}         inputs2 = [input_x2, weight2, bias2]         input_x3 = Tensor(np.random.randn(3, 3, 50), mstype.float16)         weight3 = Tensor(np.random.randn(1, 3, 2, 3), mstype.float16)         bias3 = Tensor(np.random.randn(1, ), mstype.float16)         stride3 = mutable(input_data=1, dynamic_len=False)         padding3 = 'same'         dilation3 = mutable(input_data=(1, 5), dynamic_len=False)         groups3 = mutable(input_data=1, dynamic_len=False)         attributes3 = {'stride': stride3, 'padding': padding3, 'dilation': dilation3, 'groups': groups3}         inputs3 = [input_x3, weight3, bias3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = Conv2dMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (input_x, weight, bias, stride, padding, dilation, groups) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_mint_n_f_conv2d.py:1126:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/conv2d_mint.py:340: in forward_dynamic_shape_cmp     allclose_nparray(a, b, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[ 0.04687303,  2.1588888 ,  2.0576582 , ..., 0.6429784 ,           0.34636706,  1.682324  ],         [0.0635...         [0.47335398,  0.2898569 , 1.7914011 , ..., 1.2131597 ,          0.07973671, 1.9519975 ]]], dtype=float32) data_me = array([[[ 0.04688,  2.158  ,  2.057  , ..., 0.6426 ,  0.3464 ,           1.683  ],         [0.0635 , 0.9473 , 5.57...         1.912  ],         [0.4734 ,  0.2898 , 1.791  , ..., 1.213  , 0.0797 ,          1.951  ]]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_mint_n_f_conv2d.py:425:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/conv2d_mint.py:193: in forward_cmp     allclose_nparray(out_cmp, out_mindspore, self.loss, self.loss) ../../share/utils.py:64: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[ 6.99089146e+00,  4.23183060e+00, 1.61583614e+00, ...,            2.26269007e01,  9.62609673e+00, 7.71942...310386e+00, 9.32385635e+00, ...,            2.73167515e+00, 8.36550236e+00, 2.95200014e+00]]]],       dtype=float32) data_me = array([[[[ 6.9922e+00,  4.2305e+00, 1.6162e+00, ...,  2.2656e01,            9.6250e+00, 7.7246e01],          [ 2.9...       [1.5492e+01,  2.3730e+00, 9.3203e+00, ...,  2.5117e+00,           9.0000e+00, 3.2656e+00]]]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[32.84552    17.736362   17.855343  ...   2.7316751  8.365502 E         2.9520001] E       data_me_error:[34.3    17.69   15.51  ...   2.512  9.     3.266] E       loss:[1.46698    0.04886246 2.3475304  ... 0.2199564  0.63449764 0.31362486] ../../share/utils.py:57: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03t710bl5mi89%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007:18:24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e69213e00c6b20d441be19&workspaceId=67e692106ae691186d864456 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e69211e00c6b20d441bc79&workspaceId=67e692106ae691186d864456    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-29T16:50:07+08:00,"gitee,foruda,foruda,rct/cann,mindspore-repo",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBX8WV,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,cann包升级引入，已提DTS单：https://dts.huawei.com/DTSPortal/ticket/DTS2025033103526,DTS2025033124507,Appearance & Root Cause 问题：CANN升级引入的bug 根因：见DTS单 Fix Solution CANN升级到CANN 8.1.RC1.B090 Fix Description & Test Suggestion CANN升级到CANN 8.1.RC1.B090 Selftest Report & DT Review !输入图片说明 !输入图片说明 是否需要补充 ST/UT：否 如果选择否，请补充理由 原因：非基本功能问题 Introduction Analysis 引入类型：CANN引入 引入PR：见DTS单 PR合入时间：见DTS单 问题是否偶现：否,cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250402_atlas/ !输入图片说明
ascend,tanxinglian,"[CT][MS][OPS][mint.nn.functional.interpolate][function][全量]interpolate报错RuntimeError: aclnnUpsampleNearest1dBackwardGetWorkspaceSize call failed, please check!"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > interpolate报错RuntimeError: aclnnUpsampleNearest1dBackwardGetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例： uint32/NCHW/uint32/NC1HWC0/.[THREAD:889755] E               TraceBack (most recent call last): E              Cannot find binary for op TransData.[THREAD:889755] E              Kernel GetWorkspace failed. opType: 5[THREAD:889755] E              TransDataSpecial ADD_TO_LAUNCHER_LIST_AICORE failed.[THREAD:889755] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/pyboost/customize/upsample_nearest1d_grad.cc:34 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/tensor.py:994: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb86ae691186d85d8b5&workspaceId=67e66bb7a1196417b0549ee7 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb76ae691186d85d896&workspaceId=67e66bb7a1196417b0549ee7 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03t710bl5mi89%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007:18:24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb76ae691186d85d889&workspaceId=67e66bb7a1196417b0549ee7 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2424802299561902224&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03t710bl5mi89/&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250328%2007%3A18%3A24&isMergedTask=false&nodeDate=20250328&year=20242025&TestNow=true&testcaseid=67e66bb76ae691186d85d88d&workspaceId=67e66bb7a1196417b0549ee7    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-29T15:26:49+08:00,"gitee,foruda,foruda,foruda,foruda,rca/others,rct/oldrelease,ctl/componenttest,rct/cann,mindspore-repo,sig/ops,dts-szv",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBX8E9,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,升级run包引入问题，已和海思沟通，dts单号：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025032914704, Appearance & Root Cause 问题：反向算子跑不通 根因： 海思侧bug，dts单号：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025032914704  Fix Solution 更新run包  Fix Description & Test Suggestion 无需合入 测试建议：用最新cann包回归 https://cmc.rnd.huawei.com/cmcversion/index/releaseView?deltaId=11917143714825472&isSelect=Software。  Selftest Report & DT Review !输入图片说明 !输入图片说明 !输入图片说明 !输入图片说明 是否需要补充 ST/UT：否 原因：已有用例含糊  Introduction Analysis 引入类型：run包升级引入 引入PR：无 PR合入时间：年/月/日 问题是否偶现：否,cann包：http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250402_atlas !输入图片说明 !输入图片说明
ascend,nicozhang,"在容器里使用 8G 内存，mindspore 版本为 2.2.11, 会触发 OOM"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > 在容器里，使用 mindspore2.2.11 训练一个小模型，使用 8G 内存会触发 oom。如果加大内存，也通过训练。原来用的 1.7 的版本是可以的，使用2.2.11之后就不行了。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Ascend910B   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) !输入图片说明 !输入图片说明 详细过程，见文件 代码文件",2025-03-28T16:48:53+08:00,mindspore-assistant,closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBX336,这里的8G是device memory吗？可能正好就是不够了，这种应该是正常现象，不同的版本因为内部处理有改动，所以device memory的使用上有差异也是正常的，有些版本可能做了性能优化，为了提高性能会多占一些device memory，类似于空间换时间的意思，并且和不同的cann版本、昇腾驱动版本有关，或者底层算子的不同也有关联；或者说不同的mindspore版本，某些不同的默认配置参数，也会造成一定的device memory差异；, 能观察到的现象是在train的时候，提前会准备些数据。这个阶段会创建大量的 Python 进程，可能是每个进程会占用一部分内存，最后触发了OOM。目前是如果内存加大16G就行。,python进程占用的话，应该是host memory，就是内存，device memory的话是通常所说的显存;如果是数据处理时出现大量python进程占用内存，可能是数据加载器，或者数据的map处理方法使用了多进程，你可以把数据处理的worker数改小一点，或者明确设置python多进程为false，我记得map方法默认不设置的话走的多线程，但数据加载器默认会走多进程，这个早期版本和现在的版本可能有所不同，可以都明确指定一下看看
pynative mode,徐微,【master】【OPS】【ops.where】【function】where 存在精度问题," MindSpore Where算子CPU与GPU行为不一致Bug报告  1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore中，`ops.where`算子在CPU和GPU设备上执行时产生不一致的结果。具体表现为当条件为True时，CPU正确返回负值，而GPU却将所有负值转换为0。此差异会导致在不同设备上运行相同模型产生不同结果，影响模型一致性和可靠性。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Testcase Name/ 用例名**: where_bug.py  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 准备测试环境，确保同时支持CPU和GPU后端 2. 测试脚本 ```python     import numpy as np     import mindspore as ms     from mindspore import ops     import os     import sys     import subprocess     import time     def test_where_bug(device=""CPU"", test_case=0):         ms.set_device(device)         ms.set_context(mode=ms.PYNATIVE_MODE)         test_cases = [             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1, 2, 3, 4, 5], ms.int32),                 ""desc"": ""基本测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1000000001, 1000000002, 1000000003, 1000000004, 1000000005], ms.int32),                 ""desc"": ""大数值测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1.5], ms.float32),                 ""y"": ms.Tensor([1.1, 2.2, 3.3, 4.4, 5.5], ms.float32),                 ""desc"": ""浮点数测试(float32)""             },         ]         if test_case >= len(test_cases):             test_case = 0         case = test_cases[test_case]         condition, x, y = case[""condition""], case[""x""], case[""y""]          执行操作         result = ops.where(condition, x, y)          保存结果         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         os.makedirs(results_dir, exist_ok=True)         file_name = f""{device.lower()}_case{test_case}_results.npy""         np.save(f'{results_dir}/{file_name}', result.asnumpy())         print(f""{device}结果: {result}"")         return result     def compare_results(test_case=0):         """"""比较CPU和GPU结果""""""         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         cpu_file = f'{results_dir}/cpu_case{test_case}_results.npy'         gpu_file = f'{results_dir}/gpu_case{test_case}_results.npy'         if not os.path.exists(cpu_file) or not os.path.exists(gpu_file):             print(f""错误: 结果文件不存在，请先运行测试"")             return         cpu_result = np.load(cpu_file)         gpu_result = np.load(gpu_file)         are_equal = np.array_equal(cpu_result, gpu_result)         print(f""CPU和GPU结果是否一致: {are_equal}"")         if not are_equal:             diff_indices = np.where(cpu_result != gpu_result)             diff_count = len(diff_indices[0])             total_count = cpu_result.size             diff_percent = 100 * diff_count / total_count             max_abs_diff = np.max(np.abs(cpu_result  gpu_result))             print(f""不匹配元素: {diff_count} / {total_count} ({diff_percent:.1f}%)"")             print(f""最大差值: {max_abs_diff}"")              完整展示结果             np.set_printoptions(suppress=True)   禁止科学计数法             print(f""CPU结果: {cpu_result}"")             print(f""GPU结果: {gpu_result}"")              显示差异索引和对应值             print(f""有差异的索引: {diff_indices[0]}"")             print(f""这些索引处的CPU值: {cpu_result[diff_indices]}"")             print(f""这些索引处的GPU值: {gpu_result[diff_indices]}"")     def run_all_tests():         """"""运行所有测试用例并比较结果""""""         test_cases = 3         print(""="" * 80)         print(""MindSpore Where操作在CPU和GPU上的结果比较"")         print(""="" * 80)         for case in range(test_cases):             print(f""\n测试用例 {case}:"")             print("""" * 60)              在CPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""CPU"", ""case"", str(case)],                          stdout=subprocess.PIPE)              在GPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""GPU"", ""case"", str(case)],                         stdout=subprocess.PIPE)              比较结果             compare_results(case)             print("""" * 60)     if __name__ == ""__main__"":         import argparse         parser = argparse.ArgumentParser(description='MindSpore Where操作Bug复现')         parser.add_argument('device', type=str, choices=['CPU', 'GPU'], default='CPU')         parser.add_argument('case', type=int, default=0)         parser.add_argument('runall', action='store_true',                          help='自动在CPU和GPU上运行所有测试用例并比较结果')         args = parser.parse_args()         if args.run_all:             run_all_tests()         else:             test_where_bug(args.device, args.case) ``` 2. 运行测试脚本，执行所有测试用例并比较结果:    ```bash    python /home/ms/ms_test/Bug_test/where_bug.py runall    ``` 3. 观察比较结果，特别关注负值在不同设备上的处理差异  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: CPU和GPU应产生一致的结果，特别是对于负值的处理应该相同，不应出现GPU自动将负值转为0的情况。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: ``` 测试用例 0:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [ 1 1  3 1 1] GPU结果: [1 0 3 0 0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 1:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [1000000001         1 1000000003         1         1] GPU结果: [1000000001          0 1000000003          0          0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 2:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1.5 CPU结果: [ 1.1 1.5  3.3 1.5 1.5] GPU结果: [1.1 0.  3.3 0.  0. ] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1.5 1.5 1.5] 这些索引处的GPU值: [0. 0. 0.]  ```  7.Special notes for this issue/备注 (Optional / 选填) 1. 问题特征总结:     仅在条件为`True`时且选择值为负值时出现     同时影响整数和浮点数数据类型     问题与广播机制相关，特别是负值标量被广播时 2. 可能的根本原因:     GPU实现中的符号位处理错误     CUDA内核在执行条件选择时可能截断了负值的符号位     掩码操作实现可能存在缺陷",2025-03-27T10:13:49+08:00,mindspore-assistant,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBWMQ7,  
float16,default32423,[Fuzzer] Some KERNEL failure/Unexpected Error issues in MindSpore 2.5.0," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) I encountered several KERNEL failure/Unexpected Error issues in MindSpore 2.5.0. They all produce the following output: ""This exception is caused by an unexpected framework error. Please report this issue at https://gitee.com/mindspore/mindspore/issues for assistance."" These bugs could potentially be exploited to trigger a denialofservice attack. MindSpore should be able to catch these errors and provide graceful error info.  2.Environment / 环境信息 (Mandatory / 必填) Linux CPU  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore 2.5.0  3.Related testcase / 关联用例 (Mandatory / 必填) None  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)  Bug 1: mindspore.mint. nansum Code: ``` import mindspore from mindspore import Tensor from mindspore.mint import nansum def test_bug():     inp = Tensor([])   Empty tensor     output = nansum(inp)     print(""Other error: No error raised when it should have"") if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2662342,7ff909b28640,python):2025032709:12:07.043.566 [mindspore/ccsrc/kernel/kernel.h:952] CheckShapeNull] For 'ReduceSum', the shape of input cannot contain zero, but got [const vector]{0} [ERROR] RUNTIME_FRAMEWORK(2662342,7ff9ebe5a740,python):2025032709:12:07.043.726 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed: The inner_size is zero.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/cpu/masked_fill_cpu_kernel.cc:80 Resize ```  Bug 2: mindspore.mint.scatter Code: ``` import numpy as np import mindspore as ms from mindspore import Tensor, mint def test_bug():     input_tensor = Tensor(np.zeros((5, 5)), dtype=ms.float32)     src_tensor = Tensor(np.array([[1, 2, 3]]), dtype=ms.float32)     index_tensor = Tensor(np.array([[6, 1]]), dtype=ms.int64)   Invalid indices      Trigger the bug condition     output = mint.scatter(input=input_tensor, dim=1, index=index_tensor, src=src_tensor) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [ERROR] KERNEL(2663056,7f446bb23640,python):2025032709:13:51.394.428 [mindspore/ops/kernel/cpu/scatter_cpu_kernel.cc:72] Resize] For 'Scatter', the shape of 'index' and the shape of 'src' should be same, but got index shape: [const vector]{1, 2}; src shape: [const vector]{1, 3}. [ERROR] RUNTIME_FRAMEWORK(2663056,7f454e6c0740,python):2025032709:13:51.394.878 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Scatter] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/common/pyboost/pyboost_utils.cc:386 LaunchKernel ```  Bug 3: mindspore.numpy.stack Code: ``` import subprocess import sys def test_bug():     from mindspore import numpy as np     try:         SIZE1 = 6500         SIZE2 = 4500         concat_list = []         concat_list.append(np.ones((SIZE1, 1024*512), dtype=np.uint8))         concat_list.append(np.ones((SIZE2, 1024*512), dtype=np.uint8))         result = np.stack(concat_list)         print(result.shape)     except Exception as e:         print(""Exception:"", e) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Exception: The int64_t value(887095296) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 4: mindspore.hal.contiguous_tensors_handle.slice_by_padding_shape Code: ``` import mindspore from mindspore.hal.contiguous_tensors_handle import slice_by_padding_shape def test_bug():     dummy_input = mindspore.Tensor([[1, 2], [3, 4]], mindspore.float32)     padding_start = mindspore.Tensor(1, dtype=mindspore.int32)     padding_end = mindspore.Tensor(1, dtype=mindspore.int32)     result = slice_by_padding_shape(dummy_input, padding_start, padding_end) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 9, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 7, in test_bug     result = slice_by_padding_shape(dummy_input, padding_start, padding_end)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The pointer[first_tensor>device_address()] is null.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:244 GetSliceByPaddingShapeHandle ```  Bug 5: mindspore.ops.argmax Code: ``` import numpy as np from mindspore import Tensor from mindspore import ops def test_bug():     empty_tensor = Tensor(np.empty((5, 5, 0), dtype=np.float32))     result = ops.argmax(empty_tensor) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2664438,7f6459474640,python):2025032709:19:35.344.470 [mindspore/ccsrc/kernel/kernel.h:952] CheckShapeNull] For 'Argmax', the shape of input cannot contain zero, but got [const vector]{0} [ERROR] RUNTIME_FRAMEWORK(2664438,7f653b7c6740,python):2025032709:19:35.350.468 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Default/Argmaxop0] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:574 CreateKernel ```  Bug 6: mindspore.amp.constexpr Code: ``` import mindspore as ms from mindspore.amp import constexpr def test_bug():          def constant_calculation(range_num):         out = 0         for i in range(range_num):             out += i           return out     .jit     def my_func(x):         new_shape = constant_calculation(100000)          return ms.ops.broadcast_to(x, (new_shape, ))     x = ms.Tensor([1])     my_func(x) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 17, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 15, in test_bug     my_func(x)   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1016, in staging_specialize     out = _MindsporeFunctionExecutor(func, hash_obj, dyn_args, process_obj, jit_config)(*args, **kwargs)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 190, in wrapper     results = fn(*arg, **kwargs)               ^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 638, in __call__     output = _pynative_executor.grad_jit(*new_inputs)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1568, in grad_jit     output = self._executor.grad_jit(*args)              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The size_t value(4999950000) exceeds the maximum value of int.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:152 LongToInt ```  Bug 7: mindspore.numpy.cumsum Code: ``` import mindspore.numpy as np def test_bug():     t = np.ones(2**31, dtype=np.float16)      t[2**30:] = 1     cum_sum_result = np.cumsum(t) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [ERROR] RUNTIME_FRAMEWORK(2665060,7f8dd0e93740,python):2025032709:22:45.808.168 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed: The int64_t value(2147483648) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 8: mindspore.numpy.dstack Code: ``` import mindspore.numpy as np try:     SIZE1 = 6500     SIZE2 = 4500     concat_list = []      Each tensor has shape: (SIZE, 1024*512)     concat_list.append(np.ones((SIZE1, 1024*512), dtype=np.uint8))     concat_list.append(np.ones((SIZE2, 1024*512), dtype=np.uint8))     result = np.dstack(concat_list)      If dstack somehow succeeds (no segfault), we print the shape.     print(result.shape) except Exception as e:      If any Python exception is raised, print it (though segfault might end the process)     print(""Exception:"", e) ``` Output: ``` Exception: The int64_t value(887095296) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 9: mindspore.hal.contiguous_tensors_handle.cth.slice_by_padding_shape Code: ``` import mindspore import mindspore.hal.contiguous_tensors_handle as cth def test_bug():     x = mindspore.Tensor([[0, 1, 2], [3, 4, 5]], mindspore.float32)     padding_shape = (2, 2)      padded_tensor = cth.slice_by_padding_shape(x, *padding_shape) if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 8, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 6, in test_bug     padded_tensor = cth.slice_by_padding_shape(x, *padding_shape)                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The pointer[first_tensor>device_address()] is null.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:244 GetSliceByPaddingShapeHandle ```  Bug 10: mindspore.numpy.arange Code: ``` import mindspore.numpy as np import mindspore def test_bug():     symbolic_tensor = np.arange(0, mindspore.Tensor(shape=(None,), dtype=mindspore.int32))     output = np.ones_like(symbolic_tensor) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2665960,7f1de8d27640,python):2025032709:27:16.335.885 [mindspore/ccsrc/kernel/kernel.cc:650] Resize] Invalid shape:[const vector]{1}, kernel name:Sub Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 7, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 4, in test_bug     symbolic_tensor = np.arange(0, mindspore.Tensor(shape=(None,), dtype=mindspore.int32))                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 630, in arange     num = _ceil(stop  start)           ^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/primitive.py"", line 939, in __call__     return fn(*args, **kwargs)            ^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/utils_const.py"", line 517, in _ceil     return math.ceil(number)            ^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/tensor.py"", line 372, in __float__     data = self.asnumpy()            ^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/_stub_tensor.py"", line 50, in fun     return method(*arg, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/tensor.py"", line 1036, in asnumpy     return Tensor_.asnumpy(self)            ^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The int64_t value(1) is less than 0.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:66 LongToSize ```  Bug 11: mindspore.ops.vmap Code: ``` from mindspore.mint import arange import mindspore batch_arange = mindspore.ops.vmap(lambda start, end, step: arange(start, end, step)) start = mindspore.Tensor([1., 2., 3.]) end = mindspore.Tensor([25., 26., 27.]) step = mindspore.Tensor([1, 1, 1])   Specify a constant step  When using the batched operation, check if the bug condition is triggered batch_arange(start, end, step) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] UTILS(2666424,7fb27acc4740,python):2025032709:28:52.791.845 [mindspore/ccsrc/utils/comm_manager.cc:80] GetInstance] CommManager instance for CPU not found, return default instance. Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 8, in      batch_arange(start, end, step)   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1016, in staging_specialize     out = _MindsporeFunctionExecutor(func, hash_obj, dyn_args, process_obj, jit_config)(*args, **kwargs)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 190, in wrapper     results = fn(*arg, **kwargs)               ^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 631, in __call__     raise err   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 625, in __call__     phase = self.compile(self.fn.__name__, *args_list, **kwargs)             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 729, in compile     is_compile = self._graph_executor.compile(self.fn, compile_args, kwargs, phase, True)                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ TypeError: Parse Lambda Function Fail. Node type must be Lambda, but got Call. Please check lambda expression to make sure it is defined on a separate line.  For example, the code 'func = nn.ReLU() if y      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 11, in test_bug     gradient = vjp_fn(v)                ^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py"", line 968, in wrap_container     return _vjp_grad_op(fn_)(*inputs, sens)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/composite/base.py"", line 645, in after_grad     return grad_(fn_)(*args, **kwargs)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 190, in wrapper     results = fn(*arg, **kwargs)               ^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/composite/base.py"", line 618, in after_grad     out = _pynative_executor.grad(fn, grad_, weights, grad_position, *run_args)           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/api.py"", line 1538, in grad     return self._executor.grad(grad, obj, weights, grad_position, *args)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ RuntimeError: Failure info [The given sens gradient's size should be same as out of network!].   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/pynative/grad/function/func_grad.cc:1234 CheckSensShapeAndType ```  Bug 13: mindspore.numpy.ones_like Code: ``` import mindspore.numpy as np import mindspore.ops as ops import mindspore as ms def test_bug():     shape = (1024 * 256 + 1, 8192)     device = ms.context.get_context(""device_target"")      dtype = ms.float16      x = np.ones(shape, dtype=dtype)     y = np.tanh(x)     y_grad = np.ones_like(y)      y.backward(y_grad)  if __name__ == ""__main__"":     test_bug() ``` Output: ``` Traceback (most recent call last):   File ""/export/d2/******/mindspore/test.py"", line 14, in      test_bug()   File ""/export/d2/******/mindspore/test.py"", line 10, in test_bug     y_grad = np.ones_like(y)               ^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 1092, in ones_like     return _x_like(a, dtype, shape, ones)            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 1010, in _x_like     dtype_out = _get_dtype(prototype)                 ^^^^^^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/numpy/array_creations.py"", line 996, in _get_dtype     return array_like.dtype            ^^^^^^^^^^^^^^^^   File ""/export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/common/_stub_tensor.py"", line 100, in dtype     self.stub_dtype = self.stub.get_dtype()                       ^^^^^^^^^^^^^^^^^^^^^ RuntimeError: The size_t value(2147491840) exceeds the maximum value of int.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/core/include/utils/convert_utils_base.h:34 SizeToInt ```  Bug 14: mindspore.ops.argmax Code: ``` import numpy as np from mindspore import Tensor from mindspore import ops def test_bug():     g = Tensor(np.empty((0, 4), dtype=np.float32))     result = ops.argmax(g) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] KERNEL(2668082,7f929cb74640,python):2025032709:37:35.898.328 [mindspore/ccsrc/kernel/kernel.h:952] CheckShapeNull] For 'Argmax', the shape of input cannot contain zero, but got [const vector]{0} [ERROR] RUNTIME_FRAMEWORK(2668082,7f937ef28740,python):2025032709:37:35.898.748 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Default/Argmaxop0] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:574 CreateKernel ```  Bug 15:  Code: ``` import mindspore from mindspore import nn, Tensor from mindspore import jacfwd import numpy as np class MyNet(nn.Cell):     def __init__(self, n_input, hidden_size):         super(MyNet, self).__init__()         self.layer = nn.LSTM(input_size=n_input, hidden_size=hidden_size)         self.layer_out = nn.Dense(hidden_size, 1)     def construct(self, x):         jacobian = jacfwd(self.RNN_forward)(x)         return jacobian     def RNN_forward(self, x):         output, _ = self.layer(x)         return self.layer_out(output) def test_bug():     try:         batch = 10         seq_len = 12         net = MyNet(n_input=3, hidden_size=20)         x = Tensor(np.random.rand(batch, seq_len, 3).astype(np.float32))         _ = net(x)         print(""No bug: forward pass completed without error"")     except Exception as e:         err_msg = str(e)         if ""some_error_keyword"" in err_msg:              pass         else:             print(f""Other error: {err_msg}"") if __name__ == ""__main__"":     test_bug() ``` Output: ``` Other error: Illegal primitive: Primitive LSTMGrad's bprop not defined.node:ValueNode fake_bprop, location:   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/jit/ps/validator.cc:84 ValidateOperatio ```  Bug 16:  Code: ``` from mindspore import jvp, Tensor import mindspore.nn as nn import numpy as np class Dummy:          def __torch_function__(cls, func, types, args=(), kwargs=None):         if kwargs is None:             kwargs = {}         if func is jvp:             return 1         return NotImplemented def test_bug():     try:         x = Dummy()          v = Dummy()          result = jvp(lambda x, y: (x + y, y), (x, x), (v, v))         if result[1] == 1:               pass         else:             pass     except Exception as e:         print(f""Other error: {str(e)}"") if __name__ == ""__main__"":     test_bug() ``` Output: ``` [WARNING] UTILS(2669424,7f1180607740,python):2025032709:41:21.304.174 [mindspore/ccsrc/utils/comm_manager.cc:80] GetInstance] CommManager instance for CPU not found, return default instance. Other error: Parse Lambda Function Fail. Node type must be Lambda, but got Call. Please check lambda expression to make sure it is defined on a separate line.  For example, the code 'func = nn.ReLU() if y < 1 else lambda x: x + 1' rewritten as 'if y < 1:     func = nn.ReLU() else:     func = lambda x: x + 1 'will solve the problem.   Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/pipeline/jit/ps/parse/parse.cc:570 ParseFuncGraph   The Traceback of Net Construct Code:   0 In file /export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py:774, 19~46             return _wrap_container_inner(*arg)                    ^~~~~~~~~~~~~~~~~~~~~~~~~~~  1 In file /export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py:744~747, 8~37         if has_aux:  2 In file /export/d2/secfuzz/anaconda3/envs/mindspore/lib/python3.11/sitepackages/mindspore/ops/function/grad/grad_func.py:747, 22~24             outputs = fn(*jvp_inputs)                       ^~  (See file '/export/d2/******/mindspore/rank_0/om/analyze_fail.ir' for more details. Get instructions about `analyze_fail.ir` at https://www.mindspore.cn/search?inputValue=analyze_fail.ir) ```  Bug 17: mindspore.ops.cdist Code: ``` import numpy as np from mindspore import Tensor, ops def test_bug():     x1 = Tensor(np.random.randn(0, 3, 4).astype(np.float32))   Shape (0, 3, 4)     x2 = Tensor(np.random.randn(1, 2, 4).astype(np.float32))   Shape (1, 2, 4)     actual = ops.cdist(x1, x2, p=2.0) if __name__ == ""__main__"":     test_bug() ``` Output: ``` [ERROR] KERNEL(2669635,7fc653f74640,python):2025032709:43:09.932.604 [mindspore/ops/kernel/cpu/cdist_cpu_kernel.cc:77] Resize] invalid input shape, the batch shape of input0 must be the same as the shape of input1 ,but got 'input0_shape[0]': 0 and 'input1_shape[0]': 1, kernel_name_ Cdist [ERROR] RUNTIME_FRAMEWORK(2669635,7fc7362e9740,python):2025032709:43:09.933.050 [mindspore/ccsrc/runtime/pipeline/async_rqueue.cc:230] WorkerJoin] WorkerJoin failed:    Framework Unexpected Exception Raised:  This exception is caused by framework's unexpected error. Please create an issue at https://gitee.com/mindspore/mindspore/issues to get help.   Kernel build failed: (For framework developers)  CPU kernel op [Default/Cdistop0] resize failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/cpu/hal/hardware/cpu_device_context.cc:574 CreateKernel ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) MindSpore should be able to catch these errors and provide graceful error info.    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-27T09:57:33+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBWMCY
ascend,tanxinglian,[CT][MS][OPS][ops.atleast_3d][function][全量]atleast_3d GE模式存在精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > atleast_3d GE模式存在精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_atleast_3d_float64_8d_4x4x4x3x3x7x5x8_random >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative):Graph >    Excute Mode(e.g., O0\O1\O2)：910A不设置 910B设置为O2 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_f_atleast_3d.py::test_f_atleast_3d_float64_8d_4x4x4x3x3x7x5x8_random  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```        def test_f_atleast_3d_float64_8d_4x4x4x3x3x7x5x8_random():         inputs = Tensor(np.random.randn(4, 4, 4, 3, 3, 7, 5, 8), mstype.float64)         fact = Atleast3dMock(             inputs=[inputs]) >       fact.forward_cmp() ../test_f_atleast_3d.py:442:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_3d_ops.py:129: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_3d_ops.py:103: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_3d_ops.py:100: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[ 2.94048584e01,  1.13336308e01, 3.25421547e01, ...,              1.44889729e+00, 1.31045364e+00,  7...2569e02, 6.89365756e01, 1.86348729e+00, ...,              1.81737331e+00, 9.07001391e01,  9.43350886e01]]]]]]]) data_me = array([[[[[[[ 1.31357033e+00,  1.53292253e01,  9.86229017e01, ...,               4.28676765e01, 2.27885664e+00, 7...6286e01,  2.95932361e01,  2.54707393e01, ...,               2.15095707e+00, 3.26449914e01,  3.97923877e01]]]]]]]) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[ 0.29404858  0.11333631 0.32542155 ... 1.81737331 0.90700139 E         0.94335089] E       data_me_error:[ 1.31357033  0.15329225  0.98622902 ...  2.15095707 0.32644991 E         0.39792388] E       loss:[1.01952175 0.03995595 1.31165056 ... 3.96833038 0.58055148 0.54542701] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productLine=2012%20Laboratories&taskId=8b3ba17d2ed4ffcf3bfce79440b6b48d029e4a43be789fc383ad6d91c173a746&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F&title=CT_mindspore_ascend910a_feature_full_master_124b164ee5_20250326%2009:40:33&productId=mindspore&cidaProjectId=c3a0a966ddcd43158ed878c2783678be&isMergedTask=true&testcaseid=67bacdd29b7077065374f5e0&workspaceId=67de910ef31fc3250cb57b42    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-26T10:40:12+08:00,"gitee,foruda,rca/others,rct/oldrelease,ctl/componenttest",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBWC88,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：atleast3d算子存在精度错误 根因： 非连续输入场景没有拦截，导致精度误差  Fix Solution GE不再支持非连续输入，用例需要你切换到kbk后端执行  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83634 PR合入后daily包回归 测试建议：需要切换执行后端为kbk  Selftest Report & DT Review 用例自测ok 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81245 PR合入时间：2025年/3月/7日 问题是否偶现：否,"GE不再支持非连续输入,已正确拦截，用例需适配 !输入图片说明 !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][ops.atleast_2d/atleast_1d][function][全量]atleast_2d/atleast_1d GE模式存在精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > atleast_2d/atleast_1d GE模式存在精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_atleast_2d_one_input test_f_atleast_2d_float64_8d_4x4x4x3x3x7x5x8_random test_f_atleast_1d_float64_8d_4x4x4x3x3x7x5x8_random >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：910A不设置 910B设置为O2 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_f_atleast_2d.py::test_f_atleast_2d_one_input pytest s v test_f_atleast_2d.py::test_f_atleast_2d_float64_8d_4x4x4x3x3x7x5x8_random pytest s v test_f_atleast_1d.py::test_f_atleast_1d_float64_8d_4x4x4x3x3x7x5x8_random  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       def test_f_atleast_2d_one_input():         x1 = Tensor(np.array(np.random.randn(2, 3)).astype(np.float32))         input_x = x1         fact = Atleast2dMock(inputs=[input_x]) >       fact.forward_cmp() ../test_f_atleast_2d.py:333:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_2d_ops.py:134: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_2d_ops.py:107: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_2d_ops.py:104: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0.710087  , 0.15930213, 0.9889787 ]], dtype=float32) data_me = array([[ 1.2614635 , 0.04235008, 1.9021045 ]], dtype=float32) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_f_atleast_2d.py:349:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_2d_ops.py:134: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_2d_ops.py:107: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_2d_ops.py:104: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[6.47150725e01,  5.55300267e01, 3.28036543e01, ...,               2.40420912e01, 3.99763457e02, 1...7864e01,  9.67802708e01, 1.09830324e+00, ...,              2.69247352e01,  1.40805548e01, 1.77464795e+00]]]]]]]) data_me = array([[[[[[[ 8.13775657e01,  8.72998526e01, 2.32492671e+00, ...,              3.59323163e01,  9.72418807e02, 1...1129e+00,  2.57996330e01, 1.27029780e+00, ...,              3.75397298e01, 8.99975487e01,  5.46112136e01]]]]]]]) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_f_atleast_1d.py:441:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/atleast_1d_ops.py:129: in forward_cmp     self.allclose_recursive(data_expected, data_me, self.loss, self.loss) ../../share/ops/functional/atleast_1d_ops.py:103: in allclose_recursive     self.allclose_recursive(e, d, rtol, atol, equal_nan) ../../share/ops/functional/atleast_1d_ops.py:100: in allclose_recursive     allclose_nparray(data_expected, data_me, rtol, atol, equal_nan=equal_nan) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[ 1.92223194e+00,  1.19662758e+00,  1.57134805e+00, ...,               5.36740821e01, 6.18361852e02,  1...3960e01, 1.17214672e01, 1.08765067e+00, ...,              2.25559525e01, 4.03151114e01,  1.52303502e01]]]]]]]) data_me = array([[[[[[[ 4.48446527e01,  1.95218101e+00,  8.26326072e01, ...,              8.63563393e01, 5.87472310e01, 1...5818e01,  1.75759792e+00, 4.45418779e01, ...,              4.74295572e01,  6.99296377e01,  1.11847999e02]]]]]]]) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[ 1.92223194  1.19662758  1.57134805 ... 0.22555952 0.40315111 E         0.1523035 ] E       data_me_error:[ 0.44844653  1.95218101  0.82632607 ... 0.47429557  0.69929638 E         0.0111848 ] E       loss:[1.47378541 0.75555342 0.74502198 ... 0.24873605 1.10244749 0.1411187 ] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007:58:12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67babc824503c84f0a0558a2&workspaceId=67dec2d0e00c6b20d42488d0 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03mb1082tjvbv/&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007%3A58%3A12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67babc7e4503c84f0a0557da&workspaceId=67dec2d0e00c6b20d42488d0 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=/03200tqk2t5d0/03o5107oo9agj/03mb1082tjvbv/&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007%3A58%3A12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67bad65584dee72f16df2e9e&workspaceId=67de910ef31fc3250cb57b42    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-25T18:51:03+08:00,"gitee,foruda,rca/others,rct/oldrelease,ctl/componenttest",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBW7SZ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,问题：GE模式，atleast_2d/atleast_1d 当输入参数为\*Tensor时，计算结果错误。 定位：接口只调用了ExpandDIms算子增加维度，并未修改输入数据内容，dump算子输入输出数据发现，后端处理后给到算子输入错误（第二个输入与第一个输入重复，原始第二个输入丢失）。测试其它算子例如addn，当输入为\*Tensor时，计算结果同样错误，错误类型与atleast_2d一致。 原始输入： !输入图片说明 dump addn输入： !输入图片说明,问题根因：GE后端解耦 https://gitee.com/mindspore/mindspore/pulls/82691 引入，之前GE会自动把Tensor转成连续的，但是需要依赖aclnn算子，为了保证GE后端的独立性，解耦后，不再做Tensor非连续到连续的转换，而是换成Tensor是否连续的校验，对应的代码改动如下： !输入图片说明, Appearance & Root Cause 问题：atleast算子存在精度错误 根因： 非连续输入场景没有拦截，导致精度误差  Fix Solution GE不再支持非连续输入，用例需要你切换到kbk后端执行  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83634 PR合入后daily包回归 测试建议：需要切换执行后端为kbk  Selftest Report & DT Review 用例自测ok 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81245 PR合入时间：2025年/3月/7日 问题是否偶现：否,"GE不再支持非连续输入,已正确拦截，用例需适配 !输入图片说明 !输入图片说明 !输入图片说明 !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][ops.Adam/nn.Adam][function][全量][dvm]Adam O1模式偶现计算结果与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.Adam O1模式偶现计算结果与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_n_adam_forward_inputn_16_inputc_1024_outputc_16_bias_false_lr_0001_epoch_1_dtype_fp16 test_p_adam_input_6d_f32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O1 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O1 export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_n_adam.py::test_n_adam_forward_inputn_16_inputc_1024_outputc_16_bias_false_lr_0001_epoch_1_dtype_fp16 count 30 pytest s v  test_adam.py::test_p_adam_input_6d_f32 count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason=""SoftmaxCrossEntropyWithLogits does not support float16"")     (reason='tensorflow 不支持float16输入，输出为nan, id=I8T821')     def test_n_adam_forward_inputn_16_inputc_1024_outputc_16_bias_false_lr_0001_epoch_1_dtype_fp16(             amsgrad=False):         fact = AdamFactory(input_n=16, input_c=1024, output_c=16, has_bias=False, epoch=1, lr=1e3,                            beta1=0.9, beta2=0.999, eps=1e8, weight_decay=0.0, loss_scale=1.0,                            locking=False, nesterov=False, amsgrad=amsgrad, dtype=np.float16)         fact.loss = 0.01 >       fact.forward_cmp() ../test_n_adam.py:42:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/nn/adam_ops.py:143: in forward_cmp     allclose_nparray(out_tf, out_me, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,         nan, nan, nan],        [nan, nan, nan... nan],        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,         nan, nan, nan]], dtype=float16) data_me = array([[ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,          nan,  nan,  nan,  nan,  nan],      ...nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,          nan,  nan,  nan,  nan,  nan]], dtype=float16) rtol = 0.01, atol = 0.01     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)        fact.forward_cmp() ../test_adam.py:181:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/primitive/adam_ops.py:112: in forward_cmp     allclose_nparray(exp_var, out_var[0], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[ 5.18   ,  5.36   ],            [ 5.754  ,  3.414  ]],           [[ 3.557  , 11.41   ],            ...    [  0.5723 ,  3.71   ]],           [[ 3.9    ,  4.684  ],            [  0.0703 ,  4.582  ]]]]]], dtype=float16) data_me = array([[[[[[ 5.18   ,  5.355  ],            [ 5.76   ,  3.412  ]],           [[ 3.557  , 11.41   ],            ...    [  0.5723 ,  3.71   ]],           [[ 3.9    ,  4.68   ],            [  0.07227,  4.582  ]]]]]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[5.754   0.11816 3.895   2.574   2.635   4.215   0.09766  0.5854 E         0.0703 ] E       data_me_error:[5.76    0.1211  3.887   2.57    2.639   4.207   0.0996   0.5806 E         0.07227] E       loss:[0.007812 0.00293  0.007812 0.003906 0.003906 0.007812 0.001953 0.004883 E        0.001953] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199040&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_dvm_20250322%2021:47:08&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67bea9c24503c84f0a137e34&workspaceId=67df83e7a3913b4f08c4a32a https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199040&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_dvm_20250322%2021:47:08&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67ba28957b13446a61503ef8&workspaceId=67e0a68a8dd14476536a316d    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-25T17:10:35+08:00,"gitee,foruda,ctl/componenttest,rct/bugfix,rca/codelogic",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBW6I7,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否," Appearance & Root Cause 问题：O1模式下，Adam算子偶现精度问题 根因： 1、 O1模式的算子实现中，手动使用结合律和交换律化简了一些表达式。这种化简在fp16下，部分场景会导致精度于tensorflow不一致。  Fix Solution 严格按照Adam论文中给出的公式进行计算  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83576 PR合入后daily包回归 测试建议：使用现有用例进行测试即可。  Selftest Report & DT Review ``` pytest v test_adam.py::test_p_adam_input_6d_f32 count 30 ======================================================================================================== test session starts ========================================================================================================= platform linux  Python 3.9.19, pytest8.3.1, pluggy1.5.0  /home/duxin/miniconda3/envs/py3.9/bin/python cachedir: .pytest_cache rootdir: /home/duxin/MindSporeTest/operations plugins: xdist3.6.1, repeat0.9.3 collected 30 items test_adam.py::test_p_adam_input_6d_f32[130] PASSED [ 3%] test_adam.py::test_p_adam_input_6d_f32[230] PASSED [ 6%] test_adam.py::test_p_adam_input_6d_f32[330] PASSED [ 10%] test_adam.py::test_p_adam_input_6d_f32[430] PASSED [ 13%] test_adam.py::test_p_adam_input_6d_f32[530] PASSED [ 16%] test_adam.py::test_p_adam_input_6d_f32[630] PASSED [ 20%] test_adam.py::test_p_adam_input_6d_f32[730] PASSED [ 23%] test_adam.py::test_p_adam_input_6d_f32[830] PASSED [ 26%] test_adam.py::test_p_adam_input_6d_f32[930] PASSED [ 30%] test_adam.py::test_p_adam_input_6d_f32[1030] PASSED [ 33%] test_adam.py::test_p_adam_input_6d_f32[1130] PASSED [ 36%] test_adam.py::test_p_adam_input_6d_f32[1230] PASSED [ 40%] test_adam.py::test_p_adam_input_6d_f32[1330] PASSED [ 43%] test_adam.py::test_p_adam_input_6d_f32[1430] PASSED [ 46%] test_adam.py::test_p_adam_input_6d_f32[1530] PASSED [ 50%] test_adam.py::test_p_adam_input_6d_f32[1630] PASSED [ 53%] test_adam.py::test_p_adam_input_6d_f32[1730] PASSED [ 56%] test_adam.py::test_p_adam_input_6d_f32[1830] PASSED [ 60%] test_adam.py::test_p_adam_input_6d_f32[1930] PASSED [ 63%] test_adam.py::test_p_adam_input_6d_f32[2030] PASSED [ 66%] test_adam.py::test_p_adam_input_6d_f32[2130] PASSED [ 70%] test_adam.py::test_p_adam_input_6d_f32[2230] PASSED [ 73%] test_adam.py::test_p_adam_input_6d_f32[2330] PASSED [ 76%] test_adam.py::test_p_adam_input_6d_f32[2430] PASSED [ 80%] test_adam.py::test_p_adam_input_6d_f32[2530] PASSED [ 83%] test_adam.py::test_p_adam_input_6d_f32[2630] PASSED [ 86%] test_adam.py::test_p_adam_input_6d_f32[2730] PASSED [ 90%] test_adam.py::test_p_adam_input_6d_f32[2830] PASSED [ 93%] test_adam.py::test_p_adam_input_6d_f32[2930] PASSED [ 96%] test_adam.py::test_p_adam_input_6d_f32[3030] PASSED [100%] ``` 是否需要补充 ST/UT：否（对现有ST用例进行修改）。 原因：已有ST用例，更改ST用例的输入数据构造方法，即可对该场景进行看护。  Introduction Analysis 引入类型：特性合入引入 引入PR：Not Applicable PR合入时间：2020/03/27 问题是否偶现：是",附：Tensorflow ApplyAdamKernel gpu kernel 计算逻辑： !输入图片说明,"【回归版本号】：__commit_id__ = '[sha1]:45e5acc8,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][mint.div][function][全量]mint.div ascend偶现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.div ascend偶现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_f_div_float64_6d_4x3x9x5x7x7_random_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910B：设置O0 910A:不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_JIT_LEVEL=O0 export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_mint_f_div.py::test_mint_f_div_float64_6d_4x3x9x5x7x7_random_broadcast count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_mint_f_div_float64_6d_4x3x9x5x7x7_random_broadcast():         input_x = Tensor(np.random.randn(4, 3, 9, 5, 7, 7), mstype.float64)         other = Tensor(np.random.randn(4, 3, 1, 5, 7, 7), mstype.float64)         rounding_mode = None         fact = DivMock(             attributes={'rounding_mode': rounding_mode},             inputs=[input_x, other])         fact.forward_cmp() >       fact.grad_cmp() ../test_mint_f_div.py:508:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/functional/div_mint.py:212: in grad_cmp     allclose_nparray(grad_pytorch[1], grad_mindspore[1], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[1.78287809e+00, 9.36672920e+00,  5.78629671e+02, ...,             1.66045571e+00,  4.02752162e+00,  2.8...322961e+01, 1.10456732e+03, 2.80809809e01, ...,             5.81548591e+00, 2.55709396e+00, 6.68863395e+00]]]]]]) data_me = array([[[[[[1.78287827e+00, 9.36672988e+00,  5.78629658e+02, ...,             1.66045559e+00,  4.02752160e+00,  2.8...322967e+01, 1.10456733e+03, 2.80809797e01, ...,             5.81548641e+00, 2.55709395e+00, 6.68863375e+00]]]]]]) rtol = 1e05, atol = 1e05     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0.21975757] E       data_me_error:[0.21973163] E       loss:[2.59418196e05] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199039&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910b_op_pynative_standalone_full_20250323%2000:20:07&isMergedTask=false&nodeDate=20250323&year=20242025&TestNow=true&testcaseid=67ba43cea052d7325367a917&workspaceId=67e03b336ae691186d6dbe23    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-25T16:56:58+08:00,"gitee,foruda,rct/oldrelease,ctl/componenttest,rca/algorithm",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBW699,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：偶现精度问题 根因： MindSpore与Pytorch对other反向的计算顺序不一致（数学上等价） ms计算顺序：`dy =  (dout / y * out)` pt计算顺序：`dy =  dout * ((x / y) / y )`  Fix Solution 计算顺序完全对齐Pytorch  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83814 PR合入后daily包回归 测试建议：无。  Selftest Report & DT Review !输入图片说明 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/64084 PR合入时间：2024年4月17日 问题是否偶现：是,"【回归版本号】：__commit_id__ = '[sha1]:119b7ec4,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][ops.xlogy][function][全量]xlogy GE模式报错RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > xlogy GE模式报错RuntimeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_p_xlogy_input_3d_float64 test_f_xlogy_float64_6d_3x3x4x9x4x5_random_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_xlogy.py::test_p_xlogy_input_3d_float64 pytest s v test_f_xlogy.py::test_f_xlogy_float64_6d_3x3x4x9x4x5_random_broadcast  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason=""aclnn不支持"")     (reason=""aclnn不支持"")     (reason=""aclnn不支持"")     def test_p_xlogy_input_3d_float64():         input_x1 = np.random.randn(7, 6, 12).astype(np.float64)         input_x2 = np.random.randn(7, 6, 12).astype(np.float64)         dtype = np.float64         fact = XlogyMock(inputs=[input_x1, input_x2], dtype=dtype)         fact.forward_cmp() >       fact.grad_cmp() ../test_xlogy.py:185:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/primitive/xlogy_ops.py:107: in grad_cmp     input_grad_mindspore = self.grad_mindspore_impl() ../../share/ops/primitive/xlogy_ops.py:73: in grad_mindspore_impl     input_grad = grad_net(x1, x2, output_grad) ../../share/grad.py:39: in __call__     out = super().__call__(*inputs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1135: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1576: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1558: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = GradOfAllInputs(   (network): WrapOp() ) phase = 'train.1742640611478836224.140236752847152.2...', do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[7, 6, 12], dtype=Float64, value= [[[ 4.92374478e01, 1.21381368e+00,  5.47682373e01 ...  1.71437941e+...0e01],   [ 1.19023335e+00,  1.13959236e+00, 7.52813579e01 ...  4.80040582e01, 3.20836256e+00, 8.71049552e01]]])) kwargs = {}, key_id = '1402367528471521742640611478836224', key = 2 parameter_ids = '', raw_phase = 'train' full_function_name = 'GradOfAllInputs.2.94219103284192' echo_function_name = 'GradOfAllInputs'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         _init_auto_parallel_context(obj)         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             _clear_auto_parallel_context(obj)             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         gc.collect() >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: Compile graph kernel_graph2 failed. E        E        E        Ascend Error Message: E        E       EZ3002: [PID: 1068243] 2025032218:50:12.128.532 Optype [MaskedFill] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[Dynamic shape check]: data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}[Static shape check]:data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}.[THREAD:1071846] E               Possible Cause: The operator type is unsupported in the operator information library due to specification mismatch. E               Solution: Submit an issue to request for support at https://gitee.com/ascend, or remove this type of operators from your model. E               TraceBack (most recent call last): E               Optype [MaskedFill] of Ops kernel [aicpu_ascend_kernel] is unsupported. Reason: data_type DT_DOUBLE of input[0, x] is unsupported, op type[MaskedFill]..[THREAD:1071846] E               No supported Ops kernel and engine are found for [Gradients/Default/networkWrapOp/Grad_Xlogy/MaskedFillop0], optype [MaskedFill].[THREAD:1071846] E               Assert ((SelectEngine(node_ptr, exclude_engines, is_check_support_success, op_info)) == ge::SUCCESS) failed[FUNC:operator()][FILE:engine_place.cc][LINE:148][THREAD:1071846] E               RunAllSubgraphs failed, graph=kernel_graph2.[FUNC:RunAllSubgraphs][FILE:engine_place.cc][LINE:122][THREAD:1068243] E               [Call][PreRun] Failed, graph_id:3, session_id:0.[FUNC:CompileGraph][FILE:graph_manager.cc][LINE:4538][THREAD:1068243] E               [Compile][Graph]Compile graph failed, error code:1343225857, session_id:0, graph_id:3.[FUNC:CompileGraph][FILE:ge_api.cc][LINE:1279][THREAD:1068243] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/backend/ge_backend/executor/ge_graph_executor.cc:482 CompileGraph /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1958: RuntimeError ``` ```       (reason=""aclnn not support float64"")     (reason=""aclnn not support float64"")     (reason=""aclnn not support float64"")     def test_f_xlogy_float64_6d_3x3x4x9x4x5_random_broadcast():         input_x = Tensor(np.random.randn(3, 3, 4, 9, 4, 5), mstype.float64)         other = Tensor(np.random.randn(3, 1, 4, 9, 4, 5), mstype.float64)         fact = XlogyMock(             inputs=[input_x, other])         if context.get_context(""device_target"") == ""Ascend"":              标杆pytorch 1.12.0 及mindspore 在Acsend上出现nan             fact.forward_mindspore_impl() >           fact.grad_mindspore_impl() ../test_f_xlogy.py:518:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/xlogy_ops.py:142: in grad_mindspore_impl     grad = grad_net(self.input_x, self.other_x, out_grad_ms) ../../share/grad.py:39: in __call__     out = super().__call__(*inputs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1135: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1576: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1558: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = GradOfAllInputs(   (network): WrapOp() ) phase = 'train.1742598079894010624.140663141206992.2...', do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[3, 3, 4, 9, 4, 5], dtype=Float64, value= [[[[[[ 8.33213459e01, 1.99972164e+00, 1.29058858e+00,  2.77...02,  1.85621055e02],      [ 1.99988942e+00, 1.20096894e+00, 4.71020176e01,  9.31564313e01, 1.15255923e+00]]]]]])) kwargs = {}, key_id = '1406631412069921742598079894010624', key = 2 parameter_ids = '', raw_phase = 'train' full_function_name = 'GradOfAllInputs.2.94640366888464' echo_function_name = 'GradOfAllInputs'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         _init_auto_parallel_context(obj)         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             _clear_auto_parallel_context(obj)             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict)         gc.collect() >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: Compile graph kernel_graph2 failed. E        E        E        Ascend Error Message: E        E       EZ3002: [PID: 2003449] 2025032207:01:20.624.712 Optype [MaskedFill] of Ops kernel [AIcoreEngine] is unsupported. Reason: [tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[tbecustom]:op type MaskedFill is not found in this op store.[tbecustom1]:op type MaskedFill is not found in this op store.[tbecustom2]:op type MaskedFill is not found in this op store.[tbecustom3]:op type MaskedFill is not found in this op store.[tbecustom4]:op type MaskedFill is not found in this op store.[tbecustom5]:op type MaskedFill is not found in this op store.[tbecustom6]:op type MaskedFill is not found in this op store.[tbecustom7]:op type MaskedFill is not found in this op store.[tbecustom8]:op type MaskedFill is not found in this op store.[tbecustom9]:op type MaskedFill is not found in this op store.[tbecustom10]:op type MaskedFill is not found in this op store.[tbecustom11]:op type MaskedFill is not found in this op store.[tbecustom12]:op type MaskedFill is not found in this op store.[tbecustom13]:op type MaskedFill is not found in this op store.[tbecustom14]:op type MaskedFill is not found in this op store.[Dynamic shape check]: data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}[Static shape check]:data type DT_DOUBLE of input [x] is not supported. All supported data type and format of tensor input0.x is: Data Type: {DT_FLOAT16,DT_FLOAT,DT_INT8,DT_INT32,DT_BOOL}Format:{ND,ND,ND,ND,ND}.[THREAD:2009404] E               Possible Cause: The operator type is unsupported in the operator information library due to specification mismatch. E               Solution: Submit an issue to request for support at https://gitee.com/ascend, or remove this type of operators from your model. E               TraceBack (most recent call last): E               Optype [MaskedFill] of Ops kernel [aicpu_ascend_kernel] is unsupported. Reason: data_type DT_DOUBLE of input[0, x] is unsupported, op type[MaskedFill]..[THREAD:2009404] E               No supported Ops kernel and engine are found for [Gradients/Default/networkWrapOp/Grad_Xlogy/MaskedFillop0], optype [MaskedFill].[THREAD:2009404] E               Assert ((SelectEngine(node_ptr, exclude_engines, is_check_support_success, op_info)) == ge::SUCCESS) failed[FUNC:operator()][FILE:engine_place.cc][LINE:148][THREAD:2009404] E               RunAllSubgraphs failed, graph=kernel_graph2.[FUNC:RunAllSubgraphs][FILE:engine_place.cc][LINE:122][THREAD:2003449] E               [Call][PreRun] Failed, graph_id:3, session_id:0.[FUNC:CompileGraph][FILE:graph_manager.cc][LINE:4538][THREAD:2003449] E               [Compile][Graph]Compile graph failed, error code:1343225857, session_id:0, graph_id:3.[FUNC:CompileGraph][FILE:ge_api.cc][LINE:1279][THREAD:2003449] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/backend/ge_backend/executor/ge_graph_executor.cc:482 CompileGraph /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1958: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007:58:12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67ba374c4503c84f0a03a079&workspaceId=67de9aa3f31fc3250cb5941d https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199063&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250322%2007:58:12&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67bade0c7b13446a6152933c&workspaceId=67ddf0e9e00c6b20d42232c3    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-24T18:33:38+08:00,"gitee,foruda",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBVWSW,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否, Appearance & Root Cause 问题：接口变更，GE回退double类型支持 根因： 接口变更，GE回退double类型支持，测试仓用例未及时适配  Fix Solution 无需修复  Fix Description & Test Suggestion 无 测试建议：无  Selftest Report & DT Review 无 是否需要补充 ST/UT：否 原因：非基本功能问题  Introduction Analysis 引入类型：用例未适配 引入PR：无 PR合入时间：年/月/日 问题是否偶现：是/否,接口变更 适配用例 !输入图片说明
ascend,tanxinglian,[CT][MS][OPS][mint.fmod][function][全量]test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast报错计算结果类型与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast报错计算结果类型与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b:设置O0,910a:不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_mint_f_fmod.py::test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     ()     def test_mint_f_fmod_float64_4d_39x1x19x8_random_broadcast():         input_x = Tensor(np.random.randn(39, 1, 19, 1), mstype.float32)         other = Tensor(np.random.randn(39, 1, 1, 8), mstype.float64)         fact = FmodMock(             inputs=[input_x, other]) >       fact.forward_cmp() ../test_mint_f_fmod.py:592:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =      def forward_cmp(self):         out_mindspore = self.forward_mindspore_impl()         out_cmp = self.forward_pytorch_impl()          torch cpu 输入tensor uint8+ 数字float,输出类型是float32,ms 与pta 输出类型都是uint8         if self.ms_type not in (mstype.bfloat16,): >           assert out_cmp.dtype == out_mindspore.dtype E           AssertionError ../../share/mint/functional/fmod_mint.py:174: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2407259351036199064&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250322%2005:48:44&isMergedTask=false&nodeDate=20250322&year=20242025&TestNow=true&testcaseid=67dee355f31fc3250cb644e1&workspaceId=67dee353e00c6b20d424fec0&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-24T18:17:01+08:00,"foruda,rca/others,rct/oldrelease,ctl/componenttest",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBVWMS,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否," Appearance & Root Cause 问题：mint.fmod, tensor类型分别为float32和float64是输出类型不正确 根因：未正确的进行类型提升  Fix Solution 修改 InferType 实现  Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83547 重写了InferType函数逻辑  Selftest Report & DT Review !输入图片说明 本地自验通过 是否需要补充ST/UT：否 原因：已有UT  Introduction Analysis 引入类型：Bugfix修复引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82978 PR合入时间：2025/3/18 问题是否偶现：否","【回归版本号】：__commit_id__ = '[sha1]:4459ab4c,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明 !输入图片说明"
ge backend,tanxinglian,"[CT][MS][OPS][nn.proximaladagrad][function][全量]nn.proximaladagrad 910A pynative模式报错RuntimeError: The ge backend only support contiguous inputs, please check."," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > nn.proximaladagrad 910A pynative模式报错RuntimeError: The ge backend only support contiguous inputs, please check.  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_n_proximaladagrad_gatherv2_3x4x1_0x1_axis_1 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置 >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：（1）export SLOG_PRINT_TO_STDOUT=1 export GLOG_v=2 export ME_OPINFO=1 export NPU_ASD_ENABLE=1 export CIDA_TESTBOT=1 export MS_ASCEND_CHECK_OVERFLOW_MODE=INFNAN_MODE export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_n_proximaladagrad.py::test_n_proximaladagrad_gatherv2_3x4x1_0x1_axis_1  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```  ()     def test_n_proximaladagrad_gatherv2_3x4x1_0x1_axis_1():         fact = ProximalAdagradFactory((3, 4, 1), (0, 1), (2, 3), epoch=2,                                       accum=0.1, learning_rate=0.01, l1=0.0,                                       l2=0.0, use_locking=False, loss_scale=1.0,                                       weight_decay=0.0, axis=1, dtype1=np.float32, dtype2=np.int32) >       fact.forward_cmp() test_n_proximaladagrad.py:157: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../share/ops/nn/proximaladagrad_ops.py:114: in forward_cmp     out_me = self.forward_mindspore_impl() ../share/ops/nn/proximaladagrad_ops.py:84: in forward_mindspore_impl     train_network(inputs, label) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1146: in __call__     return self.construct(*args, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/wrap/cell_wrapper.py:429: in construct     return self._no_sens_impl(*inputs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/wrap/cell_wrapper.py:451: in _no_sens_impl     loss = F.depend(loss, self.optimizer(grads)) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1146: in __call__     return self.construct(*args, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:1193: in staging_specialize     out = ms_function_executor(*args, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:193: in wrapper     results = fn(*arg, **kwargs) /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:647: in __call__     output = _pynative_executor.grad_jit(*new_inputs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self =  args = ((Tensor(shape=[3, 4, 1], dtype=Float32, value= [[[ 1.66666672e01],   [ 1.66666672e01],   [ 0.00000000e+00],   [ 0.0...0e+00],   [ 0.00000000e+00]],  [[ 1.66666672e01],   [ 1.66666672e01],   [ 0.00000000e+00],   [ 0.00000000e+00]]]),),)     def grad_jit(self, *args):         """"""         Building grad graph decorated by jit.         Args:             args (tuple): Function or cell decorated by jit input arguments.         Return:             output: The output object of function or cell decorated by jit.         """""" >       output = self._executor.grad_jit(*args) E       RuntimeError: The ge backend only support contiguous inputs, please check. E E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/backend/ge_backend/ge_backend.cc:98 CheckContiguousTensor E E        E        The Traceback of Net Construct Code: E        E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/proximal_ada_grad.py:204~222, 4~22 E            E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/proximal_ada_grad.py:212, 16~53 E               grads = self._grad_sparse_indices_deduplicate(grads) E                       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/optimizer.py:520~524, 4~24 E           def _grad_sparse_indices_deduplicate(self, gradients): E           ^ E E        In file /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/nn/optim/optimizer.py:523, 24~77 E                   gradients = self.map_(F.partial(_indices_deduplicate), gradients) E                               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ /home/miniconda3/envs/txl310/lib/python3.10/sitepackages/mindspore/common/api.py:1618: RuntimeError ``` 完整日志（通过附件上传）：    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-24T18:01:32+08:00,"gitee,foruda,rca/others,ctl/componenttest,rct/newfeature",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBVWFH,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 910A jit默认后端和图模式保持一致，从ms_backend（kbk）改为GE，由于后端解耦后新GE后端仅支持整图下沉和lazyinline，有部分在910A上使用pynative+jit的场景需要进行适配（框架+网络） Fix Solution 框架及网络ge不支持部分jit用kbkpao Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83405 PR合入后daily包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82147 PR合入时间：2025年/3月/14日 问题是否偶现：否,"【回归版本号】：__commit_id__ = '[sha1]:067a7b32,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
pynative mode,徐微,"【master】【OPS】【ops.where】【CPU,GPU】 Where算子CPU与GPU运行结果不一致"," MindSpore Where算子CPU与GPU行为不一致Bug报告  1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在MindSpore中，`ops.where`算子在CPU和GPU设备上执行时产生不一致的结果。具体表现为当条件为True时，CPU正确返回负值，而GPU却将所有负值转换为0。此差异会导致在不同设备上运行相同模型产生不同结果，影响模型一致性和可靠性。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  **Testcase Name/ 用例名**: where_bug.py  **Excute Mode / 执行模式**:    PyNative Mode    O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 准备测试环境，确保同时支持CPU和GPU后端 2. 测试脚本 ```python     import numpy as np     import mindspore as ms     from mindspore import ops     import os     import sys     import subprocess     import time     def test_where_bug(device=""CPU"", test_case=0):         ms.set_device(device)         ms.set_context(mode=ms.PYNATIVE_MODE)         test_cases = [             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1, 2, 3, 4, 5], ms.int32),                 ""desc"": ""基本测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1], ms.int32),                 ""y"": ms.Tensor([1000000001, 1000000002, 1000000003, 1000000004, 1000000005], ms.int32),                 ""desc"": ""大数值测试(int32)""             },             {                 ""condition"": ms.Tensor([False, True, False, True, True], ms.bool_),                 ""x"": ms.Tensor([1.5], ms.float32),                 ""y"": ms.Tensor([1.1, 2.2, 3.3, 4.4, 5.5], ms.float32),                 ""desc"": ""浮点数测试(float32)""             },         ]         if test_case >= len(test_cases):             test_case = 0         case = test_cases[test_case]         condition, x, y = case[""condition""], case[""x""], case[""y""]          执行操作         result = ops.where(condition, x, y)          保存结果         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         os.makedirs(results_dir, exist_ok=True)         file_name = f""{device.lower()}_case{test_case}_results.npy""         np.save(f'{results_dir}/{file_name}', result.asnumpy())         print(f""{device}结果: {result}"")         return result     def compare_results(test_case=0):         """"""比较CPU和GPU结果""""""         results_dir = '/home/ms/ms_test/Bug_test/minimal_res'         cpu_file = f'{results_dir}/cpu_case{test_case}_results.npy'         gpu_file = f'{results_dir}/gpu_case{test_case}_results.npy'         if not os.path.exists(cpu_file) or not os.path.exists(gpu_file):             print(f""错误: 结果文件不存在，请先运行测试"")             return         cpu_result = np.load(cpu_file)         gpu_result = np.load(gpu_file)         are_equal = np.array_equal(cpu_result, gpu_result)         print(f""CPU和GPU结果是否一致: {are_equal}"")         if not are_equal:             diff_indices = np.where(cpu_result != gpu_result)             diff_count = len(diff_indices[0])             total_count = cpu_result.size             diff_percent = 100 * diff_count / total_count             max_abs_diff = np.max(np.abs(cpu_result  gpu_result))             print(f""不匹配元素: {diff_count} / {total_count} ({diff_percent:.1f}%)"")             print(f""最大差值: {max_abs_diff}"")              完整展示结果             np.set_printoptions(suppress=True)   禁止科学计数法             print(f""CPU结果: {cpu_result}"")             print(f""GPU结果: {gpu_result}"")              显示差异索引和对应值             print(f""有差异的索引: {diff_indices[0]}"")             print(f""这些索引处的CPU值: {cpu_result[diff_indices]}"")             print(f""这些索引处的GPU值: {gpu_result[diff_indices]}"")     def run_all_tests():         """"""运行所有测试用例并比较结果""""""         test_cases = 3         print(""="" * 80)         print(""MindSpore Where操作在CPU和GPU上的结果比较"")         print(""="" * 80)         for case in range(test_cases):             print(f""\n测试用例 {case}:"")             print("""" * 60)              在CPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""CPU"", ""case"", str(case)],                          stdout=subprocess.PIPE)              在GPU上运行             subprocess.run([sys.executable, __file__, ""device"", ""GPU"", ""case"", str(case)],                         stdout=subprocess.PIPE)              比较结果             compare_results(case)             print("""" * 60)     if __name__ == ""__main__"":         import argparse         parser = argparse.ArgumentParser(description='MindSpore Where操作Bug复现')         parser.add_argument('device', type=str, choices=['CPU', 'GPU'], default='CPU')         parser.add_argument('case', type=int, default=0)         parser.add_argument('runall', action='store_true',                          help='自动在CPU和GPU上运行所有测试用例并比较结果')         args = parser.parse_args()         if args.run_all:             run_all_tests()         else:             test_where_bug(args.device, args.case) ``` 2. 运行测试脚本，执行所有测试用例并比较结果:    ```bash    python /home/ms/ms_test/Bug_test/where_bug.py runall    ``` 3. 观察比较结果，特别关注负值在不同设备上的处理差异  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) **【预期结果】**: CPU和GPU应产生一致的结果，特别是对于负值的处理应该相同，不应出现GPU自动将负值转为0的情况。  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图: ``` 测试用例 0:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [ 1 1  3 1 1] GPU结果: [1 0 3 0 0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 1:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1 CPU结果: [1000000001         1 1000000003         1         1] GPU结果: [1000000001          0 1000000003          0          0] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1 1 1] 这些索引处的GPU值: [0 0 0]  测试用例 2:  CPU和GPU结果是否一致: False 不匹配元素: 3 / 5 (60.0%) 最大差值: 1.5 CPU结果: [ 1.1 1.5  3.3 1.5 1.5] GPU结果: [1.1 0.  3.3 0.  0. ] 有差异的索引: [1 3 4] 这些索引处的CPU值: [1.5 1.5 1.5] 这些索引处的GPU值: [0. 0. 0.]  ```  7.Special notes for this issue/备注 (Optional / 选填) 1. 问题特征总结:     仅在条件为`True`时且选择值为负值时出现     同时影响整数和浮点数数据类型     问题与广播机制相关，特别是负值标量被广播时 2. 可能的根本原因:     GPU实现中的符号位处理错误     CUDA内核在执行条件选择时可能截断了负值的符号位     掩码操作实现可能存在缺陷",2025-03-24T16:39:52+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBVUUB
mindformers,魏琢艺,【master】ring_attention部分场景训练拉起失败," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 开data_broadcast_opt_level时，pp和RingAttention混开报错，训练报 the pointer[value] is null  2.Environment / 环境信息 (Mandatory / 必填) mindsporemaster，mindformersdev，python3.10  **Software Environment / 软件环境 (Mandatory / 必填)**:  3.Related testcase / 关联用例 (Mandatory / 必填) NA  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：llama3_8b，开2122并行，开启ring_atention，配置parallel_speed_up.json其中dataset_broadcast_opt_level=3 > 用例执行命令：bash scripts/msrun_launcher.sh ""run_mindformer.py config ../finetune_llama3_8b.yaml run_mode finetune use_parallel True auto_trans_ckpt False"" 8 9779 output/msrun_log False 7200  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常训练  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** 杨犇",2025-03-24T11:48:27+08:00,gitee,progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IBVQER,Appearance & Root Cause 问题：开data_broadcast_opt_level时，pp和RingAttention混开报错 根因：pp通信和数据broadcast保序pass只考虑了pp中的receive通信算子，没有考虑到RingAttention中的receive通信算子，误认为图中所有的receive算子都有MICRO属性，而ringattention创建的receive是没有这个属性的，所有在getvalue时候遇到了空指针。 Fix Solution 1、pp通信和数据broadcast保序pass中跳过除了pp外创建的Reveive通信算子。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83389 PR合入后daily包回归 测试建议：该问题可以通过特性用例防护，增加pp和RingAttention混开时开启data_broadcast_opt_level场景。 Selftest Report & DT Review 修复后报错不再出现，可以正常训练 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入commit：811bddb329d680bf578a2c47a1c9f2ddb2d02fea opt_dataset_reader 提交于 2024年09月04日 问题是否偶现：否
ascend,luoxuewei,tolist接口中隐式类型转换告警处理以及clean code优化,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-21T14:17:38+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBV8FF
deepseek,孙昊辰,internal add asdop fused_add_topk_div kernel,   Backgroud（背景信息）  deepseek kernel optimization   Origin（信息来源） 算子团队  Benefit / Necessity （价值/作用） improve op efficiency  Design（设计方案） add fused_add_topk_div kernel to internel,2025-03-21T10:26:53+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBV5NH
ascend,chujinjin,非连续判断错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ``` import mindspore import numpy as np from mindspore import Tensor, ops input = Tensor(np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]]), mindspore.float32) input_perm = (0, 2, 1) output = ops.transpose(input, input_perm) output.is_contiguous() False output output.is_contiguous() True ``` 打印后，连续状态被改变。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   全后端  **Software Environment / 软件环境 (Mandatory / 必填)**:   迭代版本新增问题样例：（根据实际修改和增删）   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-20T15:08:37+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUYO0,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,zhouyaqiang0,inline不支持动态shape," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-20T09:15:01+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUT7D,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,caifubi,ADS网络执行卡住，堆栈在SplitTensor," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-20T09:14:08+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUT6I,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,zhangyinxia,clean code," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-19T16:01:35+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBUNZ2,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
deepseek,李伟清,910B推理 deepseek量化模型时AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。,我使用910B推理 deepseek量化模型时一样碰到error：AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。 使用的镜像有两个： 2.0.T3.1800IA2py311openeuler24.03lts	 2.0.T3800IA2py311openeuler24.03lts 模型为：https://modelers.cn/models/State_Cloud/DeepSeekR1W8A8 !输入图片说明,2025-03-17T19:30:29+08:00,"mindspore-assistant,www,www",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBU2B9,看了下，上面链接里的模型，应该不是mindspore框架运行的，根据里面的示例代码应该是torch npu的，可以去昇腾社区的昇腾cann板块问一下： https://www.hiascend.com/forum/forum01061013859211750041.html torch npu的问题没有开单独板块，也可以提个工单咨询： https://www.hiascend.com/support 上面的错误提示，可能是显存或者内存不够导致主进程自动kill了，模型页面上有提到oom的情况
deepseek,李伟清,910B推理 deepseek量化模型时AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。,我使用910B推理 deepseek量化模型时一样碰到error：AttributeError: 'ForkAwareLocal' object has no attribute 'connection'。 使用的镜像有两个： 2.0.T3.1800IA2py311openeuler24.03lts	 2.0.T3800IA2py311openeuler24.03lts 模型为：https://modelers.cn/models/State_Cloud/DeepSeekR1W8A8 !输入图片说明,2025-03-17T19:30:28+08:00,"mindspore-assistant,www,www",progressing,0,1,https://gitee.com/mindspore/mindspore/issues/IBU2B8,看了下，上面链接里的模型，应该不是mindspore框架运行的，根据里面的示例代码应该是torch npu的，可以去昇腾社区的昇腾cann板块问一下： https://www.hiascend.com/forum/forum01061013859211750041.html torch npu的问题没有开单独板块，也可以提个工单咨询： https://www.hiascend.com/support 上面的错误提示，可能是显存或者内存不够导致主进程自动kill了，模型页面上有提到oom的情况
yi,虞良斌,Modifying the communication operator name redos attack problem,,2025-03-17T17:09:58+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBU0OF
mindnlp,RongRongStudio,msrun单机双卡运行在910A报错,"Ascend HDK 24.1.RC3 CANN 8.0.0 MindSpore 2.5.0 硬件910ProB 运行代码：https://github.com/mindsporelab/mindnlp/blob/master/llm/inference/llama3/run_llama3_distributed.py 运行命令：msrun worker_num=2 local_worker_num=2 master_port=8118 join=True bind_core=True run_llama3_distributed.py [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.470.315 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 15 source: 127.0.0.1:48616, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.470.397 [mindspore/ccsrc/distributed/rpc/tcp/tcp_client.cc:76] Connect] Failed to connect to the tcp server : 127.0.0.1:8118, retry to reconnect(1/1)... [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:58.704.571 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 15 source: 127.0.0.1:48618, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(85,ffff0a8ef120,python):2025031703:24:58.704.571 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48618 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:58.704.645 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 1 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.970.481 [mindspore/ccsrc/distributed/cluster/topology/compute_graph_node.cc:173] Register] Failed to connect to the meta server node url: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:58.970.509 [mindspore/ccsrc/distributed/cluster/topology/compute_graph_node.cc:363] ReconnectWithTimeoutWindow] Failed to register and try to reconnect to the meta server. [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:59.204.838 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 16 source: 127.0.0.1:48620, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:59.204.874 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 2 [WARNING] DISTRIBUTED(85,ffff0b90f120,python):2025031703:24:59.204.926 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48620 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.470.709 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 16 source: 127.0.0.1:48622, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff16ebf120,python):2025031703:24:59.470.730 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48622 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.470.745 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 1 [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:24:59.705.305 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(1/1200). [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.970.882 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:485] Connect] Connection 17 source: 127.0.0.1:48624, destination: 127.0.0.1:8118 [WARNING] DISTRIBUTED(92,ffff15e9f120,python):2025031703:24:59.970.891 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:79] ConnectedEventHandler] Connection from 127.0.0.1:48624 to 127.0.0.1:8118 is successfully created. System errno: Success [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:24:59.970.905 [mindspore/ccsrc/distributed/rpc/tcp/tcp_comm.cc:494] Connect] Waiting for the state of the connection to 127.0.0.1:8118 to be connected...Retry number: 2 [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:00.205.402 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(2/1200). [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:00.471.344 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(1/1200). [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:00.705.486 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:245] BuildCluster] Topology build timed out., retry(3/1200). [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:00.971.463 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:248] BuildCluster] Cluster is successfully initialized. [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:00.971.492 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:355] PostProcess] This node 1 rank id: 1 [WARNING] PS(92,ffff9e8e0c80,python):2025031703:25:00.971.561 [mindspore/ccsrc/ps/core/file_configuration.cc:24] Initialize] The file: is not exist. [WARNING] DEVICE(92,ffff9e8e0c80,python):2025031703:25:00.971.574 [mindspore/ccsrc/plugin/device/cpu/hal/hardware/ms_collective_node.cc:33] Start] Failed to initialize the configuration for this mccl collective node. [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:01.205.598 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:248] BuildCluster] Cluster is successfully initialized. [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:01.205.629 [mindspore/ccsrc/distributed/cluster/cluster_context.cc:355] PostProcess] This node 0 rank id: 0 [WARNING] PS(85,ffff93320c80,python):2025031703:25:01.205.714 [mindspore/ccsrc/ps/core/file_configuration.cc:24] Initialize] The file: is not exist. [WARNING] DEVICE(85,ffff93320c80,python):2025031703:25:01.205.738 [mindspore/ccsrc/plugin/device/cpu/hal/hardware/ms_collective_node.cc:33] Start] Failed to initialize the configuration for this mccl collective node. [WARNING] PS(85,ffff93320c80,python):2025031703:25:01.207.379 [mindspore/ccsrc/ps/core/communicator/tcp_server.cc:188] Init] The port 8119 is already in use. So increase port to: 8119 [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB [MS_ALLOC_CONF]Runtime config:  enable_vmm:True  vmm_align_size:2MB [WARNING] DISTRIBUTED(85,ffff93320c80,python):2025031703:25:04.836.447 [mindspore/ccsrc/distributed/collective/collective_manager.cc:332] CreateCommunicationGroup] Start to create communication group: hccl_world_group [const vector]{0, 1}, async: 0, submit_now: 1 [WARNING] DISTRIBUTED(85,fffe867cf120,python):2025031703:25:04.839.950 [mindspore/ccsrc/distributed/collective/collective_manager.cc:777] CreateDeviceCommunicator] Begin initialize communication group on the device side: hccl_world_group [WARNING] DEVICE(85,fffe7bfff120,python):2025031703:25:04.840.252 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:141] InitializeByRootInfoConfig] Start to initialize communicator by HcclCommInitRootInfo for hccl_world_group, hcclBufferSize is 200 MB. hcclDeterministic is 0 [WARNING] DISTRIBUTED(92,ffff9e8e0c80,python):2025031703:25:07.428.996 [mindspore/ccsrc/distributed/collective/collective_manager.cc:332] CreateCommunicationGroup] Start to create communication group: hccl_world_group [const vector]{0, 1}, async: 0, submit_now: 1 [WARNING] DISTRIBUTED(92,fffe91fbf120,python):2025031703:25:07.430.103 [mindspore/ccsrc/distributed/collective/collective_manager.cc:777] CreateDeviceCommunicator] Begin initialize communication group on the device side: hccl_world_group [WARNING] DEVICE(92,fffe917af120,python):2025031703:25:07.430.410 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:141] InitializeByRootInfoConfig] Start to initialize communicator by HcclCommInitRootInfo for hccl_world_group, hcclBufferSize is 200 MB. hcclDeterministic is 0 [WARNING] DEVICE(85,fffe7bfff120,python):2025031703:25:08.332.284 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:152] InitializeByRootInfoConfig] End to initialize communicator by HcclCommInitRootInfo for hccl_world_group [WARNING] DISTRIBUTED(85,fffe867cf120,python):2025031703:25:08.332.561 [mindspore/ccsrc/distributed/collective/collective_manager.cc:788] CreateDeviceCommunicator] End initialize communication group on the device side: hccl_world_group [WARNING] DEVICE(92,fffe917af120,python):2025031703:25:08.503.765 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ascend_collective_comm/ascend_communication_group.cc:152] InitializeByRootInfoConfig] End to initialize communicator by HcclCommInitRootInfo for hccl_world_group [WARNING] DISTRIBUTED(92,fffe91fbf120,python):2025031703:25:08.504.027 [mindspore/ccsrc/distributed/collective/collective_manager.cc:788] CreateDeviceCommunicator] End initialize communication group on the device side: hccl_world_group",2025-03-17T11:33:20+08:00,"mindspore-assistant,mp",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBTUWV,这个好像也没有报错呀？只是些警告，警告的原因是回路地址通信受阻，但重新尝试后还是成功了，受阻的原因可能有多种，服务器的账户权限、防火墙配置啥的，上述警告中还提到端口被占用的，端口占用可能是最主要的，可以检查一下,这边有篇文章，可以参考一下，调用方法和你的也是一样的： https://mp.weixin.qq.com/s?__biz=MzkxMTM2MjMzNg==&mid=2247630125&idx=1&sn=85cac4be8afbfad4f3a0aa7111b57943&chksm=c05b78a721760515aeecf50b1a6e4e588dd1f53496e48b26834beea4118130f24fc8bb2a4497&mpshare=1&scene=23&srcid=0218kieDg0yrzQhYrffB4PBC&sharer_shareinfo=78c1efb617b7dae27f91648b717a415d&sharer_shareinfo_first=2f073777e1f011aad7620386c1a794dbrd
ascend,caifubi,部分CPython接口有内存泄露，需要去除Py_INCREF," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-15T21:27:36+08:00,"gitee,user/IC",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBTN7L,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,下游单 DTS2025031459443,Appearance & Root Cause 问题：mindformers里面有网络显存不足。 根因：Tensor接口中有pyobject引用计数不正确，host Tensor泄露，导致Tensor上的显存没释放。 Fix Solution 1、修复Tensor接口的泄露问题。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83047 PR合入后daily包回归 测试建议：增加mindspore和mindformers的联合流水线。 Selftest Report & DT Review mindformer网络显存正常。 是否需要补充 ST/UT：否 原因：非基本功能问题，且属于显存泄露，不适合在CI level0看护。 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82518 PR合入时间：2025年3月8日 问题是否偶现：是/否
ascend,luoxuewei,"重构接口 tensor.is_complex, tensor.is_signed ","   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-14T15:59:23+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBTFH0
ascend,caifubi,Empty算子输出仍然为StubTensor，需要进一步去除。," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-13T21:28:22+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBT88A,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
llm,majun-bot,CVE202441996,"一、漏洞信息 漏洞编号：CVE202441996 漏洞归属组件：openssl, https://gitee.com/mindspore/mindspore 漏洞归属的版本：1.1.1k CVSS分值： &emsp;BaseScore： 7.5 High &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 漏洞简述： Validating the order of the public keys in the DiffieHellman Key Agreement Protocol, when an approved safe prime is used, allows remote attackers (from the client side) to trigger unnecessarily expensive serverside DHE modularexponentiation calculations. The client may cause asymmetric resource consumption. The basic attack scenario is that the client must claim that it can only communicate with DHE, and the server must be configured to allow DHE and validate the order of the public key. 漏洞公开时间：20240826 14:15:04 漏洞创建时间：20250313 17:13:31 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202441996 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： DiffieHellman是DiffieHellman开源的一种密钥协商协议。该密钥协商协议允许Alice和Bob交换公钥值，并根据这些值和他们自己对应的私钥的知识，安全地计算共享密钥K，从而实现进一步的安全通信。仅知道交换的公钥值，窃听者无法计算共享密钥。DiffieHellman存在安全漏洞，该漏洞源于允许远程攻击者触发不必要的DHE模幂运算，可能造成不对称资源消耗。 漏洞评分(MindSpore评分): &emsp;BaseScore： 7.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响",2025-03-13T17:13:32+08:00,"gitee,CVE/UNAFFECTED,kind/nobug",closed,0,7,https://gitee.com/mindspore/mindspore/issues/IBT5TU,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明:DiffieHellman是DiffieHellman开源的一种密钥协商协议。该密钥协商协议允许 Alice 和 Bob 交换公钥值，并根据这些值和他们自己对应的私钥的知识，安全地计算共享密钥K，从而实现进一步的安全通信。仅知道交换的公钥值，窃听者无法计算共享密钥。DiffieHellman存在安全漏洞，该漏洞源于允许远程攻击者触发不必要的DHE模幂运算，可能造成不对称资源消耗。 漏洞评分(mindspore评分): BaseScore:7.5 Vector:CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响 8.r2.4:不受影响 9.r2.5:不受影响 10.r2.6:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**", Appearance & Root Cause 问题：DH密钥协商协议存在漏洞，使得远程攻击者可以触发不必要的DHE模幂运算，造成机器的资源消耗。 漏洞分析： 1、MindSpore使用的是ECDHE算法，不是DHE； 2、OpenSSL针对1.1.1k版本未提供相关patch；  Fix Solution 评审关单。后续开源工具会重新扫描漏洞并创建新的issue，若到时OpenSSL社区有提供漏洞patch，再进行修复。,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 里程碑未变更至测试领域 2. 未包含 补充建议 (Fix Description & Test Suggestion) 3. 未包含 自测结果 & 审核结果 (Selftest Report & DT Review) 4. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,暂无法修复，后续通过安全工具扫描持续跟踪
ascend,cccc1111,atanh_/arctanh_接入aclnn, Tasks 转测对象：tensor.atanh_/tensor.arctanh_ 对标torch.tensor.atanh_/arctanh_   Background !输入图片说明  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.Tensor.atanh_.htmltorch.Tensor.atanh_  标杆在Ascend支持数据类型： bfloat16/float16/float32/float64/complex64/complex128  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反双曲正切值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-13T11:32:59+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBT14D
ascend,cccc1111,atan2_/arctan2_接入aclnn, Tasks 转测对象：tensor.atan2_/tensor.arctan2_ 对标torch.tensor.atan2_/arctan2_   Background !输入图片说明  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.Tensor.atan2_.htmltorch.Tensor.atan2_  标杆在Ascend支持数据类型： bfloat16/float16/float32/float64/uint8/int8/int16/int32/int64/bool  **2. MindSpore算子情况**   当前支持数据类型 与torch_gpu保持一致，bfloat16/float16/float32/float64  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算两个Tensor的反正切值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-13T11:26:33+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBT10I
ascend,cccc1111,atan_/arctan_接入aclnn, Tasks 转测对象：tensor.atan_/tensor.arctan_ 对标torch.tensor.atan_/arctan_   Background !输入图片说明  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.Tensor.atan_.htmltorch.Tensor.atan_  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反正切值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-13T11:20:51+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBT0WX
ascend,caifubi,网络训练场景，fork数据进程执行卡住," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-11T18:51:22+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBSKUT,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,candyhong,The 'set_memory' can not be set repeatedly.,"   Describe the current behavior / 问题描述 (Mandatory / 必填) How to set_memory again without rerunning the script  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : 3.10.12  OS platform and distribution (e.g., Linux Ubuntu 16.04): openEuler  GCC/Compiler version (if compiled from source): 11.4.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` >>> import mindspore as ms /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /usr/local/lib/python3.10/distpackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) >>> ms.runtime.set_memory(""10GB"", ""2GB"", ""28GB"", ""O1"") >>> ms.runtime.set_memory(""10GB"", ""2GB"", ""28GB"", ""O1"") Traceback (most recent call last):   File """", line 1, in    File ""/usr/local/lib/python3.10/distpackages/mindspore/_checkparam.py"", line 1367, in wrapper     return func(*args, **kwargs)   File ""/usr/local/lib/python3.10/distpackages/mindspore/runtime/memory.py"", line 54, in set_memory     raise RuntimeError(""The 'set_memory' can not be set repeatedly."") RuntimeError: The 'set_memory' can not be set repeatedly. ```  Describe the expected behavior / 预期结果 (Mandatory / 必填) I want to change max_size of memory without rerunning the script.  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-11T18:13:27+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBSKK9
ascend,zhouyaqiang0,静态图flops计算重计算虚高," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】*周亚强（根据实际修改）",2025-03-08T17:57:15+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBRTC2,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,zhouyaqiang0,静态图flops计算重计算虚高," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】*周亚强（根据实际修改）",2025-03-08T17:57:12+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBRTC1,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,孙昊辰,Cogvlm2和qwenvl VIT网络 Attention中的bmm报错,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  在测试Cogvlm2和qwenvl网络时，用例：  TestCogVLM2VideoPredict  test_predict.py::TestQwenVLPredict  报错，其中batchMatMul算子 weight 4维时，发生报错，定位原因为算子不应该走到internal实现中，从而导致weight维度校验报错。  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend 910B  **Software Environment / 软件环境 (Mandatory / 必填)**: mindspore  MindSpore version (e.g., 1.7.0.Bxxx) : 2.5.0  Python version (e.g., Python 3.7.5) : py310  OS platform and distribution (e.g., Linux Ubuntu 16.04): Ubuntu aarch64  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填)  TestCogVLM2VideoPredict  test_predict.py::TestQwenVLPredict  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. Cogvlm2和qwenvl网络中测试问题用例：     TestCogVLM2VideoPredict     test_predict.py::TestQwenVLPredict 2. 单算子运行test/st/test_batch_matmul.py用例  Describe the expected behavior / 预期结果 (Mandatory / 必填)  bmm算子使用aclnn实现，4维weight shape不报错，结果正确。  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  !输入图片说明 报错 MatMul weight shape rank must be 2/3, but got 4  Special notes for this issue/备注 (Optional / 选填)",2025-03-08T17:41:22+08:00,gitee,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBRT9N,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：Cogvlm2和qwenvl VIT网络 Attention中的bmm报错 根因： 1、 bmm算子预期使用环境变量控制，默认关闭。但实际环境变量不能控制此算子的注册，导致实际为默认开启。 2、 在默认开启情况下，Attention中的bmm weight为4维 shape，当前算子不支持，导致报错。 Fix Solution 1、（当前）删除算子注册，目前不使能bmm算子。功能使用aclnn实现。 2、近期重新使能bmm算子，增加详细的不支持场景的限制。 3、新需求支持bmm weight 4维场景。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/82658 PR合入master分支 测试建议：该问题可以通过特性用例防护，增加****场景。 Selftest Report & DT Review pr合入master分支B050版本测试 牛君豪 30057732 未发现问题复现。 是否需要补充 ST/UT：否。 原因：解决问题单当前已取消注册bmm算子，使用aclnn实现。 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/82323 PR合入时间：2025年/3月/4日 问题是否偶现：否
bert,zhangyupeng,mindspore2.2.0中mindspore.nn.Dense和对应的torch.nn.Linear在运行中有较大差异," 1.Describe the current behavior / mindspore2.2.0中mindspore.nn.Dense和对应的torch.nn.Linear在运行中有较大差异 两个框架在该模块中 输入数据的差异在输出后提高2~3个数量级  2.Environment / 环境信息 (Mandatory / 必填)   3.Related testcase / 关联用例 (Mandatory / 必填) !输入图片说明  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore.nn as mnn import torch import torch.nn as nn class BertConfig_pt:     def __init__(self, hidden_size=768, intermediate_size=3072):         self.hidden_size = hidden_size         self.intermediate_size = intermediate_size class BertIntermediate_pt(nn.Module):     def __init__(self, config):         super(BertIntermediate_pt, self).__init__()         self.dense = nn.Linear(config.hidden_size, config.intermediate_size)         self.intermediate_act_fn = nn.GELU()     def forward(self, hidden_states: torch.Tensor) > torch.Tensor:         hidden_states = self.dense(hidden_states)         hidden_states = self.intermediate_act_fn(hidden_states)         return hidden_states class BertConfig_ms:     def __init__(self, hidden_size=768, intermediate_size=3072):         self.hidden_size = hidden_size         self.intermediate_size = intermediate_size class BertIntermediate_ms(mnn.Cell):     def __init__(self, config):         super(BertIntermediate_ms, self).__init__()         self.dense = mnn.Linear(config.hidden_size, config.intermediate_size)         self.intermediate_act_fn = mnn.GELU()     def construct(self, hidden_states):         hidden_states = self.dense(hidden_states)         hidden_states = self.intermediate_act_fn(hidden_states)         return hidden_states config_ms = BertConfig_ms(hidden_size=768, intermediate_size=3072) intermediate_layer_ms = BertIntermediate_ms(config_ms) dense_layer_ms = intermediate_layer_ms.dense config_pt= BertConfig_pt(hidden_size=768, intermediate_size=3072) intermediate_layer_pt = BertIntermediate_pt(config_pt) dense_layer_pt = intermediate_layer_pt.dense input_pt = bert_compare.input_pt[""encoder.layer.2.intermediate.dense""] input_ms = bert_compare.input_ms[""encoder.layer.2.intermediate.dense""] if isinstance(input_pt, tuple):     input_pt = input_pt[0]   if isinstance(input_ms, tuple):     input_ms = input_ms[0]   output_pt = dense_layer_pt(input_pt) output_ms = dense_layer_ms(input_ms) print(""PT Output Tensor:"", output_pt.detach().cpu().numpy()) print(""MS Output Tensor:"", output_ms.asnumpy()) print(""Output DIFFERENCE:"", output_pt.detach().cpu().numpy()output_ms.asnumpy()) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 输入和输出的误差不会有太大差异  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-03-07T14:54:57+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRKXT,上述代码确定是MindSpore 2.2.0上运行的吗？2.2.0版本应该没有mindspore.nn.Linear这个算子，上述代码运行不起来的，mindspore.nn.Linear这个是后续版本中添加的，这边应该是要用mindspore.nn.Dense吧？ 不论mindspore.nn.Linear还是mindspore.nn.Dense，这里运行结果pt和ms不同，是因为初始化权重不同，ms和pt的默认权重初始化方法可能不一样，并且同一种初始化方法，比如kaimingNormal，也都是随机初始化的，所以对比结果肯定不一样，并且每次运行的结果差异都是不同的；如果要做对比，需要设置固定的权重
ascend,zhangyinxia,alltoallv算子添加add block_size属性," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 通过 block_size属性可以减少一次d2h数据拷贝，提升网络性能 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O* >  **数据集名字和路径 (Mandatory / 选填)**: >  **权重文件名字和路径 (Mandatory / 选填)**:  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 测试步骤：来自文本用例 > 用例执行命令：来自CI日志或者用户执行命令  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-07T14:52:25+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBRKWD,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,qiwenlun,Python Tensor和C++ Tensor重构,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any. 特性重构：Ascend上，每个tensor创建时间大概在10us20us左右，在C++运算后产生的 C++ Tensor传递到Python的时候，会重新生成以一个新的 Python Tensor（类深拷贝C++ Tensor）。本次重构主要消除这步copy，节省Python Tensor创建的操作，一次能节省开销 1020 us。  Origin（信息来源）  Explain which department/team made this request so that its priority can be given. 易用性增强  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request. 先前合入背景： 当前MindSpore Python Tensor继承C++ Tensor，并且拥有自己的属性(init/const_arg/virtual_flag/init_finished/device等)和方法，在Python侧使用的Tensor参与运算生成结果时，需要深拷贝一份C++Tensor。 重构之后的Python Tensor不会直接继承C++ Tensor，会继承一个TensorPy，TensorPy里面包含C++ Tensor（储存指针）。 因此，在C++运算接口中，拿到py::args/py::kwargs之后，需要cast成TensorPy再获取真实的C++ Tensor，或者从py::object中获取C++ Tensor指针对象。 本次合入改动： 本次合入在上面的基础上进行CPython改造，包括TensorPy的注册，以及TensorPy的方法属性的定义，改造完之后可以直接创建python内存块来存放TensorPy。TensorPy也由本身的智能指针改变为Cpython结构并持有TensorPy，TensorPy持有原本的C++Tensor指针，相比原先少了一步C++的make::share。并为StubTensor去除奠定基础。  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed Python Tensor和C++ Tensor重构设计文档,2025-03-07T14:51:56+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBRKW7
mindnlp,FreezingTheFlame,mindspore.nn mindspore.mint.nn mindnlp.nn 提供了三种nn，我应该如何确定三种nn的使用情境？是否会冲突," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 在mindspore以及mindnlp中，提供了多种nn接口，mindspore.nn,mindspore.mint.nn,mindnlp.nn，三种nn的接口实现各有不同，其中mindspore的两种nn应该如何区分使用？是否存在不适配的可能？可以混用吗？  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**: Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) !输入图片说明  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) 希望能在文档中描述清楚区别，并且尽可能统一mindspore中nn的两种接口实现",2025-03-06T16:41:44+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBRAHJ,mindspore.nn是比较早的，基本各平台都支持；mindspore.mint.nn是新的版本中增加的，有可能获得更好的性能，但目前应该只有910环境才支持，部分好像910b才支持，并且可能在参数上也做了一些修改，这个在文档里有说明；mindnlp套件里的nn是对标hf的那个transformer库的，transformer库的模型基本是pytorch实现的，保持与pytorch的使用习惯一致，方便快速将transformer里的模型迁移过来； 至于能否混用，只要当前环境平台是能运行的，混用是没有问题的，如果碰到出错，应该是属于bug的范畴；但在mindnlp里面，能用mindnlp.nn的话就用这个，这样比较规范，也方便迁移模型，其它情况下，如果mindspore.mint.nn支持就用这个，有可能获得更高的性能
mindir,徐微,onnx模型转换mindir推理失败," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > 使用mindspore训练一个是涉及Conv2d和Add操作的模型，经过mindspore_lite转换为mindir，然后推理。报：Unsupported op  > node: :U496{[0]: ValueNode Conv2DFusion, [1]: :param_U494, [2]: :param_U493}  2.Environment / 环境信息 (Mandatory / 必填)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name** >   test_model_infer_mindir_cpu >  **Excute Mode ** >    Graph 模式 >    没有指定优化级别，默认为 O0 级别的优化  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) '''  import os import numpy as np import mindspore as ms from mindspore import nn, Tensor, context from mindspore_lite import converter, FmkType, ModelType import onnxruntime as ort   添加 ONNX Runtime 导入 class SimpleModel(nn.Cell):   def __init__(self): ​    super(SimpleModel, self).__init__() ​    self.conv = nn.Conv2d(1, 3, kernel_size=3, stride=1, pad_mode=""same"") ​    self.add = ms.ops.Add()   def construct(self, x): ​    x = self.conv(x) ​    x = self.add(x, x) ​    return x def infer_onnx(onnx_path, input_data):   """"""使用 ONNX Runtime 推理 ONNX 模型""""""   session = ort.InferenceSession(onnx_path)   input_name = session.get_inputs()[0].name   input_numpy = input_data.asnumpy() if isinstance(input_data, Tensor) else input_data   outputs = session.run(None, {input_name: input_numpy})   result = outputs[0]   print(f""ONNX模型推理成功，输出形状: {result.shape}"")   print(f""输出数据: \n{result.flatten()[:5]}..."")   return result def main():   ms.set_context(mode=context.GRAPH_MODE)   ms.set_device(""CPU"")   save_dir = ""./model""   os.makedirs(save_dir, exist_ok=True)   model = SimpleModel()   input_shape = (1, 1, 28, 28)   input_data = Tensor(np.random.randn(*input_shape).astype(np.float32))   onnx_path = os.path.join(save_dir, ""simple_model.onnx"")   ms.export(model, input_data, file_name=onnx_path, file_format='ONNX')   \ 推理 ONNX 模型   print(""\n===== 推理 ONNX 模型 ====="")   onnx_result = infer_onnx(onnx_path, input_data)   mindir_path = os.path.join(save_dir, ""simple_model"")   conv = converter.Converter()   conv.input_shape = {""x"": list(input_shape)}   conv.save_type = ModelType.MINDIR   conv.target_device_name = ""CPU""   conv.convert(FmkType.ONNX, onnx_path, mindir_path)   \ 3. 加载并推理MindIR模型   print(""\n===== 推理 MindIR 模型 ====="")   try: ​    graph = ms.load(f""{mindir_path}.mindir"") ​    model = nn.GraphCell(graph) ​     ​    output = model(input_data) ​     ​    print(f""MindIR模型推理成功，输出形状: {output.shape}"") ​    print(f""输出数据: \n{output.asnumpy().flatten()[:5]}..."") ​     ​    \ 比较两种模型的结果 ​    try: ​      is_equal = np.allclose(output.asnumpy(), onnx_result, rtol=1e3, atol=1e3) ​      if is_equal: ​        print(""\nONNX 和 MindIR 模型推理结果一致！"") ​      else: ​        max_diff = np.max(np.abs(output.asnumpy()  onnx_result)) ​        print(f""\nONNX 和 MindIR 模型推理结果不一致！最大差异: {max_diff}"") ​    except Exception as e: ​      print(f""比较结果时出错: {e}"") ​       except Exception as e: ​    print(f""MindIR 模型推理失败: {str(e)}"") ​     if __name__ == ""__main__"":   main() ''' > （1）python bug_report.py > >   (2)出现问题：node: :U8835_copy_U496{[0]: ValueNode Conv2DFusion, [1]: :param_U8833_copy_U494, [2]: :param_U8834_copy_U493}  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：ONNX模型推理成功，输出形状: (1, 3, 28, 28) >  输出数据:  [0.6475724  0.71996325  1.4186195   2.047796    0.2572536 ]...  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明 完整日志（通过附件上传）：",2025-03-05T16:55:52+08:00,mindspore-assistant,open,0,4,https://gitee.com/mindspore/mindspore/issues/IBQYZD,带Fusion的那些算子可能是图算融合后的算子，是不是开启了图算融合，然后CPU可能不支持这种融合算子？ mindspore可以直接导出mindir的，其实不用导出onnx然后再用lite去转，你直接导出mindir然后加载推理看看行不行；如果直接导出的可以，转来的不行的话，那可能是lite转换工具有点问题，或者加入了融合算子的规则导致CPU上不支持； 还有确保上下文里图算融合的开关enable_graph_kernel设置为False了，之前的版本默认这个就是False，但2.5.0的文档中，set_context方法里没有这个参数了，但实际代码运行时测试是可以设置的，不太确定它默认是开了还是关着的，保险起见你可以设置下False,"只是想通过这种方式检验mindspore框架存在的一些bug。我关闭了图算融合，但是还是出现了这个问题。 ``` from mindspore import JitConfig JitConfig = JitConfig(jit_level=""O0"") ```",[图片上传中…(imagezP4CFhpKIKuy3waQ20dj)]," 3. 加载并推理MindIR模型 print(""\n===== 推理 MindIR 模型 ====="") try: ​ graph = ms.load(f""{mindir_path}.mindir"") ​ model = nn.GraphCell(graph) 这部分的加载需要使用mindspore lite相关接口进行加载，没法使用mindspore相关接口进行加载，mindspore lite相关接口使用可以参考mindspore官网中mindspore lite推理部分"
ascend,liuchuting,ops.bucketize连续计算时，值计算错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ops.bucketize连续计算时，值计算错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B2`/`CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >>> from mindspore import Tensor, ops >>> input = Tensor(np.array([[3, 6, 9], [3, 6, 9]])) >>> boundaries = list(np.array([1., 3., 5., 7., 9.])) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output) >>> output = ops.bucketize(input, boundaries)              >>> print(output) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 验证计算是否正确  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > 计算值正确  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-03-05T10:12:33+08:00,"gitee,usability",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBQSSK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,liuchuting,ops.bucketize连续计算时，值计算错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) ops.bucketize连续计算时，值计算错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B2`/`CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >>> from mindspore import Tensor, ops >>> input = Tensor(np.array([[3, 6, 9], [3, 6, 9]])) >>> boundaries = list(np.array([1., 3., 5., 7., 9.])) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output) >>> output = ops.bucketize(input, boundaries)              >>> print(output) >>> output = ops.bucketize(input, boundaries, right=True) >>> print(output)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > 验证计算是否正确  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > 计算值正确  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**王少聪",2025-03-05T10:11:40+08:00,,rejected,0,0,https://gitee.com/mindspore/mindspore/issues/IBQSS2
ascend,cccc1111,asinh_/arcsinh_接入aclnn, Tasks 转测对象：tensor.asinh_/tensor.arcsinh_ 对标torch.tensor.asinh_/arcsinh_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明 !输入图片说明 !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/complex64/complex128  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反双曲正弦值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-04T21:45:32+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQNH
ascend,cccc1111,asin_/arcsin_接入aclnn, Tasks 转测对象：tensor.asin_/tensor.arcsin_ 对标torch.tensor.asin_/arcsin_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明 !输入图片说明 !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  计算一个Tensor的反正弦值  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-03-04T21:30:35+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQJZ
ascend,JavaZero,mul算子动态shape下不支持layout," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > qwen2.5 蒸馏sft  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)  dev  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) bash scripts/msrun_launcher.sh ""run_mindformer.py config research/qwen2_5/finetune_cjh.yaml run_mode finetune register_path research/qwen2_5"" 8  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) [ERROR] PARALLEL(414165,ffffb0990020,python):2025030414:58:26.705.263 [mindspore/ccsrc/frontend/parallel/ops_info/operator_info.cc:1545] InitWithTensorLayout] MulInfo2020: CheckInputLayout failed.  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-03-04T20:43:20+08:00,master,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQQCM
ascend,weixu2025,mint.baddbmm、mint.sort、mint.topk在Ascend平台上无法运算," 1. 问题描述 在对mint.baddbmm、mint.sort、mint.topk接口进行测试时，发现它们不能正常运行在Ascend平台上  2.环境信息 测试环境：启智社区 硬件：NPU: 1*Ascend 910(显存: 32GB), CPU: 24, 内存: 96GB 镜像：mindspore_2_5_py311_cann8（并非唯一不能正常运行的镜像，除此之外还包括多个镜像无法运行上述几个接口  **3.报错** 当测试mint.baddbmm接口时，直接运行文档里面的示例代码（链接：MindSpore） 代码为： ```python import numpy as np from mindspore import Tensor, mint input = Tensor(np.ones([1, 3, 3]).astype(np.float32)) batch1 = Tensor(np.ones([1, 3, 4]).astype(np.float32)) batch2 = Tensor(np.ones([1, 4, 3]).astype(np.float32)) output = mint.baddbmm(input, batch1, batch2) print(output) ``` 出现了报错： ```python  AttributeError                            Traceback (most recent call last) Cell In[7], line 8       5 batch1 = Tensor(np.ones([1,3,4]).astype(np.float32))       6 batch2 = Tensor(np.ones([1,4,3]).astype(np.float32)) > 8 output = mint.baddbmm(input, batch1, batch2)       9 print(output) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/extend/math_func.py:73, in baddbmm(input, batch1, batch2, beta, alpha)      29 def baddbmm(input, batch1, batch2, beta=1, alpha=1):      30     r""""""      31     The result is the sum of the input and a batch matrixmatrix product of matrices in batch1 and batch2.      32     The formula is defined as follows:    (...)      71           [5. 5. 5.]]]      72     """""" > 73     return P.baddbmm(input, batch1, batch2, beta, alpha) AttributeError: module 'mindspore.ops.auto_generate' has no attribute 'baddbmm' ``` 但若将mint换为ops，即使用ops.baddbmm、ops.sort、ops.topk时，在NPU平台上正常运行。 除此之外，本地（Windows+CPU）也无法运行mint.baddbmm、mint.sort、mint.topk接口，而ops在本地可以正常运行。",2025-03-03T20:11:24+08:00,"mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBQDVF,这个会不会是环境问题？我在910上试了下上述代码是可以运行的，也是2.5.0版本： !输入图片说明 至于win+cpu上不能调用，应该是mint的这些方法目前只支持昇腾上使用，文档上有相关说明
ascend,luodan2024,mindspore.mint.isclose() 操作不支持梯度计算," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore.mint.isclose() 操作不支持梯度计算  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` def test_isclose_forward_back(mode):     """"""===使用mindspore和pytorch,固定输入和权重，测试正向推理结果和反向梯度===""""""     ms.set_context(mode=mode)     dtype_ms = ms.float64     dtype_torch = torch.float64     input_data_1 = [[0.1,0.2],[0.5,0.7],[0.11,0.32]]     input_data_2 = [[0.1,0.9],[0.5,0.2],[0.5,0.32]]     ms_input_1 = ms.Tensor(input_data_1,dtype_ms)     ms_input_2 = ms.Tensor(input_data_2,dtype_ms)     torch_input_1 = torch.tensor(input_data_1,dtype=dtype_torch,requires_grad=True)     torch_input_2 = torch.tensor(input_data_2,dtype=dtype_torch,requires_grad=True)     def forward_ms(input_1,input_2):         return ms.mint.isclose(input_1,input_2)     def forward_torch(input_1,input_2):         return torch.isclose(input_1,input_2)     测试正向推理结果     ms_result = forward_ms(ms_input_1,ms_input_2)     torch_result = forward_torch(torch_input_1,torch_input_2)     assert check_bool(ms_result.asnumpy(),np.asarray(torch_result.detach()))         测试反向传播梯度         try:         grad_fn = ms.value_and_grad(forward_ms,grad_position=(0,1))         _, ms_grad = grad_fn(ms_input_1,ms_input_2)         ms_grad_1 = ms_grad[0]         ms_grad_2 = ms_grad[1]         print(f""mindspore反向传播成功{ms_grad_1}{ms_grad_2}"")     except Exception as e:         print(""mindpore 反向传播失败:"", e) test_isclose_forward_back(ms.GRAPH_MODE) test_isclose_forward_back(ms.PYNATIVE_MODE) ```  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明 ",2025-03-03T18:15:58+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBQD2Q,"这个算子本身就不支持反向,torch也不支持",OK，经过确认，按此结论闭环
ascend,weixu2025,mint.bmm  float16前向结果不匹配," 1. 问题描述 在对mindspore.mint.bmm该接口进行测试的时候，发现接口float16前向结果与pytorch不匹配 >              结果比较 >           assert np.allclose(ms_output.asnumpy(), pt_output.detach().numpy(), atol=1e5), ""Forward mismatch"" E           AssertionError: Forward mismatch E           assert False E            +  where False = (array(0.01775, dtype=float16), array(0.01772, dtype=float16), atol=1e05) E            +    where  = np.allclose E            +    and   array(0.01775, dtype=float16) = asnumpy() E            +      where asnumpy = Tensor(shape=[], dtype=Float16, value= 0.017746).asnumpy E            +    and   array(0.01772, dtype=float16) = () E            +      where  = tensor(0.0177, dtype=torch.float16).numpy E            +        where tensor(0.0177, dtype=torch.float16) = () E            +          where  = tensor(0.0177, dtype=torch.float16, grad_fn=).detach >  ``` AssertionError: Forward mismatch MS result: 0.01775 (float16) Torch result: 0.01772 (float16) ```  2.环境信息  **硬件环境**: Hardware (`Ascend910B`) ",2025-03-03T15:05:32+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ9KV,应该是底层硬件的差异造成的，910B1和torch使用的CPU或者GPU浮点数处理上会有差异，这里应该是cann算子处理上的差异，不在mindspore框架层面，不过float16在1e4的误差范围内的话，应该都属于是合理的
ascend,wang_ziqi,【AR】ops.svd支持Ascend后端,"  Background  **1. 标杆情况**   标杆接口链接： tf.linalg.svd(     tensor, full_matrices=False, compute_uv=True, name=None )  标杆支持数据类型：`Float32, Float64, Complex64, Complex128`   数据支持类型由于场景不同会发生变化，已实际场景为准  **2. MindSpore算子情况**   当前支持数据类型   ```   forward:    Ascend：Float32, Float64, Complex64, Complex128   CPU：Float32, Float64, Complex64, Complex128   GPU：Float32, Float64   backward:   Ascend：Float32   CPU：Float32, Float64   GPU：Float32, Float64   数据支持类型由于场景不同会发生变化，已实际场景为准   ```  三后端统一后算子支持（标杆支持+三后端并集） `Float32, Float64, Complex64, Complex128`  Introduction  **1. 功能介绍**  爱因斯坦求和  **2. 接口描述**   functional接口   mindspore/python/mindspore/ops/function/linalg_func.py   ```python   def svd(input, full_matrices=False, compute_uv=True):   ```  对应底层aclop算子 ```     REG_OP(Svd)         .INPUT(x, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .OUTPUT(sigma, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .OUTPUT(u, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .OUTPUT(v, TensorType({ DT_DOUBLE, DT_FLOAT, DT_COMPLEX64, DT_COMPLEX128 }))         .ATTR(compute_uv, Bool, true)         .ATTR(full_matrices, Bool, false)         .OP_END_FACTORY_REG(Svd) ```",2025-03-03T09:53:30+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBQ3XJ
ascend,吴逸群,香橙派,"mindspore2.5.0/mindspore2.4.10均出现上述问题，识别不到npu报错， Unsupported device target Ascend This process only supports one of the ['CPU']. Please check whether the Ascend environment is intalled and configure correctly, and check whether current mindspore wheel package was built with ""e Ascend"".  RuntimeError：Device Ascend not exist",2025-03-03T09:40:10+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ3PO,这种情况基本上是环境没配置好，cann或者昇腾驱动没匹配，或者缺钱昇腾相关的环境变量
memory leak,majun-bot,CVE20251816,"一、漏洞信息 漏洞编号：CVE20251816 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： 4.3 Medium &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:L 漏洞简述： A vulnerability classified as problematic has been found in FFmpeg up to 6e26f57f672b05e7b8b052007a83aef99dc81ccb. This affects the function audio_element_obu of the file libavformat/iamf_parse.c of the component IAMF File Handler. The manipulation of the argument num_parameters leads to memory leak. It is possible to initiate the attack remotely. The exploit has been disclosed to the public and may be used. The identifier of the patch is 0526535cd58444dd264e810b2f3348b4d96cff3b. It is recommended to apply a patch to fix this issue. 漏洞公开时间：20250302 22:15:34 漏洞创建时间：20250302 23:10:45 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20251816 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息：  详情(点击展开)   二、漏洞分析结构反馈 影响性分析说明： 该漏洞的修复文件在5.1.4版本中没有，故不受影响 漏洞评分(MindSpore评分): &emsp;BaseScore： 4.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-03-02T23:10:46+08:00,"gitee,trac,rca/others,rct/oldrelease,ctl/componenttest,CVE/UNAFFECTED",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBQ2CX,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 该漏洞的修复文件在5.1.4版本中没有，故不受影响 漏洞评分(MindSpore评分):  BaseScore：4.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：FFmpeg漏洞CVE20251816 根因： 1、FFmpeg漏洞CVE20251816 Fix Solution 不修复，该漏洞的修复文件在5.1.4版本中没有，故不受影响 Fix Description & Test Suggestion 不涉及 Selftest Report & DT Review 不修复 Introduction Analysis 引入类型：其他，三方软件引入 引入PR：https://trac.ffmpeg.org/ticket/11475,不修复，该漏洞的修复文件在5.1.4版本中没有，故不受影响
ascend,weixu2025,mindspore.mint.minimum不支持Bool输入，但maximum支持Bool输入," 1. 问题描述 在对mindspore.mint.minimum该接口进行测试的时候，发现接口在不支持BFloat16数据类型的基础上，同时也不支持Bool型的输入。但执行相同的测试函数，mindspore.mint.maximum则是支持Bool输入的。 >torch.minimum not supported for torch.uint16 torch.minimum not supported for torch.uint32 torch.minimum not supported for torch.uint64 mint.minimum not supported for BFloat16 torch.minimum not supported for torch.bfloat16 mint.minimum not supported for Bool >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.测试代码（mint.minimum） ``` import pytest import numpy as np import mindspore as ms from mindspore import mint, Tensor, value_and_grad import torch dtype_ms = ms.float32 dtype_torch = torch.float32 input_data_x = [[1, 2], [3, 4], [5, 6]] input_data_y = [[6, 5], [4, 3], [2, 1]] ms_tensor_x = Tensor(input_data_x, dtype_ms) ms_tensor_y = Tensor(input_data_y, dtype_ms) torch_tensor_x = torch.tensor(input_data_x, dtype=dtype_torch) torch_tensor_y = torch.tensor(input_data_y, dtype=dtype_torch) .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_minimum_different_dtypes(mode):     """"""测试random输入不同dtype，对比两个框架的支持度""""""     ms.set_context(mode=mode)     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     for i in range(len(ms_dtypes)):         dtype_ms = ms_dtypes[i]         dtype_torch = torch_dtypes[i]         ms_tensor_x = Tensor(input_data_x, dtype_ms)         ms_tensor_y = Tensor(input_data_y, dtype_ms)         torch_tensor_x = torch.tensor(input_data_x, dtype=dtype_torch)         torch_tensor_y = torch.tensor(input_data_y, dtype=dtype_torch)         err = False         try:             ms_result = mint.minimum(ms_tensor_x, ms_tensor_y).asnumpy()         except Exception as e:             err = True             print(f""mint.minimum not supported for {dtype_ms}"")         try:             torch_result = torch.minimum(torch_tensor_x, torch_tensor_y).numpy()         except Exception as e:             err = True             print(f""torch.minimum not supported for {dtype_torch}"")         if not err:             if not np.allclose(ms_result, torch_result):                 print(f""mint.minimum is supported for {dtype_ms} but not working properly"") ```",2025-03-02T18:15:13+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ0ZV,在2.5版本中，mindspore.mint.minimum已支持BFloat16和Bool输入 在910B环境下MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
ascend,weixu2025,mindspore.mint.maximum希望支持BFloat16、UInt16, 1. 问题描述 在对mindspore.mint.maximum该接口进行测试的时候，发现接口不支持BFloat16、UInt16此数据类型，而Pytorch则是支持的。 > torch.maximum not supported for torch.uint16 torch.maximum not supported for torch.uint32 torch.maximum not supported for torch.uint64 mint.maximum not supported for BFloat16 torch.maximum not supported for torch.bfloat16 >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.价值 BFloat16其指数位数与FP32相同，表示的数据范围更广，在精度较低的情况下可用于提升训练速度。希望支持。,2025-03-02T17:37:53+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBQ0S9,目前，在2.5版本中，mindspore.mint.nn.functional.selu已支持BFloat16，尚未支持UInt16， 在910B环境下MindSpore与torchnpu对BFloat16的结果一致， 后续将会增加对UInt16的支持 !输入图片说明
ascend,weixu2025,mindspore.mint.less_equal希望支持BFloat16, 1. 问题描述 在对mindspore.mint.less该接口进行测试的时候，发现接口不支持BFloat16此数据类型，而Pytorch则是支持的。 > torch.lt not supported for torch.uint32 torch.lt not supported for torch.uint64 mint.less not supported for BFloat16 >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.价值 BFloat16其指数位数与FP32相同，表示的数据范围更广，在精度较低的情况下可用于提升训练速度。希望支持。,2025-03-01T20:13:40+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBPY5E,在2.5版本中，mindspore.mint.less_equal已支持BFloat16， 在910B环境下MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
ascend,j00647318,rollback batch valid length,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-03-01T18:55:21+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPXYT
mindir,李尚憬,新版本mindspore模型转换," 问题 在新版mindpsore.export中.air格式已被弃用，而在香橙派中使用.onnx与.mindir格式转换成.om均会发生错误，仅.air格式能转换，请问这是bug还是转换命令有所不同  复现步骤 1.导出模型为.air/.onnx/.mindir ```  export_model.py import mindspore import numpy as np from mindspore import Tensor from src.deep_learning.networks import resnet152 net = resnet152() params = mindspore.load_checkpoint('medical_resnet_checkpoints.ckpt') mindspore.load_param_into_net(net, params) input_tensor = Tensor(np.ones([1, 3, 572， 572]).astype(np.float32)) mindspore.export(net, input_tensor, file_name='medical_resnet', file_format='AIR')  其它格式则将""AIR""换成""MINDIR""或""ONNX"" ``` 2.在香橙派中执行模型转换 ``` atc framework=1 model=./medical_resnet.air input_format=NCHW output=medical_resnet log=error soc_version=Ascend310B4  其他格式则将.air换成.onnx或.mindir ```  执行情况 1.从.air格式起转，执行正常 !输入图片说明 2.从.onnx格式起转，执行报错 !输入图片说明 3.从.mindir格式起转，执行报错 !输入图片说明",2025-03-01T13:34:17+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBPW36,也不算是bug，应该是cann里面的atc工具转换功能对第三方格式兼容完善程度还不够吧，air本身就是昇腾专用的，自然兼容最完善，onnx相对来说是一种通用格式，又是非昇腾官方的，兼容上确实相差多一些的，还有其它tf的pb或者caffe格式也一样，我以前用的时候也经常碰到第三方格式的转换不支持；至于mindir格式本身就不能转，atc工具不支持转mindir格式： !输入图片说明 atc转换命令使用上的差别，air不需要指定输入节点的信息，onnx通常需要指定输入节点的信息
mindir,LiWanpeng,converter_lite转换Rank算子报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore生成带Rank的mindir模型转ms模型报错；以及返回是标量的算子也会报错,如Size算子.  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 无  4.Steps to reproduce the issue / 重现步骤 (1)生成的mindir模型代码: ``` import mindspore as ms import numpy as np from mindspore import nn, ops class test(nn.Cell):     def __init__(self):         super(test, self).__init__()         self.rank = ops.Rank()     def construct(self, x):         x = self.rank(x)         return x x = np.zeros((3, 3), dtype=np.float32) x_t = ms.Tensor(x) model = test() out = model(x_t) print(""out:"", out) ms.export(     model,     x_t,     file_name=""test"",     file_format=""MINDIR"", ) ``` (2)使用converter_lite工具转换命令: ./converter_lite fmk=MINDIR modelFile=test.mindir outputFile=test_rank  5.Describe the expected behavior / 预期结果  能够转换出test_rank.ms模型文件,并且该模型只有rank算子.  6.Related log / screenshot / 日志 / 截图 报错关键日志截图： !输入图片说明  ",2025-02-28T15:13:28+08:00,"gitee,mindspore-assistant",open,0,3,https://gitee.com/mindspore/mindspore/issues/IBPPF2,导出mindir，使用mslite的转换工具进行转换，目的是为了在手机cpu上推理还是在ascend卡上推理，推理硬件明确一下,是服务器的cpu还是手机cpu,服务器的cpu
ascend,weixu2025,mindspore.mint.less希望支持BFloat16, 1. 问题描述 在对mindspore.mint.less该接口进行测试的时候，发现接口不支持BFloat16此数据类型，而Pytorch则是支持的。 > torch.lt not supported for torch.uint32 torch.lt not supported for torch.uint64 mint.less not supported for BFloat16 >   2.环境信息  **硬件环境**: Hardware (`Ascend910B`)   4.价值 BFloat16其指数位数与FP32相同，表示的数据范围更广，在精度较低的情况下可用于提升训练速度。希望支持。,2025-02-28T12:56:44+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBPNES,在2.5版本中，mindspore.mint.less已支持BFloat16，在910B环境下MindSpore与torchnpu结果一致 !输入图片说明
mindformers,ffmh,reuse_data_ptr输入未同步导致显存波动," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) reuse_data_ptr输入未同步，在执行原地计算时申请新空间，导致显存波动 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改） **【引入分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-28T11:32:29+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBPMUL
ascend,tanxinglian,[CT][MS][OPS][ops.trunc][function][全量][DVM]test_t_trunc_float32_3x9_nan O1模式下计算结果错误," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_t_trunc_float32_3x9_nan O1模式下计算结果错误  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_t_trunc_float32_3x9_nan >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph >    Excute Mode(e.g., O0\O1\O2)：O1  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export CONTEXT_JIT_LEVEL=O1 export MS_DISABLE_KERNEL_BACKOFF=1 （2）cd MindSporeTest/operations （3）pytest s v test_t_trunc.py::test_t_trunc_float32_3x9_nan  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```  ()     def test_t_trunc_float32_3x9_nan():         x = Tensor(np.full((3, 9), np.nan), mstype.float16)         fact = TruncMock(             inputs=[x]) >       fact.forward_cmp() ../test_t_trunc.py:143:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/trunc_ops.py:117: in forward_cmp     allclose_nparray(out_cmp, out_mindspore, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[nan, nan, nan, nan, nan, nan, nan, nan, nan],        [nan, nan, nan, nan, nan, nan, nan, nan, nan],        [nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=float16) data_me = array([[0., 0., 0., 0., 0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-27T09:51:23+08:00,"gitee,foruda,rca/others,ctl/componenttest,rct/newfeature",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBP9R3, Appearance & Root Cause 问题：trunc f16 nan在O1下结果为0 根因：dvm实现trunc f16有问题  Fix Solution 修改dvm中trunc f16的实现   Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/82293 PR合入后daily包回归  Selftest Report & DT Review 自测通过 是否需要补充 ST/UT：否 原因：DVM仓增加测试用例覆盖  Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/74497 特性引入原因：场景考虑不充分 PR合入时间：2025年/1月/2日 问题是否偶现：否,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,"【回归版本号】：__commit_id__ = '[sha1]:ba6873c3,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
ascend,luoxuewei,tensor.__int__接口重构,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  tensor.__int__接口重构，提高执行性能  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-26T21:53:35+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP85D
ascend,cccc1111,le_接入aclnn, Tasks 转测对象：tensor.le_ 对标torch.tensor.le_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/bool  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  比较Tensor A中的元素是否小于Tensor B中的元素  **2. 接口描述**   接口重载： !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语,2025-02-26T19:28:57+08:00,"v2.1.0,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP7C6
ascend,tanxinglian,[CT][MS][OPS][Tensor.max][function][全量]test_dynamic_shape_t_max_dyn_rank_2 910A 计算结果与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_dynamic_shape_t_max_dyn_rank_2 910A 计算结果与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_t_max_dyn_rank_2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE > （2）cd MindSporeTest/operations > （3）pytest s v test_t_max.py::test_dynamic_shape_t_max_dyn_rank_2  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     (reason='not support')     (reason='not support')     (reason='not support')     def test_dynamic_shape_t_max_dyn_rank_2():         x = Tensor(None, dtype=mstype.float32)         dim = mutable(input_data=2, dynamic_len=False)         keepdim = mutable(input_data=False, dynamic_len=False)         x1 = Tensor(np.random.randn(1, 22), mstype.float32)         dim1 = mutable(input_data=2, dynamic_len=False)         keepdim1 = mutable(input_data=False, dynamic_len=False)         attributes1 = {'dim': dim1, 'keepdim': keepdim1}         inputs1 = [x1]         x2 = Tensor(np.random.randn(9, 1, 24, 1, 50, 1, 1), mstype.float32)         dim2 = mutable(input_data=5, dynamic_len=False)         keepdim2 = mutable(input_data=False, dynamic_len=False)         attributes2 = {'dim': dim2, 'keepdim': keepdim2}         inputs2 = [x2]         x3 = Tensor(np.random.randn(16, ), mstype.float32)         dim3 = mutable(input_data=1, dynamic_len=False)         keepdim3 = mutable(input_data=False, dynamic_len=False)         attributes3 = {'dim': dim3, 'keepdim': keepdim3}         inputs3 = [x3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = MaxMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (x, dim, keepdim) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_t_max.py:641:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/max_t_ops.py:296: in forward_dynamic_shape_cmp     allclose_nparray(a[1], b[1], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[ 7.]],           [[21.]],           [[ 4.]],           [[17.]],           [[ 3.]],           [[ 4.]],...           [[13.]],           [[ 4.]],           [[13.]],           [[ 1.]],           [[12.]]]]]], dtype=float32) data_me = array([[[[[[ 0]],           [[ 0]],           [[ 0]],           [[ 0]],           [[ 0]],           [[ 0]],     ...[[ 5]],           [[13]],           [[ 4]],           [[13]],           [[ 1]],           [[12]]]]]], dtype=int64) rtol = 0.0001, atol = 0.0001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T17:12:40+08:00,"gitee,foruda,rca/codelogic,rct/cann,ctl/testcismoke,mindspore-repo",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBP5TM,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：max算子在910A上出现精度异常 根因： 1、cann包中aclnnMAXDIM接口有精度问题 同时用torch_npu做了复现 !输入图片说明 Fix Solution 1、待cann修复对应问题 Fix Description & Test Suggestion cann包更新至最新版本，问题解决 http://mindsporerepo.csi.rnd.huawei.com//productrepo/HiAI/Milan_C21/20250307_atlas/ 测试建议：该问题可以通过特性用例防护，增加****场景。 Selftest Report & DT Review !输入图片说明 是否需要补充 ST/UT：否 原因：本身就是CI看护用例 Introduction Analysis 引入类型：cann包引入 引入PR：cann包引入，pr未知 PR合入时间：年/月/日 问题是否偶现：是/否,"【回归版本号】：__commit_id__ = '[sha1]:e137bd4a,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][mint.argmax][function][全量]mint.argmax 910A 计算结果与标杆不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.argmax 910A 计算结果与标杆不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_mint_f_argmax_dyn_rank_1 test_dynamic_shape_mint_f_argmax_dyn_rank_2 test_dynamic_shape_mint_f_argmax_dyn_shape_2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_f_argmax.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_dynamic_shape_mint_f_argmax_dyn_rank_1():         input_x = Tensor(None, dtype=mstype.float32)         dim = mutable(input_data=1, dynamic_len=False)         keepdim = mutable(input_data=False, dynamic_len=False)         input1 = Tensor(np.random.randn(8, 5), mstype.float32)         dim1 = mutable(input_data=1, dynamic_len=False)         keepdim1 = mutable(input_data=False, dynamic_len=False)         attributes1 = {'dim': dim1, 'keepdim': keepdim1}         inputs1 = [input1]         input2 = Tensor(np.random.randn(3, 4, 7, 7, 7, 5, 9, 5), mstype.float32)         dim2 = mutable(input_data=3, dynamic_len=False)         keepdim2 = mutable(input_data=False, dynamic_len=False)         attributes2 = {'dim': dim2, 'keepdim': keepdim2}         inputs2 = [input2]         input3 = Tensor(np.random.randn(9, ), mstype.float32)         dim3 = mutable(input_data=1, dynamic_len=False)         keepdim3 = mutable(input_data=False, dynamic_len=False)         attributes3 = {'dim': dim3, 'keepdim': keepdim3}         inputs3 = [input3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = ArgmaxMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (input_x, dim, keepdim) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_mint_f_argmax.py:533:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/functional/argmax_mint.py:116: in forward_dynamic_shape_cmp     allclose_nparray(a, b, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[5., 4., 0., 1., 3.],             [5., 0., 5., 4., 0.],             [4., 0., 5., 6., 0.],             ...,...         [0., 2., 0., 6., 4.],             [1., 6., 4., 2., 5.],             [4., 2., 3., 0., 5.]]]]]]], dtype=float32) data_me = array([[[[[[[0, 0, 0, 0, 0],             [0, 0, 0, 0, 0],             [0, 0, 0, 0, 0],             ...,             [0...         ...,             [0, 2, 0, 6, 4],             [1, 6, 4, 2, 5],             [4, 2, 3, 0, 5]]]]]]], dtype=int64) rtol = 0.0001, atol = 0.0001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:57:39+08:00,"foruda,rct/cann,mindspore-repo,productrepo/HiAI",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBP4MK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,CANN 升级 CANN包引入，具体是opp kernel组件，是否偶现：否 DTS单：DTS2025021114075,Appearance & Root Cause 问题：mint.argmax算子精度问题 根因： CANN包升级引入，升级CANN包可以解决 Fix Solution 升级CANN包 Fix Description & Test Suggestion 无 Selftest Report & DT Review 无 Introduction Analysis 引入类型：CANN升级 问题是否偶现：否 CANN 包引入，具体是opp kernel组件，是否偶现：否 DTS单：DTS2025021114075,"【回归版本号】：__commit_id__ = '[sha1]:e460364b,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com//productrepo/HiAI/Milan_C21/20250307_atlas/ !输入图片说明"
ascend,tanxinglian,"[CT][MS][OPS][ops.deformable_conv2d][function][全量]ops.deformable_conv2d ascend报错RuntimeError: Launch kernel failed, name:Default/DeformableOffsetsop0"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.deformable_conv2d ascend报错RuntimeError: Launch kernel failed, name:Default/DeformableOffsetsop0  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_deformable_conv2d_input_float16 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_f_deformable_conv2d.py::test_f_deformable_conv2d_input_float16  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ``` ../test_f_deformable_conv2d.py::test_f_deformable_conv2d_input_float16 [WARNING] ME(609796:140099693287232,MainProcess):2025022304:18:53.419.956 [mindspore/context.py:1335] For 'context.set_context', the parameter 'device_target' will be deprecated and removed in a future version. Please use the api mindspore.set_device() instead. [WARNING] ME(609796:140099693287232,MainProcess):2025022304:18:53.421.360 [mindspore/context.py:1335] For 'context.set_context', the parameter 'device_target' will be deprecated and removed in a future version. Please use the api mindspore.set_device() instead. [ERROR] KERNEL(609796,7f6b5a6de700,python3.10):2025022304:18:58.497.174 [mindspore/ccsrc/plugin/device/ascend/kernel/acl/acl_kernel_mod.cc:260] Launch] Kernel launch failed, msg: Acl compile and execute failed, op_type_:DeformableOffsets   Ascend Error Message:  EZ9999: Inner Error! EZ9999: [PID: 609796] 2025022304:18:58.496.135 Input_offsets h/w should be same as h/w after convolution, but now offset: [h:12, w:2]. conv_out: [h:63, w:2].[FUNC:DeformableOffsetsInferShape][FILE:deformable_offsets.cc][LINE:138][THREAD:611077]         TraceBack (most recent call last):        InferShape failed, node type DeformableOffsets, name DeformableOffsets1, errorcode 4294967295[FUNC:InferShape][FILE:infer_shape.cc][LINE:173][THREAD:611077]        [Exec][Op]Execute op failed. op type = DeformableOffsets, ge result = 4294967295[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:161][THREAD:611077] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/acl_ir/acl_utils.cc:395 Run [ERROR] DEVICE(609796,7f6b5a6de700,python3.10):2025022304:18:58.497.218 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge_kernel_executor.cc:1321] LaunchKernel] Launch kernel failed, kernel full name: Default/DeformableOffsetsop0 FAILED =================================== FAILURES =================================== ____________________ test_f_deformable_conv2d_input_float16 ____________________          def test_f_deformable_conv2d_input_float16():         strides = (1, 1, 1, 1)         padding = (0, 0, 0, 0)         dilations = (1, 1, 1, 1)         batch, cin, x_h, x_w = 1, 64, 3, 6         cout, kh, kw = 1, 2, 2         fact = DeformableConv2DFactory(batch, cin, cout, x_h, x_w, kh, kw, strides,                                        padding, dilations, dtype=np.float16) >       fact.forward_cmp() ../test_f_deformable_conv2d.py:62:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/deformable_conv2d_ops.py:295: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/functional/deformable_conv2d_ops.py:179: in forward_mindspore_impl     out = net(x, w, offsets, bias) ../../share/utils.py:290: in __call__     _pynative_executor.sync() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =      def sync(self):         """"""         SyncStream.         Return:             None.         """""" >       self._executor.sync() E       RuntimeError: Launch kernel failed, name:Default/DeformableOffsetsop0 E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/runtime/pynative/op_runner.cc:648 LaunchKernels /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1578: RuntimeError =============================== warnings summary =============================== ../../../../../../miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/_op_impl/_custom_op/batchnorm_fold2.py:57 ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67b8706784dee72f16d75add&workspaceId=67ba33c7a052d732536727e8    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:21:04+08:00,"gitee,foruda,rca/others,ctl/componenttest,rct/cann,mindspore-repo",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBP3Q4,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：升级Milan_C21/20250206包后，deformable_conv2d用例执行失败 根因： 1、 CANN包升级引入，opp包，必现。 2、 据CANN算子责任人分析，1月16号有人提交了对NHWC格式实现，2月6号代码回退了该代码，取2月7号以后的cann包就没这个问题了。 Fix Solution 升级CANN，使用2月7号之后的CANN包。当前使用0219的CANN验证用例，执行通过。 Fix Description & Test Suggestion 使用2月7号之后的CANN包回归用例。 测试建议：回归当前用例。 Selftest Report & DT Review 使用0219的CANN验证用例，执行通过。 是否需要补充 ST/UT：否 如果选择否，请补充理由 原因：非MS问题，当前用例足以看护。 Introduction Analysis 引入类型：Milan_C21/20250206 CANN包引入 PR合入时间：年/月/日 问题是否偶现：是/否,"【回归版本号】：__commit_id__ = '[sha1]:ba6873c3,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包 http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][mint.nn.functional.interpolate][function][全量]mint.nn.functional.interpolate 910A pynative模式报错RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.interpolate 910A pynative模式报错RuntimeError: aclnnUpsampleBilinear2dBackwardGetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_f_interpolate_dyn_rank_bilinear test_dynamic_shape_f_interpolate_dyn_shape_bilinear test_mint_n_f_interpolate_bilinear_float16 test_mint_n_f_interpolate_bilinear_float32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_n_f_interpolate.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       ()     ()     ()     def test_mint_n_f_interpolate_bilinear_float16():         input_x = Tensor(np.random.randn(3, 6, 7, 4), mstype.float16)         size = 3         scale_factor = None         mode = 'bilinear'         align_corners = True         recompute_scale_factor = False         antialias = False         fact = InterpolateMock(             attributes={'size': size, 'scale_factor': scale_factor, 'mode': mode,                         'align_corners': align_corners,                         'recompute_scale_factor': recompute_scale_factor, 'antialias': antialias},             inputs=[input_x])         fact.forward_cmp() >       fact.grad_cmp() ../test_mint_n_f_interpolate.py:466:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/interpolate_mint.py:140: in grad_cmp     grad_mindspore = self.grad_mindspore_impl() ../../share/mint/nn_functional/interpolate_mint.py:83: in grad_mindspore_impl     return grad.asnumpy() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = Tensor(shape=[3, 6, 7, 4], dtype=Float16, value= [[[[ 1.2471e+00,  5.2734e01,  2.2012e+00, 6.5283e01],    [ 1.6494e...],    [ 1.9609e+00,  1.4092e+00, 5.1660e01, 3.2104e01],    [ 7.1875e01,  3.9673e01,  0.0000e+00,  0.0000e+00]]]])     def asnumpy(self):         """"""         Convert tensor to numpy array. Returns self tensor as a NumPy ndarray. This tensor and the returned ndarray         share the same underlying storage. Changes to self tensor will be reflected in the ndarray.         Returns:             A numpy ndarray which shares the same underlying storage with the tensor.         Examples:             >>> from mindspore import Tensor             >>> import numpy as np             >>> x = Tensor(np.array([1, 2], dtype=np.float32))             >>> y = x.asnumpy()             >>> y[0] = 11             >>> print(x)             [11.  2.]             >>> print(y)             [11.  2.]         """"""         if self.has_init:             self.init_data() >       return TensorPy_.asnumpy(self) E       RuntimeError: aclnnUpsampleBilinear2dBackwardGetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 413614] 2025022401:14:57.359.393 out tensor's shape[[3,6,7,4]] is not equal with inferOut shape[[3,6,3,3]].[THREAD:415737] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/pyboost/customize/upsample_bilinear2d_grad.cc:36 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/tensor.py:1047: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bb5876a052d732536a3f38&workspaceId=67bb586884dee72f16e054f6    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:12:59+08:00,"gitee,foruda,foruda,rct/cann,mindspore-repo,dts-szv",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBP3MH,cann问题，已有dts单跟踪：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025021721028,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,"Appearance & Root Cause aclnn接口里有个判断写错了，导致没走到正确的分支,直接校验输入输出shape CANN问题单 DTS2025021721028 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：当前已有用例",【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 解决方案 (Fix Solution) 2. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,"Appearance & Root Cause 910A pynative模式报错在aclnn算子上 Fix Solution CANN问题单：aclnn接口里有个判断写错了，导致没走到正确的分支,直接校验输入输出shape DTS2025021721028 Fix Solution cann已修复 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：当前已有用例","【回归版本号】：__commit_id__ = '[sha1]:d0baee5f,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明 !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][ops.xlogy][function][全量]ops.xlogy 报错TypeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.xlogy 报错TypeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_functional_xlogy_input_2d_x_float16_y_bool test_functional_xlogy_input_2d_x_float32_y_number_float test_functional_xlogy_input_2d_x_number_int_y_float32 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_f_xlogy.py  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      def test_functional_xlogy_input_2d_x_float16_y_bool():         inputx_shape = (5, 15)         inputy = True         inputx = Tensor(np.abs(np.random.randn(*inputx_shape).astype(np.float16)))         xlogy = ms.ops.operations.Xlogy() >       xlogy(inputx, inputy) ../test_f_xlogy.py:240:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = Prim[Xlogy] input = Tensor(shape=[5, 15], dtype=Float16, value= [[ 4.2480e01,  1.6533e+00,  9.5605e01 ...  5.8643e01,  7.0166e01,  4.5...33e01,  9.3555e01,  6.0840e01],  [ 8.8818e01,  5.7373e01,  7.6965e02 ...  4.7363e01,  1.8640e01,  6.8164e01]]) other = True     def __call__(self, input, other):          Add for jit context.         if jit_context() and jit_context().compiled:             return None >       res = _convert_stub(pyboost_xlogy(self, [input, other])) E       TypeError: Failed calling Xlogy with ""Xlogy()(input=Tensor, other=bool)"". E       The valid calling should be:  E       ""Xlogy()(input=, other=)"". E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1217 PrintTypeCastError /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/auto_generate/gen_ops_prim.py:19899: TypeError =============================== warnings summary =============================== ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866710&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250223%2003:32:06&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bade0c7b13446a61529342&workspaceId=67bade059b707706537521ae    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-26T16:00:53+08:00,"gitee,rca/others,ctl/componenttest,rct/bugfix",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBP3CR,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,去掉隐式类型转换导致，走给冬冬,已提交接口变更申请议题，预计周二评审+修改资料+走单。,Appearance & Root Cause 问题：Xlogy算子原语直调时输入标量会报错TypeError 根因： 1、 原语已去除type_cast，不再支持非Tensor输入。相关变更上库只处理了对外ops、Tensor、mint接口，未处理Xlogy原语资料。 Fix Solution 1. Xlogy原语资料，补充Xlogy算子功能变更评审。 Fix Description & Test Suggestion https://gitee.com/mindspore/mindspore/pulls/83453 已合入master分支，PR合入后daily包回归 测试建议：通过MindSporeTest算子用例看护即可，出错用例为functional接口用例，不需要直接调用原语。 Selftest Report & DT Review 无，看护上层ops、Tensor、mint接口即可。 是否需要补充 ST/UT：否 修改MindSporeTest仓用例。 Introduction Analysis 引入类型：Bugfix 修复引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81625 PR合入时间：2025/2/19 问题是否偶现：否,原语已去除type_cast，不再支持非Tensor输入，接口变更邮件已发，需适配用例 相关资料已修改
ascend,孙昊辰,add 310p internal restriction when check group_list parameter,"   Describe the current behavior / 问题描述 (Mandatory / 必填) add 310p internal restriction when check group_list parameter  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  Ascend 910B  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :2.5.1  Python version (e.g., Python 3.7.5) :Python 3.9  OS platform and distribution (e.g., Linux Ubuntu 16.04):Ubuntu  GCC/Compiler version (if compiled from source): 7.3.0  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode pynative  Related testcase / 关联用例 (Mandatory / 必填) test_grouped_matmul.py  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 整网测试grouped matmul算子  Describe the expected behavior / 预期结果 (Mandatory / 必填)  报错 group_list's last element must be equal to 4  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  group_list's last element must be equal to 4  Special notes for this issue/备注 (Optional / 选填)",2025-02-26T15:02:38+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBP1Z9
graph mode,reeered,mindspore.mint.nn.functional.selu在Graph Mode下使用时编译出错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.selu在Graph Mode下使用时编译出错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python import mindspore as ms import mindspore.mint.nn.functional as F_mint import numpy as np from mindspore import Tensor class SeLUNet(ms.nn.Cell):     def __init__(self):         super().__init__()     def construct(self, x):         return F_mint.selu(x) if __name__ == '__main__':     ms.set_context(mode=ms.GRAPH_MODE, device_target='Ascend')     x_np = np.random.randn(2, 3).astype(np.float32)     net = SeLUNet()         y = net(Tensor(x_np)) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 编译出错  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.194.944 [mindspore/ccsrc/transform/graph_ir/convert.cc:4323] ConvertCNode] Cannot get adapter for Default/SeLUExtop0 [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.101 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_3{[0]: ValueNode PrimFunc_SeLUExt, [1]: param_x}. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.117 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: ValueNode Return. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.420 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_4{[0]: ValueNode Return, [1]: CNode_3}. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.444 [mindspore/ccsrc/transform/graph_ir/convert.cc:1147] GenerateCheckpointGraph] Generate checkpoint graph failed, found error code 4. [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.456 [mindspore/ccsrc/transform/graph_ir/convert.cc:1149] GenerateCheckpointGraph] 1 Operator(s) cannot be converted: [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.467 [mindspore/ccsrc/transform/graph_ir/convert.cc:1157] GenerateCheckpointGraph] Unsupported op type list: SeLUExt [ERROR] DEVICE(1569,ffffb4809010,python):2025022511:38:06.195.484 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_utils.cc:420] AddDFGraph] Convert df graph failed, err:4 [ERROR] DEVICE(1569,ffffb4809010,python):2025022511:38:06.195.524 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:1429] BuildDFGraph] GenConvertor failed [ERROR] GE_ADPT(1569,ffffb4809010,python):2025022511:38:06.195.566 [mindspore/ccsrc/transform/graph_ir/graph_runner.cc:527] GetWrapper] Get graph form DfGraphManager failed! Traceback (most recent call last):   File ""/tmp/code/OpenI_Cloudbrain_Example/test/test_selu_net.py"", line 18, in      y = net(Tensor(x_np))   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 732, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1150, in compile_and_run     self.compile(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1133, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py"", line 1897, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) RuntimeError: Compile graph kernel_graph0 failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:598 CompileGraph",2025-02-25T19:40:22+08:00,"mindspore-assistant,foruda,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOUKG,我这边测试了一下这个问题，感觉是2.5.0版本的nn.Cell的construct方法走静态图的问题，但用mindspore.jit的方式走静态图的话，就能成功运行： !输入图片说明 !输入图片说明
ascend,tanxinglian,"[CT][MS][OPS][tensor.uniform][function][全量]tensor.uniform 报错RuntimeError: aclnnInplaceUniformGetWorkspaceSize call failed, please check!"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > tensor.uniform 报错RuntimeError: aclnnInplaceUniformGetWorkspaceSize call failed, please check!  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_t_uniform_bool__8d_5x8x7x3x7x4x9x7_random_forward >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b:O0 910A：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_t_uniform.py::test_t_uniform_bool__8d_5x8x7x3x7x4x9x7_random_forward  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='aclnn算子没有开发CPU')     (reason='aclnn算子没有开发GPU')     (reason='aclnn算子没有开发GE流程')     def test_t_uniform_bool__8d_5x8x7x3x7x4x9x7_random_forward():         x = Tensor(np.random.randn(5, 8, 7, 3, 7, 4, 9, 7), mstype.bool_)         from_ = False         to = False         generator = None         fact = UniformMock(             attributes={'generator': generator},             inputs=[x, from_, to]) >       fact.forward_cmp() ../test_t_uniform.py:215:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/tensor/uniform_ops.py:133: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/ops/tensor/uniform_ops.py:69: in forward_mindspore_impl     out = net(self.x, self.from_, self.to) ../../share/utils.py:290: in __call__     _pynative_executor.sync() _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =      def sync(self):         """"""         SyncStream.         Return:             None.         """""" >       self._executor.sync() E       RuntimeError: aclnnInplaceUniformGetWorkspaceSize call failed, please check! E        E        E        Ascend Error Message: E        E       EZ1001: [PID: 2124973] 2025022313:11:35.987.946 self not implemented for DT_BOOL, should be in dtype support list [DT_FLOAT,DT_INT32,DT_INT64,DT_FLOAT16,DT_INT16,DT_INT8,DT_UINT8,DT_DOUBLE,DT_BFLOAT16,].[THREAD:2127345] E        E       (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description) E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ops/kernel/ascend/pyboost/customize/uniform_ext.cc:73 operator() /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1578: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bab13f9b7077065374b784&workspaceId=67bab133a052d7325368d29d&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T19:33:40+08:00,"gitee,rct/cann",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBOUHX,Appearance & Root Cause CANN从8.0更换到8.1之后，tensor.uniform 报错不支持bool类型输入， 经与CANN开发对齐， 当前版本8.1.RC1已删除对bool类型支持。 CANN问题单 DTS2025010742839 Fix Description & Test Suggestion 测试建议：修改测试用例，使用最新版本的CANN包回归（8.1.rc1之后） Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：CANN升级 引入PR：https://gitee.com/ascend/canndev/pulls/61484 PR合入时间：2025年/1月/22日 问题是否偶现：否,cann因DTS2025010742839去掉支持bool类型 需适配用例
graph mode,reeered,mindspore.mint.nn.functional.mish在Graph Mode下使用时编译出错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.mish在Graph Mode下使用时编译出错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python import mindspore as ms import mindspore.mint.nn.functional as F_mint import numpy as np from mindspore import Tensor class MishNet(ms.nn.Cell):     def __init__(self):         super().__init__()     def construct(self, x):         return F_mint.mish(x) if __name__ == '__main__':     ms.set_context(mode=ms.GRAPH_MODE, device_target='Ascend')     x_np = np.random.randn(2, 3).astype(np.float32)     net = MishNet()         y = net(Tensor(x_np)) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 编译出错  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.440 [mindspore/ccsrc/transform/graph_ir/convert.cc:4323] ConvertCNode] Cannot get adapter for Default/MishExtop0 [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.551 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_3{[0]: ValueNode PrimFunc_MishExt, [1]: param_x}. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.569 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: ValueNode Return. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.883 [mindspore/ccsrc/transform/graph_ir/convert.cc:1224] ConvertAllNode] Failed to convert node: :CNode_4{[0]: ValueNode Return, [1]: CNode_3}. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.907 [mindspore/ccsrc/transform/graph_ir/convert.cc:1147] GenerateCheckpointGraph] Generate checkpoint graph failed, found error code 4. [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.940 [mindspore/ccsrc/transform/graph_ir/convert.cc:1149] GenerateCheckpointGraph] 1 Operator(s) cannot be converted: [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.779.957 [mindspore/ccsrc/transform/graph_ir/convert.cc:1157] GenerateCheckpointGraph] Unsupported op type list: MishExt [ERROR] DEVICE(1901,ffff84760010,python):2025022310:33:44.779.979 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_utils.cc:420] AddDFGraph] Convert df graph failed, err:4 [ERROR] DEVICE(1901,ffff84760010,python):2025022310:33:44.780.021 [mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:1429] BuildDFGraph] GenConvertor failed [ERROR] GE_ADPT(1901,ffff84760010,python):2025022310:33:44.780.059 [mindspore/ccsrc/transform/graph_ir/graph_runner.cc:527] GetWrapper] Get graph form DfGraphManager failed! Traceback (most recent call last):   File ""/tmp/code/OpenI_Cloudbrain_Example/test/test_mish_net.py"", line 18, in      y = net(Tensor(x_np))   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 732, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1150, in compile_and_run     self.compile(*args, **kwargs)   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py"", line 1133, in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase,   File ""/home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py"", line 1897, in compile     result = self._graph_executor.compile(obj, args, kwargs, phase, self._use_vm_mode()) RuntimeError: Compile graph kernel_graph0 failed.   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/hal/hardware/ge/ge_graph_executor.cc:598 CompileGraph",2025-02-25T19:27:05+08:00,"mindspore-assistant,foruda,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOUGA,这个问题也是和selu那个一样，走nn.Cell的construct方法的静态图就报错，但走ms.jit就可以运行 !输入图片说明 !输入图片说明
graph mode,郑炼鑫,【接口测试任务26】接口mindspore.mint.nn.Fold存在的若干问题(同.mint.nn.Unfold)," 1. Describe the current behavior / 问题描述  **问题1：在图模式（GRAPH_MODE）下不支持运行（该问题在评论区中更正解答）**  **问题描述**：     `mindspore.mint.nn.Fold`在`GRAPH_MODE`下无法运行，提示底层算子不支持，而其他测试（如`Unfold`）也提到类似问题，表明`mint`模块可能普遍不支持图模式。  **预期结果**：     `mindspore.mint.nn.Fold`应在`GRAPH_MODE`下正常运行，与`torch.nn.Fold`保持一致，支持Ascend硬件加速，并在图模式下提供优化性能。  **实际结果**：     在`GRAPH_MODE`且`device_target=""Ascend""`时，`mint.nn.Fold`触发运行时错误，提示底层算子`Col2ImExt`不支持图模式编译，而`torch.nn.Fold`正常运行。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn    设置图模式和Ascend设备   context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"")    输入数据 (1, 8, 4)，适配Fold参数   input_np = np.ones((1, 8, 4), dtype=np.float32)   input_ms = Tensor(input_np, dtype=ms.float32)   input_torch = torch.tensor(input_np, dtype=torch.float32)    测试mint.nn.Fold   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = fold_mint(input_ms)       print(""MindSpore mint.nn.Fold 输出:"", output_mint.shape)   except Exception as e:       print(f""MindSpore mint.nn.Fold 错误: {type(e).__name__}: {str(e)[:100]}"")    PyTorch对比   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = fold_torch(input_torch)   print(""PyTorch nn.Fold 输出:"", output_torch.shape)   ```  **代码运行结果**：   ```   MindSpore mint.nn.Fold 错误: RuntimeError: Unsupported op type: Col2ImExt in Graph mode on Ascend   PyTorch nn.Fold 输出: torch.Size([1, 2, 4, 4])   ```  **底层原因可能是什么**：     `mint.nn.Fold`依赖Ascend的`Col2ImExt`算子，而在`GRAPH_MODE`下，MindSpore的Graph Engine（GE）需要为该算子提供适配器支持。由于`Col2ImExt`在GE中未完整实现或未注册，导致编译失败。`mint`模块可能设计时优先适配`PYNATIVE_MODE`，未充分考虑图模式需求。  **针对前面提到的原因给出分析和建议**：      **分析**：       图模式是MindSpore的优化执行模式，广泛用于训练场景。`mint.nn.Fold`不支持此模式，限制了其在生产环境中的应用。相比之下，`torch.nn.Fold`基于通用计算路径（如CPU/GPU）无需类似硬件适配问题。`mint`模块的图模式不支持可能与其优化目标（轻量化、硬件加速）有关，但未明确文档化，增加了用户误用风险。      **建议**：       1. 在官方文档中明确标注`mint.nn.Fold`不支持`GRAPH_MODE`，避免用户误用。       2. 为`Col2ImExt`提供GE适配器支持，或在图模式下回退到通用实现（如基于基础算子组合），确保一致性。       3. 若不支持为有意设计，建议优化错误提示（如“Graph mode not supported for mint.nn.Fold”），提升用户体验。   **问题2：对Float64类型伪支持，延迟报错**  **问题描述**：     `mindspore.mint.nn.Fold`对`Float64`类型表现出伪支持，前向计算未报错，但访问输出时抛出错误，与`torch.nn.Fold`支持`Float64`的行为不一致。  **预期结果**：     `mint.nn.Fold`应明确支持`Float64`类型并输出正确结果，或在调用时立即抛出类型不支持的异常，与`torch.nn.Fold`的明确支持行为对齐。  **实际结果**：     `mint.nn.Fold`在构造和前向计算时未报错，但调用`asnumpy()`访问输出时抛出底层ACL异常（`aclnnIm2colBackwardGetWorkspaceSize call failed`），表明伪支持`Float64`。而`torch.nn.Fold`正常支持`Float64`。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 8, 4), dtype=np.float64)    MindSpore mint.nn.Fold   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       input_ms = Tensor(input_np, dtype=ms.float64)       output_mint = fold_mint(input_ms)       print(f""MindSpore mint.nn.Fold 输出形状: {output_mint.shape}, dtype: {output_mint.dtype}"")       print(f""output_mint: {output_mint.asnumpy()}"")   except Exception as e:       print(f""MindSpore mint.nn.Fold 错误: {type(e).__name__}: {str(e)[:50]}"")    PyTorch nn.Fold   input_torch = torch.tensor(input_np, dtype=torch.float64)   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = fold_torch(input_torch)   print(f""PyTorch nn.Fold 输出形状: {output_torch.shape}, dtype: {output_torch.dtype}"")   print(f""output_torch: {output_torch.numpy()[:2]}"")   ```  **代码运行结果**：   ```   MindSpore mint.nn.Fold 输出形状: (1, 2, 4, 4), dtype: Float64   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 输出形状: torch.Size([1, 2, 4, 4]), dtype: torch.float64   output_torch: [[[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]] [[1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.] [1. 1. 1. 1.]]]   ```  **底层原因可能是什么**：     `mint.nn.Fold`依赖Ascend的ACL接口（如`aclnnIm2colBackward`），其底层实现未适配`Float64`，但MindSpore前端未提前校验类型兼容性，导致错误延迟到执行阶段触发。Ascend硬件（如AICore）可能优化为支持`float16`和`float32`，对`Float64`支持有限。  **针对前面提到的原因给出分析和建议**：      **分析**：       `Float64`在深度学习中较少使用，但作为标准浮点类型，PyTorch提供完整支持。`mint.nn.Fold`的伪支持现象表明其类型检查不足，可能因硬件加速优先级（`float32`/`float16`）而忽略`Float64`，但未明确拒绝，导致潜在隐患。延迟报错增加了调试难度。      **建议**：       1. 在接口层添加类型检查，提前抛出`TypeError`（如“Float64 not supported”）。       2. 若有意不支持`Float64`，应在文档中明确说明，并与`torch.nn.Fold`的行为差异进行标注。       3. 若计划支持，需完善ACL层对`Float64`的适配，确保计算完整性。   **问题3：对Int/UInt/Bool类型伪支持，延迟报错**  **问题描述**：     `mindspore.mint.nn.Fold`对`Int`、`UInt`和`Bool`类型表现出伪支持，前向计算未报错，但访问输出时抛出错误，与`torch.nn.Fold`明确拒绝此类类型的行为不一致。  **预期结果**：     `mint.nn.Fold`应明确不支持`Int`、`UInt`和`Bool`类型，在调用时立即抛出类型错误，与`torch.nn.Fold`一致（后者报错“not implemented for [type]”）。  **实际结果**：     对于`Int`、`UInt`和`Bool`类型，`mint.nn.Fold`构造和前向计算成功，但访问输出时抛出底层ACL错误（`aclnnIm2colBackwardGetWorkspaceSize call failed`），表明伪支持。`torch.nn.Fold`直接报错不支持此类类型。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 8, 4))   dtypes = [(ms.int32, torch.int32), (ms.uint8, torch.uint8), (ms.bool_, torch.bool)]   for ms_dtype, torch_dtype in dtypes:       print(f""\n测试类型: {ms_dtype}, {torch_dtype}"")        MindSpore mint.nn.Fold       fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))       try:           input_ms = Tensor(input_np, dtype=ms_dtype)           output_mint = fold_mint(input_ms)           print(f""MindSpore mint.nn.Fold 形状: {output_mint.shape}, dtype: {output_mint.dtype}"")           print(output_mint.asnumpy())       except Exception as e:           print(f""MindSpore mint.nn.Fold 错误: {type(e).__name__}: {str(e)[:50]}"")        PyTorch nn.Fold       try:           input_torch = torch.tensor(input_np, dtype=torch_dtype)           fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))           output_torch = fold_torch(input_torch)       except Exception as e:           print(f""PyTorch nn.Fold 不支持 {torch_dtype}: {type(e).__name__}: {str(e)[:50]}"")   ```  **代码运行结果**：   ```   测试类型: Int32, torch.int32   MindSpore mint.nn.Fold 形状: (1, 2, 4, 4), dtype: Int32   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 不支持 torch.int32: RuntimeError: ""col2im_out_cpu"" not implemented for 'Int'   测试类型: UInt8, torch.uint8   MindSpore mint.nn.Fold 形状: (1, 2, 4, 4), dtype: UInt8   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 不支持 torch.uint8: RuntimeError: ""col2im_out_cpu"" not implemented for 'Byte'   测试类型: Bool, torch.bool   MindSpore mint.nn.Fold 形状: (1, 2, 4, 4), dtype: Bool   MindSpore mint.nn.Fold 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, p   PyTorch nn.Fold 不支持 torch.bool: RuntimeError: ""col2im_out_cpu"" not implemented for 'Bool'   ```  **底层原因可能是什么**：     `mint.nn.Fold`的前端未对输入类型进行严格校验，允许非浮点类型（如`Int32`、`UInt8`、`Bool`）进入ACL计算流程，但Ascend的`aclnnIm2colBackward`不支持这些类型，导致延迟错误。`Fold`操作本质上是浮点计算，整数和布尔类型无意义。  **针对前面提到的原因给出分析和建议**：      **分析**：       `Int`、`UInt`和`Bool`类型在`Fold`操作中无实际意义，PyTorch在前端明确拒绝，`mint.nn.Fold`却未进行类型校验，导致伪支持。这种行为可能误导用户认为这些类型可用，实际执行时却失败，影响鲁棒性。      **建议**：       1. 在接口层添加类型校验，限制输入为`float32`或`float16`（如`if dtype not in [ms.float32, ms.float16]: raise TypeError`）。       2. 提高错误信息清晰度，明确提示不支持的类型（如“Int32 not supported by mint.nn.Fold”）。       3. 参考PyTorch实现，提前终止非浮点类型计算，减少调试成本。   **问题4：对非法输入维度校验滞后**  **问题描述**：     `mindspore.mint.nn.Fold`在面对非法维度输入（如0维、1维、5维张量）时，前向计算未立即报错，仅在访问输出时触发异常，校验滞后。  **预期结果**：     对于非法维度输入（`Fold`要求输入为2D或3D张量），`mint.nn.Fold`应在调用时立即抛出维度错误，与`torch.nn.Fold`一致（后者报错“Expected 2D or 3D tensor”）。  **实际结果**：     `mint.nn.Fold`在构造和前向计算时未报错，仅在访问输出（如`asnumpy()`）时抛出维度校验错误（如“For primitive[Col2ImExt], the input rank must be in [2,3]”），表明校验滞后。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   test_cases = [       (""0维"", Tensor(42.0, ms.float32), torch.tensor(42.0)),       (""1维"", Tensor(np.ones(6), ms.float32), torch.ones(6)),       (""5维"", Tensor(np.ones((1, 2, 3, 4, 5)), ms.float32), torch.ones(1, 2, 3, 4, 5)),   ]   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   for desc, ms_input, torch_input in test_cases:       print(f""\n测试场景: 输入为 {desc} 张量"")       try:           output_mint = fold_mint(ms_input)           print(f""MindSpore mint.nn.Fold 形状: {output_mint.shape}"")           output_mint.asnumpy()       except Exception as e:           print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")       try:           output_torch = fold_torch(torch_input)       except Exception as e:           print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   测试场景: 输入为 0维 张量   MindSpore 错误: ValueError: For primitive[Col2ImExt], the input rank must be in [2,3], but got 0.   PyTorch 错误: RuntimeError: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and nonzero dimensio   测试场景: 输入为 1维 张量   MindSpore 错误: ValueError: For primitive[Col2ImExt], the input rank must be in [2,3], but got 1.   PyTorch 错误: RuntimeError: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and nonzero dimensio   测试场景: 输入为 5维 张量   MindSpore 错误: ValueError: For primitive[Col2ImExt], the input rank must be in [2,3], but got 5.   PyTorch 错误: RuntimeError: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and nonzero dimensio   ```  **底层原因可能是什么**：     `mint.nn.Fold`的维度校验逻辑嵌入在底层算子`Col2ImExt`中，而非Python接口层，导致错误延迟暴露。`Fold`操作要求输入为2D（无批次）或3D（有批次）张量，MindSpore未在前端执行校验。  **针对前面提到的原因给出分析和建议**：      **分析**：       `Fold`操作的输入维度要求明确（2D/3D），PyTorch在调用时立即检查维度并报错，而`mint.nn.Fold`将校验推迟到执行阶段，降低了鲁棒性并增加了调试难度。这种滞后校验与其他`mint`接口（如`Unfold`）行为一致，可能为框架设计缺陷。      **建议**：       1. 在接口层添加维度校验（如`if input.ndim not in [2, 3]: raise ValueError`）。       2. 提供更具体的错误提示（如“Expected 2D or 3D tensor, got X dimensions”），参考PyTorch风格。       3. 优化异常处理流程，确保校验前置，提升用户体验。   **问题5：错误信息不够明确**  **问题描述**：     `mindspore.mint.nn.Fold`在面对不支持的类型（如`Int32`）或非法输入时，抛出的错误信息为底层ACL通用提示（如`aclnnIm2colBackwardGetWorkspaceSize call failed`），未指明具体原因，缺乏针对性。  **预期结果**：     对于不支持的类型或非法输入，`mint.nn.Fold`应提供具体且具指导性的错误信息（如“Type Int32 not supported”或“Input dimension mismatch”），与`torch.nn.Fold`的清晰提示（如“not implemented for 'Int'”）对齐。  **实际结果**：     `mint.nn.Fold`抛出的错误为底层ACL通用信息（如`aclnnIm2colBackwardGetWorkspaceSize call failed`），未明确指出类型或输入问题，`torch.nn.Fold`则直接提示具体原因。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 8, 4), dtype=np.int32)   fold_mint = mint_nn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = fold_mint(Tensor(input_np, ms.int32))       output_mint.asnumpy()   except Exception as e:       print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")   fold_torch = tnn.Fold(output_size=(4, 4), kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_torch = fold_torch(torch.tensor(input_np, dtype=torch.int32))   except Exception as e:       print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   MindSpore 错误: RuntimeError: aclnnIm2colBackwardGetWorkspaceSize call failed, please check!   PyTorch 错误: RuntimeError: ""col2im_out_cpu"" not implemented for 'Int'   ```  **底层原因可能是什么**：     MindSpore的错误处理链未将ACL层的具体错误码映射到用户友好的提示，直接暴露底层失败信息。`aclnnIm2colBackward`可能因类型不支持而失败，但未在Python层解析具体原因。  **针对前面提到的原因给出分析和建议**：      **分析**：       PyTorch的错误信息明确指向类型问题（“not implemented for 'Int'”），便于用户定位，而`mint.nn.Fold`的通用提示（“call failed”）缺乏上下文，用户难以判断是类型、维度还是其他问题导致失败。这种模糊性在`mint`模块中反复出现，影响开发效率。      **建议**：       1. 在Python层捕获ACL错误并解析（如`if ""aclnnIm2colBackward"" in str(e): raise TypeError(""Unsupported dtype"")`）。       2. 优化错误信息，提供类型或参数的具体上下文（如“Int32 not supported by mint.nn.Fold”）。       3. 参考PyTorch的异常处理机制，改进错误提示的针对性和指导性。   2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```   3. Related testcase / 关联用例  **Testcase Name / 用例名**:      null  **Excute Mode / 执行模式**:      Excute Mode: PyNative     4. Steps to reproduce the issue / 重现步骤 1. 配置MindSpore环境：    ```bash    pip install mindspore==2.4.10    ``` 2. 运行测试脚本：    ```bash    python test_mint_nn_Fold.py    ``` 3. 检查每种问题的输出日志，验证问题复现。   5. Describe the expected behavior / 预期结果  **【预期结果】**：     1. `mint.nn.Fold`在`GRAPH_MODE`下正常运行，支持Ascend硬件加速。     2. 明确支持或拒绝`Float64`，并在调用时抛出异常。     3. 对`Int`/`UInt`/`Bool`类型提前报错，不伪支持。     4. 对非法维度输入立即抛出维度错误。     5. 提供具体、清晰的错误信息，指向问题根源。   6. Related log / screenshot / 日志 / 截图  **报错关键日志截图**：    **问题1**： !输入图片说明  **问题2**： !输入图片说明  **问题3**： !输入图片说明  **问题4**： !输入图片说明  **问题5**： !输入图片说明   7. Special notes for this issue / 备注  **【定位人】**：ZhFuGui    **【优先级建议】**：      问题1（图模式不支持）：P1（影响训练场景）      问题2（Float64伪支持）：P2（类型支持一致性）      问题3（Int/UInt/Bool伪支持）：P2（潜在隐患）      问题4（维度校验滞后）：P1（鲁棒性问题）      问题5（错误信息不明确）：P3（开发体验）  ",2025-02-25T19:25:58+08:00,mindspore-assistant,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOUG3
graph mode,郑炼鑫,【接口测试任务26】接口mindspore.mint.nn.Unfold存在的若干问题," 1. Describe the current behavior / 问题描述  **问题1：在图模式（GRAPH_MODE）下不支持运行（该问题在评论区中更正解答）**  **预期结果**：     `mindspore.mint.nn.Unfold`应在`GRAPH_MODE`下正常运行，与`mindspore.nn.Unfold`和`torch.nn.Unfold`保持一致，支持Ascend硬件加速。  **实际结果**：     在`GRAPH_MODE`且`device_target=""Ascend""`时，`mint.nn.Unfold`触发运行时错误，提示底层算子`Im2ColExt`不支持图模式编译，而`nn.Unfold`和PyTorch版本正常运行。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn    设置图模式和Ascend设备   context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"")    输入数据   input_np = np.ones((1, 2, 6, 6), dtype=np.float32)   input_ms = Tensor(input_np, dtype=ms.float32)    测试mint.nn.Unfold   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = unfold_mint(input_ms)       print(""MindSpore mint.nn.Unfold 输出:"", output_mint.shape)   except Exception as e:       print(f""MindSpore mint.nn.Unfold 错误: {type(e).__name__}: {str(e)[:100]}"")    对比nn.Unfold   unfold_ms = ms.nn.Unfold(ksizes=[1, 2, 2, 1], strides=[1, 2, 2, 1], rates=[1, 1, 1, 1], padding=""valid"")   output_ms = unfold_ms(input_ms)   print(""MindSpore nn.Unfold 输出:"", output_ms.shape)    PyTorch对比   input_torch = torch.tensor(input_np, dtype=torch.float32)   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = unfold_torch(input_torch)   print(""PyTorch nn.Unfold 输出:"", output_torch.shape)   ```  **代码运行结果**：   ```   MindSpore mint.nn.Unfold 错误: RuntimeError: Unsupported op type: Im2ColExt in Graph mode on Ascend   MindSpore nn.Unfold 输出: (1, 8, 9)   PyTorch nn.Unfold 输出: torch.Size([1, 8, 9])   ```  **底层原因可能是什么**：     `mint.nn.Unfold`依赖Ascend的`Im2ColExt`算子，而在`GRAPH_MODE`下，MindSpore的Graph Engine（GE）需要为该算子提供适配器支持。由于`Im2ColExt`在GE中未完整实现或未注册，导致编译失败。  **分析和建议**：      **分析**：此问题可能源于`mint`模块的优化设计仅针对`PYNATIVE_MODE`，未充分适配图模式下的Ascend硬件加速路径。相比之下，`nn.Unfold`使用更通用的算子实现（如基础的`ExtractImagePatches`），绕过了此限制。      **建议**：       1. 在文档中明确标注`mint.nn.Unfold`不支持`GRAPH_MODE`，避免用户误用。       2. 为`Im2ColExt`提供GE适配器支持，或在图模式下回退到通用实现，确保一致性。       3. 向开发者确认是否为有意设计，若是，应优化用户提示信息（如“Graph mode not supported”）。   **问题2：对Float64类型伪支持，延迟报错**  **预期结果**：     `mint.nn.Unfold`应明确支持`Float64`类型并输出正确结果，或在调用时立即抛出类型不支持的异常，与`torch.nn.Unfold`一致。  **实际结果**：     `mint.nn.Unfold`在构造和前向计算时未报错，但访问输出（如`asnumpy()`）时抛出底层ACL异常，表明伪支持`Float64`。而`nn.Unfold`不支持`Float64`，`torch.nn.Unfold`则正常支持。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.nn as nn   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 2, 6, 6), dtype=np.float64)    MindSpore nn.Unfold   unfold_ms = nn.Unfold(ksizes=[1, 2, 2, 1], strides=[1, 2, 2, 1], rates=[1, 1, 1, 1], padding=""valid"")   try:       output_ms = unfold_ms(Tensor(input_np, dtype=ms.float64))       print(f""MindSpore nn.Unfold 输出: {output_ms.shape}"")   except Exception as e:       print(f""MindSpore nn.Unfold 错误: {type(e).__name__}: {str(e)[:50]}"")    MindSpore mint.nn.Unfold   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       input_ms = Tensor(input_np, dtype=ms.float64)       output_mint = unfold_mint(input_ms)       print(f""MindSpore mint.nn.Unfold 输出形状: {output_mint.shape}, dtype: {output_mint.dtype}"")       print(f""output_mint: {output_mint.asnumpy()}"")   except Exception as e:       print(f""MindSpore mint.nn.Unfold 错误: {type(e).__name__}: {str(e)[:50]}"")    PyTorch nn.Unfold   input_torch = torch.tensor(input_np, dtype=torch.float64)   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   output_torch = unfold_torch(input_torch)   print(f""PyTorch nn.Unfold 输出形状: {output_torch.shape}, dtype: {output_torch.dtype}"")   ```  **代码运行结果**：   ```   MindSpore nn.Unfold 错误: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 输出形状: (1, 8, 9), dtype: Float64   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 输出形状: torch.Size([1, 8, 9]), dtype: torch.float64   ```  **底层原因可能是什么**：     `mint.nn.Unfold`依赖Ascend的ACL接口（如`aclnnIm2col`），其底层实现未适配`Float64`，但MindSpore前端未提前校验类型兼容性，导致错误延迟到执行阶段触发。  **分析和建议**：      **分析**：`Float64`在深度学习中较少使用，Ascend硬件（如AICore）可能优化为支持`float16`和`float32`，未完整实现`Float64`的ACL支持。`torch.nn.Unfold`基于通用路径（如CPU/GPU）支持`Float64`，而`mint`模块未明确拒绝此类型，留下隐患。      **建议**：       1. 在接口层添加类型检查，提前抛出`TypeError`（如“Float64 not supported”）。       2. 若有意不支持`Float64`，应在文档中明确说明。       3. 若计划支持，需完善ACL层对`Float64`的适配。   **问题3：对Int/UInt/Bool类型伪支持，延迟报错**  **预期结果**：     `mint.nn.Unfold`应明确不支持`Int`、`UInt`和`Bool`类型，在调用时立即抛出类型错误，与`torch.nn.Unfold`一致（后者明确报错“not implemented for [type]”）。  **实际结果**：     对于`Int`、`UInt`和`Bool`类型，`mint.nn.Unfold`构造和前向计算成功，但访问输出时抛出底层ACL错误，表明伪支持。`nn.Unfold`直接报错，`torch.nn.Unfold`也不支持此类类型。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.nn as nn   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 2, 6, 6))   dtypes = [(ms.int32, torch.int32), (ms.uint8, torch.uint8), (ms.bool_, torch.bool)]   for ms_dtype, torch_dtype in dtypes:       print(f""\n测试类型: {ms_dtype}, {torch_dtype}"")        MindSpore nn.Unfold       unfold_ms = nn.Unfold(ksizes=[1, 2, 2, 1], strides=[1, 2, 2, 1], rates=[1, 1, 1, 1], padding=""valid"")       try:           output_ms = unfold_ms(Tensor(input_np, dtype=ms_dtype))       except Exception as e:           print(f""MindSpore nn.Unfold 不支持 {ms_dtype}: {type(e).__name__}: {str(e)[:50]}"")        MindSpore mint.nn.Unfold       unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))       try:           input_ms = Tensor(input_np, dtype=ms_dtype)           output_mint = unfold_mint(input_ms)           print(f""MindSpore mint.nn.Unfold 形状: {output_mint.shape}, dtype: {output_mint.dtype}"")           print(output_mint.asnumpy())       except Exception as e:           print(f""MindSpore mint.nn.Unfold 错误: {type(e).__name__}: {str(e)[:50]}"")        PyTorch nn.Unfold       try:           input_torch = torch.tensor(input_np, dtype=torch_dtype)           unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))           output_torch = unfold_torch(input_torch)       except Exception as e:           print(f""PyTorch nn.Unfold 不支持 {torch_dtype}: {type(e).__name__}: {str(e)[:50]}"")   ```  **代码运行结果**：   ```   测试类型: Int32, torch.int32   MindSpore nn.Unfold 不支持 Int32: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 形状: (1, 8, 9), dtype: Int32   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 不支持 torch.int32: RuntimeError: ""im2col_out_cpu"" not implemented for 'Int'   测试类型: UInt8, torch.uint8   MindSpore nn.Unfold 不支持 UInt8: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 形状: (1, 8, 9), dtype: UInt8   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 不支持 torch.uint8: RuntimeError: ""im2col_out_cpu"" not implemented for 'Byte'   测试类型: Bool, torch.bool   MindSpore nn.Unfold 不支持 Bool: TypeError: For primitive[ExtractImagePatches], the input argu   MindSpore mint.nn.Unfold 形状: (1, 8, 9), dtype: Bool   MindSpore mint.nn.Unfold 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed,   PyTorch nn.Unfold 不支持 torch.bool: RuntimeError: ""im2col_out_cpu"" not implemented for 'Bool'   ```  **底层原因可能是什么**：     `mint.nn.Unfold`的前端未对输入类型进行严格校验，允许非浮点类型（如`Int32`、`UInt8`、`Bool`）进入ACL计算流程，但Ascend的`aclnnIm2col`不支持这些类型，导致延迟错误。  **分析和建议**：      **分析**：此类类型在卷积操作（如`Unfold`）中无意义，PyTorch在前端明确拒绝，`nn.Unfold`也有类型检查，而`mint`模块缺乏类似机制，导致伪支持现象。      **建议**：       1. 在接口层添加类型校验，限制输入为`float32`或`float16`（如`if dtype not in [ms.float32, ms.float16]: raise TypeError`）。       2. 提高错误信息清晰度，明确提示不支持的类型（如“Int32 not supported”）。       3. 参考PyTorch实现，提前终止非浮点类型计算。   **问题4：非法输入维度校验滞后**  **预期结果**：     对于非法维度输入（如0维、1维、2维、5维张量），`mint.nn.Unfold`应在调用时立即抛出维度错误，与`torch.nn.Unfold`一致（后者明确报错“Dimension out of range”或“Expected 3D/4D tensor”）。  **实际结果**：     `mint.nn.Unfold`在构造和前向计算时未报错，仅在访问输出时抛出维度校验错误，表明校验滞后。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   test_cases = [       (""0维"", Tensor(42.0, ms.float32), torch.tensor(42.0)),       (""1维"", Tensor(np.ones(6), ms.float32), torch.ones(6)),       (""2维"", Tensor(np.ones((2, 6)), ms.float32), torch.ones(2, 6)),       (""5维"", Tensor(np.ones((1, 2, 3, 4, 5)), ms.float32), torch.ones(1, 2, 3, 4, 5)),   ]   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   for desc, ms_input, torch_input in test_cases:       print(f""\n测试场景: 输入为 {desc} 张量"")       try:           output_mint = unfold_mint(ms_input)           print(f""MindSpore mint.nn.Unfold 形状: {output_mint.shape}"")           output_mint.asnumpy()       except Exception as e:           print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")       try:           output_torch = unfold_torch(torch_input)       except Exception as e:           print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   测试场景: 输入为 0维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 0   PyTorch 错误: IndexError: Dimension specified as 1 but tensor has no dimensions   测试场景: 输入为 1维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 1   PyTorch 错误: IndexError: Dimension out of range (expected to be in range of [1, 0], but got 1)   测试场景: 输入为 2维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 2   PyTorch 错误: IndexError: Dimension out of range (expected to be in range of [2, 1], but got 2)   测试场景: 输入为 5维 张量   MindSpore 错误: ValueError: For primitive[Im2ColExt], the input rank must be in [4,4], but got 5   PyTorch 错误: RuntimeError: Expected 3D or 4D (batch mode) tensor with possibly 0 batch size and other   ```  **底层原因可能是什么**：     `mint.nn.Unfold`的维度校验逻辑嵌入在底层算子`Im2ColExt`中，而非Python接口层，导致错误延迟暴露。  **分析和建议**：      **分析**：`Unfold`操作要求输入为4D张量（NCHW格式），PyTorch在调用时立即检查维度，而`mint`模块将校验推迟到执行阶段，增加了调试难度。      **建议**：       1. 在接口层添加维度校验（如`if input.ndim != 4: raise ValueError`）。       2. 模仿PyTorch的错误提示，提供更具体的维度要求说明（如“Expected 4D tensor, got X”）。       3. 优化异常处理流程，确保校验前置。   **问题5：输入维度过小时延迟报错**  **预期结果**：     当输入空间维度小于`kernel_size`（如`(2, 2)`输入搭配`(3, 3)`核），`mint.nn.Unfold`应立即抛出错误，提示输出维度无效。  **实际结果**：     `mint.nn.Unfold`未在调用时报错，仅在访问输出时抛出错误，提示计算出的滑动窗口数组形状为`(0, 0)`。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 1, 2, 2), dtype=np.float32)   unfold_mint = mint_nn.Unfold(kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(0, 0))   try:       output_mint = unfold_mint(Tensor(input_np, ms.float32))       print(f""MindSpore mint.nn.Unfold 形状: {output_mint.shape}"")       output_mint.asnumpy()   except Exception as e:       print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")   unfold_torch = tnn.Unfold(kernel_size=(3, 3), stride=(1, 1), dilation=(1, 1), padding=(0, 0))   try:       output_torch = unfold_torch(torch.tensor(input_np))   except Exception as e:       print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   MindSpore 错误: ValueError: For Im2ColExt, given input with spatial size (2, 2), kernel_size=(3,   PyTorch 错误: RuntimeError: Given input with spatial size (2, 2), kernel_size=(3, 3), dilation=(1,   ```  **底层原因可能是什么**：     `Im2ColExt`算子在计算输出形状时未提前校验输入与核大小的兼容性，仅在执行时发现输出维度非法。  **分析和建议**：      **分析**：PyTorch在调用时即计算并验证输出形状，`mint`模块则延迟到执行阶段，降低了鲁棒性。      **建议**：       1. 在接口层计算预期输出形状并验证（如`if out_h <= 0 or out_w <= 0: raise ValueError`）。       2. 提供更清晰的错误提示（如“Input size (H,W) too small for kernel_size”）。   **问题6：错误信息不够明确**  **预期结果**：     对于不支持的类型或非法输入，`mint.nn.Unfold`应提供具体且具指导性的错误信息（如“Type Int32 not supported”）。  **实际结果**：     抛出的错误信息为底层ACL通用提示（如`aclnnIm2colGetWorkspaceSize call failed`），未指明具体原因，缺乏针对性。  **复现代码**：   ```python   import numpy as np   import mindspore as ms   from mindspore import Tensor, context   import mindspore.mint.nn as mint_nn   import torch   import torch.nn as tnn   context.set_context(mode=context.PYNATIVE_MODE, device_target=""Ascend"")   input_np = np.ones((1, 1, 6, 6), dtype=np.int32)   unfold_mint = mint_nn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_mint = unfold_mint(Tensor(input_np, ms.int32))       output_mint.asnumpy()   except Exception as e:       print(f""MindSpore 错误: {type(e).__name__}: {str(e)[:100]}"")   unfold_torch = tnn.Unfold(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), padding=(0, 0))   try:       output_torch = unfold_torch(torch.tensor(input_np, dtype=torch.int32))   except Exception as e:       print(f""PyTorch 错误: {type(e).__name__}: {str(e)[:100]}"")   ```  **代码运行结果**：   ```   MindSpore 错误: RuntimeError: aclnnIm2colGetWorkspaceSize call failed, please check!   PyTorch 错误: RuntimeError: ""im2col_out_cpu"" not implemented for 'Int'   ```  **底层原因可能是什么**：     MindSpore的错误处理链未将ACL层的具体错误码映射到用户友好的提示，直接暴露底层失败信息。  **分析和建议**：      **分析**：PyTorch的错误信息明确指出类型不支持，`mint`模块则仅提示调用失败，用户难以定位问题根源。      **建议**：       1. 在Python层捕获ACL错误并解析（如`if ""aclnnIm2col"" in str(e): raise TypeError(""Unsupported dtype"")`）。       2. 优化错误信息，提供类型或参数的具体上下文。       3. 参考PyTorch的异常处理机制，提升开发体验。   2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```   3. Related testcase / 关联用例  **Testcase Name / 用例名**:      null  **Excute Mode / 执行模式**:      Excute Mode: PyNative     4. Steps to reproduce the issue / 重现步骤 1. 配置MindSpore环境：    ```bash    pip install mindspore==2.4.10    ``` 2. 运行测试脚本：    ```bash    python test_nn_Unfold.py    ``` 3. 检查每种问题的输出日志，验证问题复现。   5. Describe the expected behavior / 预期结果  **【预期结果】**：     1. `mint.nn.Unfold`在`GRAPH_MODE`下正常运行，支持Ascend硬件加速。     2. 明确支持或拒绝`Float64`，并在调用时抛出异常。     3. 对`Int`/`UInt`/`Bool`类型提前报错，不伪支持。     4. 对非法维度输入立即抛出维度错误。     5. 输入维度过小时提前校验并报错。     6. 提供具体、清晰的错误信息，指向问题根源。   6. Related log / screenshot / 日志 / 截图  **问题1**：  !image  **问题2**：  !image  **问题3**：  !image  **问题4**：  !image  **问题5**：  !image  **问题6**：  !输入图片说明   7. Special notes for this issue / 备注  **【优先级建议】**：      问题1（图模式不支持）：P1（影响训练场景）      问题2（Float64伪支持）：P2（类型支持一致性）      问题3（Int/UInt/Bool伪支持）：P2（潜在隐患）      问题4（维度校验滞后）：P1（鲁棒性问题）      问题5（维度过小延迟报错）：P1（鲁棒性问题）      问题6（错误信息不明确）：P3（开发体验）  ",2025-02-25T18:30:11+08:00,mindspore-assistant,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOU14
ascend,郑炼鑫,【接口测试任务26】接口mindspore.mint.nn.L1Loss存在的若干问题," 1.Describe the current behavior / 问题描述   **问题1：GRAPH_MODE下Ascend平台不支持（已在评论区更正）**  **预期结果**：     在`GRAPH_MODE` + `device_target=""Ascend""`配置下，`mindspore.mint.nn.L1Loss`应与`nn.L1Loss`和PyTorch实现一致，支持正常训练和推理。  **实际结果**：     触发底层算子适配错误：`Unsupported op type: L1LossExt`，导致计算图编译失败。  **复现代码**： ```python import mindspore as ms from mindspore import nn, Tensor, context import mindspore.mint.nn as mint_nn context.set_context(mode=context.GRAPH_MODE, device_target=""Ascend"")  构造输入数据 pred = Tensor([1.0, 2.0, 3.0], ms.float32) target = Tensor([1.1, 2.0, 2.9], ms.float32) try:     loss_fn = mint_nn.L1Loss()     loss = loss_fn(pred, target)     print(""计算结果："", loss.asnumpy()) except Exception as e:     print(""GRAPH_MODE下错误信息：\n"", str(e)) ```  **代码运行结果**： ``` [ERROR] GE_ADPT(xxxxx): ConvertCNode] Cannot get adapter for Default/L1LossExtop0 GRAPH_MODE下错误信息：  RuntimeError: MindSpore error: The return value of the function[...] is empty... ```  **底层根因分析**：     `mint.nn.L1Loss`底层依赖的`L1LossExt`算子未在Ascend平台的Graph Engine中注册适配器，导致图模式编译失败。  **改进建议**：     1. 在CANN层为`L1LossExt`算子添加Ascend适配器     2. 或在接口层自动回退到基础算子实现（如`Abs`+`ReduceMean`）   **问题2：不支持float64精度且无明确提示**  **预期结果**：     输入`float64`类型数据时，应支持计算或抛出明确的类型不支持异常。  **实际结果**：     静默将计算精度降级为`float32`，导致输出精度与PyTorch存在差异。  **复现代码**： ```python import numpy as np import torch import mindspore as ms  构造相同输入 np_data = np.array([1.0, 2.0, 3.0], dtype=np.float64) pt_input = torch.tensor(np_data, dtype=torch.float64) ms_input = Tensor(np_data, ms.float64)  PyTorch计算 pt_loss = torch.nn.L1Loss()(pt_input, pt_input) print(f""PyTorch输出（float64）：{pt_loss.item():.17f}"")   0.00000000000000000  MindSpore计算 ms_loss = mint_nn.L1Loss()(ms_input, ms_input) print(f""MindSpore输出（float64）：{ms_loss.asnumpy()[()]:.17f}"")   0.00000000000000024 ```  **代码运行结果**： ``` PyTorch输出（float64）：0.3333333333333333 MindSpore输出（float64）：0.3333333432674408 ```  **底层根因分析**：     Ascend 910B硬件对`float64`支持不完善，MindSpore在算子层自动降级到`float32`计算。  **改进建议**：     1. 在文档中明确标注`mint.nn.L1Loss`的精度限制     2. 在接口层添加类型检查警告   **问题3：布尔类型输入报错信息不明确**  **预期结果**：     输入布尔类型时，应提示""不支持布尔类型张量计算L1损失""。  **实际结果**：     抛出模糊的ACL底层错误：`aclnnL1LossGetWorkspaceSize call failed`。  **复现代码**： ```python pred_bool = Tensor([True, False], ms.bool_) target_bool = Tensor([False, True], ms.bool_) try:     loss = mint_nn.L1Loss()(pred_bool, target_bool) except RuntimeError as e:     print(""MindSpore错误信息："", str(e))  PyTorch对比测试 try:     torch_loss = torch.nn.L1Loss()(torch.tensor([True, False]),                                   torch.tensor([False, True])) except RuntimeError as e:     print(""\nPyTorch错误信息："", str(e)) ```  **代码运行结果**： ``` MindSpore错误信息： aclnnL1LossGetWorkspaceSize call failed, please check!... PyTorch错误信息： Subtraction, the `` operator, with two bool tensors is not supported... ```  **底层根因分析**：     `mint.nn.L1Loss`未在Python层拦截非法类型，直接传递布尔张量给底层ACL算子。  **改进建议**：     在接口层添加类型校验逻辑： ```python if input.dtype == mstype.Bool_ or target.dtype == mstype.Bool_:     raise TypeError(""Bool inputs are not supported for L1Loss"") ```   **问题4：整数类型伪支持**  **预期结果**：     输入整数类型（如`int8`）时应明确报错或输出有意义结果。  **实际结果**：     计算正常完成但输出全零，未触发任何异常。  **复现代码**： ```python pred_int = Tensor([1, 2], ms.int8) target_int = Tensor([3, 4], ms.int8)  MindSpore计算 loss = mint_nn.L1Loss()(pred_int, target_int) print(""MindSpore int8输出："", loss.asnumpy())   输出0  PyTorch对比 try:     torch.nn.L1Loss()(torch.tensor([1,2], dtype=torch.int8),                      torch.tensor([3,4], dtype=torch.int8)) except Exception as e:     print(""\nPyTorch异常："", str(e)) ```  **代码运行结果**： ``` MindSpore int8输出： [0,0] 全零tensor PyTorch异常： expected scalar type Float but found Char ```  **底层根因分析**：     `mint.nn.L1Loss`未正确处理整数类型输入，未实现类型转换或校验逻辑。  **改进建议**：     1. 在接口层强制要求浮点类型输入     2. 或自动执行类型转换并添加警告   2.Environment / 环境信息  **Hardware Environment / 硬件环境** ",2025-02-25T18:09:21+08:00,"gitee,mindspore-assistant,foruda,foruda",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBOTUU,关于你这边提到的第一个问题静态图下不支持，其实这里是另外一个问题，而并不是静态图下不支持，实际静态图下是支持的，如果执行的代码不在nn.Cell的construct方法中，需要用jit标签包起来，才会走静态图，否则依旧走的是动态图，可以尝试一下，打上jit标签是可以运行的；这边的错误应该是使用了上下文的全局静态图配置，但单独调用某些api走动态图的动静结合的模式下出现了错误： !输入图片说明 !输入图片说明,是的，用jit标签标志了之后正常输出结果，感谢指正！
ascend,reeered,"mindspore.mint.nn.functional.selu不支持Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.selu不支持Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.selu(x_torch)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.selu(x_ms).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Float64, BFloat16",2025-02-25T18:00:56+08:00,"mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTRD,目前，在2.5版本中，mindspore.mint.nn.functional.selu已支持BFloat16，尚未支持Float64， 在910B环境下MindSpore与torchnpu对BFloat16，Float16，Float32的结果一致， 后续将会增加对CPU和Float64的支持。 !输入图片说明
ascend,reeered,"mindspore.mint.nn.functional.relu不支持Int16, Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.relu不支持Int16, Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.relu(x_torch)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.relu(x_ms).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Int16, Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Int16, Float64, BFloat16",2025-02-25T18:00:02+08:00,"mindspore-assistant,www",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTQZ,mindspore.mint.nn.functional.relu底层调用了aclnnReLU，而aclnnRelu在910A上不支持int16、float64和bfloat16的输入，可以参考昇腾文档：https://www.hiascend.com/document/detail/zh/CANNCommunityEdition/81RC1alpha001/apiref/aolapi/context/aclnnRelu&aclnnInplaceRelu.md
ascend,reeered,"mindspore.mint.nn.functional.prelu 不支持Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.prelu 不支持Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         weight_np = np.array([0.25], dtype=np.float32)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.prelu(x_torch, torch.tensor(weight_np, dtype=torch_dtype))         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.prelu(x_ms, Tensor(weight_np)).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Float64, BFloat16",2025-02-25T17:57:44+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTPY,"prelu的情况感觉和Mish算子一样，cann层首先没有支持float64,框架层也不好接入；然后反向没有支持bfloat16,光前向接入bfloat16的话，训练就直接报错了 !输入图片说明"
ascend,reeered,"mindspore.mint.nn.functional.mish不支持Float64, BFloat16类型输入"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.mish不支持Float64, BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.mish(x_torch)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.mish(x_ms).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持Float64, BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持Float64, BFloat16",2025-02-25T17:55:51+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTPC,"根据atlas训练系列产品（即910A）的cann算子文档，Mish算子确实不支持float1=64,mindspore框架层也就没法接入了；Mish算子前向虽然支持BFloat16，但反向的MishGrad cann算子也不支持BFloat16，我猜测可能框架层考虑到，如果前向接入了BFloat16，就会导致推理前向能走通，但涉及到训练反向就会报错了，所以也不太好只接入前向，估计要等cann算子前向和反向都完善后才方便接入 !输入图片说明"
ascend,reeered,mindspore.mint.nn.functional.log_softmax 不支持BFloat16类型输入," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore.mint.nn.functional.log_softmax 不支持BFloat16类型输入  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(Graph\PyNative): *  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ```python if __name__ == '__main__':     ms_dtypes = [ms.int8, ms.int16, ms.int32, ms.int64, ms.uint8, ms.uint16, ms.uint32, ms.uint64, ms.float16, ms.float32, ms.float64, ms.bfloat16, ms.bool_]     torch_dtypes = [torch.int8, torch.int16, torch.int32, torch.int64, torch.uint8, torch.uint16, torch.uint32, torch.uint64, torch.float16, torch.float32, torch.float64, torch.bfloat16, torch.bool]     ms_support_list = [True] * len(ms_dtypes)     torch_support_list = [True] * len(torch_dtypes)     for i in range(len(ms_dtypes)):         ms_dtype, torch_dtype = ms_dtypes[i], torch_dtypes[i]         x_np = np.random.randn(2, 3)         x_torch = torch.tensor(x_np, dtype=torch_dtype)         x_ms = Tensor(x_np, ms_dtype)         try:             F_torch.log_softmax(x_torch, dim=1)         except Exception as e:             print(""torch"", e)             torch_support_list[i] = False         try:             F_mint.log_softmax(x_ms, dim=1).asnumpy()         except Exception as e:             print(""ms"", e)             ms_support_list[i] = False     for i in range(len(ms_dtypes)):         print(f""ms: {ms_dtypes[i]}: {ms_support_list[i]}, torch: {torch_dtypes[i]}: {torch_support_list[i]}"")         if ms_support_list[i] != torch_support_list[i]:             print(f""支持情况不同：ms_dtype: {ms_dtypes[i]} ({ms_support_list[i]}), torch_dtype: {torch_dtypes[i]} ({torch_support_list[i]})"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 不支持BFloat16  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 不支持BFloat16",2025-02-25T17:51:32+08:00,"mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOTLX,目前，mindspore 2.5.0版本在Ascend环境中，mindspore.mint.nn.functional.log_softmax已支持BFloat16类型输入， 后续将会增加对CPU的支持 !输入图片说明
ascend,tanxinglian,[CT][MS][OPS][ops.ctc_loss][function][全量]ops.ctc_loss 910A（arm机器） pynative模式出现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > ops.ctc_loss 910A（arm机器） pynative模式出现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_ctc_loss_float32_log_probs_2x1x3_array >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_f_ctc_loss.py::test_f_ctc_loss_float32_log_probs_2x1x3_array  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```        def test_f_ctc_loss_float32_log_probs_2x1x3_array():         log_probs = Tensor(np.array([[[0.3, 0.6, 0.6]], [[0.9, 0.4, 0.2]]]).astype(np.float32))         targets = Tensor(np.array([[0, 1]]), mstype.int32)         input_x_lengths = Tensor(np.array([2]), mstype.int32)         target_lengths = Tensor(np.array([1]), mstype.int32)         blank = 0         reduction = 'mean'         zero_infinity = True         fact = CtcLossMock(             attributes={'blank': blank, 'reduction': reduction, 'zero_infinity': zero_infinity},             inputs=[log_probs, targets, input_x_lengths, target_lengths])         fact.forward_cmp() >       fact.grad_cmp() ../test_f_ctc_loss.py:105:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/ctc_loss_ops.py:172: in grad_cmp     allclose_nparray(grad_pytorch[0], grad_mindspore[0], self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0.26783472, 1.3949243 , 1.3949243 ]], dtype=float32) data_me = array([[1.0333853, 1.3949243, 1.3949243]], dtype=float32) rtol = 0.0001, atol = 0.0001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T17:23:30+08:00,"foruda,foruda,rct/cann,mindspore-repo,dts-szv",closed,0,9,https://gitee.com/mindspore/mindspore/issues/IBOT3R,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,test_n_ctcloss_length_tuple910A偶现精度问题 开发确认为同一个问题 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2347502646397501593&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250302%2011:00:34&isMergedTask=false&nodeDate=20250302&year=20242025&TestNow=true&testcaseid=67bade576c3f49211ec43260&workspaceId=67c412454503c84f0a2771d1,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 解决方案 (Fix Solution) 2. 未包含 引入原因分析 (Introduction Analysis) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,Appearance & Root Cause ctc_loss反向精度问题 根因： CANN引入 CANN问题单 https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025021136835 Fix Solution 1.取最新CANN包 Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN（0307）包回归 Selftest Report & DT Review 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis CANN引入,"test_f_ctc_loss_float32_log_probs_2x1x3_array已验证无问题 【回归版本号】：__commit_id__ = '[sha1]:e460364b,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250307_atlas !输入图片说明",test_n_ctcloss_length_tuple 910A（arm机器） pynative模式还有精度问题 走回开发继续定位 !输入图片说明,确认为CANN引入，CANN问题单：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025032416172,Appearance & Root Cause ctc_loss反向精度问题 根因： CANN引入 CANN问题单 https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025021136835 Fix Solution 1.取最新CANN包 http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250411_atlas/ Fix Description & Test Suggestion 测试建议：执行原用例进行测试，使用最新版本的CANN（0411）包回归 Selftest Report & DT Review !输入图片说明 !输入图片说明 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis CANN引入,cann包：http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250414_atlas/ !输入图片说明 !输入图片说明
ascend,tanxinglian,[CT][MS][OPS][mint.nn.functional.avg_pool2d][function][全量]mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题，其他910A机器未出现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_n_f_avg_pool2d_float32_2d_discontinuous_tensor >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_n_f_avg_pool2d.py::test_mint_n_f_avg_pool2d_float32_2d_discontinuous_tensor  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='not support')     (reason='not support')     ()     def test_mint_n_f_avg_pool2d_float32_2d_discontinuous_tensor():         input_x = get_discontinuous_tensor(shape=(5, 5, 28, 38), dim=(2, 1, 3, 0))         kernel_size = 2         stride = (2, 4)         padding = 0         ceil_mode = False         count_include_pad = False         divisor_override = 50         fact = AvgPool2dMock(             attributes={'kernel_size': kernel_size, 'stride': stride, 'padding': padding,                         'ceil_mode': ceil_mode, 'count_include_pad': count_include_pad,                         'divisor_override': divisor_override},             inputs=[input_x]) >       fact.forward_cmp() ../test_mint_n_f_avg_pool2d.py:1110:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/avg_pool2d_mint.py:155: in forward_cmp     allclose_nparray(out_cmp, out_mindspore, 0.001, 0.001) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[0.0317289 ],          [0.04237107],          [0.05222388],          ...,          [0.0534819 ],          [0....     [0.0433775 ],          ...,          [0.03954761],          [0.04958919],          [0.05123113]]]], dtype=float32) data_me = array([[[[0.03173828],          [0.        ],          [0.        ],          ...,          [0.05349731],          [0....     [0.        ],          ...,          [0.03955078],          [0.        ],          [0.        ]]]], dtype=float32) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count)   1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T17:17:18+08:00,"gitee,foruda,rct/cann,mindspore-repo,mindspore-pkg",closed,0,13,https://gitee.com/mindspore/mindspore/issues/IBOSYW,根据责任人转单 !输入图片说明,算子责任人更新，走给雷可鹏 00842044,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,算子功能不支持数据类型，未修改到CPU后端，测试用例有问题,问题单分析有问题，非不支持类型，与CPU后端无关，走回开发继续分析,Appearance & Root Cause 问题：mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题 根因：pynative场景下数据有丢失 Fix Solution 使用最新版的MindSpore的master分支进行测试 Fix Description & Test Suggestion 测试建议：该问题可以通过特性用例防护，增加****场景。 Selftest Report & DT Review 目前前后端耗时在12分钟以内。 是否需要补充 ST/UT：否  原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx PR合入时间：年/月/日 问题是否偶现：是/否,4.3号包http://mindsporepkg.csi.rnd.huawei.com/OpenSource/Daily/Version/202504/0403/mindspore/master_20250403010018_119b7ec4bdd7922b51cc1615345eafd9a14a99e6/unified/ 验证失败 走回开发 !输入图片说明,4月2日cann包条件下该用例pass,DTS2025041127810,910PremiumA 硬件，非连续输入场景存在精度问题： DTS2025041127810,DTS2025041203827,Appearance & Root Cause 问题：mint.nn.functional.avg_pool2d在910PremiumA上出现精度问题 根因：avg_pool2d底层调用的conv2d算子，conv2d的tiling写的有问题，修改已合入 Fix Solution 取CANN 8.1.RC1.B102可解决 Fix Description & Test Suggestion 测试建议：已解决 Selftest Report & DT Review 目前前后端耗时在12分钟以内。 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：CANN引入 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx PR合入时间：年/月/日 问题是否偶现：是/否,cann包http://mindsporerepo.csi.rnd.huawei.com/productrepo/HiAI/Milan_C21/20250414_atlas/ 已验证通过 !输入图片说明
ascend,tanxinglian,[CT][MS][OPS][nn.rmseloss][function][全量]rmseloss ascend pynative模式bool类型校验丢失 ," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > rmseloss ascend pynative模式bool类型校验丢失   2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_n_rmseloss_input_3x7x2x9_dtype_error_bool >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0 910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 export CONTEXT_JIT_LEVEL=O0 > （2）cd MindSporeTest/operations > （3）pytest s v test_n_rmseloss.py::test_n_rmseloss_input_3x7x2x9_dtype_error_bool   5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功 预期报错TypeError: For primitive[Sub], the input argument[x] must be a type of {Tensor[BFloat16], Tensor[Float16], Tensor[Float32], Tensor[Float64], Tensor[Int16], Tensor[Int32], Tensor[Int64], Tensor[Int8], Tensor[UInt16], Tensor[UInt32], Tensor[UInt64], Tensor[UInt8]}, but got Tensor[Bool].  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       def test_n_rmseloss_input_3x7x2x9_dtype_error_bool():         logits = Tensor(np.random.randn(3, 7, 2, 9).astype(np.bool_))         label = Tensor(np.random.randn(3, 7, 2, 9).astype(np.bool_))         fact = RMSELossMock(inputs=[logits, label]) >       with pytest.raises((RuntimeError, TypeError, ValueError)): E       Failed: DID NOT RAISE (, , ) ../test_n_rmseloss.py:195: Failed =============================== warnings summary ==== ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2326593508668866711&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_full_20250223%2005:22:20&isMergedTask=false&nodeDate=20250223&year=20242025&TestNow=true&testcaseid=67bb21c384dee72f16dfcfaf&workspaceId=67bb21bf68393c7aa584f463&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） >  1. 特性合入引入     引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/……     PR 合入时间：2025/x/x     是否偶现：是/否 >  2. Bugfix 修复引入     引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx     PR 合入时间：2025/x/x     是否偶现：是/否 >  3. 测试新增测试场景/测试漏测/用例未适配     测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. ……     用例如果有新增，则补充 用例新增时间：2025/x/x     是否偶现：是/否 >  4. 环境问题     具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因     是否偶现：是/否 >  5. CANN 升级     CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-25T15:50:01+08:00,gitee,closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBORII,rmseloss小算子拼接中的sub算子报错 问题引入pr: https://gitee.com/mindspore/mindspore/pulls/81323 现象：pynative下sub算子数据类型不支持bool的拦截不生效，图模式正常 转给问题引入人进一步定位根因,‘’ 操作，动态图情况下走subext，subext与torch的sub对齐，支持bool类型，故动态图情况下不再报错。对于静态图，pr修改不影响原有‘’逻辑，还是走sub，sub对于bool类型进行拦截，故还会报错。由于并没有要求动静统一，所以这里建议测试修改测试用例。,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未对此问题进行问题分析 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,Appearance & Root Cause 问题：动态图bool类型输入未报错 根因： 1、 ‘’操作，动态图情况下走subext，subext与torch_npu的sub对齐，支持bool类型，故没有拦截报错。 Fix Solution 1、测试修改用例，bool类型不拦截 Fix Description & Test Suggestion 无 测试建议：修改bool报错用例。 Selftest Report & DT Review 用例修改后，不再报错 原因：非基本功能问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81323 PR合入时间：2025年/02月/12日 问题是否偶现：是/否,适配用例 ascend pynative模式bool类型已支持
ascend,luoxuewei,重构tensor.__index__接口,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  重构tensor.__index__接口  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-25T14:14:59+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOPM6
bfloat16,fangfangssj,mint.nn.functional.max_pool2d希望支持int8，int16，int32，int64，uint8，float64，bfloat16, Backgroud（背景信息） 测试mint.nn.functional.max_pool2d这个api的时候，发现CANN后端不支持int8，int16，int32，int64，uint8，float64，bfloat16的数据类型。 torch却均支持。  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch,2025-02-25T00:33:36+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOL2A,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
bfloat16,fangfangssj,mint.nn.functional.gelu在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.gelu在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_gelu.py::test_gelu_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_gelu_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.float64, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.gelu(ms_input)             torch_output = torch.nn.functional.gelu(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-24T21:57:37+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOKLL,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
float16,fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log_softmax梯度误差," 1.Describe the current behavior / 问题描述  当输入数据类型为float16时，反向传播梯度误差大于1e3；目前测试遇到的最大误差为0.0078125  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log_softmax.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x,dim):     return torch.nn.functional.log_softmax(x,dim=dim) def forward_ms(x,dim):     return ms.mint.special.log_softmax(x,dim=dim) input_data = [[ 1.512695],  [ 3.158203],  [ 3.693359]] ms_inp=ms.Tensor(input_data,ms.float16) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float16) torch_res=forward_pt(torch_inp,dim=0) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) ms_res, gradient_ms = grad_fn(ms_inp,dim=0) ms_inp_grad=gradient_ms print(f""torch梯度结果为{torch_inp_grad}"") print(f""mindspore梯度结果为{ms_inp_grad}"") print(f""梯度的绝对误差为{abs(ms_inp_grad.asnumpy()torch_inp_grad.numpy())}"") ```  5.Describe the expected behavior / 预期结果  torch梯度结果为tensor([[ 0.8008],         [0.0348],         [0.7661]], dtype=torch.float16) mindspore梯度结果为[[ 0.800293]  [0.033752]  [0.766113]] 梯度的绝对误差为[[ 0.000488]  [ 0.001007]  [ 0.000000]] 报错关键日志截图： !输入图片说明",2025-02-24T18:08:00+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOJ7L
float16,fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log_softmax误差大于1e3," 1.Describe the current behavior / 问题描述  当输入数据类型为float16时，误差大于1e3  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log_softmax.py::test_any_random_input_fixed_dtype  4.Steps to reproduce the issue / 重现步骤  ``` import mindspore as ms import torch import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) data=[[ 9.26562],  [ 0.91504],  [ 1.16895],  [ 9.33594],  [ 8.31250]] ms_inp=ms.Tensor(data,ms.float16) torch_inp=torch.tensor(data,dtype=torch.float16) ms_res=ms.mint.special.log_softmax(ms_inp,dim=0) torch_res=torch.nn.functional.log_softmax(torch_inp,dim=0) diff=ms_res.asnumpy()torch_res.numpy() print(f""ms_res:{ms_res}\ntorch_res:{torch_res}\ndiff:{diff}"") ```  5.Describe the expected behavior / 预期结果  ms_res:[[0.899902]  [9.250000]  [8.992188]  [0.829590]  [1.852539]] torch_res:tensor([[0.8999],         [9.2500],         [9.0000],         [0.8296],         [1.8525]], dtype=torch.float16) diff:[[ 0.000000]  [ 0.000000]  [ 0.007812]  [ 0.000000]  [ 0.000000]] 报错关键日志截图： !输入图片说明",2025-02-24T18:03:54+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOJ6T
float16,fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——sinc梯度误差," 1.Describe the current behavior / 问题描述  当数据类型为float16时，梯度误差大于1e3；如输入3.525391时，梯度误差是0.002136。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_round.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np np.set_printoptions(formatter={'float': '{: 0.6f}'.format}) def forward_pt(x):     return torch.special.sinc(x) def forward_ms(x):     return ms.mint.special.sinc(x) input_data = [[3.525391]] ms_inp=ms.Tensor(input_data,ms.float16) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float16) torch_res=forward_pt(torch_inp) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) ms_res, gradient_ms = grad_fn(ms_inp) ms_inp_grad=gradient_ms print(f""torch梯度结果为{torch_inp_grad},mindspore梯度结果为{ms_inp_grad},梯度的绝对误差为{abs(ms_inp_grad.item()torch_inp_grad.item())}"") ```  5.Describe the expected behavior / 预期结果  torch梯度结果为tensor([[0.0489]], dtype=torch.float16),mindspore梯度结果为[[ 0.046753]],梯度的绝对误差为0.00213623046875 报错关键日志截图： !输入图片说明",2025-02-24T18:01:31+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOJ68,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 补充说明：当数据类型为float32时，结果一致。
float16,fengyuebo2025,【开源实习】mindspore.mint接口测试任务38——log1p与pytorch的输出差异," 1.Describe the current behavior / 问题描述  当输入数据类型为float16，且接近1时，mindspore输出65504.00000，pytorch输出inf；当输入数据类型为float32，且接近1时，mindspore输出3.4028235e+38，pytorch输出inf  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_log1p.py::test_any_wrong_input  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms data=0.9999999999999999999999999999 ms_inp=ms.Tensor(data,ms.float16) torch_inp=torch.tensor(data,dtype=torch.float16) ms_res=ms.mint.special.log1p(ms_inp) torch_res=torch.log1p(torch_inp) print(f""ms_res:{ms_res}\ntorch_res:{torch_res}"") data=0.9999999999999999999999999999 ms_inp=ms.Tensor(data,ms.float32) torch_inp=torch.tensor(data,dtype=torch.float32) ms_res=ms.mint.special.log1p(ms_inp) torch_res=torch.log1p(torch_inp) print(f""ms_res:{ms_res}\ntorch_res:{torch_res}"") ```  5.Describe the expected behavior / 预期结果  ms_res:65500.0 torch_res:inf ms_res:3.4028235e+38 torch_res:inf 报错关键日志截图： !输入图片说明",2025-02-24T17:48:28+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIZS,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致 !输入图片说明
bfloat16,houbosen2025, mint.nn.erfc希望支持bfloat16,issue编写  1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.erfc需要支持bfloat16  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > > 2. 计算测试，以float32 > >    1. 测试组，小数点后5位不同，算测试通过 > >       input_data: [ 0.55593791  0.44808426 2.71790637 0.53732477 0.45158543] >       ms_result: [0.43174636 0.5263032  1.9998777  1.5526736  1.4769242 ] >       torch_result: [0.4317416  0.52628523 1.9998788  1.5526809  1.4769417 ] > >    2. 测试组，小数点后5位不同 > >       input_data: [ 0.53237093 0.99921068  0.81374149  0.05919775 0.15359628] >       ms_result: [0.45152628 1.8423889  0.24979174 0.93325967 1.1719722 ] >       torch_result: [0.4515183  1.8423729  0.24981277 0.93328047 1.1719615 ] > > 3. 参数输入 > >    无参数设置，均通过 > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220163118648  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:43:43+08:00,"gitee,mindspore-assistant,foruda,intern",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBOIVU,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.erfc已支持bfloat16，且与torchnpu结果一致 !输入图片说明,单独测试，显示mint.nn.erfc已支持bfloat16 !输入图片说明
bfloat16,houbosen2025,mint.nn.erf 希望支持bfloat16,issue编写  1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.erf需要支持bfloat16  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > > 2. 计算测试，以float32 > >    1. 测试组，小数点后5位不同，算测试通过 > >       input_data: [0.37975368 0.34422294 1.42222966 1.04481118  0.95105012] >       ms_result: [0.4087475  0.37358218 0.9556926  0.860494    0.8213899 ] >       torch_result: [0.408769   0.37360325 0.95571023 0.8604813   0.8213707 ] > >    2. 测试组，小数点后5位不同 >       input_data: [ 2.22057531 1.10386126 0.54387706  0.14834316  1.51924453] >       ms_result: [ 0.99830514 0.8815062  0.5581943   0.16617936  0.96830803] >       torch_result: [ 0.99831253 0.88149875 0.5582007   0.16616759  0.96832895] > > 3. 参数输入 > >    无参数设置，均通过 > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220162940207  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:42:11+08:00,"gitee,mindspore-assistant,foruda,intern",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIUL,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.erf 已支持BFloat16， !输入图片说明
bfloat16,houbosen2025,mint.nn.divide希望在API ref编写支持类型，且希望支持UInt16，UInt32，UInt64，BFloat16,issue编写  1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.divide 在API表未编写支持类型，但是不支持UInt16，UInt32，UInt64，BFloat16，但是torch是支持UInt16，UInt32，UInt64的 这个issue同div  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > >  > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220162719866  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:40:26+08:00,"gitee,mindspore-assistant,intern",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIT8,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.divide已支持BFloat16，后续将支持UInt16，UInt32，UInt64
bfloat16,houbosen2025,mint.nn.div希望在API ref编写支持类型，且希望支持UInt16，UInt32，UInt64，BFloat1, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.div 在API表未编写支持类型，但是不支持UInt16，UInt32，UInt64，BFloat16，但是torch是支持UInt16，UInt32，UInt64的  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:  > >  > > 4. 报错测试 > >    均通过 > > 5. 梯度测试 > >    均通过  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !image20250220162719866  7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**houbosen2025,2025-02-24T17:37:19+08:00,"gitee,mindspore-assistant,intern",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBOIQK,目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.div已支持BFloat16，后续将支持UInt16，UInt32，UInt64
graph mode,林芃芃,`mindspore.mint.repeat_interleave`不支持空张量，与 PyTorch 行为不一致，文档没有明确说明," 1.Describe the current behavior / 问题描述 任务链接 `mindspore.mint.repeat_interleave`不支持空张量，与 PyTorch 行为不一致，可能会影响用户迁移代码。  错误信息虽然清晰，但这个限制应该在文档中明确说明  可能会影响一些边界情况的处理  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例  **Testcase Name**: >  test_repeat_interleave.py::test_edge_cases  测试边界条件  **Execute Mode**: >  Graph Mode  4.Steps to reproduce the issue / 重现步骤 1. 创建测试代码`test_repeat_interleave.py`： ```python import numpy as np import pytest import mindspore import torch from mindspore import Tensor from mindspore import mint def test_edge_cases():     """"""测试边界条件""""""      测试空张量     empty_input = Tensor(np.array([]), mindspore.float32)     try:         output = mint.repeat_interleave(empty_input, repeats=2, dim=0)         print(f""Empty tensor output shape: {output.shape}"")     except Exception as e:         print(f""Empty tensor raised: {type(e).__name__}: {str(e)}"")      测试repeats=0的情况     input_data = np.array([[1, 2], [3, 4]])     ms_input = Tensor(input_data, mindspore.float32)     try:         output = mint.repeat_interleave(ms_input, repeats=0, dim=0)         print(f""Zero repeats output shape: {output.shape}"")     except Exception as e:         print(f""Zero repeats raised: {type(e).__name__}: {str(e)}"")      测试repeats为很大的数     try:         output = mint.repeat_interleave(ms_input, repeats=1000000, dim=0)         print(f""Large repeats output shape: {output.shape}"")     except Exception as e:         print(f""Large repeats raised: {type(e).__name__}: {str(e)}"") ``` 2. 运行测试用例： ```bash pytest test_repeat_interleave.py v ``` 3. 观察测试日志中的错误信息和精度差异报告  5.Describe the expected behavior / 预期结果  测试用例应该通过，不会抛出异常  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-24T16:41:08+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBOHK1
bfloat16,fangfangssj,mint.nn.SELU在910b上静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.SELU在910b上静态图无法计算  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_Mish.py::test_Mish_all_dtypes  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_SELU_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 SELU 函数             ms_SELU = mint.nn.SELU()             ms_output = ms_SELU(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 SELU 函数             torch_SELU = torch.nn.SELU()             torch_output = torch_SELU(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-24T00:25:25+08:00,"gitee,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8JG,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 报错如下： !输入图片说明
bfloat16,fangfangssj,"mint.nn.Mish 希望支持float64,bfloat16"," Backgroud（背景信息） 测试mint.nn.Mish这个api的时候，发现CANN后端不支持float64,bfloat16的数据类型。 torch却支持float64,bfloat16  Origin（信息来源）  **Hardware Environment / 硬件环境**:   Benefit / Necessity （价值/作用） 希望可以对齐torch",2025-02-24T00:19:56+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8J8,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
bfloat16,fangfangssj,mint.nn.PReLU使用float32输入时静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.PReLU使用float32输入时静态图无法计算，支持的dtype包括DT_FLOAT32，但错误显示输入为DT_INT8，可能是框架内部类型转换错误。 框架内部类型映射错误：在MindSpore中，可能存在将float32错误映射为int8的bug  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_PReLU.py::test_PReLU_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_Mish_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32     dtypes = [ms.float16, ms.float32]     torch_dtypes = [torch.float16, torch.float32]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_Mish = mint.nn.Mish()             ms_output = ms_Mish(ms_input)             torch_Mish = torch.nn.Mish()             torch_output = torch_Mish(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-24T00:15:35+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8J3,"提供的复现代码有多处错误，更正后代码如下： ``` import pytest import torch import torch_npu import mindspore import numpy as np import mindspore as ms from mindspore import mint, Tensor .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_Mish_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32     dtypes = [ms.float32,ms.float16 ]  ms.float16     torch_dtypes = [torch.float32,torch.float16 ]  torch.float16     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(1):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             prelu = mint.nn.PReLU()             ms_output = prelu(ms_input)             torch_prelu = torch.nn.PReLU(dtype=torch_dtype)             torch_output = torch_prelu(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.detach().numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."")> 这里输入引用文本 ``` 目前，mindspore 2.5.0版本在Ascend环境中，mint.nn.PReLU已支持float32，与torchnpu结果一致 !输入图片说明"
bfloat16,fangfangssj,mint.nn.Mish在910b上静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.Mish在910b上静态图无法计算  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_Mish.py::test_Mish_all_dtypes  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_Mish_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 Mish 函数             ms_Mish = mint.nn.Mish()             ms_output = ms_Mish(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)         try:              调用 Mish 函数             torch_Mish = torch.nn.Mish()             torch_output = torch_Mish(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-24T00:01:46+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8I5,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。 报错截图如下： !输入图片说明
bfloat16,fangfangssj,mint.nn.LogSoftmax使用float16输入时静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.ReLU使用float16输入时静态图无法计算，支持的dtype包括DT_FLOAT16，但错误显示输入为DT_INT8，可能是框架内部类型转换错误。 框架内部类型映射错误：在MindSpore中，可能存在将float16错误映射为int8的bug  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_LogSoftmax.py::test_LogSoftmax_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_LogSoftmax_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_LogSoftmax = mint.nn.LogSoftmax()             ms_output = ms_LogSoftmax(ms_input)             torch_LogSoftmax = torch.nn.LogSoftmax()             torch_output = torch_LogSoftmax(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-23T23:44:07+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8GW,目前，mindspore 2.5.0版本在910b环境中，mint.nn.LogSoftmax输入float16数据，可以在静态图中计算，且结果与torchnpu结果一致，通过测试 !输入图片说明
bfloat16,fangfangssj,mint.nn.LogSoftmax在910b上float32运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.LogSoftmax在910b上float32运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_LogSoftmax.py::test_LogSoftmax_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_LogSoftmax_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_LogSoftmax = mint.nn.LogSoftmax()             ms_output = ms_LogSoftmax(ms_input)             torch_LogSoftmax = torch.nn.LogSoftmax()             torch_output = torch_LogSoftmax(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float32运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-23T23:40:23+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO8GO,目前，mindspore 2.5.0版本在910b环境中，mint.nn.LogSoftmax输入float32数据，结果与torchnpu结果一致，通过测试 !输入图片说明
bfloat16,fangfangssj,mint.nn.ReLU使用float16输入时静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.ReLU使用float16输入时静态图无法计算，支持的dtype包括DT_FLOAT16，但错误显示输入为DT_INT16，可能是框架内部类型转换错误。 框架内部类型映射错误：在MindSpore中，可能存在将float16错误映射为int16的bug  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_ReLU.py::test_ReLU_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_ReLU_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype = dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_relu = mint.nn.ReLU()             ms_output = ms_relu(ms_input)             torch_relu = torch.nn.ReLU()             torch_output = torch_relu(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明 !输入图片说明",2025-02-23T22:38:47+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBO871,在910B机器上执行mint.nn.ReLU单算子脚本，未复现该报错。并且跑静态图不仅需要配置上下文环境变量，还需要有对应结构，例如construct函数或者使用，否则即使配置上下文为GRAPH模式，运行时依旧会走PYNATIVE模式。
ascend,林芃芃,mindspore.mint.hardswish 接口数据类型支持不一致及类型转换异常问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 实习任务 在测试MindSpore的Hardswish接口时发现两个问题： 1. 接口实现与文档描述的数据类型支持不一致 2. 在处理float32类型输入时出现异常的类型转换（被错误转换为int32类型）  文档与实现不一致 1. 文档说明：     仅在输入不是tensor时报TypeError     仅在输入既不是int也不是float类型时报TypeError     暗示支持所有int和float类型的tensor输入 2. 实际实现：     错误信息显示仅支持[DT_FLOAT, DT_FLOAT16, DT_BFLOAT16]     与文档描述的支持范围不符  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    test_hardswish.py::test_diffrent_dtype >    test_hardswish.py::test_random_values >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode: Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1. 创建测试文件`test_hardswish.py` ```python import numpy as np import pytest import mindspore as ms from mindspore import Tensor import mindspore.mint as mint import torch import logging  配置日志记录 logging.basicConfig(     level=logging.INFO,     format='%(asctime)s  %(levelname)s  %(message)s',     handlers=[         logging.FileHandler('logs/test_hardswish.log', encoding='utf8'),         logging.StreamHandler()     ] ) class TestHardswish:     """"""测试 Hardswish 激活函数""""""     def setup_method(self):         """"""初始化测试环境""""""         self.ms_hardswish = mint.nn.Hardswish()         self.torch_hardswish = torch.nn.Hardswish()     def test_different_dtypes(self):         """"""测试不同数据类型的支持度""""""         dtypes = [             (np.float16, torch.float16, ms.float16),             (np.float32, torch.float32, ms.float32),             (np.int32, torch.int32, ms.int32),             (np.int64, torch.int64, ms.int64),         ]         for np_dtype, torch_dtype, ms_dtype in dtypes:             x = np.random.uniform(3, 3, size=(2, 3)).astype(np_dtype)             logging.info(f""\n测试数据类型: {np_dtype}"")             try:                 x_torch = torch.tensor(x, dtype=torch_dtype)                 y_torch = self.torch_hardswish(x_torch)                 torch_support = True                 logging.info(f""PyTorch支持{torch_dtype}"")             except Exception as e:                 torch_support = False                 logging.info(f""PyTorch不支持{torch_dtype}, 错误: {str(e)}"")             try:                 x_ms = Tensor(x, dtype=ms_dtype)                 y_ms = self.ms_hardswish(x_ms)                 ms_support = True                 logging.info(f""MindSpore支持{ms_dtype}"")             except Exception as e:                 ms_support = False                 logging.info(f""MindSpore不支持{ms_dtype}, 错误: {str(e)}"")             if torch_support and ms_support:                  检查结果误差                 diff = np.abs(y_ms.asnumpy()  y_torch.detach().numpy())                 max_diff = np.max(diff)                 logging.info(f""最大误差: {max_diff}"")                 assert max_diff < 1e3, f""误差{max_diff}超过阈值1e3""     def test_random_values(self):         """"""测试随机输入值的一致性""""""         x = np.random.uniform(3, 3, size=(4, 5)).astype(np.float32)         x_torch = torch.tensor(x, requires_grad=True)         x_ms = Tensor(x, dtype=ms.float32)         y_torch = self.torch_hardswish(x_torch)         y_ms = self.ms_hardswish(x_ms)          检查前向传播结果         diff = np.abs(y_ms.asnumpy()  y_torch.detach().numpy())         max_diff = np.max(diff)         logging.info(f""\n随机输入前向传播最大误差: {max_diff}"")         assert max_diff < 1e3, f""前向传播误差{max_diff}超过阈值1e3""          检查反向传播         y_torch.sum().backward()         grad_torch = x_torch.grad.numpy()         grad_ms = ms.grad(self.ms_hardswish)(x_ms).asnumpy()         grad_diff = np.abs(grad_ms  grad_torch)         max_grad_diff = np.max(grad_diff)         logging.info(f""随机输入反向传播最大误差: {max_grad_diff}"")         assert max_grad_diff < 1e3, f""反向传播误差{max_grad_diff}超过阈值1e3"" if __name__ == ""__main__"":     pytest.main([""v"", ""test_hardswish.py""]) ``` 2. 运行测试 ```bash pytest test_hardswish.py v ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 1. 接口应支持文档描述的所有int和float类型 2. 对于float32类型输入：     应保持类型不变     正确执行Hardswish操作并返回结果  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明  Hardswish 操作不支持 `DT_INT32` 数据类型，只支持 `DT_FLOAT`、`DT_FLOAT16` 和 `DT_BFLOAT16`   Ascend 硬件在处理 Hardswish 操作时出现了问题",2025-02-23T14:08:22+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO6KJ,使用mindspore 2.5.0版本在Ascend环境中复现了开发者描述的问题，已上报社区。
float16,fengyuebo2025,【开源实习】mindspore.mint接口测试任务17tan梯度问题1," 1.Describe the current behavior / 问题描述  当输入类型为float16，且梯度很大时，mindspore计算的是65504（float16最大值），pytorch计算的是inf（输入数据1.56934）  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_tan.py::test_any_forward_back  4.Steps to reproduce the issue / 重现步骤  ``` import torch import mindspore as ms import numpy as np def forward_pt(x):     return torch.tan(x) def forward_ms(x):     return ms.mint.tan(x) input_data = [[1.56934]] ms_inp=ms.Tensor(input_data,ms.float16) torch_inp=torch.tensor(input_data,requires_grad=True,dtype=torch.float16) torch_res=forward_pt(torch_inp) torch_res.backward(torch.ones_like(torch_res)) torch_inp_grad=torch_inp.grad grad_fn = ms.value_and_grad(forward_ms) _, gradient_ms = grad_fn(ms_inp) ms_inp_grad=gradient_ms print(f""torch梯度为{torch_inp_grad},mindspore梯度为{ms_inp_grad}"") ```  5.Describe the expected behavior / 预期结果  torch梯度为tensor([[inf]]，dtype=torch.float16),mindspore梯度为[[65504.]] 报错关键日志截图： !输入图片说明",2025-02-23T13:51:04+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBO6IU,这个可能是910b上某些算子的一个机制，上溢保护，在超过数据类型所能表达的范围时，如果不做处理就是inf无限大，后续基于inf的计算可能就会出现nan的情况，上溢保护就是会在溢出时赋一个极限值
overflow,majun-bot,CVE20251594,"一、漏洞信息 漏洞编号：CVE20251594 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： A vulnerability, which was classified as critical, was found in FFmpeg up to 7.1. This affects the function ff_aac_search_for_tns of the file libavcodec/aacenc_tns.c of the component AAC Encoder. The manipulation leads to stackbased buffer overflow. It is possible to initiate the attack remotely. The exploit has been disclosed to the public and may be used. 漏洞公开时间：N/A 漏洞创建时间：20250223 06:40:03 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20251594 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 在FFmpeg7.1及以下版本中发现一个漏洞，该漏洞被归类为严重漏洞。该漏洞影响组件AACEncoder的文件libavcodec/aacenc_tns.c中的ff_aac_search_for_tns函数。该操作会导致基于堆栈的缓冲区溢出。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-23T06:40:03+08:00,"gitee,foruda,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,8,https://gitee.com/mindspore/mindspore/issues/IBO5SF,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142"," , , , , ,huawei , , ,he91 , , , ,git , , , , , , , , , , , , , , , , , , , , , , , , , , , ,yfei , , , , ,  **issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  MindSpore评分: (评分和向量) 受影响版本排查(受影响/不受影响):  1.master: 2.v1.10: 3.v1.9.0: 4.v2.0.0: 5.v2.1.0: 6.v2.2.0: 7.v2.2.10: 8.v2.3.0: 9.v2.4.0: 10.v2.4.10:  issue处理具体操作请参考:  https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明 => 没有正确填写," CVE信息从NVD同步失败, 请稍后重试, 或者数据源不存在.",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 在 FFmpeg 7.1 及以下版本中发现一个漏洞，该漏洞被归类为严重漏洞。该漏洞影响组件 AAC Encoder 的文件 libavcodec/aacenc_tns.c 中的 ff_aac_search_for_tns 函数。该操作会导致基于堆栈的缓冲区溢出。 漏洞评分(MindSpore评分):  BaseScore：6.3 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",开发已合入相关修复代码 !输入图片说明
mindformers,baimz,[ST][MS][冒烟]llama2_7b网络multilora_embed mindie服务化和带框架单batch推理报错aclnnGroupedMatmulV3GetWorkspaceSize call failed," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > llama2_7b网络multilora_embed mindie服务化和带框架单batch推理报错aclnnGroupedMatmulV3GetWorkspaceSize call failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001 test_ms_llama2_7b_mindie_infer_multilora_embed_fp16_910b4_1p_0001 test_ms_llama2_7b_mindie_infer_multilora_perf_fp16_910b4_2p_0001 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd /configs/llama2/ > （3）python run_mindformer.py config /home/jenkins0/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_910b4_1p_0001/configs/llama2/predict_llama2_7b_slora.yaml predict_data 'I love Beijing, because' 'I believe the meaning for life is' 'Owning a dog as pet can be' 'I love to watch movies, because'  use_parallel=False adapter_id 'adapter1' > /home/jenkins0/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_910b4_1p_0001/llama2_7b_multilora.log 2>&1 & > （4）验证网络推理是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：网络推理是否正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) ``` Traceback (most recent call last):   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/tools/cloud_adapter/cloud_monitor.py"", line 34, in wrapper     result = run_func(*args, **kwargs)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/run_mindformer.py"", line 76, in main     trainer.predict(predict_checkpoint=config.load_checkpoint, input_data=config.input_data,   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/_checkparam.py"", line 1367, in wrapper     return func(*args, **kwargs)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/trainer/trainer.py"", line 792, in predict     output_result = self.trainer.predict(   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/trainer/causal_language_modeling/causal_language_modeling.py"", line 346, in predict     return self.predict_process(config=config,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/trainer/base_trainer.py"", line 1239, in predict_process     output_results = self.pipeline_task(input_data, top_k=top_k)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/base_pipeline.py"", line 149, in __call__     outputs = self.run_multi(inputs, batch_size, preprocess_params, forward_params, postprocess_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/text_generation_pipeline.py"", line 183, in run_multi     outputs.extend(self.run_single(item, preprocess_params,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/base_pipeline.py"", line 237, in run_single     model_outputs = self.forward(model_inputs, **forward_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/base_pipeline.py"", line 303, in forward     return self._forward(model_inputs, **forward_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/pipeline/text_generation_pipeline.py"", line 199, in _forward     result = self.network.generate(input_ids, **forward_params)   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 913, in generate     infer_output, is_finished = self.infer(input_ids=input_ids,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 1053, in infer     res, current_index = self.forward(input_ids=input_ids,   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 1177, in forward     res = self._incremental_infer(   File ""/data/jenkins_workspace/workspace/TDT_deployment/solution_test/cases/02network/02nlp/llama2/7b/infer/test_ms_llama2_7b_infer_multilora_embed_fp16_910b4_1p_0001/mindformers/generation/text_generator.py"", line 355, in _incremental_infer     res = self(   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 731, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 1152, in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1960, in __call__     return self.run(obj, *args, phase=phase)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 2011, in run     return self._exec_pip(obj, *args, phase=phase_real)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 191, in wrapper     results = fn(*arg, **kwargs)   File ""/home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1991, in _exec_pip     return self._graph_executor(args, phase) RuntimeError: aclnnGroupedMatmulV3GetWorkspaceSize call failed, please check! ```    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】** 戴仁杰（根据实际修改） **【根因分析模板】** 特别说明: 针对master上所有问题需要，走回归前评论里 进行问题引入分析（默认特性在特性分支已经质量OK） ** ** 1. 特性合入引入 ** ** ** **引入 PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx ** ** ** **特性引入原因：和其他特性交叉合入考虑不充分/场景考虑不充分（DT 漏测）/…… ** ** ** **PR 合入时间：2025/1/6 ** ** ** **是否偶现：是/否 ** ** 2. Bugfix 修复引入 ** ** ** **引入 PR： https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx ** ** PR 合入时间：2025/1/6 ** ** 是否偶现：是/否 ** ** 3. 测试新增测试场景/测试漏测/用例未适配 ** ** ** **测试原因：xxx ，1. 新增测试场景要讲清楚是什么测试活动 2. 用例未适配要讲清楚未适配原因（是开发未通知测试，还是测试忘记适配）3. …… ** ** 用例如果有新增，则补充 用例新增时间：2025/1/6 ** ** 是否偶现：是/否 ** ** 4. 环境问题 ** ** ** **具体环境问题描述：要讲清楚具体是什么问题，如 OS 不兼容/机器内存不足/数据集不全/……，不允许因为换一台机器不复现就走单，要有明确环境原因 ** ** 是否偶现：是/否 ** ** 5. CANN 升级 ** ** ** **CANN 包引入，具体 CANN 哪个组件，是否偶现：是/否 问题单回归原则：问题引入原因没描述清楚，测试人员直接将问题单打回，让开发人员补充说明后再回归",2025-02-22T16:07:13+08:00,"gitee,foruda,rca/others,kind/bug,dts-szv,rct/cann,ctl/solutiontest",closed,0,6,https://gitee.com/mindspore/mindspore/issues/IBO3N8,"multilora benchmark的性能也劣化了，generate speed is 278.2349, less than 280.0，上次是14号pass的结果：generate speed:290.9644 is up to 280.0，开发定位是同一问题，关联用例：test_ms_llama2_7b_mindie_infer_multilora_perf_fp16_910b4_2p_0001",问题进展： 使用0219的cann包错误复现，而使用1231的cann包正常推理且精度对齐，暂定位为cann包问题 !输入图片说明,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,确认为算子问题，产品线同事已提单：https://dtsszv.clouddragon.huawei.com/DTSPortal/ticket/DTS2025030506797,"Appearance & Root Cause 问题：slora推理时，sloraembedding出现groupedmatmul算子报错 根因： 1、 groupedmatmul约束限制存在问题，导致x的shape为[1,1]时会错认为转置。 Fix Solution 1、修改groupedmatmul算子。 Fix Description & Test Suggestion 测试建议：正常推理测试。 Selftest Report & DT Review 正常推理无报错，精度对齐。 是否需要补充 ST/UT：否 原因：非基本功能问题 Introduction Analysis 引入类型：算子约束问题 问题是否偶现：否",回归版本：MilanASL V100R001C21SPC001B203 master_20250325085444_498d8e6d48 回归步骤：参考issue复现步骤 基本功能：问题已解决 !输入图片说明 测试结论：回归通过 回归人员：白梦真 回归时间：20250328
ascend,luoxuewei,重构 tensor.tolist() 接口,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-22T14:02:06+08:00,gitee,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBO2UL
overflow,majun-bot,CVE20250838,"一、漏洞信息 漏洞编号：CVE20250838 漏洞归属组件：abseilcpp, https://gitee.com/mindspore/mindspore 漏洞归属的版本：2.0210324e+07 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： There exists a heap buffer overflow vulnerable in Abseilcpp. The sized constructors, reserve(), and rehash() methods of absl::{flat,node}hash{set,map} did not impose an upper bound on their size argument. As a result, it was possible for a caller to pass a very large size that would cause an integer overflow when computing the size of the container's backing store, and a subsequent outofbounds memory write. Subsequent accesses to the container might also access outofbounds memory. We recommend upgrading past commit 5a0e2cb5e3958dd90bb8569a2766622cb74d90c1 漏洞公开时间：N/A 漏洞创建时间：20250222 00:43:54 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20250838 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 5.9 &emsp;Vector： CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-22T00:43:55+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,24,https://gitee.com/mindspore/mindspore/issues/IBO0VI,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142"," , , , , ,huawei , , ,he91 , , , ,git , , , , , , , , , , , , , , , , , , , , , , , , , , , ,yfei , , , , ,  **issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  MindSpore评分: (评分和向量) 受影响版本排查(受影响/不受影响):  1.master: 2.v1.10: 3.v1.9.0: 4.v2.0.0: 5.v2.1.0: 6.v2.2.0: 7.v2.2.10: 8.v2.3.0: 9.v2.4.0: 10.v2.4.10:  issue处理具体操作请参考:  https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明 => 没有正确填写," CVE信息从NVD同步成功, 稍后请重新加载页面.",影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 MindSpore评分： CVSS V3.0分值： BaseScore：0.0 None Vector：CVSS：3.0/ 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明 => 没有正确填写,影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 MindSpore评分： CVSS V3.0分值： BaseScore：5.9 MEDIUM Vector：CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,影响性分析说明 => 没有正确填写," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明： 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 MindSpore评分： CVSS V3.0分值： BaseScore：5.9 MEDIUM Vector：CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明 => 没有正确填写,影响性分析说明: 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 漏洞评分(mindspore评分): BaseScore: 5.9 MEDIUM Vector: CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响," 经过 cvemanager 解析, 已分析的内容如下表所示:  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**","经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",影响性分析说明 => 没有正确填写,影响性分析说明: 该漏洞修复方案在20210324.2版本中不兼容，故不受影响。 漏洞评分(mindspore评分): BaseScore: 5.9 MEDIUM Vector: CVSS:4.0/AV:A/AC:H/AT:P/PR:L/UI:A/VC:L/VI:H/VA:L/SC:L/SI:H/SA:L 受影响版本排查(受影响/不受影响): 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,该漏洞修复方案在20210324.2版本中不兼容，故不受影响。
ascend,吴逸群,香橙派npu利用率上不去,"环境：香橙派20T 24G cann 8.0 mindspore 2.4.10 训练设置参数：ms.setcontext(device_target=""Ascend"", mode=ms.GRAPH_MODE, jit_config={jit_level"".""O2""}, ascend_config{""precision_mode"".""allow_mix_presion""}) 使用过程中，训练的时候，npu利用率持续很低，不超过40%，请问如何设置mindspore参数可以提升？",2025-02-21T17:24:30+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNYT0,ai core的利用率和模型本身有很大关联， 有些模型架构相对利用率更低一些，和模型里调用的算子也有关联，和数据预处理也有关系，数据预处理的占用时间长了，利用率也会下降；香橙派上又有一些特殊情况，CPU较弱、数据传输带宽相比于910都要弱，导致跑很多模型的性能瓶颈都不在ai core的算力上，而是在数据带宽上，或者CPU上，所以利用率通常比较低，并且和香橙派310b的算子实现也有关系，如果算子实现更高效，利用率也会更高一些
ascend,tanxinglian,"[CT][MS][OPS][mint.nn.functional.gelu][function][冒烟]mint.nn.functional.gelu报错TypeError: Failed calling gelu with ""gelu(Tensor, string)""."," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.gelu报错TypeError: Failed calling gelu with ""gelu(Tensor, string)"".  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_n_f_gelu_input_x_0d_float32_tanh >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0  910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_n_f_gelu.py::test_mint_n_f_gelu_input_x_0d_float32_tanh  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```       (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_mint_n_f_gelu_input_x_0d_float32_tanh():         input_x = Tensor(np.random.randn(), mstype.float32)         approximate = 'tanh'         fact = GeluMock(             attributes={'approximate': approximate},             inputs=[input_x]) >       fact.forward_cmp() ../test_mint_n_f_gelu.py:55:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/gelu_mint.py:126: in forward_cmp     out_mindspore = self.forward_mindspore_impl() ../../share/mint/nn_functional/gelu_mint.py:55: in forward_mindspore_impl     out = net(self.input_x, self.approximate) ../../share/utils.py:288: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:742: in __call__     return self.construct(*args, **kwargs) ../../share/mint/nn_functional/gelu_mint.py:21: in construct     out = self.op(input_x, approximate) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  args = (Tensor(shape=[], dtype=Float32, value= 0.380577), 'tanh'), kwargs = {}     def gelu(*args, **kwargs):         r""""""         gelu(input, *, approximate='none') > Tensor         Gaussian Error Linear Units activation function.         GeLU is described in the paper `Gaussian Error Linear Units (GELUs) `_.         And also please refer to `BERT: Pretraining of Deep Bidirectional Transformers for Language Understanding         `_.         When `approximate` argument is `none`, GELU is defined as follows:         .. math::             GELU(x_i) = x_i*P(X >> import mindspore             >>> from mindspore import Tensor, mint             >>> input = Tensor(np.array([[1.0, 4.0, 8.0], [2.0, 5.0, 9.0]]), mindspore.float32)             >>> result = mint.nn.functional.gelu(x)             >>> print(result)             [[1.58655241e01  3.99987316e+00 0.00000000e+00]              [ 1.95449972e+00 1.41860323e06  9.0000000e+00]]             >>> result = mint.nn.functional.gelu(input, approximate=""tanh"")             >>> print(result)             [[1.58808023e01  3.99992990e+00 3.10779147e21]              [ 1.95459759e+00 2.29180174e07  9.0000000e+00]]         """""" >       return _gelu_instance(*args, **kwargs) E       TypeError: Failed calling gelu with ""gelu(Tensor, string)"". E       The valid calling should be: E       ""gelu(input=, *, approximate=)"" E        E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/pipeline/pynative/op_function/converter.h:141 Parse /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/ops/functional_overload.py:1097: TypeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2321152541017505848&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03sk108qs1pcn%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_smoke_20250221%2003:36:50&isMergedTask=false&nodeDate=20250221&year=20242025&TestNow=true&testcaseid=67b780896c3f49211eb7a7ce&workspaceId=67b780864503c84f0af96220&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-21T15:13:02+08:00,"gitee,foruda,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBNWH3, Root Causes && Fix Solution 问题：入参不合法 根因： 接口变更，对齐torch2.1，该参数为关键字参数 !输入图片说明 已发送接口变更邮件，测试仓由测试进行适配  Appearance & Root Cause 问题：用例未适配 根因： 1、直接合入master转测，转测邮件发送较晚，导致测试未感知该变化并适配用例 Fix Solution 1、测试仓适配接口变更 Fix Description & Test Suggestion 无需合入，适配测试仓代码即可 测试建议：接口调用对齐torch Selftest Report & DT Review 无 是否需要补充 ST/UT：否 无需补充 原因：非问题 Introduction Analysis 引入类型：特性合入引入 引入PR：https://gitee.com/mindspore/mindspore/pulls/81218 PR合入时间：2025年2月19日 问题是否偶现：否,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未对此问题进行问题分析 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,接口变更，对齐torch2.1，该参数为关键字参数，适配用例
ascend,tanxinglian,[CT][MS][OPS][mint.scatter_add][function][全量]test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 910b偶现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 910b偶现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE > （2）cd MindSporeTest/operations > （3）pytest s v test_mint_f_scatter_add.py::test_dynamic_shape_mint_f_scatter_add_dyn_shape_2  disablewarnings count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```        (reason='aclnn算子没有开发CPU')     (reason='aclnn算子没有开发GPU')     (reason='aclnn算子没有开发GE流程')     def test_dynamic_shape_mint_f_scatter_add_dyn_shape_2():         input_x = Tensor(shape=(None, None, None, None, None, None, None), dtype=mstype.float16)         dim = mutable(input_data=4, dynamic_len=False)         index = Tensor(shape=(None, None, None, None, None, None, None), dtype=mstype.int32)         src = Tensor(shape=(None, None, None, None, None, None, None), dtype=mstype.float16)         input_x1 = Tensor(np.random.randn(2, 3, 3, 5, 1, 2, 4), mstype.float16)         dim1 = mutable(4)         index1 = Tensor(np.random.randint(0, [2, 3, 3, 5, 1, 2, 4][4]  1,                                           (2, 3, 3, 5, 1, 2, 4)), mstype.int32)         src1 = Tensor(np.random.randn(2, 3, 3, 5, 1, 2, 4), mstype.float16)         attributes1 = {'dim': dim1}         inputs1 = [input_x1, index1, src1]         input_x2 = Tensor(np.random.randn(5, 3, 9, 6, 3, 3, 2), mstype.float16)         dim2 = mutable(2)         index2 = Tensor(np.random.randint(0, [5, 3, 9, 6, 3, 3, 2][2]  1,                                           (5, 3, 9, 6, 3, 3, 2)), mstype.int32)         src2 = Tensor(np.random.randn(5, 3, 9, 6, 3, 3, 2), mstype.float16)         attributes2 = {'dim': dim2}         inputs2 = [input_x2, index2, src2]         input_x3 = Tensor(np.random.randn(8, 5, 9, 9, 9, 5, 7), mstype.float16)         dim3 = mutable(6)         index3 = Tensor(np.random.randint(0, [8, 5, 9, 9, 9, 5, 7][6]  1,                                           (8, 5, 9, 9, 9, 5, 7)), mstype.int32)         src3 = Tensor(np.random.randn(8, 5, 9, 9, 9, 5, 7), mstype.float16)         attributes3 = {'dim': dim3}         inputs3 = [input_x3, index3, src3]         all_attrs = [attributes1, attributes2, attributes3]         all_inputs = [inputs1, inputs2, inputs3]         fact = ScatterAddMock(attributes=attributes1, inputs=inputs1)         fact.dyn_inputs = (input_x, dim, index, src) >       fact.forward_dynamic_shape_cmp(all_attrs, all_inputs) ../test_mint_f_scatter_add.py:687:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/functional/scatter_add_mint.py:280: in forward_dynamic_shape_cmp     allclose_nparray(a, b, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[[[[[[3.6182e01, 1.0654e+00, 1.4590e+00,  2.8784e01],             [1.7344e+00, 2.1035e+00, 2.9956e01, ... 2.0203e01, 7.8320e01],             [1.5254e+00,  5.6641e01, 1.8291e+00, 1.5283e+00]]]]]]],       dtype=float16) data_me = array([[[[[[[3.6182e01, 1.0654e+00, 1.4590e+00,  2.8784e01],             [1.7344e+00, 2.1035e+00, 2.9956e01, ... 2.0203e01, 7.8320e01],             [1.5254e+00,  5.6641e01, 1.8291e+00, 1.5283e+00]]]]]]],       dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0.0713] E       data_me_error:[0.0698] E       loss:[0.001465] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2305979040019775616&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03qp108bf8sh6%2F&title=CT_mindspore_ascend910b_op_graph_standalone_full_20250216%2005:23:08&isMergedTask=false&nodeDate=20250216&year=20242025&TestNow=true&testcaseid=67b1b9ddee88407fc8dce0e1&workspaceId=67b1b9d4a052d73253495445&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T17:32:35+08:00,"gitee,foruda",closed,0,7,https://gitee.com/mindspore/mindspore/issues/IBNP5E,现象：1220 CANN包没有问题，两种模式连跑100次不复现，怀疑是CANN最近更新引入的问题。,切换到0206 CANN包后，连跑24次没有复现问题，运行速度极慢，耗时将近一个小时，暂时无法复现问题。 !输入图片说明,"在测试环境上复现了, 同样的seed，放到222环境上不复现问题,识别到的差异是torch版本不一致，测试环境是1.12， 我们的是2.1",222 torch版本降低之后，复现问题： !输入图片说明 230测试环境： !输入图片说明 可以发现低版本精度问题一致，因此可以判断，该问题为torch版本过低导致的问题。 ps. 使用的seed为37639,将seed固定37639，分别跑torch高低版本，对比之后发现torch高低版本之间有差异： !输入图片说明 高版本torch 2.10： !输入图片说明 低版本torch 1.11: !输入图片说明 因此，本问题单精度问题确定为torch版本差异导致的。走回给测试。, Appearance & Root Cause 问题：test_dynamic_shape_mint_f_scatter_add_dyn_shape_2 910b偶现精度问题 根因：验收的时候标杆用的torch 1.12版本，有偶现问题  Fix Solution 升级torch版本到2.1或者提升loss或者更换固定seed看护  Fix Description & Test Suggestion 如上  Selftest Report & DT Review 升级到torch 2.1，连跑100次pass: !输入图片说明  Introduction Analysis 引入类型：特性合入 特性引入原因：准备交付件的时候，只需所有用例一起跑一次，因为是精度问题（概率7%左右）没有暴露出来 引入pr: https://gitee.com/mindspore/mindspore/pulls/68411 pr合入时间：2025年2月19日 问题是否偶现：是,torch 2.1和1.12的输出结果有差异 torch升级到2.1.0 100次可以通过，待升级torch版本 !输入图片说明
ascend,tanxinglian,[CT][MS][OPS][tensor.baddbmm][function][冒烟]tensor.baddbmm报错TypeError和RuntimeError," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > tensor.baddbmm报错TypeError和RuntimeError  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_tensor_baddbmm_input_dtype_float32_3d >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：910b：O0  910A和CPU：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v  test_f_baddbmm.py::test_tensor_baddbmm_input_dtype_float32_3d  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      def test_tensor_baddbmm_input_dtype_float32_3d():         input_list = []         x0 = Tensor(np.random.randn(128, 16, 16).astype(np.float32))         input_list.append(x0)         x1 = Tensor(np.random.randn(128, 16, 8).astype(np.float32))         input_list.append(x1)         x2 = Tensor(np.random.randn(128, 8, 16).astype(np.float32))         input_list.append(x2)         attributes = {'alpha': 8, 'beta': 40}         fact = BaddbmmMock(attributes=attributes, inputs=input_list)          910A 海思底层不支持fp32，会转成fp16运算         if MSContext.get_instance().get_ascend_soc_version() == 'ascend910':             fact.loss = 2e2 >       fact.forward_tensor_cmp() ../test_f_baddbmm.py:427:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/baddbmm_ops.py:110: in forward_tensor_cmp     out_mindspore = self.forward_mindspore_tensor_impl() ../../share/ops/functional/baddbmm_ops.py:98: in forward_mindspore_tensor_impl     out = net(self.input, self.batch1, self.batch2, self.beta, self.alpha) ../../share/utils.py:288: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:742: in __call__     return self.construct(*args, **kwargs) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self = WrapOp inputs = Tensor(shape=[128, 16, 16], dtype=Float32, value= [[[1.30350626e+00, 2.11461234e+00, 9.46608067e01 ... 1.31597543...15e+00],   [ 2.36984327e01, 7.63088405e01, 5.07046223e01 ... 4.80446875e01, 1.28654742e+00, 1.04887199e+00]]]) batch1 = Tensor(shape=[128, 16, 8], dtype=Float32, value= [[[1.52393794e+00,  1.07605040e+00, 8.56987119e01 ...  5.67518234e...04e01],   [8.72560591e02,  6.82220161e02,  7.46518001e02 ...  5.74400067e01, 8.68605971e01, 2.31278896e01]]]) batch2 = Tensor(shape=[128, 8, 16], dtype=Float32, value= [[[1.61519969e+00, 1.13037705e01, 4.08966541e01 ...  2.69104302e...85e+00],   [ 1.66387343e+00,  3.22911054e01,  5.48864603e01 ...  1.11430407e+00, 3.46323162e01,  6.69651628e02]]]) beta = 40, alpha = 8     def construct(self, inputs, batch1, batch2, beta, alpha): >       return inputs.baddbmm(batch1, batch2, beta, alpha) E       TypeError: Failed calling baddbmm with ""baddbmm(Tensor, Tensor, int, int)"". E       The valid calling should be: E       ""Tensor.baddbmm(batch1=, batch2=, *, beta=, alpha=)"" E       ""Tensor.baddbmm(batch1=, batch2=, *, beta=, alpha=)"" E        E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/ccsrc/pipeline/pynative/op_function/converter.h:141 Parse ../../share/ops/functional/baddbmm_ops.py:29: TypeError ``` ```       def test_tensor_baddbmm_input_dtype_float32_3d():         input_list = []         x0 = Tensor(np.random.randn(128, 16, 16).astype(np.float32))         input_list.append(x0)         x1 = Tensor(np.random.randn(128, 16, 8).astype(np.float32))         input_list.append(x1)         x2 = Tensor(np.random.randn(128, 8, 16).astype(np.float32))         input_list.append(x2)         attributes = {'alpha': 8, 'beta': 40}         fact = BaddbmmMock(attributes=attributes, inputs=input_list)          910A 海思底层不支持fp32，会转成fp16运算         if MSContext.get_instance().get_ascend_soc_version() == 'ascend910':             fact.loss = 2e2 >       fact.forward_tensor_cmp() ../test_f_baddbmm.py:427:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/baddbmm_ops.py:110: in forward_tensor_cmp     out_mindspore = self.forward_mindspore_tensor_impl() ../../share/ops/functional/baddbmm_ops.py:98: in forward_mindspore_tensor_impl     out = net(self.input, self.batch1, self.batch2, self.beta, self.alpha) ../../share/utils.py:288: in __call__     out = super().__call__(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:731: in __call__     out = self.compile_and_run(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1149: in compile_and_run     self.compile(*args, **kwargs) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/nn/cell.py:1132: in compile     _cell_graph_executor.compile(self, *self._compile_args, phase=self.phase, _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  self =  obj = WrapOp, phase = 'train.1740014680927771392.281467199518448.0.....' do_convert = True jit_config_dict = {'debug_level': 'RELEASE', 'exc_mode': 'auto', 'infer_boost': 'off', 'jit_level': '', ...} args = (Tensor(shape=[128, 16, 16], dtype=Float32, value= [[[4.93089229e01,  1.14876276e03,  1.68564007e01 ...  1.5353988...   [ 2.58607864e01,  5.18578470e01, 3.37702758e03 ...  1.46455872e+00, 1.25289917e+00, 3.99672180e01]]]), 40, 8) kwargs = {}, key_id = '2814671995184481740014680927771392', key = 0 parameter_ids = '', raw_phase = 'train' full_function_name = 'WrapOp.1.187650717963712', echo_function_name = 'WrapOp'     def compile(self, obj, *args, phase='predict', do_convert=True, jit_config_dict=None, **kwargs):         """"""         Compiles graph.         Args:             obj (Function/Cell): The function or cell instance need compile.             phase (str): The name of compile phase. Default: 'predict'.             do_convert (bool): When set to True, convert ME graph to GE graph after compiling graph.             jit_config_dict (dict): Jit config for compile. Default: ``None``.             args (tuple): Args of the Cell object.             kwargs (dict): Kwargs of the Cell object.         Return:             Str, the full phase of the cell.             Bool, if the graph has been compiled before, return False, else return True.         """"""         obj.__parse_method__ = 'construct'         if not hasattr(obj, obj.__parse_method__):             raise AttributeError(                 'The class {} dose not have method {}'.format(obj.__class__.__name__, obj.__parse_method__))         key_id = str(id(obj)) + str(obj.create_time)         args = get_auto_dynamic_shape_args(args, key_id)         self.enable_tuple_broaden = False         if hasattr(obj, ""enable_tuple_broaden""):             self.enable_tuple_broaden = obj.enable_tuple_broaden         logger.debug(f""Convert the network: {do_convert}."")         self._graph_executor.set_enable_tuple_broaden(self.enable_tuple_broaden)         key = self._graph_executor.generate_arguments_key(obj, args, kwargs, self.enable_tuple_broaden)         obj.arguments_key = str(key)         obj.arguments_key = obj.arguments_key + ""."" + _get_hook_key(*args, **kwargs)          When exist parameter in the top graph inputs, need check if the parameter object has changed.         parameter_ids = _get_parameter_ids(args, kwargs)         if parameter_ids != """":             obj.arguments_key = obj.arguments_key + '.' + parameter_ids         raw_phase = phase         phase = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key         obj.phase_cache[raw_phase] = phase         update_auto_dynamic_shape_phase(args, key_id, phase)         obj.current_phase = phase         if phase in obj.compile_cache and self.has_compiled(phase) and not parameter_hook_updated():             logger.debug(""%r graph has existed."", phase)              Release resource should be released when CompileInner won't be executed, such as cur_convert_input_              generated in generate_arguments_key.             self._graph_executor.clear_compile_arguments_resource()             return phase, False         full_function_name = obj.__class__.__name__ + '.' + str(obj.instance_count) + '.' + str(id(type(obj)))         echo_function_name = obj.__class__.__name__         _check_recompile(obj, args, kwargs, full_function_name, obj.create_time, echo_function_name)         obj.check_names()         _check_full_batch()         self._set_dataset_mode(obj)         self._set_compile_cache_dep_files(phase)         self._graph_executor.set_weights_values(obj.parameters_dict())         if jit_config_dict:             self._graph_executor.set_jit_config(jit_config_dict)         else:             jit_config_dict = JitConfig().jit_config_dict             self._graph_executor.set_jit_config(jit_config_dict) >       result = self._graph_executor.compile(obj, args, kwargs, phase) E       RuntimeError: Function:baddbmm_2 takes 3 positional arguments, but 3 were given. E        E        E        C++ Call Stack: (For framework developers) E        E       mindspore/core/ir/func_graph_extends.cc:83 GenerateVarParams E        E        E        The Traceback of Net Construct Code: E        E        0 In file /home/jenkinsslave/workspace/mindspore_ascend_opensource/MindSporeTest/share/ops/functional/baddbmm_ops.py:29, 15~58 E               return inputs.baddbmm(batch1, batch2, beta, alpha) E                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ E        (See file '/home/jenkinsslave/workspace/mindspore_ascend_opensource/MindSporeTest/operations/cida_test_tensor_baddbmm_input_dtype_float32_3d/rank_0/om/analyze_fail.ir' for more details. Get instructions about `analyze_fail.ir` at https://www.mindspore.cn/search?inputValue=analyze_fail.ir) /home/miniconda3/envs/ci_310/lib/python3.10/sitepackages/mindspore/common/api.py:1918: RuntimeError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2317863798643359800&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_pynative_standalone_smoke_20250220%2000:56:03&isMergedTask=false&nodeDate=20250220&year=20242025&TestNow=true&testcaseid=67acacaa6c3f49211e92392e&workspaceId=67b60a3a4503c84f0af44949&sub=tab1 https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2319273132049825799&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03mb1082tjvbv%2F&title=CT_mindspore_ascend910a_op_graph_standalone_smoke_reRun8115_20250220%2010:24:02&isMergedTask=false&nodeDate=20250220&year=20242025&TestNow=true&testcaseid=67ac9b676c3f49211e91ed8a&workspaceId=67b685ef6c3f49211eb4a37c    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T16:18:08+08:00,"gitee,foruda,rct/refactor,rca/inf/msg,ctl/testcismoke",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBNNU2, **Appearance & Root Cause**  现象：测试仓的Tensor.baddbmm算子用例报错 根因：Tensor.baddbmm算子进行了接口变更，beta和alpha参数变更为关键字参数 !输入图片说明  **Fix Solution**  使用关键字参数给Tensor.baddbmm算子进行传参。, **问题引入分析：** 用例未适配 原因：mindspore.Tensor.baddbmm接口变更，将beta和alpha变更为关键字参数，而开发未发邮件通知测试。 是否偶现：否,接口变更邮件已补发，需适配用例 !输入图片说明
mindir,LiWanpeng,mindir模型导入导出问题," 1.Describe the current behavior / 问题描述 1. mindir模型导入后重新组网后再导出会导致原有的权重丢失。 2. mindir模型导入后重新组网后再导出时，现有网络必须要保持原有mindir模型的算子实例不变，否则权重参数无法正确加载。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  无  4.Steps to reproduce the issue / 重现步骤  (1) 先生成CNN.mindir,源代码如下: ```  CNN.py import mindspore as ms import mindspore.ops as ops import numpy as np from mindspore import context, nn from mindspore.train.serialization import export context.set_context(mode=context.PYNATIVE_MODE, device_target=""CPU"") one_channel = True class SimpleCNN(ms.nn.Cell):     def __init__(self):         super().__init__()         if one_channel:             self.conv1 = nn.Conv2d(1, 32, kernel_size=3, has_bias=True)         else:             self.conv1 = nn.Conv2d(3, 32, kernel_size=3, has_bias=True)         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, has_bias=True)         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, has_bias=True)         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)         self.flatten = nn.Flatten()         self.dense1 = nn.Dense(32768, 64)         self.dense2 = nn.Dense(64, 5)         self.relu = nn.ReLU()     def construct(self, x):         x = self.relu(self.conv1(x))         x = self.pool1(x)         x = self.relu(self.conv2(x))         x = self.pool2(x)         x = self.relu(self.conv3(x))         x = self.pool3(x)         x = self.flatten(x)         x = self.relu(self.dense1(x))         x = self.dense2(x)         return x my_model = SimpleCNN() inputs = ms.Tensor(np.random.randn(1, 1, 128, 128).astype(np.float32)) context.set_context(mode=context.GRAPH_MODE) export(my_model, inputs, file_name=""CNN"", file_format=""MINDIR"") ``` 该代码生成的CNN.midir转成ms模型,模型图部分截图如下: !输入图片说明 (2)使用nn.GraphCell(ms.load(file_name=""CNN.mindir""))接口加载模型后再导出成SAR_CNN.mindir,源码如下: ``` import mindspore as ms import mindspore.ops as ops import numpy as np from mindspore import context, nn from mindspore.train.serialization import export context.set_context(mode=context.PYNATIVE_MODE, device_target=""CPU"") one_channel = True class SimpleCNN(ms.nn.Cell):     def __init__(self):         super().__init__()         if one_channel:             self.conv1 = nn.Conv2d(1, 32, kernel_size=3, has_bias=True)         else:             self.conv1 = nn.Conv2d(3, 32, kernel_size=3, has_bias=True)         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv2 = nn.Conv2d(32, 64, kernel_size=3, has_bias=True)         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv3 = nn.Conv2d(64, 128, kernel_size=3, has_bias=True)         self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)         self.flatten = nn.Flatten()         self.dense1 = nn.Dense(32768, 64)         self.dense2 = nn.Dense(64, 5)         self.relu = nn.ReLU()         self.cnn = nn.GraphCell(ms.load(file_name=""CNN.mindir""))     def construct(self, x):         x = self.cnn(x)         return x my_model = SimpleCNN() inputs = ms.Tensor(np.random.randn(1, 1, 128, 128).astype(np.float32)) context.set_context(mode=context.GRAPH_MODE) export(my_model, inputs, file_name=""SAR_CNN"", file_format=""MINDIR"") ``` 该代码生成的SAR_CNN.midir转成ms模型,该模型和CNN.ms是一样的,  5.Describe the expected behavior / 预期结果 第二次生成的SAR_CNN.ms模型的Conv2DFusion算子的权重要和第一次生成的CNN.ms模型的Conv2DFusion算子的权重一致.  6.Related log / screenshot / 日志 / 截图 CNN.ms模型的第一个算子Conv2DFusion的权重如下图: !输入图片说明 SAR_CNN.ms模型的第一个算子Conv2DFusion的权重如下图: !输入图片说明",2025-02-20T16:00:32+08:00,"mindspore-assistant,foruda,www,www",progressing,0,8,https://gitee.com/mindspore/mindspore/issues/IBNNJX,Hi 。用例这里SAR_CNN.mindir是用新的SimpleCNN实例导出的，导出到SAR_CNN.mindir的权重，是从新的SimpleCNN实例里取的，而不是从GraphCell里面取的。我们不支持GraphCell实例里的权重跟父Cell实例里的权重去匹配，所以会出现用例里的这个问题。我们不推荐load(mindir)之后再对其网络结构进行改造，如果想改造网络结构，可以定义网络，保存ckpt并加载。,这个是用mindspore导出onnx的模型吗？,我看上面有描述.ms的模型，这个是要在哪里执行这个模型？相关信息麻烦提供详细点，从描述里没看出来，这个是要跑在什么硬件上以及这个导出的模型格式是啥,"不是,都是mindspore生成的midir模型,然后转ms模型",在cpu执行,"使用过这种方法解决,确实可行","(2)使用nn.GraphCell(ms.load(file_name=""CNN.mindir""))接口加载模型后再导出成SAR_CNN.mindir,源码如下: 这部分代码逻辑是为了干嘛？为什么已经导出mindir了，然后重新加载mindir；这个目前是不支持的； mindir的加载完之后直接进行推理即可，如果是服务器上cpu的推理，建议使用mindspore lite的推理方式，详细的可以参考mindspore官网教程： https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/mindir/converter_tool.html https://www.mindspore.cn/lite/docs/zhCN/r2.5.0/mindir/benchmark_tool.html 使用.mindir模型推理，.ms的模型一般适用于端上等算力有限场景","CNN.mindir模型是训练好的神经网络模型, 我们需要在CNN.mindir模型基础上添加一个新的分支, 转换成新的SAR_CNN.ms模型后会有两个图,其中CNN.ms模型的部分跑在是服务器上cpu的推理, 另一个图跑在我们的设备中.如下图:左边的是nn.GraphCell(ms.load(file_name=""CNN.mindir""))生成的,右边是我们在CNN.mindir基础上加的, 假如我们没有CNN.py源码,只有CNN.mindir模型,我们如何生成下图的情况, 并且不能改变CNN.ms模型各个算子的权重? !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][ops.embedding][function][全量]embedding 910A GE模式下有偶现精度问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > embedding 910A GE模式下有偶现精度问题  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_f_embedding_int64_0d__random_forward >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：不设置  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=GRAPH_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations > （3）pytest s v  test_f_embedding.py::test_f_embedding_int64_0d__random_forward count 30  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： ```      (reason='not support,ver=2.3')     (reason='not support,ver=2.3')     def test_f_embedding_int64_0d__random_forward():         input_x = Tensor(np.random.randint(0, 6, ()), mstype.int64)         weight = Parameter(Tensor(np.random.randn(7, 4), mstype.float16), name='weight')         padding_idx = 4         max_norm = 0.4         norm_type = 0.4         scale_grad_by_freq = True         fact = EmbeddingMock(             attributes={'padding_idx': padding_idx, 'max_norm': max_norm, 'norm_type': norm_type,                         'scale_grad_by_freq': scale_grad_by_freq},             inputs=[input_x, weight])         fact.forward_cmp() >       fact.grad_cmp() ../test_f_embedding.py:91:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/ops/functional/embedding_ops.py:134: in grad_cmp     allclose_nparray(grad_pytorch, grad_mindspore, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]], dtype=float32) data_me = array([[ 0.    ,  0.    ,  0.    ,  0.    ],        [ 0.    ,  0.    ,  0.    ,  0.    ],        [ 0.    ,  0.    ,  0...  ,  0.    ],        [ 0.    ,  0.    ,  0.    ,  0.    ],        [ 0.    ,  0.    ,  0.    ,  0.    ]], dtype=float16) rtol = 0.001, atol = 0.001     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0. 0. 0. 0.] E       data_me_error:[0.1635 0.3716  2.475  0.3943] E       loss:[0.16345215 0.37158203 2.4746094  0.3942871 ] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2305979040019775638&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03qp108bf8sh6%2F&title=CT_mindspore_ascend910a_op_graph_standalone_full_20250216%2010:57:17&isMergedTask=false&nodeDate=20250216&year=20242025&TestNow=true&testcaseid=67b20fb384dee72f16c059a6&workspaceId=67b23f817b13446a6133e808    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T15:32:49+08:00,"gitee,gitee,foruda,ctl/componenttest,rct/newfeature,rca/codelogic",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBNN3B, **Appearance & Root Cause**  问题：910A GE模式下，ops.embedding的测试仓用例test_f_embedding_int64_0d__random_forward反向过程中在特定输入下必现精度问题 根因：在ge模式下，当ops.embedding的输入参数padding_idx为负数时，没有像pynative模式和kbk模式的反向算子EmbeddingDenseBackward一样将padding_idx转换成对应的正数，导致反向输出与torch不一致。  **Fix Solution**  对GE模式的反向过程增加pass代码，在pass代码中判断padding_idx是否为负数，若padding_idx为负数则将其转换成对应的正数。  **Fix Description & Test Suggestion**  https://gitee.com/mindspore/mindspore/pulls/82083 PR合入后daily包回归 测试建议：安装了PR合入后的daily包，在910A GE模式下跑test_f_embedding_int64_0d__random_forward用例。  **Selftest Report & DT Review**  修改后，910A GE模式下跑test_f_embedding_int64_0d__random_forward用例可以通过 是否需要补充 ST/UT：否 原因：为测试仓的GE模式问题，不需要不充st和ut用例  **Introduction Analysis**  引入类型：特性合入引入 特性引入原因：ops.embedding的GE模式没有跟pynative和kbk模式对齐，未对padding_idx为负数的场景做适配。 引入PR：https://gitee.com/mindspore/mindspore/pulls/66585 PR合入时间：2024年/3月/29日 问题是否偶现：否,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未包含 自测结果 & 审核结果 (Selftest Report & DT Review) 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,"【回归版本号】：__commit_id__ = '[sha1]:ba6873c3,[branch]:(HEAD,origin/master,origin/HEAD,master)' 【回归环境信息】：Ascend，euleros ， arm 【测试日志】： !输入图片说明"
mindir,LiWanpeng,"mindsporelite 多线程跑模型,子图没有输入时程序死循环"," 1.Describe the current behavior / 问题描述 mindsporelite多线程推理模型,同时存在CPU设备和自定义设备时,模型中存在子图没有输入的情况下,程序进入等待状态,没有跑出结果.  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 ( 无  4.Steps to reproduce the issue / 重现步骤  (1)写一个自定义算子,该算子在自定义设备上运行. ```  complexabs.py import mindspore as ms import numpy as np from mindspore import nn from mindspore.common import dtype as mstype class ComplexAbs(nn.Cell):     def __init__(self):         super(ComplexAbs, self).__init__()         self.op_type = ""Custom_FT_ComplexAbs""         self.op = ms.ops.Custom(             self.kernel,             out_shape=self.infer_shape,             out_dtype=self.infer_dtype,             func_type=""pyfunc"",         )         self.op.add_prim_attr(""type"", self.op_type)     def infer_dtype(self, input):         if input == mstype.TensorType(mstype.complex64):             return ms.float32         elif input == mstype.TensorType(mstype.complex128):             return ms.float64         else:             raise ValueError(""Unsupported data type {}"".format(input))     def infer_shape(self, input):         return input     def kernel(self, input):         out = np.absolute(input)         return out     def construct(self, input):         output = self.op(input)         return output ``` (2)生成模型,该模型自由两个算子,一个CPU的Greater算子,一个是自定义设备的Custom_FT_ComplexAbs算子. ``` import mindspore as ms import numpy as np from mindspore import nn, ops import mindradar as mr class test(nn.Cell):     def __init__(self, LFM):         super(test, self).__init__()         self.LFM = ms.Tensor(LFM)         self.greater = ops.Greater()         self.complexabs = mr.ComplexAbs()     def construct(self, x):         y = self.complexabs(self.LFM)         x = ops.greater(x, y)         return x x = np.ones((3, 3), dtype=np.float32) x_t = ms.Tensor(x) LFM = np.ones((3), dtype=np.complex64) LFM_t = ms.Tensor(LFM) model = test(LFM) out = model(x_t) print(""out:"", out) ms.export(     model,     x_t,     file_name=""test"",     file_format=""MINDIR"", ) ``` 生成的test.mindir模型转ms模型,同时存在CPU设备和自定义设备时,mindsporelite将该模型分成两个子图,Greater算子是一个子图, Custom_FT_ComplexAbs算子是一个子图,其中Custom_FT_ComplexAbs算子的子图没有输入,只有常量. !输入图片说明  5.Describe the expected behavior / 预期结果 mindsporelite推理该模型能够正常结束.  6.Related log / screenshot / 日志 / 截图 mindsporelite多线程推理该模型时, 程序在mindspore/lite/src/litert/mindrt_executor.cc的MindrtRun函数collect.Wait();等待状态.",2025-02-20T15:05:30+08:00,"mindspore-assistant,foruda",progressing,0,2,https://gitee.com/mindspore/mindspore/issues/IBNMJM,"生成的test.mindir模型转ms模型,同时存在CPU设备和自定义设备时,mindsporelite将该模型分成两个子图,Greater算子是一个子图, Custom_FT_ComplexAbs算子是一个子图,其中Custom_FT_ComplexAbs算子的子图没有输入,只有常量. 描述清楚点，什么是自定义设备？还有就是没有子图吧，截图里面没有看到子图","`自定义设备是我们自己添加的一个设备,类似与GPU/opencl设备,你们可以将Custom_FT_ComplexAbs算子注册在GPU/opencl设备中, 然后在mindspore lite跑该模型,会在调试信息看到它们属于两个图,如下: 其中MT7004SubGraph0,是将Custom_FT_ComplexAbs算子划分到自定义设备 ` !输入图片说明"
ascend,tanxinglian,[CT][MS][OPS][mint.nn.functional.gelu][function][全量]mint.nn.functional.gelu bf16偶现精度不达标," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mint.nn.functional.gelu bf16偶现精度不达标  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：     3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): test_mint_n_f_gelu_bfloat16_2d_128x2_random_forward_broadcast >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative >    Excute Mode(e.g., O0\O1\O2)：O0  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export CONTEXT_DEVICE_TARGET=Ascend export CONTEXT_MODE=PYNATIVE_MODE export MS_DISABLE_KERNEL_BACKOFF=1 > （2）cd MindSporeTest/operations export CONTEXT_JIT_LEVEL=O0 > （3）pytest s v  test_mint_n_f_gelu.py::test_mint_n_f_gelu_bfloat16_2d_128x2_random_forward_broadcast count 200  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：用例执行成功  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： 200次出现10次精度不达标 ```      ()     (reason='not support')     (reason='not support')     (reason=""GE暂不支持"")     def test_mint_n_f_gelu_bfloat16_2d_128x2_random_forward_broadcast():         input_x = Tensor(np.random.randint(768, 367, (128, 2)), mstype.bfloat16)         approximate = 'tanh'         fact = GeluMock(             attributes={'approximate': approximate},             inputs=[input_x])         fact.forward_cmp() >       fact.grad_cmp() ../test_mint_n_f_gelu.py:443:  _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  ../../share/mint/nn_functional/gelu_mint.py:133: in grad_cmp     allclose_nparray(grad_pytorch, grad_mindspore, self.loss, self.loss) ../../share/utils.py:63: in allclose_nparray     _count_unequal_element(data_expected, data_me, rtol, atol) _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  data_expected = array([[ 1.421875  ,  0.04516602],        [ 0.47851562, 0.        ],        [ 0.        , 1.28125   ],        [ 0.02...      [ 0.        , 0.        ],        [ 0.203125  , 0.41796875],        [0.        , 0.        ]], dtype=float32) data_me = array([[ 1.4218750e+00,  4.5166016e02],        [ 4.7851562e01, 0.0000000e+00],        [ 0.0000000e+00, 1.2812500e+...+00, 0.0000000e+00],        [ 2.0312500e01, 4.1796875e01],        [0.0000000e+00, 0.0000000e+00]], dtype=float32) rtol = 0.004, atol = 0.004     def _count_unequal_element(data_expected, data_me, rtol, atol):         assert data_expected.shape == data_me.shape         total_count = len(data_expected.flatten())         error = np.abs(data_expected  data_me)         greater = np.greater(error, atol + np.abs(data_me) * rtol)         nan_diff = np.not_equal(np.isnan(data_expected), np.isnan(data_me))         inf_diff = np.not_equal(np.isinf(data_expected), np.isinf(data_me))         neginf_diff = np.not_equal(np.isneginf(data_expected), np.isneginf(data_me))         greater = greater + nan_diff + inf_diff + neginf_diff         loss_count = np.count_nonzero(greater) >       assert (loss_count / total_count) < rtol, \             ""\ndata_expected_std:{0}\ndata_me_error:{1}\nloss:{2}"". \                 format(data_expected[greater], data_me[greater], error[greater]) E       AssertionError:  E       data_expected_std:[0.01696777 1.2109375 ] E       data_me_error:[0.01049805 1.1953125 ] E       loss:[0.00646973 0.015625  ] ../../share/utils.py:56: AssertionError ``` 完整日志（通过附件上传）： https://testreporter.szv.dragon.tools.huawei.com/TestDataBot/analysis/taskdetailes?productId=mindspore&productLine=2012%20Laboratories&taskId=2305979040019775615&tmssPath=%2F03200tqk2t5d0%2F03o5107oo9agj%2F03qp108bf8sh6%2F&title=CT_mindspore_ascend910b_op_pynative_standalone_full_20250216%2014:40:00&isMergedTask=false&nodeDate=20250216&year=20242025&TestNow=true&testcaseid=67b4e1f84503c84f0af03d6f&workspaceId=67b4e1f7a052d7325353f5fa&sub=tab1    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**",2025-02-20T14:58:58+08:00,"gitee,sig/ops,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBNMGH, Appearance & Root Cause 问题：精度问题 根因： 测试环境标杆为torch1.12，开发环境标杆为torch2.1，torch高低版本存在差异导致偶现精度问题，接口预期对标标杆为torch2.1  Fix Solution 无需修复  Fix Description & Test Suggestion 无 测试建议：使用torch2.1作为标杆  Selftest Report & DT Review 无 是否需要补充 ST/UT：否 原因：非问题  Introduction Analysis 引入类型：环境问题 引入PR：无 PR合入时间：无 问题是否偶现：是,【问题单处理不规范】：您问题单根因分析不规范，问题单自动打回: 1. 未对此问题进行问题分析 具体规则请查看: https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined ,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,测试环境标杆为torch1.12，开发环境标杆为torch2.1，torch高低版本存在差异导致偶现精度问题，接口预期对标标杆为torch2.1 标杆升为torch2.1，执行200次成功 !输入图片说明
bfloat16,fangfangssj,mint.nn.functional.dropout在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mint.nn.functional.dropout在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_dropout.py::test_dropout_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_dropout_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10, 3).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              生成权重和偏置             weight_data = np.random.randn(2, 3).astype(np.float32)             ms_weight = ms.tensor(weight_data, dtype)             torch_weight = torch.tensor(weight_data, dtype=torch_dtype)             bias_data = np.random.randn(2).astype(np.float32)             ms_bias = ms.tensor(bias_data, dtype)             torch_bias = torch.tensor(bias_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.dropout(ms_input, ms_weight, ms_bias)             torch_output = torch.nn.functional.dropout(torch_input, torch_weight, torch_bias)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T23:28:33+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGXF,"1. 对比910B mindspore精度需要安装torch_npu，请根据当前环境信息安装对应版本torch_npu 2. dropout为随机数算子，进行精度对比时需要控制mindspore与torch初始状态一致，不传入generator状态时建议使用manul_seed接口设置默认generator的初始状态 样例修改后可通过 ``` import pytest import torch, torch_npu import numpy as np import mindspore as ms from mindspore import mint .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_dropout_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]      dropout是随机数算子，如要进行精度对比，需要配置seed使得torch和mindspore初始状态一致     ms.manual_seed(0)     torch.manual_seed(0)     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10, 3).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)              torch tensor放置到npu上，             torch_input = torch.tensor(input_data, dtype=torch_dtype).npu()              设置丢弃概率             p = 0.5              计算输出             ms_output = mint.nn.functional.dropout(ms_input, p)             torch_output = torch.nn.functional.dropout(torch_input, p)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).cpu().numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.cpu().numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```"
bfloat16,fangfangssj,mint.nn.functional.dropout在910b上静态图无法计算," 1.Describe the current behavior / 问题描述  mint.nn.functional.dropout在910b上静态图无法计算  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_dropout.py::test_dropout_all_dtypes  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_dropout_all_dtypes(mode):     ms.set_context(mode=mode)      定义所有 mindspore.dtype 类型     ms_dtypes = [         ms.int8,          ms.int16,          ms.int32,          ms.int64,          ms.uint8,          ms.float16,          ms.float32,          ms.float64,         ms.bfloat16,         ms.complex64,         ms.complex128     ]      定义对应的 PyTorch dtype     torch_dtypes = [         torch.int8,          torch.int16,          torch.int32,         torch.int64,          torch.uint8,          torch.float16,         torch.float32,          torch.float64,          torch.bfloat16,         torch.complex64,         torch.complex128     ]     ms_supported_dtypes = []     ms_unsupported_dtypes = []     torch_supported_dtypes = []     torch_unsupported_dtypes = []      遍历所有 dtype     for ms_dtype, torch_dtype in zip(ms_dtypes, torch_dtypes):          生成随机数据         input_data = np.random.randn(5, 3).astype(np.float32)   生成随机数据         ms_input = ms.tensor(input_data, ms_dtype)         torch_input = torch.tensor(input_data, dtype=torch_dtype)         try:              调用 dropout 函数             ms_output = mint.nn.functional.dropout(ms_input)              对比结果shape             assert ms_output.shape == ms_input.shape             ms_supported_dtypes.append(ms_dtype)         except Exception as e:             ms_unsupported_dtypes.append(ms_dtype)             print(e)         try:              调用 dropout 函数             torch_output = torch.nn.functional.dropout(torch_input)              对比结果shape             assert torch_output.shape == torch_input.shape             torch_supported_dtypes.append(torch_dtype)         except Exception as e:             torch_unsupported_dtypes.append(torch_dtype)     print(f""MindSpore supported dtypes: {ms_supported_dtypes}"")     print(f""MindSpore unsupported dtypes: {ms_unsupported_dtypes}"")     print(f""PyTorch supported dtypes: {torch_supported_dtypes}"")     print(f""PyTorch unsupported dtypes: {torch_unsupported_dtypes}"") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：和动态图有相同的计算  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T23:17:20+08:00,"gitee,mindspore-assistant,foruda",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGWH,!输入图片说明 执行该用例未复现ISSUE描述的问题，请排查环境是否安装正确，mindspore与CANN版本是否配套，或更新至最新的发布版本观察问题是否复现。
bfloat16,fangfangssj,mint.nn.functional.linear在910b上float32运算有较大精度误差," 1.Describe the current behavior / 问题描述  mint.nn.functional.linear在910b上float32运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_linear.py::test_linear_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_linear_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10, 3).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              生成权重和偏置             weight_data = np.random.randn(2, 3).astype(np.float32)             ms_weight = ms.tensor(weight_data, dtype)             torch_weight = torch.tensor(weight_data, dtype=torch_dtype)             bias_data = np.random.randn(2).astype(np.float32)             ms_bias = ms.tensor(bias_data, dtype)             torch_bias = torch.tensor(bias_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.linear(ms_input, ms_weight, ms_bias)             torch_output = torch.nn.functional.linear(torch_input, torch_weight, torch_bias)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float32运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T22:58:01+08:00,gitee,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGU7,bfloat16数据类型由于浮点精度差异，误差标准为4e3，可使用该精度标准执行用例
bfloat16,fangfangssj,mint.nn.functional.tanh在910b上float32运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.tanh在910b上float32运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_tanh.py::test_tanh_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_tanh_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.tanh(ms_input)             torch_output = torch.nn.functional.tanh(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float32运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T22:21:29+08:00,"gitee,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBNGQ1,使用mindspore 2.5.0版本在Ascend环境中未复现了开发者描述的问题，且提供的测试代码中数据类型未对应。 修改为正确代码后通过测试，与torchnpu结果一致 !输入图片说明
ascend,xiedejin1,【AR】Tensor.remainder_  Ascend后端 未接入KBK," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > Tensor.remainder_ 算子Ascend后端正向目前不支持 KBK  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B`/`Mac CPU`)    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * 见日志 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 执行测试仓用例  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 功能达标  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  7.Special notes for this issue/备注 (Optional / 选填)",2025-02-19T16:17:45+08:00,"gitee,sig/ops",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBNDNV
sharding,jiangchenglin3,Sharding Propagation mint op,**What type of PR is this?** /kind refactor **What does this PR do / why do we need it**: Refactor strategy propagation for broadcast operator **Which issue(s) this PR fixes**:  Fixes  **Code review checklist 【代码检视checklist说明】**: +  [ ] 是否进行返回值校验 (禁止使用void屏蔽安全函数、自研函数返回值，C++标准库函数确认无问题可以屏蔽) +  [ ] 是否遵守 ***SOLID原则 / 迪米特法则*** +  [ ] 是否具备UT测试用例看护 && 测试用例为有效用例 (若新特性无测试用例看护请说明原因) +  [ ] 是否为对外接口变更 +  [ ] 是否涉及官网文档修改   ,2025-02-19T15:27:01+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBNCNR
mindir,wqx,使用2.5.0版本导出mindir出现2GB容量的限制,尝试在2.5.0昇腾环境尝试了把DeepSeekR1DistillQwen1.5B导出为MINDIR格式，但出现了不能超过2GB的限制： !输入图片说明 尝试在GPU环境也有一样的情况： !输入图片说明 模型确定是能够静态图推理的；这个模型大小差不多3.5GB，我以前就导出过14GB左右的chatglm2 6b模型的mindir文件，这某个版本的bug吗？还是使用上有什么限制，或者需要设置什么？文档上也只说了onnx和air格式才有2GB的限制，没说mindir有这个限制： !输入图片说明,2025-02-19T14:47:35+08:00,"gitee,mindspore-assistant",open,0,4,https://gitee.com/mindspore/mindspore/issues/IBNC0V,这个报错是在三方库 Protobuf 。 mindir是基于protocol buffers实现的，所以会有2GB的限制, 只要使用protocol buffers作为序列化格式，就会收到单条消息最大2GB的限制,那我以前用mindformers套件里的chatglm6b模型导出过mindir，那个模型导出后总大小有12GB以上，那个是怎么做到的呢？当然他那个导出后不是一个mindir文件，而是有一个比较小的mindir文件，然后里面还有一个文件夹，里面有多个文件，好像是mindir具体的权重数据文件？当时用的导出方法是完全一样的，不知道当时是怎么导出来的？,"找出占用大量空间的常量的tensor 把他们定义为parameter 就可以了, 你用的大模型没有包含大常量tensor，一般情况是没有这种大常量的。网络模型一般就几十M就算是比较大的模型了；例如38B，是只参数parmater的规模；"
memory leak,majun-bot,CVE202525469,"一、漏洞信息 漏洞编号：CVE202525469 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg gitmaster before commit d5873b was discovered to contain a memory leak in the component libavutil/iamf.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:54:03 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202525469 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:54:03+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBN86X,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：6.5 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",该漏洞属于ffmpeg的main分支的bug，引起该问题的文件在ffmpeg5.1.4版本上没有，故不受影响。
memory leak,majun-bot,CVE202525468,"一、漏洞信息 漏洞编号：CVE202525468 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： FFmpeg gitmaster before commit d5873b was discovered to contain a memory leak in the component libavutil/mem.c. 漏洞公开时间：N/A 漏洞创建时间：20250219 09:53:34 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202525468 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞官网定义为无效漏洞，不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.5 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-02-19T09:53:34+08:00,"gitee,CVE/UNAFFECTED,ctl/componenttest,rca/others,rct/oldrelease",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBN86E,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞官网定义为无效漏洞，不受影响。 漏洞评分(MindSpore评分):  BaseScore：6.5 MEDIUM  Vector：CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",该漏洞官网定义为无效漏洞，不受影响。
mindformers,Mrtutu,动态profiling参数校验问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 动态profiling参数校验问题 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-19T09:40:09+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBN7Z1
bfloat16,fangfangssj,mint.nn.functional.softmax在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.softmax在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_softmax.py::test_softmax_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_softmax_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.float64, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.softmax(ms_input)             torch_output = torch.nn.functional.softmax(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T01:08:06+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBN713
bfloat16,fangfangssj,mint.nn.functional.sigmoid在910b上float16运算有较大精度误差," 1.Describe the current behavior / 问题描述  mindspore.mint.nn.functional.sigmoid在910b上float16运算有较大精度误差  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例 test_sigmoid.py::test_sigmoid_fixed_dtype_random_input  4.Steps to reproduce the issue / 重现步骤 ``` .mark.parametrize('mode', [ms.GRAPH_MODE, ms.PYNATIVE_MODE]) def test_sigmoid_fixed_dtype_random_input(mode):     ms.set_context(mode=mode)      固定dtype为float16、float32、float64、bfloat16     dtypes = [ms.float16, ms.float32, ms.float64, ms.bfloat16]     torch_dtypes = [torch.float16, torch.float32, torch.float64, torch.bfloat16]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):         for _ in range(100):              随机生成输入值             input_data = np.random.randn(10).astype(np.float32)             ms_input = ms.tensor(input_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)              计算输出             ms_output = mint.nn.functional.sigmoid(ms_input)             torch_output = torch.nn.functional.sigmoid(torch_input)              对比输出             if dtype == ms.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") ```  5.Describe the expected behavior / 预期结果 > **【预期结果】**：float16运算不应该有精度误差  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-19T00:44:27+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN70M,在910B环境下，复现以上问题，MindSpore 2.5.0版本与torchnpu结果一致，未出现精度问题。
bfloat16,fangfangssj,mint.nn.functional.sigmoid支持的数据类型描述不符,1. 【Document Link】/【文档链接】 https://www.mindspore.cn/docs/zhCN/r2.4.0/api_python/mint/mindspore.mint.nn.functional.silu.html 2. 【Issues Section】/【问题文档片段】 !输入图片说明 3. 【Existing Issues】/【存在的问题】 文档中对api支持参数的数据类型描述不全，异常的描述有问题。测试后发现api还支持bfloat16 4. 【Expected Result】【预期结果】 增加对应类型的数据类型描述,2025-02-19T00:36:12+08:00,"gitee,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBN70D,无明显问题，可补充 TypeError  input 不是Tensor,标题与文档链接不符
float16,fengyuebo2025,【开源实习】mindspore.mint接口测试任务9," 1.Describe the current behavior / 问题描述  在输入为float16类型时，mint.atan2接口的输出有时和torch.atan2接口输出差值大于1e3；且目前测试时，绝对误差值均为0.001953。  2.Environment / 环境信息  **Hardware Environment / 硬件环境**:       3.Related testcase / 关联用例 · test_atan2.py::test_any_random_input_fixed_dtype  4.Steps to reproduce the issue / 重现步骤  ``` import mindspore as ms import torch inp= [0.24023] oth= [0.59326] ms_i=ms.Tensor(inp,ms.float16) ms_o=ms.Tensor(oth,ms.float16) pt_i=torch.tensor(inp,dtype=torch.float16) pt_o=torch.tensor(oth,dtype=torch.float16) r1=ms.mint.atan2(ms_i,ms_o) r2=torch.atan2(pt_i,pt_o) print(f""mindspore输出为{r1},pytorch输出为{r2},绝对误差为{r1.asnumpy()r2.numpy()}"") ```  5.Describe the expected behavior / 预期结果  mindspore输出为[2.756],pytorch输出为tensor([2.7578], dtype=torch.float16),绝对误差为[0.001953] 报错关键日志截图： !输入图片说明",2025-02-18T14:40:49+08:00,"gitee,mindspore-assistant,foruda",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBN1P8,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致，未出现精度问题。 !输入图片说明
ascend,林芃芃,mint.hardshrink接口类型检查机制不完善，内部类型转换逻辑有bug，对不同shape的输入处理不一致," 1.Issue Description / 问题描述 MindSpore的Hardshrink接口在数据类型处理方面存在2个问题： 1. 类型检查不一致：     文档声明在Ascend平台仅支持float16、float32、bfloat16     实际测试中int32类型输入未被正确拒绝     错误消息与预期不符 2. 类型转换异常：     输入float16类型数据被意外转换为int32     相同的float16类型在不同场景下表现不一致  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例 >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    test_hardshrink_invalid_input: 测试int32类型输入未被正确拒绝 >    test_hardshrink_sequence: 测试序列数据的处理 >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode: Graph  4.Steps to reproduce the issue / 重现步骤 1.创建测试代码`test_hardshrink.py`: ```python import numpy as np import pytest import torch import mindspore as ms from mindspore import Tensor import mindspore.mint as mint class TestHardshrink:     """"""Hardshrink算子测试类""""""     def test_hardshrink_invalid_input(self):         """"""测试无效输入的处理""""""         ms_hardshrink = mint.nn.Hardshrink(lambd=0.5)          测试不支持的数据类型         with pytest.raises(TypeError, match=""For primitive.*must be a type of.*Float""):             x_ms = Tensor(np.array([1.0]), dtype=ms.int32)             ms_hardshrink(x_ms)          测试空输入         with pytest.raises(ValueError, match=""Input tensor cannot be empty""):             x_ms = Tensor(np.array([]), dtype=ms.float32)             ms_hardshrink(x_ms)          测试维度为0的输入         with pytest.raises(ValueError, match=""Input tensor must have at least one dimension""):             x_ms = Tensor(np.array([[]]), dtype=ms.float32)             ms_hardshrink(x_ms)          测试负的lambda值         with pytest.raises(ValueError, match=""Lambda value must be nonnegative""):             mint.nn.Hardshrink(lambd=0.5)         print(""无效输入测试通过"")     def test_hardshrink_sequence(self):         """"""测试序列数据的处理""""""          生成序列数据         seq_length = 10         batch_size = 2         hidden_size = 16         np.random.seed(42)         x_np = np.random.uniform(2, 2, size=(batch_size, seq_length, hidden_size)).astype(np.float16)          MindSpore实现         x_ms = Tensor(x_np, dtype=ms.float16)         ms_hardshrink = mint.nn.Hardshrink(lambd=0.5)         y_ms = ms_hardshrink(x_ms)          PyTorch实现         x_torch = torch.tensor(x_np, dtype=torch.float16)         torch_hardshrink = torch.nn.Hardshrink(lambd=0.5)         y_torch = torch_hardshrink(x_torch)          比较结果         np.testing.assert_allclose(             y_ms.asnumpy(),             y_torch.detach().numpy(),             rtol=1e3,             atol=1e3         )         print(""序列数据测试通过"") ``` 2. 执行测试 ```bash pytest test_hardshrink.py v ```  5.Describe the expected behavior / 预期结果 1. 类型检查行为：     严格按照文档说明，只接受float16、float32、bfloat16类型     对不支持的类型（如int32）应立即报错     错误消息应准确描述问题 2. 类型转换行为：     保持输入类型不变，不进行隐式转换     在所有场景下对相同类型有一致的处理  6.Related log / screenshot / 日志 / 截图 类型转换错误信息： ``` TypeError: For primitive[HShrink], the input argument[input_x] must be a type of {BFloat16, Float16, Float32}, but got Int32.   C++ Call Stack: (For framework developers)  mindspore/core/utils/check_convert_utils.cc:1062 CheckSubClass ``` !输入图片说明",2025-02-17T07:08:17+08:00,"gitee,mindspore-assistant",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBMLRU
ascend,朱俞桦,【开源实习】mindspore.mint接口测试任务10," 1.Describe the current behavior / 问题描述  在float16、bfloat16的dtype设置下，进行mint.cross计算时分别会出现以下两种情况： 1. dtype为float16时，计算结果与torch误差有可能大于1e3 !输入图片说明 2. dtype为bfloat16时，mint.cross计算会报运行时错误： !输入图片说明  2.Environment / 环境信息   **Hardware Environment / 硬件环境**:   3.Related testcase / 关联用例  >  **Testcase Name/ 用例名 **: >    Testcase Name: test_cross_fixed_dtype_random_input() >  **Excute Mode / 执行模式 **: >    Excute Mode(Graph): * >    Excute Mode(O2)：*  4.Steps to reproduce the issue / 重现步骤  > （1）`pip install upgrade mindspore==2.4.0` > （2）`pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 indexurl https://download.pytorch.org/whl/cpu i https://pypi.tuna.tsinghua.edu.cn/simple` > （3）运行如下代码： ``` import mindspore import numpy as np from mindspore import mint import mindspore as ms from mindspore import Tensor, mint, ops import mindspore.nn as mnn import numpy as np import torch import torch.nn as nn  设置随机种子 seed = 42 torch.manual_seed(seed) mindspore.set_seed(seed)  设置上下文，指定设备为 Ascend ms.set_context(device_target=""Ascend"", device_id=0)  ''' b) 测试固定dtype，random输入值，对比两个框架输出是否相等（误差范围为小于1e3） ''' def test_cross_fixed_dtype_random_input():      固定dtype     dtypes = [         mindspore.int8, mindspore.int16, mindspore.int32, mindspore.int64,         mindspore.uint8,          mindspore.float16,  这里会出现计算结果相对误差大于1e3的情况         mindspore.float32, mindspore.float64,         mindspore.bfloat16,  这里会出现运行时报错         mindspore.complex64, mindspore.complex128     ]     torch_dtypes = [         torch.int8, torch.int16, torch.int32, torch.int64,         torch.uint8,          torch.float16,          torch.float32, torch.float64,         torch.bfloat16,          torch.complex64, torch.complex128     ]     for dtype, torch_dtype in zip(dtypes, torch_dtypes):          print(dtype, torch_dtype)         for _ in range(100):             input_data = np.abs(np.random.randn(2, 3)).astype(np.float32)             other_data = np.abs(np.random.randn(2, 3)).astype(np.float32)             ms_input = Tensor(input_data, dtype)             ms_other = Tensor(other_data, dtype)             torch_input = torch.tensor(input_data, dtype=torch_dtype)             torch_other = torch.tensor(other_data, dtype=torch_dtype)             ms_output = mint.cross(ms_input, ms_other)             torch_output = torch.cross(torch_input, torch_other)              对比输出             if dtype == mindspore.bfloat16:                 np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)             else:                 np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     print(""MindSpore and PyTorch outputs are equal within tolerance."") test_cross_fixed_dtype_random_input() ```  5.Describe the expected behavior / 预期结果  > **【预期结果】**：两个框架输出误差范围为小于1e3，且支持所有dtype  6.Related log / screenshot / 日志 / 截图  报错关键日志截图： !输入图片说明 !输入图片说明 完整日志： 1. dtype为float16时 ```  AssertionError                            Traceback (most recent call last) Cell In[46], line 1 > 1 test_cross_fixed_dtype_random_input() Cell In[45], line 113     111             np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)     112         else: > 113             np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3)     115 print(""MindSpore and PyTorch outputs are equal within tolerance."")     [... skipping hidden 1 frame] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/testing/_private/utils.py:844, in assert_array_compare(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)     840         err_msg += '\n' + '\n'.join(remarks)     841         msg = build_err_msg([ox, oy], err_msg,     842                             verbose=verbose, header=header,     843                             names=('x', 'y'), precision=precision) > 844         raise AssertionError(msg)     845 except ValueError:     846     import traceback AssertionError:  Not equal to tolerance rtol=0.001, atol=0 Mismatched elements: 1 / 6 (16.7%) Max absolute difference: 0.0004883 Max relative difference: 0.003845  x: array([[ 1.277  , 0.6504 , 0.02371],        [0.2893 ,  0.2426 ,  0.02124]], dtype=float16)  y: array([[ 1.277  , 0.65   , 0.0238 ],        [0.2893 ,  0.2424 ,  0.02124]], dtype=float16) ``` 2. dtype为bfloat16时 ```  RuntimeError                              Traceback (most recent call last) Cell In[44], line 1 > 1 test_cross_fixed_dtype_random_input() Cell In[43], line 111     109  对比输出     110 if dtype == mindspore.bfloat16: > 111     np.testing.assert_allclose(ms_output.astype(ms.float32).asnumpy(), torch_output.to(torch.float32).numpy(), rtol=1e3)     112 else:     113     np.testing.assert_allclose(ms_output.asnumpy(), torch_output.numpy(), rtol=1e3) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/_stub_tensor.py:49, in _stub_method..fun(*arg, **kwargs)      47 stub = arg[0]      48 arg = (stub.stub_sync(),) + arg[1:] > 49 return method(*arg, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/tensor.py:1070, in Tensor.asnumpy(self)    1068 if self.has_init:    1069     self.init_data() > 1070 return Tensor_.asnumpy(self) RuntimeError: aclnnLinalgCrossGetWorkspaceSize call failed, please check!   Ascend Error Message:  EZ1001: 2025021622:52:14.763.073 self not implemented for DT_BFLOAT16, should be in dtype support list [DT_FLOAT,DT_FLOAT16,DT_DOUBLE,DT_INT8,DT_INT16,DT_INT32,DT_INT64,DT_COMPLEX64,DT_COMPLEX128,DT_UINT8,].[THREAD:28251] (Please search ""CANN Common Error Analysis"" at https://www.mindspore.cn for error code description)   C++ Call Stack: (For framework developers)  mindspore/ops/kernel/ascend/pyboost/customize/cross.cc:54 operator() ```",2025-02-16T22:58:40+08:00,mindspore-assistant,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBMLH6,在910B环境下，MindSpore 2.5.0版本与torchnpu结果一致，未出现精度问题。
graph mode,林芃芃,`mindspore.mint.cumsum` 在处理 int8 类型数据时存在溢出问题," 1.Describe the current behavior / 问题描述 任务链接 `mint.cumsum` 在处理 int8 类型数据时存在溢出问题  2.Environment / 环境信息  **Hardware Environment / 硬件环境**    **Additional Information**  **NPUSMI Info**:   ```   npusmi 23.0.rc2.2   NPU: 910B   Health: OK   Power: 67.4W   Temp: 37°C   Memory Usage: 2942 / 15665 MB   HBM Usage: 2 / 32768 MB   ```  **OS Details**:   ```   Linux v162d976f5b34a378c2232db989fe0dftask00 5.4.042generic 46Ubuntu SMP Fri Jul 10 00:24:02 UTC 2020 aarch64 GNU/Linux   ```  **GCC Details**:   ```   gcc (GCC) 7.3.0   ```  3.Related testcase / 关联用例  **Testcase Name**: >  test_cumsum.py::test_int8_overflow  **Execute Mode**: >  Graph Mode  4.Steps to reproduce the issue / 重现步骤 1. 准备测试环境： ```python import numpy as np import pytest import mindspore import torch from mindspore import Tensor from mindspore import mint def test_int8_overflow():     """"""测试int8类型的溢出情况""""""     print(""\n=== 测试int8类型溢出 ==="")      测试用例1: 正数溢出     data1 = np.array([64, 64, 64], dtype=np.int8)   累加后会超过127      测试用例2: 负数溢出     data2 = np.array([64, 64, 64], dtype=np.int8)   累加后会小于128      测试用例3: 边界值     data3 = np.array([127, 1, 1], dtype=np.int8)   从最大值开始累加     test_cases = [         (data1, ""正数溢出""),         (data2, ""负数溢出""),         (data3, ""边界值"")     ]     results = {}     for data, case_name in test_cases:         print(f""\n测试{case_name}:"")         print(f""输入数据: {data}"")          PyTorch测试         torch_input = torch.tensor(data, dtype=torch.int8)         torch_output = torch.cumsum(torch_input, dim=0)          MindSpore测试         ms_input = Tensor(data, dtype=ms.int8)         ms_output = mint.cumsum(ms_input, dim=0)          计算结果         torch_result = torch_output.numpy()         ms_result = ms_output.asnumpy()         print(f""PyTorch结果: {torch_result}"")         print(f""MindSpore结果: {ms_result}"")          检查是否一致         is_equal = np.array_equal(torch_result, ms_result)         results[case_name] = {             'torch_output': torch_result,             'ms_output': ms_result,             'is_equal': is_equal         } ``` 2. 运行测试用例： ```bash pytest test_cumsum.py v ```  5.Describe the expected behavior / 预期结果 通过测试用例，确保 MindSpore 的`mint.cumsum`函数在处理 int8 类型的数据时，不会出现溢出。  6.Related log / screenshot / 日志 / 截图 !输入图片说明",2025-02-14T21:11:46+08:00,"gitee,mindspore-assistant",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBMF65,int8 类型能表达的最大值就是127。当累加运算结果超过127后，产生溢出是正常现象。 MindSpore 当前行为是与torch_npu对齐的，与pytorch_cpu是不一致的，并非是问题。 若用户的应用场景会产生溢出值，建议使用int32/int64输入数据类型。
mindformers,zhangyinxia,手册修改," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） 1、input格式调整 2、中文手册补充 3、中英文映射表补充 > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-14T15:28:21+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBMBWK,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
yi,caifubi,某些环境编译GPU会缺少符号undefined symbol: _ZN9mindspore6kernel7pyboost9OpFactoryINS1_15GroupedMatmulV4EE3GetEv,,2025-02-14T10:51:18+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBM8US
minddata,jalenlee,"Ascend910B在Ubuntu22.04上执行chartglm26b ptuning报错, 同样的配置在Ubuntu20.04上正常执行","Ascend910B在Ubuntu22.04上执行chartglm26b ptuning报错, 同样的配置在Ubuntu20.04上正常执行 环境:  Ascend 910b OS:Ubuntu 22.04 driver: Ascendhdk910bnpudriver_24.1.rc1_linuxaarch64.run 固件: Ascendhdk910bnpufirmware_7.1.0.6.220.run docker ascend: Ascenddockerruntime_6.0.RC1_linuxaarch64.run  镜像:  swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.0_mindspore2.2.11:aarch_20240125 Mindformers版本: 1.0.0 !Mindformers版本 执行chartglm26b ptuning微调时报错:    C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/kernel/opapi/aclnn/tile_aclnn_kernel.h:37 RunOp Traceback (most recent call last):   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/run_mindformer.py"", line 365, in      main(config_)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/tools/cloud_adapter/cloud_monitor.py"", line 44, in wrapper     raise exc   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/tools/cloud_adapter/cloud_monitor.py"", line 34, in wrapper     result = run_func(*args, **kwargs)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/run_mindformer.py"", line 143, in main     create_task_trainer(config)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/run_mindformer.py"", line 85, in create_task_trainer     trainer.train(config, is_full_config=True)   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/trainer/causal_language_modeling/causal_language_modeling.py"", line 97, in train     self.training_process(   File ""/usr/local/Models/algorithm/mindformers1.0.0/scripts/mf_standalone/mindformers/trainer/base_trainer.py"", line 734, in training_process     model.train(config.runner_config.epochs, dataset,   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 1290, in train     _train_wrapper(epoch,   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 119, in wrapper     func(self, *args, **kwargs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 815, in _train     self._train_dataset_sink_process(epoch, train_dataset, list_callback,   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/train/model.py"", line 902, in _train_dataset_sink_process     outputs = train_network(*inputs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 703, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/nn/cell.py"", line 1074, in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1860, in __call__     return self.run(obj, *args, phase=phase)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1911, in run     return self._exec_pip(obj, *args, phase=phase_real)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 185, in wrapper     results = fn(*arg, **kwargs)   File ""/root/miniconda3/envs/ms2.3_me1.0.rc2_py310/lib/python3.10/sitepackages/mindspore/common/api.py"", line 1891, in _exec_pip     return self._graph_executor(args, phase) RuntimeError: Call aclnnRepeat failed, detail:EZ9903: 2025021107:56:36.166.797 rtKernelLaunchWithHandleV2 failed: 507035[THREAD:8007]         Solution: In this scenario, collect the plog when the fault occurs and locate the fault based on the plog.         TraceBack (most recent call last):         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 1, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x2a00564840, mte error info: 0x160305559d, ifu error info: 0x78a6837abfac0, ccu error info: 0x9289844c3f03727b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x305559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:2, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 2, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x721a37e4be, mte error info: 0x160303559d, ifu error info: 0x2c83313078ec0, ccu error info: 0x7f84821e3ab63e3f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x303559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:3, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 3, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x20149747da, mte error info: 0x160301559d, ifu error info: 0x16b1079a41080, ccu error info: 0xc6eb7b31464ef6b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:4, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 4, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x4015b1c410, mte error info: 0x160301559d, ifu error info: 0x10889be15ec80, ccu error info: 0x9c202769282711f9, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:5, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 5, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x6013a0a12d, mte error info: 0x160301559d, ifu error info: 0x441165f72800, ccu error info: 0xdd7469d01c7bfd7b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:6, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 7, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x321e372d21, mte error info: 0x160301559d, ifu error info: 0x146b0b625f280, ccu error info: 0x57e820dc38214ea0, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:8, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 9, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x630057e008, mte error info: 0x160305459d, ifu error info: 0x310c303a0b000, ccu error info: 0x84112e0d391720bf, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x305459d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:10, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 10, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x6915c59205, mte error info: 0x160301559d, ifu error info: 0x68ee9f6b8cfc0, ccu error info: 0xe285e407cb3346d, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:11, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 11, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x610915508c, mte error info: 0x160303559d, ifu error info: 0x101c831ea46c0, ccu error info: 0x822e3cb258a3909f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x303559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 12, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x3303054c00, mte error info: 0x160307559d, ifu error info: 0x3103792b8f340, ccu error info: 0xc4d5f3ff7bc7476f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x307559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:13, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 13, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x5305c40c6c, mte error info: 0x160307559d, ifu error info: 0x3f73f7ca59180, ccu error info: 0x3e0e7e7d173805b1, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x307559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:14, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         The error from device(chipId:0, dieId:0), serial number is 4, there is an aivec error exception, core id is 47, error code = 0x800000, dump info: pc start: 0x1240c0045370, current: 0x1240c00461d8, vec error info: 0x730b9f9a19, mte error info: 0x160301559d, ifu error info: 0x3f3ad3bb7bac0, ccu error info: 0x5f42008c7896e01f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd000288, para base: 0x124100401000.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1212][THREAD:7565]         The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x301559d, fixp_error1 info: 0x16 fsmId:0, tslot:0, thread:0, ctxid:0, blk:0, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_proc.cc][LINE:1224][THREAD:7565]         Kernel task happen error, retCode=0x31, [vector core exception].[FUNC:PreCheckTaskErr][FILE:davinic_kernel_task.cc][LINE:1220][THREAD:7565]         AIV Kernel happen error, retCode=0x31.[FUNC:GetError][FILE:stream.cc][LINE:1082][THREAD:7565]         Aicore kernel execute failed, device_id=0, stream_id=2, report_stream_id=2, task_id=4, flip_num=0, fault kernel_name=GatherV2_618279a26921567d421037acce4dee5b_high_precision_900015010, fault kernel info ext=none, program id=12, hash=18024093464264554721.[FUNC:GetError][FILE:stream.cc][LINE:1082][THREAD:8007]         [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1082][THREAD:8007]         Failed to submit kernel task, retCode=0x715005e.[FUNC:LaunchKernelSubmit][FILE:context.cc][LINE:677][THREAD:8007]         kernel launch submit failed.[FUNC:LaunchKernelWithHandle][FILE:context.cc][LINE:893][THREAD:8007]         rtKernelLaunchWithHandleV2 execute failed, reason=[vector core exception][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53][THREAD:8007]         rtKernelLaunchWithHandleV2 failed: 507035[THREAD:8007]         OpExecCache run fail.[THREAD:8007]   C++ Call Stack: (For framework developers)  mindspore/ccsrc/plugin/device/ascend/kernel/opapi/aclnn/tile_aclnn_kernel.h:37 RunOp [WARNING] MD(7400,ffff8d6b2020,python):2025021107:57:36.468.869 [mindspore/ccsrc/minddata/dataset/engine/datasetops/data_queue_op.cc:163] ~DataQueueOp] channel_name: 93a21600e84d11efa4f2b04fa6440df3; have_sent: 101; host_queue: 1, 1, 0, 0, 1, 1, 0, 0, 1, 1; device_queue: 91, 92, 93, 94, 95, 96, 97, 98, 99, 99;       push_first_start_time > push_first_end_time 2025021107:55:36.203.430 > 2025021107:55:36.204.534             push_start_time > push_end_time 2025021107:55:36.549.759 > 2025021107:55:36.550.217 2025021107:55:36.550.425 > 2025021107:55:36.550.885 2025021107:55:36.552.788 > 2025021107:55:36.553.246 2025021107:55:36.555.619 > 2025021107:55:36.556.062 2025021107:55:36.561.950 > 2025021107:55:36.562.565 2025021107:55:36.562.806 > 2025021107:55:36.563.257 2025021107:55:36.563.459 > 2025021107:55:36.564.052 2025021107:55:36.573.849 > 2025021107:55:36.574.219 2025021107:55:36.574.377 > 2025021107:55:36.574.762 2025021107:56:31.438.491 > 2025021107:56:31.439.006 For more details, please refer to the FAQ at https://www.mindspore.cn/docs/en/master/faq/data_processing.html. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.474.548 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_manager.cc:257] SyncStream] Call runtime aclrtSynchronizeStreamWithTimeout error. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.474.757 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_kernel_runtime.cc:578] SyncStream] Sync default stream failed. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.474.790 [mindspore/ccsrc/runtime/device/kernel_runtime_manager.cc:134] WaitTaskFinishOnDevice] SyncStream failed [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.475.005 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_manager.cc:257] SyncStream] Call runtime aclrtSynchronizeStreamWithTimeout error. [ERROR] DEVICE(7400,ffff8d6b2020,python):2025021107:57:36.475.041 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_stream_manager.cc:270] SyncAllStreams] SyncStream for stream id 0 failed. [ERROR] ME(7400,ffff8d6b2020,python):2025021107:57:36.475.067 [mindspore/ccsrc/runtime/hardware/device_context_manager.cc:490] WaitTaskFinishOnDevice] SyncStream failed",2025-02-11T16:09:33+08:00,"gitee,foruda,foruda,www,www,help,bugs,mirrors,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBLK30,看错误提示可能是驱动和cann、mindspore不匹配造成的；确定环境都一样，一个能跑一个不能跑吗？还有cann版本是多少？ 根据你上面列出的各个版本，匹配上是可能有问题的；上面写的mindspore是2.2.11版本，这个对应的cann版本是7.0，而对应的驱动应该是23.*开头的；而你上面的驱动版本是24.1.rc1，这个驱动对应了cann8.0开始的版本，mindspore版本也需要2.3以后的 !输入图片说明 !输入图片说明,"=======================答复: 环境说明============================ VERSION=”20.04.5 LTS (Focal Fossa)” Ascendhdk910bnpudriver_24.1.rc1_linuxaarch64.run Ascendhdk910bnpufirmware_7.1.0.6.220.run Ascenddockerruntime_6.0.RC1_linuxaarch64.run Mindformers 1.0.0 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.0_mindspore2.2.11:aarch_20240125 Get component version(7.1.0.6.220) succeed for deviceId(7), componentType(27).         {""device_id"":7, ""component"":hlink2, ""version"":7.1.0.6.220} } root:~ npusmi info ++  root:~ cat /etc/osrelease NAME=""Ubuntu"" VERSION=""20.04.5 LTS (Focal Fossa)"" ID=ubuntu ID_LIKE=debian PRETTY_NAME=""Ubuntu 20.04.5 LTS"" VERSION_ID=""20.04"" HOME_URL=""https://www.ubuntu.com/"" SUPPORT_URL=""https://help.ubuntu.com/"" BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/"" PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/termsandpolicies/privacypolicy"" VERSION_CODENAME=focal UBUNTU_CODENAME=focal 使用这个组合是可以运行的 使用镜像启动: swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.0_mindspore2.2.11:aarch_20240125这个镜像中的版本:  !容器内 Ubuntu22上还尝试过这两个镜像, toolkit是8.0的, 报错是一样的 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.2_mindspore2.3:20240722 swr.cncentral221.ovaijisuan.com/mindformers/mindformers1.1_mindspore2.3rc2:2024051 ==================问题====================== 问题1. gitee上看Mindformers1.2已经没有了chatglm26b的ptuning微调文档说明, 是否已经不支持? 问题2. 看镜像站上最旧的一个os是ubuntu22的镜像http://mirrors.cncentral221.ovaijisuan.com/detail/138.html, 匹配的是mindformers1.2, 微调是否跟os有关系?ubuntu22是否支持chatglm26b的ptuningw微调?"
ascend,hedongdong,【AR】算子Tensor接口重载Tensor.roll," Tasks 转测对象：Tensor.roll   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.roll  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  Roll the tensor input along the given dims.  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` roll:      op_yaml: roll_op.yaml       py_method: tensor_roll  callback to python function ""def tensor_roll""       Ascend: pyboost       CPU: py_method       GPU: py_method       interface: tensor      op_yaml: deprecated/roll_method.yaml       py_method: tensor_roll  callback to python function ""def tensor_roll""       Ascend: py_method       CPU: py_method       GPU: py_method       interface: tensor ```  算子原语 ``` roll:   args:     input:       dtype: tensor     shifts:       dtype: tuple[int]       prim_init: True       type_cast:  int, list[int]     dims:       dtype: tuple[int]       default: None       prim_init: True       type_cast:  int, list[int]   returns:     output:       dtype: tensor ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-02-11T14:48:57+08:00,"gitee,sig/ops",progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBLIK1
deepseek,孙昊辰,support 3d batch matmul in internal kernal,   Backgroud（背景信息）  deepseek branch  support 3d batch matmul in internal kernal  Origin（信息来源）  算子团队  Benefit / Necessity （价值/作用）  提高算子效率  Design（设计方案）  support 3d batch matmul in internal kernal,2025-02-11T10:52:34+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBLFQ2
ascend,guyueyuan,mindspore.mint.distributed.init_process_group训练时cpu与npu运行参数异常,"  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode graph  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 普通的训练测试代码 ``` import os import numpy as np import mindspore as ms import mindspore.nn as nn from mindspore import ops from mindspore import set_context import mindspore.dataset as ds import mindspore.mint.distributed as ms_dist  定义一个简单的MLP网络 class SimpleMLP(nn.Cell):     def __init__(self):         super(SimpleMLP, self).__init__()         self.flatten = nn.Flatten()         self.layer1 = nn.Dense(28*28, 256)         self.relu1 = nn.ReLU()         self.layer2 = nn.Dense(256, 64)         self.relu2 = nn.ReLU()         self.layer3 = nn.Dense(64, 10)     def construct(self, x):         x = self.flatten(x)         x = self.relu1(self.layer1(x))         x = self.relu2(self.layer2(x))         return self.layer3(x) def create_dataset(batch_size):      创建随机数据用于测试     data = np.random.randn(1000, 28, 28).astype(np.float32)     label = np.random.randint(0, 10, (1000,)).astype(np.int32)     dataset = ds.NumpySlicesDataset(         {""data"": data, ""label"": label},          shuffle=True     )     dataset = dataset.batch(batch_size)     return dataset def main():      设置运行环境     ms.set_context(mode=ms.PYNATIVE_MODE, device_target=""Ascend"")      使用mint接口初始化分布式环境     ms_dist.init_process_group(         backend='hccl',   Ascend使用hccl后端         world_size=2,     总进程数     )     rank_id = ms_dist.get_rank()     rank_size = ms_dist.get_world_size()     print(f""当前进程 rank_id: {rank_id}, 总进程数 rank_size: {rank_size}"")      创建数据集     dataset = create_dataset(batch_size=32)      创建网络、损失函数和优化器     network = SimpleMLP()     loss_fn = nn.CrossEntropyLoss()     optimizer = nn.Adam(network.trainable_params())     def forward_fn(data, label):         logits = network(data)         loss = loss_fn(logits, label)         return loss     grad_fn = ops.value_and_grad(forward_fn, None, optimizer.parameters)     def train_step(data, label):         loss, grads = grad_fn(data, label)         optimizer(grads)         return loss     try:          训练循环         epochs = 5         for epoch in range(epochs):             total_loss = 0             steps = 0             for data in dataset.create_dict_iterator():                 loss = train_step(data[""data""], data[""label""])                 total_loss += loss                 steps += 1                 print(f""Epoch: {epoch}, Step: {steps}, Loss: {loss}"")             print(f""Epoch: {epoch}, 平均损失: {total_loss/steps}"")     finally:          清理分布式环境         ms_dist.destroy_process_group()         print(""分布式环境已清理"") if __name__ == ""__main__"":     main() ```  Describe the expected behavior / 预期结果 (Mandatory / 必填) npu内存和aicore参数正常  Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 可以看见基本上都是cpu在主跑，目前测试在昇思大模型平台和启智社区，皆出现此异常 !输入图片说明 !输入图片说明  Special notes for this issue/备注 (Optional / 选填) !输入图片说明",2025-02-08T19:28:08+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKZQN
ascend,daheyinyin,数据类型转换为uint32时，在不同设备结果不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  将负数转换为Uint32时，Ascend和CPU上的结果不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填)  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore as ms import torch x = [[1, 6], [7.9, 3.2]] ms_tensor = ms.tensor(x, dtype=ms.uint32) torch_tensor = torch.tensor(x, dtype=torch.uint32) print(ms_tensor, torch_tensor) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：不同设备结果一致  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： linux Ascend，与torch结果不同 !输入图片说明 windows运行结果,与torch一致 !windows运行结果    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-08T15:44:34+08:00,"gitee,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBKX66,补充，Ascend环境是启智平台的910A,经分析， 该问题是平台架构X86和aarch64不同导致的，将副店类型负数直接转换为无符号整数会返回无法预期的结果
ascend,hedongdong,【AR】算子Tensor接口重载Tensor.xlogy及ops接口重载ops.xlogy," Tasks 转测对象：Tensor.xlogy / ops.xlogy   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.xlogy  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  !输入图片说明  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` xlogy:    op_yaml: xlogy_scalar_other_op.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: pyboost     CPU: py_method     GPU: py_method     interface: tensor, function    op_yaml: xlogy_scalar_self_op.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: pyboost     CPU: py_method     GPU: py_method     interface: function    op_yaml: xlogy_op.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: pyboost     CPU: pyboost     GPU: pyboost     interface: tensor, function    op_yaml: deprecated/xlogy_method.yaml     py_method: tensor_xlogy  callback to python function ""def tensor_xlogy_tensor""     Ascend: py_method     CPU: py_method     GPU: py_method     interface: tensor ```  算子原语 ``` xlogy:   args:     input:       dtype: tensor       type_cast: number     other:       dtype: tensor       type_cast: number   args_signature:     dtype_group: (input, other)   returns:     out:       dtype: tensor ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-02-08T11:46:00+08:00,sig/ops,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBKUDP
ascend,hedongdong,【AR】算子Tensor接口重载Tensor.logaddexp," Tasks 转测对象：Tensor.logaddexp   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.logaddexp  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  !输入图片说明  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` logaddexp:    op_yaml: logaddexp_op.yaml     py_method: deprecated_tensor_logaddexp  callback to python function ""def deprecated_tensor_logaddexp""     Ascend: pyboost     CPU: py_method     GPU: py_method     interface: tensor    op_yaml: deprecated/logaddexp_method.yaml     py_method: deprecated_tensor_logaddexp  callback to python function ""def deprecated_tensor_logaddexp""     Ascend: py_method     CPU: py_method     GPU: py_method     interface: tensor ```  算子原语 ``` logaddexp:   args:     input:       dtype: tensor     other:       dtype: tensor   args_signature:     dtype_group: (input, other)   returns:     output:       dtype: tensor ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-02-08T11:41:42+08:00,sig/ops,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBKUAR
ascend,guyueyuan,mindspore.mint.distributed.init_process_group启动内存异常问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore.mint.distributed.init_process_group初始化拉起分布式环境的时候，内存占用异常  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Ascend: 2*Ascend910proA  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: /mode graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore as ms from mindspore import set_context from mindspore.mint.distributed import init_process_group, destroy_process_group set_context(device_target=""Ascend"",mode=ms.GRAPH_MODE) init_process_group(backend='hccl',world_size=2) print(""环境初始化完成"") destroy_process_group() print(""销毁通信组"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 初始化阶段内存占用应该比较少，至少不会像我测试这样这么高  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 !输入图片说明 !输入图片说明 报错关键日志截图： !输入图片说明  7.Special notes for this issue/备注 (Optional / 选填) 环境信息截图： !输入图片说明 !输入图片说明",2025-02-08T11:35:54+08:00,"foruda,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBKU7P,换了个环境，也是一样的问题 !输入图片说明,去掉mode=ms.GRAPH_MODE试试，图模式会固定分配一块静态内存。
ascend,guyueyuan,mindspore.mint.distributed.init_process_group启动内存异常问题," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mindspore.mint.distributed.init_process_group初始化拉起分布式环境的时候，内存占用异常  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Ascend: 2*Ascend910proA  3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: /mode graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) ``` import mindspore as ms from mindspore import set_context from mindspore.mint.distributed import init_process_group, destroy_process_group set_context(device_target=""Ascend"",mode=ms.GRAPH_MODE) init_process_group(backend='hccl',world_size=2) print(""环境初始化完成"") destroy_process_group() print(""销毁通信组"") ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 初始化阶段内存占用应该比较少，至少不会像我测试这样这么高  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !输入图片说明 !输入图片说明 !输入图片说明 报错关键日志截图： !输入图片说明  7.Special notes for this issue/备注 (Optional / 选填) 环境信息截图： !输入图片说明 !输入图片说明",2025-02-08T11:35:52+08:00,"gitee,mindspore-assistant",rejected,0,1,https://gitee.com/mindspore/mindspore/issues/IBKU7O,https://gitee.com/mindspore/mindspore/issues/IBKU7P?from=projectissue 重复提单， 详见这个issue
ascend,cccc1111,index_put接入aclnn, Tasks 转测对象：tensor.index_put 对标torch.tensor.index_put   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/bool  **2. MindSpore算子情况**   当前支持数据类型 index_put在Ascend后端PyNative模式下支持数据类型与torch_npu保持一致 index_put在Ascend后端KBK/GE与CPU后端与之前保持一致（复用IndexPut原语）  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  根据指定的索引位置，将新的值赋给张量中的对应元素。  **2. 接口描述**   接口重载： tensor.index_put: !输入图片说明 !输入图片说明 !输入图片说明 对于Ascend后端，PyNative模式会走新增IndexPutExt原语，对于KBK/GE与CPU后端走原有逻辑。 Ascend的PyNative模式： !输入图片说明 Ascend的KBK模式： !输入图片说明 Ascend的GE模式： !输入图片说明 CPU的PyNative模式 !输入图片说明 CPU的KBK模式： !输入图片说明 CPU的GE模式： !输入图片说明  算子原语   自动生成对应原语,2025-02-07T15:13:51+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKNNU
mindnlp,wqx,尝试用在香橙派上推理DeepSeekR1DistillQwen1.5B碰到的一些问题,"目前在香橙派ai pro 20t 24G测试了DeepSeekR1DistillQwen1.5B，用的mindspore 2.3.1， 2.4.1和2.4.10，使用的mindnlp版本是master分支和0.4.0版本，都没能成功运行，cann版本都是根据文档装的，2.3.1用的是8.0rc2,2.4.1和2.4.10用的是8.0rc3； 测试代码如下： !输入图片说明 出错情况总结如下： 如果是在fp32模式下运行，都是加载权重出错： !输入图片说明 !输入图片说明 如果是在fp16模式下运行，其中2.4.1和2.4.10都是报了aclnn相关错误： !输入图片说明 如果是2.3.1的话，是报了内存相关错误，这个错误我在910b上也见到过，通常是显存不足的情况下会报： !输入图片说明 但照理说这个1.5b的模型，fp16运行应该不会显存不足，我在我的4090，以及线上910b上测试结果都是占用8G不到的显存 在2.3.1上也测试了qwen0.5b，也是返回这个memory相关的错误",2025-02-07T12:05:35+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBKLMF,最终验证下来是mindspore或者cann版本在香橙派ai pro上不适配的问题，使用cann 8.0.RC3 alpha 002，mindspore使用2.4.0或者以上正式发布的版本都可以
ascend,zhangyinxia,通信算子性能内存调优,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-02-07T11:35:13+08:00,gitee,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKL8G
mindformers,luoxuewei,pyboost流程中op_run_info数据结构优化," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填)    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**luoxuewei（根据实际修改）",2025-02-07T09:51:05+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBKJHI
ascend,Alicya,"运行mistral7b,报 RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm"," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > 使用华为云北京四910A对应镜像运行mistral7b,报 RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(mistral7Bv0.1): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）在华为云提供的镜像中搭好必要环境 > （2）根据github中提供的关于mistral的readme文档（https://github.com/lvyufeng/mistralmindspore/tree/12109d82ae9ff0fa854a5ebccba9ff62325e8fd7）下载和运行mistral7Bv0.1 > （3）运行报错  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：mistral7Bv0.1运行正常 !预期结果  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 在使用北京四 910A的对应镜像的时候运行会有一个警告和RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm报错（见图1.1和图1.2），搜了一下然后在mian.py中添加了行代码用自动并行模式还是报错RuntimeError: Cast failed, original value: 0.0883883, type: FP32Imm（见图1.3和图1.4） 报错关键日志截图： !图1.1 !图1.2 !图1.3 !图1.4 完整日志（通过附件上传）： 没保存    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-02-06T13:34:59+08:00,"mindspore-assistant,github",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBKDIR,这个是比较早的代码实现了，看样子是早期的实现代码和框架环境的兼容问题，或者用的框架版本比较早，触发了以前版本的某个bug；mistral模型的代码现在建议使用mindnlp套件里的实现： https://github.com/mindsporelab/mindnlp/tree/master/mindnlp/transformers/models/mistral 并且昇腾910环境mindspore建议用较新的版本，尽量不要低于2.3.1，这要启动速度快，体验好； 华为云贵阳一区，或者启智社区都有比较新的mindspore版本的昇腾环境，可以试试
ascend,xiedejin1,【AR】//= Ascend后端 在910B上 e2e 性能不达标," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > floor_divide_(符号//=) PyNative正向e2e性能在910B Ascend后端上不达标  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B`/`Mac CPU`)    3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): PyNative 单脚本测试用例： ```python import mindspore import numpy as np from mindspore import Tensor, mint from mindspore.common.api import _pynative_executor from mindspore._c_expression import _framework_profiler_step_start, _framework_profiler_step_end import time np.random.seed(23) input = Tensor(np.random.uniform(low=10000, high=10000, size=(10, 10)).astype(np.float32)) other = Tensor(np.random.uniform(low=0.998, high=1.002, size=(10, 10)).astype(np.float32)) for _ in range(1000):     input //= other _pynative_executor.sync() _framework_profiler_step_start() start = time.time() for _ in range(1000):     input //= other _pynative_executor.sync() end = time.time() _framework_profiler_step_end() print(f""ms cost: {(endstart)*1000} us"") ```  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 使用脚本执行性能测试用例  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) 性能达标  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 见评论区  7.Special notes for this issue/备注 (Optional / 选填)",2025-02-05T17:16:47+08:00,"gitee,foruda,sig/ops",open,0,1,https://gitee.com/mindspore/mindspore/issues/IBK7UB,在910B上，PyNative Ascend后端e2e不达标 !输入图片说明 !输入图片说明
yi,Mike Cheung,ops.Receive document issue," 1. 【Document Link】/【文档链接】 https://www.mindspore.cn/docs/en/master/api_python/ops/mindspore.ops.Receive.html 2. 【Issues Section】/【问题文档片段】 sr_tag (int) – A required integer identifying the send/recv message tag. The message will will be send by the Send op with the same ""sr_tag"". 3. 【Existing Issues】/【存在的问题】 double `will` and it should be `come from the Send op` instead of `send by xxx` 4. 【Expected Result】【预期结果】  Please fill in the expected result",2025-02-05T15:51:28+08:00,"foruda,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBK6RJ,"In the revised document, the relevant description has been changed to: ""This operator will receive the tensor sent by the Send operator with the same sr_tag tag."" !screenshot"
mindir,Guan_nauG,mindsporelite转换模型，不支持TensorScatterUpdate," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > 用mindspore_lite将mindyolo训练得到的mindir模型转为ms模型时，报错显示不支持TensorScatterUpdate算子  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）将ckpt模型导出为mindir  python deploy/export.py config ../configs/yolov5/yolov5s.yaml weight ../weights/EMA_yolov5s_500.ckpt per_batch_size 1 file_format MINDIR device_target CPU > （2）验证导出的mindir模型能否正常推理 python deploy/mslite_predict.py mindir_path ./weights/yolov5s_500.mindir conf_thres 0.45 iou_thres 0.45 config ./configs/yolov5/yolov5s.yaml image_path XXXimages/val/00006050.jpg !mindir推理结果 > （3）将mindir模型用mindsporelite转为ms模型，未转换成功 converter_lite fmk=MINDIR modelFile=./EMA_yolov5s500e.mindir outputFile=./250121 inputDataFormat=NCHW  4.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：成功导出ms模型，且可正常推理  5.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志部分： [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\legacy_optimizer\graph\dropout_node_remove_pass.cc:35] IsolateDropoutNode] Only support node who has no more than one input and two output [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\legacy_optimizer\graph\dropout_node_remove_pass.cc:106] Run] IsolateDropoutNode failed, subGraph: , node: Default/modelModel/modelCellList/24YOLOv5Head/TensorScatterUpdateop4, error: 1 [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\optimizer.cc:78] Run] Run GraphPass failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\graphdef_transform.cc:93] Transform] Run unused_op_remove_optimizer graphPasses Failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter_metagraph.cc:102] Build] Transform meta graph failed!ret = 1 [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1259] SaveGraph] Convert to meta graph failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1212] HandleGraphCommon] Save graph failed: 1 Common error code. [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1152] Convert] Handle graph failed: 1 Common error code. [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\converter.cc:1344] RunConverter] Convert model failed [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:60] PrintOps] =========================================== [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:61] PrintOps] UNSUPPORTED OP LIST: [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:63] PrintOps] FMKTYPE: , OP TYPE: TensorScatterUpdate [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore/lite/tools/converter/converter_context.h:65] PrintOps] =========================================== [ERROR] LITE(107288,1,?):2025124 10:42:59 [mindspore\lite\tools\converter\cxx_api\converter.cc:374] Convert] Convert model failed, ret=Common error code. ERROR [mindspore\lite\tools\converter\converter_lite\main.cc:104] main] Convert failed. Ret: Common error code. Convert failed. Ret: Common error code.",2025-01-24T16:10:02+08:00,"gitee,mindspore-assistant",progressing,0,5,https://gitee.com/mindspore/mindspore/issues/IBJNP4,"在yolov5_head.py中将以下部分 y[..., 0:2] = (y[..., 0:2] * 2.0  0.5 + grid_tensor) * self.stride[i]  xy y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  wh z += (y.view(bs, 1, self.no),) 更改为： xy = (y[..., 0:2] * 2.0  0.5 + grid_tensor) * self.stride[i] wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i] y = ops.concat([xy, wh, y[..., 4:]], axis=1) z += (y.view(bs, 1, self.no),) 经export.py得到mindir模型，再用mindspore_lite,可得到能使用的ms模型。 但推理时，不包括前处理和后处理，从传入输入后开始计时，得到模型输出用了400ms左右，请问如何优化，谢谢",请问你的环境信息具体是什么，可否补充一下？,"您好，补充环境信息：(1)模型训练的时候用的是ascend910b, mindspore2.3.0    cann8.0.rc1    py3.9    euler2.10.7    aarch64 (2)用mindsporelite2.4.10将mindir模型转为了ms (3)端侧调用ms模型用的是CPU",算子解析不支持，需要适配,已转需求，内部开发中；
ascend,陈盼妙,[CT][MS][门禁]test_print_string.py::test_run_op_print failed in gate," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) test_print_string.py::test_run_op_print failed in gate  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:     3.Related testcase / 关联用例 (Mandatory / 必填) [gate failed]tests/st/dynamic_shape test_print_string.py::test_run_op_print			  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填)  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：跑pass  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) master 80722 machenggui 20250120 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/MindSpore_Gitee_Gate/runs/375826/nodes/133/log 80775 huangbingjian 20250122 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/MindSpore_Gitee_Gate/runs/376016/nodes/219/log 80834 liubuyu 20250123 https://build.mindspore.cn/blue/rest/organizations/jenkins/pipelines/MindSpore_Gitee_Gate/runs/376194/nodes/623/log ``` [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] test_print_string.py F [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] =================================== FAILURES =================================== [20250122T02:11:05.500Z] ______________________________ test_run_op_print _______________________________ [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]     (plat_marks=['platform_ascend'], level_mark='level0', card_mark='onecard', essential_mark='essential') [20250122T02:11:05.500Z]     def test_run_op_print(): [20250122T02:11:05.500Z]         """""" [20250122T02:11:05.500Z]         Feature: Test print string by calling _run_op method. [20250122T02:11:05.500Z]         Description: Test print string by calling _run_op method. [20250122T02:11:05.500Z]         Expectation: No exception and result is correct. [20250122T02:11:05.500Z]         """""" [20250122T02:11:05.500Z]         ms.set_context(mode=ms.PYNATIVE_MODE) [20250122T02:11:05.500Z]         class Net(nn.Cell): [20250122T02:11:05.500Z]             def __init__(self): [20250122T02:11:05.500Z]                 super().__init__() [20250122T02:11:05.500Z]                 self.print = P.Print() [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]             def construct(self, x): [20250122T02:11:05.500Z]                 _run_op(self.print, ""Print"", (""TensorStart"", x, ""TheEnd"")) [20250122T02:11:05.500Z]                 return x [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]         cap = Capture() [20250122T02:11:05.500Z]         with capture(cap): [20250122T02:11:05.500Z]             input_x = Tensor([1, 2, 3]) [20250122T02:11:05.500Z]             net = Net() [20250122T02:11:05.500Z]             out = net(input_x) [20250122T02:11:05.500Z]             np.testing.assert_array_equal(out.asnumpy(), np.array([1, 2, 3], dtype=np.int32)) [20250122T02:11:05.500Z]             sys.stdout.flush() [20250122T02:11:05.500Z]             time.sleep(0.1) [20250122T02:11:05.500Z]      [20250122T02:11:05.500Z]         patterns = ['TensorStart', [20250122T02:11:05.500Z]                     'Tensor(shape=[3], dtype=Int64, value=[1 2 3])', [20250122T02:11:05.500Z]                     'TheEnd'] [20250122T02:11:05.500Z] >       check_output(cap.output, patterns) [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] test_print_string.py:238:  [20250122T02:11:05.500Z] _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _  [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] output = '' [20250122T02:11:05.500Z] patterns = ['TensorStart', 'Tensor(shape=[3], dtype=Int64, value=[1 2 3])', 'TheEnd'] [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z]     def check_output(output, patterns): [20250122T02:11:05.500Z] >       assert output, ""Capture output failed!"" [20250122T02:11:05.500Z] E       AssertionError: Capture output failed! [20250122T02:11:05.500Z] E       assert '' [20250122T02:11:05.500Z]  [20250122T02:11:05.500Z] test_print_string.py:65: AssertionError [20250122T02:11:05.500Z] =============================== warnings summary =============================== [20250122T02:11:05.500Z] /home/****/.local/lib/python3.7/sitepackages/mindspore/ops/_op_impl/_custom_op/batchnorm_fold2.py:57 [20250122T02:11:05.500Z]   /home/****/.local/lib/python3.7/sitepackages/mindspore/ops/_op_impl/_custom ```  7.Special notes for this issue/备注 (Optional / 选填)",2025-01-24T11:53:55+08:00,"kind/developertest,rct/oldrelease,rca/others,ctl/personalbuild",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBJM2P, Appearance & Root Cause 问题：print用例小概率性是吧 根因：用例中需要捕获输出到stdout上的日志，由于sleep时间较短，导致有时捕获不到stdout输出  Fix Solution 修改用例，调大用例中的sleep时间  Fix Description & Test Suggestion 修改用例，调大用例中的sleep时间 测试建议：该用例为门禁用例，测试无需再看护  Selftest Report & DT Review 修改的用例为门禁用例，门禁pass后自动合入 是否需要补充 ST/UT：否； 原因：当前用例已经是st用例,回归通过
mindir,wangsir,mindocr进行图片检测和识别时报错,执行命令如下： python3 infer.py \     input_images_dir=/home/wyj/ocr/images \     det_model_path=/root/mindspore/weight/dbnet.mindir \     det_model_name_or_config=/root/mindspore/mindocr/configs/det/dbnet/db_r50_icdar15.yaml \     rec_model_path=/root/mindspore/weight/crnn.mindir \     rec_model_name_or_config=/root/mindspore/mindocr/configs/rec/crnn/crnn_resnet34.yaml \     res_save_dir=det_rec \     vis_pipeline_save_dir=det_rec 其中检测和识别模型分别是从官网下载的mindir模型，已经通过converter工具将其转为lite.mindir，执行报错提示如下： !输入图片说明 软硬件信息： mindocr 0.2.0 mindspore 2.4.1 mindspore_lite 2.4.1 CANN 8.0.RC3 NPU 310P3,2025-01-23T15:00:59+08:00,"foruda,mindspore-assistant",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBJHAE,这个错误应该和mslite或者说cann环境没有啥关系，是python代码层面的逻辑出错了，是在截图中最后那行代码中的dict中通过key取value时，key出错了，你可以通过在那里打印日志看看，是不是使用的key不在dict中,报错的那个python文件的名称叫rec_postprecess.py，推理应该是成功了，是后处理的时候python逻辑出错，一般名字带postprecess的python文件就是后处理的,"!输入图片说明 看了下代码，确实是indices数组的值6623在字典character里没有对应的key,但是怎么解决呢？这个问题","尊敬的开发者您好，我们尝试复现但是失败，主要没有你那张报错的图片。不过看了一下你用的mindocr版本是v0.2.0，版本太老了，0.3.0的时候离线推理就重构过了，也没有那行报错的代码。建议他用下高版本的ocr，配套的ms和ms_lite也是2.4.1的； !输入图片说明.png"") 而且返回值也没用到这个raw_chars，调试用，一直没删？"
ascend,hedongdong,【AR】算子Tensor接口重载Tensor.logsumexp," Tasks 转测对象：Tensor.logsumexp   Background  **1. 标杆情况**   标杆接口链接： torch.Tensor.logsumexp  标杆支持数据类型：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL。  **2. MindSpore算子情况**   当前支持数据类型   ```   Ascend：FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL   ```  三后端统一后算子支持（标杆支持+三后端并集） FLOAT、FLOAT16、BFLOAT16、INT32、INT64、INT16、INT8、UINT8、BOOL  Introduction  **1. 功能介绍**  !输入图片说明  **2. 接口描述（nn/functional接口需要与标杆保持一致）**  ``` logsumexp:      op_yaml: logsumexp_op.yaml       py_method: deprecated_tensor_logsumexp  callback to python function ""def deprecated_tensor_logsumexp""       Ascend: pyboost       CPU: py_method       GPU: py_method       interface: tensor      op_yaml: deprecated/logsumexp_method.yaml       py_method: deprecated_tensor_logsumexp  callback to python function ""def deprecated_tensor_logsumexp""       Ascend: py_method       CPU: py_method       GPU: py_method       interface: tensor ```  算子原语 ``` logsumexp:     args:         input:             dtype: tensor         dim:             dtype: tuple[int]             type_cast: int, list[int]         keepdim:             dtype: bool             default: False     returns:         output:             dtype: tensor     class:         name: LogSumExp ```  可参考以下例子填写 【众筹】存量算子 Flatten 功能补齐（如数据类型补齐）及性能优化 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69NU3 [鹏城][客户需求] NPU上需要支持AdaptiveAvgPool2D正反向算子 https://e.gitee.com/mind_spore/projects/69994/requirements/table?issue=I69VBB",2025-01-23T11:30:15+08:00,sig/ops,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBJFUV
mindformers,mengyuanli,magic number clean," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 告警清理。魔鬼数字消除。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-23T09:34:04+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBJEMN
mindir,wangsir,使用mindsporelite 将社区下载的MindIR模型文件转换为Lite MindIR模型文件报错,!输入图片说明 !输入图片说明 !输入图片说明 mindocr 0.2.0 mindspore 2.4.1 mindspore_lite 2.4.1 CANN 8.0.RC3 NPU 310P3,2025-01-22T17:00:53+08:00,mindspore-assistant,closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBJCBP,你这是转的哪个模型，我去试试看；有些模型确实是转不了的，有算子上的不支持，比如yolov5能转成功，v7我这边也转不了，有不支持的算子；也可以尝试下直接用mslite加载你下载的那个mindir，有些模型也是能直接加载的，转成Lite MindIR的话，就是做了些lite的调优，可能启动会快一些,不过你这边报了卷积算子的错误，卷积应该是没问题的，有可能是310P的环境搭建上的问题，导致卷积算子找不到；你的310P的kernels算子包有没有装，以及cann的环境变量是否都OK了,怎么验证你说的环境问题是否OK?,"可以跑个官方确认能跑的简单模型看看就行，或者我一般就安装个对应版本的mindspore试一下： import mindspore as ms ms.set_context(device_target='Ascend') t = ms.Tensor([1, 2, 3]).astype(ms.float16) t.mean() 跑个类似上面简单的代码试试，通常这个代码都是支持的，如果能跑，说明环境环境搭建没问题，ms.set_context(device_target='Ascend')这个执行成功，说明昇腾后端加载没问题，cann环境变量的配置都是OK的，不过有些环境下可能求平均这种简单的操作也走不通，那应该是该环境确实没适配好mindspore的在线推理，确保kernels安装包已经装了就行了",我重新安装了一下cann和kernel可以了，感谢
ascend,蛋蛋de忧桑,mint.arctan2、mint.asin、mint.asinh、mint.atan在图模式下报错,"  Describe the current behavior / 问题描述 (Mandatory / 必填) mint.arctan2、mint.asin、mint.asinh、mint.atan四个接口在mindspore.GRAPH_MODE静态图模式时运行出错。 RuntimeError: Compile graph kernel_graph0 failed. 但是同样的环境，mint.arctanh可以成功运行。  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Ascend: 1*ascendsnt9b1|ARM: 24核 192GB  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version : Mindspore 2.4.0  Python version : Python 3.9.10  OS platform and distribution : Linux version 4.19.90vhulk2211.3.0.h1543.eulerosv2r10.aarch64  **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > /mode graph  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) Bug复现代码： ```python import mindspore as ms from mindspore import mint, Tensor, value_and_grad import numpy as np ms.set_context(mode=ms.GRAPH_MODE) input_data = np.array([0, 1]) other_data = np.array([1, 1]) ms_input = Tensor(input_data, ms.float32) ms_other = Tensor(other_data, ms.float32) def forward_ms(x, y):     return mint.arctan2(x, y)  Gradients for MindSpore grad_fn = value_and_grad(forward_ms) output_ms, gradient_ms = grad_fn(ms_input, ms_other)  打印输出和梯度 print(""MindSpore output:"", output_ms) print(""MindSpore gradient:"", gradient_ms) ``` 其余接口复现代码类似，仅仅修改forward_ms中调用的函数。 mint.arctanh正常运行代码： ```python import mindspore as ms from mindspore import mint, Tensor, value_and_grad import numpy as np ms.set_context(mode=ms.GRAPH_MODE) input_data = np.array([0, 0.5]) ms_input = Tensor(input_data, ms.float32) def forward_ms(x):     return mint.arctanh(x)  Gradients for MindSpore grad_fn = value_and_grad(forward_ms) output_ms, gradient_ms = grad_fn(ms_input)  打印输出和梯度 print(""MindSpore output:"", output_ms) print(""MindSpore gradient:"", gradient_ms) ``` 环境相同，但是mint.arctanh可以正常运行。  Describe the expected behavior / 预期结果 (Mandatory / 必填) 代码可以正常运行  Related log / screenshot / 日志 / 截图 (Mandatory / 必填) !正常运行截图 !报错截图1 !报错截图2  Special notes for this issue/备注 (Optional / 选填) 环境信息 !环境信息",2025-01-22T16:31:46+08:00,"foruda,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBJBX8,试了下上面的arctan2的代码，其实是可以跑的，出错可能和环境设置有关，执行下unset RANK_TABLE_FILE后再试试看； !输入图片说明 上述代码中其实走的仍然是动态图的模式，设置了ms.set_context(mode=ms.GRAPH_MODE)后，是让nn.Cell对象或者其子类的construct方法中的代码走静态图，如果不在construct中，依旧是动态图模式，需要用mindspore.jit包起来的代码才是走静态图，比如在forward_ms加上mindspore.jit标注；上面的错误可能是在未执行unset RANK_TABLE_FILE把RANK_TABLE_FILE环境变量去掉的情况下，触发了动静结合模式下的啥bug,可以的，执行了unset RANK_TABLE_FILE之后再运行没有报错
mindformers,weiwei123,test custom param," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-22T15:28:45+08:00,gitee,open,0,1,https://gitee.com/mindspore/mindspore/issues/IBJB8M,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,b_rookie,ops.einsum为什么不支持CPU ASCEND,   Backgroud（背景信息） einsum是常见的算子，但是现在只支持GPU，请支持CPU ASCEND端  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-01-22T14:06:52+08:00,"gitee,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBJA92,请使用 mint.einsum 这个支持了Ascend， 但CPU仍不支持,> 请使用 mint.einsum 这个支持了Ascend， 但CPU仍不支持  mint也是比较新的版本才有，老版本没有，从算子完备性来说，ops应该支持
ascend,fengtingyan,双机推理MatmulAllReduceAddRmsNorm算子报错, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 双机推理MatmulAllReduceAddRmsNorm算子报错不支持rank size16 报错：[图片上传中…(imagesSNyaWxEo96M06ZV5VM5)]  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   3.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）配置mindie双机config.json，配置yaml > （2）cd mindieservice/bin/ > （3）验证服务化是否正常拉起,2025-01-20T20:57:46+08:00,,progressing,0,0,https://gitee.com/mindspore/mindspore/issues/IBIZJO
minddata,majun-bot,CVE20249880,"一、漏洞信息 漏洞编号：CVE20249880 漏洞归属组件：pandas, https://gitee.com/mindspore/mindspore 漏洞归属的版本：>= 1.0.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector： N/A 漏洞简述： credit：Aftersnows Vulnerability Research Institute Below is an Example of Command Execution Caused by the pandas.DataFrame.query Function, Which Developers Can Use for Debugging and Identifying Issues import pandas as pd df = pd.DataFrame({'a': [1, 2, 3], 'b': ['error_details', 'confidential_info', 'normal']}) query = '.core.frame.com.builtins.__import__(""os"").system(""""""ping google.com """""")' try:     engine = ""python""     result = df.query(query,local_dict={},engine=""python"",).index except Exception as e:     print(f'Error: {e}') Pandas DataFrame query Function Intended Usage and Potential for Command Execution The pandas.DataFrame.query function is intended to allow querying the columns of a DataFrame using a boolean expression. However, if an attacker constructs a malicious query, they can potentially bypass validation mechanisms and trigger a command execution vulnerability. .core.frame.com.builtins.__import__(""os"").system(""""""ping google.com """""" 漏洞公开时间：N/A 漏洞创建时间：20250120 15:45:07 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20249880 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 5.3 &emsp;Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-20T15:45:07+08:00,"gitee,CVE/UNAFFECTED,rct/oldrelease,rca/others,ctl/componenttest",closed,0,10,https://gitee.com/mindspore/mindspore/issues/IBIW96,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：N/A None  Vector：N/A 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：N/A None  Vector：N/A 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,BaseScore => 没有正确填写,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否,影响性分析说明： 该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 漏洞评分(MindSpore评分):  BaseScore： 5.3 Medium  Vector： CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Appearance & Root Cause 问题：pandas漏洞 根因： pandas漏洞 Fix Solution 不涉及，该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 Fix Description & Test Suggestion 不涉及，该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。 Selftest Report & DT Review 不涉及 Introduction Analysis 引入类型：三方件pandas引入 引入PR：未知 PR合入时间：未知,该漏洞未收录在nvd上，并且Minddata中使用的是python的pandas，故不受影响。
ascend,吴逸群,在docker中使用mindyolo训练失败, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 我想要在docker中使用mindyolo，但是使用中出现了很奇怪的问题，具体描述如下： 我有2个华为服务器，一个是atlas 800T，另一个是atlas 800I 服务器，我在这两个服务器都安装了asecnd_docker，之后，我下载了官方的ascend_mindspore镜像，并使用如下指令run了一个容器： docker run it name lkx_mindspore2 ipc=host network host device=/dev/davinci0 device=/dev/davinci1 device=/dev/davinci2 device=/dev/davinci3 device=/dev/davinci_manager device=/dev/devmm_svm device=/dev/hisi_hdc v /usr/local/dcmi:/usr/local/dcmi v /usr/local/bin/npusmi:/usr/local/bin/npusmi v /usr/local/Ascend/driver/lib64/common:/usr/local/Ascend/driver/lib64/common v /usr/local/Ascend/driver/lib64/driver:/usr/local/Ascend/driver/lib64/driver v /etc/ascend_install.info:/etc/ascend_install.info v /etc/vnpu.cfg:/etc/vnpu.cfg v /usr/local/Ascend/driver/version.info:/usr/local/Ascend/driver/version.info v /home/lkx:/home/lkx entrypoint=/bin/bash 930poc:py310_cannRC3_mindieT65_torch_npu_dev20240929 我使用的是mindyolo0.4官方仓库的代码 （https://github.com/mindsporelab/mindyolo），yaml等配置都没错，然后我在容器中开始训练就会出现下图的结果，就是训练过程不报错，但是模型无法训练（我用npusmi info查看了，AI core占用率一直为0%），同样的环境和代码拿到宿主机环境里面训练就不会出现任何问题。我在atlas 800T和800I上试了至少10几个官方的ascend_mindspore镜像，换了很多mindspore和mindyolo版本，都是这样的现象。我在容器中直接用mindspore训练yolo又不会出问题。  2.Environment / 环境信息 (Mandatory / 必填) atlas 800T 训练服务器 atlas 800I 推理服务器 !输入图片说明,2025-01-20T10:40:56+08:00,"foruda,www,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBIT8D,MindSpore 安装的run check能跑通，可以显示mindspore版本号和successful（在宿主机和容器里面都可以跑通）。 cann版本号如下： !输入图片说明 我上面这个图片用的是atlas 800I，但是我在atlas 800T上面也试了（cann版本一致），也一样只能在宿主机上运行，不能在docker容器里面使用。,解答：启动命令有变化，详细参照指南：https://www.hiascend.com/developer/ascendhub/detail/9de02a1a179b4018a4bf8e50c6c2339e
ascend,ErjieWu,NVIDIA卡安装mindsporedev GPU版失败, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) NVIDIA的GPU安装Mindsporedev后测试安装结果报错，CPU版本可正常运行，GPU版本报错如下（包含一些配置信息）： !输入图片说明 安装流程根据官网的安装教程，对应masterGPU CUDA 11.6Linuxx86_64Python3.9pip。已经检查过cuda、cudnn动态链接库的位置无误并加入环境变量（包括cuda的stubs），libmindspore_gpu.so.11.6也存在在对应位置。libge_runner.so不清楚位置以及是否NVIDIA卡是否需要。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`) ,2025-01-20T09:42:05+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBIS7K,执行以下export CUDA_HOME=/cuda这个环境变量再运行试试看，2.3以上的GPU版本可能都需要这个操作，CUDA_HOME的路径随便写一个就行，就能绕过一些检测运行起来,解决了，谢谢！
ascend,cccc1111,Sub_补充反向实现与__isub__ / =重载, Tasks 转测对象：tensor.sub_/__isub__/= 对标torch.tensor.sub_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/complex64/complex128/bool  **2. MindSpore算子情况**   当前支持数据类型 sub_ PyNative正反向支持的类型与PTA保持一致 __isub__与=支持类型保持不变  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  与other相减，alpha表示对于other的缩放系数  **2. 接口描述**   接口重载： sub_: !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语 （1）对于tensor.sub_，原始支持Ascend后端正向PyNative模式。目前Ascend后端，正反向PyNative都支持，KBK/GE在input/other情况下，走deprecated，input/other/alpha情况下，会报错。在CPU后端，PyNative模式，走py_bind，KBK/GE在input/other情况下，走deprecated，input/other/alpha情况下，走py_bind。GPU与CPU情况一致。 （2）对于__isub__，原始支持input/other三后端三模式。目前Ascend后端，支持input/other的PyNative模式正反向，KBK/GE走deprecated（与原始流程一致）。CPU后端，PyNative模式支持，走py_bind（与原始流程一致），KBK/GE走deprecated（与原始流程一致）。GPU后端，与CPU后端情况一致。 （3）对于=，原始支持Ascend/CPU/GPU，PyNative/KBK/GE。目前，Ascend后端，正反向PyNative支持，KBK与GE支持，静态图走下图逻辑。CPU后端，正反向PyNative走py_bind（与原始流程一致），KBK与GE支持，静态图走下图逻辑。GPU后端，与CPU后端情况一致。 !输入图片说明,2025-01-19T22:28:35+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBIR3J
mindformers,wqx,goldenstick的样例代码结果为nan,https://www.mindspore.cn/golden_stick/docs/zhCN/r0.5.0/ptq/round_to_nearest.html 请问下这个示例代码中使用mindspore的哪个版本运行的？目前我测试下来，在2.3.1和2.3.0昇腾环境下，mindformers和gs的版本都是文档里写的1.2.0和0.5.0，然后fp16和量化模型的示例代码的运行评估结果loss和评估指标都是nan: !输入图片说明,2025-01-18T16:10:21+08:00,"gitee,foruda,mindspore-assistant",closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBINGH,量化后运行的结果如图： !输入图片说明,round_to_nearest已经废弃，请使用ptq算法代替：https://gitee.com/mindspore/goldenstick/blob/master/mindspore_gs/ptq/ptq/README_CN.md
minddata,majun-bot,CVE20250518,"一、漏洞信息 漏洞编号：CVE20250518 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector：  漏洞简述： Unchecked Return Value, Outofbounds Read vulnerability in FFmpeg allows Read Sensitive Constants Within an Executable. This vulnerability is associated with program files  https://github.Com/FFmpeg/FFmpeg/blob/master/libavfilter/af_pan.C . This issue affects FFmpeg: 7.1. Issue was fixed:  https://github.com/FFmpeg/FFmpeg/commit/b5b6391d64807578ab872dc58fb8aa621dcfc38a  https://github.com/FFmpeg/FFmpeg/commit/b5b6391d64807578ab872dc58fb8aa621dcfc38a This issue was discovered by: Simcha Kosman 漏洞公开时间：00010101 08:05:43 漏洞创建时间：20250117 04:01:35 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE20250518 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： 该漏洞是FFmpeg中未经检查的返回值、越界读取漏洞允许读取可执行文件中的敏感常量，属于libavfilter中的漏洞，Minddata中未使用到libavfilter，故不受影响。 漏洞评分(MindSpore评分): &emsp;BaseScore： 4.8 &emsp;Vector： CVSS:4.0/AV:N/AC:L/AT:N/PR:L/UI:A/VC:L/VI:N/VA:N/SC:L/SI:N/SA:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-17T04:01:36+08:00,"gitee,CVE/UNAFFECTED,rct/oldrelease,rca/others,ctl/componenttest",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBID73,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： 该漏洞是FFmpeg 中未经检查的返回值、越界读取漏洞允许读取可执行文件中的敏感常量，属于libavfilter中的漏洞，Minddata中未使用到libavfilter，故不受影响。 漏洞评分(MindSpore评分):  BaseScore：4.8 MEDIUM  Vector：CVSS:4.0/AV:N/AC:L/AT:N/PR:L/UI:A/VC:L/VI:N/VA:N/SC:L/SI:N/SA:N 受影响版本排查(受影响/不受影响)： 1.master:不受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",Minddata中未使用到libavfilter，故不受影响。
mindformers,wtcheng,新增并行解码st用例," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-16T17:06:29+08:00,gitee,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBIAPL,请参考以下典型优秀案例进行问题单根因分析，如未按此模板进行根因分析，转回归会被打回，更多问题单规范请参看https://e.gitee.com/mind_spore/docs/2489468/file/5767947?sub_id=11382313&scope=undefined > Appearance & Root Cause > 问题：pangu_sigma2.3编译耗时优化未达预期 > 根因： > 1、 2.3上某些pass相比于2.2版本的实现，存在性能劣化 > 2、 2.3版本把trace功能下掉了，导致前端编译劣化 >  > Fix Solution > 1、修复性能劣化的前端图优化pass > 2、通过支持boost infer功能把trace功能下掉导致的性能劣化拿回来 >  > Fix Description & Test Suggestion > https://gitee.com/mindspore/mindspore/pulls/70920 PR合入后daily包回归 > 测试建议：该问题可以通过特性用例防护，增加****场景。 >  > Selftest Report & DT Review > 目前前后端耗时在12分钟以内。 > 是否需要补充 ST/UT：否 如果选择否，请补充理由 > 原因：非基本功能问题 >  > Introduction Analysis > 引入类型：特性合入引入 > 引入PR：https://e.gitee.com/mind_spore/repos/mindspore/mindspore/pulls/xxx > PR合入时间：年/月/日 > 问题是否偶现：是/否
ascend,tridu33,现有并行代码计算cpu数量的时候考虑的代码逻辑考虑不够周密，推荐修改一下异常边界情况,"这里是因为Ascend910卡版本问题，需要`.bashrc`中提前设置环境变量`LD_PRELOAD=$LD_PRELOAD:/home/tridu33/.conda/envs/openmindpt/lib/python3.9/sitepackages/scikit_learn.libs/libgompd22c30c5.so.1.0.0:/home/tridu33/.conda/envs/openmindpt/lib/python3.9/sitepackages/torch.libs/libgomp6e1a1d1b.so.1.0.0`才能启动mindspore相关cpp依赖库。 但是 https://gitee.com/mindspore/mindspore/blob/master/mindspore/python/mindspore/parallel/cluster/process_entity/_api.pyL273  这行代码直接判断 ```python             cpu_num = subprocess.getoutput(""cat /proc/cpuinfowc l""线程返回结果是字符串  ```bash ""ERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\nERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\nERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\nERROR: ld.so: object '$LD_PRELOAD' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n192"" ``` 所以推荐补充这个异常情况的边界问题，进行相应的修改",2025-01-16T10:44:47+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBI4NV,解决方案就是上述描述中的改法
minddata,hmy2022,【加急】【问题汇总】使用mindspore中MindSpore Golden Stick进行量化，分别使用 2种配置文件有2种不同的错误。,"部署平台：Modelarts 区域：西南贵阳一 公共镜像：mindspore_2.3.0cann_8.0.rc2py_3.9euler_2.10.7aarch64snt9b 实例规格：Ascend: 1*ascendsnt9b1|ARM: 24核 192GB 创建实例后，从将官网下载的已经编译好的包导入。 !输入图片说明 分别安装mindspore 2.3.1/mindformer1.2.0/MindSpore Golden Stick 0.5.0 匹配官网文档中的环境配置。官网文档为https://www.mindspore.cn/golden_stick/docs/zhCN/r0.5.0/ptq/round_to_nearest.html !输入图片说明 然后按照教程准备workspace,ckpt文件是从教程中的链接下载。 配置config文件，在gitee源码中分别找到2种配置文件模板分别进行测试。 路径如下： !输入图片说明 !输入图片说明 图一运行后会报无法找到量化层的错误（已经进行推理测试，推理脚本可以正常运行） 图二运行后会运行无输出，等待45分钟无果。 图一配置文件为： ``` config  seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: './workspace/llama2_7b.ckpt' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'predict'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 1   sink_mode: True   sink_size: 2   gradient_accumulation_steps: 8  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr sechdule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: False   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 1   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: False   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMonitor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   max_call_depth: 10000   max_device_memory: ""28GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 4096     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""float16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float32""     rotary_dtype: ""float16""     param_init_type: ""float16""     use_past: True     scaling_factor: 1.0  The scale factor of seq length     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     use_flash_attention: True  FA can accelerate training or finetune     block_size: 16     num_blocks: 1024     is_dynamic: True     qkv_concat: False     offset: 0     checkpoint_name_or_path: """"     repetition_penalty: 1     max_decode_length: 512     top_k: 3     top_p: 1     do_sample: False   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer     vocab_file: './workspace/tokenizer.model'   type: LlamaProcessor  metric metric:   type: EmF1Metric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform."" ``` 报错为： ```  Quantizeing network... 20250115 21:08:01,128  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 4096, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250115 21:08:01,130  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250115 21:08:01,131  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250115 21:08:01,132  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. 20250115 21:08:01,134  mindformers[mindformers/models/llama/llama.py:386]  INFO  Set dynamic input for llama. [ERROR] KERNEL(48504,fffc237fe1e0,python):2025011521:08:35.340.595 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:70] Build] Internal Op 'Gather' is initialized FAILED. [ERROR] KERNEL(48504,fffc237fe1e0,python):2025011521:08:35.340.646 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:165] Resize] op Gather build kernel failed [ERROR] KERNEL(48504,fffc22ffd1e0,python):2025011521:08:43.931.679 [mindspore/ccsrc/kernel/kernel.cc:538] SyncDataFromDeviceToHost] Not malloc device memory yet, sync data from device to host side failed, size: 16 [ERROR] RUNTIME_FRAMEWORK(48504,fffc227fc1e0,python):2025011521:08:43.936.487 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(48504,fffc227fc1e0,python):2025011521:08:43.936.741 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(48504,fffc21ffb1e0,python):2025011521:08:43.936.760 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(48504,fffc21ffb1e0,python):2025011521:08:43.936.896 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod  RuntimeError                              Traceback (most recent call last) Cell In[1], line 68      66 print(' Quantizeing network...', flush=True)      67 start = time.time() > 68 network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config)      69 logger.info(f'Quant Network cost time is {time.time()  start} s.')      70 print(' Saving checkpoint...', flush=True) Cell In[1], line 45, in quant_network(net, mode, backend, **kwargs)      43     raise ValueError(""Please provide mfconfig for calibrating."")      44 network_helper = MFLlama2Helper(mfconfig) > 45 net = ptq.apply(net, network_helper)      46 logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')      47 start_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/round_to_nearest/round_to_nearest.py:194, in RoundToNearest.apply(self, network, network_helper)     192     if network_helper:     193         bs = network_helper.get_spec(""batch_size"") if network_helper.get_spec(""batch_size"") else 1 > 194         network_helper.generate(network, input_ids=np.ones([bs, 1], dtype=np.int32))     195 else:     196     warn_str = ""No layer found in network is suitable for quantization, please check network and "" \     197                ""opname_blacklist."" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/network_helpers/mf_net_helpers.py:60, in MFNetworkHelper.generate(self, mf_network, input_ids, max_new_tokens, **kwargs)      58 top_p = self.mf_config.model.model_config.top_p      59 top_k = self.mf_config.model.model_config.top_k > 60 return mf_network.generate(input_ids, do_sample=do_sample, max_length=seq, max_new_tokens=max_new_tokens,      61                            top_p=top_p, top_k=top_k) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:848, in GenerationMixin.generate(self, input_ids, generation_config, logits_processor, streamer, seed, **kwargs)     844     else:     845         block_tables, slot_mapping = self.block_mgr.assemble_pa_inc_inputs(valid_length_each_example,     846                                                                            is_finished) > 848 infer_output, is_finished = self.infer(input_ids=input_ids,     849                                        valid_length_each_example=valid_length_each_example,     850                                        generation_config=generation_config,     851                                        logits_processor=logits_processor,     852                                        logits_warper=logits_warper,     853                                        block_tables=block_tables,     854                                        slot_mapping=slot_mapping,     855                                        prefill=prefill,     856                                        is_finished=is_finished,     857                                        encoder_mask=encoder_mask,     858                                        encoder_output=encoder_output,     859                                        target_mask=target_mask,     860                                        **model_kwargs)     861 if generation_config.return_dict_in_generate:     862     target_list = infer_output[""target_list""] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:986, in GenerationMixin.infer(self, input_ids, valid_length_each_example, generation_config, logits_processor, logits_warper, block_tables, slot_mapping, prefill, is_finished, encoder_mask, encoder_output, target_mask, **model_kwargs)     983 start_time = time.time()     985 input_ids = np.array(input_ids) > 986 res, current_index = self.forward(input_ids=input_ids,     987                                   valid_length_each_example=valid_length_each_example,     988                                   block_tables=block_tables,     989                                   slot_mapping=slot_mapping,     990                                   prefill=prefill,     991                                   use_past=generation_config.use_past,     992                                   encoder_mask=encoder_mask,     993                                   encoder_output=encoder_output,     994                                   target_mask=target_mask,     995                                   **model_kwargs)     997 forward_time = time.time()  start_time     998 sample_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:1100, in GenerationMixin.forward(self, input_ids, valid_length_each_example, block_tables, slot_mapping, prefill, use_past, encoder_mask, encoder_output, target_mask, **model_kwargs)    1097 model_kwargs[""current_index""] = current_index    1099 if use_past: > 1100     res = self._incremental_infer(    1101         model_inputs=model_inputs,    1102         prefill=prefill,    1103         current_index=current_index,    1104         valid_length_each_example=valid_length_each_example,    1105         block_tables=block_tables,    1106         slot_mapping=slot_mapping    1107     )    1108 else:    1109     res = self(**model_inputs)   pylint: disable=E1102 File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:313, in GenerationMixin._incremental_infer(self, model_inputs, prefill, current_index, valid_length_each_example, block_tables, slot_mapping)     311     model_inputs[""slot_mapping""] = Tensor.from_numpy(slot_mapping)     312  pylint: disable=E1102 > 313 res = self(     314     **model_inputs,     315 )     316 ms.hal.synchronize()     317 self.phase = ""increment"" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:703, in Cell.__call__(self, *args, **kwargs)     700         logger.warning(f""For 'Cell', it's not support hook function in graph mode. If you want to use hook ""     701                        f""function, please use context.set_context to set pynative mode."")     702     self._self_check() > 703     out = self.compile_and_run(*args, **kwargs)     704     return out     706  Run in PyNative mode. File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:1074, in Cell.compile_and_run(self, *args, **kwargs)    1072 self.add_flags(ge_sync_data=False)    1073 new_args = _get_args_for_run(self, args, kwargs, self._compile_args) > 1074 return _cell_graph_executor(self, *new_args, phase=self.phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1860, in _CellGraphExecutor.__call__(self, obj, phase, *args)    1858 if context.get_context(""precompile_only"") or _is_role_sched():    1859     return None > 1860 return self.run(obj, *args, phase=phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1911, in _CellGraphExecutor.run(self, obj, phase, *args)    1909 phase_real = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key    1910 if self.has_compiled(phase_real): > 1911     return self._exec_pip(obj, *args, phase=phase_real)    1912 raise KeyError('{} graph is not exist.'.format(phase_real)) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:185, in _wrap_func..wrapper(*arg, **kwargs)     183 (fn)     184 def wrapper(*arg, **kwargs): > 185     results = fn(*arg, **kwargs)     186     return _convert_python_data(results) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1891, in _CellGraphExecutor._exec_pip(self, obj, phase, *args)    1889 fn = obj.construct    1890 obj.__parse_method__ = fn.__name__ > 1891 return self._graph_executor(args, phase) RuntimeError: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod ``` 图二配置文件为： ``` seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: './workspace/llama2_7b.ckpt' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'train'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 6   sink_mode: True   sink_size: 2  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr sechdule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: True   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 4   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: True   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMointor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   graph_kernel_flags: ""disable_expand_ops=Softmax,Dropout enable_parallel_fusion=true reduce_fuse_depth=8 enable_auto_tensor_inplace=true""   max_call_depth: 10000   max_device_memory: ""28GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 1024     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""bfloat16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float16""     rotary_dtype: ""float32""     param_init_type: ""float16""     use_past: True     pretrain_seqlen: 4096  seqlen of the pretrain checkpoint: 2048 for llama and 4096 for llama2     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     compute_in_2d: True     use_flash_attention: False  FA can accelerate training or finetune     offset: 0     use_past_shard: False     checkpoint_name_or_path: """"     repetition_penalty: 1     max_decode_length: 700     top_k: 3     top_p: 1     do_sample: False     max_new_tokens: 20   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer     vocab_file: './workspace/tokenizer.model'   type: LlamaProcessor  metric metric:   type: PerplexityMetric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform."" ``` 报错为，运行到此即卡住，等待45分钟无果： ``` /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:499: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal)  Creating network... 20250115 20:20:41,243  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. [WARNING] DEVICE(3433,ffff83f0c0b0,python):2025011520:20:44.575.380 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:96] Initialize] Reserved memory size for other components(1610612736) is less than recommend size(1958250496), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory' [WARNING] CORE(3433,ffff83f0c0b0,python):2025011520:20:44.575.480 [mindspore/core/utils/ms_context.cc:531] GetJitLevel] Set jit level to O2 for rank table startup method. 20250115 20:20:48,554  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250115 20:20:48,558  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN [WARNING] ME(3433:281472895336624,MainProcess):2025011520:20:48.569.873 [mindspore/ops/primitive.py:204] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored.  If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL) 20250115 20:20:55,088  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False [WARNING] ME(3433:281472895336624,MainProcess):2025011520:20:55.917.33 [mindspore/common/parameter.py:805] This interface may be deleted in the future. 20250115 20:20:59,695  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:04,247  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:08,791  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:13,370  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:17,969  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:22,585  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:27,078  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:31,681  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:21:36,254  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250115 20:23:19,060  mindformers[mindformers/models/modeling_utils.py:1531]  INFO  model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None. 20250115 20:23:19,062  mindformers[mindformers/models/modeling_utils.py:599]  INFO  Set jit config for jit level:O0 and infer boost:on. 20250115 20:23:19,064  mindformers[mindformers/models/llama/llama.py:350]  INFO  Predict run mode:False [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.643.779 [mindspore/train/serialization.py:214] The type of model.layers.0.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.646.001 [mindspore/train/serialization.py:214] The type of model.layers.0.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.652.441 [mindspore/train/serialization.py:214] The type of model.layers.1.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.654.311 [mindspore/train/serialization.py:214] The type of model.layers.1.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.660.409 [mindspore/train/serialization.py:214] The type of model.layers.2.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.661.957 [mindspore/train/serialization.py:214] The type of model.layers.2.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.668.053 [mindspore/train/serialization.py:214] The type of model.layers.3.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.669.683 [mindspore/train/serialization.py:214] The type of model.layers.3.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.676.145 [mindspore/train/serialization.py:214] The type of model.layers.4.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.677.484 [mindspore/train/serialization.py:214] The type of model.layers.4.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.683.567 [mindspore/train/serialization.py:214] The type of model.layers.5.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.685.208 [mindspore/train/serialization.py:214] The type of model.layers.5.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.691.514 [mindspore/train/serialization.py:214] The type of model.layers.6.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.692.708 [mindspore/train/serialization.py:214] The type of model.layers.6.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.698.961 [mindspore/train/serialization.py:214] The type of model.layers.7.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.700.901 [mindspore/train/serialization.py:214] The type of model.layers.7.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.707.462 [mindspore/train/serialization.py:214] The type of model.layers.8.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.708.905 [mindspore/train/serialization.py:214] The type of model.layers.8.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.715.230 [mindspore/train/serialization.py:214] The type of model.layers.9.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.716.455 [mindspore/train/serialization.py:214] The type of model.layers.9.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.722.973 [mindspore/train/serialization.py:214] The type of model.layers.10.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.724.214 [mindspore/train/serialization.py:214] The type of model.layers.10.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.730.835 [mindspore/train/serialization.py:214] The type of model.layers.11.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.732.327 [mindspore/train/serialization.py:214] The type of model.layers.11.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.739.029 [mindspore/train/serialization.py:214] The type of model.layers.12.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. ... [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.889.925 [mindspore/train/serialization.py:214] The type of model.layers.31.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.896.275 [mindspore/train/serialization.py:214] The type of model.norm_out.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.903.864 [mindspore/train/serialization.py:1560] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint. [WARNING] ME(3433:281472895336624,MainProcess):2025011520:24:12.905.452 [mindspore/train/serialization.py:1564] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded. Output is truncated. View as a scrollable element or open in a text editor. Adjust cell output settings...  Quantizeing network... 20250115 20:24:14,303  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 1024, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250115 20:24:14,306  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250115 20:24:14,307  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250115 20:24:14,309  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. ```",2025-01-16T09:47:47+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBI3TU,mindsporeassistant,错误已经定位，同样的代码使用终端脚本即可运行，使用notebook运行会报以上错误。
ascend,cccc1111,Div_补充反向实现与/=重载, Tasks 转测对象：tensor.div_ 与 /= 对标torch.tensor.div_   Background  **1. 标杆情况**   标杆接口链接： !输入图片说明  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/complex64/complex128/bool  **2. MindSpore算子情况**   当前支持数据类型 tensor.div_ Ascend后端支持数据类型与torch_npu保持一致，CPU/GPU后端支持数据类型为div_op支持类型 /= Ascend后端PyNative支持数据类型与torch_npu保持一致，KBK/GE与之前保持一致。CPU/GPU的PyNative支持数据类型为div_op支持类型，KBK/GE与之前保持一致  三后端统一后算子支持（标杆支持+三后端并集） 如上  Introduction  **1. 功能介绍**  与other相除，rounding_mode表示对于结果的取整操作  **2. 接口描述**   ops接口   mint/tensor接口： Div_: !输入图片说明 !输入图片说明 !输入图片说明  算子原语   自动生成对应原语 （1）对于tensor.div_，原始支持Ascend后端正向PyNative模式。目前Ascend后端，正反向PyNative支持，KBK与GE不支持。CPU/GPU后端走div_op。 （2）对于/=，原始支持Ascend/CPU/GPU，PyNative/KBK/GE。目前，Ascend后端，正反向PyNative支持（支持的类型变少），KBK与GE支持（不走当前div_.yaml）。CPU后端，正反向PyNative支持（支持的类型一致），KBK与GE支持。GPU后端，正反向PyNative支持（支持类型一致），KBK与GE支持。,2025-01-15T16:05:22+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBHZNE
minddata,hmy2022,[mindforemer1.2.0][mindspore2.3.1[MindSpore Golden Stick 0.5.0]使用RoundToNearest量化Llama2网络出现找不到要量化的层的报错。急急急！求大佬看看！！救救孩子,"服务器使用Modelart服务器 使用官方镜像：mindspore_2.3.0cann_8.0.rc2py_3.9euler_2.10.7aarch64snt9b 进入镜像后手动升级mindspore_2.3.1 实例规格为：Ascend: 1*ascendsnt9b1|ARM: 24核 192GB 整体报错如下： `WARNING] ME(1603:281473745211568,MainProcess):2025011422:54:49.250.432 [mindspore/context.py:1208] For 'context.set_context' in Ascend backend, the backend is already initialized, please set it before the definition of any Tensor and Parameter, and the instantiation and execution of any operation and net, otherwise the settings may not take effect.  20250114 22:54:49,253  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. 20250114 22:54:49,260  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250114 22:54:49,261  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN 20250114 22:54:53,939  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:54:56,641  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:54:59,341  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:02,046  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:04,742  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:07,457  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:10,145  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:12,859  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:15,543  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:55:18,253  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250114 22:56:19,256  mindformers[mindformers/models/modeling_utils.py:1531]  INFO  model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None. 20250114 22:56:19,259  mindformers[mindformers/models/modeling_utils.py:599]  INFO  Set jit config for jit level:O0 and infer boost:on. 20250114 22:56:19,260  mindformers[mindformers/models/llama/llama.py:350]  INFO  Predict run mode:False [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.627.357 [mindspore/train/serialization.py:214] The type of model.layers.0.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.629.663 [mindspore/train/serialization.py:214] The type of model.layers.0.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.636.347 [mindspore/train/serialization.py:214] The type of model.layers.1.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.637.642 [mindspore/train/serialization.py:214] The type of model.layers.1.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.643.761 [mindspore/train/serialization.py:214] The type of model.layers.2.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.645.132 [mindspore/train/serialization.py:214] The type of model.layers.2.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.651.315 [mindspore/train/serialization.py:214] The type of model.layers.3.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.652.885 [mindspore/train/serialization.py:214] The type of model.layers.3.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.658.972 [mindspore/train/serialization.py:214] The type of model.layers.4.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.660.397 [mindspore/train/serialization.py:214] The type of model.layers.4.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.667.128 [mindspore/train/serialization.py:214] The type of model.layers.5.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.668.244 [mindspore/train/serialization.py:214] The type of model.layers.5.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.674.960 [mindspore/train/serialization.py:214] The type of model.layers.6.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.676.102 [mindspore/train/serialization.py:214] The type of model.layers.6.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.682.704 [mindspore/train/serialization.py:214] The type of model.layers.7.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.683.979 [mindspore/train/serialization.py:214] The type of model.layers.7.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.690.539 [mindspore/train/serialization.py:214] The type of model.layers.8.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.691.673 [mindspore/train/serialization.py:214] The type of model.layers.8.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.698.256 [mindspore/train/serialization.py:214] The type of model.layers.9.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.699.377 [mindspore/train/serialization.py:214] The type of model.layers.9.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.705.350 [mindspore/train/serialization.py:214] The type of model.layers.10.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.706.861 [mindspore/train/serialization.py:214] The type of model.layers.10.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.712.884 [mindspore/train/serialization.py:214] The type of model.layers.11.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.714.298 [mindspore/train/serialization.py:214] The type of model.layers.11.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.721.315 [mindspore/train/serialization.py:214] The type of model.layers.12.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.722.441 [mindspore/train/serialization.py:214] The type of model.layers.12.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.728.591 [mindspore/train/serialization.py:214] The type of model.layers.13.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.729.868 [mindspore/train/serialization.py:214] The type of model.layers.13.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.737.254 [mindspore/train/serialization.py:214] The type of model.layers.14.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.738.395 [mindspore/train/serialization.py:214] The type of model.layers.14.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.744.603 [mindspore/train/serialization.py:214] The type of model.layers.15.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.746.005 [mindspore/train/serialization.py:214] The type of model.layers.15.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.752.645 [mindspore/train/serialization.py:214] The type of model.layers.16.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.753.873 [mindspore/train/serialization.py:214] The type of model.layers.16.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.760.451 [mindspore/train/serialization.py:214] The type of model.layers.17.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.761.635 [mindspore/train/serialization.py:214] The type of model.layers.17.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.768.596 [mindspore/train/serialization.py:214] The type of model.layers.18.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.769.707 [mindspore/train/serialization.py:214] The type of model.layers.18.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.775.768 [mindspore/train/serialization.py:214] The type of model.layers.19.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.777.286 [mindspore/train/serialization.py:214] The type of model.layers.19.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.783.091 [mindspore/train/serialization.py:214] The type of model.layers.20.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.784.769 [mindspore/train/serialization.py:214] The type of model.layers.20.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.790.762 [mindspore/train/serialization.py:214] The type of model.layers.21.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.792.270 [mindspore/train/serialization.py:214] The type of model.layers.21.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.798.116 [mindspore/train/serialization.py:214] The type of model.layers.22.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.799.636 [mindspore/train/serialization.py:214] The type of model.layers.22.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.805.575 [mindspore/train/serialization.py:214] The type of model.layers.23.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.807.081 [mindspore/train/serialization.py:214] The type of model.layers.23.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.814.069 [mindspore/train/serialization.py:214] The type of model.layers.24.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.815.241 [mindspore/train/serialization.py:214] The type of model.layers.24.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.820.905 [mindspore/train/serialization.py:214] The type of model.layers.25.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.822.717 [mindspore/train/serialization.py:214] The type of model.layers.25.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.828.665 [mindspore/train/serialization.py:214] The type of model.layers.26.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.830.339 [mindspore/train/serialization.py:214] The type of model.layers.26.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.836.761 [mindspore/train/serialization.py:214] The type of model.layers.27.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.838.244 [mindspore/train/serialization.py:214] The type of model.layers.27.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.843.825 [mindspore/train/serialization.py:214] The type of model.layers.28.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.845.606 [mindspore/train/serialization.py:214] The type of model.layers.28.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.851.154 [mindspore/train/serialization.py:214] The type of model.layers.29.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.852.395 [mindspore/train/serialization.py:214] The type of model.layers.29.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.858.770 [mindspore/train/serialization.py:214] The type of model.layers.30.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.859.966 [mindspore/train/serialization.py:214] The type of model.layers.30.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.866.195 [mindspore/train/serialization.py:214] The type of model.layers.31.ffn_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.867.576 [mindspore/train/serialization.py:214] The type of model.layers.31.attention_norm.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.873.532 [mindspore/train/serialization.py:214] The type of model.norm_out.weight:Float16 in 'parameter_dict' is different from the type of it in 'net':Float32, then the type convert from Float16 to Float32 in the network. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.880.971 [mindspore/train/serialization.py:1560] For 'load_param_into_net', 64 parameters in the 'net' are not loaded, because they are not in the 'parameter_dict', please check whether the network structure is consistent when training and loading checkpoint. [WARNING] ME(1603:281473745211568,MainProcess):2025011422:57:14.881.720 [mindspore/train/serialization.py:1564] ['model.layers.0.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.0.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.1.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.2.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.3.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.4.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.5.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.6.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.7.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.8.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.9.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.10.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.11.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.12.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.13.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.14.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.15.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.16.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.17.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.18.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.19.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.20.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.21.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.22.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.23.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.24.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.25.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.26.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.27.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.28.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.29.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.30.attention.infer_attention.paged_attention_mgr.value_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.key_cache', 'model.layers.31.attention.infer_attention.paged_attention_mgr.value_cache'] are not loaded.  Quantizeing network... 20250114 22:57:16,308  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 4096, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250114 22:57:16,311  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250114 22:57:16,313  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250114 22:57:16,314  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. 20250114 22:57:16,316  mindformers[mindformers/models/llama/llama.py:386]  INFO  Set dynamic input for llama. [ERROR] KERNEL(1603,fffc1e7f61e0,python):2025011422:57:48.163.234 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:70] Build] Internal Op 'Gather' is initialized FAILED. [ERROR] KERNEL(1603,fffc1e7f61e0,python):2025011422:57:48.163.281 [mindspore/ccsrc/plugin/device/ascend/kernel/internal/internal_kernel_mod.cc:165] Resize] op Gather build kernel failed [ERROR] KERNEL(1603,fffc1dff51e0,python):2025011422:57:56.093.849 [mindspore/ccsrc/kernel/kernel.cc:538] SyncDataFromDeviceToHost] Not malloc device memory yet, sync data from device to host side failed, size: 16 [ERROR] RUNTIME_FRAMEWORK(1603,fff6e0c571e0,python):2025011422:57:56.098.461 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(1603,fff6e0c571e0,python):2025011422:57:56.098.691 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(1603,fff6e0c571e0,python):2025011422:57:56.098.782 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod [ERROR] RUNTIME_FRAMEWORK(1603,fff6d3fff1e0,python):2025011422:57:56.098.867 [mindspore/ccsrc/runtime/graph_scheduler/actor/actor_common.cc:327] WaitRuntimePipelineFinish] Wait runtime pipeline finish and an error occurred: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod  RuntimeError                              Traceback (most recent call last) Cell In[3], line 68      66 print(' Quantizeing network...', flush=True)      67 start = time.time() > 68 network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config)      69 logger.info(f'Quant Network cost time is {time.time()  start} s.')      70 print(' Saving checkpoint...', flush=True) Cell In[3], line 45, in quant_network(net, mode, backend, **kwargs)      43     raise ValueError(""Please provide mfconfig for calibrating."")      44 network_helper = MFLlama2Helper(mfconfig) > 45 net = ptq.apply(net, network_helper)      46 logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')      47 start_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/round_to_nearest/round_to_nearest.py:194, in RoundToNearest.apply(self, network, network_helper)     192     if network_helper:     193         bs = network_helper.get_spec(""batch_size"") if network_helper.get_spec(""batch_size"") else 1 > 194         network_helper.generate(network, input_ids=np.ones([bs, 1], dtype=np.int32))     195 else:     196     warn_str = ""No layer found in network is suitable for quantization, please check network and "" \     197                ""opname_blacklist."" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore_gs/ptq/network_helpers/mf_net_helpers.py:60, in MFNetworkHelper.generate(self, mf_network, input_ids, max_new_tokens, **kwargs)      58 top_p = self.mf_config.model.model_config.top_p      59 top_k = self.mf_config.model.model_config.top_k > 60 return mf_network.generate(input_ids, do_sample=do_sample, max_length=seq, max_new_tokens=max_new_tokens,      61                            top_p=top_p, top_k=top_k) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:848, in GenerationMixin.generate(self, input_ids, generation_config, logits_processor, streamer, seed, **kwargs)     844     else:     845         block_tables, slot_mapping = self.block_mgr.assemble_pa_inc_inputs(valid_length_each_example,     846                                                                            is_finished) > 848 infer_output, is_finished = self.infer(input_ids=input_ids,     849                                        valid_length_each_example=valid_length_each_example,     850                                        generation_config=generation_config,     851                                        logits_processor=logits_processor,     852                                        logits_warper=logits_warper,     853                                        block_tables=block_tables,     854                                        slot_mapping=slot_mapping,     855                                        prefill=prefill,     856                                        is_finished=is_finished,     857                                        encoder_mask=encoder_mask,     858                                        encoder_output=encoder_output,     859                                        target_mask=target_mask,     860                                        **model_kwargs)     861 if generation_config.return_dict_in_generate:     862     target_list = infer_output[""target_list""] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:986, in GenerationMixin.infer(self, input_ids, valid_length_each_example, generation_config, logits_processor, logits_warper, block_tables, slot_mapping, prefill, is_finished, encoder_mask, encoder_output, target_mask, **model_kwargs)     983 start_time = time.time()     985 input_ids = np.array(input_ids) > 986 res, current_index = self.forward(input_ids=input_ids,     987                                   valid_length_each_example=valid_length_each_example,     988                                   block_tables=block_tables,     989                                   slot_mapping=slot_mapping,     990                                   prefill=prefill,     991                                   use_past=generation_config.use_past,     992                                   encoder_mask=encoder_mask,     993                                   encoder_output=encoder_output,     994                                   target_mask=target_mask,     995                                   **model_kwargs)     997 forward_time = time.time()  start_time     998 sample_time = time.time() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:1100, in GenerationMixin.forward(self, input_ids, valid_length_each_example, block_tables, slot_mapping, prefill, use_past, encoder_mask, encoder_output, target_mask, **model_kwargs)    1097 model_kwargs[""current_index""] = current_index    1099 if use_past: > 1100     res = self._incremental_infer(    1101         model_inputs=model_inputs,    1102         prefill=prefill,    1103         current_index=current_index,    1104         valid_length_each_example=valid_length_each_example,    1105         block_tables=block_tables,    1106         slot_mapping=slot_mapping    1107     )    1108 else:    1109     res = self(**model_inputs)   pylint: disable=E1102 File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/generation/text_generator.py:313, in GenerationMixin._incremental_infer(self, model_inputs, prefill, current_index, valid_length_each_example, block_tables, slot_mapping)     311     model_inputs[""slot_mapping""] = Tensor.from_numpy(slot_mapping)     312  pylint: disable=E1102 > 313 res = self(     314     **model_inputs,     315 )     316 ms.hal.synchronize()     317 self.phase = ""increment"" File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:703, in Cell.__call__(self, *args, **kwargs)     700         logger.warning(f""For 'Cell', it's not support hook function in graph mode. If you want to use hook ""     701                        f""function, please use context.set_context to set pynative mode."")     702     self._self_check() > 703     out = self.compile_and_run(*args, **kwargs)     704     return out     706  Run in PyNative mode. File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/nn/cell.py:1074, in Cell.compile_and_run(self, *args, **kwargs)    1072 self.add_flags(ge_sync_data=False)    1073 new_args = _get_args_for_run(self, args, kwargs, self._compile_args) > 1074 return _cell_graph_executor(self, *new_args, phase=self.phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1860, in _CellGraphExecutor.__call__(self, obj, phase, *args)    1858 if context.get_context(""precompile_only"") or _is_role_sched():    1859     return None > 1860 return self.run(obj, *args, phase=phase) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1911, in _CellGraphExecutor.run(self, obj, phase, *args)    1909 phase_real = phase + '.' + str(obj.create_time) + '.' + str(id(obj)) + '.' + obj.arguments_key    1910 if self.has_compiled(phase_real): > 1911     return self._exec_pip(obj, *args, phase=phase_real)    1912 raise KeyError('{} graph is not exist.'.format(phase_real)) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:185, in _wrap_func..wrapper(*arg, **kwargs)     183 (fn)     184 def wrapper(*arg, **kwargs): > 185     results = fn(*arg, **kwargs)     186     return _convert_python_data(results) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/common/api.py:1891, in _CellGraphExecutor._exec_pip(self, obj, phase, *args)    1889 fn = obj.construct    1890 obj.__parse_method__ = fn.__name__ > 1891 return self._graph_executor(args, phase) RuntimeError: Resize failed for kernel: Default/modelLlamaModel/tok_embeddingsLlamaEmbedding/Gatherop0   The Traceback of Net Construct Code:   In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:397~458, 4~19     def construct(self, input_ids, labels=None, input_position=None, position_ids=None, attention_mask=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:429, 17~27         output = self.model(tokens, batch_valid_length, batch_index, zactivate_len, block_tables, \                  ^~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:194~250, 4~21     def construct(self, tokens: Tensor, batch_valid_length=None, batch_index=None, zactivate_len=None,     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:242, 22~41         h = self.cast(self.tok_embeddings(tokens), self.dtype)                       ^~~~~~~~~~~~~~~~~~~  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:122~126, 4~21     def construct(self, input_ids):     ^  In file /home/mauser/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:125, 17~65         output = self.gather(self.embedding_weight, input_ids, 0)                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   C++ Call Stack: (For framework developers)  mindspore/ccsrc/runtime/graph_scheduler/actor/kernel_actor.cc:1023 ResizeKernelMod ` 运行代码为： ``` import os import time import mindspore as ms from mindformers import LlamaForCausalLM, MindFormerConfig, LlamaConfig, init_context from mindspore_gs.ptq import PTQMode, PTQConfig from mindspore_gs.common import BackendTarget, logger from mindspore_gs.ptq import RoundToNearest as RTN from mindspore_gs.ptq.network_helpers.mf_net_helpers import MFLlama2Helper class Llama2Network:     """"""Llama2Network.""""""          def create_mfconfig(config_path):         """"""Create mindformers config for llama2 network for example.""""""         config = MindFormerConfig(config_path)         config.model.model_config = LlamaConfig(**config.model.model_config)         init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel)         return config          def create_network(mindformers_config):         network = LlamaForCausalLM(mindformers_config.model.model_config)         network.set_train(False)         network.phase = 'predict'         return network def quant_network(net: LlamaForCausalLM, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, **kwargs):     """"""Quant llama2 model to w8a16 with RTN algorithm.""""""     start_time = time.time()     if mode == PTQMode.QUANTIZE:         logger.info(""Use RTN algo to quant network and weight."")     else:         logger.info(""Use RTN algo to quant network."")     cfg = PTQConfig(mode=mode, backend=backend, opname_blacklist=[""lm_head""])     ptq = RTN(config=cfg)     logger.info(f'Create PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     mfconfig = kwargs.get(""mfconfig"", None)     if not mfconfig:         raise ValueError(""Please provide mfconfig for calibrating."")     network_helper = MFLlama2Helper(mfconfig)     net = ptq.apply(net, network_helper)     logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     net.phase = ""quant_convert""     net = ptq.convert(net)     logger.info(f'Convert to real quantize cost time is {time.time()  start_time} s.')     return net start = time.time() print(' Creating network...', flush=True) net_mgr: Llama2Network = Llama2Network() config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") network = net_mgr.create_network(config) logger.info(f'Create Network cost time is {time.time()  start} s.') start = time.time() ckpt_path = config.load_checkpoint logger.info(f'Loading ckpt :{ckpt_path}.') ms.load_checkpoint(ckpt_path, network) ms.ms_memory_recycle() logger.info(f'Load ckpt cost time is {time.time()  start} s.') print(' Quantizeing network...', flush=True) start = time.time() network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config) logger.info(f'Quant Network cost time is {time.time()  start} s.') print(' Saving checkpoint...', flush=True) start = time.time() save_ckpt_path = os.path.join(config.output_dir, ""w8a16_ckpt"") save_path = os.path.join(save_ckpt_path, f""rank_0"") os.makedirs(save_path, exist_ok=True) ms.save_checkpoint(network.parameters_dict(), os.path.join(save_path, ""w8a16.ckpt""),                    choice_func=lambda x: ""key_cache"" not in x and ""value_cache"" not in x) logger.info(f'Save checkpoint cost time is {time.time()  start} s.') print(f' Checkpoint saved to {save_path}...', flush=True) ``` 配置文件为： ``` seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: './workspace/llama2_7b.ckpt' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'predict'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 1   sink_mode: True   sink_size: 2   gradient_accumulation_steps: 8  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr sechdule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 1   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: False   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 1   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: False   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMonitor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   max_call_depth: 10000   max_device_memory: ""28GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 4096     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""float16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float32""     rotary_dtype: ""float16""     param_init_type: ""float16""     use_past: True     scaling_factor: 1.0  The scale factor of seq length     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     use_flash_attention: True  FA can accelerate training or finetune     block_size: 16     num_blocks: 1024     is_dynamic: True     qkv_concat: False     offset: 0     checkpoint_name_or_path: """"     repetition_penalty: 1     max_decode_length: 512     top_k: 3     top_p: 1     do_sample: False   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer     vocab_file: './workspace/tokenizer.model'   type: LlamaProcessor  metric metric:   type: EmF1Metric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform.""```",2025-01-14T23:08:15+08:00,"foruda,www,www,www,www,www,www",progressing,0,12,https://gitee.com/mindspore/mindspore/issues/IBHTTR,mindsporeassistant,算法：RTN 8bit权重量化 报错阶段：量化统计权重minmax阶段 报错层：llama2网络开头的词表embedding层 根据日志可以发现报错发生在词表embedding层，尚未进入量化统计层，该报错时理论上与量化无关。请确保当前配置下可以进行该网络的浮点推理，再使用量化算法。,!使用推理脚本是可以正常推理的 使用推理脚本是可以正常推理的,"使用官方的包，mindspore2.3.1，mindformers1.2.0，mindspore_gs0.5.0，无法复现问题，运行代码ok： ``` $ python run.py [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:10.219.000 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:10.219.000 [mindspore/run_check/_check_version.py:469] Can not find driver so(need by mindsporeascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install  Creating network... [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.925.000 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.925.000 [mindspore/run_check/_check_version.py:469] Can not find driver so(need by mindsporeascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.926.000 [mindspore/run_check/_check_version.py:348] Using custom Ascend AI software package (Ascend Data Center Solution) path, package version checking is skipped. Please make sure Ascend AI software package (Ascend Data Center Solution) version is supported. For details, refer to the installation guidelines https://www.mindspore.cn/install [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:15.926.000 [mindspore/run_check/_check_version.py:469] Can not find driver so(need by mindsporeascend). Please check whether the Environment Variable LD_LIBRARY_PATH is set. For details, refer to the installation guidelines: https://www.mindspore.cn/install 20250116 14:05:15,927  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. [WARNING] DEVICE(1902031,ffffb838faf0,python):2025011614:05:16.140.448 [mindspore/ccsrc/plugin/device/ascend/hal/device/ascend_memory_adapter.cc:96] Initialize] Reserved memory size for other components(1610612736) is less than recommend size(1956155136), It may lead to Out Of Memory in HCCL or other components, Please double check context key 'variable_memory_max_size'/'max_device_memory' 20250116 14:05:20,204  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250116 14:05:20,204  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:20.227.000 [mindspore/ops/primitive.py:204] The in_strategy/in_layout of the operator in your network will not take effect in stand_alone mode. This means the the shard function called in the network is ignored. If you want to enable it, please use semi auto or auto parallel mode by context.set_auto_parallel_context(parallel_mode=ParallelMode.SEMI_AUTO_PARALLEL or context.set_auto_parallel_context(parallel_mode=ParallelMode.AUTO_PARALLEL) 20250116 14:05:24,522  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False [WARNING] ME(1902031:281473772485360,MainProcess):2025011614:05:24.523.000 [mindspore/common/parameter.py:805] This interface may be deleted in the future. 20250116 14:05:27,275  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:30,022  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:32,708  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:35,407  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:38,193  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:41,018  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:43,815  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:46,466  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:05:49,185  mindformers[mindformers/models/llama/llama_transformer.py:574]  INFO  Predict run mode:False 20250116 14:06:51,880  mindformers[mindformers/models/modeling_utils.py:1531]  INFO  model built, but weights is unloaded, since the config has no checkpoint_name_or_path attribute or checkpoint_name_or_path is None. 20250116 14:06:51,881  mindformers[mindformers/models/modeling_utils.py:599]  INFO  Set jit config for jit level:O0 and infer boost:on. 20250116 14:06:51,881  mindformers[mindformers/models/llama/llama.py:350]  INFO  Predict run mode:False  Quantizeing network... 20250116 14:06:53,828  mindformers[mindformers/generation/text_generator.py:698]  INFO  Generation Config is: {'max_length': 4096, 'max_new_tokens': 1, 'min_length': 0, 'min_new_tokens': None, 'num_beams': 1, 'do_sample': False, 'use_past': True, 'temperature': 1.0, 'top_k': 3, 'top_p': 1, 'repetition_penalty': 1, 'encoder_repetition_penalty': 1.0, 'renormalize_logits': False, 'return_dict_in_generate': False, 'output_scores': False, 'output_logits': False, 'pad_token_id': 0, 'bos_token_id': 1, 'eos_token_id': [2], '_from_model_config': True} 20250116 14:06:53,828  mindformers[mindformers/generation/text_generator.py:729]  INFO  The generation mode will be **GREEDY_SEARCH**. 20250116 14:06:53,829  mindformers[mindformers/generation/text_generator.py:97]  INFO  Set kbk infer :True 20250116 14:06:53,829  mindformers[mindformers/modules/block_tables.py:63]  INFO  init cache engine success. 20250116 14:06:53,830  mindformers[mindformers/models/llama/llama.py:386]  INFO  Set dynamic input for llama. 20250116 14:07:35,466  mindformers[mindformers/generation/text_generator.py:908]  INFO  total time: 41.63577461242676 s; generated tokens: 1 tokens; generate speed: 0.024017807025536558 tokens/s 20250116 14:07:35,477  mindformers[mindformers/modules/block_tables.py:129]  INFO  Clear block table cache engines.  Saving checkpoint...  Checkpoint saved to ./output/w8a16_ckpt/rank_0... ```",请问使用配置文件是什么呢，是裸机开发还是ModelArt开发呢,用了你提供的配置文件，去除了ckpt的加载 裸机开发,用modelart不知道为什么就会失败，如果是裸机手头只有310b的应该是肯定量化不了吧,不太了解modelart是啥。 310P机器确实没有验证过算法是否能运行，理论上会有两个问题 1）性能较差，算法耗时较长 2）如果最终部署环境不是310P，在310P上校准会有误差，导致精度损失较大,modelart是华为云的服务器，我是想量化后的模型放到310上跑下。那也就是说即使我在910b上量化完，想在香橙派的310端侧部署也会精度损失很大吗,会有精度损失，但也不一定会造成致命精度退化,这个问题可以抓取一些日志再分析下： 1. env  grep INTERNAL 3. export GLOG_v=1 后重新抓一把日志,错误已经定位，同样的代码使用终端脚本即可运行，使用notebook运行会报以上错误。
mindformers,hmy2022,急求大佬回复，根据官方教程进行RoundToNearest后量化出现以下set_context()报错，使用modelarts昇腾平台单卡。,"代码为 `import os import time import mindspore as ms from mindformers import LlamaForCausalLM, MindFormerConfig, LlamaConfig, init_context from mindspore_gs.ptq import PTQMode, PTQConfig from mindspore_gs.common import BackendTarget, logger from mindspore_gs.ptq import RoundToNearest as RTN from mindspore_gs.ptq.network_helpers.mf_net_helpers import MFLlama2Helper class Llama2Network:     """"""Llama2Network.""""""          def create_mfconfig(config_path):         """"""Create mindformers config for llama2 network for example.""""""         config = MindFormerConfig(config_path)         config.model.model_config = LlamaConfig(**config.model.model_config)         init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel)         return config          def create_network(mindformers_config):         network = LlamaForCausalLM(mindformers_config.model.model_config)         network.set_train(False)         network.phase = 'predict'         return network def quant_network(net: LlamaForCausalLM, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, **kwargs):     """"""Quant llama2 model to w8a16 with RTN algorithm.""""""     start_time = time.time()     if mode == PTQMode.QUANTIZE:         logger.info(""Use RTN algo to quant network and weight."")     else:         logger.info(""Use RTN algo to quant network."")     cfg = PTQConfig(mode=mode, backend=backend, opname_blacklist=[""lm_head""])     ptq = RTN(config=cfg)     logger.info(f'Create PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     mfconfig = kwargs.get(""mfconfig"", None)     if not mfconfig:         raise ValueError(""Please provide mfconfig for calibrating."")     network_helper = MFLlama2Helper(mfconfig)     net = ptq.apply(net, network_helper)     logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.')     start_time = time.time()     net.phase = ""quant_convert""     net = ptq.convert(net)     logger.info(f'Convert to real quantize cost time is {time.time()  start_time} s.')     return net start = time.time() print(' Creating network...', flush=True) net_mgr: Llama2Network = Llama2Network() config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") network = net_mgr.create_network(config) logger.info(f'Create Network cost time is {time.time()  start} s.') start = time.time() ckpt_path = config.load_checkpoint logger.info(f'Loading ckpt :{ckpt_path}.') ms.load_checkpoint(ckpt_path, network) ms.ms_memory_recycle() logger.info(f'Load ckpt cost time is {time.time()  start} s.') print(' Quantizeing network...', flush=True) start = time.time() network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config) logger.info(f'Quant Network cost time is {time.time()  start} s.') print(' Saving checkpoint...', flush=True) start = time.time() save_ckpt_path = os.path.join(config.output_dir, ""w8a16_ckpt"") save_path = os.path.join(save_ckpt_path, f""rank_0"") os.makedirs(save_path, exist_ok=True) ms.save_checkpoint(network.parameters_dict(), os.path.join(save_path, ""w8a16.ckpt""),                    choice_func=lambda x: ""key_cache"" not in x and ""value_cache"" not in x) logger.info(f'Save checkpoint cost time is {time.time()  start} s.') print(f' Checkpoint saved to {save_path}...', flush=True) ` 报错为： ```  TypeError                                 Traceback (most recent call last) Cell In[8], line 58      56 print(' Creating network...', flush=True)      57 net_mgr: Llama2Network = Llama2Network() > 58 config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"")      59 network = net_mgr.create_network(config)      60 logger.info(f'Create Network cost time is {time.time()  start} s.') Cell In[8], line 20, in Llama2Network.create_mfconfig(config_path)      18 config = MindFormerConfig(config_path)      19 config.model.model_config = LlamaConfig(**config.model.model_config) > 20 init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel)      21 return config File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/core/context/build_context.py:139, in init_context(use_parallel, context_config, parallel_config)     136 rank_id = 0     137 context_config['mode'] = MODE.get(context_config.get('mode')) > 139 context.set_context(max_device_memory=context_config.get('max_device_memory'),     140                     mode=context_config.get('mode'))     141 del context_config['mode']     142 del context_config['max_device_memory'] File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/_checkparam.py:1352, in args_type_check..type_check..wrapper(*args, **kwargs)    1350         if value is not None and not isinstance(value, bound_types[name]):    1351             raise TypeError(f""The parameter '{name}' must be {bound_types[name]}, but got {type(value)}"") > 1352 return func(*args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/context.py:1803, in set_context(**kwargs)    1801     continue    1802 if key in ctx.setters: > 1803     ctx.setterskey    1804     continue    1805 if hasattr(ctx, key): File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/context.py:545, in _Context.set_max_device_memory(self, max_device_memory)     543 if max_device_memory_value == 0:     544     raise ValueError(""For 'context.set_context', the argument 'max_device_memory' should not be \""0GB\""."") > 545 self.set_param(ms_ctx_param.max_device_memory, max_device_memory_value) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/context.py:187, in _Context.set_param(self, param, value)     186 def set_param(self, param, value): > 187     self._context_handle.set_param(param, value) TypeError: For 'set_context', the parameter max_device_memory can not be set repeatedly, origin value [58] has been in effect. Maybe 'mindspore.communication.init()' has been called before 'set_context()'.   C++ Call Stack: (For framework developers)  mindspore/core/utils/ms_context.cc:405 CheckReadStatus ```",2025-01-13T16:33:49+08:00,"foruda,www",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBHGN7,mindsporeassistant,请先补充下具体昇腾服务器的信息，MindSpore mindformers和CANN的版本？ 谢谢,https://www.mindspore.cn/golden_stick/docs/zhCN/r0.5.0/ptq/round_to_nearest.html根据这个链接的代码进行实验的。 MindSpore mindformers版本为1.2.0 mindspore_2.3.0cann_8.0.rc2py_3.9,请确认在!输入图片说明之前没有调用mindspore的set_context接口,问题已解决，如果前面运行到set_context之后，需要清空Npu缓存，清空之后错误就解决。
ascend,Albert,masked_scatter接口不支持bfloat16类型数据, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) masked_scatter接口传入bfloat16数据报错，官方文档并未说明不支持bfloat16格式数据 !输入图片说明  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例： ,2025-01-13T14:17:05+08:00,"gitee,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBHEGL,"当前算子本身应该也不支持，说是是个老接口，还没做aclnn的适配，之前老接口是不承诺支持bf16, 若有使用场景，可以提需求；"
mindir,李永昌,mindspore lite bgererankerbase 推理结果nan值bug,"mindspore lite bgererankerbase 推理结果nan值bug 目的：把bgebasezh，bgererankerbase部署到昇腾910B 步骤： 1. huggingface模型权重转换为onnx 备注：BAAI/bgererankerbase在huggingface仓库中已经开源onnx权重 Python代码方式 ```bash from transformers import AutoModel, AutoTokenizer import torch.onnx  加载模型和分词器 model_name = ""xxx/bgebasezh"" model = AutoModel.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name)  创建一个示例输入 dummy_input = tokenizer(""示例句子"", return_tensors=""pt"")  导出模型为ONNX格式 torch.onnx.export(     model,     args=(dummy_input[""input_ids""], dummy_input[""attention_mask""]),     f=""bgebasezh.onnx"",     input_names=[""input_ids"", ""attention_mask""],     output_names=[""output""],     dynamic_axes={         ""input_ids"": {0: ""batch_size"", 1: ""sequence_length""},         ""attention_mask"": {0: ""batch_size"", 1: ""sequence_length""},     },     opset_version=17, ) ``` 命令行方式 ```bash export HF_ENDPOINT=https://hfmirror.com optimumcli export onnx model BAAI/bgebasezh bgebasezhonnx ``` 2.把onnx权重转换为MINDIR格式的模型权重 2.1和2.2都一样的输出nan值 2.1 使用配置文件convert.ini ```bash  创建配置文件convert.ini [acl_build_options] input_format=""ND"" input_shape=""input_ids:1,1;attention_mask:1,1"" ``` ```bash PACKAGE_ROOT_PATH=./mindsporelite2.4.0linuxaarch64 export PATH=${PACKAGE_ROOT_PATH}/tools/converter/converter:$PATH export LD_LIBRARY_PATH=${PACKAGE_ROOT_PATH}/tools/converter/lib:${LD_LIBRARY_PATH} converter_lite fmk=ONNX \     modelFile=xxx/bgererankerbase/onnx/model.onnx \     outputFile=xxx/bgererankerbase/onnx/modelwoshape \     saveType=MINDIR \     optimize=ascend_oriented     configFile=convert.ini ``` 2.2不用配置文件，默认配置 ```bash PACKAGE_ROOT_PATH=./mindsporelite2.4.0linuxaarch64 export PATH=${PACKAGE_ROOT_PATH}/tools/converter/converter:$PATH export LD_LIBRARY_PATH=${PACKAGE_ROOT_PATH}/tools/converter/lib:${LD_LIBRARY_PATH} converter_lite fmk=ONNX \     modelFile=xxx/bgererankerbase/onnx/model.onnx \     outputFile=xxx/bgererankerbase/onnx/modelwoshape \     saveType=MINDIR \     optimize=ascend_oriented ``` 3.910B推理 推理代码 ```python import torch import torch_npu from transformers import AutoTokenizer import mindspore_lite as mslite def mslite_init_model(model_path):     context = mslite.Context()     context.target = [""ascend""]     context.ascend.device_id = 0     context.cpu.thread_num = 1     context.cpu.thread_affinity_mode=2      build model from file     model = mslite.Model()     model.build_from_file(model_path, mslite.ModelType.MINDIR, context)     return model def mslite_infer(model, input_data):     ms_inp = list(input_data.values())     inputs = model.get_inputs()     shapes = [ms_inp[0].shape, ms_inp[1].shape]     model.resize(inputs, shapes)     for i, _input in enumerate(inputs):         _input.set_data_from_numpy(ms_inp[i])     outputs = model.predict(inputs)     print(f'mslite_infer:\n{outputs}\n{type(outputs)}')     print(f'mslite_infer:\n{outputs[0]}\n{type(outputs[0])}')     print(f'mslite_infer:\n{outputs[0].get_data_to_numpy()}\n{outputs[0].get_data_to_numpy().shape}')     return outputs[0].get_data_to_numpy() def main():     pt_path = 'xxx/bgererankerbase'     ms_path = 'xxx/bgererankerbase/onnx/model.mindir'     device = torch.device('npu:0')     pairs = [['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']]     tokenizer = AutoTokenizer.from_pretrained(pt_path)     encoded_input = tokenizer(pairs, padding=True, truncation=True, max_length=512, return_tensors=""np"")     mslite infer     input_ids = encoded_input['input_ids'].astype(""int32"")     attention_mask = encoded_input['attention_mask'].astype(""int32"")     mslite_input_data = {""input_ids"": input_ids,""attention_mask"":attention_mask}     mslite_model = mslite_init_model(ms_path)     mslite_output = mslite_infer(mslite_model, mslite_input_data)     print(""mslite_output shape:"", mslite_output.shape) if __name__ == ""__main__"":    torch_npu.npu.config.allow_internal_format = False     torch.npu.set_compile_mode(jit_compile=False)    main() ``` 输出结果 !输入图片说明 reranker model输出的10个句子的重排序分数为nan值，请问该如何解决？（bgebase0zh安装什么步骤，正确输出。） 硬件个系统详情： !输入图片说明 !输入图片说明 !输入图片说明",2025-01-13T14:16:41+08:00,mindspore-assistant,closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBHEGE,FA面对输入较大的场景会输出NAN，可以配置饱和模式让输出正常：export MS_ASCEND_CHECK_OVERFLOW_MODE=SATURATION_MODE,非常感谢你的回复。我还有3个问题： 1. FA是什么（全写）？ 2. SATURATION_MODE具体值设置多少？ 3. 有相关的文档吗？能分享一下嘛，非常期待你的回复。,1、FA是FlashAttention的缩写，是一种用于优化 Transformer 模型中注意力机制的技术（详细原理可自行搜索了解）。 2、SATURATION_MODE无具体值，就是指饱和模式，MS_ASCEND_CHECK_OVERFLOW_MODE默认是非饱和模式，解决输出NAN的问题可以在推理前设置下宏，具体命令是：export MS_ASCEND_CHECK_OVERFLOW_MODE=SATURATION_MODE（仅在服务器型号Atlas 800I A2上支持）。
minddata,hmy2022,【mindformers1.2.0】【mindspore2.3.1】单卡使用MindSpore Golden Stick0.5.0文档中的RoundToNearest后量化算法出现以下报错,"运行代码为： > > > import os > import time >  > import mindspore as ms > from mindformers import LlamaForCausalLM, MindFormerConfig, LlamaConfig, init_context > from mindspore_gs.ptq import PTQMode, PTQConfig > from mindspore_gs.common import BackendTarget, logger > from mindspore_gs.ptq import RoundToNearest as RTN > from mindspore_gs.ptq.network_helpers.mf_net_helpers import MFLlama2Helper >  >  > class Llama2Network: >     """"""Llama2Network."""""" >      >     def create_mfconfig(config_path): >         """"""Create mindformers config for llama2 network for example."""""" >          >         config = MindFormerConfig(config_path) >         config.model.model_config = LlamaConfig(**config.model.model_config) >         init_context(use_parallel=config.use_parallel, context_config=config.context, parallel_config=config.parallel) >         return config >  >      >     def create_network(mindformers_config): >         network = LlamaForCausalLM(mindformers_config.model.model_config) >         network.set_train(False) >         network.phase = 'predict' >         return network >  >  > def quant_network(net: LlamaForCausalLM, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, **kwargs): >     """"""Quant llama2 model to w8a16 with RTN algorithm."""""" >     start_time = time.time() >     if mode == PTQMode.QUANTIZE: >         logger.info(""Use RTN algo to quant network and weight."") >     else: >         logger.info(""Use RTN algo to quant network."") >     cfg = PTQConfig(mode=mode, backend=backend, opname_blacklist=[""lm_head""]) >     ptq = RTN(config=cfg) >     logger.info(f'Create PTQ cost time is {time.time()  start_time} s.') >     start_time = time.time() >     mfconfig = kwargs.get(""mfconfig"", None) >     if not mfconfig: >         raise ValueError(""Please provide mfconfig for calibrating."") >     network_helper = MFLlama2Helper(mfconfig) >     net = ptq.apply(net, network_helper) >     logger.info(f'Apply PTQ cost time is {time.time()  start_time} s.') >     start_time = time.time() >     net.phase = ""quant_convert"" >     net = ptq.convert(net) >     logger.info(f'Convert to real quantize cost time is {time.time()  start_time} s.') >     return net >  >  > start = time.time() > print(' Creating network...', flush=True) > net_mgr: Llama2Network = Llama2Network() > config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") > network = net_mgr.create_network(config) > logger.info(f'Create Network cost time is {time.time()  start} s.') > start = time.time() > ckpt_path = config.load_checkpoint > logger.info(f'Loading ckpt :{ckpt_path}.') > ms.load_checkpoint(ckpt_path, network) > ms.ms_memory_recycle() > logger.info(f'Load ckpt cost time is {time.time()  start} s.') > print(' Quantizeing network...', flush=True) > start = time.time() > network = quant_network(network, mode=PTQMode.QUANTIZE, backend=BackendTarget.ASCEND, mfconfig=config) > logger.info(f'Quant Network cost time is {time.time()  start} s.') > print(' Saving checkpoint...', flush=True) > start = time.time() > save_ckpt_path = os.path.join(config.output_dir, ""w8a16_ckpt"") > save_path = os.path.join(save_ckpt_path, f""rank_0"") > os.makedirs(save_path, exist_ok=True) > ms.save_checkpoint(network.parameters_dict(), os.path.join(save_path, ""w8a16.ckpt""), >                    choice_func=lambda x: ""key_cache"" not in x and ""value_cache"" not in x) > logger.info(f'Save checkpoint cost time is {time.time()  start} s.') > print(f' Checkpoint saved to {save_path}...', flush=True) 配置文件为： seed: 0 output_dir: './output'  path to save checkpoint/strategy load_checkpoint: '' src_strategy_path_or_dir: '' auto_trans_ckpt: False   If true, auto transform load_checkpoint to load in distributed model only_save_strategy: False resume_training: False run_mode: 'predict'  trainer config trainer:   type: CausalLanguageModelingTrainer   model_name: 'llama2_7b'  runner config runner_config:   epochs: 2   batch_size: 1   sink_mode: True   sink_size: 2   gradient_accumulation_steps: 8  optimizer optimizer:   type: FP32StateAdamWeightDecay   beta1: 0.9   beta2: 0.95   eps: 1.e8   learning_rate: 5.e5  lr schedule lr_schedule:   type: CosineWithWarmUpLR   learning_rate: 5.e5   lr_end: 0   warmup_ratio: 0.03   total_steps: 1  1 means it will load the total steps of the dataset  dataset train_dataset: &train_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: True   input_columns: [""input_ids""]   ""input_ids"", ""labels"" , labels are used in instruction finetune.   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: True   batch_size: 6   repeat: 1   numa_enable: False   prefetch_size: 1 train_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *train_dataset  if True, do evaluate during the training process. if false, do nothing.  note that the task trainer should support _evaluate_in_training function. do_eval: False  eval dataset eval_dataset: &eval_dataset   data_loader:     type: MindDataset     dataset_dir: """"     shuffle: False   input_columns: [""input_ids""]   num_parallel_workers: 8   python_multiprocessing: False   drop_remainder: False   repeat: 1   numa_enable: False   prefetch_size: 1 eval_dataset_task:   type: CausalLanguageModelDataset   dataset_config: *eval_dataset use_parallel: False  parallel context config parallel:   parallel_mode: 1  0data parallel, 1semiauto parallel, 2auto parallel, 3hybrid parallel   gradients_mean: False   enable_alltoall: False   full_batch: True   search_mode: ""sharding_propagation""   enable_parallel_optimizer: False   strategy_ckpt_save_file: ""./ckpt_strategy.ckpt""   parallel_optimizer_config:     gradient_accumulation_shard: False     parallel_optimizer_threshold: 64  default parallel of device num = 8 for Atlas 800T A2 parallel_config:   data_parallel: 8   model_parallel: 1   pipeline_stage: 1   use_seq_parallel: False   micro_batch_num: 1   vocab_emb_dp: True   gradient_aggregation_group: 4  when model parallel is greater than 1, we can set micro_batch_interleave_num=2, that may accelerate the train process. micro_batch_interleave_num: 1  recompute config recompute_config:   recompute: False   select_recompute: False   parallel_optimizer_comm_recompute: False   mp_comm_recompute: True   recompute_slice_activation: True  callbacks callbacks:    type: MFLossMonitor    type: CheckpointMonitor     prefix: ""llama2_7b""     save_checkpoint_steps: 100     integrated_save: False     async_save: False    type: ObsMonitor  mindspore context init config context:   mode: 0 0Graph Mode; 1Pynative Mode   device_target: ""Ascend""   enable_graph_kernel: False   max_call_depth: 10000   max_device_memory: ""29GB""   save_graphs: False   save_graphs_path: ""./graph""   device_id: 0  model config model:   model_config:     type: LlamaConfig     batch_size: 1  add for increase predict     seq_length: 4096     hidden_size: 4096     num_layers: 32     num_heads: 32     vocab_size: 32000     multiple_of: 256     rms_norm_eps: 1.0e5     bos_token_id: 1     eos_token_id: 2     pad_token_id: 0     ignore_token_id: 100     compute_dtype: ""float16""     layernorm_compute_type: ""float32""     softmax_compute_type: ""float32""     rotary_dtype: ""float16""     param_init_type: ""float16""     use_past: True     scaling_factor: 1.0  The scale factor of seq length     extend_method: ""None""  support ""None"", ""PI"", ""NTK""     use_flash_attention: True  FA can accelerate training or finetune     block_size: 16     num_blocks: 1024     is_dynamic: True     qkv_concat: False     offset: 0     checkpoint_name_or_path: ""llama2_7b""     repetition_penalty: 1     max_decode_length: 512     top_k: 3     top_p: 1     do_sample: False   arch:     type: LlamaForCausalLM processor:   return_tensors: ms   tokenizer:     unk_token: ''     bos_token: ''     eos_token: ''     pad_token: ''     type: LlamaTokenizer   type: LlamaProcessor  metric metric:   type: EmF1Metric  wrapper cell config runner_wrapper:   type: MFTrainOneStepCell   scale_sense:     type: DynamicLossScaleUpdateCell     loss_scale_value: 65536     scale_factor: 2     scale_window: 1000   use_clip_grad: True eval_callbacks:    type: ObsMonitor auto_tune: False filepath_prefix: './autotune' autotune_per_step: 10 profile: False profile_start_step: 1 profile_stop_step: 10 init_start_profile: False profile_communication: False profile_memory: True layer_scale: False layer_decay: 0.65 lr_scale_factor: 256  aicc remote_save_url: ""Please input obs url on AICC platform."" 报错为：  Creating network... 20250113 08:18:34,790  mindformers[mindformers/version_control.py:96]  INFO  The Lazy Inline compilation acceleration feature does not support singlecard mode.This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect. 20250113 08:18:34,795  mindformers[mindformers/models/llama/llama.py:92]  INFO  enable asd op:False 20250113 08:18:34,797  mindformers[mindformers/models/llama/llama.py:96]  INFO  MoE config is None, use normal FFN  TypeError                                 Traceback (most recent call last) Cell In[2], line 59      57 net_mgr: Llama2Network = Llama2Network()      58 config = net_mgr.create_mfconfig(""./workspace/predict_llama2_7b.yaml"") > 59 network = net_mgr.create_network(config)      60 logger.info(f'Create Network cost time is {time.time()  start} s.')      61 start = time.time() Cell In[2], line 25, in Llama2Network.create_network(mindformers_config)      23       24 def create_network(mindformers_config): > 25     network = LlamaForCausalLM(mindformers_config.model.model_config)      26     network.set_train(False)      27     network.phase = 'predict' File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/version_control.py:98, in get_lazy_inline..decorator(*args, **kwargs)      95 if stand_alone:      96     logger.info(""The Lazy Inline compilation acceleration feature does not support singlecard mode.""      97                 ""This feature is disabled by default. ENABLE_LAZY_INLINE=1 does not take effect."") > 98     func(*args, **kwargs)      99     return     101 if not pipline_parallel and os.getenv(""ENABLE_LAZY_INLINE_NO_PIPELINE"", ""0"") == ""0"": File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:300, in LlamaForCausalLM.__init__(self, config)     298 self.gather = P.Gather(1)     299 self.sub_batch_valid_len = P.Sub() > 300 self.model = LlamaModel(config=config)     301 self.lm_head = Linear(in_channels=config.hidden_size,     302                       out_channels=config.vocab_size,     303                       has_bias=False,     304                       compute_dtype=config.compute_dtype,     305                       param_init_type=config.param_init_type,     306                       weight_init=""normal"")   meta default: xavier_normal     308 mp = config.parallel_config.model_parallel File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama.py:145, in LlamaModel.__init__(self, config)     122     layer = LLamaDecodeLayerInterleave(config.batch_size,     123                                        config.seq_length,     124                                        layer_id,    (...)     142                                        fine_grain_interleave=config.fine_grain_interleave,     143                                        parallel_config=config.parallel_config)     144 else: > 145     layer = LLamaDecodeLayer(layer_id,     146                              dim=config.hidden_size,     147                              n_heads=config.num_heads,     148                              n_kv_heads=config.n_kv_heads,     149                              intermediate_size=config.intermediate_size,     150                              multiple_of=config.multiple_of,     151                              ffn_dim_multiplier=config.ffn_dim_multiplier,     152                              norm_eps=config.rms_norm_eps,     153                              qkv_has_bias=config.qkv_has_bias,     154                              qkv_concat=config.qkv_concat,     155                              compute_dtype=config.compute_dtype,     156                              layernorm_compute_dtype=config.layernorm_compute_type,     157                              softmax_compute_dtype=config.softmax_compute_type,     158                              rotary_dtype=config.rotary_dtype,     159                              param_init_type=config.param_init_type,     160                              use_past=config.use_past,     161                              use_flash_attention=config.use_flash_attention,     162                              use_attn_mask_compression=config.use_attn_mask_compression,     163                              block_size=config.block_size,     164                              num_blocks=config.num_blocks,     165                              is_dynamic=config.is_dynamic,     166                              use_rope_slice=config.use_rope_slice,     167                              moe_config=config.moe_config,     168                              parallel_config=config.parallel_config)     169 set_layer_stage_recompute(layer, layer_id, config.offset, config.parallel_config, config.num_layers)     170 self.layers.append(layer) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/version_control.py:64, in get_predict_lazy_inline..decorator(*args, **kwargs)      62     logger.info(""Predict enable lazy inline."")      63 else: > 64     func(*args, **kwargs) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_transformer.py:486, in LLamaDecodeLayer.__init__(self, layer_id, dim, n_heads, n_kv_heads, intermediate_size, multiple_of, ffn_dim_multiplier, norm_eps, qkv_concat, compute_dtype, layernorm_compute_dtype, softmax_compute_dtype, rotary_dtype, param_init_type, qkv_has_bias, use_past, is_dynamic, use_rope_slice, moe_config, use_flash_attention, use_attn_mask_compression, block_size, num_blocks, parallel_config)     484 self.reshape = P.Reshape()     485 self.add = P.Add() > 486 self.ffn_norm = LlamaRMSNorm(self.hidden_size, norm_eps, compute_type=layernorm_compute_dtype)     487 self.attention_norm = LlamaRMSNorm(self.hidden_size, norm_eps, compute_type=layernorm_compute_dtype)     488 self.attention = LLamaAttention(dim=dim,     489                                 n_heads=n_heads,     490                                 n_kv_heads=n_kv_heads,    (...)     503                                 num_blocks=num_blocks,     504                                 parallel_config=parallel_config) File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindformers/models/llama/llama_layer.py:175, in LlamaRMSNorm.__init__(self, dim, eps, compute_type)     173     self.cast = P.Cast()     174     self.rcast = P.Cast() > 175     self.cast.recompute()     176 else:     177     self.cast = P.Cast() File ~/anaconda3/envs/MindSpore/lib/python3.9/sitepackages/mindspore/ops/primitive.py:482, in Primitive.recompute(self, mode)     438 """"""     439 Set the primitive recomputed. If a primitive set recomputed feeds into some backward nodes     440 for computing gradient, rather than storing the intermediate activation computed in forward    (...)     479     [0. 0.5]     480 """"""     481 if context.get_context(""mode"") == context.PYNATIVE_MODE: > 482     raise TypeError(""Recompute is not supported in pynative mode currently."")     483 Validator.check_bool(mode)     484 self.add_prim_attr(""recompute"", mode) TypeError: Recompute is not supported in pynative mode currently.",2025-01-13T08:26:58+08:00,"gitee,mindspore-assistant",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBHAF5,mindsporeassistant,mindsporeassistant
mixtral,wuweikang,add mixtral dry run test case,,2025-01-11T11:10:15+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBH57Z
ascend,cccc1111,Add/Sub在Ascend侧对接aclnn算子, Tasks 转测对象：mint.add/tensor.add/mint.sub/tensor.sub 对标torch.add/torch.sub   Background  **1. 标杆情况**   标杆接口链接： https://pytorch.org/docs/2.1/generated/torch.add.htmltorch.add  标杆在Ascend支持数据类型： float64/float32/float16/bfloat16/uint8/int8/int16/int32/int64/complex64/complex128/bool  **2. MindSpore算子情况**   当前支持数据类型 与torch_npu保持一致  三后端统一后算子支持（标杆支持+三后端并集） 与torch_npu保持一致  Introduction  **1. 功能介绍**  与other相加减，alpha为放大缩小系数  **2. 接口描述**   ops接口   mint/tensor接口： Add: !输入图片说明 Sub: !输入图片说明  算子原语   自动生成对应原语 （1）在Tensor/Scalar场景中，Scalar为complex场景，因为框架数据类型原因，没有对齐 （2）在Tensor/Tensor场景中，Tensor为标量Tensor场景，InferType没有对齐 对于add： （1）Ascend后端： PyNative模式，匹配add_scalar_op与add_ext_op； KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op； GE模式，input/other输入，匹配deprecated， input/other/alpha输入，匹配add_scalar_op与add_ext_op报错； （2）CPU后端： PyNative模式，匹配add_scalar_op与add_ext_op； KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op; GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op报错； （3）GPU后端： PyNative模式，匹配add_scalar_op与add_ext_op; KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op; GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配add_scalar_op与add_ext_op报错； 对于__add__: 同add，与之前保持一致 对于 +： 同add，与之前保持一致 对于sub： （1）Ascend后端： PyNative模式，匹配sub_scalar_op与sub_ext_op； KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op; GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op报错； （2）CPU后端 PyNative模式，匹配sub_scalar_op与sub_ext_op; KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op； GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op报错； （3）GPU后端 PyNative模式，匹配sub_scalar_op与sub_ext_op; KBK模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op； GE模式，input/other输入，匹配deprecated，input/other/alpha输入，匹配sub_scalar_op与sub_ext_op报错； 对于__sub__: 同sub，与之前保持一致 对于 ： 同sub，与之前保持一致,2025-01-08T22:15:42+08:00,"sig/ops,v2.1.0",open,0,0,https://gitee.com/mindspore/mindspore/issues/IBGKMX
chatglm,hmy2022,【MindSpore Golden Stick】【SmoothQuant】请问目前想通过MindSpore Golden Stick来PTQ量化ChatGLM36b可以吗，我看好像没有适配的类。,本人模型量化小白，想请教下如果通过MindSpore Golden Stick来SmoothQuant量化ChatGLM36b，很急，求大佬解答。,2025-01-08T21:51:10+08:00,mindspore-assistant,closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBGKK3,mindsporeassistant,确实没有增加chatglm的支持，需要加一行代码将chatglm的decoder类注册一下： ptq_config = PTQConfig(xxx) ptq = PTQ(ptq_config)  **ptq.decoder_layer_types.append(ChatGLM2Block)**  ptq.apply(network) ptq.convert(network),请问，我如果想通过MindSpore Golden Stick来PTQ量化ChatGLM36b，有大概的代码架构可以提供给我吗，感谢大佬,目前教程中很多API我看都在我使用的0.5.0分支中没有，所以使用下来比较混乱，如果能提供一个框架真的万分感谢。
minddata,liguozheng,8卡16G V100训练报 Memory not enough," 报错如下： WARNING] MD(474008,7f4c6d7fe700,python):2025010809:27:59.089.071 [mindspore/ccsrc/minddata/dataset/engine/datasetops/source/generator_o 25 seconds to generator.__next__ new row, which might cause `GetNext` timeout problem when sink_mode=True. You can increase the parameterof obtaining samples in the userdefined generator function. [WARNING] PRE_ACT(474008,7f4dc5fff700,python):2025010809:28:00.513.098 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.513.306 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.513.463 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.514.322 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc5fff700,python):2025010809:28:00.515.428 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcde4b700,python):2025010809:28:00.515.536 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.515.706 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.516.580 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc5fff700,python):2025010809:28:00.517.660 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcde4b700,python):2025010809:28:00.517.930 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcd64a700,python):2025010809:28:00.518.016 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.228 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.518.388 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.526 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.680 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.518.880 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcce49700,python):2025010809:28:00.519.016 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.520.767 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. [WARNING] PRE_ACT(474008,7f4dcde4b700,python):2025010809:28:00.521.354 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[25165824]. [WARNING] PRE_ACT(474008,7f4dc57fe700,python):2025010809:28:00.521.856 [mindspore/ccsrc/backend/common/mem_reuse/mem_dynamic_allocator. size[5963776] is smaller than required size[50331648]. pid: 474008 20250108 09:27:00.008152 Traceback (most recent call last):   File ""/home/lgz/v100/kunpeng/nowcastnet/framework_test/test/main.py"", line 134, in      train(config_flatten, logger)   File ""/home/lgz/v100/kunpeng/nowcastnet/framework_test/test/main.py"", line 87, in train     evo_trainer.train()   File ""/home/lgz/v100/kunpeng/nowcastnet/framework_test/common/framework/nowcastnet/solver.py"", line 606, in train     evo_res = self.evo_solver(inputs, labels)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/nn/cell.py"", line 680, in __call__     out = self.compile_and_run(*args, **kwargs)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/nn/cell.py"", line 1023, in compile_and_run     return _cell_graph_executor(self, *new_args, phase=self.phase)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 1589, in __call__     return self.run(obj, *args, phase=phase)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 1628, in run     return self._exec_pip(obj, *args, phase=phase_real)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 121, in wrapper     results = fn(*arg, **kwargs)   File ""/home/lgz/miniconda3/envs/mindspore/lib/python3.7/sitepackages/mindspore/common/api.py"", line 1608, in _exec_pip     return self._graph_executor(args, phase) RuntimeError:    Memory not enough:  Device(id:0) memory isn't enough and alloc failed, kernel name: Gradients/Default/networkEvolutionLoss/evo_modelEvolutionNet/gradStrided   C++ Call Stack: (For framework developers)",2025-01-08T18:36:37+08:00,"gitee,foruda,www,mindspore-assistant",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBGJOL,具体跑的什么模型，多大规格的，batchsize是多少，用的什么并行方式？最好提供代码看一下；目前错误的信息就是说显存不够,https://gitee.com/mindspore/mindscience/tree/r0.6/MindEarth/applications/nowcasting/Nowcastnet 我用这个试了下，也可以复现,你这边单卡能跑不？可以先试试单卡；我用里面默认的训练配置，8G显存都能跑： !输入图片说明 看看你这边单卡会不会有显存不足的问题，有的话，可能是环境配置的原因,"问题已经解决 代码需要增加 init(""nccl"")初始化 https://www.mindspore.cn/docs/programming_guide/zhCN/r1.6/distributed_training_gpu.html 或者通过mpirun的方式尝试"
bfloat16,looop5,DVM MatMul融合算子dry run core dump,"dry run执行core dump ``` class Net(Cell):     def __init__(self):         super(Net, self).__init__()     def construct(self, para1_Parameter_9338, para2_Parameter_9339, para3_Parameter_9342):         y0 = ops.MatMul(transpose_a=False, transpose_b=True)(para1_Parameter_9338, para2_Parameter_9339)         y1 = ops.Cast()(y0, mindspore.float32)         y2 = ops.Cast()(para3_Parameter_9342, mindspore.float32)         y3 = ops.Add()(y1, y2)         y4 = ops.Cast()(y3, mindspore.bfloat16)         return y4 ```",2025-01-08T17:05:34+08:00,,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBGIB9,根因分析：dry run的时候会跳过dvm编译，dvm matmul kernel有些变量没初始化，析构的时候又去访问了这些没初始化的变量，就core dump了。 解决方法：析构函数里需要对指针判空。 已补充st用例run_matmul。 自验通过。
mindformers,zhangbuxue,add args introduction for Tensor expand," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-08T15:08:41+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGGJT
ascend,tridu33,910服务器上执行案例ascend310_single_op_sample执行报错,"正确编译 https://gitee.com/mindspore/docs/tree/master/docs/sample_code/ascend310_single_op_sample 后执行报错： ```bash (openmindms) tridu33master:~/workspace/mindsporedocssamplecodes/ascend310_single_op_sample$ ./tensor_add_sample /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for  type is zero.   setattr(self, word, getattr(machar, word).flat[0]) /home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for  type is zero.   return self._float_to_str(self.smallest_subnormal) 3 5 7 9 double free or corruption (out) Aborted (core dumped) (openmindms) tridu33master:~/workspace/mindsporedocssamplecodes/ascend310_single_op_sample$ Process ForkServerProcess9: Process ForkServerProcess8: Process ForkServerProcess7: Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run() Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs) Process ForkServerProcess6: Process ForkServerProcess5:   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get() Process ForkServerProcess2: Process ForkServerProcess3: Process ForkServerProcess4:   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv() Traceback (most recent call last):   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs) EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get() EOFError   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError EOFError Traceback (most recent call last): Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv() Traceback (most recent call last): Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get() Traceback (most recent call last):   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap     self.run()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/process.py"", line 108, in run     self._target(*self._args, **self._kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 65, in wrapper     raise exp   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 62, in wrapper     func(*args, **kwargs)   File """", line 2, in get EOFError   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/sitepackages/tbe/common/repository_manager/route.py"", line 262, in task_distribute     key, func_name, detail = resource_proxy[TASK_QUEUE].get()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File """", line 2, in get   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/managers.py"", line 810, in _callmethod     kind, result = conn.recv()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4)   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 250, in recv     buf = self._recv_bytes()   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 414, in _recv_bytes     buf = self._recv(4) EOFError   File ""/home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/connection.py"", line 383, in _recv     raise EOFError EOFError EOFError /home/tridu33/.conda/envs/openmindms/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 30 leaked semaphore objects to clean up at shutdown   warnings.warn('resource_tracker: There appear to be %d ' ```",2025-01-08T10:37:12+08:00,mindspore-assistant,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBGDP9,这个是早期的mindspore版本，在310上的使用mindspore的C++ API直接加载mindir文件推理的示例代码，根据官方文档可知，这种方式目前新版本已经不在支持维护了，并且之前的版本也是在310上支持这种方式，就是以前200DK开发板的那种环境（不是200I DK A2），而不是910（也不是310b或者310p）
ascend,zhangyinxia,Continuous optimization for comm op,"   Describe the current behavior / 问题描述 (Mandatory / 必填)  Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment(`Ascend`/`GPU`/`CPU`)  / 硬件环境**:  > Please delete the backend not involved / 请删除不涉及的后端: > /device ascend/GPU/CPU/kirin/等其他芯片  **Software Environment / 软件环境 (Mandatory / 必填)**:  MindSpore version (e.g., 1.7.0.Bxxx) :  Python version (e.g., Python 3.7.5) :  OS platform and distribution (e.g., Linux Ubuntu 16.04):  GCC/Compiler version (if compiled from source):   **Excute Mode / 执行模式 (Mandatory / 必填)(`PyNative`/`Graph`)**:  > Please delete the mode not involved / 请删除不涉及的模式: > /mode pynative > /mode graph  Related testcase / 关联用例 (Mandatory / 必填)  Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 1.  2.   3.   Describe the expected behavior / 预期结果 (Mandatory / 必填)  Related log / screenshot / 日志 / 截图 (Mandatory / 必填)  Special notes for this issue/备注 (Optional / 选填)",2025-01-08T10:12:31+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBGD9W
mindformers,mengyuanli,xlogy tensor 接口语义不清晰," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) xlogy(y) 与参考接口中的 other 入参是统一参数，需要补充说明。 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-07T14:25:19+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBG73N
allgather,李尚蔚,llama3.1 70b动态shape lora微调重排冗余allgathersplit算子未去除," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) llama3.1 70b动态shape lora微调重排冗余allgathersplit算子未去除  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   .*w2' profile: True parallel_config:   data_parallel: 4   model_parallel: 1   pipeline_stage: 8 ``` （2） ``` bash ../scripts/msrun_launcher.sh ""llama3_1/run_llama3_1.py \  config llama3_1/finetune_llama3_1_8b.yaml \  load_checkpoint ./ms_trans \  auto_trans_ckpt False \  run_mode finetune \  train_data ./test.json"" ``` （3）使用mindstudio insight分析profiling  5.Describe the expected behavior / 预期结果 (Mandatory / 必填)  **【预期结果】**：DP域仅前向开始前存在allgather算子  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) PP域send算子后split算子在等待DP域allgather算子 !PP域send算子后split算子在等待DP域allgather算子    7.Special notes for this issue/备注 (Optional / 选填) 【定位人】刘崇鸣",2025-01-07T09:47:54+08:00,,open,0,0,https://gitee.com/mindspore/mindspore/issues/IBG3V2
ascend,张汉权,cann哪个版本和mindspore2.5.0适配？,cann哪个版本和mindspore2.5.0适配？我是员工已经下了cann8.0.0和mindspore2.5.0下来，但是报了一个 Load dynamic library: libmindspore_ascend.so.2 failed. libge_runner.so: cannot open shared object file: No such file or directory，问了几个人都说是编的有问题，或者安排一个人给帮忙安装一下也行,2025-01-06T20:17:00+08:00,"foruda,foruda,foruda,mindspore-assistant,repo",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBG1WM,2.5.0目前还没正式发布呢，你这边用的应该是每日dev版本，开发流水线上应该是每天都会打一个包的，每日版保不准有什么bug，目前因为还没正式发布，所以官网也没对应的文档说明与cann的对应关系，一般来说会用最新版本的cann，这cann版本可能也还没发布，可以的话，建议还是用已发布的2.4.1正式版； 或者你可以就下载个已发布的最新版本的cann 8.0.0.alpha003试试看： !输入图片说明 看上面的错误情况，大概率还是cann、驱动版本没匹配好，或者环境变量设置有误的原因；我这边测试了下，用1月1号的2.5.0包，在华为云modelarts的8.0.RC1环境里运行，还是能够跑的，这个环境我是用来跑2.3.1的，里面的cann包和2.5.0不是完美匹配的，但测试下来基本的运行没有问题，你可以参考一下： !输入图片说明 我这边通过环境变量把警告信息屏蔽掉了，如果不屏蔽的话，因为cann和mindspore不完美匹配，会有一大堆警告的，不过从警告里也可以看到，2.5.0所需要的昇腾软件包版本是7.5或者7.6，你可以去昇腾那边问一下，这个版本的软件包对应的cann是什么版本呢： !输入图片说明 说回来，尽管2.5.0在cann 8.0RC1能运行，但一方面不是正式版，且没有完美匹配版本，保不准会出什么错；你这边下载到mindspore每日包和我的可能也不是同一天的，所以情况也可能有差别,谢谢，我目前用的是https://repo.mindspore.cn/mindspore/mindspore/version/202412/20241227/master_20241227010019_d0e4d9b30db7a01da2ae55cc8aed59d68dd3c5ef_newest/unified/这个链接里面的2.5.0，cann用的是8.0.0的，那会报这个错的原因到底是哪里不适配呢？runtime那边的人也说不适配，不过我原来装了一个mindspore2.3.1版本的，原来的cann是8.0.RC2，我查了latest里面也是这个版本的这里面会不会有冲突呢？我的理解是新装的cann是不是没有起作用？,哦，谢谢我已经解决这个问题了,新装的cann有没有起作用看你环境变量的设置方式了，每次安装cann时，默认他会有个单独的cann目录，就是以cann的版本号命名的，然后会更新一个latest目录，这个目录其实是个软连接，连接到对应的cann版本目录，如果配置cann的环境变量时都是指向latest的话，新装一个就直接生效了； 但也有些情况可能导致出错，就是某个cann版本的环境变量有变化的话，或者新装的cann和物理机上的驱动不匹配的话，就可能出错；
ascend,橙橙橙,创建 tensor 时负数转成无符号整数(如uint32等)行为与pytorch不一致," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) 创建 tensor 时输入超过二维，负数转成无符号整数(如uint32等)行为与pytorch不一致  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:    Hardware (e.g.`Ascend910B1`/`Mac CPU`): Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph\PyNative  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 代码： ```python import mindspore as ms import torch x = [[1, 6], [7.9, 3.2]] ms_tensor = ms.tensor(x, dtype=ms.uint32) torch_tensor = torch.tensor(x, dtype=torch.uint32) print(ms_tensor, torch_tensor) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常跑通  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-01-06T18:49:26+08:00,gitee,closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBG1GY,这是由于不同的转换策略造成的，后续可能会进行改进
ascend,橙橙橙,mint.acos 不支持输入 uint16 和 uint32 类型," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.acos 不支持 uint16 和 uint32, 而 torch.acos 是支持的。mint.acosh 也是这样。  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:    Hardware (e.g.`Ascend910B1`/`Mac CPU`): Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 代码： ```python import mindspore as ms from mindspore import mint import torch x = [0.74, 0.04, 0.30, 0.56],[0.7, 0.3, 0.8, 0.2],[1.0, 0.9, 0.11, 0.5] ms_tensor = ms.tensor(x, dtype=ms.uint32) torch_tensor = torch.tensor(x, dtype=torch.uint32) ms_result = mint.acos(ms_tensor).asnumpy() torch_result = torch.acos(torch_tensor).numpy() print(ms_tensor, torch_tensor) print(torch_result)  print(ms_result, torch_result) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常跑通  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-01-06T18:44:49+08:00,"foruda,mindspore-assistant",closed,0,1,https://gitee.com/mindspore/mindspore/issues/IBG1FR,这个应该是目前的cann算子还不支持，mint里的api目前都是针对昇腾环境的，框架层肯定也没发支持了； cann算子手册里的acos算子： !输入图片说明 uint16 和 uint32 类型估计要等最新的cann版本支持后，然后最新的mindspore分支代码才能接入
ascend,lubingjie66,使用单卡推理llama3.18B时出现The config for soc_verison: Ascend910ProA does not exist.,!输入图片说明 请问这个问题应该怎么解决？,2025-01-06T16:56:37+08:00,mindspore-assistant,closed,0,2,https://gitee.com/mindspore/mindspore/issues/IBFZOL,执行的命令如下： bash scripts/examples/llama3/run_llama3_predict.sh single \  research/llama3_1/llama3_1_8b/predict_llama3_1_8b.yaml \  path/to/llama3_1_8b.ckpt \  path/to/tokenizer.model,这个是不支持当前硬件设备，建议使用atlas 800T A2 系列
ascend,liubuyu,ascend后端支持进程级断点续训,   Backgroud（背景信息）  Describe/Explain the status of the problem you wish to solve.  Attach relevant issues if there is any.  Origin（信息来源）  Explain which department/team made this request so that its priority can be given.  Benefit / Necessity （价值/作用）  Describe/Explain the key value by fulfilling the request.  Design（设计方案）  Describe/Explain the general idea of the design. Pseudocode is allowed,2025-01-06T16:52:56+08:00,"gitee,gitee,www,wiki,dbox",open,0,2,https://gitee.com/mindspore/mindspore/issues/IBFZN3,"方案设计： https://wiki.huawei.com/domains/83650/wiki/141984/WIKI202502065859426 DT用例： 当前特性至少双机，功能无法在门禁看护，进提供ut等测试用例，见方案设计2.7章节 [图片上传中…(imageztT7vxQb7RqYuTfCRjGs)] 需求列表： https://dbox.huawei.com/dashboard?pid=OR%3Awt.pdmlink.PDMLinkProduct%3A22045263215&oid=22045310781,22046387564,22050447354,22050448322,100066216895,100404828007,100865042799,100865043663,100866058137,100866058645 用例列表： https://gitee.com/mindspore/mindspore/pulls/81208/files 代码检视：见pr 代码行号：0.9k 资料：https://gitee.com/mindspore/docs/pulls/15991 遗留DI:叠加故障，预计228确认并解决https://e.gitee.com/mind_spore/issues/list?issue=IBNE6C 归档：https://dbox.huawei.com/dashboard?pid=OR%3Awt.pdmlink.PDMLinkProduct%3A22045263215&oid=22045310781,22046387564,22050447354,22050448322,100066216895,100404828007,100865042799,100865043663,100866058137,100866058645",https://www.hiascend.com/document/detail/zh/mindxdl/600/clusterscheduling/ref/mindiottp/mindiotft001.html
ascend,橙橙橙,mint.rand 在图模式下报错," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) mint.rand 在图模式下报错  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:    Hardware (e.g.`Ascend910B1`/`Mac CPU`): Ascend  **Software Environment / 软件环境 (Mandatory / 必填)**:   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): Graph  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) 代码： ```python import mindspore as ms from mindspore import mint ms.set_context(pynative_synchronize=True) ms.set_context(mode=ms.GRAPH_MODE) print(mint.rand(4)) ```  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：正常跑通  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !输入图片说明",2025-01-05T21:43:21+08:00,"foruda,foruda,mindspore-assistant",closed,0,5,https://gitee.com/mindspore/mindspore/issues/IBFRKL,走静态图的话，建议把对应的代码用mindspore.jit包一下，这样是能运行的： !输入图片说明 !输入图片说明 如果运行的代码不在nn.Cell类或者其子类的construct方法中的话，就算是在上下文中设置了静态图，走的也是动态图模式，需要用jit包起来才是真的走了静态图，这也是mindspore动静结合的一种方式；不过这边可能有动静结合模式下调用mint一些方法的bug，之前也看到有提问说不少mint的方法不用jit包起来的情况下会出错； 还有ms.set_context(pynative_synchronize=True)这个方法是开启动态图的同步，方便定位动态图下的错误，对于静态图是无效的,谢谢你，我加上 jit 之后还是报错了。 !输入图片说明 !输入图片说明,这个代码加上jit之后在2.3.1上是可以运行的，这个错误可能是环境的设置上的问题，执行下 unset RANK_TABLE_FILE 命令再运行看看,执行完 unset RANK_TABLE_FILE 就没有报错了，请教下这个是什么问题呢,具体的报错机制和原因我也不太清楚，这个设置其实和错误本身应该没有直接关联，但会影响到默认运行的动静图模式，你这边用的是华为云贵阳一区的modelarts镜像吧，里面的镜像默认是配置了RANK_TABLE_FILE，你可以echo $RANK_TABLE_FILE看一下，可能正好就是这种模式下触发了某些bug
overflow,majun-bot,CVE202436613,"一、漏洞信息 漏洞编号：CVE202436613 漏洞归属组件：FFmpeg, https://gitee.com/mindspore/mindspore 漏洞归属的版本：5.1.2 CVSS分值： &emsp;BaseScore： N/A None &emsp;Vector：  漏洞简述： FFmpeg n6.1.1 has a vulnerability in the DXA demuxer of the libavformat library allowing for an integer overflow, potentially resulting in a denialofservice (DoS) condition or other undefined behavior. 漏洞公开时间：00010101 08:05:43 漏洞创建时间：20250104 03:52:36 漏洞详情参考链接： https://nvd.nist.gov/vuln/detail/CVE202436613 漏洞分析指导链接： https://gitee.com/mindspore/community/blob/master/security/cve_issue_template.md 漏洞补丁信息： 二、漏洞分析结构反馈 影响性分析说明： FFmpegn6.1.1在libavformat库的DXA解复用器中存在一个漏洞，允许整数溢出，可能导致拒绝服务(DoS)条件或其他未定义的行为。 受影响分支已经合入patch。 漏洞评分(MindSpore评分): &emsp;BaseScore： 6.2 &emsp;Vector： CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响",2025-01-04T03:52:36+08:00,"gitee,rca/others,rct/oldrelease,ctl/componenttest,CVE/FIXED",closed,0,4,https://gitee.com/mindspore/mindspore/issues/IBFLK1,"**issue处理注意事项:**  **1. 当前issue受影响的分支提交pr时, 须在pr描述中填写当前issue编号进行关联, 否则无法关闭当前issue;** **2. 模板内容需要填写完整, 无论是受影响或者不受影响都需要填写完整内容,未引入的分支不需要填写, 否则无法关闭当前issue;** **3. 以下为模板中需要填写完整的内容, 请复制到评论区回复, 注: 内容的标题名称(影响性分析说明, MindSpore评分, 受影响版本排查(受影响/不受影响))不能省略,省略后cvemanager将无法正常解析填写内容.** ************************************************************************ 影响性分析说明:  漏洞评分(mindspore评分): BaseScore: Vector: 受影响版本排查(受影响/不受影响):  1.master: 2.r1.10: 3.r1.9: 4.r2.0: 5.r2.1: 6.r2.2: 7.r2.3:  pr关联issue具体操作请参考: https://gitee.com/help/articles/4142",影响性分析说明： FFmpeg n6.1.1 在 libavformat 库的 DXA 解复用器中存在一个漏洞，允许整数溢出，可能导致拒绝服务 (DoS) 条件或其他未定义的行为。 受影响分支已经合入patch。 漏洞评分(MindSpore评分):  BaseScore：6.2 MEDIUM  Vector：CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H 受影响版本排查(受影响/不受影响)： 1.master:受影响 2.r1.10:不受影响 3.r1.9:不受影响 4.r2.0:不受影响 5.r2.1:不受影响 6.r2.2:不受影响 7.r2.3:不受影响,"经过cvemanager解析，已分析的内容如下表所示：  **请确认分析内容的准确性, 确认无误后, 您可以进行后续步骤, 否则您可以继续分析.**",受影响分支已经合入patch
mindir,wmc,mindspore_lite转换mindyolo的mindir模型时make_list算子不支持, 1.Describe the current behavior / 问题描述 (Mandatory / 必填) > mindspore_lite转换mindyolo的mindir模型失败  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**: CPU环境：Intel(R) Xeon(R) Platinum 8369B CPU @ 2.70GHz  **Software Environment / 软件环境 (Mandatory / 必填)**:   4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）export LITE_HOME=/mnt/workspace/mindyolo/deploy/mindsporelite2.2.14linuxx64 > （2）export LD_LIBRARY_PATH=$LITE_HOME/runtime/lib:$LITE_HOME/tools/converter/lib:$LD_LIBRARY_PATH > （3）export PATH=$LITE_HOME/tools/converter/converter:$LITE_HOME/tools/benchmark:$PATH > （4）./converter_lite fmk=MINDIR modelFile=./ckp/yoloxs124_30.mindir  outputFile=yoloxs124_30  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错： 1. 我将SilU替换为EdgeSiLU后，silu不支持的报错消失了，但是似乎不支持make_list! !输入图片说明 2.另外我将SilU替换为EdgeSiLU后，尝试将cpkt转换为onnx格式时，同样会报错不支持make_list算子，报错如下： !输入图片说明,2025-01-03T16:07:41+08:00,"gitee,mindspore-assistant",closed,0,3,https://gitee.com/mindspore/mindspore/issues/IBFI4G,mindsporelite目前仅支持2.2.14、2.3.0和2.3.1，其他版本未经过完整的验证；请安装一致对应版本的ascenddrive、firmware和ascendtoolkit，再次尝试，谢谢！,三个版本的mindsporelite都尝试过了，都是上面的报错,看日志这是在导出onnx模型时报的错，请问是在导出onnx模型吗？ 不是的话python脚本麻烦附一下
mindformers,mengyuanli,GMM 310P nz weight自动转换逻辑被重构误删," 1.Describe the current behavior / 问题描述 (Mandatory / 必填) GMM 310P nz weight没有自动转换 原本转换逻辑在https://gitee.com/mindspore/mindspore/pulls/74073/中实现， 经过https://gitee.com/mindspore/mindspore/pulls/74745重构，该部分逻辑被误删 样例：  （根据实际修改和增删） > mixtral网络8x7B 16卡，配置执行参数：cell共享+梯度累加4+dp1mp4ep1pp4mb4gas1bs2，训练报 RuntimeError: Exec graph failed  2.Environment / 环境信息 (Mandatory / 必填)  **Hardware Environment / 硬件环境(Mandatory / 必填)**:   Hardware (e.g.`Ascend910B1`/`Mac CPU`)   样例：   3.Related testcase / 关联用例 (Mandatory / 必填) >  **Testcase Name/ 用例名 (Mandatory / 必填)**: >    Testcase Name(e.g.test\_mf\_llama\_7b\_wiki4096\_train\_cell\_dp1mp4pp4mb4\_910\_16p\_0005): * >  **Excute Mode / 执行模式 (Mandatory / 必填)**: >    Excute Mode(e.g., Graph\PyNative): * >    Excute Mode(e.g., O0\O1\O2)：O*  4.Steps to reproduce the issue / 重现步骤 (Mandatory / 必填) > （1）get code from mindformers > （2）cd mindformers/research/qwen1_5 > （3）bash ../../scripts/msrun_launcher.sh ""python run_qwen1_5_long_seq.py config research/qwen1_5/predict_qwen1_5_72b_chat.yaml load_checkpoint /home/workspace/large_model_ckpt//qwen1_5/72b/qwen1_5_72b_chat_181 run_mode predict use_parallel True do_sample False  auto_trans_ckpt False seq_length 32768 predict_length 32768"" 8 > （4）验证网络推理精度是否正常  5.Describe the expected behavior / 预期结果 (Mandatory / 必填) > **【预期结果】**：qwen1_5 推理精度正常  6.Related log / screenshot / 日志 / 截图 (Mandatory / 必填) 报错关键日志截图： !image 完整日志（通过附件上传）： !image    7.Special notes for this issue/备注 (Optional / 选填) **【定位人】**吴某某（根据实际修改）",2025-01-02T15:04:34+08:00,,closed,0,0,https://gitee.com/mindspore/mindspore/issues/IBF6PM
